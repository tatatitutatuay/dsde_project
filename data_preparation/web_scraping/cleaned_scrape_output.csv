abstract,keywords,country
,[],[]
"We show evidence of particle acceleration at GEV energies associated directly with protons from the prompt emission of a long-duration M6-class solar flare on July 17, 2023, rather than from protons acceleration by shocks from its associated Coronal Mass Ejection (CME), which erupted with a speed of 1342 km/s. Solar Energetic Particles (SEP) accelerated by the blast have reached Earth, up to an almost S3 (strong) category of a radiation storm on the NOAA scale.
Also, we show a temporal correlation between the fast rising of GOES-16 proton and muon excess at ground level in the count rate of the New-Tupi muon detector at the central SAA region.
A Monte Carlo spectral analysis based on muon excess at New-Tupi is consistent with the acceleration of electrons and protons (ions) up to relativistic energies (GeV energy range) in the impulsive phase of the flare. In addition, we present another two marginal particle excesses (with low confidence) at ground-level detectors in correlation with the solar flare prompt emission.","['sun:activity', 'high-speed stream', 'cosmic rays modulation']",['Brazil']
"Metamaterials with functional responses, such as wave-based responses or deformation-induced property variation under external stimuli, can exhibit varying properties or functionalities under different conditions. Herein, we aim at rapid inverse design of these metamaterials to meet target qualitative functional behaviors. This inverse problem is challenging due to its intractability and the existence of non-unique solutions. Past works mainly focus on deep-learning-based methods that are data-demanding, require time-consuming training and hyperparameter tuning, and are non-interpretable. To overcome these limitations, we propose the Random-forest-based Interpretable Generative Inverse Design (RIGID), a single-shot inverse design method to achieve the fast generation of metamaterial designs with on-demand functional behaviors. Unlike most existing methods, by exploiting the interpretability of the random forest, we eliminate the need to train an inverse model mapping responses to designs. Based on the likelihood of target satisfaction derived from the trained forward model, one can sample design solutions using Markov chain Monte Carlo methods. The RIGID method therefore functions as a generative model that captures the conditional distribution of satisfying solutions given a design target. We demonstrate the effectiveness and efficiency of RIGID on both acoustic and optical metamaterial design problems where only small datasets (less than 250 training samples) are available. Synthetic design problems are created to further illustrate and validate the mechanism of likelihood estimation in RIGID. This work offers a new perspective on solving on-demand inverse design problems, showcasing the potential for incorporating interpretable machine learning into generative design and eliminating its large data requirement.",[],[]
,[],[]
,[],[]
"Building open-ended learning agents involves challenges in pre-trained language model (LLM) and reinforcement learning (RL) approaches. LLMs struggle with context-specific real-time interactions, while RL methods face efficiency issues for exploration. To this end, we propose OpenContra, a co-training framework that cooperates LLMs and GRL to construct an open-ended agent capable of comprehending arbitrary human instructions.
The implementation comprises two stages: (1) fine-tuning an LLM to translate human instructions into structured goals, and curriculum training a goal-conditioned RL policy to execute arbitrary goals; (2) collaborative training to make the LLM and RL policy learn to adapt each, achieving open-endedness on instruction space.
We conduct experiments on Contra, a battle royale FPS game with a complex and vast goal space.
The results show that an agent trained with OpenContra comprehends arbitrary human instructions and completes goals with a high completion ratio, which proves that OpenContra may be the first practical solution for constructing open-ended embodied agents.","['Machine', 'Learning', 'ICML']",[]
,[],[]
,[],[]
"In the wake of large language models, there has been a resurgence of claims and questions about the Turing test and its value for AI, which are reminiscent of decades of practical “Turing” tests. If AI were quantum physics, by now several “Schrödinger’s” cats could have been killed. Better late than never, it is time for a historical reconstruction of Turing’s beautiful thought experiment. In this paper I present a wealth of evidence, including new archival sources, give original answers to several open questions about Turing’s 1950 paper, and address the core question of the value of Turing’s test.","['Alan', 'Turing', 'Turing test', 'Thought experiment', 'Foundations of', 'AI & computer science', 'Galileo', 'Galilei', 'History of science', 'History of', 'AI']",['Brazil']
"Online recruitment platforms typically employ Person-Job Fit models in the core service that automatically match suitable job seekers with appropriate job positions. While existing works leverage historical or contextual information, they often disregard a crucial aspect: job seekers’ social relationships in professional networks. This paper emphasizes the importance of incorporating professional networks into the Person-Job Fit model. Our innovative approach consists of two stages: (1) defining a Workplace Heterogeneous Information Network (WHIN) to capture heterogeneous knowledge, including professional connections and pre-training representations of various entities using a heterogeneous graph neural network; (2) designing a Contextual Social Attention Graph Neural Network (CSAGNN) that supplements users’ missing information with professional connections’ contextual information. We introduce a job-specific attention mechanism in CSAGNN to handle noisy professional networks, leveraging pre-trained entity representations from WHIN. We demonstrate the effectiveness of our approach through experimental evaluations conducted across three real-world recruitment datasets from LinkedIn, showing superior performance compared to baseline models.","['Person-Job', 'Fit', 'Heterogeneous', 'Information', 'Network', 'Graph', 'Neural', 'Network']",['China']
"Recent years have seen a lot of progress in algorithms for learning parameters of spreading dynamics from both full and partial data. Some of the remaining challenges include model selection under the scenarios of unknown network structure, noisy data, missing observations in time, as well as an efficient incorporation of prior information to minimize the number of samples required for an accurate learning. Here, we introduce a universal learning method based on scalable dynamic message-passing technique that addresses these challenges often encountered in real data. The algorithm leverages available prior knowledge on the model and on the data, and reconstructs both network structure and parameters of a spreading model. We show that a linear computational complexity of the method with the key model parameters makes the algorithm scalable to large network instances.",[],[]
,[],[]
,[],[]
"The prediction of tumor progression and chemotherapy response has been recently tackled exploiting Tumor Infiltrating Lymphocytes (TILs) and the nuclear protein Ki67 as prognostic factors.
Recently, deep neural networks (DNNs) have been shown to achieve top results in estimating Ki67 expression and simultaneous determination of intratumoral TILs score in breast cancer cells. However,
in the last ten years the extraordinary progress induced by deep models proliferated
at least as much as their resource demand.
The exorbitant computational costs required to query (and in some cases also to store) a deep model represent a strong limitation in resource-limited contexts, like that of IoT-based applications to support healthcare personnel.
To this end, we propose a resource consumption-aware DNN for the effective estimate of the percentage of Ki67-positive cells in breast cancer screenings. Our approach reduced up to 75%percent7575\%75 % and 89%percent8989\%89 % the usage of memory and disk space respectively, up to 1.5×1.5\times1.5 × the energy consumption, and preserved or improved the overall accuracy of a benchmark state-of-the-art solution. Encouraged by such positive results, we developed and structured the adopted framework so as to allow its general purpose usage, along with a public software repository to support its usage.","['Tumor infiltrating lymphocytes', 'Ki67 protein', 'Resource-limited learning', 'Resource-limited devices', 'DNN compression', 'Deep learning.']",['Italy']
"Growth in the penetration of renewable energy sources makes supply more uncertain and leads to an increase in the system imbalance. This trend, together with the single imbalance pricing, opens an opportunity for balance responsible parties (BRPs) to perform energy arbitrage in the imbalance settlement mechanism. To this end, we propose a battery control framework based on distributional reinforcement learning (DRL). Our proposed control framework takes a risk-sensitive perspective, allowing BRPs to adjust their risk preferences: we aim to optimize a weighted sum of the arbitrage profit and a risk measure while constraining the daily number of cycles for the battery. We assess the performance of our proposed control framework using the Belgian imbalance prices of 2022 and compare two state-of-the-art RL methods, deep Q learning and soft actor-critic. Results reveal that the distributional soft actor-critic method can outperform other methods. Moreover, we note that our fully risk-averse agent appropriately learns to hedge against the risk related to the unknown imbalance price by (dis)charging the battery only when the agent is more certain about the price.",[],[]
"The potential for augmenting the segmentation of brain tumors through the use of few-shot learning is vast. Although several deep learning networks (DNNs) demonstrate promising results in terms of segmentation, they require a substantial quantity of training data in order to produce suitable outcomes. Furthermore, a major issue faced by most of these models is their ability to perform well when faced with unseen classes. To address these challenges, we propose a one-shot learning model for segmenting brain tumors in magnetic resonance images (MRI) of the brain, based on a single prototype similarity score. Leveraging the recently developed techniques of few-shot learning, which involve the utilization of support and query sets of images for training and testing purposes, we strive to obtain a definitive tumor region by focusing on slices that contain foreground classes. This approach differs from other recent DNNs that utilize the entire set of images. The training process for this model is carried out iteratively, with each iteration involving the selection of random slices that contain foreground classes from randomly sampled data as the query set, along with a different random slice from the same sample as the support set. In order to distinguish the query images from the class prototypes, we employ a metric learning-based approach that relies on non-parametric thresholds. We employ the multimodal Brain Tumor Image Segmentation (BraTS) 2021 dataset, which comprises 60 training images and 350 testing images. The effectiveness of the model is assessed using the mean dice score and mean Intersection over Union (IoU) score. The experimental results demonstrate a dice score of 83.42, which exceeds the performance of other works in the literature. Moreover, the proposed one-shot segmentation model surpasses conventional methods in terms of computational time, memory usage, and the amount of data employed.","['brain tumor', 'magnetic resonance images', 'few-shot learning']",[]
"I use QAOA to solve the Hamiltonian Circle problem. First, inspired by Lucas [8], I define the QUBO form of Hamiltonian Cycle an transform it to a quantum circuit by embedding the problem of n𝑛nitalic_n vertices to an encoding of (n−1)2superscript𝑛12(n-1)^{2}( italic_n - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT qubits. Then, I calcluate the spectrum of the cost hamiltonian for both triangle case and square case and justify my definition. I also write a python program to generate the cost hamiltonian automatically for finding the hamiltonian cycle in an arbitrary graph. I test the correctess of the hamailtonian by analyze their energy spectrums. Since the (n−1)2superscript𝑛12(n-1)^{2}( italic_n - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT embedding limit my simulation of graph size to be less than 5555, I decide to test the correctness, only for small and simple graph in this project. I implement the QAOA algorithm using qiskit and run the simulation for the triangle case and the square case, which are easy to test the correctness, both with and without noise. A very interesting result I got is that for the square case, the QAOA get much better result on a noisy simulator than a noiseless simulator! The explanation for this phenomena require further investigation, perhaps quantum noise can actually be helpful, rather than harmful in the annealing algorithms. I also use two different kinds of mixer, Rxsubscript𝑅𝑥R_{x}italic_R start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT mixer and Rysubscript𝑅𝑦R_{y}italic_R start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT circuit to run the simulation. It turns out that Rxsubscript𝑅𝑥R_{x}italic_R start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT mixer performs much better than Rysubscript𝑅𝑦R_{y}italic_R start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT mixer in this problem.",[],[]
"The Bayesian reconstruction entropy is considered an alternative to the Shannon-Jaynes entropy, as it does not exhibit the asymptotic flatness characteristic of the Shannon-Jaynes entropy and obeys the scale invariance. It is commonly utilized in conjunction with the maximum entropy method to derive spectral functions from Euclidean time correlators produced by lattice QCD simulations. This study expands the application of the Bayesian reconstruction entropy to the reconstruction of spectral functions for Matsubara or imaginary-time Green’s functions in quantum many-body physics. Furthermore, it extends the Bayesian reconstruction entropy to implement the positive-negative entropy algorithm, enabling the analytic continuations of matrix-valued Green’s functions on an element-wise manner. Both the diagonal and off-diagonal components of the matrix-valued Green’s functions are treated equally. Benchmark results for the analytic continuations of synthetic Green’s functions indicate that the Bayesian reconstruction entropy, when combined with the preblur trick, demonstrates comparable performance to the Shannon-Jaynes entropy. Notably, it exhibits greater resilience to noises in the input data, particularly when the noise level is moderate.",[],['China']
"In this article, we discuss how a kind of hybrid computation, which employs symbolic, numeric, classic, and quantum algorithms, allows us to conduct Hartree-Fock electronic structure computation of molecules. In the proposed algorithm, we replace the Hartree-Fock equations with a set of equations composed of multivariate polynomials. We transform those polynomials to the corresponding Gröbner bases, and then we investigate the corresponding quotient ring, wherein the orbital energies, the LCAO coefficients, or the atomic coordinates are represented by the variables in the ring. In this quotient ring, the variables generate the transformation matrices that represent the multiplication with the monomial bases, and the eigenvalues of those matrices compose the roots of the equation. The quantum phase estimation (QPE) algorithm enables us to record those roots in the quantum states, which would be used in the input data for more advanced and more accurate quantum computations.",[],[]
,[],[]
,[],[]
"Let R𝑅Ritalic_R be a finitely generated ℕℕ\mathbb{N}blackboard_N-graded algebra domain over a Noetherian ring and let I𝐼Iitalic_I be a homogeneous ideal of R𝑅Ritalic_R. Given P∈Ass⁡(R/I)𝑃Ass𝑅𝐼P\in\operatorname{Ass}(R/I)italic_P ∈ roman_Ass ( italic_R / italic_I ) one defines the v𝑣vitalic_v-invariant vP⁢(I)subscript𝑣𝑃𝐼v_{P}(I)italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I ) of I𝐼Iitalic_I at P𝑃Pitalic_P as the least c∈ℕ𝑐ℕc\in\mathbb{N}italic_c ∈ blackboard_N such that P=I:f:𝑃𝐼𝑓P=I:fitalic_P = italic_I : italic_f for some f∈Rc𝑓subscript𝑅𝑐f\in R_{c}italic_f ∈ italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. A classical result of Brodmann [1] asserts that Ass⁡(R/In)Ass𝑅superscript𝐼𝑛\operatorname{Ass}(R/I^{n})roman_Ass ( italic_R / italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) is constant for large n𝑛nitalic_n. So it makes sense to consider a prime ideal P∈Ass⁡(R/In)𝑃Ass𝑅superscript𝐼𝑛P\in\operatorname{Ass}(R/I^{n})italic_P ∈ roman_Ass ( italic_R / italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) for all the large n𝑛nitalic_n and investigate how vP⁢(In)subscript𝑣𝑃superscript𝐼𝑛v_{P}(I^{n})italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) depends on n𝑛nitalic_n. We prove that vP⁢(In)subscript𝑣𝑃superscript𝐼𝑛v_{P}(I^{n})italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) is eventually a linear function of n𝑛nitalic_n.
When R𝑅Ritalic_R is the polynomial ring over a field this statement has been proved independently also by Ficarra and Sgroi in their recent preprint [4].","['Associated primes', 'v-invariant']",[]
"Image-to-image translation has gained popularity in the medical field to transform images from one domain to another.
Medical image synthesis via domain transformation is advantageous in its ability to augment an image dataset where images for a given class is limited. From the learning perspective, this process contributes to data-oriented robustness of the model by inherently broadening the model’s exposure to more diverse visual data and enabling it to learn more generalized features. In the case of generating additional neuroimages, it is advantageous to obtain unidentifiable medical data and augment smaller annotated datasets. This study proposes the development of a CycleGAN model for translating neuroimages from one field strength to another (e.g., 3 Tesla to 1.5). This model was compared to a model based on DCGAN architecture. CycleGAN was able to generate the synthetic and reconstructed images with reasonable accuracy. The mapping function from the source (3 Tesla) to target domain (1.5 Tesla) performed optimally with an average PSNR value of 25.69 ±plus-or-minus\pm± 2.49 dB and an MAE value of 2106.27 ±plus-or-minus\pm± 1218.37.",[],[]
,[],[]
"Learning from demonstration is a powerful method for teaching robots new skills, and more demonstration data often improves policy learning. However, the high cost of collecting demonstration data is a significant bottleneck. Videos, as a rich data source, contain knowledge of behaviors, physics, and semantics, but extracting control-specific information from them is challenging due to the lack of action labels. In this work, we introduce a novel framework, Any-point Trajectory Modeling (ATM), that utilizes video demonstrations by pre-training a trajectory model to predict future trajectories of arbitrary points within a video frame. Once trained, these trajectories provide detailed control guidance, enabling the learning of robust visuomotor policies with minimal action-labeled data. Our method’s effectiveness is demonstrated across 130 simulation tasks, focusing on language-conditioned manipulation tasks. Visualizations and code are available at: https://xingyu-lin.github.io/atm.",[],[]
"We reaffirm the claim of Lee et al. [preceding Comment, Phys. Rev. A 108, 066401 (2023)] that the expression of quantum dual total correlation of a multipartite system in terms of quantum relative entropy as proposed in previous work [A. Kumar, Phys. Rev. A 96, 012332 (2017)] is not correct. We provide alternate expression(s) of quantum dual total correlation in terms of quantum relative entropy. We, however, prescribe that in computing quantum dual total correlation one should use its expression in terms of von Neumann entropy.",[],['India']
"Coarse-to-fine schemes are widely used in traditional single-image motion deblur; however, in the context of deep learning, existing multi-scale algorithms not only require the use of complex modules for feature fusion of low-scale RGB images and deep semantics, but also manually generate low-resolution pairs of images that do not have sufficient confidence. In this work, we propose a multi-scale network based on single-input and multiple-outputs(SIMO) for motion deblurring. This simplifies the complexity of algorithms based on a coarse-to-fine scheme. To alleviate restoration defects impacting detail information brought about by using a multi-scale architecture, we combine the characteristics of real-world blurring trajectories with a learnable wavelet transform module to focus on the directional continuity and frequency features of the step-by-step transitions between blurred images to sharp images. In conclusion, we propose a multi-scale network with a learnable discrete wavelet transform (MLWNet), which exhibits state-of-the-art performance on multiple real-world deblurred datasets, in terms of both subjective and objective quality as well as computational efficiency. Our code will be open-sourced on github later.",[],[]
"The laws of model size, data volume, computation and model performance have been extensively studied in the field of Natural Language Processing (NLP). However, the scaling laws in Optical Character Recognition (OCR) have not yet been investigated. To address this, we conducted comprehensive studies that involved examining the correlations between performance and the scale of models, data volume and computation in the field of text recognition. Conclusively, the study demonstrates smooth power laws between performance and model size, as well as training data volume, when other influencing factors are held constant. Additionally, we have constructed a large-scale dataset called REBU-Syn, which comprises 6 million real samples and 18 million synthetic samples. Based on our scaling law and new dataset, we have successfully trained a scene text recognition model, achieving a new state-of-the-art on 6 common test benchmarks with a top-1 average accuracy of 97.42%percent\%%.",[],[]
"Estimating the 6D object pose from a single RGB image often involves noise and indeterminacy due to challenges such as occlusions and cluttered backgrounds.
Meanwhile, diffusion models have shown appealing performance in generating high-quality images from random noise with high indeterminacy through step-by-step denoising.
Inspired by their denoising capability, we propose a novel diffusion-based framework (6D-Diff) to handle the noise and indeterminacy in object pose estimation for better performance.
In our framework, to establish accurate 2D-3D correspondence, we formulate 2D keypoints detection as a reverse diffusion (denoising) process.
To facilitate such a denoising process, we design a Mixture-of-Cauchy-based forward diffusion process and condition the reverse process on the object features.
Extensive experiments on the LM-O and YCB-V datasets demonstrate the effectiveness of our framework.",[],[]
,[],[]
"Decision-making is a dynamic process requiring perception, memory, and reasoning to make choices and find optimal policies.
Traditional approaches to decision-making suffer from sample efficiency and generalization, while large-scale self-supervised pretraining has enabled fast adaptation with fine-tuning or few-shot learning in language and vision.
We thus argue to integrate knowledge acquired from generic large-scale self-supervised pretraining into downstream decision-making problems.
We propose Pretrain-Then-Adapt pipeline and survey recent work on data collection, pretraining objectives and adaptation strategies for decision-making pretraining and downstream inference.
Finally, we identify critical challenges and future directions for developing decision foundation model with the help of generic and flexible self-supervised pretraining.",[],[]
"Computational imaging (CI) has been attracting a lot of interest in recent years for its superiority over traditional imaging in various applications. In CI systems, information is generally acquired in an encoded form and subsequently decoded via processing algorithms, which is quite in line with the information transmission mode of modern communication, and leads to emerging studies from the viewpoint of information optical imaging.
Currently, one of the most important issues to be theoretically studied for CI is to quantitatively evaluate the fundamental ability of information acquisition, which is essential for both objective performance assessment and efficient design of imaging system.
In this paper, by incorporating the Bayesian filtering paradigm, we propose a framework for CI that enables quantitative evaluation and design of the imaging system, and demonstate it based on ghost imaging. In specific, this framework can provide a quantitative evaluation on the acquired information through Fisher information and Cramér-Rao Lower Bound (CRLB), and the intrinsic performance of the imaging system can be accessed in real-time.
With simulation and experiments, the framework is validated and compared with existing linear unbiased algorithms.
In particular, the image retrieval can reach the CRLB.
Furthermore, information-driven adaptive design for optimizing the information acquisition procedure is also achieved.
By quantitative describing and efficient designing, the proposed framework is expected to promote the practical applications of CI techniques.",[],[]
"Design patterns provide a systematic way to convey solutions to recurring modeling challenges. This paper introduces design patterns for hybrid modeling, an approach that combines modeling based on first principles with data-driven modeling techniques. While both approaches have complementary advantages there are often multiple ways to combine them into a hybrid model, and the appropriate solution will depend on the problem at hand. In this paper, we provide four base patterns that can serve as blueprints for combining data-driven components with domain knowledge into a hybrid approach. In addition, we also present two composition patterns that govern the combination of the base patterns into more complex hybrid models. Each design pattern is illustrated by typical use cases from application areas such as climate modeling, engineering, and physics.",[],[]
,[],[]
"Complex dynamical systems are notoriously difficult to model because some degrees of freedom (e.g., small scales) may be computationally unresolvable or are incompletely understood, yet they are dynamically important. For example, the small scales of cloud dynamics and droplet formation are crucial for controlling climate, yet are unresolvable in global climate models. Semi-empirical closure models for the effects of unresolved degrees of freedom often exist and encode important domain-specific knowledge. Building on such closure models and correcting them through learning the structural errors can be an effective way of fusing data with domain knowledge. Here we describe a general approach, principles, and algorithms for learning about structural errors. Key to our approach is to include structural error models inside the models of complex systems, for example, in closure models for unresolved scales. The structural errors then map, usually nonlinearly, to observable data. As a result, however, mismatches between model output and data are only indirectly informative about structural errors, due to a lack of labeled pairs of inputs and outputs of structural error models. Additionally, derivatives of the model may not exist or be readily available. We discuss how structural error models can be learned from indirect data with derivative-free Kalman inversion algorithms and variants, how sparsity constraints enforce a “do no harm” principle, and various ways of modeling structural errors. We also discuss the merits of using non-local and/or stochastic error models. In addition, we demonstrate how data assimilation techniques can assist the learning about structural errors in non-ergodic systems. The concepts and algorithms are illustrated in two numerical examples based on the Lorenz-96 system and a human glucose-insulin model.",[],[]
"We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently contain distributional information, liberating the network from a single output to concurrently generate multiple samples proves to be highly effective. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with two intriguing properties: highly compressed representation and more general zero-shot conditional generation. We demonstrate the efficacy of DDN and these intriguing properties through experiments on CIFAR-10 and FFHQ.",[],[]
"The tasks of designing
messenger RNAs and non-coding RNAs are
discrete optimization problems, and
several versions of these problems are NP-hard.
As an alternative to commonly used local search methods,
we formulate these problems
as continuous optimization and develop
a general framework for this optimization based on
a new concept of “expected partition function”.
The basic idea is to start with a distribution over all possible candidate sequences,
and extend the objective function from a sequence to a distribution. We then use gradient descent-based optimization methods
to improve the extended objective function, and the distribution
will gradually shrink towards a one-hot sequence (i.e., a single sequence).
We consider two important case studies within this framework,
the mRNA design problem
optimizing for partition function (i.e., ensemble free energy)
and the non-coding RNA design problem optimizing for conditional (i.e., Boltzmann) probability.
In both cases, our approach demonstrate promising preliminary results. We make our code available at https://github.com/KuNyaa/RNA_Design_codebase.",[],[]
"We investigate the embedding formalism in conjunction with the Mellin transform to determine tree-level gluon amplitudes in AdS/CFT. Detailed computations of three to five-point correlators are conducted, ultimately distilling what were previously complex results for five-point correlators into a more succinct and comprehensible form. We then proceed to derive a recursion relation applicable to a specific class of n𝑛nitalic_n-point gluon amplitudes. This relation is instrumental in systematically constructing amplitudes for a range of topologies. We illustrate its efficacy by specifically computing six to eight-point functions.
Despite the complexity encountered in the intermediate steps of the recursion, the higher-point correlator is succinctly expressed as a polynomial in boundary coordinates, upon which a specific differential operator acts. Remarkably, we observe that these amplitudes strikingly mirror their counterparts in flat space, traditionally computed using standard Feynman rules. This intriguing similarity has led us to propose a novel dictionary: comprehensive rules that bridge AdS Mellin amplitudes with flat-space gluon amplitudes.",[],[]
,[],[]
"We consider phenomenological aspects of a natural class of
Standard Model-like supersymmetric F-theory vacua realized through
flux breaking of rigid E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT gauge factors.
Three
generations of Standard Model matter
are realized in many of these vacua.
We further
find that many other Standard Model-like features
are naturally compatible
with these constructions. For example, dimension-4 and 5 terms associated
with proton decay are ubiquitously suppressed. Many of these features are
due to the group theoretical structure
of E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT and associated F-theory geometry. In particular, a set of approximate global symmetries descends
from the E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT group,
leading to exponential suppression of undesired
couplings.",[],[]
"We present a new formulation for Yang-Mills scattering amplitudes in any number of dimensions and at any loop order, based on the same combinatorial and binary-geometric ideas in kinematic space recently used to give an all-order description of Tr ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT theory. We propose that in a precise sense the amplitudes for a suitably “stringy” form of these two theories are identical, up to a simple shift of kinematic variables. This connection is made possible by describing the amplitudes for n𝑛nitalic_n gluons via a “scalar scaffolding”, arising from the scattering of 2⁢n2𝑛2n2 italic_n colored scalars coming in n𝑛nitalic_n distinct pairs of flavors fusing to produce the gluons. Fundamental properties of the “u𝑢uitalic_u-variables”, describing the “binary geometry” for surfaces appearing in the topological expansion, magically guarantee that the kinematically shifted Tr ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT amplitudes satisfy the physical properties needed to be interpreted as scaffolded gluons. These include multilinearity, gauge invariance, and factorization on tree- and loop- level gluon cuts. Our “stringy” scaffolded gluon amplitudes coincide with amplitudes in the bosonic string for extra-dimensional gluon polarizations at tree-level, but differ (and are simpler) at loop-level. We provide many checks on our proposal, including matching non-trivial leading singularities through two loops. The simple counting problem underlying the u𝑢uitalic_u variables autonomously “knows” about everything needed to convert colored scalar to gluon amplitudes, exposing a striking “discovery” of Yang-Mills amplitudes from elementary combinatorial ideas in kinematic space.",[],[]
,[],[]
"Dark matter constitutes 26%percent2626\%26 % of the total energy in our universe, but its nature remains elusive. Among the assortment of viable dark matter candidates, particles and fields with masses lighter than 40⁢e⁢V40eV40\mathrm{eV}40 roman_e roman_V, called ultralight dark matter, stand out as particularly promising thanks to their feasible production mechanisms, consistency with current observations, and diverse and testable predictions. In light of ongoing and forthcoming experimental and observational efforts, it is important to advance the understanding of ultralight dark matter from theoretical and phenomenological perspectives: How does it interact with itself, ordinary matter, and gravity? What are some promising ways to detect it?
In this thesis, we aim to explore the dynamics and interaction of ultralight dark matter and other astrophysically accessible hypothetical fields in a relatively model-independent way. Without making specific assumptions about their ultraviolet physics, we first demonstrate a systematic approach for constructing a classical effective field theory for both scalar and vector dark fields and discuss conditions for its validity. Then, we explore the interaction of ultralight dark fields, both gravitational and otherwise, within various contexts such as nontopological solitons, neutron stars, and gravitational waves.",[],[]
"The subsolar mass  primordial black hole (PBH) attracts attention as robust evidence of its primordial origin against the astrophysical black hole.
Not only with themselves, PBHs can also form binaries with ordinary astrophysical objects, catching them by  gravitational wave (GW) bremsstrahlung.
We discuss the detectability of the inspiral GWs from binaries consisting of a PBH and a  white dwarf (WD) by using space-borne gravitational wave interferometers like DECIGO. The conservative assessment shows the expected event number in three years by DECIGO is 𝒪⁢(10−6)𝒪superscript106\mathcal{O}(10^{-6})caligraphic_O ( 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT ) for MPBH∼0.1⁢M⊙similar-tosubscript𝑀PBH0.1subscript𝑀direct-productM_{\textrm{PBH}}\sim 0.1M_{\odot}italic_M start_POSTSUBSCRIPT PBH end_POSTSUBSCRIPT ∼ 0.1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.
Possible enhancement mechanisms of WD-PBH binary formation may amplify this event rate. We discuss how large enhancement associated with WDs is required to detect WD-PBH merger events without violating the existing constraints on the PBH-PBH merger by the ground-based detector.",[],['Japan']
"In this work, we compare the supermassive black hole (SMBH) and host galaxy properties of X-ray obscured and unobscured AGN. For that purpose, we use ∼35 000similar-toabsent35000\sim 35\,000∼ 35 000 X-ray detected AGN in the 4XMM-DR11 catalogue for which there are available measurements for their X-ray spectral parameters, such as the hydrogen column density, NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT, and photon index, ΓΓ\Gammaroman_Γ, from the XMM2Athena Horizon 2020 European project. We construct the spectral energy distributions (SEDs) of the sources and we calculate the host galaxy properties via SED fitting analysis, utilising the CIGALE code. We apply strict photometric requirements and quality selection criteria to include only sources with robust X-ray and SED fitting measurements. Our sample consists of 1 443 AGN. In the first part of our analysis, we use different NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT thresholds (102323{}^{23}start_FLOATSUPERSCRIPT 23 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT or 102222{}^{22}start_FLOATSUPERSCRIPT 22 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT), taking also into account the uncertainties associated with the NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT measurements, to classify these sources into obscured and unobscured (or mildly obscured). We find that obscured AGN tend to live in more massive systems (by ∼0.1similar-toabsent0.1\sim 0.1∼ 0.1 dex) that have lower SFR (by ∼0.25similar-toabsent0.25\sim 0.25∼ 0.25 dex) compared to their unobscured counterparts. However, only the difference in stellar mass, M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT, appears statistically significant (>2⁢σabsent2𝜎>2\sigma> 2 italic_σ). The results do not depend on the NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT threshold used to classify AGN. The differences in M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT and SFR are not statistically significant for luminous AGN (log⁢(LX,2−10⁢KeV/erg⁢s−1)>44logsubscriptLX210KeVergsuperscripts144\rm log\,(L_{X,2-10\,KeV}/erg\,s^{-1})>44roman_log ( roman_L start_POSTSUBSCRIPT roman_X , 2 - 10 roman_KeV end_POSTSUBSCRIPT / roman_erg roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) > 44). Our findings also show that unobscured AGN have, on average, higher specific black hole accretion rates, λs⁢B⁢H⁢A⁢Rsubscript𝜆𝑠𝐵𝐻𝐴𝑅\lambda_{sBHAR}italic_λ start_POSTSUBSCRIPT italic_s italic_B italic_H italic_A italic_R end_POSTSUBSCRIPT, compared to their obscured counterparts, a parameter which is often used as a proxy of the Eddington ratio. In the second part of our analysis, we cross-match the 1 443 X-ray AGN with the SDSS DR16 quasar catalogue to obtain information on the SMBH properties of our sources. This results in 271 type 1 AGN, at z<1.9z1.9\rm z<1.9roman_z < 1.9. Our findings show that type 1 AGN with increased NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT (>1022absentsuperscript1022>10^{22}> 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT) tend to have higher black hole masses, MB⁢H𝐵𝐻{}_{BH}start_FLOATSUBSCRIPT italic_B italic_H end_FLOATSUBSCRIPT, compared to AGN with lower NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values, at similar M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT. The MB⁢H𝐵𝐻{}_{BH}start_FLOATSUBSCRIPT italic_B italic_H end_FLOATSUBSCRIPT/M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT ratio remains consistent for NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values below 102222{}^{22}start_FLOATSUPERSCRIPT 22 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT, but it exhibits signs of an increase at higher NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values. Finally, we detect a correlation between ΓΓ\Gammaroman_Γ and Eddington ratio, but only for type 1 sources with N<H1022{}_{H}<10^{22}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT < 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT.",[],[]
"Based on the covariant underdamped and overdamped Langevin equations
with Stratonovich coupling to multiplicative noises and the associated
Fokker-Planck equations on Riemannian manifold, we present
the first law of stochastic thermodynamics on the trajectory level.
The corresponding fluctuation theorems are also
established, with the total entropy production of the Brownian particle
and the heat reservoir playing the role of dissipation function.","['Langevin equation', 'Fokker-Planck equation', 'fluctuation theorem', 'Riemannian manifold']",['China']
"The usual gravitational wave memory effect can be understood as a change in the separation of two initially comoving observers due to a burst of gravitational waves.
Over the past few decades, a wide variety of other, “persistent” observables which measure permanent effects on idealized detectors have been introduced, each probing distinct physical effects.
These observables can be defined in (regions of) any spacetime where there exists a notion of radiation, such as perturbation theory off of a fixed background, nonlinear plane wave spacetimes, or asymptotically flat spacetimes.
Many of the persistent observables defined in the literature have been considered only in asymptotically flat spacetimes, and the perturbative nature of such calculations has occasionally obscured deeper relationships between these observables that hold more generally.
The goal of this paper is to show how these more general results arise, and to do so we focus on two observables related to the separation between two, potentially accelerated observers.
The first is the curve deviation, which is a natural generalization of the displacement memory, and also contains what this paper proposes to call drift memory (previously called “subleading displacement memory”) and ballistic memory.
The second is a relative proper time shift that arises between the two observers, either at second order in their initial separation and relative velocity, or in the presence of relative acceleration.
The results of this paper are, where appropriate, entirely non-perturbative in the curvature of spacetime, and so could be used beyond leading order in asymptotically flat spacetimes.",[],[]
,[],[]
"Context:The existence of low-mass giants with large amounts of lithium (Li) in their surfaces has challenged stellar evolution for decades. One of the possibilities usually discussed in the literature to explain these Li-rich giants involves the interaction with a close binary companion, a scenario that predicts that, when compared against their non-enriched counterparts, Li-rich giants should preferentially be found as part of binary systems.
Aims:We aim to assemble the largest possible sample of low-mass giants with well-measured Li abundances, to determine with high statistical significance the close binary fractions of Li-rich and Li-normal giants, and thus test the binary interaction scenario for the emergence of Li-rich giants.
Methods:We develop a method that uses radial velocities (RVs) at three different epochs to quantify the degree of RV variability, which we use as a proxy for the presence of a close binary companion. The method is tested and calibrated against samples of known RV standard stars and known spectroscopic binaries. We then assemble a sample of 1418 giants with available RVs from RAVE, GALAH, and Gaia, as well as stellar parameters and Li abundances from GALAH, to which we apply our variability classification. We can determine an evolutionary state for 1030 of these giants. We also compare the results of our RV variability analysis with binarity indicators from the Gaia mission.
Results:When applying our methodology to the control samples, we find that the accuracy of the classification is controlled by the precision of the RVs used in the analysis. For the set of RVs available for the giants, this accuracy is 80-85%. Consistent with seismic studies, the resulting sample of giants contains a fraction of Li-rich objects in the red clump (RC) that is twice as large as that in the first ascent red giant branch (RGB). Among RC giants, the fractions of Li-rich objects with high RV variability and with no RV variability are the same as those for Li-normal objects, but we find some evidence that these fractions may be different for giants in the first-ascent RGB. Analysis of binary indicators in Gaia DR3 shows a smaller fraction of binary giants than our criteria, but no relation can be seen between Li enrichment and binarity either.
Conclusions:Our RV variability analysis indicates that there is no preference for Li-rich giants in the RC to be part of binary systems, thus arguing against a binary interaction scenario for the genesis of the bulk of Li-rich giants at that evolutionary stage. On the other hand, Li-rich giants in the RGB appear to have a small but measurable preference for having close companions, something that deserves further scrutiny with more and better data. Additional measurements of the RVs of these giants at higher RV precision would greatly help in confirming and more robustly quantifying these results.",['stars: abundances – stars: evolution – binaries: general'],[]
"Higher-order topological insulators in two spatial dimensions display fractional corner charges. While fractional charges in one dimension are known to be captured by a many-body bulk invariant, computed by the Resta formula, a many-body bulk invariant for higher-order topology and the corresponding fractional corner charges remains elusive despite several attempts. Inspired by recent work by Tada and Oshikawa, we propose a well-defined many-body bulk invariant for Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT symmetric higher-order topological insulators, which is valid for both non-interacting and interacting systems. Instead of relating them to the bulk quadrupole moment as was previously done, we show that in the presence of Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT rotational symmetry, this bulk invariant can be directly identified with quantized fractional corner charges. In particular, we prove that the corner charge is quantized as e/n𝑒𝑛e/nitalic_e / italic_n with Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT symmetry, leading to a ℤnsubscriptℤ𝑛\mathbb{Z}_{n}blackboard_Z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT classification for higher-order topological insulators in two dimensions.",[],[]
"The physical sciences require models tailored to specific nuances of different dynamics. In this work, we study outcome predictions in nuclear fusion tokamaks, where a major challenge are disruptions, or the loss of plasma stability with damaging implications for the tokamak. Although disruptions are difficult to model using physical simulations, machine learning (ML) models have shown promise in predicting these phenomena. Here, we first study several variations on masked autoregressive transformers, achieving an average of 5% increase in Area Under the Receiving Operating Characteristic metric above existing methods. We then compare transformer models to limited context neural networks in order to shed light on the “memory” of plasma effected by tokamaks controls. With these model comparisons, we argue for the persistence of a memory throughout the plasma in the context of tokamaks that our model exploits.",[],[]
"With the rapid evolution of Natural Language Processing (NLP), Large Language Models (LLMs) like ChatGPT have emerged as powerful tools capable of transforming various sectors. Their vast knowledge base and dynamic interaction capabilities represent significant potential in improving education by operating as a personalized assistant. However, the possibility of generating incorrect, biased, or unhelpful answers are a key challenge to resolve when deploying LLMs in an education context. This work introduces an innovative architecture that combines the strengths of ChatGPT with a traditional information retrieval based chatbot framework to offer enhanced student support in higher education. Our empirical evaluations underscore the high promise of this approach.",[],[]
"With this paper, we begin a series of studies of extremal problems for estimating distributions of
martingale transforms of bounded martingales. The Bellman functions corresponding to such problems
are pointwise minimal diagonally concave functions on a horizontal strip, satisfying certain given boundary conditions. We describe the basic structures that arise when constructing such functions and present a solution in the case of asymmetric boundary conditions and a sufficiently small width of the strip.","['Bellman function', 'martingale transform', 'diagonally concave function']",[]
"The late time acceleration of the Universe has challenged contemporary cosmology since its discovery. General Relativity explains this phenomenon by introducing the cosmological constant, named the standard cosmological model (ΛΛ\Lambdaroman_ΛCDM). However, the cosmological constant solution has several drawbacks that have led cosmologists to explore and propose alternative models to explain the late time acceleration of the Universe. These alternatives span from models of a dynamical dark fluid, known as “dark energy”, to models of large-scale modifications of the gravitational interaction, known as “modified gravity”.
The first chapter briefly introduces background formulation, fundamental gravity theories, and cosmological observations. In chapters LABEL:Chapter2-LABEL:Chapter5, we investigate the dark sector of the Universe in modified gravity using Markov Chain Monte Carlo (MCMC) methods and large datasets derived from measurements of the background expansion of the Universe.
Chapter LABEL:Chapter2 discusses the acceleration of the Universe by incorporating bulk viscosity in f⁢(R,𝒯)𝑓𝑅𝒯f(R,\mathcal{T})italic_f ( italic_R , caligraphic_T ) gravity. Incorporating bulk viscosity into the f⁢(R,𝒯)𝑓𝑅𝒯f(R,\mathcal{T})italic_f ( italic_R , caligraphic_T ) gravity model violated the strong energy condition describing the accelerated expansion. In chapters LABEL:Chapter3 and LABEL:Chapter4, we examine the theoretical viability of f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity. We investigate f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity using the matter-dominated Universe and the effective equation of state. To achieve this, we constrain the two models with the Hubble dataset, Union 2.1 and Pantheon supernovae datasets, and the BAO dataset with the analyses of numerous cosmological parameters. The study indicates whether the f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity models are supported by the observational data in comparison to the ΛΛ\Lambdaroman_ΛCDM scenario. The reconstructed models of dark energy exhibit accelerating behavior and deviate from the ΛΛ\Lambdaroman_ΛCDM at certain redshifts.
In chapter LABEL:Chapter5, we analyze the exponential f⁢(Q)𝑓𝑄f(Q)italic_f ( italic_Q ) gravity to examine the formation of structures and the viable cosmology. The study aims to reproduce feasible results within f⁢(Q)𝑓𝑄f(Q)italic_f ( italic_Q ) gravity using MCMC constraints and N-body + SPH simulations. We deduce CDM+baryons over density/temperature/mean molecular weight fields, matter power spectrum, bispectrum, two-point correlation function, and halo mass function. Therefore, the outcomes for small and large simulation boxes are appropriately compared. Chapter LABEL:Chapter6 finishes with concluding remarks and a discussion of the thesis with an eye toward the future.",[],[]
"Research on algorithmic recourse typically considers how an individual can reasonably change an unfavorable automated decision when interacting with a fixed decision-making system.
This paper focuses instead on the online setting, where system parameters are updated dynamically according to interactions with data subjects.
Beyond the typical individual-level recourse, the online setting opens up new ways for groups to shape system decisions by leveraging the parameter update rule.
We show empirically that recourse can be improved when users coordinate by jointly computing their feature perturbations, underscoring the importance of collective action in mitigating adverse automated decisions.","['Recourse', 'Collective', 'Recourse', 'User', 'Agency']",[]
,[],[]
"Recent work on object-centric world models aim to factorize representations in terms of objects in a completely unsupervised or self-supervised manner. Such world models are hypothesized to be a key component to address the generalization problem. While self-supervision has shown improved performance however, OOD generalization has not been systematically and explicitly tested. In this paper, we conduct an extensive study on the generalization properties of contrastive world model. We systematically test the model under a number of different OOD generalization scenarios such as extrapolation to new object attributes, introducing new conjunctions or new attributes. Our experiments show that the contrastive world model fails to generalize under the different OOD tests and the drop in performance depends on the extent to which the samples are OOD. When visualizing the transition updates and convolutional feature maps, we observe that any changes in object attributes (such as previously unseen colors, shapes, or conjunctions of color and shape) breaks down the factorization of object representations. Overall, our work highlights the importance of object-centric representations for generalization and current models are limited in their capacity to learn such representations required for human-level generalization.",[],[]
,[],[]
"We examine the transmission of quantum particles (phonons, electrons, and photons) across interfaces, identifying universal patterns in diverse physical scenarios. Starting with classical wave equations, we quantize them and derive kinetic equations. Those are matching conditions for the distribution functions of particles at the interface. We note the time irreversibility of the derived kinetic equations — an essential feature for accurately describing irreversible processes like heat transport. We identify the juncture in our derivation where the time symmetry of wave equations is disrupted, it is the assumption of the non-coherence of incident waves. Consequently, we infer that non-coherent transmission through the interface exhibits time irreversibility. We propose an experiment to validate this hypothesis.",[],['Argentina']
"Observatories need to measure and evaluate the scientific output and overall impact of their facilities. An observatory bibliography consists of the papers published using that observatory’s data, typically gathered by searching the major journals for relevant keywords. Recently, the volume of literature and methods by which the publications pool is evaluated have increased. Efficient and standardized procedures are necessary to assign meaningful metadata, enable user-friendly retrieval, and provide the opportunity to derive reports, statistics, and visualizations to impart a deeper understanding of the research output.

In 2021, a group of observatory bibliographers from around the world convened online to continue the discussions presented in Lagerstrom (2015). We worked to extract general guidelines from our experiences, techniques, and lessons learnt. This paper explores the development, application, and current status of telescope bibliographies and future trends. The paper briefly describes the methodologies employed in constructing the databases, along with the various bibliometric techniques used to analyze and interpret them. We explain reasons for non-standardization and why it is essential for each observatory to identify metadata and metrics that are meaningful for them; caution the (over-)use of comparisons among various facilities that are, ultimately, not comparable through bibliometrics; and highlight the benefits of telescope bibliographies, both for researchers within the astronomical community and for stakeholders beyond the specific observatories. There is tremendous diversity in the ways bibliographers track publications and maintain databases, due to parameters such as resources (personnel, time, budget, IT capabilities), type of observatory, historical practices, and reporting requirements to funders and outside agencies. However, there are also common sets of Best Practices. This paper describes some of our results from our collaborative discussions.","['Astronomy', 'Databases (83) —', 'Astronomical reference materials (90) —', 'Observatories (1147) —', 'Telescopes (1689)']","['Spain', 'Japan', 'Germany']"
"We introduce a physics-informed neural network (PINN) method to study thermoacoustic interactions leading to combustion instability in combustors. Specifically, we employ a PINN to investigate thermoacoustic interactions in a bluff body anchored flame combustor, representative of ramjet and industrial combustors. Vortex shedding and acoustic oscillations appear in such combustors, and their interactions lead to the phenomenon of vortex-acoustic lock-in. Acoustic pressure fluctuations at three locations and the total flame heat release rate serve as the measured data. The coupled parameterized model is based on the acoustic equations and the van der Pol oscillator for vortex shedding. The PINN was applied in the combustor, where the measurements suitable for a future machine learning application were not anticipated at the time of the experiments, as is the case in the vast majority of available data in the literature. We demonstrate a good performance of PINN in generating the acoustic field (pressure and velocity fluctuations) in the entire spatiotemporal domain, along with estimating all the parameters of the model. Therefore, this PINN-based model can potentially serve as an effective tool in improving existing combustors or designing new thermoacoustically stable and structurally efficient combustors.",[],[]
"A critical function of an organization is to foster the level of integration (coordination and cooperation) necessary to achieve its objectives. The need to coordinate and motivation to cooperate emerges from the myriad dependencies between an organization’s members and their work. Therefore, to reason about solutions to coordination and cooperation problems requires a robust representation that includes the underlying dependencies. We find that such a representation remains missing from formal organizational models, and we leverage semantics to bridge this gap. Drawing on well-established organizational research and our extensive fieldwork with one of North America’s largest municipalities, (1) we introduce an ontology, formalized in first-order logic, that operationalizes concepts like outcome, reward, and epistemic dependence, and their links to potential integration risks; and (2) present real-world applications of this ontology to analyze and support integration in complex government infrastructure projects. Our ontology is implemented and validated in both Z3 and OWL. Key features of our model include inferable dependencies, explainable coordination and cooperation risks, and actionable insights on how dependency structures within an organization can be altered to mitigate the risks. Conceptualizing real-world challenges like incentive misalignment, free-riding, and subgoal optimization in terms of dependency structures, our semantics-based approach represents a novel method for modelling and enhancing coordination and cooperation. Integrated within a decision-support system, our model may serve as an impactful aid for organizational design and effectiveness. More broadly, our approach underscores the transformative potential of semantics in deriving tangible, real-world value from existing organization theory.","['Cooperation', 'Coordination', 'Dependence', 'Organization', 'Ontology', 'OWL', 'Z3']",[]
"Analyzing the geometry of correlation sets constrained by general causal structures is of paramount importance for foundational and quantum technology research.
Addressing this task is generally challenging, prompting the development of diverse theoretical techniques for distinct scenarios. Recently, novel hybrid scenarios combining different causal assumptions within different parts of the causal structure have emerged.
In this work, we extend a graph theoretical technique to explore classical, quantum, and no-signaling distributions in hybrid scenarios,
where classical causal constraints and weaker no-signaling ones are used for different nodes of the causal structure.
By mapping such causal relationships into an undirected graph
we are able to characterize the associated sets of compatible distributions and analyze their relationships.
In particular we show how with our method we can construct minimal Bell-like inequalities capable of simultaneously distinguishing classical, quantum, and no-signaling behaviors, and efficiently estimate the corresponding bounds.
The demonstrated method will represent a powerful tool to study quantum networks and for applications in quantum information tasks.",[],"['Italy', 'Australia', 'Brazil']"
,[],[]
,[],[]
,[],[]
"Statistical Shape Modeling (SSM) is a quantitative method for analyzing morphological variations in anatomical structures. These analyses often necessitate building models on targeted anatomical regions of interest to focus on specific morphological features.
We propose an extension to particle-based shape modeling (PSM), a widely used SSM framework, to allow shape modeling to arbitrary regions of interest. Existing methods to define regions of interest are computationally expensive and have topological limitations. To address these shortcomings, we use mesh fields to define free-form constraints, which allow for delimiting arbitrary regions of interest on shape surfaces. Furthermore, we add a quadratic penalty method to the model optimization to enable computationally efficient enforcement of any combination of cutting-plane and free-form constraints.
We demonstrate the effectiveness of this method on a challenging synthetic dataset and two medical datasets.",[],[]
"The description of the T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG deformation in terms of two-dimensional gravity is analyzed from the Hamiltonian point of view, in a manner analogous to the ADM description of general relativity. We find that the Hamiltonian constraints of the theory imply relations between target-space momentum at finite volume which are equivalent to the T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG finite volume flow equations. This fully-quantum T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG result emerges already at the classical level within the gravitational theory. We exemplify the analysis for the case when the undeformed sector is a collection of D−2𝐷2D-2italic_D - 2 free massless scalars, where it is shown that –somewhat non-trivially– the target-space two-dimensional Poincaré symmetry is extended to D𝐷Ditalic_D dimensions. The connection between canonical quantization of this constrained Hamiltonian system and previous path integral quantizations is also discussed. We extend our analysis to the “gravitational” description of J⁢T¯𝐽¯𝑇J\bar{T}italic_J over¯ start_ARG italic_T end_ARG-type deformations, where it is found that the flow equations obtained involve deformations that twist the spatial boundary conditions.",[],['Uruguay']
"In this work we are motivated by factorization
of bosonic quantum dynamics and
we study the corresponding Lie algebras,
which can potentially be infinite dimensional.
To characterize such factorization,
we identify conditions for these Lie algebras
to be finite dimensional.
We consider cases where each free Hamiltonian term
is itself an element of the generated Lie algebra.
In our approach, we develop new tools to systematically divide skew-hermitian bosonic operators
into appropriate subspaces, and construct specific sequences of
skew-hermitian operators that are used to gauge the dimensionality of the Lie algebras themselves.
The significance of our result relies on conditions that constrain only the
independently controlled generators
in a particular Hamiltonian, thereby providing an effective algorithm for verifying the finiteness of the generated
Lie algebra.
In addition, our results are tightly connected to
mathematical work where the polynomials of creation and annihilation operators
are known as the Weyl algebra.
Our work paves the way for better understanding
factorization of bosonic dynamics relevant to quantum control and quantum technology.",[],"['Germany', 'Malta']"
"Beineke, Harary and Ringel discovered a formula for the minimum genus of a
torus in which the n𝑛nitalic_n-dimensional hypercube graph can be embedded.
We give a new proof of the formula by building this surface
as a union of certain faces in the hypercube’s 2-skeleton. For odd dimension n𝑛nitalic_n, the entire 2-skeleton decomposes into
(n−1)/2𝑛12(n-1)/2( italic_n - 1 ) / 2 copies of the surface, and the intersection of any two copies is
the hypercube graph.",[],[]
"We apply the shifted composition rule—an information-theoretic principle introduced in our earlier work [scr1]—to establish shift Harnack inequalities for the Langevin diffusion.
We obtain sharp constants for these inequalities for the first time, allowing us to investigate their relationship with other properties of the diffusion.
Namely, we show that they are equivalent to a sharp “local gradient-entropy” bound, and that they imply curvature upper bounds in a compelling reflection of the Bakry–Émery theory of curvature lower bounds.
Finally, we show that the local gradient-entropy inequality implies optimal concentration of the score, a.k.a. the logarithmic gradient of the density.",[],[]
"We present a general framework for modeling materials using deep neural networks. Material represented by multidimensional characteristics (that mimic measurements) is used to train the neural autoencoder model in an unsupervised manner. The encoder is trying to predict the material parameters of a theoretical model, which is then used in a decoder part. The decoder, using the predicted parameters, reconstructs the input characteristics. The neural model is trained to capture a synthetically generated set of characteristics that can cover a broad range of material behaviors, leading to a model that can generalize on the underlying physics rather than just optimize the model parameters for a single measurement. After setting up the model we prove its usefulness in the complex problem of modeling magnetic materials in the frequency and current (out-of-linear range) domains simultaneously.","['materials modeling', 'deep neural networks', 'synthetic data']",['Poland']
,[],[]
,[],[]
"This work proposes a Reynolds number scaling of the required number of grid points to perform wall-modeled LES of turbulent flows encountering separation off a solid surface. Based on comparisons between the various time scales in a non-equilibrium turbulent boundary layer (due to the action of an external pressure gradient), a simple definition of the near-wall “under-equilibrium"" and “out-of-equilibrium"" scales is put forward (where “under-equilibrium"" scales are governed by a quasi-balance between the viscous and the pressure gradient terms). It is shown that this “under-equilibrium"" characteristic length scale varies with Reynolds number as lp∼R⁢e−2/3similar-tosubscript𝑙𝑝𝑅superscript𝑒23l_{p}\sim Re^{-2/3}italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ∼ italic_R italic_e start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT. The same scaling is obtained from a simplified Green’s function solution of the Poisson equation in the vicinity of the separation point. A-priori analysis is used to demonstrate that the resolution required to reasonably predict the wall-shear stress (for example, errors lower than approximately 10−15%10percent1510-15\%10 - 15 % in the entire domain) in several nonequilibrium flows is at least 𝒪⁢(10)𝒪10\mathcal{O}(10)caligraphic_O ( 10 )lpsubscript𝑙𝑝l_{p}italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT irrespective of the Reynolds number and the Clauser parameter. Further, a series of a-posteriori validation studies are performed to determine the accuracy of this scaling including the flow over the Boeing speed bump, Song-Eaton diffuser, Notre-Dame Ramp, and the backward-facing step. The results suggest that for these flows, scaling the computational grids (ΔΔ\Deltaroman_Δ) such that Δ/lpΔsubscript𝑙𝑝\Delta/l_{p}roman_Δ / italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is independent of the Reynolds number results in accurate predictions of flow separation at the same “nominal"" grid resolution across different Reynolds numbers. Finally, it is suggested that atleast locally, in the vicinity of the separation and reattachment points, the grid-point requirements for wall-modeled large eddy simulations may scale as R⁢e4/3𝑅superscript𝑒43Re^{4/3}italic_R italic_e start_POSTSUPERSCRIPT 4 / 3 end_POSTSUPERSCRIPT, which is more restrictive than the previously proposed flat-plate boundary layer-based estimates (∼R⁢e1similar-toabsent𝑅superscript𝑒1\sim Re^{1}∼ italic_R italic_e start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT) of Choi and Moin, Phys. Fluids, 2012 and Yang and Griffin, Phys. Fluids, 2021.",[],[]
"Seasonal influenza causes on average 425,000 hospitalizations and 32,000 deaths per year in the United States.
Forecasts of influenza-like illness (ILI)—a surrogate for the proportion of patients infected with influenza—support public health decision making.
The goal of an ensemble forecast of ILI is to increase accuracy and calibration compared to individual forecasts and to provide a single, cohesive prediction of future influenza.
However, an ensemble may be composed of models that produce similar forecasts, causing issues with ensemble forecast performance and non-identifiability.
To improve upon the above issues we propose a novel Cluster-Aggregate-Pool or ‘CAP’ ensemble algorithm that first clusters together individual forecasts, aggregates individual models that belong to the same cluster into a single forecast (called a cluster forecast), and then pools together cluster forecasts via a linear pool.
When compared to a non-CAP approach, we find that a CAP ensemble improves calibration by approximately 10% while maintaining similar accuracy to non-CAP alternatives.
In addition, our CAP algorithm (i) generalizes past ensemble work associated with influenza forecasting and introduces a framework for future ensemble work, (ii) automatically accounts for missing forecasts from individual models, (iii) allows public health officials to participate in the ensemble by assigning individual models to clusters, and (iv) provide an additional signal about when peak influenza may be near.",[],[]
"Scientists are adopting new approaches to scale up their activities and goals. Progress in neurotechnologies, artificial intelligence, automation, and tools for collaboration promises new bursts of discoveries. However, compared to other disciplines and the industry, neuroscience laboratories have been slow to adopt key technologies to support collaboration, reproducibility, and automation. Drawing on progress in other fields, we define a roadmap for implementing automated research workflows for diverse research teams. We propose establishing a five-level capability maturity model for operations in neuroscience research. Achieving higher levels of operational maturity requires new technology-enabled methodologies, which we describe as “SciOps”. The maturity model provides guidelines for evaluating and upgrading operations in multidisciplinary neuroscience teams.",[],[]
"Motivated by the question of how biological systems maintain homeostasis in changing environments,
Shinar and Feinberg introduced in 2010 the concept of absolute concentration robustness (ACR).
A biochemical system exhibits ACR in some species if the steady-state value of that species does not depend on initial conditions. Thus, a system
with ACR can maintain a constant level of one species even as the environment changes. Despite a great deal of interest
in ACR in recent years, the following basic question remains open: How can we determine quickly whether a given
biochemical system has ACR? Although various approaches to this problem have been proposed, we show that
they are incomplete. Accordingly, we present new methods for deciding ACR, which harness computational algebra. We
illustrate our results on several biochemical signaling networks.
MSC Codes:
37N25, 92E20, 12D10, 37C25, 65H14, 14Q20",[],[]
"We prove that if A𝐴Aitalic_A is a computable Hopfian finitely presented structure, then A𝐴Aitalic_A has a computable d𝑑ditalic_d-Σ2subscriptΣ2\Sigma_{2}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Scott sentence if and only if the weak Whitehead problem for A𝐴Aitalic_A is decidable.
We use this to infer that every hyperbolic group as well as any polycyclic-by-finite group has a computable d𝑑ditalic_d-Σ2subscriptΣ2\Sigma_{2}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Scott sentence, thus covering two main classes of finitely presented groups. Our proof also implies that every weakly Hopfian finitely presented group is strongly defined by its ∃+superscript\exists^{+}∃ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT-types, a question which arose in a different context.",[],[]
"Re-identifying participants in ultra-distance running competitions can be daunting due to the extensive distances and constantly changing terrain. To overcome these challenges, computer vision techniques have been developed to analyze runners’ faces, numbers on their bibs, and clothing. However, our study presents a novel gait-based approach for runners’ re-identification (re-ID) by leveraging various pre-trained human action recognition (HAR) models and loss functions. Our results show that this approach provides promising results for re-identifying runners in ultra-distance competitions. Furthermore, we investigate the significance of distinct human body movements when athletes are approaching their endurance limits and their potential impact on re-ID accuracy. Our study examines how the recognition of a runner’s gait is affected by a competition’s critical point (CP), defined as a moment of severe fatigue and the point where the finish line comes into view, just a few kilometers away from this location. We aim to determine how this CP can improve the accuracy of athlete re-ID. Our experimental results demonstrate that gait recognition can be significantly enhanced (up to a 9% increase in mAP) as athletes approach this point. This highlights the potential of utilizing gait recognition in real-world scenarios, such as ultra-distance competitions or long-duration surveillance tasks.",[],[]
,[],[]
"Large ensembles of stochastically evolving interacting particles
describe phenomena in diverse fields including statistical physics, neuroscience, biology, and engineering.
In such systems, the infinitesimal evolution of each particle depends only on its own state (or history)
and the states (or histories) of neighboring particles with respect to
an underlying, possibly random, interaction graph. While these high-dimensional processes are typically too
complex to be amenable to exact analysis, their dynamics are quite well understood when the interaction graph is
the complete graph. In this case, classical theorems show that in the limit as the number of particles goes to infinity, the dynamics of the empirical measure and the law of a typical particle coincide and can be characterized in terms of a much more tractable dynamical system of reduced dimension called the mean-field limit. In contrast, until recently not much was known about corresponding convergence results in the complementary case when the interaction graph is sparse (i.e., with uniformly bounded average degree). This article provides a brief survey of classical
work and then describes recent progress on the sparse regime that relies
on a combination of techniques from random graph theory, Markov random
fields, and stochastic analysis. The article concludes by discussing ramifications
for applications and posing several open problems.",[],[]
"The Gouy phase is essential for accurately describing various wave phenomena, ranging from classical electromagnetic waves to matter waves and quantum optics. In this work, we employ phase-space methods based on the cross-Wigner transformation to analyze spatial and temporal interference in the evolution of matter waves characterized initially by a correlated Gaussian wave packet.
First, we consider the cross-Wigner of the initial function with its free evolution, and second for the evolution through a double-slit arrangement. Different from the wave function which acquires a global Gouy phase, we find that the cross-Wigner acquires a Gouy phase difference due to different evolution times. The results suggest that temporal like-Gouy phases are important for an accurate description of temporal interference.
Furthermore, we propose a technique based on the Wigner function to reconstruct the cross-Wigner from the spatial intensity interference term in a double-slit experiment with matter waves.",[],"['Poland', 'Brazil']"
"For strongly connected, pure n𝑛nitalic_n-dimensional regular CW-complexes, we show that
evenness (each (n−1)𝑛1(n{-}1)( italic_n - 1 )-cell is contained in an even number of n𝑛nitalic_n-cells)
is equivalent to generalizations of both cycle decomposition and traversability.",[],[]
"This paper addresses the “curse of dimensionality” in the loss valuation of credit risk models. A dimension reduction methodology based on the Bayesian filter and smoother is proposed. This methodology is designed to achieve a fast and accurate loss valuation algorithm in credit risk modelling, but it can also be extended to valuation models of other risk types. The proposed methodology is generic, robust and can easily be implemented. Moreover, the accuracy of the proposed methodology in the estimation of expected loss and value-at-risk is illustrated by numerical experiments. The results suggest that, compared to the currently most used PCA approach, the proposed methodology provides more accurate estimation of expected loss and value-at-risk of a loss distribution. 
keywords: Bayesian filter, credit risk, loss valuation
2020 Mathematics Subject Classification: 62P05, 91G40",[],['Netherlands']
"This paper proposes a computational model for policy administration.
As an organization evolves, new users and resources are gradually
placed under the mediation of the access control model. Each time
such new entities are added, the policy administrator must
deliberate on how the access control policy shall be revised to
reflect the new reality. A well-designed access control model must
anticipate such changes so that the administration cost does not
become prohibitive when the organization scales up. Unfortunately,
past Access Control research does not offer a formal way to quantify
the cost of policy administration. In this work, we propose to
model ongoing policy administration in an active learning
framework. Administration cost can be quantified in terms of query
complexity. We demonstrate the utility of this approach by applying
it to the evolution of protection domains. We also modelled
different policy administration strategies in our framework. This
allowed us to formally demonstrate that domain-based policies have a
cost advantage over access control matrices because of the use of
heuristic reasoning when the policy evolves. To the best of our
knowledge, this is the first work to employ an active learning
framework to study the cost of policy deliberation and demonstrate
the cost advantage of heuristic policy administration.","['Access control', 'policy administration', 'active learning', 'query complexity', 'heuristics']",['Canada']
"Rollback recovery strategies are well-known in
concurrent and distributed systems. In this context,
recovering from unexpected failures is even more
relevant given the non-deterministic nature of
execution, which means that it is practically
impossible to foresee all possible process interactions.

In this work, we consider a message-passing concurrent
programming language where processes interact through
message sending and receiving, but shared memory
is not allowed. In this context, we design a
checkpoint-based
rollback recovery strategy which does not
need a central coordination.
For this purpose, we extend the language
with three new operators: 𝖼𝗁𝖾𝖼𝗄𝖼𝗁𝖾𝖼𝗄\mathsf{check}sansserif_check,
𝖼𝗈𝗆𝗆𝗂𝗍𝖼𝗈𝗆𝗆𝗂𝗍\mathsf{commit}sansserif_commit, and 𝗋𝗈𝗅𝗅𝖻𝖺𝖼𝗄𝗋𝗈𝗅𝗅𝖻𝖺𝖼𝗄\mathsf{rollback}sansserif_rollback.
Furthermore, our approach
is purely asynchronous, which is an essential
ingredient to develop a source-to-source program
instrumentation implementing a rollback recovery
strategy.","['message-passing concurrency', 'rollback recovery', 'checkpointing']",['Spain']
This template helps you to create a properly formatted LATEX manuscript.,[],[]
"For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. We study the problem of determining a quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration as a generalization of Descartes’ rule of signs. We exploit the combinatorial properties of our definition for eigenvalue configuration to reduce a two-polynomial root counting problem into several single-polynomial root counting problems of symmetric polynomials. We then leverage the fundamental theorem of symmetric polynomials to derive a final quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration.",[],['Spain']
,[],[]
"Disformal transformations of Friedmann–Lemaître–Robertson–Walker and
Bianchi geometries are analyzed in the context of scalar–tensor gravity.
Novel aspects discussed are the 3+1313+13 + 1 splitting, the effective fluid
equivalent of the gravitational scalar, Bianchi models, stealth solutions
and de Sitter solutions with non–constant scalar field (which are
signatures of scalar–tensor gravity). Both pure disformal transformations
and more general ones are discussed.",[],['Germany']
"We investigate the role of the spectral dimension dssubscript𝑑𝑠d_{s}italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT in determining the universality of phase transitions on a complex network. Due to its structural heterogeneity, a complex network generally acts as a disordered system. Specifically, we study the synchronization and entrainment transitions in the nonequilibrium dynamics of the Kuramoto model and the phase transition of the equilibrium dynamics of the classical X⁢Y𝑋𝑌XYitalic_X italic_Y model, thereby covering a broad spectrum from nonlinear dynamics to statistical and condensed matter physics. Using linear theory, we obtain a general relationship between the dynamics occurring on the network and the underlying network properties. This yields the lower critical spectral dimension of the phase synchronization and entrainment transitions in the Kuramoto model as ds=4subscript𝑑𝑠4d_{s}=4italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 4 and ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2 respectively, whereas for the phase transition in the X⁢Y𝑋𝑌XYitalic_X italic_Y model it is ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2. To test our theoretical hypotheses, we employ a network where any two nodes on the network are connected with a probability proportional to a power law of the distance between the nodes; this realizes any desired ds∈[1,∞)subscript𝑑𝑠1d_{s}\in[1,\infty)italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ∈ [ 1 , ∞ ). Our detailed numerical study agrees well with the prediction of linear theory for the phase synchronization transition in the Kuramoto model. However, it shows a clear entrainment transition in the Kuramoto model and phase transition in the X⁢Y𝑋𝑌XYitalic_X italic_Y model at ds≳3greater-than-or-equivalent-tosubscript𝑑𝑠3d_{s}\gtrsim 3italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≳ 3, not ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2 as predicted by linear theory. Our study indicates that network disorder in the region 2≤ds≲32subscript𝑑𝑠less-than-or-similar-to32\leq d_{s}\lesssim 32 ≤ italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≲ 3 seems to be relevant and have a profound effect on the dynamics.",[],"['Germany', 'Switzerland']"
"The rapid growth of the ride-hailing industry has revolutionized urban transportation worldwide. Despite its benefits, equity concerns arise as underserved communities face limited accessibility to affordable ride-hailing services. A key issue in this context is the vehicle rebalancing problem, where idle vehicles are moved to areas with anticipated demand. Without equitable approaches in demand forecasting and rebalancing strategies, these practices can further deepen existing inequities. In the realm of ride-hailing, three main facets of fairness are recognized: algorithmic fairness, fairness to drivers, and fairness to riders. This paper focuses on enhancing both algorithmic and rider fairness through a novel vehicle rebalancing method. We introduce an approach that combines a Socio-Aware Spatial-Temporal Graph Convolutional Network (SA-STGCN) for refined demand prediction and a fairness-integrated Matching-Integrated Vehicle Rebalancing (MIVR) model for subsequent vehicle rebalancing. Our methodology is designed to reduce prediction discrepancies and ensure equitable service provision across diverse regions. The effectiveness of our system is evaluated using simulations based on real-world ride-hailing data. The results suggest that our proposed method enhances both accuracy and fairness in forecasting ride-hailing demand, ultimately resulting in more equitable vehicle rebalancing in subsequent operations. Specifically, the algorithm developed in this study effectively reduces the standard deviation and average customer wait times by 6.48% and 0.49%, respectively. This achievement signifies a beneficial outcome for ride-hailing platforms, striking a balance between operational efficiency and fairness.",[],[]
"The recent progress in language-based open-vocabulary object detection can be largely attributed to finding better ways of leveraging large-scale data with free-form text annotations. Training such models with a discriminative objective function has proven successful, but requires good positive and negative samples. However, the free-form nature and the open vocabulary of object descriptions make the space of negatives extremely large. Prior works randomly sample negatives or use rule-based techniques to build them. In contrast, we propose to leverage the vast knowledge built into modern generative models to automatically build negatives that are more relevant to the original data. Specifically, we use large-language-models to generate negative text descriptions, and text-to-image diffusion models to also generate corresponding negative images. Our experimental analysis confirms the relevance of the generated negative data, and its use in language-based detectors improves performance on two complex benchmarks.",[],[]
"This paper presents a novel Automatic Essay Scoring (AES) algorithm tailored for the Portuguese-language essays of Brazil’s Exame Nacional do Ensino Médio (ENEM), addressing the challenges in traditional human grading systems. This approach leverages advanced deep learning techniques to align closely with human grading criteria, targeting efficiency and scalability in evaluating large volumes of student essays. This research not only responds to the logistical and financial constraints of manual grading in Brazilian educational assessments but also promises to enhance fairness and consistency in scoring, marking a significant step forward in the application of AES in large-scale academic settings.",[],[]
,[],[]
This paper presents a regularized recursive identification algorithm with simultaneous on-line estimation of both the model parameters and the algorithms hyperparameters. A new kernel is proposed to facilitate the algorithm development. The performance of this novel scheme is compared with that of the recursive least-squares algorithm in simulation.,[],[]
"In this work, we generalize the spacetime induced by a rotating cosmic string, taking into account anisotropic effects due the breaking of the Lorentz violation. In particular, we explore the energy levels of a massive spinless particle that is covariantly coupled to a uniform magnetic field aligned with the string. Subsequently, we introduce a scalar potential featuring both a Coulomb–type and a linear confining term and comprehensively solve the Klein–Gordon equations for each configuration. Finally, by imposing rigid–wall boundary conditions, we determine the Landau levels when the linear defect itself possesses magnetization. Notably, our analysis reveals the occurrence of Landau quantization even in the absence of gauge fields, provided the string possesses spin. Finally, the thermodynamic properties are computed as well in these scenarios.",[],['Brazil']
"Demagnetization in ferromagnetic transition metals driven by a
femtosecond laser pulse is a fundamental problem in solid state
physics, and its understanding is essential to the development of
spintronics devices. Ab initio calculation of time-dependent magnetic
moment in the velocity gauge so far has not been successful in
reproducing the large amount of demagnetization observed in
experiments. In this work, we propose a method to incorporate
intraband transitions within the velocity gauge through a convective
derivative in the crystal momentum space. Our results for
transition-element bulk crystals (bcc Fe, hcp Co and fcc Ni) based on
the time-dependent quantum Liouville equation show a dramatic
enhancement in the amount of demagnetization after the inclusion of an
intraband term, in agreement with experiments. We also find that the
effect of intraband transitions to each ferromagnetic material is
distinctly different because of their band structure and spin property
differences. Our finding has a far-reaching impact on understanding
of ultrafast demagnetization.","['femtomagnetism', 'all optical spin switching', 'time dependent quantum', 'Liouville equation', 'm-mixing', 'circularly-polarized laser field']",[]
,[],[]
"Knowledge of exact analytical functional forms for the pair correlation function g2⁢(r)subscript𝑔2𝑟g_{2}(r)italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r ) and its corresponding structure factor S⁢(k)𝑆𝑘S(k)italic_S ( italic_k ) of disordered many-particle systems is limited.
For fundamental and practical reasons, it is highly desirable to add to the existing data base of analytical functional forms for such pair statistics.
Here, we design a plethora of such pair functions in direct and Fourier spaces across the first three Euclidean space dimensions that are realizable by diverse many-particle systems with varying degrees of correlated disorder across length scales, spanning a wide spectrum of hyperuniform, typical nonhyperuniform and antihyperuniform ones.
This is accomplished by utilizing an efficient inverse algorithm that determines equilibrium states with up to pair interactions at positive temperature that precisely match targeted forms for both g2⁢(r)subscript𝑔2𝑟g_{2}(r)italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r ) and S⁢(k)𝑆𝑘S(k)italic_S ( italic_k ).
Among other results, we realize an example with the strongest hyperuniform property among known positive-temperature equilibrium states, critical-point systems (implying unusual 1D systems with phase transitions) that are not in the Ising universality class, systems that attain self-similar pair statistics under Fourier transformation, and an experimentally feasible polymer model.
We show that our pair functions enable one to achieve systems with a wide range of translational order and self-diffusion coefficients 𝒟𝒟\cal Dcaligraphic_D, which are inversely related to one another.
One can design other realizable pair statistics via linear combinations of our functions or by applying our inverse procedure to other desirable functional forms.
Our approach facilitates the inverse design of materials with desirable physical and chemical properties by tuning their pair statistics.",[],[]
,[],[]
"We extend the notion of forward performance criteria to settings with random endowment in incomplete markets. Building on these results, we introduce and develop the novel concept of forward optimized certainty equivalent (forward OCE), which offers a genuinely dynamic valuation mechanism that accommodates progressively adaptive market model updates, stochastic risk preferences, and incoming claims with arbitrary maturities.
In parallel, we develop a new methodology to analyze the emerging stochastic optimization problems by directly studying the candidate optimal control processes for both the primal and dual problems. Specifically, we derive two new systems of forward-backward stochastic differential equations (FBSDEs) and establish necessary and sufficient conditions for optimality, and various equivalences between the two problems. This new approach is general and complements the existing one based on backward stochastic partial differential equations (backward SPDEs) for the related value functions. We, also, consider representative examples for both forward performance criteria with random endowment and forward OCE, and for the case of exponential criteria, we investigate the connection between forward OCE and forward entropic risk measures.",[],[]
"Reinforcement learning (RL) is a powerful technique for training intelligent agents, but understanding why these agents make specific decisions can be quite challenging. This lack of transparency in RL models has been a long-standing problem, making it difficult for users to grasp the reasons behind an agent’s behaviour. Various approaches have been explored to address this problem, with one promising avenue being reward decomposition (RD). RD is appealing as it sidesteps some of the concerns associated with other methods that attempt to rationalize an agent’s behaviour in a post-hoc manner. RD works by exposing various facets of the rewards that contribute to the agent’s objectives during training. However, RD alone has limitations as it primarily offers insights based on sub-rewards and does not delve into the intricate cause-and-effect relationships that occur within an RL agent’s neural model. In this paper, we present an extension of RD that goes beyond sub-rewards to provide more informative explanations. Our approach is centred on a causal learning framework that leverages information-theoretic measures for explanation objectives that encourage three crucial properties of causal factors: causal sufficiency, sparseness, and orthogonality. These properties help us distill the cause-and-effect relationships between the agent’s states and actions or rewards, allowing for a deeper understanding of its decision-making processes. Our framework is designed to generate local explanations and can be applied to a wide range of RL tasks with multiple reward channels. Through a series of experiments, we demonstrate that our approach offers more meaningful and insightful explanations for the agent’s action selections.",[],[]
"In this paper, we elaborate on correctly predicting Échelle spectrograms by employing the fully three-dimensional representation of Snell’s law to model the effects of prisms as cross-dispersers in Échelle spectrographs.
We find that it is not sufficient to simply apply the frequently used trigonometric prism dispersion equation to describe recorded spectra.
This vector equation approach is not limited to a single dispersive element when modeling multi-prism cross-disperser configurations.
Our results help to understand the main levers in an Échelle spectrograph as well as contribute to auto-calibration algorithms for minimizing calibration efforts in daily operation.","['Prism', 'Echelle', 'Cross-Disperser', 'Snell’s law', 'Sellmeier', 'QtYETI']",[]
"It is our purpose to study complete space-like self-expanders in the Minkovski space.
By use of maximum principle of Omori-Yau type, we
can obtain the rigidity theorems on n𝑛nitalic_n-dimensional complete space-like self-expanders in the Minkovski space ℝ1n+1subscriptsuperscriptℝ𝑛11\mathbb{R}^{n+1}_{1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. For complete space-like self-expanders of dimension 2222, we give a classification of them under assumption of constant squared norm of the second fundamental form.",[],[]
,[],[]
"In this work, we consider constrained stochastic optimization problems under hidden convexity, i.e., those that admit a convex reformulation via non-linear (but invertible) map c⁢(⋅)𝑐⋅c(\cdot)italic_c ( ⋅ ). A number of non-convex problems ranging from optimal control, revenue and inventory management, to convex reinforcement learning all admit such a hidden convex structure. Unfortunately, in the majority of applications considered, the map c⁢(⋅)𝑐⋅c(\cdot)italic_c ( ⋅ ) is unavailable or implicit; therefore, directly solving the convex reformulation is not possible. On the other hand, the stochastic gradients with respect to the original variable are often easy to obtain. Motivated by these observations, we examine the basic projected stochastic (sub-) gradient methods for solving such problems under hidden convexity. We provide the first sample complexity guarantees for global convergence in smooth and non-smooth settings. Additionally, in the smooth setting, we improve our results to the last iterate convergence in terms of function value gap using the momentum variant of projected stochastic gradient descent.",[],[]
"The increasing availability of temporal data poses a challenge to time-series and signal-processing domains due to its high numerosity and complexity. Symbolic representation outperforms raw data in a variety of engineering applications due to its storage efficiency, reduced numerosity, and noise reduction. The most recent symbolic aggregate approximation technique called ABBA demonstrates outstanding performance in preserving essential shape information of time series and enhancing the downstream applications. However, ABBA cannot handle multiple time series with consistent symbols, i.e., the same symbols from distinct time series are not identical. Also, working with appropriate ABBA digitization involves the tedious task of tuning the hyperparameters, such as the number of symbols or tolerance. Therefore, we present a joint symbolic aggregate approximation that has symbolic consistency, and show how the hyperparameter of digitization can itself be optimized alongside the compression tolerance ahead of time. Besides, we propose a novel computing paradigm that enables parallel computing of symbolic approximation. The extensive experiments demonstrate its superb performance and outstanding speed regarding symbolic approximation and reconstruction.",[],[]
"Diffusion models trained with mean squared error loss tend to generate unrealistic samples. Current state-of-the-art models rely on classifier-free guidance to improve sample quality, yet its surprising effectiveness is not fully understood. In this paper, We show that the effectiveness of classifier-free guidance partly originates from it being a form of implicit perceptual guidance. As a result, we can directly incorporate perceptual loss in diffusion training to improve sample quality. Since the score matching objective used in diffusion training strongly resembles the denoising autoencoder objective used in unsupervised training of perceptual networks, the diffusion model itself is a perceptual network and can be used to generate meaningful perceptual loss. We propose a novel self-perceptual objective that results in diffusion models capable of generating more realistic samples. For conditional generation, our method only improves sample quality without entanglement with the conditional input and therefore does not sacrifice sample diversity. Our method can also improve sample quality for unconditional generation, which was not possible with classifier-free guidance before.",[],[]
,[],[]
"The integration of sensorized vessels, enabling real-time data collection and machine learning-driven data analysis marks a pivotal advancement in the maritime industry. This transformative technology not only can enhance safety, efficiency, and sustainability but also usher in a new era of cost-effective and smart maritime transportation in our increasingly interconnected world. This study presents a deep learning-driven anomaly detection system augmented with interpretable machine learning models for identifying performance anomalies in an industrial sensorized vessel, called TUCANA. We Leverage a human-in-the-loop unsupervised process that involves utilizing standard and Long Short-Term Memory (LSTM) autoencoders augmented with interpretable surrogate models, i.e., random forest and decision tree, to add transparency and interpretability to the results provided by the deep learning models. The interpretable models also enable automated rule generation for translating the inference into human-readable rules. Additionally, the process also includes providing a projection of the results using t-distributed stochastic neighbor embedding (t-SNE), which helps with a better understanding of the structure and relationships within the data and assessment of the identified anomalies. We empirically evaluate the system using real data acquired from the vessel TUCANA and the results involve achieving over 80% precision and 90% recall with the LSTM model used in the process. The interpretable models also provide logical rules aligned with expert thinking, and the t-SNE-based projection enhances interpretability. Our system demonstrates that the proposed approach can be used effectively in real-world scenarios, offering transparency and precision in performance anomaly detection.","['Performance', 'Anomaly', 'Detection', 'Human-in-the-loop', 'Learning', 'Process', 'Deep', 'Learning', 'Interpretable', 'Machine', 'Learning', 'Sensorized', 'Vessels', 'Maritime', 'Industry.']",[]
"Late-type stars are the most abundant in the galactic stellar population. These stars, with the similar internal structure to the Sun, are expected to have solar-like atmospheres.
Investigating the stellar parameters and chemical abundances on late-type stars is essential to provide valuable constraints about stellar age, chemical evolution, and atmosphere of exoplanets.
In this work, we present the study of the Near-UV and optical spectroscopic observation of three late-type stars: HR 8038, AC Her, HD 76446, as obtained from 36-inch MIRA/Oliver Observing Station.
We derived surface temperature, gravity, metallicity, and the chemical abundances of light element Carbon in the stellar atmosphere. The elemental abundance of the Carbon for HR 8038, AC Her, and HD 76446 are derived to be 95%, 97%, and 108%, respectively, of the solar value.",[],[]
"Both humans and social animals live in groups and are frequently faced to choose between options with different qualities. When there are no leader agents controlling the group decision, consensus can be achieved through repeated interactions among group members. Various studies on collective decision-making illustrate how the dynamics of the opinions are determined by the structure of the social network and the methods that individuals use to share and update their opinion upon a social interaction.
In this paper, we are interested in further exploring how cognitive, social, and environmental factors interactively contribute to determining the outcome of a collective best-of-n𝑛nitalic_n decision process involving asymmetric options, i.e., different costs and/or benefits for each option.
We propose and study a novel model capturing those different factors, i) the error in processing social information, ii) the number of zealots (i.e., asocial agents who never change their opinion), iii) the option qualities, iv) the social connectivity structure, and v) the degree centrality of the asocial agents. By using the heterogeneous mean-field approach, we study the impact of the above-mentioned factors in the decision dynamics. Our findings indicate that when susceptible agents, i.e., individuals who change their opinion to conform with others, use the voter model as a mechanism to update their opinion, both the number and the degree of connectivity of the zealots can lead the population to converge towards the lowest quality option. Instead, when susceptible agents use methods more cognitively demanding, the group is marginally impacted by the presence of zealots.
The results of the analytical model are complemented and extended by agent-based simulations.
Our analysis also shows that the network topology can modulate the influence of zealots on group dynamics. In fact, in homogeneous networks where all nodes have the same degree (numbers of neighbours), any location of the zealots has similar impact on the group dynamics. Instead, when the network is heterogeneous, our simulations confirm the model predictions that show that placing the zealots in the network hubs (nodes with several neighbours) has a much larger impact than placing them in lower-degree nodes.",[],['Belgium']
"Treating the X⁢(4140)𝑋4140X(4140)italic_X ( 4140 ) as a compact JP⁢C=1++superscript𝐽𝑃𝐶superscript1absentJ^{PC}=1^{++}italic_J start_POSTSUPERSCRIPT italic_P italic_C end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + + end_POSTSUPERSCRIPT c⁢s⁢c¯⁢s¯𝑐𝑠¯𝑐¯𝑠cs\bar{c}\bar{s}italic_c italic_s over¯ start_ARG italic_c end_ARG over¯ start_ARG italic_s end_ARG state and using its mass as a reference scale, we systematically estimate the masses of doubly heavy tetraquark states Q⁢Q⁢q¯⁢q¯𝑄𝑄¯𝑞¯𝑞QQ\bar{q}\bar{q}italic_Q italic_Q over¯ start_ARG italic_q end_ARG over¯ start_ARG italic_q end_ARG where Q=c,b𝑄𝑐𝑏Q=c,bitalic_Q = italic_c , italic_b and q=u,d,s𝑞𝑢𝑑𝑠q=u,d,sitalic_q = italic_u , italic_d , italic_s. Their decay properties are studied with a simple rearrangement scheme. Based on our results, the lowest I⁢(JP)=0⁢(1+)𝐼superscript𝐽𝑃0superscript1I(J^{P})=0(1^{+})italic_I ( italic_J start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT ) = 0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) b⁢b⁢n¯⁢n¯𝑏𝑏¯𝑛¯𝑛bb\bar{n}\bar{n}italic_b italic_b over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG state is a stable tetraquark about 20 MeV below the B¯*⁢B¯superscript¯𝐵¯𝐵\bar{B}^{*}\bar{B}over¯ start_ARG italic_B end_ARG start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT over¯ start_ARG italic_B end_ARG threshold. The mass and width of the low-mass 0⁢(1+)0superscript10(1^{+})0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) c⁢c⁢n¯⁢n¯𝑐𝑐¯𝑛¯𝑛cc\bar{n}\bar{n}italic_c italic_c over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG (n=u,d𝑛𝑢𝑑n=u,ditalic_n = italic_u , italic_d) tetraquark are compatible with the Tc⁢c⁢(3875)+subscript𝑇𝑐𝑐superscript3875T_{cc}(3875)^{+}italic_T start_POSTSUBSCRIPT italic_c italic_c end_POSTSUBSCRIPT ( 3875 ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT observed by the LHCb Collaboration. The location of the lowest 0⁢(0+)0superscript00(0^{+})0 ( 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) and 0⁢(1+)0superscript10(1^{+})0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) b⁢c⁢n¯⁢n¯𝑏𝑐¯𝑛¯𝑛bc\bar{n}\bar{n}italic_b italic_c over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG states are found to be close to the B¯⁢D¯𝐵𝐷\bar{B}Dover¯ start_ARG italic_B end_ARG italic_D and B¯*⁢Dsuperscript¯𝐵𝐷\bar{B}^{*}Dover¯ start_ARG italic_B end_ARG start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_D thresholds, respectively. We hope that the predicted ratios between partial widths of different channels may be helpful to identify compact tetraquark states from future measurements.",[],['China']
"Ionic liquids (ILs) are appealing electrolytes for their favorable physicochemical properties. However, despite their longstanding use, understanding the capacitive behavior of ILs remains challenging. This is largely due to the formation of a non-conventional electric double layer (EDL) at the electrode-electrolyte interface. This study shows that the short-range Yukawa interactions, representing the large anisotropically charged ILs, demix IL to create a spontaneous surface charge separation, which is reinforced by the strongly coupled charge interaction.
The properties of the condensed layer, the onset of charge separation, and the rise of overscreening and crowding critically depend on the asymmetry of Yukawa interactions.",[],[]
"We present an X-ray and UV investigation of five X-ray flares detected on two active systems, CC Eri and AB Dor, using the AstroSat observatory. The peak X-ray luminosities of the flares in the 0.3–7.0 keV band are found to be within 1031−333133{}^{31-33}start_FLOATSUPERSCRIPT 31 - 33 end_FLOATSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. Preliminary spectral analysis indicates the presence of three and four-temperature corona for CC Eri and AB Dor, respectively, where the highest temperature is found to vary with flare. The flare temperatures peaked at 51–59 MK for CC Eri and 29–44 MK for AB Dor. The peak emission measures of the flaring loops are estimated to be ∼similar-to\sim∼105454{}^{54}start_FLOATSUPERSCRIPT 54 end_FLOATSUPERSCRIPT for CC Eri and ∼similar-to\sim∼105555{}^{55}start_FLOATSUPERSCRIPT 55 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT for AB Dor. Global metallic abundances were also found to increase during flares.",[],[]
"Understanding the origin of electron incoherence is the first step toward a theoretical description of the non-Fermi liquid behavior of the high-Tc𝑐{}_{c}start_FLOATSUBSCRIPT italic_c end_FLOATSUBSCRIPT cuprate superconductors. Such electron incoherence manifests itself most evidently in the non-Drude behavior of the optical response of the system and the anomalous density fluctuation behavior in the long wave length limit. The spectral weight transfer related to such dissipative response, which is absent in conventional Fermi liquid metal, has direct consequence on the dc transport property of the system in the normal state and the superfluid stiffness in the superconducting state. It is found that such electron incoherence remains significant even in the clean limit and at low temperature and thus must be attributed to the strong electron correlation effect in the cuprate superconductors. Here we study such an intrinsic effect in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model through the variational calculation of its optical conductivity σ⁢(ω)𝜎𝜔\sigma(\omega)italic_σ ( italic_ω ). We assume a resonating valence bond ground state as our starting point and find that a significant portion of the total optical spectral weight remains incoherent throughout the phase diagram. The optical absorption is found to extend all the way to an energy of the order of the bare band width. We find that both the total optical weight K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG and the integrated incoherent optical weight I𝐼Iitalic_I increase monotonically with doping, with their ratio Ri⁢n⁢c⁢o⁢h=I/K¯subscript𝑅𝑖𝑛𝑐𝑜ℎ𝐼¯𝐾R_{incoh}=I/\bar{K}italic_R start_POSTSUBSCRIPT italic_i italic_n italic_c italic_o italic_h end_POSTSUBSCRIPT = italic_I / over¯ start_ARG italic_K end_ARG decreasing monotonically with doping. Our results indicate that the majority part of electron incoherence in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model can be attributed to the electron fractionalization mechanism assumed in such a treatment. We also find that the Drude weight deduced from D=K¯−I𝐷¯𝐾𝐼D=\bar{K}-Iitalic_D = over¯ start_ARG italic_K end_ARG - italic_I scales linearly with hole doping, without any sign of a non-monotonic behavior in the overdoped regime. Our results form an estimate of the lower bound for electron incoherence in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model as the multi-spinon excitation processes are neglected in our treatment.",[],['China']
"A Christ-Kiselev maximal theorem is proved for linear operators between quasi-Banach function lattices satisfying certain lattice geometrical conditions. The result is further explored for weighted Lorentz spaces, classical Lorentz spaces, and Wiener amalgams of Lebesgue function and sequence spaces. Extensions are made to Köthe dual operators and to operators on interpolation spaces of quasi-Banach function lattices. Several applications to maximal Fourier operators are presented.","['Maximal operators', 'filtrations', 'function spaces', 'Lorentz spaces', 'Weiner amalgam spaces', 'Fourier transform']",[]
"We employ the eigen microstate approach to explore the self-organized criticality (SOC) in two celebrated sandpile models, namely, the BTW model and the Manna model. In both models, phase transitions from the absorbing-state to the critical state can be understood by the emergence of dominant eigen microstates with significantly increased weights. Spatial eigen microstates of avalanches can be uniformly characterized by a linear system size rescaling. The first temporal eigen microstates reveal scaling relations in both models. Furthermore, by finite-size scaling analysis of the first eigen microstate, we numerically estimate critical exponents i.e., σ0⁢w1/v~1∝LDproportional-tosubscript𝜎0subscript𝑤1subscript~𝑣1superscript𝐿𝐷\sqrt{\sigma_{0}w_{1}}/\tilde{v}_{1}\propto L^{D}square-root start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG / over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∝ italic_L start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT and v~1∝LD⁢(1−τs)/2proportional-tosubscript~𝑣1superscript𝐿𝐷1subscript𝜏𝑠2\tilde{v}_{1}\propto L^{D(1-\tau_{s})/2}over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∝ italic_L start_POSTSUPERSCRIPT italic_D ( 1 - italic_τ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) / 2 end_POSTSUPERSCRIPT. Our findings could provide profound insights into eigen states of the universality and phase transition in non-equilibrium complex systems governed by self-organized criticality.",[],['China']
"We propose a contour integral-based algorithm for computing a few singular
values of a matrix or a few generalized singular values of a matrix pencil.
Mathematically, the generalized singular values of a matrix pencil are the
eigenvalues of an equivalent Hermitian–definite matrix pencil, known as the
Jordan–Wielandt matrix pencil.
However, direct application of the FEAST solver does not fully exploit the
structure of this problem.
We analyze several projection strategies on the Jordan–Wielandt matrix pencil,
and propose an effective and robust scheme tailored to GSVD.
Both theoretical analysis and numerical experiments demonstrate that our
algorithm achieves rapid convergence and satisfactory accuracy.",[],[]
"We develop a new efficient sequential approximate leverage score algorithm, SALSA, using methods from randomized numerical linear algebra (RandNLA) for large matrices. We demonstrate that, with high probability, the accuracy of SALSA’s approximations is within (1+𝒪⁢(ε))1𝒪𝜀(1+\mathcal{O}\left(\varepsilon\right))( 1 + caligraphic_O ( italic_ε ) ) of the true leverage scores. In addition, we show that the theoretical computational complexity and numerical accuracy of SALSA surpass existing approximations. These theoretical results are subsequently utilized to develop an efficient algorithm, named LSARMA, for fitting an appropriate ARMA model to large-scale time series data. Our proposed algorithm is, with high probability, guaranteed to find the maximum likelihood estimates of the parameters for the true underlying ARMA model. Furthermore, it has a worst-case running time that significantly improves those of the state-of-the-art alternatives in big data regimes. Empirical results on large-scale data strongly support these theoretical results and underscore the efficacy of our new approach.",[],[]
"The survey is devoted to operator splitting methods in the abstract formulation and their applications in probability. While the survey is focused on multiplicative methods, the BCH formula is used to discuss exponential splitting methods and a short informal introduction to additive splitting is presented. We introduce frameworks and available deterministic and probabilistic results and concentrate on constructing a wide picture of the field of operator splitting methods, providing a rigorous description in the setting of abstract Cauchy problems and an informal discussion for further and parallel advances. Some limitations and common difficulties are listed, as well as examples of works that provide solutions or hints. No new results are provided. The bibliography contains illustrative deterministic examples and a selection of probability-related works.","['Operator splitting methods', 'Trotter-Kato formula', 'exponential splitting']",[]
"Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse contents intelligently and automatically.
To support such artificial intelligence-generated content (AIGC) services, future communication systems should fulfill much more stringent requirements (including data rate, throughput, latency, etc.) with limited yet precious spectrum resources.
To tackle this challenge, semantic communication (SemCom), dramatically reducing resource consumption via extracting and transmitting semantics, has been deemed as a revolutionary communication scheme. The advanced GAI algorithms facilitate SemCom on sophisticated intelligence for model training, knowledge base construction and channel adaption. Furthermore, GAI algorithms also play an important role in the management of SemCom networks.
In this survey, we first overview the basics of GAI and SemCom as well as the synergies of the two technologies. Especially, the GAI-driven SemCom framework is presented, where many GAI models for information creation, SemCom-enabled information transmission and information effectiveness for AIGC are discussed separately. We then delve into the GAI-driven SemCom network management involving with novel management layers, knowledge management, and resource allocation. Finally, we envision several promising use cases, i.e., autonomous driving, smart city, and the Metaverse for a more comprehensive exploration.","['Semantic communication', 'AIGC', 'Generative', 'AI', 'Intelligent wireless networks', 'Knowledge management.']",[]
"Although planning is a crucial component of the autonomous driving stack, researchers have yet to develop robust planning algorithms that are capable of safely handling the diverse range of possible driving scenarios. Learning-based planners suffer from overfitting and poor long-tail performance [37]. On the other hand, rule-based planners generalize well, but might fail to handle scenarios that require complex driving maneuvers [10]. To address these limitations, we investigate the possibility of leveraging the common-sense reasoning capabilities of Large Language Models (LLMs) such as GPT4 [19] and Llama2 [28] to generate plans for self-driving vehicles. In particular, we develop a novel hybrid planner that leverages a conventional rule-based planner in conjunction with an LLM-based planner. Guided by commonsense reasoning abilities of LLMs, our approach navigates complex scenarios which existing planners struggle with, produces well-reasoned outputs while also remaining grounded through working alongside the rule-based approach. Through extensive evaluation on the nuPlan benchmark, we achieve state-of-the-art performance, outperforming all existing pure learning- and rule-based methods across most metrics.
Our code will be available at https://llmassist.github.io.",[],[]
"In this paper, we present a comprehensive investigation of stress propagation in a two-dimensional elastic circular disk.
To accurately describe the displacements and stress fields within the disk, we employ a scalar and vector potential approach, representing them as sums of Bessel functions.
The determination of the coefficients for these expansions is accomplished in the Laplace space, where we compare the boundary conditions.
By converting the inverse Laplace transforms into complex integrals using residue calculus, we successfully derive explicit expressions for the displacements and stress fields.
Notably, these expressions encompass primary, secondary, and surface waves, providing a thorough characterization of the stress propagation phenomena within the disk.
Our findings contribute to the understanding of mechanical behavior in disk-shaped components and can be valuable in the design and optimization of such structures across various engineering disciplines.","['Linear elasticity', 'Navier-Cauchy equation', 'Shock propagation', 'Laplace transform', 'Residue']",[]
"The synergy of language and vision models has given rise to Large Language and Vision Assistant models (LLVAs), designed to engage users in rich conversational experiences intertwined with image-based queries. These comprehensive multimodal models seamlessly integrate vision encoders with Large Language Models (LLMs), expanding their applications in general-purpose language and visual comprehension. The advent of Large Multimodal Models (LMMs) heralds a new era in Artificial Intelligence (AI) assistance, extending the horizons of AI utilization. This paper takes a unique perspective on LMMs, exploring their efficacy in performing image classification tasks using tailored prompts designed for specific datasets. We also investigate the LLVAs zero-shot learning capabilities. Our study includes a benchmarking analysis across four diverse datasets: MNIST, Cats Vs. Dogs, Hymnoptera (Ants Vs. Bees), and an unconventional dataset comprising Pox Vs. Non-Pox skin images. The results of our experiments demonstrate the model’s remarkable performance, achieving classification accuracies of 85%, 100%, 77%, and 79% for the respective datasets without any fine-tuning. To bolster our analysis, we assess the model’s performance post fine-tuning for specific tasks. In one instance, fine-tuning is conducted over a dataset comprising images of faces of children with and without autism. Prior to fine-tuning, the model demonstrated a test accuracy of 55%, which significantly improved to 83% post fine-tuning. These results, coupled with our prior findings, underscore the transformative potential of LLVAs and their versatile applications in real-world scenarios.","['Large', 'Language', 'Models', 'Large', 'Multimodal', 'Models', 'Prompt', 'Engineering', 'Classification']",[]
,[],[]
"We generalize Integration-By-Parts (IBP) and differential equations methods to de Sitter amplitudes related to inflation. While massive amplitudes in de Sitter spacetime are usually regarded as highly intricate, we find they have remarkably hidden concise structures from the perspective of IBP. We find the irrelevance of IBP relations to propagator-types. This also leads to the factorization of the IBP relations of each vertex integral family corresponding to d⁢τidsubscript𝜏𝑖\mathrm{d}\tau_{i}roman_d italic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT integration. Furthermore, with a smart construction of master integrals, the universal formulas for iterative reduction and d⁢logd\mathrm{d}\logroman_d roman_log-form differential equations of arbitrary vertex integral family are presented and proved. These formulas dominate all tree-level de Sitter amplitude and play a kernel role at the loop-level as well.",[],[]
"Recently, Amnon Neeman settled a bold conjecture by Antieau, Gepner, and Heller regarding the relationship between the regularity of finite-dimensional noetherian schemes and the existence of bounded t𝑡titalic_t-structures on their derived categories of perfect complexes.
In this paper, we prove some very general results about the existence of bounded t𝑡titalic_t-structures on (not necessarily algebraic or topological) triangulated categories and their invariance under completion. Our general treatment, when specialized to the case of schemes, immediately gives us Neeman’s theorem as an application and significantly generalizes another remarkable theorem by Neeman about the equivalence of bounded t𝑡titalic_t-structures on the bounded derived categories of coherent sheaves. When specialized to other cases like (not necessarily commutative) rings, nonpositive DG-rings, connective 𝔼1subscript𝔼1\mathbb{E}_{1}blackboard_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-rings, triangulated categories without models, etc., we get many other applications.
Under mild finiteness assumptions, these results give a categorical obstruction, the singularity category in our sense, to the existence of bounded t𝑡titalic_t-structures on a triangulated category. The two key tools used in our treatment are the finitistic dimension for a triangulated category (a new concept introduced in the paper) and lifting t𝑡titalic_t-structures along completions of triangulated categories.",[],[]
"In this article, we investigate periodically driven open quantum systems within the framework of Floquet-Lindblad master equations. Specifically, we discuss Lindblad master equations in the presence of a coherent, time-periodic driving and establish their general spectral features. We also clarify the notions of transient and non-decaying solutions from this spectral perspective, and then prove that any physical system described by a Floquet-Lindblad equation must have at least one physical non-equilibrium steady state (NESS), corresponding to an eigenoperator of the Floquet-Lindblad evolution superoperator 𝒰Fsubscript𝒰𝐹\mathcal{U}_{F}caligraphic_U start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT with unit eigenvalue. Since the Floquet-Lindblad formalism encapsulates the entire information regarding the NESS, it in principle enables us to obtain non-linear effects to all orders at once. The Floquet-Lindblad formalism thus provides a powerful tool for studying driven-dissipative solid-state systems, which we illustrate by deriving the nonlinear optical response of a simple two-band model of an insulating solid and comparing it with prior results established through Keldysh techniques.",[],['China']
"Multi-agent systems often require agents to collaborate with or compete against other agents with diverse goals, behaviors, or strategies. Agent modeling is essential when designing adaptive policies for intelligent machine agents in multi-agent systems, as this is the means by which the ego agent understands other agents’ behavior and extracts their meaningful policy representations. These representations can be used to enhance the ego agent’s adaptive policy which is trained by reinforcement learning. However, existing agent modeling approaches typically assume the availability of local observations from other agents (modeled agents) during training or a long observation trajectory for policy adaption. To remove these constrictive assumptions and improve agent modeling performance, we devised a Contrastive Learning-based Agent Modeling (CLAM) method that relies only on the local observations from the ego agent during training and execution. With these observations, CLAM is capable of generating consistent high-quality policy representations in real-time right from the beginning of each episode. We evaluated the efficacy of our approach in both cooperative and competitive multi-agent environments. Our experiments demonstrate that our approach achieves state-of-the-art on both cooperative and competitive tasks, highlighting the potential of contrastive learning-based agent modeling for enhancing reinforcement learning.",[],[]
"In this paper, we present a signal processing framework for directed graphs. Unlike undirected graphs, a graph shift operator such as the adjacency matrix associated with a directed graph usually does not admit an orthogonal eigenbasis. This makes it challenging to define the Fourier transform. Our methodology leverages the polar decomposition to define two distinct eigendecompositions, each associated with different matrices derived from this decomposition. We propose to extend the frequency domain and introduce a Fourier transform that jointly encodes the spectral response of a signal for the two eigenbases from the polar decomposition. This allows us to define convolution following a standard routine. Our approach has two features: it is lossless as the shift operator can be fully recovered from factors of the polar decomposition. Moreover, it subsumes the traditional graph signal processing if the graph is directed. We present numerical results to show how the framework can be applied.","['Directed graph', 'graph signal processing', 'polar decomposition']",[]
"Training large-scale language models is increasingly critical in various domains, but it is hindered by frequent failures, leading to significant time and economic costs. Current failure recovery methods in cloud-based settings inadequately address the diverse and complex scenarios that arise, focusing narrowly on erasing downtime for individual tasks without considering the overall cost impact on a cluster.
We introduce Unicron, a workload manager designed for efficient self-healing in large-scale language model training. Unicron optimizes the training process by minimizing failure-related costs across multiple concurrent tasks within a cluster. Its key features include in-band error detection for real-time error identification without extra overhead, a dynamic cost-aware plan generation mechanism for optimal reconfiguration, and an efficient transition strategy to reduce downtime during state changes. Deployed on a 128-GPU distributed cluster, Unicron demonstrates up to a 1.9×1.9\times1.9 × improvement in training efficiency over state-of-the-art methods, significantly reducing failure recovery costs and enhancing the reliability of large-scale language model training.",[],[]
,[],[]
"We extend prior work to derive three additional M-1-dimensional integral
representations – over the interval [0,1]01[0,1][ 0 , 1 ], where the prior version
was over the interval [0,∞]0[0,\infty][ 0 , ∞ ] – for products of M Slater orbitals
(such as appear in quantum transition amplitudes) that allows their
magnitudes of coordinate vector differences (square roots of polynomials)
|𝐱1−𝐱2|=x12−2⁢x1⁢x2⁢cos⁡θ+x22subscript𝐱1subscript𝐱2superscriptsubscript𝑥122subscript𝑥1subscript𝑥2𝜃superscriptsubscript𝑥22|{\bf x}_{1}-{\bf x}_{2}|=\sqrt{x_{1}^{2}-2x_{1}x_{2}\cos\theta+x_{2}^{2}}| bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | = square-root start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 2 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_cos italic_θ + italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG
to be moved from disjoint products of functions into a single quadratic
form whose square my be completed. This provides more alternatives
to Fourier transforms that introduce a 3M-dimensional momentum integral
for those products of Slater orbitals (in M separate denominators),
followed in many cases by another set of M-1-dimensional integral
representations to combine those denominators into one denominator
having a single (momentum) quadratic form. The current and prior work
is also slightly more compact than Gaussian transforms that introduce
an M-dimensional integral for products of M Slater orbitals, while
simultaneously moving them into a single (spatial) quadratic form
in a common exponential.
One may also use addition theorems for extracting the angular variables,
or even direct integration at times. Each method has its strengths
and weaknesses. We have found that two of these M-1-dimensional integral
representations over the interval [0,1]01[0,1][ 0 , 1 ] are numerically
stable, as was the prior version having integrals running over the interval
[0,∞]0[0,\infty][ 0 , ∞ ], and one does not need to test for a sufficiently large
upper integration limit as one does for the latter approach. The third integral
representation might have a better form for analytical reduction of integrals. For analytical
reductions of integrals arising from any of the three, however, there is the possible drawback for
large M of there being fewer tabled integrals over [0,1]01[0,1][ 0 , 1 ] than over
[0,∞]0[0,\infty][ 0 , ∞ ]. In particular, the results of both prior and current
representations have integration variables within square roots as
arguments of Macdonald functions. In a number of cases, these may be
converted to Meijer G-functions whose arguments have the form (a⁢x2+b⁢x+c)/x𝑎superscript𝑥2𝑏𝑥𝑐𝑥(ax^{2}+bx+c)/x( italic_a italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_b italic_x + italic_c ) / italic_x
for which a single tabled integral exists for the integrals from running
over the interval [0,∞]0[0,\infty][ 0 , ∞ ] of the prior paper, and from which
other forms may be found using the techniques given therein. This
is not so for integral representations over the interval [0,1]01[0,1][ 0 , 1 ].
Finally, we introduce a fourth integral representation that is not
easily generalizable to large M, but may well provide a bridge for
finding the requisite integrals for such Meijer G-functions over [0,1]01[0,1][ 0 , 1 ].",[],[]
"The extensive adoption of Self-supervised learning (SSL) has led to an increased security threat from backdoor attacks. While existing research has mainly focused on backdoor attacks in image classification, there has been limited exploration into their implications for object detection. In this work, we propose the first backdoor attack designed for object detection tasks in SSL scenarios, termed Object Transform Attack (SSL-OTA). SSL-OTA employs a trigger capable of altering predictions of the target object to the desired category, encompassing two attacks: Data Poisoning Attack (NA) and Dual-Source Blending Attack (DSBA). NA conducts data poisoning during downstream fine-tuning of the object detector, while DSBA additionally injects backdoors into the pre-trained encoder. We establish appropriate metrics and conduct extensive experiments on benchmark datasets, demonstrating the effectiveness and utility of our proposed attack. Notably, both NA and DSBA achieve high attack success rates (ASR) at extremely low poisoning rates (0.5%). The results underscore the importance of considering backdoor threats in SSL-based object detection and contribute a novel perspective to the field.",[],[]
,[],[]
"This paper explores the causal reasoning of large language models (LLMs) to enhance their interpretability and reliability in advancing artificial intelligence. Despite the proficiency of LLMs in a range of tasks, their potential for understanding causality requires further exploration. We propose a novel causal attribution model that utilizes “do-operators” for constructing counterfactual scenarios, allowing us to systematically quantify the influence of input numerical data and LLMs’ pre-existing knowledge on their causal reasoning processes. Our newly developed experimental setup assesses LLMs’ reliance on contextual information and inherent knowledge across various domains. Our evaluation reveals that LLMs’ causal reasoning ability depends on the context and domain-specific knowledge provided, and supports the argument that knowledge is, indeed, what LLMs principally require for sound causal reasoning. On the contrary, in the absence of knowledge, LLMs still maintain a degree of causal reasoning using the available numerical data, albeit with limitations in the calculations.
A Python implementation of our proposed method is available at https://github.com/ncsulsj/Causal_LLM.",[],[]
"In a previous paper [9] we studied an age-structured branching model without immigration. Here we consider a special case of the model, where the system is founded by a single particle with a random lifetime and the reproduction regime is supercritical. We show that there is a necessary and sufficient condition for the convergence of the Malthus normalized random measures e−α~⁢t⁢Xtsuperscript𝑒~𝛼𝑡subscript𝑋𝑡e^{-\tilde{\alpha}t}X_{t}italic_e start_POSTSUPERSCRIPT - over~ start_ARG italic_α end_ARG italic_t end_POSTSUPERSCRIPT italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where α~~𝛼\tilde{\alpha}over~ start_ARG italic_α end_ARG is a strictly positive Malthusian parameter. The convergence of e−α~⁢t⁢⟨Xt,f⟩superscript𝑒~𝛼𝑡subscript𝑋𝑡𝑓e^{-\tilde{\alpha}t}\langle X_{t},f\rangleitalic_e start_POSTSUPERSCRIPT - over~ start_ARG italic_α end_ARG italic_t end_POSTSUPERSCRIPT ⟨ italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_f ⟩ can be strengthened to hold with probability one under conditions weaker than those given in Jagers [24]. A central limit theorem of ⟨Xt,f⟩subscript𝑋𝑡𝑓\langle X_{t},f\rangle⟨ italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_f ⟩ is further proved.",[],[]
"With rising concerns about the security of IoT devices, network operators need better ways to handle potential risks. Luckily, IoT devices show consistent patterns in how they communicate. But despite previous efforts, it remains unclear how knowledge of these patterns can be made available.
As data marketplaces become popular in different domains, this paper111This manuscript is the full version of our paper [1] accepted to the IEEE/IFIP NOMS 2024 conference. proposes creating a special marketplace focused on IoT cybersecurity. The goal is to openly share knowledge about IoT devices’ behavior, using structured data formats like Manufacturer Usage Description (MUD) files. To make this work, we employ technologies like blockchain and smart contracts to build a practical and secure foundation for sharing and accessing important information about how IoT devices should behave on the network.
Our contributions are two-fold.
(1) We identify the essential features of an effective marketplace for sharing data related to the expected behaviors of IoT devices. We develop a smart contract on the Ethereum blockchain with five concrete functions; and,
(2) We implement a prototype of our marketplace in a private chain environment—our codes are publicly released. We demonstrate how effectively our marketplace functions through experiments involving MUD files from consumer IoT devices. Our marketplace enables suppliers and consumers to share MUD data on the Ethereum blockchain for under a hundred dollars, promoting accessibility and participation.","['Decentralized data marketplace', 'IoT behaviors', 'MUD files']",[]
"In recent work, Dao and Eisenbud define the notion of a Burch
index, expanding the notion of Burch rings of Dao, Kobayashi, and Takahashi, and show that for any module over a ring of Burch index at least 2, its
n𝑛nitalic_nth syzygy contains direct summands of the residue field for n=4𝑛4n=4italic_n = 4 or 5555 and all n≥7𝑛7n\geq 7italic_n ≥ 7. We investigate how this behavior is explained by the bar
resolution formed from appropriate differential graded (dg) resolutions, yielding a new proof that includes all n≥5𝑛5n\geq 5italic_n ≥ 5, which is sharp. When the module is Golod, we use instead the bar resolution formed from A∞subscript𝐴A_{\infty}italic_A start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT resolutions to identify such k𝑘kitalic_k summands explicitly for all n≥4𝑛4n\geq 4italic_n ≥ 4 and show that the number of these grows exponentially as the homological degree increases.",['Burch'],[]
,[],[]
"We investigate the tachyonic instability of Kerr-Newman (KN) black hole with a rotation parameter a𝑎aitalic_a in the Einstein-Chern-Simons-scalar theory coupled with a quadratic massive scalar field.
This instability analysis corresponds to exploring the onset of spontaneous scalarization for KN black holes.
First, we find no a𝑎aitalic_a-bound for α<0𝛼0\alpha<0italic_α < 0 case by considering (1+1)-dimensional analytical method.
A direct numerical method is adopted to explore (2+1)-dimensional time evolution of a massive scalar perturbation with positive and negative α𝛼\alphaitalic_α to obtain threshold curves numerically.
We obtain threshold curves αth⁢(a)subscript𝛼th𝑎\alpha_{\rm th}(a)italic_α start_POSTSUBSCRIPT roman_th end_POSTSUBSCRIPT ( italic_a ) of tachyonic instability for positive α𝛼\alphaitalic_α without any a𝑎aitalic_a-bounds.
We expect to find the same threshold curves αth⁢(a)subscript𝛼th𝑎\alpha_{\rm th}(a)italic_α start_POSTSUBSCRIPT roman_th end_POSTSUBSCRIPT ( italic_a ) of tachyonic instability for negative α𝛼\alphaitalic_α without any a𝑎aitalic_a-bound because its linearized scalar theory is invariant under the transformation of α→−α→𝛼𝛼\alpha\to-\alphaitalic_α → - italic_α and θ→−θ→𝜃𝜃\theta\to-\thetaitalic_θ → - italic_θ. In addition, it is found that the scalar mass term suppresses tachyonic instability of KN black holes.",[],[]
,[],[]
"Quantum cryptography is now considered as a promising technology due to its promise of unconditional security. In recent years, rigorous work is being done for the experimental realization of quantum key distribution (QKD) protocols to realize secure networks. Among various QKD protocols, coherent one way and differential phase shift QKD protocols have undergone rapid experimental developments due to the ease of experimental implementations with the present available technology. In this work, we have experimentally realized optical fiber based coherent one way and differential phase shift QKD protocols at telecom wavelength. Both protocols belong to a class of protocols named as distributed phase reference protocol in which weak coherent pulses are used to encode the information. Further, we have analysed the key rates with respect to different parameters such distance, disclose rate, compression ratio and detector dead time.",[],['India']
Suppose G𝐺Gitalic_G is a finitely generated infinite group and 𝒢𝒢\mathcal{G}caligraphic_G is a graph of groups decomposition of G𝐺Gitalic_G such that the edge groups are finite. This paper establishes that the topology of the Floyd boundary of G𝐺Gitalic_G is uniquely determined by the topology of the Floyd boundary of each vertex group of 𝒢𝒢\mathcal{G}caligraphic_G.,"['Bass–Serre tree', 'Floyd boundary', 'free products']",[]
"Autonomous vehicles increasingly utilize the vision-based perception module to acquire information about driving environments and detect obstacles. Correct detection and classification are important to ensure safe driving decisions. Existing works have demonstrated the feasibility of fooling the perception models such as object detectors and image classifiers with printed adversarial patches. However, most of them are indiscriminately offensive to every passing autonomous vehicle.
In this paper, we propose TPatch, a physical adversarial patch triggered by acoustic signals. Unlike other adversarial patches, TPatch remains benign under normal circumstances but can be triggered to launch a hiding, creating or altering attack by a designed distortion introduced by signal injection attacks towards cameras. To avoid the suspicion of human drivers and make the attack practical and robust in the real world, we propose a content-based camouflage method and an attack robustness enhancement method to strengthen it. Evaluations with three object detectors, YOLO V3/V5 and Faster R-CNN, and eight image classifiers demonstrate the effectiveness of TPatch in both the simulation and the real world. We also discuss possible defenses at the sensor, algorithm, and system levels.",[],[]
"We construct a class of nonlinear coherent states (NLCSs) by introducing a more general nonlinear function and study their non-classical properties, specifically the second-order correlation function g(2)⁢(0)superscript𝑔20g^{(2)}(0)italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ), Mandel parameter Q𝑄Qitalic_Q, squeezing, amplitude squared squeezing and Wigner function of the optical field.
The results indicate that the non-classical properties of the new types of even and odd NLCSs crucially depend on nonlinear functions. More concretely, we find that the new even NLCSs could exhibit the photon-bunching effect whereas the new odd NLCSs could show photon-antibunching effect. The degree of squeezing is also significantly affected by the parameter selection of these NLCSs. By employing various forms of nonlinear functions, it becomes possible to construct NLCSs with diverse properties, thereby providing a theoretical foundation for corresponding experimental investigations.",[],['China']
"We report the occurrence of vibrational resonance (VR) and the underlying mechanism in a simple piecewise linear electronic circuit, namely the Murali-Lakshmanan-Chua (MLC) circuit, driven by an additional biharmonic signal with widely different frequency. When the amplitude of the high-frequency force is tuned, the resultant vibrational resonance is used to detect the low-frequency signal and also to enhance it into a high-frequency signal. Further, we also show that even when the low-frequency signal is changed from sine wave to square and sawtooth waves, vibrational resonance can be used to detect and enhance them into high-frequency signals. These behaviors, confirmed by experimental results, are illustrated with appropriate analytical and numerical solutions of the corresponding circuit equations describing the system. Finally, we also verify the signal detection in the above circuit even with the addition of noise.",[],['India']
"The proliferation of images captured from millions of cameras and the advancement of facial recognition (FR) technology have made the abuse of FR a severe privacy threat. Existing works typically rely on obfuscation, synthesis, or adversarial examples to modify faces in images to achieve anti-facial recognition (AFR). However, the unmodified images captured by camera modules that contain sensitive personally identifiable information (PII) could still be leaked. In this paper, we propose a novel approach, CamPro, to capture inborn AFR images. CamPro enables well-packed commodity camera modules to produce images that contain little PII and yet still contain enough information to support other non-sensitive vision applications, such as person detection. Specifically, CamPro tunes the configuration setup inside the camera image signal processor (ISP), i.e., color correction matrix and gamma correction, to achieve AFR, and designs an image enhancer to keep the image quality for possible human viewers. We implemented and validated CamPro on a proof-of-concept camera, and our experiments demonstrate its effectiveness on ten state-of-the-art black-box FR models. The results show that CamPro images can significantly reduce face identification accuracy to 0.3% while having little impact on the targeted non-sensitive vision application. Furthermore, we find that CamPro is resilient to adaptive attackers who have re-trained their FR models using images generated by CamPro, even with full knowledge of privacy-preserving ISP parameters.",[],[]
The assumption that the system Hamiltonian for entangled states is additive is widely used in orthodox quantum no-signalling arguments. It is shown that additivity implies a contradiction with the assumption that the system being studied is entangled.,[],[]
"Inadequate generality across different organs and tasks constrains the application of ultrasound (US) image analysis methods in smart healthcare. Building a universal US foundation model holds the potential to address these issues. Nevertheless, the development of such foundational models encounters intrinsic challenges in US analysis, i.e., insufficient databases, low quality, and ineffective features. In this paper, we present a universal US foundation model, named USFM, generalized to diverse tasks and organs towards label efficient US image analysis. First, a large-scale Multi-organ, Multi-center, and Multi-device US database was built, comprehensively containing over two million US images. Organ-balanced sampling was employed for unbiased learning. Then, USFM is self-supervised pre-trained on the sufficient US database. To extract the effective features from low-quality US images, we proposed a spatial-frequency dual masked image modeling method. A productive spatial noise addition-recovery approach was designed to learn meaningful US information robustly, while a novel frequency band-stop masking learning approach was also employed to extract complex, implicit grayscale distribution and textural variations. Extensive experiments were conducted on the various tasks of segmentation, classification, and image enhancement from diverse organs and diseases. Comparisons with representative US image analysis models illustrate the universality and effectiveness of USFM. The label efficiency experiments suggest the USFM obtains robust performance with only 20% annotation, laying the groundwork for the rapid development of US models in clinical practices.",[],[]
,[],[]
"Occlusion presents a significant challenge in human pose estimation. The challenges posed by occlusion can be attributed to the following factors: 1) Data: The collection and annotation of occluded human pose samples are relatively challenging. 2) Feature: Occlusion can cause feature confusion due to the high similarity between the target person and interfering individuals. 3) Inference: Robust inference becomes challenging due to the loss of complete body structural information. The existing methods designed for occluded human pose estimation usually focus on addressing only one of these factors. In this paper, we propose a comprehensive framework DAG (Data, Attention, Graph) to address the performance degradation caused by occlusion. Specifically, we introduce the mask joints with instance paste data augmentation technique to simulate occlusion scenarios. Additionally, an Adaptive Discriminative Attention Module (ADAM) is proposed to effectively enhance the features of target individuals. Furthermore, we present the Feature-Guided Multi-Hop GCN (FGMP-GCN) to fully explore the prior knowledge of body structure and improve pose estimation results. Through extensive experiments conducted on three benchmark datasets for occluded human pose estimation, we demonstrate that the proposed method outperforms existing methods. Code and data will be publicly available.",[],[]
"Radical subgroups play an important role in both group theory and representation theory. In this paper we present
a strategy of classifying radical subgroups of finite reductive groups. As an application, we complete the proof
of the inductive blockwise Alperin weight condition for the Chevalley groups F4⁡(q)subscriptF4𝑞\operatorname{F}_{4}(q)roman_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_q ), contributing to the program
to prove the Alperin weight conjecture by verifying its inductive condition for simple groups.","['Radical subgroups', 'finite reductive group', 'Alperin weight conjecture', 'inductive blockwise', 'Alperin weight condition', 'exceptional groups of type', 'F4subscriptF4\\operatorname{F}_{4}roman_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT.']",[]
"In this supplementary material, we first provide more details about fundamentals of quantum channels, and properties of fixed points and extreme metastable states (EMSs) in Ramsey interferometry measurements (RIMs). Then we present Monte Carlo simulation results for a target system composed of multiple qubits, with the ancilla qubit under both RIMs and dynamical decoupling (DD) sequences. Moreover, we numerically demonstrate that quantum metastability is robust even when the target system suffers additional dissipation.",[],['China']
"Question Answering over Knowledge Graph (KGQA) aims to seek answer entities for the natural language question from a large-scale Knowledge Graph (KG).
To better perform reasoning on KG, recent work typically adopts a pre-trained language model (PLM) to model the question, and a graph neural network (GNN) based module to perform multi-hop reasoning on the KG.
Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions.
To solve it, we aim to simplify the above two-module approach, and develop a more capable PLM that can directly support subgraph reasoning for KGQA, namely ReasoningLM.
In our approach, we propose a subgraph-aware self-attention mechanism to imitate the GNN for performing structured reasoning, and also adopt an adaptation tuning strategy to adapt the model parameters with 20,000 subgraphs with synthesized questions.
After adaptation, the PLM can be parameter-efficient fine-tuned on downstream tasks.
Experiments show that ReasoningLM surpasses state-of-the-art models by a large margin, even with fewer updated parameters and less training data.
Our codes and data are publicly available at https://github.com/RUCAIBox/ReasoningLM.",[],[]
"Purpose:
Progression of hip osteoarthritis (hip OA) leads to pain and disability, likely leading to surgical treatment such as hip arthroplasty at the terminal stage. The severity of hip OA is often classified using the Crowe and Kellgren-Lawrence (KL) classifications. However, as the classification is subjective, we aimed to develop an automated approach to classify the disease severity based on the two grades using digitally-reconstructed radiographs (DRRs) from CT images.
Methods:
Automatic grading of the hip OA severity was performed using deep learning-based models. The models were trained to predict the disease grade using two grading schemes, i.e., predicting the Crowe and KL grades separately, and predicting a new ordinal label combining both grades and representing the disease progression of hip OA. The models were trained in classification and regression settings. In addition, the model uncertainty was estimated and validated as a predictor of classification accuracy. The models were trained and validated on a database of 197 hip OA patients, and externally validated on 52 patients. The model accuracy was evaluated using exact class accuracy (ECA), one-neighbor class accuracy (ONCA), and balanced accuracy.
Results:
The deep learning models produced a comparable accuracy of approximately 0.65 (ECA) and 0.95 (ONCA) in the classification and regression settings. The model uncertainty was significantly larger in cases with large classification errors (P<6e-3).
Conclusion:
In this study, an automatic approach for grading hip OA severity from CT images was developed. The models have shown comparable performance with high ONCA, which facilitates automated grading in large-scale CT databases and indicates the potential for further disease progression analysis. Classification accuracy was correlated with the model uncertainty, which would allow for the prediction of classification errors. The code will be made publicly available at https://github.com/NAIST-ICB/HipOA-Grading.",[],[]
"As indoor applications grow in diversity, wireless sensing, vital in areas like localization and activity recognition, is attracting renewed interest. Indoor wireless sensing relies on signal processing, particularly channel state information (CSI) based signal parameter estimation. Nonetheless, regarding reflected signals induced by dynamic human targets, no satisfactory algorithm yet exists for estimating the acceleration of dynamic path length change (DPLC), which is crucial for various sensing tasks in this context. Hence, this paper proposes DP-AcE, a CSI based DPLC acceleration estimation algorithm. We first model the relationship between the phase difference of adjacent CSI measurements and the DPLC’s acceleration. Unlike existing works assuming constant velocity, DP-AcE considers both velocity and acceleration, yielding a more accurate and objective representation. Using this relationship, an algorithm combining scaling with Fourier transform is proposed to realize acceleration estimation. We evaluate DP-AcE via the acceleration estimation and acceleration-based fall detection with the collected CSI. Experimental results reveal that, using distance as the metric, DP-AcE achieves a median acceleration estimation percentage error of 4.38%. Furthermore, in multi-target scenarios, the fall detection achieves an average true positive rate of 89.56% and a false positive rate of 11.78%, demonstrating its importance in enhancing indoor wireless sensing capabilities.","['Wireless sensing', 'channel state information', 'signal parameter estimation.']",[]
"The hybrid neural differentiable models mark a significant advancement in the field of scientific machine learning. These models, integrating numerical representations of known physics into deep neural networks, offer enhanced predictive capabilities and show great potential for data-driven modeling of complex physical systems. However, a critical and yet unaddressed challenge lies in the quantification of inherent uncertainties stemming from multiple sources. Addressing this gap, we introduce a novel method, DiffHybrid-UQ, for effective and efficient uncertainty propagation and estimation in hybrid neural differentiable models, leveraging the strengths of deep ensemble Bayesian learning and nonlinear transformations. Specifically, our approach effectively discerns and quantifies both aleatoric uncertainties, arising from data noise, and epistemic uncertainties, resulting from model-form discrepancies and data sparsity. This is achieved within a Bayesian model averaging framework, where aleatoric uncertainties are modeled through hybrid neural models. The unscented transformation plays a pivotal role in enabling the flow of these uncertainties through the nonlinear functions within the hybrid model. In contrast, epistemic uncertainties are estimated using an ensemble of stochastic gradient descent (SGD) trajectories. This approach offers a practical approximation to the posterior distribution of both the network parameters and the physical parameters. Notably, the DiffHybrid-UQ framework is designed for simplicity in implementation and high scalability, making it suitable for parallel computing environments. The merits of the proposed method have been demonstrated through problems governed by both ordinary and partial differentiable equations.",[],[]
"The sparsity of reward feedback remains a challenging problem in online deep reinforcement learning (DRL). Previous approaches have utilized temporal credit assignment (CA) to achieve impressive results in multiple hard tasks. However, many CA methods relied on complex architectures or introduced sensitive hyperparameters to estimate the impact of state-action pairs. Meanwhile, the premise of the feasibility of CA methods is to obtain trajectories with sparse rewards, which can be troublesome in sparse-reward environments with large state spaces. To tackle these problems, we propose a simple and efficient algorithm called Policy Optimization with Smooth Guidance (POSG) that leverages a small set of sparse-reward demonstrations to make reliable and effective long-term credit assignments while efficiently facilitating exploration. The key idea is that the relative impact of state-action pairs can be indirectly estimated using offline demonstrations rather than directly leveraging the sparse reward trajectories generated by the agent. Specifically, we first obtain the trajectory importance by considering both the trajectory-level distance to demonstrations and the returns of the relevant trajectories. Then, the guidance reward is calculated for each state-action pair by smoothly averaging the importance of the trajectories through it, merging the demonstration’s distribution and reward information. We theoretically analyze the performance improvement bound caused by smooth guidance rewards and derive a new worst-case lower bound on the performance improvement. A comprehensive evaluation of POSG is conducted by benchmarking it with several state-of-the-art RL methods in four different sparse-reward environments with discrete and continuous action spaces. Extensive results demonstrate POSG’s significant advantages in control performance and convergence speed compared to benchmark DRL algorithms. Notably, the specific metrics and quantifiable results are investigated to demonstrate the superiority of POSG.",[],[]
"Backdoor attacks in the traditional graph neural networks (GNNs) field are easily detectable due to the dilemma of confusing labels.
To explore the backdoor vulnerability of GNNs and create a more stealthy backdoor attack method, a clean-label graph backdoor attack method(CGBA) in the node classification task is proposed in this paper.
Differently from existing backdoor attack methods, CGBA requires neither modification of node labels nor graph structure.
Specifically, to solve the problem of inconsistency between the contents and labels of the samples, CGBA selects poisoning samples in a specific target class and uses the label of sample as the target label (i.e., clean-label) after injecting triggers into the target samples. To guarantee the similarity of neighboring nodes, the raw features of the nodes are elaborately picked as triggers to further improve the concealment of the triggers.
Extensive experiments results show the effectiveness of our method.
When the poisoning rate is 0.04, CGBA can achieve an average attack success rate of 87.8%, 98.9%, 89.1%, and 98.5%, respectively.",[],[]
"We study solutions to systems of stream inclusions f∈T⁢(f)𝑓𝑇𝑓f\in T(f)italic_f ∈ italic_T ( italic_f ), where T𝑇Titalic_T is assumed to be causal in the sense that elements in output streams are determined by a finite history of inputs.
For solving these inclusions we develop a correspondence of causality
and contraction with respect to the prefix distance on streams.
Now, based on this causality-contraction correspondence, we apply fixpoint principles for the spherically complete ultrametric space of streams to obtain solutions for causal stream inclusions.
The underlying fixpoint iterations induce fixpoint induction principles for reasoning about solutions of causal stream inclusions.
In addition, these fixpoint approximations induce anytime algorithms for computing finite stream prefixes of solutions.
We illustrate the use of these developments
for some central concepts of system design.","['Formal', 'Methods', 'Fixpoint', 'Approximation', 'Systems', 'Engineering.']",[]
"In open-domain Question Answering (QA), dense retrieval is crucial for finding relevant passages for answer generation. Typically, contrastive learning is used to train a retrieval model that maps passages and queries to the same semantic space. The objective is to make similar ones closer and dissimilar ones further apart. However, training such a system is challenging due to the false negative issue, where relevant passages may be missed during data annotation. Hard negative sampling, which is commonly used to improve contrastive learning, can introduce more noise in training. This is because hard negatives are those closer to a given query, and thus more likely to be false negatives. To address this issue, we propose a novel contrastive confidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly used loss for dense retrieval. Our analysis shows that the regularizer helps dense retrieval models be more robust against false negatives with a theoretical guarantee. Additionally, we propose a model-agnostic method to filter out noisy negative passages in the dataset, improving any downstream dense retrieval models. Through experiments on three datasets, we demonstrate that our method achieves better retrieval performance in comparison to existing state-of-the-art dense retrieval systems.",[],[]
"This paper investigates block-level interference exploitation (IE) precoding for multi-user multiple-input single-output (MU-MISO) downlink systems. To overcome the need for symbol-level IE precoding to frequently update the precoding matrix, we propose to jointly optimize all the precoders or transmit signals within a transmission block. The resultant precoders only need to be updated once per block, and while not necessarily constant over all the symbol slots, we refer to the technique as block-level slot-variant IE precoding. Through a careful examination of the optimal structure and the explicit duality inherent in block-level power minimization (PM) and signal-to-interference-plus-noise ratio (SINR) balancing (SB) problems, we discover that the joint optimization can be decomposed into subproblems with smaller variable sizes. As a step further, we propose block-level slot-invariant IE precoding by adding a structural constraint on the slot-variant IE precoding to maintain a constant precoder throughout the block. A novel linear precoder for IE is further presented, and we prove that the proposed slot-variant and slot-invariant IE precoding share an identical solution when the number of symbol slots does not exceed the number of users. Numerical simulations demonstrate that the proposed precoders achieve a significant complexity reduction compared against benchmark schemes, without sacrificing performance.","['MU-MISO', 'block-level precoding', 'symbol-level precoding', 'power minimization', 'SINR balancing', 'interference exploitation.']",[]
"Incorporating symmetry as an inductive bias into multi-agent reinforcement learning (MARL) has led to improvements in generalization, data efficiency, and physical consistency. While prior research has succeeded in using perfect symmetry prior, the realm of partial symmetry in the multi-agent domain remains unexplored. To fill in this gap, we introduce the partially symmetric Markov game, a new subclass of the Markov game. We then theoretically show that the performance error introduced by utilizing symmetry in MARL is bounded, implying that the symmetry prior can still be useful in MARL even in partial symmetry situations. Motivated by this insight, we propose the Partial Symmetry Exploitation (PSE) framework that is able to adaptively incorporate symmetry prior in MARL under different symmetry-breaking conditions. Specifically, by adaptively adjusting the exploitation of symmetry, our framework is able to achieve superior sample efficiency and overall performance of MARL algorithms. Extensive experiments are conducted to demonstrate the superior performance of the proposed framework over baselines. Finally, we implement the proposed framework in real-world multi-robot testbed to show its superiority.",[],[]
"In this paper, we scale evolutionary algorithms to high-dimensional optimization problems that deceptively possess a low effective dimensionality (certain dimensions do not significantly affect the objective function). To this end, an instantiation of the multiform optimization paradigm is presented, where multiple low-dimensional counterparts of a target high-dimensional task are generated via random embeddings. Since the exact relationship between the auxiliary (low-dimensional) tasks and the target is a priori unknown, a multiform evolutionary algorithm is developed for unifying all formulations into a single multi-task setting. The resultant joint optimization enables the target task to efficiently reuse solutions evolved across various low-dimensional searches via cross-form genetic transfers, hence speeding up overall convergence characteristics. To validate the overall efficacy of our proposed algorithmic framework, comprehensive experimental studies are carried out on well-known continuous benchmark functions as well as a set of practical problems in the hyper-parameter tuning of machine learning models and deep learning models in classification tasks and Predator-Prey games, respectively.","['High-dimensional search', 'evolutionary multi-tasking', 'transfer optimization', 'random embeddings.']",[]
,[],[]
"This work introduces the L3Cube-MahaSocialNER dataset, the first and largest social media dataset specifically designed for Named Entity Recognition (NER) in the Marathi language. The dataset comprises 18,000 manually labeled sentences covering eight entity classes, addressing challenges posed by social media data, including non-standard language and informal idioms. Deep learning models, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on the individual dataset with IOB and non-IOB notations. The results demonstrate the effectiveness of these models in accurately recognizing named entities in Marathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric information extraction and supports real-time applications, providing a valuable resource for public opinion analysis, news, and marketing on social media platforms. We also show that the zero-shot results of the regular NER model are poor on the social NER test set thus highlighting the need for more social NER datasets. The datasets and models are publicly available at https://github.com/l3cube-pune/MarathiNLP","['Named', 'Entity', 'Recognition', 'Deep', 'Learning', 'Natural', 'Language', 'Processing', 'BERT', 'mBERT', 'ALBERT', 'RoBERTa', 'Muril', 'Indic bert', 'Convolutional', 'Neural', 'Network', 'Bidirectional long short-term memory', 'Long short-term memory', 'Marathi', 'NER', 'Efficient', 'NLP']",['India']
"We study the implementation of a Chebyshev spectral method with forward Euler integrator proposed in [6] to investigate a peridynamic nonlocal formulation of Richards’ equation. We prove the convergence of the fully-discretization of the model showing the existence and uniqueness of a solution to the weak formulation of the method by using the compactness properties of the approximated solution and exploiting the stability of the numerical scheme. We further support our results through numerical simulations, using initial conditions with different order of smoothness, showing reliability and robustness of the theoretical findings presented in the paper.","['Richards’ equation', 'nonlocal models', 'peridynamics', 'Chebyshev spectral methods']",[]
,[],[]
"We investigated the beat-to-beat fluctuation of the photoplethysmography (PPG) waveform. The motivation is that morphology variability extracted from the arterial blood pressure (ABP) has been found to correlate with baseline condition and short-term surgical outcome of the patients undergoing liver transplant surgery. Numerous interactions of physiological mechanisms regulating the cardiovascular system could underlie the variability of morphology. We used the unsupervised manifold learning algorithm, Dynamic Diffusion Map, to quantify the multivariate waveform morphological variation. Due to the physical principal of light absorption, PPG waveform signals are more susceptible to artifact and are nominally used only for visual inspection of data quality in clinical medical environment. But on the other hand, the noninvasive, easy-to-use nature of PPG grants a wider range of biomedical application, which inspired us to investigate the variability of morphology information from PPG waveform signal. We developed data analysis techniques to improve the performance and validated with the real-life clinical database. We investigated the beat-to-beat fluctuation of the photoplethysmography (PPG) waveform. The motivation is that morphology variability extracted from the arterial blood pressure (ABP) has been found to correlate with baseline condition and short-term surgical outcome of the patients undergoing liver transplant surgery. Numerous interactions of physiological mechanisms regulating the cardiovascular system could underlie the variability of morphology. We used the unsupervised manifold learning algorithm, Dynamic Diffusion Map, to quantify the multivariate waveform morphological variation. Due to the physical principal of light absorption, PPG waveform signals are more susceptible to artifact and are nominally used only for visual inspection of data quality in clinical medical environment. But on the other hand, the noninvasive, easy-to-use nature of PPG grants a wider range of biomedical application, which inspired us to investigate the variability of morphology information from PPG waveform signal. We developed data analysis techniques to improve the performance and validated with the real-life clinical database.",[],[]
"We study nonequilibrium spin dynamics in differentially rotating systems, deriving an effective Hamiltonian for conduction electrons in the comoving frame. In contrast to conventional spin current generation mechanisms that require vorticity, our theory describes spins and spin currents arising from differentially rotating systems regardless of vorticity. We demonstrate the generation of spin currents in differentially rotating systems, such as liquid metals with Taylor-Couette flow.
Our alternative mechanism will be important in the development of nanomechanical spin devices.",[],"['Japan', 'China']"
"Distributed computing in Blockchain Technology (BCT) hinges on a trust assumption among independent nodes. Without a third-party interface or what’s known as a ‘Blockchain Oracle’, it can’t interact with the external world. This Oracle plays a crucial role by feeding extrinsic data into the Blockchain, ensuring that Smart Contracts operate accurately in real time. The ‘Oracle problem’ arises from the inherent difficulty in verifying the truthfulness of the data sourced by these Oracles. The genuineness of a Blockchain Oracle is paramount, as it directly influences the Blockchain’s reliability, credibility, and scalability. To tackle these challenges, a strategy rooted in Byzantine fault-tolerance ϕitalic-ϕ\phiitalic_ϕ is introduced. Furthermore, an autonomous system for sustainability and audibility, built on heuristic detection, is put forth. The effectiveness and precision of the proposed strategy outperformed existing methods using two real-world datasets, aimed to meet the authenticity standards for Blockchain Oracles.","['Blockchain', 'Oracles', 'Trust', 'Assumption', 'Asymmetric', 'Byzantine', 'Quorums', 'Smart', 'Contracts', 'Oracle', 'Data', 'Reliability', 'Blockchain', 'Scalability', 'Solutions', 'Decentralized', 'Applications (DApps).']",['France']
"The paper is an attempt to apply the theory of dessins d’enfants to the theory of fullerenes. The classical results concerning the calculation of the dodecahedron Belyi function are presented and then applied to the calculation of the Belyi function of the barrel, and the euclidean geometry of the latter is investigated. The non-existence of the fullerene with the only hexagonal face is established by the methods of dessins d’enfants.",[],[]
,[],[]
,[],[]
"Gas-particle flows are commonly simulated through two-fluid model at industrial-scale. However, these simulations need very fine grid to have accurate flow predictions, which is prohibitively demanding in terms of computational resources. To circumvent this problem, the filtered two-fluid model has been developed, where large-scale flow field is numerically resolved and small-scale fluctuations are accounted for through subgrid-scale modeling. In this study, we have performed fine-grid two-fluid simulations of dilute gas-particle flows in periodic domains and applied explicit filtering to generate datasets. Then, these datasets have been used to develop artificial neural network (ANN) models for closures such as the filtered drag force and solid phase stress for the filtered two-fluid model. The set of input variables for the subgrid drag force ANN model that has been found previously to work well for dense flow regimes is found to work as well for the dilute regime. In addition, we present a Galilean invariant tensor basis neural network (TBNN) model for the filtered solid phase stress which can capture nicely the anisotropic nature of the solid phase stress arising from subgrid-scale velocity fluctuations. Finally, the predictions provided by this new TBNN model are compared with those obtained from a simple eddy-viscosity ANN model.",[],[]
"This paper proposes a cyber-resilient distributed control strategy equipped with attack detection capabilities for islanded AC microgrids in the presence of bounded stealthy cyber attacks affecting both frequency and power information exchanged among neighboring distributed generators (DGs). The proposed control methodology relies on the construction of an auxiliary layer and the establishment of effective inter-layer cooperation between the actual DGs in the control layer and the virtual DGs in the auxiliary layer. This cooperation aims to achieve robust frequency restoration and proportional active power-sharing. It is shown that the in situ presence of a concealed auxiliary layer not only guarantees resilience against stealthy bounded attacks on both frequency and power-sharing but also facilitates a network-enabled attack identification mechanism. The paper provides rigorous proof of the stability of the closed-loop system and derives bounds for frequency and power deviations under attack conditions, offering insights into the impact of the attack signal, control and pinning gains, and network connectivity on the system’s convergence properties. The performance of the proposed controllers is illustrated by simulating a networked islanded AC microgrid in a Simulink environment showcasing both attributes of attack resilience and attack detection.","['AC microgrids', 'cyber-security', 'network-enabled attack detection', 'resilient control', 'stealthy attacks.']",[]
We investigate the Galois structure of algebraic units in cyclic extensions of number fields and thereby obtain strong new results on the existence of independent Minkowski S𝑆Sitalic_S-units.,"['Minkowski units', 'Galois structure of algebraic units', 'Krull-Schmidt decomposition', 'Yakovlev diagram']",[]
"For a finite valued field extension (L/K,v)𝐿𝐾𝑣(L/K,v)( italic_L / italic_K , italic_v ) we describe the problem of find sets of generators for the corresponding extension 𝒪L/𝒪Ksubscript𝒪𝐿subscript𝒪𝐾\mathcal{O}_{L}/\mathcal{O}_{K}caligraphic_O start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT / caligraphic_O start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT of valuation rings. The main tool to obtain such sets are complete sets of (key) polynomials. We show that when the initial index coincide with the ramification index, sequences of key polynomials naturally give rise to sets of generators. We use this to prove Knaf’s conjecture for pure extensions.","['Key polynomials', 'Kähler differentials', 'the defect']",[]
,[],[]
,[],[]
"Context:Solar filaments, also called solar prominences when appearing on the solar limb, consist of dense, cool plasma suspended in the hot and tenuous corona, which are the main potential sources of solar storms.
Aims:To understand the onset mechanism of solar filaments, we investigate the eruption process of an inverted U-shaped solar filament and two precursory jet-like activities.
Methods:Utilizing observations from the New Vacuum Solar Telescope (NVST), Solar Dynamics Observatory (SDO), and Solar Terrestrial Relations Observatory-Ahead (STEREO-A), we investigate the event from two distinct observational perspectives: on the solar disk using NVST and SDO, and on the solar limb using STEREO-A. We employ both a non-linear force-free field model and a potential field model to reconstruct the coronal magnetic field, aiming to understand its magnetic properties.
Results:Two precursor jet-like activities were observed before the eruption, displaying an untwisted rotation. The second activity released an estimated twist of over two turns. During these two jet-like activities, “Y”-shaped brightenings, newly emerging magnetic flux accompanied by magnetic cancellation, and the formation of newly moving fibrils were identified. Combining these observational features, it can be inferred that these two precursor jet-like activities released the magnetic field constraining the filament and were caused by newly emerging magnetic flux. Before the filament eruption, it was observed that some moving flows had been ejected from the site as the onset of two jet-like activities, indicating the same physical process as two jet-like activities. Extrapolations revealed that the filament laid under the height of the decay index of 1.0 and had strong magnetic field (540 Gauss) and a high twist number (2.4 turns) before the eruption. An apparent rotational motion was observed during the filament eruption.
Conclusions:We deduce that the solar filament, exhibiting an inverted U-shape, is a significantly twisted flux rope. The eruption of the filament was initiated by the release of constraining magnetic fields through continuous magnetic reconnection. This reconnection process was caused by the emergence of newly magnetic flux.","['Solar filament –', 'Solar filament eruptions –', 'Solar activity']",[]
"Linear Regression and neural networks are widely used to model data. Neural networks distinguish themselves from linear regression with their use of activation functions that enable modeling nonlinear functions. The standard argument for these activation functions is that without them, neural networks only can model a line. However, a novel explanation we propose in this paper for the impracticality of neural networks without activation functions, or linear neural networks, is that they actually reduce both training and testing performance. Having more parameters makes LNNs harder to optimize, and thus they require more training iterations than linear regression to even potentially converge to the optimal solution. We prove this hypothesis through an analysis of the optimization of an LNN and rigorous testing comparing the performance between both LNNs and linear regression on synthethic, noisy datasets.",[],[]
,[],[]
,[],['Italy']
"In this paper, we introduce semi-infinite tensor complementarity problem to provide an approach for considering a more realistic situation of the problem. We prove the necessary and sufficient conditions for the existence of the solution set. In this context, we study the error bounds of the solution set in terms of residual function.

Keywords: Semi-infinite tensor complementarity problem, error bound, residual function, R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-tensor.

AMS subject classifications: 90C30, 90C33, 15A69.",[],[]
"Context:The far-infrared (FIR) distribution at high Galactic latitudes,
observed with Planck, is filamentary with coherent structures in
polarization. These structures are also closely related to
H i filaments with coherent velocity structures. There is a
long-standing debate about the physical nature of these
structures. They are considered either as velocity caustics,
fluctuations engraved by the turbulent velocity field or as cold
three-dimensional density structures in the interstellar medium (ISM).
Aims:We discuss different approaches to data analysis and interpretation in order to
work out the differences.
Methods:We considered mathematical preliminaries for the derivation of caustics
that characterize filamentary structures in the ISM. Using the
Hessian operator, we traced individual FIR filamentary structures in
H i from channel maps as observed and alternatively from data that
are provided by the velocity decomposition algorithm (VDA). VDA is
claimed to separate velocity caustics from density effects.
Results:Based on the strict mathematical definition, the so-called velocity
caustics are not actually caustics. These VDA data products may contain caustics
in the same way as the original H i observations. Caustics derived
by a Hessian analysis of both databases are nearly identical with a
correlation coefficient of 98%. However, the VDA algorithm leads to a
30% increase in the alignment uncertainties when fitting
FIR/H i orientation angles. Thus, the VDA velocity crowding concept
fails to explain the alignment of FIR/H i filaments at |b|>20⁢°𝑏20°|b|>20\degr| italic_b | > 20 °. We used H i absorption data to constrain the physical nature
of FIR/H i filaments and determine spin temperatures and volume
densities of FIR/H i filaments. H i filaments exist as cold neutral medium
(CNM)
structures; outside the filaments no CNM absorption is detectable.
Conclusions: The CNM in the diffuse ISM is exclusively located in filaments with FIR
counterparts. These filaments at high Galactic latitudes exist as cold
density structures; velocity crowding effects are negligible.","['clouds –', 'ISM: structure – (ISM:) dust', 'extinction –\nturbulence – magnetic fields – magnetohydrodynamics (MHD)']",[]
"In this paper, we introduce set-valued tensor complementarity problem where the elements of the involved tensors are defined based on a set-valued mapping. We study several properties of the solution set under the framework of set-valued mapping. We provide the necessary and sufficient conditions for the zero solution of a set-valued tensor complementarity problem. We introduce limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property for the set of tensors and establish a connection between limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property and the level boundedness of the merit function of the corresponding set-valued tensor complementarity problem.

Keywords: Set-valued tensor complementarity problem, S𝑆Sitalic_S-tensor, semi-positive tensor, R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-tensor, merit function, limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property.

AMS subject classifications: 15A69, 90C30, 90C33.",[],[]
"In this letter, we propose a deep-unfolding-based framework (DUNet) to maximize the secrecy rate in reconfigurable intelligent surface (RIS) empowered multi-user wireless networks. To tailor DUNet, first we relax the problem, decouple it into beamforming and phase shift subproblems, and propose an alternative optimization (AO) based solution for the relaxed problem. Second, we apply Karush-Kuhn-Tucker (KKT) conditions to obtain a closed-form solutions for the beamforming and the phase shift. Using deep-unfolding mechanism, we transform the closed-form solutions into a deep learning model (i.e., DUNet) that achieves a comparable performance to that of AO in terms of accuracy and about 25.6 times faster.","['Reconfigurable intelligent surface (RIS)', 'beamforming', 'phase shift', 'secrecy rate', 'deep-unfolding.']",[]
"In order to fully harness the potential of machine learning, it is crucial to establish a system that renders the field more accessible and less daunting for individuals who may not possess a comprehensive understanding of its intricacies. The paper describes the design of a system that integrates AutoML, XAI, and synthetic data generation to provide a great UX design for users. The system allows users to navigate and harness the power of machine learning while abstracting its complexities and providing high usability. The paper proposes two novel classifiers, Logistic Regression Forest and Support Vector Tree, for enhanced model performance, achieving 96% accuracy on a diabetes dataset and 93% on a survey dataset. The paper also introduces a model-dependent local interpreter called MEDLEY and evaluates its interpretation against LIME, Greedy, and Parzen. Additionally, the paper introduces LLM-based synthetic data generation, library-based data generation, and enhancing the original dataset with GAN. The findings on synthetic data suggest that enhancing the original dataset with GAN is the most reliable way to generate synthetic data, as evidenced by KS tests, standard deviation, and feature importance. The authors also found that GAN works best for quantitative datasets.",[],[]
"Unlimited sampling was recently introduced to deal with the clipping or saturation of measurements where a modulo operator is applied before sampling. In this paper, we investigate the identifiability of the model where measurements are acquired under a discrete Fourier transform (DFT) sensing matrix first followed by a modulo operator (modulo-DFT). Firstly, based on the theorems of cyclotomic polynomials, we derive a sufficient condition for uniquely identifying the original signal in modulo-DFT. Additionally, for periodic bandlimited signals (PBSs) under unlimited sampling which can be viewed as a special case of modulo-DFT, the necessary and sufficient condition for the unique recovery of the original signal are provided. Moreover, we show that when the oversampling factor exceeds 3⁢(1+1/P)311𝑃3(1+1/P)3 ( 1 + 1 / italic_P ), PBS is always identifiable from the modulo samples, where P𝑃Pitalic_P is the number of harmonics including the fundamental component in the positive frequency part.","['Unlimited sampling', 'DFT sensing matrix', 'periodic bandlimited signal', 'identifiability']",[]
,[],[]
"In many causal studies, outcomes are ’censored by death,’ in the sense that they are neither observed nor defined for units who die. In such studies, the focus is usually on the stratum of ’always survivors’ up to a single fixed time s. Building on a recent strand of the literature, we propose an extended framework for the analysis of longitudinal studies, where units can die at different time points, and the main endpoints are observed and well-defined only up to the death time. We develop a Bayesian longitudinal principal stratification framework, where units are cross-classified according to the longitudinal death status. Under this framework, the focus is on causal effects for the principal strata of units that would be alive up to a time point s irrespective of their treatment assignment, where these strata may vary as a function of s. We can get precious insights into the effects of treatment by inspecting the distribution of baseline characteristics within each longitudinal principal stratum, and by investigating the time trend of both principal stratum membership and survivor-average causal effects. We illustrate our approach for the analysis of a longitudinal observational study aimed to assess, under the assumption of strong ignorability of treatment assignment, the causal effects of a policy promoting start-ups on firms’ survival and hiring policy, where firms’ hiring status is censored by death.",[],[]
"Research into the prediction and analysis of perceived audio quality is hampered by the scarcity of openly available datasets of audio signals accompanied by corresponding subjective quality scores.
To address this problem, we present the Open Dataset of Audio Quality (ODAQ), a new dataset containing the results of a MUSHRA listening test conducted with expert listeners from 2 international laboratories. ODAQ contains 240 audio samples and corresponding quality scores. Each audio sample is rated by 26 listeners.
The audio samples are stereo audio signals sampled at 44.1 or 48 kHz and are processed by a total of 6 method classes, each operating at different quality levels.
The processing method classes are designed to generate quality degradations possibly encountered during audio coding and source separation, and the quality levels for each method class span the entire quality range.
The diversity of the processing methods, the large span of quality levels, the high sampling frequency, and the pool of international listeners make ODAQ particularly suited for further research into subjective and objective audio quality.
The dataset is released with permissive licenses, and the software used to conduct the listening test is also made publicly available.",[],[]
"In this paper, we study the stability of traveling wave solutions arising from a credit rating migration problem with a free boundary, After some transformations, we turn the Free Boundary Problem into a fully nonlinear parabolic problem on a fixed domain and establish a rigorous stability analysis of the equilibrium in an exponentially weighted function space. It implies the convergence of the discounted value of bonds that stands as an attenuated traveling wave solution.",['Free boundary problems stability traveling waves fully nonlinear parabolic problems credit rating migration'],[]
We determine when the integral homology of the classifying space of a P⁢U⁢(n)𝑃𝑈𝑛PU(n)italic_P italic_U ( italic_n )-gauge group over the sphere S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT has torsion.,"['classifying space', 'torsion', 'cohomology', 'gauge group']",[]
"We present a framework to assist therapists and children with autism spectrum disorder in their Applied Behavioral Analysis (ABA) therapy. The framework was designed in collaboration with Spazio Autismo, an autism center in Mantova, Italy. The framework is a first step toward transitioning from the current paper-based to fully digital-supported therapy. We evaluated the framework over four months with 18 children diagnosed with classic autism, ranging from 4 to 7 years old. The framework integrates a mobile app that children and therapists use during the sessions with a backend for managing therapy workflow and monitoring progress. Our preliminary results show that the framework can improve the efficacy of the therapy sessions, reducing non-therapeutic time, increasing patient focus, and quickening the completion of the assigned objectives. It can also support therapists in preparing learning materials, data acquisition, and reporting. Finally, the framework demonstrated improved privacy and security of patients’ data while maintaining reliability.","['Autism', 'Applied', 'Behavioural', 'Analysis', 'Serious', 'Games', 'Gamification']",['Italy']
,[],[]
"Given an integer M≥2𝑀2M\geq 2italic_M ≥ 2, we deploy the generating function techniques to compute the number of M𝑀Mitalic_M-th roots of identity in some of the well-known finite groups of Lie type, more precisely for finite general linear groups, symplectic groups, orthogonal groups of all types and unitary groups over finite fields of odd characteristics.","['word maps', 'finite groups of', 'Lie type', 'M𝑀Mitalic_M-th root']",[]
"We numerically study the coarsening of topological defects in 2D polar active matter and make several interesting observations and predictions. (i) The long time state is characterized by nonzero density of defects, in stark contrast to theoretical expectations. (ii) The kinetics of defect coarsening shows power law decay to steady state, as opposed to exponential decay in thermal equilibrium. (iii) Observations (i) and (ii) together suggest emergent screening of topological charges due to activity. (iv) Nontrivial defect coarsening in the active model leads to nontrivial steady state patterns. We investigate, characterize, and validate these patterns and discuss their biological significance.",[],[]
"Neutron star contains a large number of nucleons and muons, if coupled with hidden ultralight particles, the orbit motion can produce sizable energy flux in addition to the binary’s gravitational quadrupole radiation. Here, we explore a scenario in which the scalar boson sourced by the binary is also coupled to the lowest dimensional photon operator, through which indirect electromagnetic radiation is generated beyond the scalar’s mass threshold. Using the observational data of two pulsar binaries, we place stringent constraints on the strength of such couplings.",[],[]
,[],[]
"We prove geometric upper bounds for the Poincaré and Logarithmic Sobolev constants for Brownian motion on manifolds with sticky reflecting boundary diffusion i.e. extended Wentzell-type boundary condition under general curvature assumptions on the manifold and its boundary. The method is based on an interpolation involving energy interactions between the boundary and the interior of the manifold. As side results we obtain explicit geometric bounds on the first nontrivial Steklov eigenvalue, for the norm of the boundary trace operator on Sobolev functions, and on the boundary trace logarithmic Sobolev constant. The case of Brownian motion with pure sticky reflection is also treated.",[],[]
"We propose and analyze a unified structure-preserving parametric finite element method (SP-PFEM) for the anisotropic surface diffusion of curves in two dimensions (d=2)𝑑2(d=2)( italic_d = 2 ) and surfaces in three dimensions (d=3)𝑑3(d=3)( italic_d = 3 ) with an arbitrary anisotropic surface energy density γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), where 𝒏∈𝕊d−1𝒏superscript𝕊𝑑1\boldsymbol{n}\in\mathbb{S}^{d-1}bold_italic_n ∈ blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT represents the outward unit vector. By introducing a novel unified surface energy matrix 𝑮k⁢(𝒏)subscript𝑮𝑘𝒏\boldsymbol{G}_{k}(\boldsymbol{n})bold_italic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_n ) depending
on γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), the Cahn–Hoffman 𝝃𝝃\boldsymbol{\xi}bold_italic_ξ-vector and
a stabilizing function k⁢(𝒏):𝕊d−1→ℝ:𝑘𝒏→superscript𝕊𝑑1ℝk(\boldsymbol{n}):\ \mathbb{S}^{d-1}\to{\mathbb{R}}italic_k ( bold_italic_n ) : blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT → blackboard_R, we obtain a
unified and conservative variational formulation for the anisotropic surface diffusion via
different surface differential operators including the surface gradient operator, the surface divergence operator
and the surface Laplace–Beltrami operator. A SP-PFEM discretization is presented for the variational
problem. In order to establish the unconditional energy stability of the proposed SP-PFEM under
a very mild condition on γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), we propose
a new framework via local energy estimate for proving energy stability/structure-preserving
properties of the parametric finite element method for the anisotropic surface diffusion. This framework
sheds light on how to prove unconditional energy stability of other numerical methods
for geometric partial differential equations.
Extensive numerical results are reported to demonstrate the efficiency and accuracy as well
as structure-preserving properties of the proposed SP-PFEM for the anisotropic surface diffusion
with arbitrary anisotropic surface energy density γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ) arising from different applications.",['anisotropic surface diffusion anisotropic surface energy density parametric finite element method structure-preserving unconditional energy stability'],[]
,[],[]
,[],[]
,[],[]
"Transportation has greatly benefited the cities’ development in the modern civilization process. Intelligent transportation, leveraging advanced computer algorithms, could further increase people’s daily commuting efficiency. However, intelligent transportation, as a cross-discipline, often requires practitioners to comprehend complicated algorithms and obscure neural networks, bringing a challenge for the advanced techniques to be trusted and deployed in practical industries. Recognizing the expressiveness of the pre-trained large language models, especially the potential of being augmented with abilities to understand and execute intricate commands, we introduce Open-TI. Serving as a bridge to mitigate the industry-academic gap, Open-TI is an innovative model targeting the goal of Turing Indistinguishable Traffic Intelligence, it is augmented with the capability to harness external traffic analysis packages based on existing conversations. Marking its distinction, Open-TI is the first method capable of conducting exhaustive traffic analysis from scratch - spanning from map data acquisition to the eventual execution in complex simulations. Besides, Open-TI is able to conduct task-specific embodiment like training and adapting the traffic signal control policies (TSC), explore demand optimizations, etc. Furthermore, we explored the viability of LLMs directly serving as control agents, by understanding the expected intentions from Open-TI, we designed an agent-to-agent communication mode to support Open-TI conveying messages to ChatZero (control agent), and then the control agent would choose from the action space to proceed the execution. We eventually provide the formal implementation structure, and the open-ended design invites further community-driven enhancements.",[],[]
"The networked nature of multi-robot systems presents challenges in the context of multi-agent reinforcement learning.
Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots,
exhibiting poor performance in cooperative-competitive tasks. In this work we propose a physics-informed reinforcement learning approach able to learn distributed multi-robot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions.
Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor-critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multi-robot scenarios demonstrate the success of the proposed approach, surpassing previous multi-robot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to ×2absent2\times 2× 2 greater than the state-of-the-art with robot teams ×6absent6\times 6× 6 larger than the number of robots at training time).","['Cooperative control', 'distributed systems', 'multi-robot systems', 'physics-informed neural networks', 'reinforcement learning.']",[]
"In the present work we revisit the problem
of the quantum droplet in atomic Bose-Einstein
condensates with an eye towards describing
its ground state in the large density, so-called
Thomas-Fermi limit. We consider the problem
as being separable into 3 distinct regions:
an inner one, where the Thomas-Fermi approximation
is valid, a sharp transition region where the
density abruptly drops towards the (vanishing)
background value and an outer region which
asymptotes to the background value.
We analyze the spatial extent of each of these
regions, and develop a systematic effective
description of the rapid intermediate transition
region. Accordingly, we derive a uniformly
valid description of the ground state that
is found to very accurately match our
numerical computations. As an additional application
of our considerations, we show that this formulations
allows for an analytical approximation of excited
states such as the (trapped) dark soliton in the large density
limit.",[],[]
"Understanding the evolution of cooperation is pivotal in biology and social science. Public resources sharing is a common scenario in the real world. In our study, we explore the evolutionary dynamics of cooperation on a regular graph with degree k𝑘kitalic_k, introducing the presence of a third strategy, namely the benevolence, who does not evolve over time, but provides a fixed benefit to all its neighbors. We find that the presence of the benevolence can foster the development of cooperative behavior and it follows a simple rule: b/c>k−pS⁢(k−1)𝑏𝑐𝑘subscript𝑝𝑆𝑘1b/c>k-p_{S}(k-1)italic_b / italic_c > italic_k - italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_k - 1 ). Our results provide new insights into the evolution of cooperation in structured populations.",[],[]
"Let p𝑝pitalic_p and q𝑞qitalic_q be two distinct odd primes, p<q𝑝𝑞p<qitalic_p < italic_q and Ep,q:y2=x3−p⁢q⁢x:subscript𝐸𝑝𝑞superscript𝑦2superscript𝑥3𝑝𝑞𝑥E_{p,q}:y^{2}=x^{3}-pqxitalic_E start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_x start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT - italic_p italic_q italic_x be an elliptic curve. Fix a line La.b:y=ab⁢x:subscript𝐿formulae-sequence𝑎𝑏𝑦𝑎𝑏𝑥L_{a.b}:y=\frac{a}{b}xitalic_L start_POSTSUBSCRIPT italic_a . italic_b end_POSTSUBSCRIPT : italic_y = divide start_ARG italic_a end_ARG start_ARG italic_b end_ARG italic_x where a∈ℤ,b∈ℕformulae-sequence𝑎ℤ𝑏ℕa\in\mathbb{Z},b\in\mathbb{N}italic_a ∈ blackboard_Z , italic_b ∈ blackboard_N and (a,b)=1𝑎𝑏1(a,b)=1( italic_a , italic_b ) = 1. We study sufficient conditions that p𝑝pitalic_p and q𝑞qitalic_q must satisfy so that there are infinitely many elliptic curves Ep,qsubscript𝐸𝑝𝑞E_{p,q}italic_E start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT that intersect La,bsubscript𝐿𝑎𝑏L_{a,b}italic_L start_POSTSUBSCRIPT italic_a , italic_b end_POSTSUBSCRIPT.","['Elliptic', 'Curves', 'Rational', 'Points']",[]
"With Wilson quarks, on-shell O(a𝑎aitalic_a) improvement of the lattice QCD action is achieved by including
the Sheikholeslami-Wohlert term and two further operators of mass dimension 5,
which amount to a mass-dependent rescaling of the bare parameters. We here focus on the rescaled bare coupling,
g~02=g02⁢(1+bg⁢a⁢mq)superscriptsubscript~𝑔02superscriptsubscript𝑔021subscript𝑏g𝑎subscript𝑚q{\tilde{g}_{0}^{2}}=g_{0}^{2}(1+b_{\rm g}am_{\rm q})over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 1 + italic_b start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT italic_a italic_m start_POSTSUBSCRIPT roman_q end_POSTSUBSCRIPT ), and the determination of bg⁢(g02)subscript𝑏gsuperscriptsubscript𝑔02b_{\rm g}(g_{0}^{2})italic_b start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT ( italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), which is currently only known
to 1-loop order of perturbation theory. We derive suitable improvement conditions in the chiral limit and
in a finite space-time volume and evaluate these for different pure gauge observables, both with and without the gradient flow.
The choice of β𝛽\betaitalic_β-values and the line of constant physics are motivated by the ALPHA collaboration’s
decoupling strategy to determine αs⁢(mZ)subscript𝛼𝑠subscript𝑚𝑍\alpha_{s}(m_{Z})italic_α start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPT ) [1]. However,
the improvement conditions and some insight into systematic effects may prove useful in other contexts, too.",[],[]
"The problem of packing a set of circles into the smallest surrounding container is considered. This problem arises in different application areas such as automobile, textile, food, and chemical industries. The so-called circle packing problem can be cast as a nonconvex quadratically constrained program, and is difficult to solve in general. An iterative solution approach based on a bisection-type algorithm on the radius of the larger circle is provided. The present algorithm discretizes the container into small cells and solves two different integer linear programming formulations proposed for a restricted and a relaxed version of the original problem. The present algorithm is enhanced with solution space reduction, bound tightening and variable elimination techniques. Then, a computational study is performed to evaluate the performance of the algorithm. The present algorithm is compared with BARON and Gurobi that solve the original nonlinear formulation and heuristic methods from literature, and obtain promising results.",[],[]
"We show that, contrary to the claim by Kumar [Phys. Rev. A 96, 012332 (2017)], the quantum dual total correlation of an n𝑛nitalic_n-partite quantum state cannot be represented as the quantum relative entropy between n−1𝑛1n-1italic_n - 1 copies of the quantum state and the product of n𝑛nitalic_n different reduced quantum states for n≥3𝑛3n\geq 3italic_n ≥ 3. Specifically, we argue that the latter fails to yield a finite value for generalized n𝑛nitalic_n-partite Greenberger-Horne-Zeilinger states.",[],[]
"This paper proposes an alternative regularization method for handling the ultraviolet behavior of entanglement entropy. Utilizing an i⁢ϵ𝑖italic-ϵi\epsilonitalic_i italic_ϵ prescription in the Euclidean double cone geometry, it accurately reproduces the universal behavior of entanglement entropy. The method is demonstrated in the free boson theory in arbitrary dimensions and two-dimensional conformal field theories.
The findings highlight the effectiveness of the i⁢ϵ𝑖italic-ϵi\epsilonitalic_i italic_ϵ regularization method in addressing ultraviolet issues in quantum field theory and gravity, suggesting potential applications to other calculable quantities.",[],[]
"Atacama Large Millimeter/Submillimeter Array (ALMA) has revolutionized the field of dust polarization in protoplanetary disks across multiple wavelengths. Previous observations and empirical modeling suggested multiple mechanisms of dust polarization toward HL Tau, including grain alignment and dust scattering. However, a detailed modeling of dust polarization based on grain alignment physics is not yet available. Here, using our updated POLARIS code, we perform numerical modeling of dust polarization arising from both grain alignment by Magnetically Enhanced Radiative Torque (MRAT) mechanism and self-scattering to reproduce the HL Tau polarization observed at three wavelengths 0.87, 1.3, and 3.1 mm. Our modeling results show that the observed multi-wavelength polarization could be reproduced only when large grains contain embedded iron inclusions and those with slow internal relaxation must have wrong internal alignment (i.e., the grain’s major axis parallel to its angular momentum). The abundance of iron embedded inside grains in the form of clusters is constrained to be ≳16greater-than-or-equivalent-toabsent16\gtrsim 16≳ 16%, and the number of iron atoms per cluster is Ncl∼2×103similar-tosubscript𝑁cl2superscript103N_{\rm cl}\sim 2\times 10^{3}italic_N start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ∼ 2 × 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Maximum grain sizes probed at wavelengths λ𝜆\lambdaitalic_λ = 0.87, 1.3, and 3.1 mm are constrained at ∼similar-to\sim∼ 60, 90, and 130μ𝜇\,\muitalic_μm, respectively. Assuming a dust differential settling effect with grain sizes from the constraint gives the value of maximum grain size at the disk mid-plane to be millimeter-scaled.","['Protoplanetary disks', 'Polarimetry', 'Radio astronomy', 'Circumstellar dust', 'Magnetic field']",['Germany']
"Patient-to-room assignment (PRA) is a scheduling problem in decision support for large hospitals. This work proposes Integer Programming (IP) formulations for dynamic PRA, where either full, limited or uncertain information on incoming patients is available. The applicability is verified through a computational study. Results indicate that large, real world instances can be solved to a high degree of optimality within (fractions of) seconds. Furthermore, different objectives are considered to ensure validity across varying practical requirements. So far, previous approaches for IP in PRA have only been applicable for small instances or special cases. Subsequently, we show that the modelling of gender conflicts and transfers are crucial modelling choices that determine whether the corresponding IPs are solvable in reasonable time.",[],[]
"A muonium consists of a positive muon associated with an orbital electron, and the spontaneous conversion to antimuonium serves as a clear indication of new physics beyond the Standard Model in particle physics.
One of the most important aspects in muonium-to-antimuonium conversion experiment (MACE) is to increase the muonium yield in vacuum to challenge the latest limit obtained in 1999.
This study focuses on a simulation of the muonium formation and diffusion in the perforated silica aerogel.
The independent simulation results can be well validated by experimental data.
By optimizing the target geometry, we find a maximum muonium emission efficiency of 7.92⁢(2)%7.92percent27.92(2)\%7.92 ( 2 ) % and a maximum vacuum yield of 1.134⁢(2)%1.134percent21.134(2)\%1.134 ( 2 ) % with a typical surface muon beam, indicating a 2.6 times and a 2.1 times enhancement, respectively.
Our results will pave the way for muonium experiments.",[],['China']
"With a motive of ubiquitous connectivity over the globe with enhanced spectral efficiency, intelligent reflecting surfaces (IRS) integrated satellite-terrestrial communications is a topic of research interest in an infrastructure-deficient remote terrains. In line with this vision, this paper entails the performance analysis of satellite-terrestrial networks leveraging both aerial and terrestrial IRS nodes, with the support of high altitude platforms over diverse fading channels including shadowed Rician, Rician, and Nakagami-m𝑚mitalic_m fading channels. The merits of IRS in enhancing spectral efficiency is analyzed through closed-form expressions of outage probability and ergodic rate. Further, the average symbol error rate analysis for the higher-order quadrature amplitude modulation (QAM) schemes such as hexagonal QAM, rectangular QAM, cross QAM, and square QAM is performed. Practical constraints like antenna gains, path loss, and link fading are considered to characterize the satellite terrestrial links. Finally, a comparison between the high-altitude platforms based IRS node and terrestrial IRS nodes is performed and various insights are drawn under various fading scenarios and path loss conditions. This paper contribute towards understanding and potential implementation of IRS-integrated satellite-terrestrial networks for efficient and reliable communication.","['IRS', 'HAP', 'Nakagami-m𝑚mitalic_m', 'Rician', 'shadowed', 'Rician', 'ergodic rate', 'HQAM', 'RQAM', 'XQAM.']",[]
"We investigate edge and bulk states in Weyl-orbit based quantum Hall effect by measuring a Corbino-type device fabricated from a topological Dirac semimetal (Cd1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPTZnx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTAs22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT film.
Clear quantum Hall plateaus are observed when measuring one-sided terminals of the Corbino-type device.
This indicates that edge states of the Weyl-orbit quantum Hall effect form closed trajectories consisting of Fermi arcs and chiral zero modes independently on inner and outer sides.
On the other hand, the bulk resistance does not diverge at fields where the quantum Hall plateau appears, suggesting that the Weyl orbits in the bulk region are not completely localized when applying electric current through the bulk region.",[],['Japan']
,[],[]
"The intrinsic resolution is the primary limitation on the total energy resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal. This intrinsic resolution arises from two effects: fluctuations occurring in the process of energy transfer to luminescent centers within the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal and the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal’s non-proportional luminescence. Presently, experimental measurements regarding the intrinsic resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal are scarce, and the underlying physical mechanisms remain incompletely understood. In this paper, we aim to elucidate the concept of intrinsic resolution. We investigated the entire physical process of luminescence following energy deposition in the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal, quantifying the various components in the total energy resolution. We conducted a series of experimental measurements and Geant4 simulations, determining the intrinsic resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal to 100 keV electrons as 2.12%. The non-proportionality contributes significantly at 1.43%, while fluctuations in the energy transfer process accounted for 0.27%. It is evident that non-proportionality in light output constitutes the primary source of intrinsic resolution. Horizontal and vertical unevenness in light collection contributed 0.25% and 0.07%, respectively. Statistical fluctuations showed the largest impact on the total energy resolution, at 2.86%. The contribution from fluctuations in single-photoelectron events was 0.77%. Furthermore, we reconstructed the photon response using Geant4, and the consistency between the simulated relative light yield and the experimentally measured one confirmed the reliability of the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) detector mass model employed in the simulation.","['LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) detector', 'Energy', 'Response', 'Intrinsic', 'Resolution', 'Non-proportional', 'Light', 'Yield', 'Energy', 'Transfer', 'Process']",['China']
,[],[]
"This paper presents a parallel-in-time multilevel iterative method for solving differential algebraic equation, arising from a discretization of linear time-dependent partial differential equation. The core of the method is the multilevel Krylov method, introduced by Erlangga and Nabben [SIAM J. Sci. Comput., 30(2008), pp. 1572–1595]. In the method, special time restriction and interpolation operators are proposed to coarsen the time grid and to map functions between fine and coarse time grids. The resulting Galerkin coarse-grid system can be interpreted as time integration of an equivalent differential algebraic equation associated with a larger time step and a modified θ𝜃\thetaitalic_θ-scheme. A perturbed coarse time-grid matrix is used on the coarsest level to decouple the coarsest-level system, allowing full parallelization of the method. Within this framework, spatial coarsening can be included in a natural way, reducing further the size of the coarsest grid problem to solve. Numerical results are presented for the 1- and 2-dimensional heat equation using simulated parallel implementation, suggesting the potential computational speed-up of up to 9 relative to the single-processor implementation and the speed-up of about 3 compared to the sequential θ𝜃\thetaitalic_θ-scheme.",[],[]
"Thermal leptogenesis is a mechanism that explains the observed asymmetry between matter and antimatter in the early universe. In this study, we review the impact of nonextensive Tsallis statistical mechanics on the early universe and study its effect on thermal leptogenesis. The study has found that the use of nonextensive statistical mechanics can affect the production of baryon asymmetry in thermal leptogenesis by modifying the equilibrium abundance of particles, decay, and washout parameters. Also, we show that nonextensive statistical mechanics potentially reduce the required right-handed neutrino mass scale.",[],[]
"In the domain of multivariate forecasting, transformer models stand out as powerful apparatus, displaying exceptional capabilities in handling messy datasets from real-world contexts. However, the inherent complexity of these datasets, characterized by numerous variables and lengthy temporal sequences, poses challenges, including increased noise and extended model runtime. This paper focuses on reducing redundant information to elevate forecasting accuracy while optimizing runtime efficiency. We propose a novel transformer forecasting framework enhanced by Principal Component Analysis (PCA) to tackle this challenge. The framework is evaluated by five state-of-the-art (SOTA) models and four diverse real-world datasets. Our experimental results demonstrate the framework’s ability to minimize prediction errors across all models and datasets while significantly reducing runtime. From the model perspective, one of the PCA-enhanced models: PCA+Crossformer, reduces mean square errors (MSE) by 33.3% and decreases runtime by 49.2% on average. From the dataset perspective, the framework delivers 14.3% MSE and 76.6% runtime reduction on Electricity datasets, as well as 4.8% MSE and 86.9% runtime reduction on Traffic datasets. This study aims to advance various SOTA models and enhance transformer-based time series forecasting for intricate data.",[],[]
"Comets would have amorphous ice rather than crystalline one at the epoch of their accretion.
Cometary ice contains some impurities that govern the latent heat of ice crystallization, Lcrysubscript𝐿cryL_{\rm cry}italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT.
However, it is still controversial whether the crystallization process is exothermic or endothermic.
In this study, we perform one-dimensional simulations of the thermal evolution of km-sized comets and investigate the effect of the latent heat.
We find that the depth where amorphous ice can survive significantly depends on the latent heat of ice crystallization.
Assuming the cometary radius of 2⁢km2km2~{}$\mathrm{k}\mathrm{m}$2 roman_km, the depth of the amorphous ice mantle is approximately 100⁢m100m100~{}$\mathrm{m}$100 roman_m when the latent heat is positive (i.e., the exothermic case with Lcry=+9×104⁢J⁢kg−1subscript𝐿cry9superscript104Jsuperscriptkg1L_{\rm cry}=+9\times 10^{4}~{}$\mathrm{J}\,\mathrm{k}\mathrm{g}^{-1}$italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT = + 9 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT roman_J roman_kg start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT).
In contrast, when we consider the impure ice representing the endothermic case with Lcry=−9×104⁢J⁢kg−1subscript𝐿cry9superscript104Jsuperscriptkg1L_{\rm cry}=-9\times 10^{4}~{}$\mathrm{J}\,\mathrm{k}\mathrm{g}^{-1}$italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT = - 9 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT roman_J roman_kg start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, the depth of the amorphous ice mantle could exceed 1⁢km1km1~{}$\mathrm{k}\mathrm{m}$1 roman_km.
Although our numerical results indicate that these depths depend on the size and the accretion age of comets, the depth in a comet with the negative latent heat is a few to several times larger than the positive case for a given comet size.
This work suggests that the spatial distribution of the ice crystallinity in a comet nucleus depends on the latent heat, which can be different from the previous estimates assuming pure water ice.",[],[]
"Low-dose \acET plays a crucial role in medical imaging, enabling the acquisition of functional information for various biological processes while minimizing the patient dose. However, the inherent randomness in the photon counting process is a source of noise which is amplified low-dose \acET. This review article provides an overview of existing post-processing techniques, with an emphasis on deep \acNN approaches. Furthermore, we explore future directions in the field of \acNN-based low-dose \acET. This comprehensive examination sheds light on the potential of deep learning in enhancing the quality and resolution of low-dose \acET images, ultimately advancing the field of medical imaging.","['Low-Dose', 'PET', 'SPECT', 'Deep', 'Learning']",[]
"A conducting cylinder with a central source of electrons, in a uniform magnetic field along its axis,
and radial temperature gradient, is considered at the stationary state.
Interaction of heat flux, magnetic field and charge distribution is discussed.
Four different models are considered, regarding of the electronic supply and possibility of electrons to leave the cylinder.",[],[]
"We describe an experiment to measure the electromagnetic analog of gravitational wave memory, the so-called electromagnetic memory. Whereas gravitational wave memory is a residual displacement of test masses, electromagnetic memory is a residual velocity (i.e. kick) of test charges.
The source of gravitational wave memory is energy that is not confined to any bounded spatial region: in the case of binary black hole mergers the emitted energy of gravitational radiation as well as the recoil energy of the final black hole. Similarly, electromagnetic memory requires a source whose charges are not confined to any bounded spatial region.
While particle beams can provide unbounded charges, their currents are too small to be practical for such an experiment. Instead we propose a short microwave pulse applied to the center of a long dipole antenna. In this way the measurement of the kick can be done quickly enough that the finite size of the antenna does not come into play and it acts for our purposes the same as if it were an infinite antenna.",[],[]
"We derive new estimates on analytic capacities of finite sequences
in the unit disc in Besov spaces with zero smoothness, which
sharpen the estimates obtained by N. K. Nikolski in 2005
and, for a range of parameters, are optimal.
The work is motivated both from the perspective of complex analysis by the description of sets of
zeros/uniqueness, and from the one of matrix analysis/operator theory
by estimates on norms of inverses.",[],[]
,[],[]
"Wind turbines are subjected to continuous rotational stresses and unusual external forces such as storms, lightning, strikes by flying objects, etc., which may cause defects in turbine blades. Hence, it requires a periodical inspection to ensure proper functionality and avoid catastrophic failure. The task of inspection is challenging due to the remote location and inconvenient reachability by human inspection. Researchers used images with cropped defects from the wind turbine in the literature. They neglected possible background biases, which may hinder real-time and autonomous defect detection using aerial vehicles such as drones or others. To overcome such challenges, in this paper, we experiment with defect detection accuracy by having the defects with the background using a two-step deep-learning methodology. In the first step, we develop virtual models of wind turbines to synthesize the near-reality images for four types of common defects - cracks, leading edge erosion, bending, and light striking damage. The Unity® perception package is used to generate wind turbine blade defects images with variations in background, randomness, camera angle, and light effects. In the second step, a customized U-Net architecture is trained to classify and segment the defect in turbine blades. The outcomes of U-Net architecture have been thoroughly tested and compared with 5-fold validation datasets. The proposed methodology provides reasonable defect detection accuracy, making it suitable for autonomous and remote inspection through aerial vehicles.
Keywords Defect Detection, Virtual Reality, Deep Learning, U-Net, Segmentation",[],['Bangladesh']
"In this short paper, we examine the main metrics used to evaluate textual coreference and we detail some of their limitations. We show that a unique score cannot represent the full complexity of the problem at stake, and is thus uninformative, or even misleading. We propose a new way of evaluating coreference, taking into account the context (in our case, the analysis of fictions, esp. novels). More specifically, we propose to distinguish long coreference chains (corresponding to main characters), from short ones (corresponding to secondary characters), and singletons (isolated elements). This way, we hope to get more interpretable and thus more informative results through evaluation.",[],[]
"Exploring the physics of low-dimensional spin systems and their pressure-driven electronic and magnetic transitions are thriving research field in modern condensed matter physics. In this context, recently antiferromagnetic Cr-based compounds such as CrI33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, CrBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, CrGeTe33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT have been investigated experimentally and theoretically for their possible spintronics applications. Motivated by the fundamental and industrial importance of these materials, we theoretically studied the electronic and magnetic properties of a relatively less explored Cr-based chalcogenide, namely LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT where 2D layers of magnetic Cr3+limit-from3{}^{3+}start_FLOATSUPERSCRIPT 3 + end_FLOATSUPERSCRIPT ions form a rectangular lattice. We employed density functional theory + Hubbard U𝑈Uitalic_U approach in conjunction with constrained random-phase approximation (cRPA) where the later was used to estimate the strength of U𝑈Uitalic_U. Our findings at ambient pressure show that the system exhibits semiconducting antiferromagnetic ground state with a gap of 0.5 eV and large Cr moments that corresponds to nominal S=3/2 spin-state. The 1st nearest neighbor (NN) interatomic exchange coupling (J11{}_{1}start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT) is found to be strongly antiferromagnetic (AFM), while 2nd NN couplings are relatively weaker ferromagnetic (FM), making this system a candidate for 1D non-frustrated antiferromagnetic spin-chain family of materials. Based on orbital resolved interactions, we demonstrated the reason behind two different types of interactions among 1st and 2nd NN despite their very similar bond lengths. We observe a significant spin-orbit coupling effect, giving rise to a finite magneto crystalline anisotropy, and Dzyaloshinskii-Moriya (DM) interaction. Further, we found that by applying uniaxial tensile strain along crystallographic a𝑎aitalic_a and b𝑏bitalic_b-axis, LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT exhibits a magnetic transition to a semi-conducting FM ground state, while compression gives rise to the realization of novel gapless semiconducting antiferromagnetic ground state. Thus, our findings can enrich the versatility of LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT and make it a promising candidate for industrial applications.",[],['India']
"We revisit the study of the violation of the Leggett-Garg inequality in neutrino oscillation data as a mean to test some of the fundamental aspects of quantum mechanics. In particular, we consider the results by the Daya Bay and RENO reactor experiments, and the MINOS and NOvA accelerator experiments. We find that DB and MINOS exhibit a strong manifestation of Leggett-Garg violation, while for RENO and NOvA data the indication is weaker. Considering the particular baselines and energy ranges explored by each experiment, our results demonstrate that the Leggett-Garg violation is more evident for smaller baseline-to-energy ratio in all the data sets considered, a relevant aspect to be considered when searching for evidences of quantum mechanical decoherence on neutrino oscillations.",[],['Colombia']
,[],[]
"Direct imaging of Earth-like exoplanets is one of the most prominent scientific drivers of the next generation of ground-based telescopes. Typically, Earth-like exoplanets are located at small angular separations from their host stars, making their detection difficult. Consequently, the adaptive optics (AO) system’s control algorithm must be carefully designed to distinguish the exoplanet from the residual light produced by the host star.
A new promising avenue of research to improve AO control builds on data-driven control methods such as Reinforcement Learning (RL). RL is an active branch of the machine learning research field, where control of a system is learned through interaction with the environment. Thus, RL can be seen as an automated approach to AO control, where its usage is entirely a turnkey operation. In particular, model-based reinforcement learning (MBRL) has been shown to cope with both temporal and misregistration errors. Similarly, it has been demonstrated to adapt to non-linear wavefront sensing while being efficient in training and execution.
In this work, we implement and adapt an RL method called Policy Optimization for AO (PO4AO) to the GHOST test bench at ESO headquarters, where we demonstrate a strong performance of the method in a laboratory environment. Our implementation allows the training to be performed parallel to inference, which is crucial for on-sky operation. In particular, we study the predictive and self-calibrating aspects of the method. The new implementation on GHOST running PyTorch introduces only around 700 µs of in addition to hardware, pipeline, and Python interface latency. We open-source well-documented code for the implementation and specify the requirements for the RTC pipeline. We also discuss the important hyperparameters of the method and how they affect the method. Further, the paper discusses the source of the latency and the possible paths for a lower latency implementation.",[],"['Germany', 'Finland', 'Switzerland', 'France']"
"Reinforcement learning from human feedback (RLHF) emerges as a promising paradigm for aligning large language models (LLMs).
However, a notable challenge in RLHF is overoptimization, where beyond a certain threshold, the pursuit of higher rewards leads to a decline in human preferences.
In this paper, we observe the weakness of KL regularization which is commonly employed in existing RLHF methods to address overoptimization.
To mitigate this limitation, we scrutinize the RLHF objective in the offline dataset and propose uncertainty-penalized RLHF (UP-RLHF), which incorporates uncertainty regularization during RL-finetuning.
To enhance the uncertainty quantification abilities for reward models, we first propose a diverse low-rank adaptation (LoRA) ensemble by maximizing the nuclear norm of LoRA matrix concatenations.
Then we optimize policy models utilizing penalized rewards, determined by both rewards and uncertainties provided by the diverse reward LoRA ensembles.
Our experimental results, based on two real human preference datasets, showcase the effectiveness of diverse reward LoRA ensembles in quantifying reward uncertainty.
Additionally, uncertainty regularization in UP-RLHF proves to be pivotal in mitigating overoptimization, thereby contributing to the overall performance.","['Machine', 'Learning', 'ICML']",[]
,[],[]
"Many statistical problems require estimating a density function, say f𝑓fitalic_f, from data samples. In this work, for example, we are interested in highest-density regions (HDRs), i.e., minimum volume sets that contain a given probability. HDRs are typically computed using a density quantile approach, which, in the case of unknown densities, involves their estimation. This task turns out to be far from trivial, especially over increased dimensions and when data are sparse and exhibit complex structures (e.g., multimodalities or particular dependencies).
We address this challenge by exploring alternative approaches to build HDRs that overcome direct (multivariate) density estimation. First, we generalize the density quantile method–currently implementable on the basis of a consistent estimator of the density–to neighbourhood measures, i.e., measures that preserve the order induced in the sample by f𝑓fitalic_f. Second, we discuss a number of suitable probabilistic- and distance-based measures such as the k𝑘kitalic_k-nearest neighbourhood Euclidean distance. Third, motivated by the ubiquitous role of copula modeling in modern statistics, we explore its use in the context of probabilistic-based measures. An extensive comparison among the introduced measures is provided, and their implications for computing HDRs in real-world problems are discussed.",[],[]
"Large language models (LLMs) have made significant advancements in natural language processing and are concurrently extending the language ability to other modalities, such as speech and vision. Nevertheless, most of the previous work focuses on prompting LLMs with perception abilities like auditory comprehension, and the effective approach for augmenting LLMs with speech synthesis capabilities remains ambiguous. In this paper, we conduct a comprehensive empirical exploration of boosting LLMs with the ability to generate speech, by combining pre-trained LLM LLaMA/OPT and text-to-speech synthesis model VALL-E. We compare three integration methods between LLMs and speech synthesis models, including directly fine-tuned LLMs, superposed layers of LLMs and VALL-E, and coupled LLMs and VALL-E using LLMs as a powerful text encoder. Experimental results show that, using LoRA method to fine-tune LLMs directly to boost the speech synthesis capability does not work well, and superposed LLMs and VALL-E can improve the quality of generated speech both in speaker similarity and word error rate (WER). Among these three methods, coupled methods leveraging LLMs as the text encoder can achieve the best performance, making it outperform original speech synthesis models with a consistently better speaker similarity and a significant (10.9%) WER reduction.",[],[]
"Numerical simulations can model the physical processes that govern cardiovascular device deployment. When such simulations incorporate digital twins; computational models of patient-specific anatomy, they can expedite and de-risk the device design process. Nonetheless, the exclusive use of patient-specific data constrains the anatomic variability which can be precisely or fully explored. In this study, we investigate the capacity of Latent Diffusion Models (LDMs) to edit digital twins to create anatomic variants, which we term digital siblings. Digital twins and their corresponding siblings can serve as the basis for comparative simulations, enabling the study of how subtle anatomic variations impact the simulated deployment of cardiovascular devices, as well as the augmentation of virtual cohorts for device assessment. However, while diffusion models have been characterized in their ability to edit natural images, their capacity to anatomically edit digital twins has yet to be studied. Using a case example centered on 3D digital twins of cardiac anatomy, we implement various methods for generating digital siblings and characterize them through morphological and topological analyses. We specifically edit digital twins to introduce anatomic variation at different spatial scales and within localized regions, demonstrating the existence of bias towards common anatomic features. We further show that such anatomic bias can be leveraged for virtual cohort augmentation through selective editing, partially alleviating issues related to dataset imbalance and lack of diversity. Our experimental framework thus delineates the limits and capabilities of using latent diffusion models in synthesizing anatomic variation for in silico trials.",[],[]
"Segmenting any object represents a crucial step towards achieving artificial general intelligence, and the ”Segment Anything Model” (SAM) has significantly advanced the development of foundational models in computer vision. We have high expectations regarding whether SAM can enhance highly accurate dichotomous image segmentation. In fact, the evidence presented in this article demonstrates that by inputting SAM with simple prompt boxes and utilizing the results output by SAM as input for IS5Net, we can greatly improve the effectiveness of highly accurate dichotomous image segmentation.","['Segment', 'Anything', 'Model', 'SAM', 'highly accurate dichotomous image segmentation', 'DIS.']",[]
"Forecasting a key macroeconomic variable, consumer price index (CPI) inflation, for BRIC countries using economic policy uncertainty and geopolitical risk is a difficult proposition for policymakers at the central banks. This study proposes a novel filtered ensemble wavelet neural network (FEWNet) that can produce reliable long-term forecasts for CPI inflation. The proposal applies a maximum overlapping discrete wavelet transform to the CPI inflation series to obtain high-frequency and low-frequency signals. All the wavelet-transformed series and filtered exogenous variables are fed into downstream autoregressive neural networks to make the final ensemble forecast. Theoretically, we show that FEWNet reduces the empirical risk compared to single, fully connected neural networks. We also demonstrate that the rolling-window real-time forecasts obtained from the proposed algorithm are significantly more accurate than benchmark forecasting methods. Additionally, we use conformal prediction intervals to quantify the uncertainty associated with the forecasts generated by the proposed approach.
The excellent performance of FEWNet can be attributed to its capacity to effectively capture non-linearities and long-range dependencies in the data through its adaptable architecture.",[],[]
"For the first time, we estimate the in-medium mass shift of
the two-flavored heavy mesons Bc,Bc*,Bs,Bs*,Dssubscript𝐵𝑐superscriptsubscript𝐵𝑐subscript𝐵𝑠superscriptsubscript𝐵𝑠subscript𝐷𝑠B_{c},B_{c}^{*},B_{s},B_{s}^{*},D_{s}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT , italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT and Ds*superscriptsubscript𝐷𝑠D_{s}^{*}italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT in symmetric nuclear
matter. The estimates are made by evaluating the lowest order one-loop self-energies.
The enhanced excitations of intermediate state
heavy-light mesons in symmetric nuclear matter are the origin of their negative mass shift.
Our results show that the magnitude of the mass shift for the Bcsubscript𝐵𝑐B_{c}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT meson (b¯⁢c¯𝑏𝑐\bar{b}cover¯ start_ARG italic_b end_ARG italic_c or b⁢c¯𝑏¯𝑐b\bar{c}italic_b over¯ start_ARG italic_c end_ARG)
is larger than
those of the ηc⁢(c¯⁢c)subscript𝜂𝑐¯𝑐𝑐\eta_{c}(\bar{c}c)italic_η start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( over¯ start_ARG italic_c end_ARG italic_c ) and ηb⁢(b¯⁢b)subscript𝜂𝑏¯𝑏𝑏\eta_{b}(\bar{b}b)italic_η start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ( over¯ start_ARG italic_b end_ARG italic_b ),
different from a naive expectation that it would
be in-between of them.
While, that of the Bc*superscriptsubscript𝐵𝑐B_{c}^{*}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT shows the in-between of the J/ψ𝐽𝜓J/\psiitalic_J / italic_ψ and ΥΥ\Upsilonroman_Υ.
We observe that the lighter vector meson excitation
in each meson self-energy gives a dominant contribution for the corresponding meson mass shift,
Bc,Bs,subscript𝐵𝑐subscript𝐵𝑠B_{c},B_{s},italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , and Dssubscript𝐷𝑠D_{s}italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT.",[],['Brazil']
"Nanoparticle-Enhanced Phase Change Materials (NePCM) have been a subject of intensive research owing to their potential for enhanced thermo-physical properties. However, their behavior during phase change processes, such as melting or solidification, remains inadequately understood. This investigation focuses on the melting process of NePCM in a square cavity, exploring distinct cases of melting from both the top and bottom sides. The NePCM comprises copper nanoparticles (2 nm in size) suspended in water. Our study involves different combinations of constant temperature boundary conditions and particle volume fractions. Utilizing a numerical model based on the one-fluid mixture approach combined with the single-domain enthalpy-porosity model, we account for the phase change process and particles’ interaction with the solid-liquid interface. When melting NePCM from the top side, convection effects are suppressed, resulting in a melting process primarily governed by conduction. Both NePCM and pure water melt at the same rate under these conditions. However, melting NePCM from the bottom side induces convection-dominated melting. For pure water, thermal convection leads to the formation of convection cells during melting. Contrastingly, melting NePCM triggers thermosolutal convection due to temperature and particle concentration gradients. The flow cells formed from thermosolutal convection in NePCM differ from those in pure water driven by pure thermal convection. Our simulations reveal that thermosolutal convection contributes to decelerating the solid-liquid interface, thereby prolonging NePCM melting compared to pure water. Surprisingly, the viscosity increase in NePCM plays a minimal role in the deceleration process, contrary to prior literature attributing slow-downs of the melting process of the NePCM primarily to increased viscosity.",[],[]
"Motivated by recent developments in the construction of Newton–Okounkov bodies and toric degenerations via cluster algebras in [GHKK18, FO20], we consider a family of Newton–Okounkov polytopes of a complex smooth Fano variety X𝑋Xitalic_X related by a composition of tropicalized cluster mutations. According to the work of [HK15], the toric degeneration associated with each Newton–Okounkov polytope ΔΔ\Deltaroman_Δ in the family produces a Lagrangian torus fibration of X𝑋Xitalic_X over ΔΔ\Deltaroman_Δ. We investigate circumstances in which each Lagrangian torus fibration possesses a monotone Lagrangian torus fiber. We provide a sufficient condition, based on the data of tropical integer points and exchange matrices, for the family of constructed monotone Lagrangian tori to contain infinitely many monotone Lagrangian tori, no two of which are related by any symplectomorphisms. By employing this criterion and exploiting the correspondence between the tropical integer points and the dual canonical basis elements, we generate infinitely many distinct monotone Lagrangian tori on flag manifolds of arbitrary type except in a few cases.",[],[]
"Let [n]:={1,2,…,n}assigndelimited-[]𝑛12…𝑛[n]:=\{1,2,\ldots,n\}[ italic_n ] := { 1 , 2 , … , italic_n }, and M𝑀Mitalic_M be a set of positive integers. We use ([n]M)binomialdelimited-[]𝑛𝑀\binom{\left[n\right]}{M}( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_M end_ARG ) to denote the family of all subsets of [n]delimited-[]𝑛[n][ italic_n ] whose sizes are in M𝑀Mitalic_M. The non-empty families 𝒜⊆([n]R)𝒜binomialdelimited-[]𝑛𝑅\mathcal{A}\subseteq\binom{\left[n\right]}{R}caligraphic_A ⊆ ( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_R end_ARG ) and ℬ⊆([n]S)ℬbinomialdelimited-[]𝑛𝑆\mathcal{B}\subseteq\binom{\left[n\right]}{S}caligraphic_B ⊆ ( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_S end_ARG ) are said to be cross t𝑡titalic_t-intersecting if |A∩B|≥t𝐴𝐵𝑡|A\cap B|\geq t| italic_A ∩ italic_B | ≥ italic_t for all A∈𝒜𝐴𝒜A\in\mathcal{A}italic_A ∈ caligraphic_A and B∈ℬ𝐵ℬB\in\mathcal{B}italic_B ∈ caligraphic_B. In this paper, we determine the maximum sum of sizes of non-empty cross t𝑡titalic_t-intersecting families, and characterize the extremal families. We also prove similar results for finite vector spaces.

Key words: Erdős-Ko-Rado Theorem; non-empty cross t𝑡titalic_t-intersecting; finite sets ; vector spaces",[],[]
"Masked Image Modeling (MIM) arises as a promising option for Vision Transformers among various self-supervised learning (SSL) methods. The essence of MIM lies in token-wise masked patch predictions, with targets patchified from images; or generated by pre-trained tokenizers or models. We argue targets from the pre-trained models usually exhibit spatial inconsistency, which makes it excessively challenging for the model to follow to learn more discriminative representations. To mitigate the issue, we introduce a novel self-supervision signal based on Dynamic Token Morphing (DTM), which dynamically aggregates contextually related tokens. DTM can be generally applied to various SSL frameworks, yet we propose a simple MIM that employs DTM to effectively improve the performance barely introducing extra training costs. Our experiments on ImageNet-1K and ADE20K evidently demonstrate the superiority of our methods. Furthermore, the comparative evaluation of iNaturalist and Fine-grained Visual Classification datasets further validates the transferability of our method on various downstream tasks. Our code will be released publicly.",[],[]
"The Wilcoxon signed-rank test and the Wilcoxon-Mann-Whitney test are commonly employed in one sample and two sample mean tests for one-dimensional hypothesis problems. For high-dimensional mean test problems, we calculate the asymptotic distribution of the maximum of rank statistics for each variable and suggest a max-type test. This max-type test is then merged with a sum-type test, based on their asymptotic independence offered by stationary and strong mixing assumptions. Our numerical studies reveal that this combined test demonstrates robustness and superiority over other methods, especially for heavy-tailed distributions.",[],[]
"We introduce hypergeometric-type sequences. They are linear combinations of interlaced hypergeometric sequences (of arbitrary interlacements). We prove that they form a subring of the ring of holonomic sequences. An interesting family of sequences in this class are those defined by trigonometric functions with linear arguments in the index and π𝜋\piitalic_π, such as Chebyshev polynomials, (sin2⁡(n⁢π/4)⋅cos⁡(n⁢π/6))nsubscript⋅superscript2𝑛𝜋4𝑛𝜋6𝑛\left(\sin^{2}\left(n\,\pi/4\right)\cdot\cos\left(n\,\pi/6\right)\right)_{n}( roman_sin start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_n italic_π / 4 ) ⋅ roman_cos ( italic_n italic_π / 6 ) ) start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, and compositions like (sin⁡(cos⁡(n⁢π/3)⁢π))nsubscript𝑛𝜋3𝜋𝑛\left(\sin\left(\cos(n\pi/3)\pi\right)\right)_{n}( roman_sin ( roman_cos ( italic_n italic_π / 3 ) italic_π ) ) start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT.
We describe an algorithm that computes a hypergeometric-type normal form of a given holonomic n⁢th𝑛thn\text{th}italic_n th term whenever it exists. Our implementation enables us to generate several identities for terms defined via trigonometric functions.","['Petkovšek’s algorithm', 'Hyper mfoldHyper', 'P-recursive sequences interlaced hypergeometric term m𝑚mitalic_m-fold indicator sequences']",[]
"There is a growing interest in the analysis of replication studies
of original findings
across many disciplines.
When testing a hypothesis for an effect size,
two Bayesian approaches stand out for their principled use of
the Bayes factor (BF), namely
the replication BF and the skeptical BF.
In particular, the latter BF
is based on the skeptical prior, which represents the
opinion of an investigator who is unconvinced by the
original findings and wants to challenge them.
We embrace the skeptical perspective, and elaborate a novel mixture prior which
incorporates skepticism while at the same time controlling for prior-data conflict within the original data.
Consistency properties of the resulting skeptical mixture BF are provided
together with an extensive analysis of the main features of our proposal.
Finally, we apply our methodology to
data from the Social Sciences Replication Project.
In particular we show that,
for some case studies
where prior-data conflict is an issue,
our method uses a more realistic prior and leads to
evidence-classification for replication success
which differs from the standard skeptical approach.",[],[]
"Employing the projective formalism of determinant quantum Monte Carlo (DQMC) simulations, we meticulously explore the ground-state phase diagram and critical behavior of the half-filled Hubbard model on a square-hexagon-octagon (SHO) lattice. This lattice, a two-dimensional (2D) structure comprising squares, hexagons, and octagons, is representative of the biphenylene network (BPN). Our findings reveal an intriguing ground-state phase diagram, featuring an antiferromagnetic (AFM) Mott insulating phase enveloped by three valence-bond solid-like (VBS-like) insulating phases. Analyzing the single-particle gap, spin gap, and single-particle spectral function, we observe that the metallic state in the noninteracting case becomes unstable under the influence of Hubbard U𝑈Uitalic_U.
This interaction drives the system into a hexagon insulating phase before transitioning into an AFM Mott insulating phase. To quantify the critical exponents, we use finite-size scaling techniques. The critical exponents of quantum critical points between the AFM Mott insulating phase and two insulating phases, plaquette insulator and ethylene insulator, closely align with the 3D O(3) universality class. However, the critical exponents of quantum critical points between the hexagon insulating phase and the AFM Mott insulating phase deviate from the 3D O(3) universality class. This deviation is a finite-size effect and can be attributed to the coupling between the fluctuations of magnetic order parameter and very low-energy fermionic excitations. Our comprehensive study not only advances the understanding of correlation effects on the SHO lattice but also sheds light on the less-explored critical exponents in weakly insulating quantum critical point.",[],['China']
,[],['China']
"Over the past decade, visual gaze estimation has garnered growing attention within the research community, thanks to its wide-ranging application scenarios. While existing estimation approaches have achieved remarkable success in enhancing prediction accuracy, they primarily infer gaze directions from single-image signals and discard the huge potentials of the currently dominant text guidance. Notably, visual-language collaboration has been extensively explored across a range of visual tasks, such as image synthesis and manipulation, leveraging the remarkable transferability of large-scale Contrastive Language-Image Pre-training (CLIP) model. Nevertheless, existing gaze estimation approaches ignore the rich semantic cues conveyed by linguistic signals and priors in CLIP feature space, thereby yielding performance setbacks. In pursuit of making up this gap, we delve deeply into the text-eye collaboration protocol and introduce a novel gaze estimation framework in this paper, referred to as GazeCLIP. Specifically, we intricately design a linguistic description generator to produce text signals with coarse directional cues. Additionally, a CLIP-based backbone that excels in characterizing text-eye pairs for gaze estimation is presented. This is followed by the implementation of a fine-grained multi-modal fusion module aimed at modeling the interrelationships between heterogeneous inputs. Extensive experiments on three challenging datasets demonstrate the superiority of the proposed GazeCLIP which surpasses the previous approaches and achieves the state-of-the-art estimation accuracy.",[],[]
,[],[]
"We study a generalized Witten’s finiteness conjecture for the skein modules of oriented compact 3333-manifolds with boundary.
We formulate an equivalent version of the generalized finiteness conjecture using handlebodies and 2-handles, and prove the conjecture for some classes with the handlebodies of genus 2222 and 3333 using the equivalent version.",[],[]
"This paper sets out a framework for the valuation of insurance liabilities that is intended to be economically realistic, elementary, reasonably practically applicable, and as a special case to provide a basis for the valuation in regulatory solvency systems such as Solvency II and the SST. The valuation framework is based on the cost of producing the liabilities to an insurance company that is subject to solvency regulation (regulatory solvency capital requirements) and insolvency laws (consequences of failure) in finite discrete time. Starting from the replication approach of classical no-arbitrage theory, the framework additionally considers the nature and cost of capital (expressed by a “financiability condition”), that the liabilities may be required to be fulfilled only “in sufficiently many cases” (expressed by a “fulfillment condition”), production using “fully illiquid” assets in addition to tradables, and the asymmetry between assets and liabilities. We identify necessary and sufficient conditions on the capital investment under which the framework recovers the market prices of tradables, investigate extending production to take account of insolvency, implications of using illiquid assets in the production, and show how Solvency II and SST valuation can be derived with specific assumptions.",[],[]
"This paper studies identification for a wide range of nonlinear panel data models, including binary choice, ordered repsonse, and other types of limited dependent variable models. Our approach accommodates dynamic models with any number of lagged dependent variables as well as other types of (potentially contemporary) endogeneity. Our identification strategy relies on a partial stationarity condition, which not only allows for an unknown distribution of errors but also for temporal dependencies in errors. We derive partial identification results under flexible model specifications and provide additional support conditions for point identification. We demonstrate the robust finite-sample performance of our approach using Monte Carlo simulations, with static and dynamic ordered choice models as illustrative examples.

Keywords: Panel Discrete Choice Models; Stationarity; Dynamic Models; Partial Identification; Endogeneity",[],[]
"In condensed matter physics, the Kagome lattice and its inherent flat bands have attracted considerable attention for their potential to host a variety of exotic physical phenomena. Despite extensive efforts to fabricate thin films of Kagome materials aimed at modulating the flat bands through electrostatic gating or strain manipulation, progress has been limited. Here, we report the observation of a novel d𝑑ditalic_d-orbital hybridized Kagome-derived flat band in Ag/Si(111) 3×333\sqrt{3}\times\sqrt{3}square-root start_ARG 3 end_ARG × square-root start_ARG 3 end_ARG as revealed by angle-resolved photoemission spectroscopy. Our findings indicate that silver atoms on a silicon substrate form a Kagome-like structure, where a delicate balance in the hopping parameters of the in-plane d𝑑ditalic_d-orbitals leads to destructive interference, resulting in a flat band. These results not only introduce a new platform for Kagome physics but also illuminate the potential for integrating metal-semiconductor interfaces into Kagome-related research, thereby opening a new avenue for exploring ideal two-dimensional Kagome systems.",[],[]
"We introduce a natural two-cardinal version of Bagaria’s sequence of derived topologies on ordinals. We prove that for our sequence of two-cardinal derived topologies, limit points of sets can be characterized in terms of a new iterated form of pairwise simultaneous reflection of certain kinds of stationary sets, the first few instances of which are often equivalent to notions related to strong stationarity, which has been studied previously in the context of strongly normal ideals [10]. The non-discreteness of these two-cardinal derived topologies can be obtained from certain two-cardinal indescribability hypotheses, which follow from local instances of supercompactness. Additionally, we answer several questions posed by the first author, Peter Holy and Philip White on the relationship between Ramseyness and indescribability in both the cardinal context and in the two-cardinal context.","['derived topology', 'stationary reflection', 'indescribable cardinals', 'Ramsey cardinals', 'Ramsey hierarchy']",[]
"This proceedings paper extends the scope of our conference talk, where we presented a comprehensive analysis of newly expanded and refined lattice data concerning the SU⁢(3)SU3\mathrm{SU}(3)roman_SU ( 3 ) gauge theory with Nf=8subscript𝑁𝑓8N_{f}=8italic_N start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = 8 light Dirac fermions — a theory positioned near the conformal window boundary. The analysis presented here makes use of a dilaton effective field theory and we delve deeper into the intricacies of the dilaton potential. We aim to clarify the connection between parameters appearing the potential and properties of the underlying gauge theory.",[],[]
"Pretrained large-scale vision-language models such as CLIP have demonstrated excellent generalizability over a series of downstream tasks. However, they are sensitive to the variation of input text prompts and need a selection of prompt templates to achieve satisfactory performance. Recently, various methods have been proposed to dynamically learn the prompts as the textual inputs to avoid the requirements of laboring hand-crafted prompt engineering in the fine-tuning process. We notice that these methods are suboptimal in two aspects. First, the prompts of the vision and language branches in these methods are usually separated or uni-directionally correlated. Thus, the prompts of both branches are not fully correlated and may not provide enough guidance to align the representations of both branches. Second, it’s observed that most previous methods usually achieve better performance on seen classes but cause performance degeneration on unseen classes compared to CLIP. This is because the essential generic knowledge learned in the pretraining stage is partly forgotten in the fine-tuning process. In this paper, we propose Co-Articulated Multi-Modal Learning (COMMA) to handle the above limitations. Especially, our method considers prompts from both branches to generate the prompts to enhance the representation alignment of both branches. Besides, to alleviate forgetting about the essential knowledge, we minimize the feature discrepancy between the learned prompts and the embeddings of hand-crafted prompts in the pre-trained CLIP in the late transformer layers. We evaluate our method across three representative tasks of generalization to novel classes, new target datasets and unseen domain shifts. Experimental results demonstrate the superiority of our method by exhibiting a favorable performance boost upon all tasks with high efficiency. Code is available at https://github.com/hulianyuyy/COMMA",[],[]
,[],[]
"Motivated by their research on automorphism groups of pseudo-real Riemann surfaces, Bujalance, Cirre and Conder have conjectured that there are infinitely many primes p𝑝pitalic_p such that p+2𝑝2p+2italic_p + 2 has all its prime factors q≡−1𝑞1q\equiv-1italic_q ≡ - 1 mod (4)4(4)( 4 ). We use a theorem of Raikov to prove that the number of integers n≤x𝑛𝑥n\leq xitalic_n ≤ italic_x with only such prime factors q𝑞qitalic_q is asymptotic to c⁢x/ln⁡x𝑐𝑥𝑥cx/\sqrt{\ln x}italic_c italic_x / square-root start_ARG roman_ln italic_x end_ARG for a specific constant c=0.4865⁢…𝑐0.4865…c=0.4865\ldotsitalic_c = 0.4865 …. Heuristic arguments, following Hardy and Littlewood, then yield a conjecture that the number of such primes p≤x𝑝𝑥p\leq xitalic_p ≤ italic_x is asymptotic to c′⁢∫2x(ln⁡t)−3/2⁢𝑑tsuperscript𝑐′superscriptsubscript2𝑥superscript𝑡32differential-d𝑡c^{\prime}\int_{2}^{x}(\ln t)^{-3/2}dtitalic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∫ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT ( roman_ln italic_t ) start_POSTSUPERSCRIPT - 3 / 2 end_POSTSUPERSCRIPT italic_d italic_t for a constant c′=0.8981⁢…superscript𝑐′0.8981…c^{\prime}=0.8981\ldotsitalic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 0.8981 …. The theorem, the conjecture and a similar conjecture applying the Bateman–Horn Conjecture to other pseudo-real Riemann surfaces are supported by evidence from extensive computer searches.","['Riemann surface', 'pseudo-real', 'prime number', 'Riemann zeta function', 'Dirichlet series', 'Bateman–Horn', 'Conjecture']",[]
"Existing gait recognition benchmarks mostly include minor clothing variations in the laboratory environments, but lack persistent changes in appearance over time and space. In this paper, we propose the first in-the-wild benchmark CCGait for cloth-changing gait recognition, which incorporates diverse clothing changes, indoor and outdoor scenes, and multi-modal statistics over 92 days. To further address the coupling effect of clothing and viewpoint variations, we propose a hybrid approach HybridGait that exploits both temporal dynamics and the projected 2D information of 3D human meshes. Specifically, we introduce a Canonical Alignment Spatial-Temporal Transformer (CA-STT) module to encode human joint position-aware features, and fully exploit 3D dense priors via a Silhouette-guided Deformation with 3D-2D Appearance Projection (SilD) strategy. Our contributions are twofold: we provide a challenging benchmark CCGait that captures realistic appearance changes across an expanded and space, and we propose a hybrid framework HybridGait that outperforms prior works on CCGait and Gait3D benchmarks.
Our project page is available at
https://github.com/HCVLab/HybridGait.",[],[]
"Proactively and naturally guiding the dialog from the non-recommendation context (e.g., Chit-chat) to the recommendation scenario (e.g., Music) is crucial for the Conversational Recommender System (CRS).
Prior studies mainly focus on planning the next dialog goal (e.g., chat on a movie star) conditioned on the previous dialog.
However, we find the dialog goals can be simultaneously observed at different levels, which can be utilized to improve CRS.
In this paper, we propose
Dual-space Hierarchical Learning (DHL)
to leverage multi-level goal sequences and their hierarchical relationships for conversational recommendation.
Specifically, we exploit multi-level goal sequences from both the representation space and the optimization space.
In the representation space, we propose the hierarchical representation learning where a cross attention module derives mutually enhanced multi-level goal representations.
In the optimization space, we devise the hierarchical weight learning to reweight lower-level goal sequences, and introduce bi-level optimization for stable update.
Additionally, we propose a soft labeling strategy to guide optimization gradually.
Experiments on two real-world datasets verify the effectiveness of our approach.
Code and data are available here.",[],[]
"This work evaluated several cutting-edge large-scale foundation models based on self-supervision or weak supervision, including SeamlessM4T, SeamlessM4T v2, and Whisper-large-v3, on three code-switched corpora. We found that self-supervised models can achieve performances close to the supervised model, indicating the effectiveness of multilingual self-supervised pre-training. We also observed that these models still have room for improvement as they kept making similar mistakes and had unsatisfactory performances on modeling intra-sentential code-switching. In addition, the validity of several variants of Whisper was explored, and we concluded that they remained effective in a code-switching scenario, and similar techniques for self-supervised models are worth studying to boost the performance of code-switched tasks.",[],[]
"Recently, fictitious identical particles have provided a promising way to overcome the fermion sign problem and have been used in path integral Monte Carlo (PIMC) to accurately simulate warm dense matter with up to 1000 electrons (T. Dornheim et al., arXiv:2311.08098 (2023)). The inclusion of fictitious identical particles in path integral molecular dynamics (PIMD) can provide another way to simulate fermion systems. In a recent paper (J. Chem. Phys. 159, 154107 (2023)), Feldman and Hirshberg improved the recursive formula for PIMD of N identical bosons, significantly reducing the computational complexity from O⁢(P⁢N3)𝑂𝑃superscript𝑁3O(PN^{3})italic_O ( italic_P italic_N start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) to O⁢(N2+P⁢N)𝑂superscript𝑁2𝑃𝑁O(N^{2}+PN)italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_P italic_N ). In this paper, we extend this latest recursive formula for bosons to PIMD of fictitious identical particles to improve the efficiency of simulating fermion systems. We also provide the virial estimator for calculating energy by using the recursive technique. As an example, we use the quadratic scaling PIMD for fictitious identical particles to study the simulation of hundreds of fermions in a two-dimensional periodic potential, in the hope of providing a simulation tool for two-dimensional Fermi-Hubbard model and other strongly correlated fermion systems, such as the simulation of ultracold fermionic gases in optical lattices.",[],['China']
"Magnetic particle imaging (MPI) is an emerging medical imaging modality which has gained increasing interest in recent years.
Among the benefits of MPI are its high temporal resolution, and that the technique does not expose the specimen to any kind of ionizing radiation.
It is based on the non-linear response of magnetic nanoparticles to an applied magnetic field.
From the electric signal measured in receive coils, the particle concentration has to be reconstructed.
Due to the ill-posedness of the reconstruction problem, various regularization methods have been proposed for reconstruction ranging from early stopping methods, via classical Tikhonov regularization and iterative methods to modern machine learning approaches.
In this work, we contribute to the latter class: we propose a plug-and-play approach based on a generic zero-shot denoiser with an ℓ1superscriptℓ1\ell^{1}roman_ℓ start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT-prior. Moreover, we develop parameter selection strategies. Finally, we quantitatively and qualitatively evaluate the proposed algorithmic scheme on the 3D Open MPI data set with different levels of preprocessing.",[],[]
"Uncertainty quantification is a critical aspect of machine learning models, providing important insights into the reliability of predictions and aiding the decision-making process in real-world applications. This paper proposes a novel way to use variance-based measures to quantify uncertainty on the basis of second-order distributions in classification problems. A distinctive feature of the measures is the ability to reason about uncertainties on a class-based level, which is useful in situations where nuanced decision-making is required. Recalling some properties from the literature, we highlight that the variance-based measures satisfy important (axiomatic) properties. In addition to this axiomatic approach, we present empirical results showing the measures to be effective and competitive to commonly used entropy-based measures.",[],[]
"Ultracold neutrons are great experimental tools to explore the gravitational interaction in the regime of quantized states.
From a theoretical perspective, starting from a Dirac equation in curved spacetime, we applied a perturbative scheme to systematically derive the non-relativistic Schrödinger equation that governs the evolution of the neutron’s wave function in the Earth’s gravitational field. At the lowest order, this procedure reproduces a Schrödinger system affected by a linear Newtonian potential, but corrections due to both curvature and relativistic effects are present. Here, we argue that one should be very careful when going one step further in the perturbative expansion. Proceeding methodically with the help of the Foldy-Wouthuysen transformation and a formal post-Newtonian 1/c2−limit-from1superscript𝑐2\nicefrac{{1}}{{c^{2}}}-/ start_ARG 1 end_ARG start_ARG italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG -expansion, we derive the non-relativistic Hamiltonian for a generic static spacetime. By employing Fermi coordinates within this framework, we calculate the next-to-leading order corrections to the neutron’s energy spectrum. Finally, we evaluate them for typical experimental configurations, such as that of qBOUNCE, and note that, while the current precision for observations of ultracold neutrons may not yet enable to probe them, they could still be relevant in the future or in alternative circumstances.",[],"['Austria', 'Chile']"
"The intrinsic alignment (IA) of galaxies acts as a systematic effect in weak lensing measurements and tends to introduce biases. It mimics the gravitational lensing signal which makes it difficult to distinguish it from the true gravitational weak lensing effect. Hence, it is critical to account for the noise for correctly interpreting the results. This study aims at a quantitative analysis of IA using the Tidal Alignment and Tidal Torquing (TATT) model. We also investigate how the signals for shear and galaxy-galaxy lensing behave upon changing the parameters of the TATT model.
The data for this study was prepared with a computational pipeline based on the Cocoa model to explore the parameter space of the intrinsic shape signal.
Through this work, we identify that linear terms of the intrinsic shape signal are dominant in the case of GGL while the higher-order terms dictate the shear signal.","['Intrinsic', 'Alignments —', 'Weak', 'Gravitational', 'Lensing —', 'Tidal', 'Alignment —', 'Tidal', 'Torquing —', 'Cosmic', 'Shear —', 'Galaxy', 'Alignments']",[]
We prove that the singular set of a 2222-valued Lipschitz graph that is stationary for the area is of codimension 1111.,[],[]
"Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use to exploit vulnerabilities. The interpretation of TTPs in the MITRE ATT&CK framework can be challenging for cybersecurity practitioners due to presumed expertise, complex dependencies, and inherent ambiguity. Meanwhile, advancements with Large Language Models (LLMs) have led to recent surge in studies exploring its uses in cybersecurity operations. This leads us to question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5) LLMs can comprehend and summarize TTPs to inform analysts of the intended purposes (i.e., tactics) of a cyberattack procedure. The state-of-the-art LLMs have shown to be prone to hallucination by providing inaccurate information, which is problematic in critical domains like cybersecurity. Therefore, we propose the use of Retrieval Augmented Generation (RAG) techniques to extract relevant contexts for each cyberattack procedure for decoder-only LLMs (without fine-tuning). We further contrast such approach against supervised fine-tuning (SFT) of encoder-only LLMs. Our results reveal that both the direct-use of decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only LLMs offer inaccurate interpretation of cyberattack procedures. Significant improvements are shown when RAG is used for decoder-only LLMs, particularly when directly relevant context is found. This study further sheds insights on the limitations and capabilities of using RAG for LLMs in interpreting TTPs.",[],[]
"We study populations of oscillators, all-to-all coupled by means of quenched disordered phase shifts. While there is no traditional synchronization transition with a nonvanishing Kuramoto order parameter, the system demonstrates a specific order as the coupling strength increases. This order is characterized by partial phase locking, which is put into evidence by the introduced correlation order parameter and via frequency entrainment. Simulations with phase oscillators, Stuart-Landau oscillators, and chaotic Roessler oscillators demonstrate similar scaling of the correlation order parameter with the coupling and the system size and also similar behavior of the frequencies with maximal entrainment at some finite coupling.",[],"['Germany', 'Italy']"
"Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery.
However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space.
Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables.
We make the observation that closed-form equations often have structural characteristics and invariances (e.g., the commutative law) that could be further exploited to build more effective symbolic regression solutions.
Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps.
We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training.
Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR).
In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions.",[],[]
,[],[]
"In a scenario where multi-modal cameras are operating together, the problem of working with non-aligned images cannot be avoided. Yet, existing image fusion algorithms rely heavily on strictly registered input image pairs to produce more precise fusion results, as a way to improve the performance of downstream high-level vision tasks. In order to relax this assumption, one can attempt to register images first. However, the existing methods for registering multiple modalities have limitations, such as complex structures and reliance on significant semantic information. This paper aims to address the problem of image registration and fusion in a single framework, called BusRef. We focus on Infrared-Visible image registration and fusion task (IVRF). In this framework, the input unaligned image pairs will pass through three stages: Coarse registration, Fine registration and Fusion. It will be shown that the unified approach enables more robust IVRF. We also propose a novel training and evaluation strategy, involving the use of masks to reduce the influence of non-reconstructible regions on the loss functions, which greatly improves the accuracy and robustness of the fusion task. Last but not least, a gradient-aware fusion network is designed to preserve the complementary information.
The advanced performance of this algorithm is demonstrated by comparing it with different registration/fusion algorithms.",[],[]
,[],[]
"As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research.
This paper presents Safety and Over-Defensiveness Evaluation (SODE) benchmark: a collection of diverse safe and unsafe prompts with carefully designed evaluation methods that facilitate systematic evaluation, comparison, and analysis over ‘safety’ and ‘over-defensiveness.’
With SODE, we study a variety of LLM defense strategies over multiple state-of-the-art LLMs, which reveals several interesting and important findings, such as
(a) the widely popular ‘self-checking’ techniques indeed improve the safety against unsafe inputs, but this comes at the cost of extreme over-defensiveness on the safe inputs,
(b) providing a safety instruction along with in-context exemplars (of both safe and unsafe inputs) consistently improves safety and also mitigates undue over-defensiveness of the models,
(c) providing contextual knowledge easily breaks the safety guardrails and makes the models more vulnerable to generating unsafe responses.
Overall, our work reveals numerous such critical findings that we believe will pave the way and facilitate further research in improving the safety of LLMs.
WARNING: This paper contains several toxic and offensive model responses. Reader discretion is advised.",[],[]
"Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming.
Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages.
In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks.
We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models.
In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence.
Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io).
At last, we also point out several challenging and promising directions for future research.",[],"['Australia', 'China', 'Canada']"
,[],[]
"We consider the problem of red teaming LLMs on elementary calculations and algebraic tasks to evaluate how various prompting techniques affect the quality of outputs. We present a framework to procedurally generate numerical questions and puzzles, and compare the results with and without the application of several red teaming techniques. Our findings suggest that even though structured reasoning and providing worked-out examples slow down the deterioration of the quality of answers, the gpt-3.5-turbo and gpt-4 models are not well suited for elementary calculations and reasoning tasks, also when being red teamed.",[],[]
,[],[]
"The Multi-Objective Mixed-Integer Programming (MOMIP) problem is one of the most challenging. To derive its Pareto optimal solutions one can use the well-known Chebyshev scalarization and Mixed-Integer Programming (MIP) solvers. However, for a large-scale instance of the MOMIP problem, its scalarization may not be solved to optimality, even by state-of-the-art optimization packages, within the time limit imposed on the optimization.
If a MIP solver cannot derive the optimal solution within the assumed time limit, it provides the optimality gap, which gauges the quality of the approximate solution. However, for the MOMIP case, no information is provided on the lower and upper bounds of the components of the Pareto optimal outcome.
For the MOMIP problem with two and three objective functions, an algorithm is proposed to provide the so-called interval representation of the Pareto optimal outcome designated by the weighting vector when there is a time limit on solving the Chebyshev scalarization. Such interval representations can be used to navigate on the Pareto front.
The results of several numerical experiments on selected large-scale instances of the multi-objective, multidimensional 0-1 knapsack problem illustrate the proposed approach. The limitations and possible enhancements of the proposed method are also discussed.","['multi-objective mixed-integer programming', 'large-scale optimization', 'Chebyshev scalarization', 'Pareto front approximations', 'lower bounds', 'upper bounds']",[]
"This work deals with a maximal monotone operator A𝐴Aitalic_A of type (D) in a Banach space whose dual space is strictly convex. We establish some representations for the value A⁢x𝐴𝑥Axitalic_A italic_x at a given point x𝑥xitalic_x via its values at nearby points of x𝑥xitalic_x. We show that the faces of A⁢x𝐴𝑥Axitalic_A italic_x are contained in the set of all weak*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT convergent limits of bounded nets of the operator at nearby points of x𝑥xitalic_x, then we obtain a representation for A⁢x𝐴𝑥Axitalic_A italic_x by use of this set. In addition, representations for the support function of A⁢x𝐴𝑥Axitalic_A italic_x based on the minimal-norm selection of the operator in certain Banach spaces are given.



Keywords:
Maximal monotone operator, monotone operator of type (D), minimal-norm selection, w-Kadec-Klee-property, w*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT-Kadec-Klee-property, strictly convex space


MSC 2020: 47H05, 47H04, 47N10",[],[]
"Robust control of quantum systems is an increasingly relevant field of study amidst the second quantum revolution, but there remains a gap between taming quantum physics and robust control in its modern analytical form that culminated in fundamental performance bounds. In general, quantum systems are not amenable to linear, time-invariant, measurement-based robust control techniques, and thus novel gap-bridging techniques must be developed. This survey is written for control theorists to highlight parallels between the current state of quantum control and classical robust control. We present issues that arise when applying classical robust control theory to quantum systems, typical methods used by quantum physicists to explore such systems and their robustness, as well as a discussion of open problems to be addressed in the field. We focus on general, practical applications and recent work to enable control researchers to contribute to advancing this burgeoning field.",[],[]
"Achieving perfect control over the parameters defining a quantum gate is, in general, a very challenging task and at the same time, environmental interactions can introduce disturbances to the initial states as well. Here we address the problem of how the imperfections in unitaries and noise present in the input states affect the entanglement-generating power of a given quantum gate – we refer to it as imperfect (noisy) entangling power. We observe that, when the parameters of a given unitary are chosen randomly from a Gaussian distribution centered around the desired mean, the quenched average entangling power – averaged across multiple random samplings – exhibits intriguing behavior like it may increase or show nonmonotonic behavior with the increase of disorder strength for certain classes of diagonal unitary operators. For arbitrary unitary operators, the quenched average power tends to stabilize, showing almost constant behavior with variation in the parameters instead of oscillating. Our observations also reveal that, in the presence of a local noise model, the input states that maximize the entangling power of a given unitary operator differ considerably from the noiseless scenario. Additionally, we report that the rankings among unitary operators according to their entangling power in the noiseless case change depending on the noise model and noise strength.",[],['India']
"When applying T-duality to a generic, non-extreme Killing horizon, T-duality is spacelike on one side and timelike on the other. We show, using simple examples from four-dimensional Einstein-Maxwell theory, that the image of the horizon is a singularity which can be understood as an interface between two different T-dual theories and their solutions. Using an embedding into type-II string theory, we show that the singularity occurs when scalars reach
the boundary of moduli space, resulting in a breakdown of the effective field theory due to the presence of tensionless strings.",[],[]
,[],[]
"Principal-agent problems arise when one party acts on behalf of another, leading to conflicts of interest. The economic literature has extensively studied principal-agent problems, and recent work has extended this to more complex scenarios such as Markov Decision Processes (MDPs). In this paper, we further explore this line of research by investigating how reward shaping under budget constraints can improve the principal’s utility. We study a two-player Stackelberg game where the principal and the agent have different reward functions, and the agent chooses an MDP policy for both players. The principal offers an additional reward to the agent, and the agent picks their policy selfishly to maximize their reward, which is the sum of the original and the offered reward. Our results establish the NP-hardness of the problem and offer polynomial approximation algorithms for two classes of instances: Stochastic trees and deterministic decision processes with a finite horizon.",[],[]
"Denote by Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT the d𝑑ditalic_d-dimensional hypercube. Addressing a recent
question we estimate the number of ways the vertex set of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT
can be partitioned into
vertex disjoint smaller cubes. Among other results, we prove
that the asymptotic order
of this function is not much larger than the number of
perfect matchings of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. We also describe
several new (and old) questions.",[],[]
"We present multivariable extremum seeking (ES) designs that achieve unbiased convergence to the optimum. Two designs are introduced: one with exponential unbiased convergence (unbiased extremum seeker, uES) and the other with user-assignable prescribed-time unbiased convergence (unbiased PT extremum seeker, uPT-ES). In contrast to the conventional ES, which uses persistent sinusoids and results in steady-state oscillations around the optimum, the exponential uES employs an exponentially decaying amplitude in the perturbation signal (for achieving convergence) and an exponentially growing demodulation signal (for making the convergence unbiased). The achievement of unbiased convergence also entails employing an adaptation gain that is sufficiently large in relation to the decay rate of the perturbation amplitude. Stated concisely, the bias is eliminated by having the learning process outpace the waning of the perturbation. The other algorithm, uPT-ES, employs prescribed-time convergent/blow-up functions in place of constant amplitudes of sinusoids, and it also replaces constant-frequency sinusoids with chirp signals whose frequency grows over time. Among the convergence results in the ES literature, uPT-ES may be the strongest yet in terms of the convergence rate (prescribed-time) and accuracy (unbiased). To enhance the robustness of uES to a time-varying optimum, exponential functions are modified to keep oscillations at steady state. Stability analysis of the designs is based on a state transformation, averaging, local exponential/PT stability of the averaged system, local stability of the transformed system, and local exponential/PT stability of the original system. For numerical implementation of the developed ES schemes and comparison with previous ES designs, the problem of source seeking by a two-dimensional velocity-actuated point mass is considered.",[],[]
"Dynamic control via optimized, piecewise-constant pulses is a common paradigm for open-loop control to implement quantum gates. While numerous methods exist for the synthesis of such controls, there are many open questions regarding the robustness of the resulting control schemes in the presence of model uncertainty; unlike in classical control, there are generally no analytical guarantees on the control performance with respect to inexact modeling of the system. In this paper a new robustness measure based on the differential sensitivity of the gate fidelity error to parametric (structured) uncertainties is introduced, and bounds on the differential sensitivity to parametric uncertainties are used to establish performance guarantees for optimal controllers for a variety of quantum gate types, system sizes, and control implementations. Specifically, it is shown how a maximum allowable perturbation over a set of Hamiltonian uncertainties that guarantees a given fidelity error, can be reliably computed. This measure of robustness is inversely proportional to the upper bound on the differential sensitivity of the fidelity error evaluated under nominal operating conditions. Finally, the results show that the nominal fidelity error and differential sensitivity upper bound are positively correlated across a wide range of problems and control implementations, suggesting that in the high-fidelity control regime, rather than there being a trade-off between fidelity and robustness, higher nominal gate fidelities are positively correlated with increased robustness of the controls in the presence of parametric uncertainties.",[],[]
"For a relational structure 𝕏𝕏{\mathbb{X}}blackboard_X we investigate the partial order ⟨ℙ⁢(𝕏),⊂⟩ℙ𝕏\langle{\mathbb{P}}({\mathbb{X}}),\subset\rangle⟨ blackboard_P ( blackboard_X ) , ⊂ ⟩,
where ℙ⁢(𝕏):={f⁢[X]:f∈Emb(𝕏)}assignℙ𝕏conditional-set𝑓delimited-[]𝑋𝑓Emb𝕏{\mathbb{P}}({\mathbb{X}}):=\{f[X]:f\in\mathop{\rm Emb}\nolimits({\mathbb{X}})\}blackboard_P ( blackboard_X ) := { italic_f [ italic_X ] : italic_f ∈ roman_Emb ( blackboard_X ) }.
A previous analysis shows that 𝔥=ω1𝔥subscript𝜔1{\mathfrak{h}}=\omega_{1}fraktur_h = italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT implies that for each countable ordinal we have
ro(sq(ℙ⁢(α)))≅ro(P⁢(ω)/Fin)rosqℙ𝛼ro𝑃𝜔Fin\mathop{\rm ro}\nolimits(\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha)))\cong%
\mathop{\rm ro}\nolimits(P(\omega)/\mathop{\rm Fin})roman_ro ( roman_sq ( blackboard_P ( italic_α ) ) ) ≅ roman_ro ( italic_P ( italic_ω ) / roman_Fin ).
But in ZFC we have sq(ℙ⁢(α))≅∏i=0n((rpri(P⁢(ωγi)/ℐωγi))+)sisqℙ𝛼superscriptsubscriptproduct𝑖0𝑛superscriptsuperscriptsuperscriptrpsubscript𝑟𝑖𝑃superscript𝜔subscript𝛾𝑖subscriptℐsuperscript𝜔subscript𝛾𝑖subscript𝑠𝑖\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha))\cong\prod_{i=0}^{n}((\mathop{%
\rm rp}\nolimits^{r_{i}}(P(\omega^{\gamma_{i}})/{\mathcal{I}}_{\omega^{\gamma_%
{i}}}))^{+})^{s_{i}}roman_sq ( blackboard_P ( italic_α ) ) ≅ ∏ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( ( roman_rp start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_P ( italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) / caligraphic_I start_POSTSUBSCRIPT italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT,
where ∑i=n0ωγi+ri⁢si+ksuperscriptsubscript𝑖𝑛0superscript𝜔subscript𝛾𝑖subscript𝑟𝑖subscript𝑠𝑖𝑘\sum_{i=n}^{0}\omega^{\gamma_{i}+r_{i}}s_{i}+k∑ start_POSTSUBSCRIPT italic_i = italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_k is the presentation of α𝛼\alphaitalic_α in the Cantor normal form
and rp(𝔹)rp𝔹\mathop{\rm rp}\nolimits({\mathbb{B}})roman_rp ( blackboard_B ) denotes the reduced power of a Boolean algebra 𝔹𝔹{\mathbb{B}}blackboard_B modulo finite:
𝔹ω/Finsuperscript𝔹𝜔Fin{\mathbb{B}}^{\omega}/\mathop{\rm Fin}blackboard_B start_POSTSUPERSCRIPT italic_ω end_POSTSUPERSCRIPT / roman_Fin.
Consequently, ro(sq(ℙ⁢(α)))≅ro((P⁢(ω)/Fin)+∗π)rosqℙ𝛼ro∗superscript𝑃𝜔Fin𝜋\mathop{\rm ro}\nolimits(\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha)))\cong%
\mathop{\rm ro}\nolimits((P(\omega)/\mathop{\rm Fin})^{+}\ast\pi)roman_ro ( roman_sq ( blackboard_P ( italic_α ) ) ) ≅ roman_ro ( ( italic_P ( italic_ω ) / roman_Fin ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ∗ italic_π ),
where π𝜋\piitalic_π is an P⁢(ω)/Fin𝑃𝜔FinP(\omega)/\mathop{\rm Fin}italic_P ( italic_ω ) / roman_Fin-name for an σ𝜎\sigmaitalic_σ-closed separative atomless poset.
Here we consider uncountable ordinals.
Since sqℙ⁢(α)sqℙ𝛼\mathop{\rm sq}\nolimits{\mathbb{P}}(\alpha)roman_sq blackboard_P ( italic_α ) is isomorphic to the direct product ∏i=1n(sqℙ⁢(ωδi))sisuperscriptsubscriptproduct𝑖1𝑛superscriptsqℙsuperscript𝜔subscript𝛿𝑖subscript𝑠𝑖\prod_{i=1}^{n}(\mathop{\rm sq}\nolimits{\mathbb{P}}(\omega^{\delta_{i}}))^{s_%
{i}}∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( roman_sq blackboard_P ( italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT,
where α=ωδn⁢sn+…+ωδ1⁢s1+m𝛼superscript𝜔subscript𝛿𝑛subscript𝑠𝑛…superscript𝜔subscript𝛿1subscript𝑠1𝑚\alpha=\omega^{\delta_{n}}s_{n}+\dots+\omega^{\delta_{1}}s_{1}+mitalic_α = italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT + … + italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m is the Cantor normal form for α𝛼\alphaitalic_α,
the analysis is reduced to the investigation of the posets of the form ℙ⁢(ωδ)ℙsuperscript𝜔𝛿{\mathbb{P}}(\omega^{\delta})blackboard_P ( italic_ω start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ).
It turns out that, in ZFC, either the poset sqℙ⁢(α)sqℙ𝛼\mathop{\rm sq}\nolimits{\mathbb{P}}(\alpha)roman_sq blackboard_P ( italic_α ) is σ𝜎\sigmaitalic_σ-closed and completely embeds P⁢(ω)/Fin𝑃𝜔FinP(\omega)/\mathop{\rm Fin}italic_P ( italic_ω ) / roman_Fin
and, hence, preserves ω1subscript𝜔1\omega_{1}italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and forces |𝔠|=|𝔥|𝔠𝔥|{\mathfrak{c}}|=|{\mathfrak{h}}|| fraktur_c | = | fraktur_h |,
or, otherwise, completely embeds the algebra P⁢(λ)/[λ]<λ𝑃𝜆superscriptdelimited-[]𝜆absent𝜆P(\lambda)/[\lambda]^{<\lambda}italic_P ( italic_λ ) / [ italic_λ ] start_POSTSUPERSCRIPT < italic_λ end_POSTSUPERSCRIPT, for some regular ω<λ≤cf(δ)𝜔𝜆cf𝛿\omega<\lambda\leq\mathop{\rm cf}\nolimits(\delta)italic_ω < italic_λ ≤ roman_cf ( italic_δ ), and collapses ω2subscript𝜔2\omega_{2}italic_ω start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to ω𝜔\omegaitalic_ω.
Regarding the Cantor normal form,
the first case appears iff for each i≤n𝑖𝑛i\leq nitalic_i ≤ italic_n we have cf(δi)≤ωcfsubscript𝛿𝑖𝜔\mathop{\rm cf}\nolimits(\delta_{i})\leq\omegaroman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ≤ italic_ω,
or δi=θi+cf(δi)subscript𝛿𝑖subscript𝜃𝑖cfsubscript𝛿𝑖\delta_{i}=\theta_{i}+\mathop{\rm cf}\nolimits(\delta_{i})italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ),
where Ord∋θi≥cf(δi)>cf(θi)=ωcontainsOrdsubscript𝜃𝑖cfsubscript𝛿𝑖cfsubscript𝜃𝑖𝜔\mathop{\mathrm{Ord}}\nolimits\ni\theta_{i}\geq\mathop{\rm cf}\nolimits(\delta%
_{i})>\mathop{\rm cf}\nolimits(\theta_{i})=\omegaroman_Ord ∋ italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≥ roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) > roman_cf ( italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_ω
and θi=limn→ωδnsubscript𝜃𝑖subscript→𝑛𝜔subscript𝛿𝑛\theta_{i}=\lim_{n\rightarrow\omega}\delta_{n}italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_lim start_POSTSUBSCRIPT italic_n → italic_ω end_POSTSUBSCRIPT italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, where cf(δn)=cf(δi)cfsubscript𝛿𝑛cfsubscript𝛿𝑖\mathop{\rm cf}\nolimits(\delta_{n})=\mathop{\rm cf}\nolimits(\delta_{i})roman_cf ( italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), for all n∈ω𝑛𝜔n\in\omegaitalic_n ∈ italic_ω.

2020 MSC:
06A05, 06A10, 03E40, 03E35. 
Keywords: uncountable ordinal, poset of copies, σ𝜎\sigmaitalic_σ-closed poset, cardinal collapse, forcing.",[],[]
"Synthetic data sets are used in cosmology to test analysis procedures, to verify that systematic errors are well understood and to demonstrate that measurements are unbiased. In this work we describe the methods used to generate synthetic datasets of Lyman-α𝛼\alphaitalic_α quasar spectra aimed for studies with the Dark Energy Spectroscopic Instrument (DESI). In particular, we focus on demonstrating that our simulations reproduces important features of real samples, making them suitable to test the analysis methods to be used in DESI and to place limits on systematic effects on measurements of Baryon Acoustic Oscillations (BAO).
We present a set of mocks that reproduce the statistical properties of the DESI early data set with good agreement. Additionally, we use full survey synthetic data to forecast the BAO scale constraining power with DESI.",[],[]
"We prove tunneling estimates for two-dimensional Dirac systems which are localized in space due to the presence of a magnetic field.
The Hamiltonian driving the motion admits the decomposition H=H0+W𝐻subscript𝐻0𝑊H=H_{0}+Witalic_H = italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_W, where H0subscript𝐻0H_{0}italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a rotationally symmetric magnetic Dirac operator and W𝑊Witalic_W is a position-dependent matrix-valued potential satisfying certain smoothness condition in the angular variable.
A consequence of our results are upper bounds for the
growth in time
of the expected size of the system and its total angular momentum.",[],[]
,[],[]
"Decisions are often made by heterogeneous groups of individuals, each with distinct initial biases and access to information of different quality. We show that in large groups of independent agents who accumulate evidence the first to decide are those with the strongest initial biases. Their decisions align with their initial bias, regardless of the underlying truth. In contrast, agents who decide last make decisions as if they were initially unbiased, and hence make better choices. We obtain asymptotic expressions in the large population limit that quantify how agents’ initial inclinations shape early decisions. Our analysis shows how bias, information quality, and decision order interact in non-trivial ways to determine the reliability of decisions in a group.",[],[]
"Earlier in my career, prevalent approaches in the emerging field of market design largely represented the experiences and perspectives of leaders who were commissioned to design or reform various institutions. Since being commissioned for a similar task seemed unlikely for me as an aspiring design economist, I developed my own minimalist approach to market design. Using the policy objectives of stakeholders, my approach creates a new institution from the existing one with minimal interference with its elements that compromise the objectives.
Minimalist market design initially evolved through my integrated research and policy efforts in school choice from 1997 to 2005 and in kidney exchange from 2003 to 2007. Given its success in school choice and kidney exchange, I systematically followed this approach in many other, often unusual real-world settings. In recent years, my efforts in minimalist market design led to the 2021 reform of the US Army’s branching system for its cadets to military specialties, the adoption of reserve systems during the Covid-19 pandemic for vaccine allocation in 15 states and therapies in 2 states, and the deployment of a highly efficient liver exchange system in Türkiye. This same methodology also predicted the rescission of a 1995 Supreme Court judgment in India, resulting in countless litigations and interruptions of public recruitment for 25 years, as well as the mandates of its replacement.
In this monograph, I describe the philosophy, evolution, and successful applications of minimalist market design, contrasting it with the mainstream paradigm for the field. In doing so, I also provide a paradigm for economists who want to influence policy and change institutions through their research.",[],[]
"The classical Canonical Correlation Analysis (CCA) identifies the correlations between two sets of multivariate variables based on their
covariance, which has been widely applied in diverse fields such as computer vision, natural language processing, and speech analysis. Despite its popularity, CCA can encounter challenges in explaining correlations between two variable sets within high-dimensional data contexts. Thus, this paper studies Sparse Canonical Correlation Analysis (SCCA) that enhances the interpretability of CCA. We first show that SCCA generalizes three well-known sparse optimization problems, sparse PCA, sparse SVD, and sparse regression, which are all classified as NP-hard problems. This result motivates us to develop strong formulations and efficient algorithms. Our main contributions include (i) the introduction of a combinatorial formulation that captures the essence of SCCA and allows the development of approximation algorithms; (ii) the derivation of an equivalent mixed-integer semidefinite programming model that facilitates a specialized branch-and-cut algorithm with analytical cuts; and (iii) the establishment of the complexity results for two low-rank special cases of SCCA. The effectiveness of our proposed formulations and algorithms is validated through numerical experiments.",[],[]
"New results are presented on a high-statistics measurement of Collins and Sivers asymmetries of charged hadrons produced in deep inelastic scattering of muons on a transversely polarised 66{}^{6}start_FLOATSUPERSCRIPT 6 end_FLOATSUPERSCRIPTLiD target.
The data were taken in 2022 with the COMPASS spectrometer using the 160 GeV muon beam at CERN, balancing the existing data
on transversely polarised proton targets.
The first results from about two-thirds of the new data have total
uncertainties smaller by up to a factor of three compared to
the previous deuteron measurements.
Using all the COMPASS proton and deuteron results, both the transversity and the Sivers distribution functions of the u𝑢uitalic_u and d𝑑ditalic_d quark, as well as the tensor charge
in the measured x𝑥xitalic_x-range are extracted. In particular, the accuracy of the d𝑑ditalic_d quark results is significantly improved.",[],[]
"Traves and Wehlau [9] recently gave a straightedge construction that checks whether 10 points lie on a plane cubic curve. They also highlighted several open problems in the synthetic geometry of cubics. Hermann Grassmann investigated incidence relations among points on cubic curves in three papers [4, 5, 6] appearing in Crelle’s Journal from 1846 to 1856. Grassmann’s methods give an alternative way to check whether 10 points lie on a cubic. Using Grassmann’s techniques, we solve the synthetic geometry problems introduced by Traves and Wehlau. In particular, we give straightedge constructions that find the intersection of a line with a cubic, find the tangent line to a cubic at a given point, and find the third point of intersection of this tangent line with the cubic. As well, given 5 points on a conic and a cubic and 4 additional points on the cubic, a straightedge construction is given that finds the sixth intersection point of the conic and the cubic. The paper ends with two open problems.",[],[]
"A sequence of operators Tnsubscript𝑇𝑛T_{n}italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT from a Hilbert space ℌℌ{\mathfrak{H}}fraktur_H
to Hilbert spaces 𝔎nsubscript𝔎𝑛{\mathfrak{K}}_{n}fraktur_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT
which is nondecreasing in the sense of contractive domination
is shown to have a limit which is still a linear operator T𝑇Titalic_T from ℌℌ{\mathfrak{H}}fraktur_H
to a Hilbert space 𝔎𝔎{\mathfrak{K}}fraktur_K.
Moreover, the closability or closedness of Tnsubscript𝑇𝑛T_{n}italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is preserved in the limit.
The closures converge likewise and the connection between the limits is investigated.
There is no similar way of dealing directly with linear relations.
However, the sequence of closures is still nondecreasing
and then the convergence is governed by
the monotonicity principle. There are some related results
for nonincreasing sequences.","['Domination of linear relations', 'nondecreasing sequences of linear relations in the sense\nof domination', 'monotonicity principle']",[]
,[],[]
"Medical imaging is an essential tool for diagnosing and treating diseases. However, lacking medical images can lead to inaccurate diagnoses and ineffective treatments. Generative models offer a promising solution for addressing medical image shortage problems due to their ability to generate new data from existing datasets and detect anomalies in this data.
Data augmentation with position augmentation methods like scaling, cropping, flipping, padding, rotation, and translation could lead to more overfitting in domains with little data, such as medical image data.
This paper proposes the GAN-GA, a generative model optimized by embedding a genetic algorithm. The proposed model enhances image fidelity and diversity while preserving distinctive features. The proposed medical image synthesis approach improves the quality and fidelity of medical images, an essential aspect of image interpretation. To evaluate synthesized images: Frechet Inception Distance (FID) is used. The proposed GAN-GA model is tested by generating Acute lymphoblastic leukemia (ALL) medical images, an image dataset, and is the first time to be used in generative models. Our results were compared to those of InfoGAN as a baseline model. The experimental results show that the proposed optimized GAN-GA enhances FID scores by about 6.8%, especially in earlier training epochs. The source code and dataset will be available at: https://github.com/Mustafa-AbdulRazek/InfoGAN-GA.","['Generative', 'Models', 'InfoGAN', 'Medical', 'Image', 'Generation', 'Genetic', 'Algorithms.']",[]
"The Multi-Agent Path Finding (MAPF) problem involves planning collision-free paths for multiple agents in a shared environment. The majority of MAPF solvers rely on the assumption that an agent can arrive at a specific location at a specific timestep. However, real-world execution uncertainties can cause agents to deviate from this assumption, leading to collisions and deadlocks. Prior research solves this problem by having agents follow a Temporal Plan Graph (TPG), enforcing a consistent passing order at every location as defined in the MAPF plan. However, we show that TPGs are overly strict because, in some circumstances, satisfying the passing order requires agents to wait unnecessarily, leading to longer execution time. To overcome this issue, we introduce a new graphical representation called a Bidirectional Temporal Plan Graph (BTPG), which allows switching passing orders during execution to avoid unnecessary waiting time. We design two anytime algorithms for constructing a BTPG: BTPG-naïve and BTPG-optimized. Experimental results show that following BTPGs consistently outperforms following TPGs, reducing unnecessary waits by 8-20%.",[],[]
,[],[]
"The chiral magnetic/vortical effect (CME/CVE)
in heavy-ion collisions probe the topological sector of Quantum Chromodynamics, where 𝒫𝒫\cal Pcaligraphic_P and 𝒞⁢𝒫𝒞𝒫\cal CPcaligraphic_C caligraphic_P symmetries are violated locally in strong interactions.
However, the experimental observables for the CME/CVE are dominated by backgrounds related to elliptic flow and nonflow.
We employ event shape variables to mitigate the flow background and event planes based on spectators to minimize the nonflow background.
We report on the CME search in Au+Au collisions at sNNsubscript𝑠NN\sqrt{s_{\rm NN}}square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 7.7, 14.6, 19.6, 27, and 200 GeV, as well as the CVE search at 19.6 and 27 GeV.",[],[]
,[],[]
"Heavy-ion collisions provide a unique opportunity to explore nucleon-hyperon (N-Y) interactions through two-particle correlations. The p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlations shed light on both N-Y two-body and N-N-Y three-body interactions, which is crucial for understanding neutron star properties. We present the high precision measurement of p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and the first measurement of d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlation with sNN=subscript𝑠NNabsent\sqrt{s_{{}_{\rm NN}}}=square-root start_ARG italic_s start_POSTSUBSCRIPT start_FLOATSUBSCRIPT roman_NN end_FLOATSUBSCRIPT end_POSTSUBSCRIPT end_ARG = 3 GeV Au+Au collisions at STAR. Using the Lednicky-Lyuboshitz formalism, we characterized emission source size, the scattering length (f0subscript𝑓0f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT), and the effective range (d0subscript𝑑0d_{0}italic_d start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) of p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ interactions. Using the f0subscript𝑓0f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and d0subscript𝑑0d_{0}italic_d start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT extracted from two spin states in d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlation, the parameters from the doublet state indicate the hypertriton binding energy is consistent with the current average of world measurements.",[],[]
"We propose a new way to explain and to visualize neural network classification through a decomposition-based explainable AI (DXAI).
Instead of providing an explanation heatmap, our method yields a decomposition of the image into class-agnostic and class-distinct parts, with respect to the data and chosen classifier. Following a fundamental signal processing paradigm of analysis and synthesis, the original image is the sum of the decomposed parts. We thus obtain a radically different way of explaining classification. The class-agnostic part ideally is composed of all image features which do not posses class information, where the class-distinct part is its complementary.
This new visualization can be more helpful and informative in certain scenarios, especially when the attributes are dense, global and additive in nature, for instance, when colors or textures are essential for class distinction. Code is available at https://github.com/dxai2024/dxai.",[],[]
"The Ginzburg-Landau (GL) theory is very successful in describing the pairing symmetry, a fundamental characterization of the broken symmetries in a paired superfluid or superconductor. However, GL theory does not describe fermionic excitations such as Bogoliubov quasiparticles or Andreev bound states that are directly related to topological properties of the superconductor. In this work, we show that the symmetries of the fermionic excitations are captured by a Projective Symmetry Group (PSG), which is a group extension of the bosonic symmetry group in the superconducting state. We further establish a correspondence between the pairing symmetry and the fermion PSG. When the normal and superconducting states share the same spin rotational symmetry, there is a simpler correspondence between the pairing symmetry and the fermion PSG, which we enumerate for all 32 crystalline point groups. We also discuss the general framework for computing PSGs when the spin rotational symmetry is spontaneously broken in the superconducting state. This PSG formalism leads to experimental consequences, and as an example, we show how a given pairing symmetry dictates the classification of topological superconductivity.",[],[]
"Kantorovich operators are non-linear extensions of Markov operators and are omnipresent in several branches of mathematical analysis. The asymptotic behaviour of their iterates plays an important role even in classical ergodic, potential and probability theories, which are normally concerned with linear Markovian operators, semi-groups, and resolvents.
The Kantorovich operators that appear implicitly in these cases, though non-linear, are all positively 1111-homogenous. General Kantorovich operators amount to assigning “a cost” to most operations on measures and functions normally conducted “for free” in these classical settings. Motivated by extensions of the Monge-Kantorovich duality in mass transport, the stochastic counterpart of Aubry-Mather theory for Lagrangian systems, weak KAM theory à la Fathi-Mather, and ergodic optimization of dynamical systems, we study the asymptotic properties of general Kantorovich operators.",[],[]
"A famous theorem in graph theory—originating with Euler—characterizes connected even-degree graphs
as (1) those graphs that admit an Euler tour, and (2) those connected graphs that decompose as a face-disjoint union of cycles.
We explore a 2-dimensional generalization of this theorem, with graphs (i.e., 1-complexes) replaced by
2-complexes. This entails an interesting generalization of cycles, and the introduction
of the notion of a “2-dimensional Euler tour.”",[],[]
"Approximate Bayesian computation (ABC) methods are standard tools for inferring parameters of complex models when the likelihood function is analytically intractable. A popular approach to improving the poor acceptance rate of the basic rejection sampling ABC algorithm is to use sequential Monte Carlo (ABC SMC) to produce a sequence of proposal distributions adapting towards the posterior, instead of generating values from the prior distribution of the model parameters. Proposal distribution for the subsequent iteration is typically obtained from a weighted set of samples, often called particles, of the current iteration of this sequence. Current methods for constructing these proposal distributions treat all the particles equivalently, regardless of the corresponding value generated by the sampler, which may lead to inefficiency when propagating the information across iterations of the algorithm. To improve sampler efficiency, we introduce a modified approach called stratified distance ABC SMC. Our algorithm stratifies particles based on their distance between the corresponding synthetic and observed data, and then constructs distinct proposal distributions for all the strata. Taking into account the distribution of distances across the particle space leads to substantially improved acceptance rate of the rejection sampling. We further show that efficiency can be gained by introducing a novel stopping rule for the sequential process based on the stratified posterior samples and demonstrate these advances by several examples.",[],"['Finland', 'Norway']"
"We treat some classes of stochastic partial differential equations of Schrödinger type within the framework of white noise analysis,
combined with Wiener-Itô chaos expansions and pseudodifferential operator methods. The initial data and potential term of the Schrödinger operator are assumed to be generalized stochastic processes that have spatial dependence. We prove that the equations under consideration have unique solutions in the appropriate (intersections of
weighted) Sobolev-Kato-Kondratiev spaces.","['Stochastic partial differential equations', 'Wick product', 'Chaos expansions', 'Schrödinger equation', 'pseudodifferential calculus']",[]
"Two quantum algorithms are presented for the numerical solution of a linear one-dimensional advection-diffusion equation with periodic boundary conditions. Their accuracy and performance with increasing qubit number are compared point-by-point with each other. Specifically, we solve the linear partial differential equation with a Quantum Linear Systems Algorithms (QLSA) based on the Harrow–Hassidim–Lloyd method and a Variational Quantum Algorithm (VQA), for resolutions that can be encoded using up to 6 qubits, which corresponds to N=64𝑁64N=64italic_N = 64 grid points on the unit interval. Both algorithms are of hybrid nature, i.e., they involve a combination of classical and quantum computing building blocks. The QLSA and VQA are solved as ideal statevector simulations using the in-house solver QFlowS and open-access Qiskit software, respectively. We discuss several aspects of both algorithms which are crucial for a successful performance in both cases. These are the sizes of an additional quantum register for the quantum phase estimation for the QLSA and the choice of the algorithm of the minimization of the cost function for the VQA. The latter algorithm is also implemented in the noisy Qiskit framework including measurement and decoherence circuit noise. We reflect the current limitations and suggest some possible routes of future research for the numerical simulation of classical fluid flows on a quantum computer.",[],[]
,[],[]
,[],[]
"Traffic from distributed training of machine learning (ML) models makes up a large and growing fraction of the traffic mix in enterprise data centers. While work on distributed ML abounds, the network traffic generated by distributed ML has received little attention.
Using measurements on a testbed network, we investigate the traffic characteristics
generated by the training of the ResNet-50 neural network
with an emphasis on studying its short-term burstiness.
For the latter we propose metrics that
quantify traffic burstiness at different time scales.
Our analysis reveals that distributed ML traffic exhibits a very high degree of burstiness on
short time scales, exceeding a 60:1 peak-to-mean ratio on time intervals as long as 5 ms. We observe that training software orchestrates
transmissions in such a way that burst transmissions from different sources
within the same application do not result
in congestion and packet losses.
An extrapolation of the measurement data to multiple applications
underscores the challenges of distributed ML traffic
for congestion and flow control algorithms.",[],[]
"In this work, we consider the offline preference-based reinforcement learning problem. We focus on the two-phase learning approach that is prevalent in previous reinforcement learning from human preference works. We find a challenge in applying two-phase learning in the offline PBRL setting that the learned utility model can be too hard for the learning agent to optimize during the second learning phase. To overcome the challenge, we propose a two-phasing learning approach under behavior regularization through action clipping. The insight is that the state-actions which are poorly covered by the dataset can only provide limited information and increase the complexity of the problem in the second learning phase. Our method ignores such state-actions during the second learning phase to achieve higher learning efficiency. We empirically verify that our method has high learning efficiency on a variety of datasets in robotic control environments.",[],[]
"This paper presents an efficient coupling of the 3D Stokes flow interacting with an effective perforated periodic heterogeneous anisotropic 2D plate. The effective model was obtained by the asymptotic analysis in earlier works and here an effective numerical algorithm is given. By Q3subscript𝑄3Q_{3}italic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT or bi-cubic spacial interpolation the time-dependent problem was reduced to an algebraic system of ordinary differential equation in time. Different examples were given, demonstrating the influence of the structural plate parameters on the solution.",[],[]
"We construct various statistical ensembles associated to the 3D Euler equations and prove global regularity of these equations for data living on these sets. Similar results are also proven for generalized SQG equations and some shell models. Qualitative properties of the ensembles and the constructed flows are also given.


Keywords: 3D Euler equation, SQG equations, shell models, global regularity, invariant measure, long time behavior, fluctuation-dissipation, statistical ensemble.

2020 MSC: 35B40, 35B44, 35B65, 35Q31, 35Q35,
76D03.",[],[]
"In the literature, lines of the projective space PG⁢(3,q)PG3𝑞\mathrm{PG}(3,q)roman_PG ( 3 , italic_q ) are partitioned into classes, each of which is a union of line orbits under the stabilizer group of the twisted cubic. The least studied class is named 𝒪6subscript𝒪6\mathcal{O}_{6}caligraphic_O start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT. This class contains lines external to the twisted cubic which are not its chords or axes and do not lie in any of its osculating planes. For even and odd q𝑞qitalic_q, we propose a new family of orbits of 𝒪6subscript𝒪6\mathcal{O}_{6}caligraphic_O start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and investigate in detail their stabilizer groups and the corresponding submatrices of the point-line and plane-line incidence matrices. To obtain these submatrices, we explored the number of solutions of cubic and quartic equations connected with intersections of lines (including the tangents to the twisted cubic), points, and planes in PG⁢(3,q)PG3𝑞\mathrm{PG}(3,q)roman_PG ( 3 , italic_q ).",[],[]
"This work focuses on plant leaf disease classification and explores three crucial aspects: adversarial training, model explainability, and model compression. The models’ robustness against adversarial attacks is enhanced through adversarial training, ensuring accurate classification even in the presence of threats. Leveraging explainability techniques, we gain insights into the model’s decision-making process, improving trust and transparency. Additionally, we explore model compression techniques to optimize computational efficiency while maintaining classification performance. Through our experiments, we determine that on a benchmark dataset, the robustness can be the price of the classification accuracy with performance reductions of 3%-20% for regular tests and gains of 50%-70% for adversarial attack tests. We also demonstrate that a student model can be 15-25 times more computationally efficient for a slight performance reduction, distilling the knowledge of more complex models.",[],[]
,[],[]
"We compute a nonperturbative effective potential between two static fermions in
light-front Yukawa theory as a Hamiltonian eigenvalue problem.
Fermion pair production is suppressed, to make
possible an exact analytic solution in the form of a coherent state of
bosons that form clouds around the sources. The effective potential is
essentially an interference term between individual clouds. The model
is regulated with Pauli-Villars bosons and fermions, to achieve
consistent quantization and renormalization of masses and couplings.
This extends earlier work on scalar Yukawa theory where Pauli-Villars
regularization did not play a central role. The key result is that
the nonperturbative solution restores rotational symmetry even though
the light-front formulation of Yukawa theory, with its preferred axis,
appears antithetical to such a symmetry.",[],[]
"Let Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be positive definite matrices for every i=1,⋯,m.𝑖1⋯𝑚i=1,\cdots,m.italic_i = 1 , ⋯ , italic_m . Let Z=[Zi⁢j]𝑍delimited-[]subscript𝑍𝑖𝑗Z=[Z_{ij}]italic_Z = [ italic_Z start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ] be the block matrix, where Zi⁢j=Bi12⁢(∑k=1mAk)⁢Bj12subscript𝑍𝑖𝑗superscriptsubscript𝐵𝑖12superscriptsubscript𝑘1𝑚subscript𝐴𝑘superscriptsubscript𝐵𝑗12Z_{ij}=B_{i}^{{}^{\frac{1}{{}_{2}}}}\left(\displaystyle\sum_{k=1}^{m}A_{k}%
\right)B_{j}^{{}^{\frac{1}{{}_{2}}}}italic_Z start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT for every i,j=1,⋯,mformulae-sequence𝑖𝑗1⋯𝑚i,j=~{}1,\cdots,mitalic_i , italic_j = 1 , ⋯ , italic_m. It is shown that



‖|∑i=1m(Ais⁢♯⁢Bis)r|‖≤‖|Zs⁢r2|‖≤‖|((∑i=1mAi)s⁢r⁢p4⁢(∑i=1mBi)s⁢r⁢p2⁢(∑i=1mAi)s⁢r⁢p4)1p|‖,normsuperscriptsubscript𝑖1𝑚superscriptsuperscriptsubscript𝐴𝑖𝑠♯superscriptsubscript𝐵𝑖𝑠𝑟normsuperscript𝑍𝑠𝑟2normsuperscriptsuperscriptsuperscriptsubscript𝑖1𝑚subscript𝐴𝑖𝑠𝑟𝑝4superscriptsuperscriptsubscript𝑖1𝑚subscript𝐵𝑖𝑠𝑟𝑝2superscriptsuperscriptsubscript𝑖1𝑚subscript𝐴𝑖𝑠𝑟𝑝41𝑝\left|\left|\left|\sum_{i=1}^{m}\left(A_{i}^{s}\sharp B_{i}^{s}\right)^{r}%
\right|\right|\right|\leq\left|\left|\left|Z^{{}^{\frac{sr}{{}_{2}}}}\right|%
\right|\right|\leq\left|\left|\left|\left(\left(\scalebox{0.85}{$\displaystyle%
\sum_{i=1}^{m}A_{i}$}\right)^{\frac{srp}{{}_{4}}}\left(\scalebox{0.85}{$%
\displaystyle\sum_{i=1}^{m}B_{i}$}\right)^{\frac{srp}{{}_{2}}}\left(\scalebox{%
0.85}{$\displaystyle\sum_{i=1}^{m}A_{i}$}\right)^{\frac{srp}{{}_{4}}}\right)^{%
\frac{1}{{}_{p}}}\right|\right|\right|,| | | ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ♯ italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT | | | ≤ | | | italic_Z start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG italic_s italic_r end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT | | | ≤ | | | ( ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT italic_p end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT | | | ,



for all s≥2𝑠2s\geq 2italic_s ≥ 2, for all p>0𝑝0p>0italic_p > 0 and r≥1𝑟1r\geq 1italic_r ≥ 1 such that r⁢p≥1𝑟𝑝1rp\geq 1italic_r italic_p ≥ 1 and for all unitarily invariant norms.
This result generalizes the results in [8] and gives an affirmative answer to a conjecture in [9] for all s≥2𝑠2s\geq 2italic_s ≥ 2 and for all p>0𝑝0p>0italic_p > 0 and r≥1𝑟1r\geq 1italic_r ≥ 1 such that r⁢p≥1𝑟𝑝1rp\geq 1italic_r italic_p ≥ 1 and t=12𝑡12t=\frac{1}{2}italic_t = divide start_ARG 1 end_ARG start_ARG 2 end_ARG.
This result also leads directly to Dinh, Ahsani, and Tam’s conjecture in [1] and proves Audenaert’s result in [2].","['Unitarily invariant norm', 'positive semidefinite matrix', 'Bourin’s question', 'inequality.']",[]
,[],[]
"Along the lines of the Einstein-Rosen wave equation of General Relativity (GR), we derive a gravitational wave equation with cylindrical symmetry in the Einstein-aether (EA) theory. We show that the gravitational wave in the EA is periodic in time for both the metric functions Ψ⁢(r,t)Ψ𝑟𝑡\Psi(r,t)roman_Ψ ( italic_r , italic_t ) and H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ). However, in GR, Ψ⁢(r,t)Ψ𝑟𝑡\Psi(r,t)roman_Ψ ( italic_r , italic_t ) is periodic in time, but H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ) is semi-periodic in time, having a secular drifting in the wave frequency. The evolution of wave pulses of a given width is entirely different in both theories in the H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ) metric function due to this frequency drifting. Another fundamental difference between the two theories is the gravitational wave velocity. While in GR, the waves propagate with the speed of light, in EA, there is no upper limit to the wave velocity, reaching infinity if c13→1→subscript𝑐131c_{13}\rightarrow 1italic_c start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT → 1 and zero if c13→−∞→subscript𝑐13c_{13}\rightarrow-\inftyitalic_c start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT → - ∞. We also show that energy-momentum pseudotensor and superpotential get contributions from aether in addition to the usual gravitational field part. All these characteristics are observational signatures that differentiate GR and EA.",[],[]
"We present the notion of non-abelian descent type, which classifies torsors up to twisting by a Galois cocycle. This relies on the previous construction of kernels and non-abelian Galois 2-cohomology due to Springer and Borovoi. The necessity of descent types arises in the context of the descent theory where no torsors are given a priori, for example, when we wish to study the arithmetic properties such as the Brauer–Manin obstruction to the Hasse principle on homogeneous spaces without rational points. This new definition also unifies the types by Colliot-Thélène–Sansuc, the extended types by Harari–Skorobogatov, and the finite descent type by Harpaz–Wittenberg.",[],[]
"This is a survey of the recent results and unsolved problems about locally compact homogeneous metric spaces. Mostly, homogeneous finite-dimensional A⁢N⁢R𝐴𝑁𝑅ANRitalic_A italic_N italic_R-spaces are discussed.","['absolute neighborhood retracts', 'cohomological dimension', 'cohomology and homology groups', 'homogeneous spaces']",[]
"This paper studies a discrete-time version of the Lucas-Uzawa endogenous growth model with physical and human capital. Equilibrium existence is proved applying tools of dynamic programming with unbounded returns. The proofs rely on properties of homogeneous functions and also apply well-known inequalities in real analysis, seldom used in the literature, which significantly simplifies the task of verifying certain assumptions that are rather technical in nature.
Keywords: Endogenous Growth, Equilibrium, Human capital, Dynamic Programming

JEL Classification: C61, C63, O41",[],['Argentina']
"The accuracy of 3D Human Pose and Shape reconstruction (HPS) from an image is progressively improving. Yet, no known method is robust across all image distortion. To address issues due to variations of camera poses, we introduce SHARE, a novel fine-tuning method that utilizes adversarial data augmentation to enhance the robustness of existing HPS techniques.
We perform a comprehensive analysis on the impact of camera poses on HPS reconstruction outcomes. We first generated large-scale image datasets captured systematically from diverse camera perspectives. We then established a mapping between camera poses and reconstruction errors as a continuous function that characterizes the relationship between camera poses and HPS quality. Leveraging this representation, we introduce RoME (Regions of Maximal Error), a novel sampling technique for our adversarial fine-tuning method.
The SHARE framework is generalizable across various single-view HPS methods and we demonstrate its performance on HMR, SPIN, PARE, CLIFF and ExPose. Our results illustrate a reduction in mean joint errors across single-view HPS techniques, for images captured from multiple camera positions without compromising their baseline performance. In many challenging cases, our method surpasses the performance of existing models, highlighting its practical significance for diverse real-world applications.",[],[]
"Over the past decade, characterizing the exact asymptotic risk of regularized estimators in high-dimensional regression has emerged as a popular line of work. This literature considers the proportional asymptotics framework, where the number of features and samples both diverge, at a rate proportional to each other. Substantial work in this area relies on Gaussianity assumptions on the observed covariates. Further, these studies often assume the design entries to be independent and identically distributed. Parallel research investigates the universality of these findings, revealing that results based on the i.i.d. Gaussian assumption extend to a broad class of designs, such as i.i.d. sub-Gaussians. However, universality results examining dependent covariates so far focused on correlation-based dependence or a highly structured form of dependence, as permitted by right rotationally invariant designs. In this paper, we break this barrier and study a dependence structure that in general falls outside the purview of these established classes. We seek to pin down the extent to which results based on i.i.d. Gaussian assumptions persist. We identify a class of designs characterized by a block dependence structure that ensures the universality of i.i.d. Gaussian-based results. We establish that the optimal values of the regularized empirical risk and the risk associated with convex regularized estimators, such as the Lasso and ridge, converge to the same limit under block dependent designs as they do for i.i.d. Gaussian entry designs.
Our dependence structure differs significantly from correlation-based dependence, and enables, for the first time, asymptotically exact risk characterization in prevalent nonparametric regression problems in high dimensions. Finally, we illustrate through experiments that this universality becomes evident quite early, even for relatively moderate sample sizes.",[],[]
"We construct a 3333-dimensional cell complex that is the 3333-skeleton for an Eilenberg–MacLane classifying space for the symmetric group 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT.
Our complex starts with the presentation for 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT with n−1𝑛1n-1italic_n - 1 adjacent transpositions with squaring, commuting, and braid relations, and adds seven classes of 3333-cells that fill in certain 2222-spheres bounded by these relations.
We use a rewriting system and a combinatorial method of K. Brown to prove the correctness of our construction.
Our main application is a computation of the second cohomology of 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT in certain twisted coefficient modules; we use this computation in a companion paper to study splitting of extensions related to braid groups.
As another application, we give a concrete description of the third homology of 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT with untwisted coefficients in ℤℤ\mathbb{Z}blackboard_Z.",[],[]
"The advancements in nanotechnology, material science, and electrical engineering have shrunk the sizes of electronic devices down to the micro/nanoscale.
This brings the opportunity of developing the Internet of Nano Things (IoNT), an extension of the Internet of Things (IoT).
With nanodevices, numerous new possibilities emerge in the biomedical, military fields, and industrial products.
However, a continuous energy supply is needed for these devices to work.
At the micro/nanoscale, batteries cannot supply this demand due to size limitations and the limited energy contained in the batteries.
Internet of Harvester Nano Things (IoHNT), a concept of Energy Harvesting (EH), which converts the existing different energy sources, which otherwise would be dissipated to waste, into electrical energy via electrical generators.
Sources for EH are abundant, from sunlight, sound, water, and airflow to living organisms.
IoHNT methods are significant assets to ensure the proper operation of the IoNT; thus, in this review, we comprehensively investigate the most useful energy sources and IoHNT principles to power the nano/micro-scaled electronic devices with the scope of IoNT. We discuss the IoHNT principles, material selections, challenges, and state-of-the-art applications of each energy source for both in-vivo and in vitro applications.
Finally, we present the latest challenges of EH along with future research directions to solve the problems regarding constructing continuous IoNT containing various self-powered nanodevices.
Therefore, IoHNT represents a significant shift in nanodevice power supply, leading us towards a future where wireless technology is widespread.
Hence, it will motivate researchers to envision and contribute to the advancement of the following power revolution in IoNT, providing unmatched simplicity and efficiency.","['Energy harvesting', 'Energy scavenging', 'Hybrid', 'Energy', 'Harvesting', 'IoT', 'IoNT', 'Nanodevices', 'Nanogenerators.']",[]
"This work deals with undirected graphs that have the same betweenness centrality for each vertex,
so-called betweenness uniform graphs (or BUGs). The class of these graphs is not trivial and its
classification is still an open problem. Recently, Gago, Coroničová-Hurajová and Madaras conjectured
that for every rational α≥3/4𝛼34\alpha\geq 3/4italic_α ≥ 3 / 4 there exists a BUG having betweenness
centrality α𝛼\alphaitalic_α. We disprove this conjecture, and provide an alternative view of the
structure of betweenness-uniform graphs from the point of view of their complement. This allows
us to characterise all the BUGs with betweennes centrality at most 9/10, and show that their
betweenness centrality is equal to ℓℓ+1ℓℓ1\frac{\ell}{\ell+1}divide start_ARG roman_ℓ end_ARG start_ARG roman_ℓ + 1 end_ARG for some integer ℓ≤9ℓ9\ell\leq 9roman_ℓ ≤ 9. We
conjecture that this characterization extends to all the BUGs with betweenness centrality smaller
than 1.",[],[]
,[],[]
"We consider normal subgroups N𝑁Nitalic_N of the braid group Bnsubscript𝐵𝑛B_{n}italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that the quotient Bn/Nsubscript𝐵𝑛𝑁B_{n}/Nitalic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT / italic_N is an extension of the symmetric group by an abelian group.
We show that, if n≥4𝑛4n\geq 4italic_n ≥ 4, then there are exactly 8888 commensurability classes of such subgroups.
We define a Specht subgroup to be a subgroup of this form that is maximal in its commensurability class.
We give descriptions of the Specht subgroups in terms of winding numbers and in terms of infinite generating sets.
The quotient of the pure braid group by a Specht subgroup is a module over the symmetric group.
We show that the modules arising this way are closely related to Specht modules for the partitions (n−1,1)𝑛11(n-1,1)( italic_n - 1 , 1 ) and (n−2,2)𝑛22(n-2,2)( italic_n - 2 , 2 ), working over the integers.
We compute the second cohomology of the symmetric group with coefficients in both of these Specht modules, working over an arbitrary commutative ring.
Finally, we determine which of the extensions of the symmetric group arising from Specht subgroups are split extensions.",[],[]
,[],[]
"We investigate the behavior of the empirical neighbourhood distribution of marked graphs in the framework of local weak convergence. We establish a large deviation principle for such families of empirical measures. The proof builds on Bordenave and Caputo’s seminal 2015 paper, and Delgosha and Anantharam’s 2019 introduction of BC entropy, relying on combinatorial lemmas that allow one to construct suitable approximations of measures supported on marked trees.

Keywords and phrases: large deviations, local topology, sparse random graphs. 
MSC 2010: 60F10, 05C80.",[],[]
"We study inflation driven by the tachyon field in the holographic braneworld by assuming the second slow-roll parameter η𝜂\etaitalic_η is constant. The parameter η𝜂\etaitalic_η can be either defined by the tachyon scalar field and the Hubble parameter or by the Hubble parameter only. By assuming a constant η𝜂\etaitalic_η, we derive and numerically solve a differential equation for the Hubble expansion rate. We calculate numerically the scalar spectral index and the tensor-to-scalar ratio. We confront the results with the observational data and find some constraints on the free model parameters. The swampland conjectures are discussed in the context of the constant-roll inflation, with some accent on the holographic model.",[],"['Croatia', 'Serbia']"
,[],[]
"This study focuses on the estimation of the Emax dose-response model, a widely utilized framework in clinical trials, agriculture, and environmental experiments. Existing challenges in obtaining maximum likelihood estimates (MLE) for model parameters are often ascribed to computational issues but, in reality, stem from the absence of MLE. Our contribution provides a new understanding and control of all the experimental situations that pratictioners might face, guiding them in the estimation process.
We derive the exact MLE for a three-point experimental design and we identify the two scenarios where the MLE fails. To address these challenges, we propose utilizing Firth’s modified score, providing its analytical expression as a function of the experimental design. Through a simulation study, we demonstrate that, in one of the problematic cases, the Firth modification yields a finite estimate. For the remaining case, we introduce a design-correction strategy akin to a hypothesis test.","['nonlinear regression', 'Emax model', 'maximum likelihood', 'experimental design', 'small sample', 'score modification', 'optimal design']",[]
"This paper develops a stochastic and unifying framework to examine variability in car-following (CF) dynamics of commercial automated vehicles (AVs) and its direct relation to traffic-level dynamics. The asymmetric behavior (AB) model by Chen et al. (2012a) is extended to accommodate a range of CF behaviors by AVs and compare with the baseline of human-driven vehicles (HDVs). The parameters of the extended AB (EAB) model are calibrated using an adaptive sequential Monte Carlo method for Approximate Bayesian Computation (ABC-ASMC) to stochastically capture various uncertainties including model mismatch resulting from unknown AV CF logic. The estimated posterior distributions of the parameters reveal significant differences in CF behavior (1) between AVs and HDVs, and (2) across AV developers, engine modes, and speed ranges, albeit to a lesser degree. The estimated behavioral patterns and simulation experiments further reveal mixed platoon dynamics in terms of traffic throughout reduction and hysteresis.",[],[]
"Agency is an important human characteristic that users of automated complex technologies are usually denied.
This affects the user’s experience leading to decreased satisfaction and productivity.
In this paper, we consider the ridesharing context and interviewed 7 drivers to understand the controls that would improve the agency they feel.
The results show that they desire transparency, community and an effective ability to seek redress.","['User', 'Agency', 'Ridesharing']",[]
"In this review, we detail the commonality of mathematical intuitions that underlie three numerical methods used for the quantitative description of electron swarms propagating in a gas under the effect of externally applied electric and/or magnetic fields.
These methods can be linked to the integral transport equation, following a common thread much better known in the theory of neutron transport than in the theory of electron transport. First, we discuss the exact solution of the electron transport problem using Monte Carlo (MC) simulations. In reality we will progress much further, showing the interpretative role that the diagrams used in quantum theory and quantum field theory can play in the development of MC. Then, we present two methods, the Monte Carlo Flux and the Propagator method, which have been developed at this moment. The first one is based on a modified MC method, while the second shows the advantage of explicitly applying the mathematical idea of propagator to the transport problem.",[],[]
,[],[]
"Degeneracy plays an important role in understanding Turán- and Ramsey-type properties of graphs. Unfortunately, the usual hypergraphical generalization of degeneracy fails to capture these properties. We define the skeletal degeneracy of a k𝑘kitalic_k-uniform hypergraph as the degeneracy of its 1111-skeleton (i.e., the graph formed by replacing every k𝑘kitalic_k-edge by a k𝑘kitalic_k-clique). We prove that skeletal degeneracy controls hypergraph Turán and Ramsey numbers in a similar manner to (graphical) degeneracy.
Specifically, we show that k𝑘kitalic_k-uniform hypergraphs with bounded skeletal degeneracy have linear Ramsey number. This is the hypergraph analogue of the Burr–Erdős conjecture (proved by Lee). In addition, we give upper and lower bounds of the same shape for the Turán number of a k𝑘kitalic_k-uniform k𝑘kitalic_k-partite hypergraph in terms of its skeletal degeneracy. The proofs of both results use the technique of dependent random choice. In addition, the proof of our Ramsey result uses the ‘random greedy process’ introduced by Lee in his resolution of the Burr–Erdős conjecture.",[],[]
"We have built and operated a cryogenic Penning trap arrangement that allows for the efficient production, selection, and long-term storage of highly charged atomic ions. In close similarity to an electron-beam ion trap (EBIT) it works by electron-impact ionisation of atoms inside a dedicated confinement region. The electrons are produced by field emission at liquid-helium temperature and are subsequently accelerated to the keV energy range. The electron beam is reflected through the trap multiple times to increase the ionisation efficiency. We show a characterisation of the system and measurements with argon and tungsten ions up to Ar16+limit-from16{}^{16+}start_FLOATSUPERSCRIPT 16 + end_FLOATSUPERSCRIPT and W27+limit-from27{}^{27+}start_FLOATSUPERSCRIPT 27 + end_FLOATSUPERSCRIPT, respectively.",[],[]
"In this work, we study the effects of random temperature fluctuations on the equation of state of a non-interacting, relativistic fermion gas by means of the replica method. This picture provides a conceptual model for a non-equilibrium system, depicted as an ensemble of subsystems at different temperatures, randomly distributed with respect to a given mean value.
We then assume the temperature displays stochastic fluctuations T=T0+δ⁢T𝑇subscript𝑇0𝛿𝑇T=T_{0}+\delta Titalic_T = italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_δ italic_T with respect to its ensemble average value T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, with zero mean δ⁢T¯=0¯𝛿𝑇0\overline{\delta T}=0over¯ start_ARG italic_δ italic_T end_ARG = 0 and standard deviation δ⁢T2¯=Δ¯𝛿superscript𝑇2Δ\overline{\delta T^{2}}=\Deltaover¯ start_ARG italic_δ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = roman_Δ. By means of the replica method, we obtain the average grand canonical potential, leading to the equation of state of the fermion gas expressed in terms of the excess pressure caused by these fluctuations with respect to the ideal gas at uniform temperature. We further extend our results for the ideal Bose gas as well. Our findings reveal an increase in pressure as the system’s ensemble average temperature T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT rises, consistently exceeding the pressure observed in an equilibrium state. Finally, we explore the implications for the deconfinement transition in the context of the simple Bag model, where we show that the critical temperature decreases.",[],['Chile']
"A vertex in a graph is said to be sedentary if a quantum state assigned on that vertex tends to stay on that vertex. Under mild conditions, we show that the direct product and join operations preserve vertex sedentariness. We also completely characterize sedentariness in blow-up graphs. These results allow us to construct new infinite families of graphs with sedentary vertices. We prove that a vertex with a twin is either sedentary or admits pretty good state transfer. Moreover, we give a complete characterization of twin vertices that are sedentary, and provide sharp bounds on their sedentariness. As an application, we determine the conditions in which perfect state transfer, pretty good state transfer and sedentariness occur in complete bipartite graphs and threshold graphs of any order.",[],[]
"Integer or fractional quantum Hall crystals, states postulating the coexistence of charge order with integer or fractional quantum Hall effect, have long been proposed in theoretical studies in Landau levels Kivelson et al. (1986); Halperin et al. (1986); Tešanović et al. (1989); Balents (1996); Fradkin and Kivelson (1999); Murthy (2000a). Inspired by recent experiments on integer or fractional quantum anomalous Hall (IQAH/FQAH) states in MoTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCai et al. (2023); Park et al. (2023); Zeng et al. (2023); Xu et al. (2023a) and rhombohedral multilayer graphene Lu et al. (2023a), this work examines the archetypal correlated flat band model on a checkerboard lattice at filling ν=2/3𝜈23\nu=2/3italic_ν = 2 / 3.
Interestingly, at this filling level, we find that this topological flatband does not stabilize conventional FQAH states. Instead, the unique interplay between smectic charge order and topological order gives rise to two intriguing quantum states. As the interaction strength increases, the system first transitions from a Fermi liquid into FQAH smectic (FQAHS) states, where FQAH topological order coexists cooperatively with smectic charge order. With a further increase in interaction strength, the system undergoes another quantum phase transition and evolves into a polar smectic metal. Contrary to conventional smectic order and FQAHS states, this gapless state spontaneously breaks the two-fold rotational symmetry, resulting in a nonzero electric dipole moment and ferroelectric order.
In addition to identifying the ground states, large-scale numerical simulations are also used to study low-energy excitations and thermodynamic characteristics. We find that FQAHS states exhibit two distinct temperature scales: the onset of charge order and the onset of the fractional Hall plateau, respectively. Interestingly, the latter is dictated by charge-neutral low-energy excitations with finite momenta, known as magnetorotons. Our studies suggest that these nontrivial phenomena could, in principle, be accessed in future experiments with moiré systems.",[],['China']
,[],[]
"Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on image datasets show that HQ-VAE enhances codebook usage and improves reconstruction performance. We also validated HQ-VAE in terms of its applicability to a different modality with an audio dataset.",[],[]
,[],[]
"In this note, we discuss the extension of several important stable square matrices, e.g., D-stable matrices, diagonal dominance matrices, Volterra-Lyapunov stable matrices, to their corresponding non-square matrices. The extension is motivated by some distributed control-related problems, such as decentralized unconditional stability and decentralized integral controllability for non-square processes. We will provide the connections of conditions between these special square matrices and their associated non-square counterparts. Some conjectures for these special matrices are proposed for future research.",[],[]
"In this paper,
we introduce a novel and simple method for obtaining high-quality text embeddings
using only synthetic data and less than 1111k training steps.
Unlike existing methods that often depend on multi-stage intermediate pre-training
with billions of weakly-supervised text pairs,
followed by fine-tuning with a few labeled datasets,
our method does not require building complex training pipelines
or relying on manually collected datasets that are often constrained by task diversity and language coverage.
We leverage proprietary LLMs to generate diverse synthetic data
for hundreds of thousands of text embedding tasks across nearly 100100100100 languages.
We then fine-tune open-source decoder-only LLMs on the synthetic data using standard contrastive loss.
Experiments demonstrate that our method achieves strong performance on highly competitive text embedding benchmarks
without using any labeled data.
Furthermore, when fine-tuned with a mixture of synthetic and labeled data,
our model sets new state-of-the-art results on the BEIR and MTEB benchmarks.",[],[]
"This paper explores the impact of biologically plausible neuron models on the performance of Spiking Neural Networks (SNNs) for regression tasks. While SNNs are widely recognized for classification tasks, their application to Scientific Machine Learning and regression remains underexplored. We focus on the membrane component of SNNs, comparing four neuron models: Leaky Integrate-and-Fire, FitzHugh–Nagumo, Izhikevich, and Hodgkin-Huxley. We investigate their effect on SNN accuracy and efficiency for function regression tasks, by using Euler and Runge-Kutta 4th-order approximation schemes. We show how more biologically plausible neuron models improve the accuracy of SNNs while reducing the number of spikes in the system. The latter represents an energetic gain on actual neuromorphic chips since it directly reflects the amount of energy required for the computations.","['Spiking', 'Neural', 'Networks', 'LIF model', 'FitzHugh-Nagumo model', 'Izhikevich model', 'Hodgkin-Huxley model', 'Regression', 'Scientific', 'Machine', 'Learning']",[]
"Recent image restoration methods can be broadly categorized into two classes: (1) regression methods that recover the rough structure of the original image without synthesizing high-frequency details and (2) generative methods that synthesize perceptually-realistic high-frequency details even though the resulting image deviates from the original structure of the input.
While both directions have been extensively studied in isolation, merging their benefits with a single framework has been rarely studied.
In this paper, we propose UGPNet, a universal image restoration framework that can effectively achieve the benefits of both approaches by simply adopting a pair of an existing regression model and a generative model.
UGPNet first restores the image structure of a degraded input using a regression model and synthesizes a perceptually-realistic image with a generative model on top of the regressed output.
UGPNet then combines the regressed output and the synthesized output, resulting in a final result that faithfully reconstructs the structure of the original image in addition to perceptually-realistic textures.
Our extensive experiments on deblurring, denoising, and super-resolution demonstrate that UGPNet can successfully exploit both regression and generative methods for high-fidelity image restoration.",[],[]
,[],[]
"We study the quench dynamics of a two dimensional superconductor in a lattice of size up to 200×200200200200\times 200200 × 200 employing the self-consistent time dependent Bogoliubov-de Gennes (BdG) formalism. In the clean limit, the dynamics of the order parameter for short times, characterized by a fast exponential growth and an oscillatory pattern, agrees with the Bardeen-Cooper-Schrieffer (BCS) prediction. However, unlike BCS, we observe for longer times an universal exponential decay of these time oscillations that we show explicitly
to be induced by the full emergence of spatial inhomogeneities of the order parameter, even in the clean limit, characterized by the exponential growth of its variance.
The addition of a weak disorder does not alter these results qualitatively.
In this region, the spatial inhomogeneities rapidly develops into an intricate spatial structure consisting of ordered fragmented stripes in perpendicular directions where the order parameter is heavily suppressed especially in the central region.
As the disorder strength increases, the fragmented stripes gradually turn into a square lattice of approximately circular spatial regions where the condensate is heavily suppressed. A further increase of disorder leads to the deformation and ultimate destruction of this lattice.
We explore suitable settings for the experimental confirmation of these findings.",[],['China']
"With the expanding reach of physics, xenon-based detectors such as PandaX-4T in the China Jinping Underground Laboratory aim to cover an energy range from sub-keV to multi-MeV.
A linear response of the photomultiplier tubes (PMTs) is required for both scintillation and electroluminescence signals.
Through a dedicated bench test, we investigated the cause of the non-linear response in the Hamamatsu R11410-23 PMTs used in PandaX-4T.
The saturation and suppression of the PMT waveform observed during the commissioning of PandaX-4T were caused by the high-voltage divider base.
The bench test data validated the de-saturation algorithm used in the PandaX-4T data analysis.
We also confirmed the improvement in linearity of a new PMT base design, which will be used to upgrade the PMT readout system in PandaX-4T.",[],[]
"We propose EMAGE, a framework to generate full-body human gestures from audio and masked gestures, encompassing facial, local body, hands, and global movements. To achieve this, we first introduce BEATX (BEAT-SMPLX-FLAME), a new mesh-level holistic co-speech dataset. BEATX combines MoShed SMPLX body with FLAME head parameters and further refines the modeling of head, neck, and finger movements, offering a community-standardized, high-quality 3D motion captured dataset.
EMAGE leverages masked body gesture priors during training to boost inference performance. It involves a Masked Audio Gesture Transformer, facilitating joint training on audio-to-gesture generation and masked gesture reconstruction to effectively encode audio and body gesture hints. Encoded body hints from masked gestures are then separately employed to generate facial and body movements.
Moreover, EMAGE adaptively merges speech features from the audio’s rhythm and content and utilizes four compositional VQ-VAEs to enhance the results’ fidelity and diversity. Experiments demonstrate that EMAGE generates holistic gestures with state-of-the-art performance and is flexible in accepting predefined spatial-temporal gesture inputs, generating complete, audio-synchronized results. Our code and dataset are available111https://pantomatrix.github.io/EMAGE/.",[],[]
,[],[]
"We investigate the magnetic excitations of the trimerized Heisenberg models with intra-trimer interaction J1subscript𝐽1J_{1}italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and inter-trimer interaction J2subscript𝐽2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT on four different two-dimensional lattices using a combination of stochastic series expansion quantum Monte Carlo (SSE QMC) and stochastic analytic continuation methods (SAC), complemented by cluster perturbation theory (CPT). These models exhibit quasi-particle-like excitations when g=J2/J1𝑔subscript𝐽2subscript𝐽1g=J_{2}/J_{1}italic_g = italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT / italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is small, characterized by low-energy magnons, intermediate-energy doublons, and high-energy quartons. The low-energy magnons are associated with the magnetic ground states. They can be described by the linear spin wave theory (LSWT) of the effective block spin model and the original spin model. Doublons and quartons emerge from the corresponding internal excitations of the trimers with distinct energy levels, which can be effectively analyzed using perturbation theory when the ratio of exchange interactions g𝑔gitalic_g is small. In this small g𝑔gitalic_g regime, we observe a clear separation between the magnon and higher-energy spectra. However, as g𝑔gitalic_g increases, these three spectra gradually merge into the magnon modes or continua. Nevertheless, the LSWT fails to provide quantitative descriptions of the higher-energy excitation bands due to significant quantum fluctuations. Notably, in the Collinear II and trimerized hexagon lattice, a broad continuum emerges above the single-magnon spectrum, originating from the quasi-1D physics due to the dilute connections between chains. Our numerical analysis of these 2D trimers yields valuable theoretical predictions and explanations for the inelastic neutron scattering (INS) spectra of 2D magnetic materials featuring trimerized lattices.",[],['China']
"We prove a weighted a priori energy estimate for the two dimensional water-waves problem with contact points in the absence of gravity and surface tension. When the surface graph function and its time derivative have some decay near the contact points, we show that there is corresponding decay for the velocity, the pressure and other quantities in a short time interval. As a result, we have fixed contact points and contact angles. To prove the energy estimate, a conformal mapping is used to transform the equation for the mean curvature into an equivalent equation in a flat strip with some weights. Moreover, the weighted limits at contact points for the velocity, the pressure etc. are tracked and discussed. Our formulation can be adapted to deal with more general cases.",[],[]
"We study the ergodic properties of two classes of random dynamical systems: a type of Markov chain which we call the alternating random walk and a certain stochastic billiard system which describes the motion of a free-moving rough disk bouncing between two parallel rough walls. Our main results characterize the types of Markov transition kernels which make each system ergodic – in the first case, with respect to uniform measure on the state space, and in the second case, with respect to Lambertian measure (a classic measure from geometric optics). In addition, building on results from [25], we give explicit examples of rough microstructures which produce ergodic dynamics in the second system. Both systems have the property that the transition kernel governing the dynamics is singular with respect to uniform measure on the state space. As a result, these systems occupy a kind of mean in the problem space between diffusive processes, where establishing ergodicity is relatively easy, and physically realistic deterministic systems, where questions of ergodicity are far less approachable.",[],[]
"Deep Learning models have become an integrated component of modern software systems.
In response to the challenge of model design, researchers proposed Automated Machine Learning (AutoML) systems, which automatically search for model architecture and hyperparameters for a given task.
Like other software systems, existing AutoML systems suffer from bugs.
We identify two common and severe bugs in AutoML, performance bug (i.e., searching for the desired model takes an unreasonably long time) and ineffective search bug (i.e., AutoML systems are not able to find an accurate enough model).
After analyzing the workflow of AutoML, we observe that existing AutoML systems overlook potential opportunities in search space, search method, and search feedback, which results in performance and ineffective search bugs.
Based on our analysis, we design and implement DREAM, an automatic debugging and repairing system for AutoML systems.
It monitors the process of AutoML to collect detailed feedback and automatically repairs bugs by expanding search space and leveraging a feedback-driven search strategy.
Our evaluation results show that DREAM can effectively and efficiently repair AutoML bugs.",[],['China']
"In a seminal paper [1],
Watling proposes a stochastic variational inequality approach to model traffic flow equilibrium over a network where
the transportation time is random and
a path is selected by
to transport if the user’s expected utility of the transportation of the path is maximized over their paths.
A key feature of Watling’s model is that the user’s utility function
incorporates a penalty term for lateness
and the resulting equilibrium is known as
Late Arrival Penalised User Equilibrium (LAPUE).
In this paper, we revisit the LAPUE model with a different focus:
we begin by adopting a new penalty function
which gives a smooth transition of the boundary
between lateness and no lateness and demonstrate
the LAPUE model based on the new penalty function
has a unique equilibrium and is stable with respect to (w.r.t.)
small perturbation of probability distribution under moderate conditions.
We then move on to discuss statistical robustness of the modified
LAPUE (MLAPUE) model by considering the
case that the data to be used for fitting the density function may be perturbed in practice or there is a discrepancy between the probability distribution of the underlying uncertainty constructed with empirical data and the true probability distribution in future,
we investigate how the data perturbation may affect the equilibrium. We undertake the analysis from two perspectives:
(a) a few data are
perturbed by outliers and (b)
all data are potentially
perturbed.
In case (a), we use the well-known influence function to quantify the sensitivity of the equilibrium by the outliers and in case (b) we examine
the difference between empirical distributions of the equilibrium based on perturbed data and the equilibrium based on unperturbed data.
To examine the performance of the MLAPUE model and our theoretical analysis of statistical robustness, we carry out some numerical experiments, the preliminary results confirm the statistical robustness as desired.",[],[]
"At the intersection of computation and cognitive science, graph theory is utilized as a formalized description of complex relationships and structures. Traditional graph models are often static, lacking dynamic and autonomous behavioral patterns. They rely on algorithms with a global view, significantly differing from biological neural networks, in which, to simulate information storage and retrieval processes, the limitations of centralized algorithms must be overcome. This study introduces a directed graph model that equips each node with adaptive learning and decision-making capabilities, thereby facilitating decentralized dynamic information storage and modeling and simulation of the brain’s memory process. We abstract different storage instances as directed graph paths, transforming the storage of information into the assignment, discrimination, and extraction of different paths. To address writing and reading challenges, each node has a personalized adaptive learning ability. A storage algorithm without a “God’s eye” view is developed, where each node uses its limited neighborhood information to facilitate the extension, formation, solidification, and awakening of directed graph paths, achieving competitive, reciprocal, and sustainable utilization of limited resources. Storage behavior occurs in each node, with adaptive learning behaviors of nodes concretized in a microcircuit centered around a variable resistor, simulating the electrophysiological behavior of neurons. Based on Ohm’s and Kirchhoff’s laws, we simulated the dynamics of this directed graph network on a computer, where the network could store and retrieve uploaded instances, confirming the model’s effectiveness and exploring its storage capacity. Under the constraints of neurobiology on the anatomy and electrophysiology of biological neural networks, this model offers a plausible explanation for the mechanism of memory realization, providing a comprehensive, system-level experimental validation of the memory trace theory.",[],[]
"In this paper, we investigate the concept of infinite dense-lineability recently introduced by M. Calderón-Moreno, P. Gerlach-Mena and J. Prado-Bassas. We answer a question posed by the authors about the equivalence between infinite (pointwise) dense-lineability and (pointwise) dense-lineability. We prove that the equivalence always holds in first-countable topological vector spaces and under some assumptions about the weight of the topology. However, the equivalence is not always true, as shown in an example. Furthermore, we introduce the notions of infinite (α,β)𝛼𝛽(\alpha,\beta)( italic_α , italic_β )-dense-lineability and infinite (strongly) dense-algebrability and obtain some analogous results in these cases. We also obtain a criterion for strongly dense-algebrability for sets of the form X∖Y𝑋𝑌X\setminus Yitalic_X ∖ italic_Y, where X𝑋Xitalic_X is a free algebra and Y𝑌Yitalic_Y is a free subalgebra of X𝑋Xitalic_X.",[],[]
"Understanding and predicting the emotional trajectory in multi-party multi-turn conversations is of great significance. Such information can be used, for example, to generate empathetic response in human-machine interaction or to inform models of pre-emptive toxicity detection. In this work, we introduce the novel problem of Predicting Emotions in Conversations (PEC) for the next turn (n+1𝑛1n+1italic_n + 1), given combinations of textual and/or emotion input up to turn n𝑛nitalic_n. We systematically approach the problem by modeling three dimensions inherently connected to evoked emotions in dialogues, including (i) sequence modeling, (ii) self-dependency modeling, and (iii) recency modeling. These modeling dimensions are then incorporated into two deep neural network architectures, a sequence model and a graph convolutional network model. The former is designed to capture the sequence of utterances in a dialogue, while the latter captures the sequence of utterances and the network formation of multi-party dialogues. We perform a comprehensive empirical evaluation of the various proposed models for addressing the PEC problem. The results indicate (i) the importance of the self-dependency and recency model dimensions for the prediction task, (ii) the quality of simpler sequence models in short dialogues, (iii) the importance of the graph neural models in improving the predictions in long dialogues.",[],[]
"Cavity-mediated adiabatic transfer (CMAT) is a robust way to perform a two-qubit gate between trapped atoms inside an optical cavity.
In the previous study by Goto and Ichimura [H. Goto and K. Ichimura, Phys. Rev. A 77, 013816 (2008).], the upper bound of success probability of CMAT was shown where the operation is adiabatically slow.
For practical applications, however, it is crucial to operate CMAT as fast as possible without sacrificing the success probability.
In this paper, we investigate the operational speed limit of CMAT conditioned on the success probability being close to the upper bound.
In CMAT both the adiabatic condition and the decay of atoms and cavity modes limit the operational speed.
We show which of these two conditions more severely limits the operational speed in each cavity-QED parameter region, and find that the maximal operational speed, which is proportional to γ⁢C𝛾𝐶\gamma\sqrt{C}italic_γ square-root start_ARG italic_C end_ARG, is achieved when the influence of cavity decay is dominant compared to spontaneous emission, where γ𝛾\gammaitalic_γ and C𝐶Citalic_C are spontaneous emission rate and cooperativity.",[],['Japan']
"To obtain strong convergence rates of numerical schemes, an overwhelming majority of existing works impose a global monotonicity condition on coefficients of SDEs.
On the contrary, a majority of SDEs from applications do not have globally monotone coefficients.
As a recent breakthrough,
the authors of [Hutzenthaler, Jentzen, Ann. Probab., 2020] originally presented a perturbation theory
for stochastic differential equations (SDEs),
which is crucial to recovering strong convergence rates
of numerical schemes in a non-globally monotone setting.
However, only a convergence rate of order 1/2121/21 / 2
was obtained there for time-stepping schemes such as
a stopped increment-tamed Euler-Maruyama (SITEM) method.
As an open problem,
a natural question was raised
by the aforementioned work as to whether higher
convergence rate than 1/2121/21 / 2 can be obtained
when higher order schemes are used.
The present work attempts to solve
the tough problem. To this end, we develop
some new perturbation estimates that are
able to reveal the order-one
strong convergence of numerical methods.
As the first application of the newly developed estimates,
we identify the expected order-one pathwise uniformly
strong convergence
of the SITEM method for additive noise driven SDEs
and multiplicative noise driven second order SDEs
with non-globally monotone coefficients.
As the other application, we propose and analyze a
positivity preserving explicit Milstein-type method for
Lotka-Volterra competition model driven by multi-dimensional
noise, with a pathwise uniformly strong convergence rate of
order one recovered under mild assumptions.
These obtained results are completely new
and significantly improve the existing theory.
Numerical experiments are also
provided to confirm the theoretical findings.

AMS subject classifications:  60H35,
65C30.

Key Words:  SDEs with non-globally monotone coefficients; explicit method;
exponential integrability properties;
pathwise uniformly strong convergence; order-one strong convergence; Lotka-Volterra competition model.",[],[]
"In the Constructor-Blocker game, two players, Constructor and Blocker, alternatively claim unclaimed edges of the complete graph Knsubscript𝐾𝑛K_{n}italic_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. For given graphs F𝐹Fitalic_F and H𝐻Hitalic_H, Constructor can only claim edges that leave her graph F𝐹Fitalic_F-free, while Blocker has no restrictions. Constructor’s goal is to build as many copies of H𝐻Hitalic_H as she can, while Blocker attempts to stop this. The game ends once there are no more edges that Constructor can claim. The score g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) of the game is the number of copies of H𝐻Hitalic_H in Constructor’s graph at the end of the game when both players play optimally and Constructor plays first.

In this paper, we extend results of Patkós, Stojaković and Vizer on g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) to many pairs of H𝐻Hitalic_H and F𝐹Fitalic_F: We determine g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) when H=Kr𝐻subscript𝐾𝑟H=K_{r}italic_H = italic_K start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and χ⁢(F)>r𝜒𝐹𝑟\chi(F)>ritalic_χ ( italic_F ) > italic_r, also when both H𝐻Hitalic_H and F𝐹Fitalic_F are odd cycles, using Szemerédi’s Regularity Lemma. We also obtain bounds of g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) when H=K3𝐻subscript𝐾3H=K_{3}italic_H = italic_K start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and F=K2,2𝐹subscript𝐾22F=K_{2,2}italic_F = italic_K start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPT.",[],[]
"It has been more than 30 years since the enigmatic 21 μ𝜇\muitalic_μm emission feature was first discovered in protoplanetary nebulae (PPNs).
Although dozens of different dust carrier candidates have been proposed, there is as yet no widely accepted one.
We present the results of molecular observations toward 21 μ𝜇\muitalic_μm objects using the 10 m Submillimeter Telescope of Arizona Radio Observatory at the 1.3 mm band
and the 13.7 m telescope of Purple Mountain Observatory at the 3 mm band,
aiming to investigate whether the gas-phase environments of these unusual sources have some peculiarities compared to normal PPNs.
We detect 31 emission lines belonging to seven different molecular species, most of which are the first detection in 21 μ𝜇\muitalic_μm PPNs.
The observations provide clues on the identification of the 21 μ𝜇\muitalic_μm feature.
We report a correlation study between the fractional abundance of gas-phase molecules and the strengths of the 21 μ𝜇\muitalic_μm emission.
Our study shows that given the small sample size, the 21 μ𝜇\muitalic_μm feature has weak or no correlations with the gas-phase molecules.
Future radio observations of high spatial and spectral resolution toward a large sample are desirable to elucidate the 21 μ𝜇\muitalic_μm emission phenomena.","['21\u2009μ𝜇\\muitalic_μm feature —', 'ISM: molecules — circumstellar matter —', 'Line: identification —', 'Circumstellar envelopes']",['China']
"Answering questions using pre-trained language models (LMs) and knowledge graphs (KGs) presents challenges in identifying relevant knowledge and performing joint reasoning. We compared LMs (fine-tuned for the task) with the previously published QAGNN method for the Question-answering (QA) objective and further measured the impact of additional factual context on the QAGNN performance. The QAGNN method employs LMs to encode QA context and estimate KG node importance, and effectively update the question choice entity representations using Graph Neural Networks (GNNs). We further experimented with enhancing the QA context encoding by incorporating relevant knowledge facts for the question stem. The models are trained on the OpenbookQA dataset, which contains ~6000 4-way multiple choice questions and is widely used as a benchmark for QA tasks.
Through our experimentation, we found that incorporating knowledge facts context led to a significant improvement in performance. In contrast, the addition of knowledge graphs to language models resulted in only a modest increase. This suggests that the integration of contextual knowledge facts may be more impactful for enhancing question-answering performance compared to solely adding knowledge graphs.","['Knowledge graphs (KG)', 'language models (LM)', 'question and answering (QA)', 'graph neural networks (GNN)']",[]
"The investigation of high-temperature superconductors under high
magnetic fields is one of the most important topics in condensed matter physics.
For YBa22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT (YBCO), the measurements of magnetoresistance
under a high magnetic field are technically challenging because the required magnetic field (B𝐵Bitalic_B) is 100 T class.
The low temperature (from 52 to 150 K) magnetoresistance is measured in optimally-doped
YBCO thin films under the condition B𝐵Bitalic_B∥parallel-to\parallel∥CuO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT-plane up to 103 T by employing the
single-turn coil technique and a radio frequency reflection method.
The electrical resistivity ρ𝜌\rhoitalic_ρ exhibits B𝐵Bitalic_B-linear behavior in the
normal phase in the high magnetic field region.
The field slope coefficient
β𝛽\betaitalic_β (=d⁢ρ/d⁢B𝑑𝜌𝑑𝐵d\rho/dBitalic_d italic_ρ / italic_d italic_B) becomes converged at low temperatures.
The convergency of β𝛽\betaitalic_β below Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT indicates the field-induced strange metal
phase, which is determined by the quantum critical fluctuation at high magnetic fields. The β𝛽\betaitalic_β value difference under the different directions
of the magnetic field suggests the strong anisotropy in quantum critical fluctuations in the strange metal phase of
YBCO.",[],['Japan']
"In the modern world, the amount of visual data recorded has been rapidly increasing. In many cases, data is stored in geographically distinct locations and thus requires a large amount of time and space to consolidate. Sometimes, there are also regulations for privacy protection which prevent data consolidation. In this work, we present federated implementations for object detection and recognition using a federated Faster R-CNN (FRCNN) and image segmentation using a federated Fully Convolutional Network (FCN). Our FRCNN was trained on 5000 examples of the COCO2017 dataset while our FCN was trained on the entire train set of the CamVid dataset. The proposed federated models address the challenges posed by the increasing volume and decentralized nature of visual data, offering efficient solutions in compliance with privacy regulations.",[],[]
"Evaluating the performance of autonomous vehicle planning algorithms necessitates simulating long-tail traffic scenarios. Traditional methods for generating safety-critical scenarios often fall short in realism and controllability. Furthermore, these techniques generally neglect the dynamics of agent interactions. To mitigate these limitations, we introduce a novel closed-loop simulation framework rooted in guided diffusion models. Our approach yields two distinct advantages: 1) the generation of realistic long-tail scenarios that closely emulate real-world conditions, and 2) enhanced controllability, enabling more comprehensive and interactive evaluations. We achieve this through novel guidance objectives that enhance road progress while lowering collision and off-road rates. We develop a novel approach to simulate safety-critical scenarios through an adversarial term in the denoising process, which allows the adversarial agent to challenge a planner with plausible maneuvers, while all agents in the scene exhibit reactive and realistic behaviors. We validate our framework empirically using the NuScenes dataset, demonstrating improvements in both realism and controllability. These findings affirm that guided diffusion models provide a robust and versatile foundation for safety-critical, interactive traffic simulation, extending their utility across the broader landscape of autonomous driving. For additional resources and demonstrations, visit our project page at https://safe-sim.github.io.",[],[]
"We improve the upper bound on the Ramsey number R⁢(3,10)𝑅310R(3,10)italic_R ( 3 , 10 ) from 42424242 to 41414141. Hence R⁢(3,10)𝑅310R(3,10)italic_R ( 3 , 10 ) is equal to 40404040 or 41414141.",[],[]
,[],[]
,[],[]
"The Gaussian process (GP) regression model is a widely employed surrogate modeling technique for computer experiments, offering precise predictions and statistical inference for the computer simulators that generate experimental data.
Estimation and inference for GP can be performed in both frequentist and Bayesian frameworks.
In this chapter, we construct the GP model through variational inference, particularly employing the recently introduced energetic variational inference method by Wang et al. (2021).
Adhering to the GP model assumptions, we derive posterior distributions for its parameters.
The energetic variational inference approach bridges the Bayesian sampling and optimization and enables approximation of the posterior distributions and identification of the posterior mode.
By incorporating a normal prior on the mean component of the GP model, we also apply shrinkage estimation to the parameters, facilitating mean function variable selection. To showcase the effectiveness of our proposed GP model, we present results from three benchmark examples.",[],[]
"Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs).
Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents.
In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination.
This paper presents RAGTruth, a corpus tailored for analyzing word-level hallucinations in various domains and tasks within the standard RAG frameworks for LLM applications.
RAGTruth comprises nearly 18,000 naturally generated responses from diverse LLMs using RAG.
These responses have undergone meticulous manual annotations at both the individual cases and word levels, incorporating evaluations of hallucination intensity.
We not only benchmark hallucination frequencies across different LLMs, but also critically assess the effectiveness of several existing hallucination detection methodologies.
Furthermore, we show that using a high-quality dataset such as RAGTruth, it is possible to finetune a relatively small LLM and achieve a competitive level of performance in hallucination detection when compared to the existing prompt-based approaches using state-of-the-art large language models such as GPT-4.111The RAGTruth dataset is available at https://github.com/ParticleMedia/RAGTruth",[],[]
"In this work, we introduce the notion of warped Yosida regularization and study the asymptotic behaviour of the orbit of dynamical systems generated by warped Yosida regularization, which includes Douglas-Rachford dynamical system. We analyze an algorithm where the inclusion problem is first approximated by a regularized one and then the preconditioned regularization parameter is reduced to converge to a solution of original problem. We propose and investigate backward-backward splitting using degenerate preconditioning for monotone inclusion problems. The applications provide a tool for finding a minima of a preconditioned regularization of the sum of two convex functions.",[],['India']
,[],[]
"We conducted 4-night multiwavelength observations of an active M-dwarf star EV Lac on 2022 October 24−--27 with simultaneous coverage of soft X-rays (NICER; 0.2−--12 keVkeV\mathrm{keV}roman_keV, Swift XRT; 0.2−--10 keVkeV\mathrm{keV}roman_keV), near-ultraviolet (Swift UVOT/UVW2; 1600−--3500 ÅÅ\mathrm{\AA}roman_Å ), optical photometry (TESS; 6000−--10000 ÅÅ\mathrm{\AA}roman_Å), and optical spectroscopy (Nayuta/MALLS; 6350−--6800 ÅÅ\mathrm{\AA}roman_Å).
During the campaign, we detected a flare starting at 12:28 UTC on October 25 with its white-light bolometric energy of 3.4×10323.4superscript10323.4\times 10^{32}3.4 × 10 start_POSTSUPERSCRIPT 32 end_POSTSUPERSCRIPT erg.
At about 1 hour after this flare peak, our H⁢αH𝛼\mathrm{H\alpha}roman_H italic_α spectrum showed a blue-shifted excess component at its corresponding velocity of ∼100⁢km⁢s−1similar-toabsent100kmsuperscripts1\sim 100\>\mathrm{km\>s^{-1}}∼ 100 roman_km roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
This may indicate that the prominence erupted with a 1-hour delay of the flare peak.
Furthermore, the simultaneous 20-second cadence near-ultraviolet and white-light curves show gradual and rapid brightening behaviors during the rising phase at this flare.
The ratio of flux in NUV to white light at the gradual brightening was ∼0.49similar-toabsent0.49\sim 0.49∼ 0.49, which may suggest that the temperature of the blackbody is low (<9000⁢Kabsent9000K<9000\>\mathrm{K}< 9000 roman_K) or the maximum energy flux of a nonthermal
electron beam is less than 5×1011⁢erg⁢cm−2⁢s−15superscript1011ergsuperscriptcm2superscripts15\times 10^{11}\>\mathrm{erg\>cm^{-2}\>s^{-1}}5 × 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT roman_erg roman_cm start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
Our simultaneous observations of NUV and white-light flare raise the issue of a simple estimation of UV flux from optical continuum data
by using a blackbody model.",[],[]
We perform a finite-size scaling analysis of the critical point in the heavy-quark region of QCD at nonzero temperature. Our previous analysis on the Binder cumulant at Nt=4subscript𝑁𝑡4N_{t}=4italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 4 is extended to finer lattices with Nt=6subscript𝑁𝑡6N_{t}=6italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 6 and 8888. The aspect ratio is also extended up to 15151515 to suppress the non-singular contribution. High-precision analysis of the Binder cumulant is realized by an efficient Monte-Carlo simulation with the hopping-parameter expansion (HPE). Effects of higher-order terms in the HPE are incorporated by the reweighting method.,[],[]
"Various popular multiplayer battle royale games share a lot of common elements. Drawing from our observations, we summarized these shared characteristics and subsequently proposed a novel heuristic algorithm named multiplayer battle game-inspired optimizer (MBGO). The proposed MBGO streamlines mainstream multiplayer battle royale games into two discrete phases: movement and battle. Specifically, the movement phase incorporates the principles of commonly encountered “safe zones” to incentivize participants to relocate to areas with a higher survival potential. The battle phase simulates a range of strategies adopted by players in various situations to enhance the diversity of the population. To evaluate and analyze the performance of the proposed MBGO, we executed it alongside eight other algorithms, including three classics and five latest ones, across multiple diverse dimensions within the CEC2017 and CEC2020 benchmark functions. In addition, we employed several industrial design problems to evaluate the scalability and practicality of the proposed MBGO. The results of the statistical analysis reveal that the novel MBGO demonstrates significant competitiveness, excelling not only in convergence speed, but also in achieving high levels of convergence accuracy across both benchmark functions and real-world problems.","['Optimization', 'Heuristic', 'Algorithm', 'Evolutionary', 'Computation', 'Multiplayer', 'Battle', 'Game-Inspired', 'Optimizer']",[]
Insert your english abstract here.,[],[]
"Selecting proper clients to participate in the iterative federated learning (FL) rounds is critical to effectively harness a broad range of distributed datasets. Existing client selection methods simply consider the variability among FL clients with uni-modal data, however, have yet to consider clients with multi-modalities. We reveal that traditional client selection scheme in MFL may suffer from a severe modality-level bias, which impedes the collaborative exploitation of multi-modal data, leading to insufficient local data exploration and global aggregation. To tackle this challenge, we propose a Client-wise Modality Selection scheme for MFL (CMSFed) that can comprehensively utilize information from each modality via avoiding such client selection bias caused by modality imbalance. Specifically, in each MFL round, the local data from different modalities are selectively employed to participate in local training and aggregation to mitigate potential modality imbalance of the global model. To approximate the fully aggregated model update in a balanced way, we introduce a novel local training loss function to enhance the weak modality and align the divergent feature spaces caused by inconsistent modality adoption strategies for different clients simultaneously. Then, a modality-level gradient decoupling method is designed to derive respective submodular functions to maintain the gradient diversity during the selection progress and balance MFL according to local modality imbalance in each iteration. Our extensive experiments showcase the superiority of CMSFed over baselines and its effectiveness in multi-modal data exploitation.",[],[]
,[],[]
"Single-view 3D shape retrieval is a challenging task that is increasingly important with the growth of available 3D data. Prior work that has studied this task has not focused on evaluating how realistic occlusions impact performance, and how shape retrieval methods generalize to scenarios where either the target 3D shape database contains unseen shapes, or the input image contains unseen objects. In this paper, we systematically evaluate single-view 3D shape retrieval along three different axes: the presence of object occlusions and truncations, generalization to unseen 3D shape data, and generalization to unseen objects in the input images. We standardize two existing datasets of real images and propose a dataset generation pipeline to produce a synthetic dataset of scenes with multiple objects exhibiting realistic occlusions. Our experiments show that training on occlusion-free data as was commonly done in prior work leads to significant performance degradation for inputs with occlusion. We find that that by first pretraining on our synthetic dataset with occlusions and then finetuning on real data, we can significantly outperform models from prior work and demonstrate robustness to both unseen 3D shapes and unseen objects.",[],[]
,[],[]
"Some theoretical models for the early universe predict a spike-type enhancement in the primordial power spectrum on a small scale, which would result in forming early-formed dark matter halos (EFHs).
In this work, we study the CMB lensing effect, considering the existence of EFHs, and investigate the potential to probe the EFHs and the primordial perturbations on scales smaller than 1⁢M⁢p⁢c1Mpc1\mathrm{Mpc}1 roman_M roman_p roman_c.
We numerically calculate the angular power spectrum of the lensing potential and the lensed CMB anisotropy of temperature, E-mode, and B-mode polarization, including the nonlinear effects of EFHs.
We find the possibility that the lensed CMB temperature anisotropy is significantly enhanced on small scales, ℓ>1000ℓ1000\ell>1000roman_ℓ > 1000, and could be tested by component decomposition of observed signals through multi-frequency observations.
Through the calculation with different models of the spiky-type power spectrum, we demonstrate that the accurate measurements of the CMB lensing effect would provide insight into the abundance of EFHs within the limited mass range around 1012⁢M⊙superscript1012subscript𝑀direct-product10^{12}M_{\odot}10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and the primordial power spectrum on the limited scales around k∼1⁢M⁢p⁢c−1similar-to𝑘1Mpsuperscriptc1k\sim 1\mathrm{Mpc}^{-1}italic_k ∼ 1 roman_M roman_p roman_c start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
In particular,
we find that the existence of such EFHs can amplify the lensed anisotropy of CMB B-mode polarization even on large scales, ℓ<100ℓ100\ell<100roman_ℓ < 100, as the overall enhancement by ∼10%similar-toabsentpercent10\sim 10\%∼ 10 % level compared to the standard structure formation model without EFHs.
Therefore, future CMB measurements such as the LiteBIRD satellite can probe the existence of the EFHs and the spike-type primordial power spectrum
through the precise measurement
of the large-scale CMB B-mode polarization.",[],['Japan']
"In this paper, we tackle the
following problem:
compute the gcd for several univariate polynomials with parametric coefficients. It amounts
to partitioning the parameter space into “cells” so that the gcd has a uniform expression over each cell and constructing a uniform expression of gcd in each cell.
We tackle the problem as follows.
We begin by making a natural and obvious extension of subresultant
polynomials of two polynomials to several polynomials. Then we develop the following
structural
theories about them.


1.

We generalize Sylvester’s theory
to several polynomials, in order to obtain an elegant relationship between generalized
subresultant polynomials and the gcd of several polynomials, yielding an elegant
algorithm.



2.

We generalize Habicht’s theory to several polynomials, in order to obtain
a systematic relationship between generalized subresultant polynomials and pseudo-remainders, yielding an efficient algorithm.



Using the generalized theories, we present a simple (structurally elegant) algorithm
which is significantly more efficient (both in the output size and computing time) than algorithms based on previous approaches.",[],[]
"Human Interaction Recognition (HIR) is the process of identifying and understanding interactive actions and activities between multiple participants in a specific environment or situation. The aim of this task is to recognise the action interactions between multiple people or entities and their meaning and purpose. Many single Convolutional Neural Network (CNN) has issues, such as the inability to capture global instance interaction features or difficulty in training, leading to ambiguity in action semantics. In addition, the computational complexity of the Transformer cannot be ignored, and its ability to capture local information and motion features in the image is poor. In this work, we propose a Two-stream Hybrid CNN-Transformer Network (THCT-Net), which exploits the local specificity of CNN and models global dependencies through the Transformer. CNN and Transformer simultaneously model the entity, time and space relationships between interactive entities respectively. Specifically, Transformer-based stream integrates 3D convolutions with multi-head self-attention to learn inter-token correlations; We propose a new multi-branch CNN framework for CNN-based streams that automatically learns joint spatio-temporal features from skeleton sequences. The convolutional layer independently learns the local features of each joint neighborhood and aggregates the features of all joints. And the raw skeleton coordinates as well as their temporal difference are integrated with a dual-branch paradigm to fuse the motion features of the skeleton. Besides, a residual structure is added to speed up training convergence. Finally, the recognition results of the two branches are fused using parallel splicing. Multi-grained information modelling is employed to enhance the accuracy and robustness of the action recognition system. Experimental results on diverse and challenging datasets, such as NTU-RGBD, H2O, and Assembly101, demonstrate that the proposed method can better comprehend and infer the meaning and context of various actions, outperforming state-of-the-art methods.","['human interaction recognition', 'CNN', 'Transformer', 'multi-grained context.']",[]
,[],[]
"We perform a combined fit of the invariant mass distribution of X⁢(3872)→J/ψ⁢π+⁢π−→𝑋3872𝐽𝜓superscript𝜋superscript𝜋{X(3872)}\rightarrow{J}/{\psi}\pi^{+}\pi^{-}italic_X ( 3872 ) → italic_J / italic_ψ italic_π start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_π start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT from LHCb and X⁢(3872)→D0⁢D¯0⁣*→𝑋3872superscript𝐷0superscript¯𝐷0{X(3872)}\rightarrow{D}^{0}\overline{D}^{0*}italic_X ( 3872 ) → italic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT over¯ start_ARG italic_D end_ARG start_POSTSUPERSCRIPT 0 * end_POSTSUPERSCRIPT from Belle using an effective field theory approach. In this approach, we can directly determine the Z𝑍Zitalic_Z which is the probability of finding the compact component in X⁢(3872)𝑋3872{X(3872)}italic_X ( 3872 ). In the combined analysis, we find that the Z𝑍Zitalic_Z is 0.52±0.11plus-or-minus0.520.110.52\pm 0.110.52 ± 0.11 for X⁢(3872)𝑋3872{X(3872)}italic_X ( 3872 ).","['Exotic hadron', 'X\u2062(3872)𝑋3872{X(3872)}italic_X ( 3872 )', 'Compositeness criterion', 'Effective field theory', 'Lineshape']",['China']
,[],[]
"Solving partial differential equations (PDEs) numerically often requires huge computing time, energy cost, and hardware resources in practical applications. This has limited their applications in many scenarios (e.g., autonomous systems, supersonic flows) that have a limited energy budget and require near real-time response. Leveraging optical computing, this paper develops an on-chip training framework for physics-informed neural networks (PINNs), aiming to solve high-dimensional PDEs with fJ/MAC photonic power consumption and ultra-low latency. Despite the ultra-high speed of optical neural networks, training a PINN on an optical chip is hard due to (1) the large size of photonic devices, and (2) the lack of scalable optical memory devices to store the intermediate results of back-propagation (BP). To enable realistic optical PINN training, this paper presents a scalable method to avoid the BP process. We also employ a tensor-compressed approach to improve the convergence and scalability of our optical PINN training. This training framework is designed with tensorized optical neural networks (TONN) for scalable inference acceleration and MZI phase-domain tuning for in-situ optimization. Our simulation results of a 20-dim HJB PDE show that our photonic accelerator can reduce the number of MZIs by a factor of 1.17×103absentsuperscript103\times 10^{3}× 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, with only 1.36 J and 1.15 s to solve this equation. This is the first real-size optical PINN training framework that can be applied to solve high-dimensional PDEs.",[],[]
"Deep neural networks have significantly improved the performance of face forgery detection models in discriminating Artificial Intelligent Generated Content (AIGC). However, their security is significantly threatened by the injection of triggers during model training (i.e., backdoor attacks). Although existing backdoor defenses and manual data selection can mitigate those using human-eye-sensitive triggers, such as patches or adversarial noises, the more challenging natural backdoor triggers remain insufficiently researched. To further investigate natural triggers, we propose a novel analysis-by-synthesis backdoor attack against face forgery detection models, which embeds natural triggers in the latent space. We thoroughly study such backdoor vulnerability from two perspectives: (1) Model Discrimination (Optimization-Based Trigger): we adopt a substitute detection model and find the trigger by minimizing the cross-entropy loss; (2) Data Distribution (Custom Trigger): we manipulate the uncommon facial attributes in the long-tailed distribution to generate poisoned samples without the supervision from detection models. Furthermore, to completely evaluate the detection models towards the latest AIGC, we utilize both state-of-the-art StyleGAN and Stable Diffusion for trigger generation. Finally, these backdoor triggers introduce specific semantic features to the generated poisoned samples (e.g., skin textures and smile), which are more natural and robust. Extensive experiments show that our method is superior from three levels: (1) Attack Success Rate: ours achieves a high attack success rate (over 99%percent\%%) and incurs a small model accuracy drop (below 0.2%percent\%%) with a low poisoning rate (less than 3%percent\%%); (2) Backdoor Defense: ours shows better robust performance when faced with existing backdoor defense methods; (3) Human Inspection: ours is less human-eye-sensitive from a comprehensive user study.",['Backdoor attacks face forgery detection facial attribute editing'],['China']
,[],[]
"Video-based facial affect analysis has recently attracted increasing attention owing to its critical role in human-computer interaction.
Previous studies mainly focus on developing various deep learning architectures and training them in a fully supervised manner. Although significant progress has been achieved by these supervised methods, the longstanding lack of large-scale high-quality labeled data severely hinders their further improvements.
Motivated by the recent success of self-supervised learning in computer vision, this paper introduces a self-supervised approach, termed Self-supervised Video Facial Affect Perceiver (SVFAP), to address the dilemma faced by supervised methods.
Specifically, SVFAP leverages masked facial video autoencoding to perform self-supervised pre-training on massive unlabeled facial videos.
Considering that large spatiotemporal redundancy exists in facial videos, we propose a novel temporal pyramid and spatial bottleneck Transformer as the encoder of SVFAP, which not only enjoys low computational cost but also achieves excellent performance.
To verify the effectiveness of our method, we conduct experiments on nine datasets spanning three downstream tasks, including dynamic facial expression recognition, dimensional emotion recognition, and personality recognition.
Comprehensive results demonstrate that SVFAP can learn powerful affect-related representations via large-scale self-supervised pre-training and it significantly outperforms previous state-of-the-art methods on all datasets.
Codes will be available at https://github.com/sunlicai/SVFAP.","['Video-based facial affect analysis', 'self-supervised learning', 'masked autoencoding', 'Transformer', 'spatial bottleneck', 'temporal pyramid']",[]
"In this paper, we study the stability for 2-D plane Poiseuille flow (1−y2,0)1superscript𝑦20(1-y^{2},0)( 1 - italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0 ) in a channel 𝕋×(−1,1)𝕋11\mathbb{T}\times(-1,1)blackboard_T × ( - 1 , 1 ) with non-slip boundary condition. Three effects are studied in this paper: enhanced dissipation, inviscid damping and boundary layer effect. For the Navier-Stokes equations around Poiseuille flow with non-slip boundary condition, we prove that if the initial perturbation of velocity u0subscript𝑢0u_{0}italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT satisfies



‖u0‖H2+≤ϵ0⁢ν34subscriptnormsubscript𝑢0superscript𝐻limit-from2subscriptitalic-ϵ0superscript𝜈34\|u_{0}\|_{H^{2+}}\leq\epsilon_{0}\nu^{\frac{3}{4}}∥ italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT italic_H start_POSTSUPERSCRIPT 2 + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ≤ italic_ϵ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_ν start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT



for some constants ϵ0>0subscriptitalic-ϵ00\epsilon_{0}>0italic_ϵ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 independent of the viscosity ν𝜈\nuitalic_ν, then the solution to 2-D Navier-Stokes equations does not transit from plane Poiseuille flow. Meanwhile, for the Navier-slip boundary problem, we prove that if the initial perturbation of velocity u0subscript𝑢0u_{0}italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT satisfies



‖u0‖H32+≤ϵ1⁢ν12subscriptnormsubscript𝑢0superscript𝐻limit-from32subscriptitalic-ϵ1superscript𝜈12\|u_{0}\|_{H^{\frac{3}{2}+}}\leq\epsilon_{1}\nu^{\frac{1}{2}}∥ italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT italic_H start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 2 end_ARG + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ≤ italic_ϵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_ν start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT



for some constants ϵ1>0subscriptitalic-ϵ10\epsilon_{1}>0italic_ϵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0 independent of the viscosity ν𝜈\nuitalic_ν, then the solution to 2-D Navier-Stokes equations does not transit from plane Poiseuille flow, which improves the result of [17] from ν34superscript𝜈34\nu^{\frac{3}{4}}italic_ν start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT to ν12superscript𝜈12\nu^{\frac{1}{2}}italic_ν start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT.",[],[]
"We consider locally recoverable codes (LRCs) and aim to determine the smallest
possible length n=nq⁢(k,d,r)𝑛subscript𝑛𝑞𝑘𝑑𝑟n=n_{q}(k,d,r)italic_n = italic_n start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_k , italic_d , italic_r ) of a linear [n,k,d]qsubscript𝑛𝑘𝑑𝑞[n,k,d]_{q}[ italic_n , italic_k , italic_d ] start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT-code with locality r𝑟ritalic_r.
For k≤7𝑘7k\leq 7italic_k ≤ 7 we exactly determine all values of n2⁢(k,d,2)subscript𝑛2𝑘𝑑2n_{2}(k,d,2)italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_k , italic_d , 2 ) and for k≤6𝑘6k\leq 6italic_k ≤ 6
we exactly determine all values of n2⁢(k,d,1)subscript𝑛2𝑘𝑑1n_{2}(k,d,1)italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_k , italic_d , 1 ). For the ternary field we also
state a few numerical results. As a general result we prove that nq⁢(k,d,r)subscript𝑛𝑞𝑘𝑑𝑟n_{q}(k,d,r)italic_n start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_k , italic_d , italic_r )
equals the Griesmer bound if the minimum Hamming distance d𝑑ditalic_d is sufficiently
large and all other parameters are fixed.
Mathematics Subject Classification: 94B27, 94B05
Keywords: linear codes, locally recoverable codes, data storage, bounds for parameters",[],[]
"We consider here the Multi_Bot problem for the scheduling and the resource parametrization of jobs related to the production or the transportation of different products inside a given time horizon. Those jobs must meet known in advance demands. The time horizon is divided into several discrete identical periods representing each the time needed to proceed a job. The objective is to find a parametrization and a schedule for the jobs in such a way they require as less resources as possible. Though this problem derived from the applicative context of reconfigurable robots, we focus here on fundamental issues. We show that the resulting strongly NP-hard Multi_Bot  problem may be handled in a greedy way with an approximation ratio of 4/3434/34 / 3.",[],['France']
"In cross-domain retrieval, a model is required to identify images from the same semantic category across two visual domains. For instance, given a sketch of an object, a model needs to retrieve a real image of it from an online store’s catalog. A standard approach for such a problem is learning a feature space of images where Euclidean distances reflect similarity. Even without human annotations, which may be expensive to acquire, prior methods function reasonably well using unlabeled images for training. Our problem constraint takes this further to scenarios where the two domains do not necessarily share any common categories in training data. This can occur when the two domains in question come from different versions of some biometric sensor recording identities of different people. We posit a simple solution, which is to generate synthetic data to fill in these missing category examples across domains. This, we do via category preserving translation of images from one visual domain to another. We compare approaches specifically trained for this translation for a pair of domains, as well as those that can use large-scale pre-trained text-to-image diffusion models via prompts, and find that the latter can generate better replacement synthetic data, leading to more accurate cross-domain retrieval models. Code for our work is available at https://github.com/samarth4149/SynCDR",[],[]
"With the rapid progression of deep learning technologies, multi-modality image fusion has become increasingly prevalent in object detection tasks. Despite its popularity, the inherent disparities in how different sources depict scene content make fusion a challenging problem. Current fusion methodologies identify shared characteristics between the two modalities and integrate them within this shared domain using either iterative optimization or deep learning architectures, which often neglect the intricate semantic relationships between modalities, resulting in a superficial understanding of inter-modal connections and, consequently, suboptimal fusion outcomes. To address this, we introduce a text-guided multi-modality image fusion method that leverages the high-level semantics from textual descriptions to integrate semantics from infrared and visible images. This method capitalizes on the complementary characteristics of diverse modalities, bolstering both the accuracy and robustness of object detection. The codebook is utilized to enhance a streamlined and concise depiction of the fused intra- and inter-domain dynamics, fine-tuned for optimal performance in detection tasks. We present a bilevel optimization strategy that establishes a nexus between the joint problem of fusion and detection, optimizing both processes concurrently. Furthermore, we introduce the first dataset of paired infrared and visible images accompanied by text prompts, paving the way for future research. Extensive experiments on several datasets demonstrate that our method not only produces visually superior fusion results but also achieves a higher detection mAP over existing methods, achieving state-of-the-art results.",[],[]
,[],[]
"Multivariate time series forecasting poses an ongoing challenge across various disciplines. Time series data often exhibit diverse intra-series and inter-series correlations, contributing to intricate and interwoven dependencies that have been the focus of numerous studies. Nevertheless, a significant research gap remains in comprehending the varying inter-series correlations across different time scales among multiple time series, an area that has received limited attention in the literature. To bridge this gap, this paper introduces MSGNet, an advanced deep learning model designed to capture the varying inter-series correlations across multiple time scales using frequency domain analysis and adaptive graph convolution. By leveraging frequency domain analysis, MSGNet effectively extracts salient periodic patterns and decomposes the time series into distinct time scales. The model incorporates a self-attention mechanism to capture intra-series dependencies, while introducing an adaptive mixhop graph convolution layer to autonomously learn diverse inter-series correlations within each time scale. Extensive experiments are conducted on several real-world datasets to showcase the effectiveness of MSGNet. Furthermore, MSGNet possesses the ability to automatically learn explainable multi-scale inter-series correlations, exhibiting strong generalization capabilities even when applied to out-of-distribution samples. Code is available at https://github.com/YoZhibo/MSGNet.",[],[]
"Multi-modal intent detection aims to utilize various modalities to understand the user’s intentions, which is essential for the deployment of dialogue systems in real-world scenarios.
The two core challenges for multi-modal intent detection are (1) how to effectively align and fuse different features of modalities and (2) the limited labeled multi-modal intent training data. In this work, we introduce a shallow-to-deep interaction framework with data augmentation (SDIF-DA) to address the above challenges. Firstly, SDIF-DA leverages a shallow-to-deep interaction module to progressively and effectively align and fuse features across text, video, and audio modalities. Secondly, we propose a ChatGPT-based data augmentation approach to automatically augment sufficient training data. Experimental results demonstrate that SDIF-DA can effectively align and fuse multi-modal features by achieving state-of-the-art performance. In addition, extensive analyses show that the introduced data augmentation approach can successfully distill knowledge from the large language model.",[],[]
"We study twisted Courant sigma models, a class of topological field theories arising from the coupling of 3D 0-/2-form BF theory and Chern-Simons theory and containing a 4-form Wess-Zumino term. They are examples of theories featuring a nonlinearly open gauge algebra, where products of field equations appear in the commutator of gauge transformations, and they are reducible gauge systems.
We determine the solution to the master equation using a technique, the BRST power finesse, that combines aspects of the AKSZ construction (which applies to the untwisted model) and the general BV-BRST formalism. This allows for a geometric interpretation of the BV coefficients in the interaction terms of the master action in terms of an induced generalised connection on a 4-form twisted (pre-)Courant algebroid, its Gualtieri torsion and the basic curvature tensor. It also produces a frame independent formulation of the model. We show, moreover, that the gauge fixed action is the sum of the classical one and a BRST commutator, as expected from a Schwarz type topological field theory.",[],[]
"Large language models (LLMs) have exhibited remarkable performance on various natural language processing (NLP) tasks, especially for question answering.
However, in the face of problems beyond the scope of knowledge, these LLMs tend to talk nonsense with a straight face, where the potential solution could be incorporating an Information Retrieval (IR) module and generating response based on these retrieved knowledge.
In this paper, we present a novel framework to assist LLMs, such as ChatGPT, to retrieve question-related structured information on the knowledge graph, and demonstrate that Knowledge-based question answering (Keqing) could be a nature Chain-of-Thought (CoT) mentor to guide the LLM to sequentially find the answer entities of a complex question through interpretable logical chains.
Specifically, the workflow of Keqing will execute decomposing a complex question according to predefined templates, retrieving candidate entities on knowledge graph, reasoning answers of sub-questions, and finally generating response with reasoning paths, which greatly improves the reliability of LLM’s response.
The experimental results on KBQA datasets show that Keqing can achieve competitive performance and illustrate the logic of answering each question.",[],[]
"We prove that the functional volume product for even functions is monotone increasing along the Fokker–Planck heat flow.
This in particular yields a new proof of the functional Blaschke–Santaló inequality by K. Ball and also Artstein-Avidan–Klartag–Milman in the even case.
When the input and its polar function are moreover uniformly log-concave, we prove that the functional volume product experiences a strict jump along the heat evolution. As a corollary of this, we confirm a conjecture due to Barthe–Böröczky–Fradelizi regarding stability estimates under the uniformly log-concave assumption.

To establish these results, we develop a new approach based on ideas from the regularizing effect of the Ornstein–Uhlenbeck heat flow.
Motivated by this link, we establish an improvement of Borell’s reverse hypercontractivity inequality for even functions and identify the sharp range of the admissible exponents.","['Blaschke–Santaló inequality', 'Borell’s reverse hypercontractivity', 'Brascamp–Lieb inequality', 'Heat flow monotonicity', 'Stability estimate']",[]
"Experimental particle physics uses machine learning for many of tasks,
where one application is to classify signal and background events.
The classification can be used to bin an analysis region to
enhance the expected significance for a mass resonance search.
In natural language processing, one of the leading neural network architectures
is the transformer.
In this work, an event classifier transformer is proposed to bin an analysis region,
in which the network is trained with special techniques.
The techniques developed here can enhance the significance
and reduce the correlation between the network’s output and the reconstructed mass.
It is found that this trained network can perform better than
boosted decision trees and feed-forward networks.","['mass resonance search', 'transformer', 'significance']",[]
"In today’s era, users have increasingly high expectations regarding the performance and efficiency of communication networks. Network operators aspire to achieve efficient network planning, operation, and optimization through Digital Twin Networks (DTN). The effectiveness of DTN heavily relies on the network model, with graph neural networks (GNN) playing a crucial role in network modeling. However, existing network modeling methods still lack a comprehensive understanding of communication networks. In this paper, we propose DWNet (Deeper and Wider Networks), a heterogeneous graph neural network modeling method based on data-driven approaches that aims to address end-to-end latency and jitter prediction in network models. This method stands out due to two distinctive features: firstly, it introduces deeper levels of state participation in the message passing process; secondly, it extensively integrates relevant features during the feature fusion process. Through experimental validation and evaluation, our model achieves higher prediction accuracy compared to previous research achievements, particularly when dealing with unseen network topologies during model training. Our model not only provides more accurate predictions but also demonstrates stronger generalization capabilities across diverse topological structures.","['digital twin', 'graph neural networks', 'deep learning', 'network modeling']",[]
"In the era of Artificial Intelligence Generated Content (AIGC), conditional multimodal synthesis technologies (e.g., text-to-image, text-to-video, text-to-audio, etc) are gradually reshaping the natural content in the real world. The key to multimodal synthesis technology is to establish the mapping relationship between different modalities. Brain signals, serving as potential reflections of how the brain interprets external information, exhibit a distinctive One-to-Many correspondence with various external modalities. This correspondence makes brain signals emerge as a promising guiding condition for multimodal content synthesis. Brian-conditional multimodal synthesis refers to decoding brain signals back to perceptual experience, which is crucial for developing practical brain-computer interface systems and unraveling complex mechanisms underlying how the brain perceives and comprehends external stimuli. This survey comprehensively examines the emerging field of AIGC-based Brain-conditional Multimodal Synthesis, termed AIGC-Brain, to delineate the current landscape and future directions. To begin, related brain neuroimaging datasets, functional brain regions, and mainstream generative models are introduced as the foundation of AIGC-Brain decoding and analysis. Next, we provide a comprehensive taxonomy for AIGC-Brain decoding models and present task-specific representative work and detailed implementation strategies to facilitate comparison and in-depth analysis. Quality assessments are then introduced for both qualitative and quantitative evaluation. Finally, this survey explores insights gained, providing current challenges and outlining prospects of AIGC-Brain. Being the inaugural survey in this domain, this paper paves the way for the progress of AIGC-Brain research, offering a foundational overview to guide future work. A webpage associated with this survey is available at: https://github.com/MichaelMaiii/AIGC-Brain.",[],[]
"Rendering the visual appearance of moving humans from occluded monocular videos is a challenging task. Most existing research renders 3D humans under ideal conditions, requiring a clear and unobstructed scene. Those methods cannot be used to render humans in real-world scenes where obstacles may block the camera’s view and lead to partial occlusions. In this work, we present Wild2Avatar, a neural rendering approach catered for occluded in-the-wild monocular videos. We propose occlusion-aware scene parameterization for decoupling the scene into three parts - occlusion, human, and background. Additionally, extensive objective functions are designed to help enforce the decoupling of the human from both the occlusion and the background and to ensure the completeness of the human model. We verify the effectiveness of our approach with experiments on in-the-wild videos.",[],[]
"We investigate the magnetic order and related strongly-correlated effects in
an one-dimensional Ising-Kondo lattice with transverse field. This model is
the anisotropic limit of the conventional isotropic Kondo lattice model, in
the sense that the itinerant electrons interact with the localized magnetic
moments via only longitudinal Kondo exchange. Adopting the numerical
density-matrix-renormalization group method, we map out the ground-state
phase diagram in various parameter spaces. Depending on the Kondo coupling
and filling number, three distinct phases, including a metallic
paramagnetic, a metallic ferromagnetic, and a gapped spin-density wave
phase, are obtained. The spin-density wave is characterized by an ordering
wave vector which coincides with the nesting wave vector of the Fermi
surface. This makes the corresponding magnetic transition a spin analog of
the Peierls transition occurring in the one-dimensional metal. Moreover, by
analyzing the momentum distribution function and charge correlation
function, the conduction electrons are shown to behave like free spinless
fermions in the ferromagnetic phase. We finally discuss the effect of the
repulsive Hubbard interaction between conduction electrons. Our work
enriches the Kondo physics and deepens the current understanding of the
heavy fermion compounds.",[],['China']
"We show that a measurable function g:𝕊d−1→ℝ:𝑔→superscript𝕊𝑑1ℝg:\mathbb{S}^{d-1}\to\mathbb{R}italic_g : blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT → blackboard_R, with d≥3𝑑3d\geq 3italic_d ≥ 3, satisfies the functional relation



g⁢(ω)+g⁢(ω*)=g⁢(ω′)+g⁢(ω*′),𝑔𝜔𝑔subscript𝜔𝑔superscript𝜔′𝑔superscriptsubscript𝜔′g(\omega)+g(\omega_{*})=g(\omega^{\prime})+g(\omega_{*}^{\prime}),italic_g ( italic_ω ) + italic_g ( italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT ) = italic_g ( italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) + italic_g ( italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ,



for all admissible ω,ω*,ω′,ω*′∈𝕊d−1𝜔subscript𝜔superscript𝜔′superscriptsubscript𝜔′superscript𝕊𝑑1\omega,\omega_{*},\omega^{\prime},\omega_{*}^{\prime}\in\mathbb{S}^{d-1}italic_ω , italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT , italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT in the sense that




ω+ω*=ω′+ω*′,𝜔subscript𝜔superscript𝜔′superscriptsubscript𝜔′\omega+\omega_{*}=\omega^{\prime}+\omega_{*}^{\prime},italic_ω + italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT = italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT + italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ,



if and only if it can be written as



g⁢(ω)=A+B⋅ω,𝑔𝜔𝐴⋅𝐵𝜔g(\omega)=A+B\cdot\omega,italic_g ( italic_ω ) = italic_A + italic_B ⋅ italic_ω ,



for some constants A∈ℝ𝐴ℝA\in\mathbb{R}italic_A ∈ blackboard_R and B∈ℝd𝐵superscriptℝ𝑑B\in\mathbb{R}^{d}italic_B ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT.

Such functions form a family of quantized collision invariants which play a fundamental role in the study of hydrodynamic regimes of the Boltzmann–Fermi–Dirac equation near Fermionic condensates, i.e., at low temperatures. In particular, they characterize the elastic collisional dynamics of Fermions near a statistical equilibrium where quantum effects are predominant.",[],[]
"Large language models (LLMs) have achieved huge success for their general knowledge and ability to solve a wide spectrum of tasks in natural language processing (NLP). Due to their impressive abilities, LLMs have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S).
In the meantime, utilizing NLP techniques in geoscience research and practice is wide and convoluted, contributing from knowledge extraction and document classification to question answering and knowledge discovery.
In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach. We try to specialize an open-sourced LLM into geoscience, by further pre-training the model with a vast amount of texts in geoscience, as well as supervised fine-tuning (SFT) the resulting model with our custom collected instruction tuning dataset.
These efforts result in a model GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is the largest language model for the geoscience domain.
More specifically, GeoGalactica is from further pre-training of Galactica – a top-performing LLM trained with a large number of scientific documents.
We train GeoGalactica over a geoscience-related text corpus containing 65 billion tokens curated from extensive data sources in the big science project Deep-time Digital Earth (DDE), preserving as the largest geoscience-specific text corpus. Then we fine-tune the model with 1 million pairs of instruction-tuning data consisting of questions that demand professional geoscience knowledge to answer.
We validate GeoGalactica on various geoscience examinations and geoscience-related open-domain questions evaluated by a group of senior geoscientists.
GeoGalactica demonstrates the state-of-the-art performance in a diverse range of NLP tasks in geoscience, as well as revealing the potential of using geoscience-related tools.
In this technical report, we will illustrate in detail all aspects of GeoGalactica, including data collection, data cleaning, base model selection, pre-training, SFT, and evaluation.
We open-source our data curation tools and the checkpoints of GeoGalactica during the first 3/4343/43 / 4 of pre-training in https://github.com/geobrain-ai/geogalactica§§{}^{\lx@sectionsign}start_FLOATSUPERSCRIPT § end_FLOATSUPERSCRIPT.",[],[]
"The Handwritten Mathematical Expression Recognition (HMER) task is a critical branch in the field of OCR. Recent studies have demonstrated that incorporating bidirectional context information significantly improves the performance of HMER models. However, existing methods fail to effectively utilize bidirectional context information during the inference stage. Furthermore, current bidirectional training methods are primarily designed for string decoders and cannot adequately generalize to tree decoders, which offer superior generalization capabilities and structural analysis capacity. In order to overcome these limitations, we propose the Mirror-Flipped Symbol Layout Tree (MF-SLT) and Bidirectional Asynchronous Training (BAT) structure. Our method extends the bidirectional training strategy to the tree decoder, allowing for more effective training by leveraging bidirectional information. Additionally, we analyze the impact of the visual and linguistic perception of the HMER model separately and introduce the Shared Language Modeling (SLM) mechanism. Through the SLM, we enhance the model’s robustness and generalization when dealing with visual ambiguity, particularly in scenarios with abundant training data. Our approach has been validated through extensive experiments, demonstrating its ability to achieve new state-of-the-art results on the CROHME 2014, 2016, and 2019 datasets, as well as the HME100K dataset. The code used in our experiments will be publicly available.",[],[]
"Efficiently finding optimal correspondences between point clouds is crucial for solving both rigid and non-rigid point cloud registration problems. Existing methods often rely on geometric or semantic feature embedding to establish correspondences and estimate transformations or flow fields. Recently, state-of-the-art methods have employed RAFT-like iterative updates to refine the solution. However, these methods have certain limitations. Firstly, their iterative refinement design lacks transparency, and their iterative updates follow a fixed path during the refinement process, which can lead to suboptimal results. Secondly, these methods overlook the importance of refining or optimizing correspondences (or matching matrices) as a precursor to solving transformations or flow fields. They typically compute candidate correspondences based on distances in the point feature space. However, they only project the candidate matching matrix into some matrix space once with Sinkhorn or dual softmax operations to obtain final correspondences. This one-shot projected matching matrix may be far from the globally optimal one, and these approaches do not consider the distribution of the target matching matrix. In this paper, we propose a novel approach that exploits the Denoising Diffusion Model to predict a searching gradient for the optimal matching matrix within the Doubly Stochastic Matrix Space. Our method incorporates the diffusion model to learn a denoising gradient direction. During the reverse denoising process, our method iteratively searches for better solutions along this denoising gradient, which points towards the maximum likelihood direction of the target matching matrix. Our method offers flexibility by allowing the search to start from any initial matching matrix provided by the online backbone or white noise. Along with the trajectory provided by the reverse sampling process, it iteratively approximates the globally optimal solution. To improve efficiency, we utilize the Denoising Diffusion Implicit Model (DDIM) to accelerate the sampling speed. Experimental evaluations on the 3DMatch/3DLoMatch and 4DMatch/4DLoMatch datasets demonstrate the effectiveness of our newly designed framework.",[],[]
"Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators.
However, current sample-wise evaluation paradigm suffers from the following issues:
(1) Sensitive to prompt design;
(2) Poor resistance to noise;
(3) Inferior ensemble performance with static reference.
Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BatchEval, a paradigm that conducts batch-wise evaluation iteratively to alleviate the above problems.
We explore variants under this paradigm and confirm the optimal settings are two stage procedure with heterogeneous batch composition strategy and decimal scoring format.
Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate that BatchEval outperforms state-of-the-art methods by 10.5% on Pearson correlations with only 64% API cost on average.
Further analyses have been conducted to verify the robustness, generalization, and working mechanism of BatchEval111Our code and data have been released on https://github.com/ypw0102/BatchEval..",[],[]
"The ability to locate and classify action segments in long untrimmed video is of particular interest to many applications such as autonomous cars, robotics and healthcare applications. Today, the most popular pipeline for action segmentation is composed of encoding the frames into feature vectors, which are then processed by a temporal model for segmentation. In this paper we present a self-supervised method that comes in the middle of the standard pipeline and generated refined representations of the original feature vectors. Experiments show that this method improves the performance of existing models on different sub-tasks of action segmentation, even without additional hyper parameter tuning.",[],[]
,[],[]
"In contrast to the well-investigated field of SAR-to-Optical translation, this study explores the lesser-investigated domain of Optical-to-SAR translation, a challenging field due to the ill-posed nature of this translation. The complexity arises as a single optical data can have multiple SAR representations based on the SAR viewing geometry. We propose a novel approach, termed SAR Temporal Shifting, which inputs an optical data from the desired timestamp along with a SAR data from a different temporal point but with a consistent viewing geometry as the expected SAR data, both complemented with a change map of optical data during the intervening period. This model modifies the SAR data based on the changes observed in optical data to generate the SAR data for the desired timestamp. Our model, a dual conditional Generative Adversarial Network (GAN), named Temporal Shifting GAN (TSGAN), incorporates a siamese encoder in both the Generator and the Discriminator. To prevent the model from overfitting on the input SAR data, we employed a change weighted loss function.
Our approach surpasses traditional translation methods by eliminating the GAN’s fiction phenomenon, particularly in unchanged regions, resulting in higher SSIM and PSNR in these areas. Additionally, modifications to the Pix2Pix architecture and the inclusion of attention mechanisms have enhanced the model’s performance on all regions of the data. This research paves the way for leveraging legacy optical datasets, the most abundant and longstanding source of Earth datary data, extending their use to SAR domains and temporal analyses. To foster further research, we provide the code, datasets used in our study, and a framework for generating paired SAR-Optical datasets for new regions of interest. These resources are available on GitHub at github.com/moienr/TemporalGAN","['Generative', 'Adversarial', 'Networks (GANs)', 'Attention', 'Mechanism', 'Temporal', 'Shifting', 'Weighted', 'Loss', 'Optical-to-SAR', 'Super', 'Temporal', 'Resolution.']",[]
,[],[]
"The fisheye camera, with its unique wide field of view and other characteristics, has found extensive applications in various fields[1, 2]. However, the fisheye camera suffers from significant distortion compared to pinhole cameras, resulting in distorted images of captured objects. Fish-eye camera distortion is a common issue in digital image processing, requiring effective correction techniques to enhance image quality. This review provides a comprehensive overview of various methods used for fish-eye camera distortion correction[3]. The article explores the polynomial distortion model, which utilizes polynomial functions to model and correct radial distortions. Additionally, alternative approaches such as panorama mapping, grid mapping, direct methods, and deep learning-based methods are discussed. The review highlights the advantages, limitations, and recent advancements of each method, enabling readers to make informed decisions based on their specific needs.",[],[]
"The energy consumption of mobile networks poses a critical challenge.
Mitigating this concern necessitates the deployment and optimization of network energy-saving solutions,
such as carrier shutdown,
to dynamically manage network resources.
Traditional optimization approaches encounter complexity due to factors like the large number of cells, stochastic traffic, channel variations, and intricate trade-offs.
This paper introduces the  simulated reality of communication networks (SRCON) framework, a novel, data-driven modeling paradigm that harnesses live network data and employs a blend of  machine learning (ML)- and expert-based models.
These mix of models accurately characterizes the functioning of network components,
and predicts network energy efficiency and  user equipment (UE) quality of service for any energy carrier shutdown configuration in a specific network.
Distinguishing itself from existing methods,
SRCON eliminates the reliance on expensive expert knowledge, drive testing, or incomplete maps for predicting network performance.
This paper details the pipeline employed by SRCON to decompose the large network energy efficiency modeling problem into ML- and expert-based submodels.
It demonstrates how,
by embracing stochasticity,
and carefully crafting the relationship between such submodels,
the overall computational complexity can be reduced and prediction accuracy enhanced.
Results derived from real network data underscore the paradigm shift introduced by SRCON,
showcasing significant gains over a state-of-the-art method used by a operator for network energy efficiency modeling.
The reliability of this local, data-driven modeling of the network proves to be a key asset for network energy-saving optimization.",[],"['Spain', 'France']"
"The following paper proposes a new target localization system design using an architecture based on reconfigurable intelligent surfaces (RISs) and passive radars (PRs) for integrated sensing and communications systems.
The preamble of the communication signal is exploited in order to perform target sensing tasks, which involve detection and localization.
The RIS in this case can aid the PR in sensing targets that are otherwise not seen by the PR itself, due to the many obstacles encountered within the propagation channel.
Therefore, this work proposes a localization algorithm tailored for the integrated sensing and communications RIS-aided architecture, which is capable of uniquely positioning targets within the scene.
The algorithm is capable of detecting the number of targets along with estimating the position of targets via angles and times of arrival.
Our simulation results demonstrate the performance of the localization method in terms of different localization and detection metrics and for increasing RIS sizes.","['integrated sensing and communications (ISAC)', 'reconfigurable intelligent surfaces (RIS)', '6G', 'localization', 'passive radar']",[]
"The limited energy and computing resources of unmanned aerial vehicles
(UAVs) hinder the application of aerial artificial intelligence. The
utilization of split inference in UAVs garners significant attention
due to its effectiveness in mitigating computing and energy requirements.
However, achieving energy-efficient split inference in UAVs remains
complex considering of various crucial parameters such as energy level
and delay constraints, especially involving multiple tasks. In this
paper, we present a two-timescale approach for energy minimization
in split inference, where discrete and continuous variables are segregated
into two timescales to reduce the size of action space and computational
complexity. This segregation enables the utilization of tiny reinforcement
learning (TRL) for selecting discrete transmission modes for sequential
tasks. Moreover, optimization programming (OP) is embedded between
TRL’s output and reward function to optimize the continuous transmit
power. Specifically, we replace the optimization of transmit power
with that of transmission time to decrease the computational complexity
of OP since we reveal that energy consumption monotonically decreases
with increasing transmission time. The replacement significantly reduces
the feasible region and enables a fast solution according to the closed-form
expression for optimal transmit power. Simulation results show that
the proposed algorithm can achieve a higher probability of successful
task completion with lower energy consumption.","['Power control', 'tiny learning', 'energy-efficient', 'multiple-task split\ninference.']",[]
"Accreting supermassive black holes (SMBHs) frequently power jets that interact with the interstellar/circumgalactic medium (ISM/CGM), regulating star-formation in the galaxy. Highly supersonic jets launched by active galactic nuclei (AGN) power a cocoon that confines them and shocks the ambient medium. We build upon the models of narrow conical jets interacting with a smooth ambient medium, to include the effect of dense clouds that are an essential ingredient of a multiphase ISM. The key physical ingredient of this model is that the clouds along the supersonic jet-beam strongly decelerate the jet-head, but the subsonic cocoon easily moves around the clouds without much resistance. We propose scalings for important physical quantities – cocoon pressure, head & cocoon speed, and jet radius. We obtain, for the first time, the analytic condition on clumpiness of the ambient medium for the jet to dissipate within the cocoon and verify it with numerical simulations of conical jets interacting with a uniform ISM with embedded spherical clouds. A jet is defined to be dissipated when the cocoon speed exceeds the speed of the jet-head. We compare our models to more sophisticated numerical simulations, direct observations of jet-ISM interaction (e.g., quasar J1316+1753), and discuss implications for the Fermi/eROSITA bubbles. Our work also motivates effective subgrid models for AGN jet feedback in a clumpy ISM unresolved by the present generation of cosmological galaxy formation simulations.","['ISM: jets and outflows – galaxies: jets –', 'ISM: clouds – galaxies: clusters: intracluster medium']","['India', 'Israel']"
"In contrast to conventional reconfigurable intelligent surface (RIS),
simultaneous transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) has been proposed recently to enlarge the serving
area from 180osuperscript180𝑜180^{o}180 start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT to 360osuperscript360𝑜360^{o}360 start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT coverage. This work considers the
performance of a STAR-RIS aided full-duplex (FD) non-orthogonal multiple
access (NOMA) communication systems. The STAR-RIS is implemented at
the cell-edge to assist the cell-edge users, while the cell-center
users can communicate directly with a FD base station (BS). We first
introduce new user clustering schemes for the downlink and uplink
transmissions. Then, based on the proposed transmission schemes closed-form
expressions of the ergodic rates in the downlink and uplink modes
are derived taking into account the system impairments caused by the
self interference at the FD-BS and the imperfect successive interference
cancellation (SIC). Moreover, an optimization problem to maximize
the total sum-rate is formulated and solved by optimizing the amplitudes
and the phase-shifts of the STAR-RIS elements and allocating the transmit
power efficiently. The performance of the proposed user clustering
schemes and the optimal STAR-RIS design are investigated through numerical
results.","['STAR-RIS', 'Full-duplex', 'NOMA', 'Sum-rate.']",[]
"Large language model (LLM) scaling laws are empirical formulas that estimate changes in model quality as a result of increasing parameter count and training data. However, these formulas, including the popular DeepMind Chinchilla scaling laws, neglect to include the cost of inference. We modify the Chinchilla scaling laws to calculate the optimal LLM parameter count and pre-training data size to train and deploy a model of a given quality and inference demand. We conduct our analysis both in terms of a compute budget and real-world costs and find that LLM researchers expecting reasonably large inference demand (~1B requests) should train models smaller and longer than Chinchilla-optimal.",[],[]
"Despite recent initiatives aimed at improving accessibility, the field of digital accessibility remains markedly behind contemporary advancements in the software industry as a large number of real world software and web applications continue to fall short of accessibility requirements.
A persisting skills deficit within the existing technology workforce has been an enduring impediment, hindering organizations from delivering truly accessible software products.
This, in turn, elevates the risk of isolating and excluding a substantial portion of potential users.
In this paper, we report lessons learned from a training program for teaching digital accessibility using the Communities of Practice (CoP) framework to industry professionals.
We recruited 66 participants from a large multi-national software company and assigned them to two groups: one participating in a CoP and the other using self-paced learning.
We report experiences from designing the training program, conducting the actual training, and assessing the efficiency of the two approaches.
Based on these findings, we provide recommendations for practitioners in Learnng and Development teams and educators in designing accessibility courses for industry professionals.","['Accessibility (a11y)', 'massive open online courses', 'communities of practice', 'Computing', 'Education']",['India']
"Hybridizing different degrees of freedom or physical platforms potentially offers various advantages in building scalable quantum architectures.
We here introduce a fault-tolerant hybrid quantum computation by taking the advantages of both discrete variable (DV) and continuous variable (CV) systems. Particularly, we define a CV-DV hybrid qubit with bosonic cat-code and single photon, which is implementable in current photonic platforms. By the cat-code encoded in the CV part, the dominant loss errors are readily correctable without multi-qubit encoding, while the logical basis is inherently orthogonal due to the DV part. We design fault-tolerant architectures by concatenating hybrid qubits and an outer DV quantum error correction code such as topological codes, exploring their potential merits in developing scalable quantum computation. We demonstrate by numerical simulations that our scheme is at least an order of magnitude more resource-efficient over all previous proposals in photonic platforms, allowing to achieve a record-high loss threshold among existing CV and hybrid approaches. We discuss its realization not only in all-photonic platforms but also in other hybrid platforms including superconduting and trapped-ion systems, which allows us to find various efficient routes towards fault-tolerant quantum computing.",[],['Australia']
"A UserWay study in 2021 indicates that an annual global e-commerce revenue loss of approximately $16 billion can be attributed to inaccessible websites and applications. According to the 2023 WebAIM study, only 3.7% of the world’s top one million website homepages are fully accessible. This shows that many software developers use poor coding practices that don’t adhere to the Web Content Accessibility Guidelines (WCAG). This research centers on software professionals and their role in addressing accessibility. This work seeks to understand (a) who within the software development community actively practices accessibility, (b) when and how accessibility is considered in the software development lifecycle, (c) the various challenges encountered in building accessible software, and (d) the resources required by software professionals to enhance product accessibility. Our survey of 269 software professionals from India sheds light on the pressing need for accessibility education within the software industry. A substantial majority (69.9%, N=269) of respondents express the need for training materials, workshops, and bootcamps to enhance their accessibility skills. We present a list of actionable recommendations that can be implemented within the industry to promote accessibility awareness and skills. We also open source our raw data for further research, encouraging continued exploration in this domain.","['Accessibility (a11y)', 'Indian', 'IT', 'Industry', 'accessibility education']",['India']
"We deploy an advanced Machine Learning (ML) environment, leveraging a multi-scale cross-attention encoder for event classification, towards the identification of the g⁢g→H→h⁢h→b⁢b¯⁢b⁢b¯→𝑔𝑔𝐻→ℎℎ→𝑏¯𝑏𝑏¯𝑏gg\to H\to hh\to b\bar{b}b\bar{b}italic_g italic_g → italic_H → italic_h italic_h → italic_b over¯ start_ARG italic_b end_ARG italic_b over¯ start_ARG italic_b end_ARG process at the High Luminosity Large Hadron Collider (HL-LHC), where hℎhitalic_h is the discovered Standard Model (SM)-like Higgs boson and H𝐻Hitalic_H a heavier version of it (with mH>2⁢mhsubscript𝑚𝐻2subscript𝑚ℎm_{H}>2m_{h}italic_m start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT > 2 italic_m start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT).  In the ensuing boosted Higgs regime, the final state consists of two fat jets. Our multi-modal network can extract information from the jet substructure and the kinematics of the final state particles through self-attention transformer layers. The diverse learned information is subsequently integrated to improve classification performance using an additional transformer encoder with cross-attention heads. We ultimately prove that our approach surpasses in performance current alternative methods used to establish sensitivity to this process, whether solely based on kinematic analysis or else on a combination of this with mainstream ML approaches. Then, we employ various interpretive methods to evaluate the network results, including attention map analysis and visual representation of Gradient-weighted Class Activation Mapping (Grad-CAM). Finally, we note that the proposed network is generic and can be applied to analyse any process carrying information at different scales. Our code is publicly available for generic use111https://github.com/AHamamd150/Multi-Scale-Transformer-Encoder..",[],[]
"This paper gives a nearly tight characterization of the quantum communication complexity of the permutation-invariant Boolean functions. With such a characterization, we show that the quantum and randomized communication complexity of the permutation-invariant Boolean functions are quadratically equivalent (up to a logarithmic factor). Our results extend a recent line of research regarding query complexity [2, 17, 11] to communication complexity, showing symmetry prevents exponential quantum speedups.
Furthermore, we show the Log-rank Conjecture holds for any non-trivial total permutation-invariant Boolean function. Moreover, we establish a relationship between the quantum/classical communication complexity and the approximate rank of permutation-invariant Boolean functions. This implies the correctness of the Log-approximate-rank Conjecture for permutation-invariant Boolean functions in both randomized and quantum settings (up to a logarithmic factor).",[],[]
"Second-order gravitational self-force theory has recently led to the breakthrough calculation of “first post-adiabatic” (1PA) compact-binary waveforms [Phys. Rev. Lett. 130, 241402 (2023)]. The computations underlying those waveforms depend on a method of solving the perturbative second-order Einstein equation in the Fourier domain. In this paper we present that method, which involves dividing the domain into several regions. Different regions utilize different time slicings and allow for the use of “punctures” to tame sources and enforce physical boundary conditions. We demonstrate the method for Lorenz-gauge and Teukolsky equations in the relatively simple case of calculating parametric derivatives (“slow time derivatives”) of first-order fields, which are an essential input at second order.",[],"['Germany', 'Israel']"
"We study the finite model property of subframe logics with expressible transitive closure modality.
For m>0𝑚0m>0italic_m > 0, let LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT be the logic given by axiom ◆m⁢p→◆⁢p∨p→superscript◆𝑚𝑝◆𝑝𝑝\lozenge^{m}p\rightarrow\lozenge p\vee p◆ start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_p → ◆ italic_p ∨ italic_p.
We construct filtrations for the logics LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. It follows that these logics and their tense counterparts
have the finite model property. Then we show that every canonical subframe logic that contains LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT have the finite model property.",[],[]
"We considered two sequences of spiral galaxies with different shapes of the radial gas-phase oxygen abundance distributions from the galaxies in the survey Mapping Nearby Galaxies
at Apache Point Observatory (MaNGA): (1) Galaxies in which the gradient is well approximated by a single linear relation across the whole disc, that is, galaxies with an S (slope)
gradients, (2) galaxies in which the metallicity in the inner region of the disc is at a nearly constant level and the gradient is negative at larger radii, that is, galaxies with
level-slope (LS) gradients. We also selected galaxies with a nearly uniform oxygen abundance across the whole galaxy, that is, galaxies with level (L) gradients (or O/H uniform
galaxies) with a high oxygen abundance that can be the final evolutionary stage of the two galaxy sequences described above. The radial nitrogen abundance distributions
in galaxies with LS oxygen abundance distributions also show breaks at radii smaller than the O/H distribution breaks. The observed behaviour of the oxygen and nitrogen
abundances with radius in these galaxies can be explained by the time delay between the nitrogen and oxygen enrichment together with the variation in the star formation history
along the radius. These galaxies clearly show the effect of the inside-out disc evolution model, which predicts that the galactic centre evolves more rapidly than
the regions at greater galactocentric distances. We find that the shape of the radial abundance distribution in a galaxy is not related to its macroscopic characteristics (rotation
velocity, stellar mass, isophotal radius, and star formation rate) and is independent of its present-day environment.
The correlations between the gradient slopes and macroscopic characteristics of galaxies are weak in the sense that the scatter of the points in each diagram is large.
The galaxies with different abundance distributions (S, LS, or L) in our sample are located within the main sequence of the star-forming
galaxies in the diagram of star formation rate – stellar mass. We also examined the properties of the Milky Way in the context of the considered galaxy samples.","['galaxies: abundances –', 'ISM: abundances –', 'H\u2009ii regions', 'galaxies']",[]
"We present a surface analog to a dripping faucet, where a viscous liquid slides down an immiscible meniscus.
Periodic pinch-off of the dripping filament is observed, generating a succession of monodisperse floating lenses.
We show that this interfacial dripping faucet can be described analogously to its single-phase counterpart, replacing surface tension by the spreading coefficient, and even undergoes a transition to a jetting regime.
This liquid/liquid/gas system opens perspectives for the study of the dynamics of emulsions at interfaces.",[],"['Spain', 'Netherlands']"
"Autonomous driving technology nowadays targets to level 4 or beyond, but the researchers are faced with some limitations for developing reliable driving algorithms in diverse challenges. To promote the autonomous vehicles to spread widely, it is important to address safety issues on this technology. Among various safety concerns, the sensor blockage problem by severe weather conditions can be one of the most frequent threats for multi-task learning based perception algorithms during autonomous driving. To handle this problem, the importance of the generation of proper datasets is becoming more significant. In this paper, a synthetic road dataset with sensor blockage generated from real road dataset BDD100K is suggested in the format of BDD100K annotation. Rain streaks for each frame were made by an experimentally established equation and translated utilizing the image-to-image translation network based on style transfer. Using this dataset, the degradation of the diverse multi-task networks for autonomous driving, such as lane detection, driving area segmentation, and traffic object detection, has been thoroughly evaluated and analyzed. The tendency of the performance degradation of deep neural network-based perception systems for autonomous vehicle has been analyzed in depth. Finally, we discuss the limitation and the future directions of the deep neural network-based perception algorithms and autonomous driving dataset generation based on image-to-image translation based.",[],[]
"In environmental health research, it is of interest to understand the effect of the neighborhood environment on health. Researchers have shown a protective association between green space around a person’s residential address and depression outcomes. In measuring exposure to green space,
distance buffers are often used. However, buffer distances differ across studies. Typically, the buffer distance is determined by researchers a priori. It is unclear how to identify an appropriate buffer distance for exposure assessment. To address geographic uncertainty problem for exposure assessment, we present a domain selection algorithm based on the penalized functional linear Cox regression model. The theoretical properties of our proposed method are studied and simulation studies are conducted to evaluate finite sample performances of our method. The proposed method is illustrated in a study of associations of green space exposure with depression and/or antidepressant use in the Nurses’ Health Study.",[],['Israel']
"In this article, we prove the existence of rigid analytic families of G𝐺Gitalic_G-stable lattices with locally constant reductions inside families of representations of a topologically compact group G𝐺Gitalic_G, extending a result of Hellman obtained in the semi-simple residual case. Implementing this generalization in the context of Galois representations, we prove a local constancy result for reductions modulo prime powers of trianguline representations of generic dimension d𝑑ditalic_d. Moreover, we present two explicit applications. First, in dimension two, we extend to a prime power setting and to the whole rigid projective line a recent result of Bergdall, Levin and Liu concerning reductions of semi-stable representations of Gal⁢(ℚ¯p/ℚp)Galsubscript¯ℚ𝑝subscriptℚ𝑝\text{Gal}(\overline{\mathbb{Q}}_{p}/\mathbb{Q}_{p})Gal ( over¯ start_ARG blackboard_Q end_ARG start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT / blackboard_Q start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) with fixed Hodge-Tate weights and large ℒℒ\mathcal{L}caligraphic_L-invariant.
Second, in dimension d𝑑ditalic_d, let Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be a sequence of crystalline representations converging in a certain geometric sense to a crystalline representation V𝑉Vitalic_V. We show that for any refined version (V,σ)𝑉𝜎(V,\sigma)( italic_V , italic_σ ) of V𝑉Vitalic_V (or equivalently for any chosen triangulation of its attached (φ,Γ)𝜑Γ(\varphi,\Gamma)( italic_φ , roman_Γ )-module Drig⁢(V)subscript𝐷rig𝑉D_{\text{rig}}(V)italic_D start_POSTSUBSCRIPT rig end_POSTSUBSCRIPT ( italic_V ) over the Robba ring), there exists a sequence of refinement σnsubscript𝜎𝑛\sigma_{n}italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of each of the Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that the limit as refined representations (Vn,σn)subscript𝑉𝑛subscript𝜎𝑛(V_{n},\sigma_{n})( italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) converges to the (V,σ)𝑉𝜎(V,\sigma)( italic_V , italic_σ ). This result does not hold under the weaker assumption that Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT converges only uniformly p𝑝pitalic_p-adically to V𝑉Vitalic_V (in the sense of Chenevier, Khare and Larsen).",[],[]
"In this paper, we present a comparative analysis of various self-supervised Vision Transformers (ViTs), focusing on their local representative power. Inspired by large language models, we examine the abilities of ViTs to perform various computer vision tasks with little to no fine-tuning.
We design evaluation framework to analyze the quality of local, i.e. patch-level, representations in the context of few-shot semantic segmentation, instance identification, object retrieval and tracking.
We discover that contrastive learning based methods like DINO produce more universal patch representations that can be immediately applied for downstream tasks with no parameter tuning, compared to masked image modeling. The embeddings learned using the latter approach, e.g. in masked autoencoders, have high variance features that harm distance-based algorithms, such as k-NN, and do not contain useful information for most downstream tasks.
Furthermore, we demonstrate that removing these high-variance features enhances k-NN by providing an analysis of the benchmarks for this work and for Scale-MAE, a recent extension of masked autoencoders.
Finally, we find an object instance retrieval setting where DINOv2, a model pretrained on two orders of magnitude more data, performs worse than its less compute intensive counterpart DINO.",[],[]
"The usual Sobolev inequality in ℝNsuperscriptℝ𝑁\mathbb{R}^{N}blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT, asserts that ‖∇u‖Lp⁢(ℝN)≥𝒮⁢‖u‖Lp*⁢(ℝN)subscriptnorm∇𝑢superscript𝐿𝑝superscriptℝ𝑁𝒮subscriptnorm𝑢superscript𝐿superscript𝑝superscriptℝ𝑁\|\nabla u\|_{L^{p}(\mathbb{R}^{N})}\geq\mathcal{S}\|u\|_{L^{p^{*}}(\mathbb{R}%
^{N})}∥ ∇ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT ≥ caligraphic_S ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT for 1<p<N1𝑝𝑁1<p<N1 < italic_p < italic_N and p*=p⁢NN−psuperscript𝑝𝑝𝑁𝑁𝑝p^{*}=\frac{pN}{N-p}italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT = divide start_ARG italic_p italic_N end_ARG start_ARG italic_N - italic_p end_ARG, with 𝒮𝒮\mathcal{S}caligraphic_S being the sharp constant. This note is concerned, instead, with function restricted to bounded domain Ω⊂ℝNΩsuperscriptℝ𝑁\Omega\subset\mathbb{R}^{N}roman_Ω ⊂ blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT. Based on the recent work of Figalli and Zhang [Duke Math. J., 2022], a remainder term with weak norm is established



‖∇u‖Lp⁢(Ω)‖u‖Lp*⁢(Ω)−𝒮≥𝒞⁢(‖u‖Lwp¯⁢(Ω)‖u‖Lp*⁢(Ω))max⁡{2,p},∀u∈C0∞⁢(Ω)∖{0},formulae-sequencesubscriptnorm∇𝑢superscript𝐿𝑝Ωsubscriptnorm𝑢superscript𝐿superscript𝑝Ω𝒮𝒞superscriptsubscriptnorm𝑢subscriptsuperscript𝐿¯𝑝𝑤Ωsubscriptnorm𝑢superscript𝐿superscript𝑝Ω2𝑝for-all𝑢subscriptsuperscript𝐶0Ω0\frac{\|\nabla u\|_{L^{p}(\Omega)}}{\|u\|_{L^{p^{*}}(\Omega)}}-\mathcal{S}\geq%
\mathcal{C}\left(\frac{\|u\|_{L^{\bar{p}}_{w}(\Omega)}}{\|u\|_{L^{p^{*}}(%
\Omega)}}\right)^{\max\{2,p\}},\quad\forall u\in C^{\infty}_{0}(\Omega)%
\setminus\{0\},divide start_ARG ∥ ∇ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG - caligraphic_S ≥ caligraphic_C ( divide start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT roman_max { 2 , italic_p } end_POSTSUPERSCRIPT , ∀ italic_u ∈ italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Ω ) ∖ { 0 } ,



for some 𝒞=𝒞⁢(N,p,Ω)>0𝒞𝒞𝑁𝑝Ω0\mathcal{C}=\mathcal{C}(N,p,\Omega)>0caligraphic_C = caligraphic_C ( italic_N , italic_p , roman_Ω ) > 0, where p¯=p*⁢(p−1)/p¯𝑝superscript𝑝𝑝1𝑝\bar{p}=p^{*}(p-1)/pover¯ start_ARG italic_p end_ARG = italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_p - 1 ) / italic_p and ∥⋅∥Lwp¯⁢(Ω)\|\cdot\|_{L^{\bar{p}}_{w}(\Omega)}∥ ⋅ ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT denotes the weak Lp¯superscript𝐿¯𝑝L^{\bar{p}}italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT-norm. Furthermore, the weak norm can not be replaced by the strong norm. This result answers the long-standing open problem raised by Bianchi and Egnell [J. Funct. Anal., 1991].",[],[]
,[],[]
"Symbolic Music Alignment is the process of matching performed MIDI notes to corresponding score notes.
In this paper, we introduce a reinforcement learning (RL)-based online symbolic music alignment technique.
The RL agent — an attention-based neural network — iteratively estimates the current score position from local score and performance contexts.
For this symbolic alignment task, environment states can be sampled exhaustively and the reward is dense, rendering a formulation as a simplified offline RL problem straightforward.
We evaluate the trained agent in three ways.
First, in its capacity to identify correct score positions for sampled test contexts; second, as the core technique of a complete algorithm for symbolic online note-wise alignment; and finally, as a real-time symbolic score follower.
We further investigate the pitch-based score and performance representations used as the agent’s inputs.
To this end, we develop a second model, a two-step Dynamic Time Warping (DTW)-based offline alignment algorithm leveraging the same input representation.
The proposed model outperforms a state-of-the-art reference model of offline symbolic music alignment.",[],[]
,[],[]
"The industrial Internet of Things (IIoT) involves the integration of Internet of Things (IoT) technologies into industrial settings. However, given the high sensitivity of the industry to the security of industrial control system networks and IIoT, the use of software-defined networking (SDN) technology can provide improved security and automation of communication processes. Despite this, the architecture of SDN can give rise to various security threats. Therefore, it is of paramount importance to consider the impact of these threats on SDN-based IIoT environments. Unlike previous research, which focused on security in IIoT and SDN architectures separately, we propose an integrated method including two components that work together seamlessly for better detecting and preventing security threats associated with SDN-based IIoT architectures. The two components consist in a convolutional neural network-based Intrusion Detection System (IDS) implemented as an SDN application and a Blockchain-based system (BS) to empower application layer and network layer security, respectively.
A significant advantage of the proposed method lies in jointly minimizing the impact of attacks such as command injection and rule injection on SDN-based IIoT architecture layers.
The proposed IDS exhibits superior classification accuracy in both binary and multiclass categories.","['Blockchain', 'Industrial', 'IoT', 'SDN', 'Deep learning', 'Intrusion detection system', 'and', 'Security.']",[]
"This review paper examines the concept and advancements in the evolving landscape of Dual-functional Radar Communication (DFRC) systems. Traditionally, radar and communication systems have functioned independently, but current research is actively investigating the integration of these functionalities into a unified platform. This paper discusses the motivations behind the development of DFRC systems, the challenges involved, and the potential benefits they offer. A discussion on the performance bounds for DFRC systems is also presented. The paper encompasses a comprehensive analysis of various techniques, architectures, and technologies used in the design and optimization of DFRC systems, along with their performance and trade-offs. Additionally, we explore potential application scenarios for these joint communication and sensing systems, offering a comprehensive perspective on the multifaceted landscape of DFRC technology.","['Joint', 'Communication and radar/radio', 'Sensing (JCAS)', 'Dual-functional', 'Radar', 'Communications (DFRC)', 'Integrated', 'Sensing and', 'Communications (ISAC)', 'Wireless', 'Communications', 'and', 'Radar.']",[]
"We study M-Theory solutions with G𝐺Gitalic_G-flux on the Fermat sextic Calabi-Yau fourfold, focussing on the relationship between the number of stabilized complex structure moduli and the tadpole contribution of the flux. We use two alternative approaches to define the fluxes: algebraic cycles and (appropriately quantized) Griffiths residues. In both cases, we collect evidence for the non-existence of solutions which stabilize all moduli and stay within the tadpole bound.",[],[]
"Generative models of expressive piano performance are usually assessed by comparing their predictions to a reference human performance.
A generative algorithm is taken to be better than competing ones if it produces
performances that are closer to a human reference performance.
However, expert human performers can (and do) interpret music in different ways, making for different possible references, and quantitative closeness is not necessarily aligned with perceptual similarity, raising concerns about the validity of this evaluation approach.
In this work, we present a number of experiments that shed light on this problem.
Using precisely measured high-quality performances of classical piano music,
we carry out a listening test indicating that listeners can sometimes perceive subtle performance difference that go unnoticed under quantitative evaluation.
We further present tests that indicate that such evaluation frameworks show a lot of variability in reliability and validity across different reference performances and pieces.
We discuss these results and their implications for quantitative evaluation, and hope to foster a critical appreciation of the uncertainties involved in quantitative assessments of such performances within the wider music information retrieval (MIR) community.","['Performance', 'Expression', 'Evaluation', 'Validity', 'Listening', 'Study']",['Austria']
"A proposal is made for what may well be the most elementary Riemannian spaces which are homogeneous but not isotropic. In other words: a proposal is made for what may well be the the nicest symmetric spaces beyond the real space forms, that is, beyond the Riemannian spaces which are homogeneous and isotropic. The above qualification of ‘’nicest symmetric spaces” finds a justification in that, together with the real space forms, these spaces are most natural with respect to the importance in human vision of our ability to readily recognise conformal things and in that  these spaces are most natural with respect to what in Weyl’s view is symmetry in Riemannian geometry.
Following his suggestion to remove the real space forms’ isotropy condition, the quasi space forms thus introduced do offer a metrical, local geometrical solution to the geometrical space form problem as posed by Thurston in his 1979 Princeton Lecture Notes on ‘’The Geometry and Topology of 3-manifolds”. Roughly speaking, quasi space forms are the Riemannian manifolds of dimension greater than or equal to 3, which are not real space forms but which admit two orthogonally complementary distributions such that at all points all the 2-planes that in the tangent spaces there are situated in a same position relative to these distributions do have the same sectional curvatures.",[],[]
"Motivated by the inapproximability of reconfiguration problems,
we present a new PCP-type characterization of \PSPACE\PSPACE\PSPACE, which we call
a probabilistically checkable reconfiguration proof (PCRP):
Any \PSPACE\PSPACE\PSPACE computation can be encoded into an exponentially long sequence of polynomially long proofs
such that
every adjacent pair of the proofs differs in at most one bit,
and every proof can be probabilistically checked by reading a constant number of bits.
Using the new characterization, we prove \PSPACE\PSPACE\PSPACE-completeness of approximate versions of many reconfiguration problems,
such as the Maxmin 3333-SAT Reconfiguration problem.
This resolves the open problem posed by Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno (ISAAC 2008; Theor. Comput. Sci. 2011)
as well as the Reconfiguration Inapproximability Hypothesis by Ohsaka (STACS 2023) affirmatively.
We also present \PSPACE\PSPACE\PSPACE-completeness of approximating the Maxmin Clique Reconfiguration problem
to within a factor of nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT for some constant ε>0𝜀0\varepsilon>0italic_ε > 0.",[],[]
"This study focuses on emotion-sensitive spoken dialogue in human-machine speech interaction. With the advancement of Large Language Models (LLMs), dialogue systems can handle multimodal data, including audio. Recent models have enhanced the understanding of complex audio signals through the integration of various audio events. However, they are unable to generate appropriate responses based on emotional speech. To address this, we introduce the Emotional chat Model (E-chat), a novel spoken dialogue system capable of comprehending and responding to emotions conveyed from speech. This model leverages an emotion embedding extracted by a speech encoder, combined with LLMs, enabling it to respond according to different emotional contexts. Additionally, we introduce the E-chat200 dataset, designed explicitly for emotion-sensitive spoken dialogue. In various evaluation metrics, E-chat consistently outperforms baseline LLMs, demonstrating its potential in emotional comprehension and human-machine interaction.",[],[]
,[],[]
"Although user cooperation cannot improve the capacity of Gaussian two-way channels (GTWCs) with independent noises, it can improve communication reliability.
In this work,
we aim to enhance and balance the communication reliability in GTWCs by minimizing the sum of error probabilities via joint design of encoders and decoders at the users.
We first formulate general encoding/decoding functions, where the user cooperation is captured by the coupling of user encoding processes.
The coupling effect renders the encoder/decoder design non-trivial, requiring effective decoding to capture this effect, as well as efficient power management at the encoders within power constraints.
To address these challenges,
we propose two different two-way coding strategies: linear coding and learning-based coding.
For linear coding,
we propose optimal linear decoding and discuss new
insights on encoding regarding user cooperation to balance reliability.
We then propose an efficient algorithm
for joint encoder/decoder design.
For learning-based coding, we introduce a novel recurrent neural network (RNN)-based coding architecture, where we propose interactive RNNs and a power control layer for encoding, and we incorporate bi-directional RNNs with an attention mechanism for decoding.
Through simulations, we show that our two-way coding methodologies outperform conventional channel coding schemes (that do not utilize user cooperation) significantly in sum-error performance.
We also demonstrate that our linear coding
excels at high signal-to-noise ratios (SNRs), while
our RNN-based coding performs best at low SNRs.
We further investigate our two-way coding strategies in terms of power distribution, two-way coding benefit, different coding rates, and block-length gain.","['Gaussian two-way channels', 'communication reliability', 'user cooperation', 'linear coding', 'neural coding']",[]
"In this paper, we study the large-time behavior of small solutions to the standard form of the systems of 1D cubic nonlinear Schrödinger equations consisting of two components and possessing a coercive mass-like conserved quantity.
The cubic nonlinearity is known to be critical in one space dimension in view of the large-time behavior.
By employing the result by Katayama and Sakoda, one can obtain the large-time behavior of the solution if we can integrate the corresponding ODE system.
We introduce an integration scheme suited to the system. The key idea is to rewrite the ODE system, which is cubic, as a quadratic system of quadratic quantities of the original unknown.
By using this technique, we described the large-time behavior of solutions in terms of elementary functions and the Jacobi elliptic functions for several examples of standard systems.","['nonlinear', 'Schrödinger equation', 'system', 'nonlinear ordinary differential system', 'explicit solution of nonlinear ordinary differential system', 'asymptotic behavior', 'Jacobi elliptic function']",[]
"In this paper we consider the vector-valued Schrödinger operator −Δ+VΔ𝑉-\Delta+V- roman_Δ + italic_V, where the potential term V𝑉Vitalic_V is a matrix-valued function whose entries belong to Lloc1⁢(ℝd)subscriptsuperscript𝐿1locsuperscriptℝ𝑑L^{1}_{\rm loc}({\mathbb{R}}^{d})italic_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) and, for every x∈ℝd𝑥superscriptℝ𝑑x\in{\mathbb{R}}^{d}italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, V⁢(x)𝑉𝑥V(x)italic_V ( italic_x ) is a symmetric and nonnegative definite matrix, with non positive off-diagonal terms and with eigenvalues comparable each other. For this class of potential terms we obtain maximal inequality in L1⁢(ℝd,ℝm).superscript𝐿1superscriptℝ𝑑superscriptℝ𝑚L^{1}({\mathbb{R}}^{d},{\mathbb{R}}^{m}).italic_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ) . Assuming further that the minimal eigenvalue of V𝑉Vitalic_V belongs to some reverse Hölder class of order q∈(1,∞)∪{∞}𝑞1q\in(1,\infty)\cup\{\infty\}italic_q ∈ ( 1 , ∞ ) ∪ { ∞ }, we obtain maximal inequality in Lp⁢(ℝd,ℝm)superscript𝐿𝑝superscriptℝ𝑑superscriptℝ𝑚L^{p}({\mathbb{R}}^{d},{\mathbb{R}}^{m})italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ), for p𝑝pitalic_p in between 1111 and some q𝑞qitalic_q.","['Vector-valued elliptic operators', 'Schrödinger operators with unbounded coefficients', 'vector-valued analytic semigroups', 'domain characterization', 'Lebesgue', 'Lpsuperscript𝐿𝑝L^{p}italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT-spaces', 'reverse', 'Hölder class.']",[]
"To improve our understanding of the quark-gluon dynamics underlying multiquark states, we systematically study their electromagnetic properties. In this study, the electromagnetic properties of the X⁢(4140)X4140\mathrm{X(4140)}roman_X ( 4140 ) and X⁢(4630)X4630\mathrm{X(4630)}roman_X ( 4630 ) states with the quantum numbers JPC=1++superscriptJPCsuperscript1absent\mathrm{J^{PC}=1^{++}}roman_J start_POSTSUPERSCRIPT roman_PC end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + + end_POSTSUPERSCRIPT and JPC=1−+superscriptJPCsuperscript1absent\mathrm{J^{PC}=1^{-+}}roman_J start_POSTSUPERSCRIPT roman_PC end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT - + end_POSTSUPERSCRIPT, respectively are investigated within the framework of the QCD light-cone sum rules method by considering the diquark-antidiquark configuration of these states. We also calculate the magnetic and quadrupole moments of the theoretically predicted singly-charmed state, XAVsubscriptXAV\mathrm{X_{AV}}roman_X start_POSTSUBSCRIPT roman_AV end_POSTSUBSCRIPT, with the quantum numbers JP=1+superscriptJPsuperscript1\mathrm{J^{P}=1^{+}}roman_J start_POSTSUPERSCRIPT roman_P end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. The predicted results for the magnetic moments are as μX⁢(4140)=−1.11−0.31+0.41⁢μNsubscript𝜇X4140subscriptsuperscript1.110.410.31subscript𝜇𝑁\mu_{\mathrm{X(4140)}}=-1.11^{+0.41}_{-0.31}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X ( 4140 ) end_POSTSUBSCRIPT = - 1.11 start_POSTSUPERSCRIPT + 0.41 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.31 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, μX⁢(4630)=−0.62−0.11+0.13⁢μNsubscript𝜇X4630subscriptsuperscript0.620.130.11subscript𝜇𝑁\mu_{\mathrm{X(4630)}}=-0.62^{+0.13}_{-0.11}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X ( 4630 ) end_POSTSUBSCRIPT = - 0.62 start_POSTSUPERSCRIPT + 0.13 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.11 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, and μXAV=−0.98−0.21+0.27⁢μNsubscript𝜇subscriptXAVsubscriptsuperscript0.980.270.21subscript𝜇𝑁\mu_{\mathrm{X_{AV}}}=-0.98^{+0.27}_{-0.21}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X start_POSTSUBSCRIPT roman_AV end_POSTSUBSCRIPT end_POSTSUBSCRIPT = - 0.98 start_POSTSUPERSCRIPT + 0.27 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.21 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. The results obtained can be useful in determining the exact nature of these states. This work will hopefully stimulate experimental interest in the study of the electromagnetic properties of multiquark systems.","['Magnetic and quadrupole moments', 'tetraquarks', 'diquark-antidiquark picture', 'QCD light-cone sum rules']",[]
"The successful commercialization of flexible spintronic devices requires a complete understanding of the impact of external strain on the structural, electronic, and magnetic properties of a system. The impact of bending-induced strain on flexible films is studied quite well. However, little is known about the effect of other modes of flexibility, e.g., wrinkling, twisting, peeling, and stretching on the functional properties of flexible films. In this context, perpendicular magnetic anisotropic Co/Pt and Co/Pd thin films are prepared on flexible Kapton substrates, and the impact of the peeling mode is studied in detail. The peeling method generates numerous cracks, and buckling in the thin film, along with localized blister formation imaged by scanning electron microscopy. Further, the resistivity measurement confirms a significant enhancement in sample resistance owing to the severe damage of the films. The structural discontinuities strongly affect the magnetization reversal phenomena as measured by the magneto-optic Kerr effect (MOKE)-based microscopy. The bubble domains got converted to elongated-shaped domains due to several hindrances to the wall motion after strain application. Further, the relaxation measurements reveal that the thermal energy is insufficient to switch the magnetization at a few areas due to their high pinning potential associated with the damages. In contrast to bending-induced strain, here, all the modifications in the functional properties are found to be irreversible in nature.",[],['India']
"A recent study has demonstrated that a fermionic two-leg ladder model, threaded by a flux and characterized by a spatially varying interleg hopping term, gives rise to a quasiflat low-energy band. This band exhibits an unusual ground state at half filling in the presence of interaction—a ferromagnetic Mott insulator. In this paper, we extend the study of this model to other fillings of the quasiflat band and explore the magnetic properties of the ground state at these fillings. In particular, we study four fillings: one-quarter, three-quarters, slightly above half filling (half filling plus two electrons), and slightly below half-filling (half filling minus two electrons). Incorporating interaction within the Hubbard model and using the Density Matrix Renormalization Group method to find the ground states, we find that the spin-spin correlation is ferromagnetic at fillings less than half, similar to that observed at half filling, but is antiferromagnetic beyond half filling. Interestingly, these results hold only when mixing between the lowest quasiflat band and the next-to-lowest dispersive band is negligible; once mixing between the two bands is facilitated by increasing the interaction strength, the correlation becomes ferromagnetic above half filling as well. Additionally, by reducing the strength of the interaction in comparison to the bandwidth, a transition from the ferromagnetic to the antiferromagnetic state is observed in all the cases.",[],['India']
"The flow of cerebrospinal fluid through the perivascular spaces of the brain is believed to play a crucial role in eliminating toxic waste proteins. While the driving forces of this flow have been enigmatic, experiments have shown that arterial wall motion is central. In this work, we present a network model for simulating pulsatile fluid flow in perivascular networks. We establish the well-posedness of this model in the primal and dual mixed variational settings, and show how it can be discretized using mixed finite elements. Further, we utilize this model to investigate fundamental questions concerning the physical mechanisms governing perivascular fluid flow. Notably, our findings reveal that arterial pulsations can induce directional flow in branching perivascular networks.",[],[]
"We establish Jafarian’s 2009 conjecture that every additive spectrum preserving mapping from a von Neumann algebra
onto a semisimple Banach algebra is a Jordan isomorphism.","['Von', 'Neumann algebras', 'Jordan isomorphisms', 'spectrum preserving mappings']",[]
"Development of power efficient spintronics devices has been the compelling need in the post-CMOS technology era. The effective tunability of spin-orbit-coupling (SOC) in bulk and at the interfaces of hybrid materials stacking is a prerequisite for scaling down the dimension and power consumption of these devices. In this work, we demonstrate the strong chemisorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules when grown on the high SOC β𝛽\betaitalic_β-W layer. The parent CFB/β𝛽\betaitalic_β-W bilayer exhibits large spin-to-charge interconversion efficiency, which can be ascribed to the interfacial SOC observed at the Ferromagnet/Heavy metal interface. Further, the adsorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules on β𝛽\betaitalic_β-W reduces the effective Gilbert damping by ∼similar-to\sim∼15%percent\%% in the CFB/β𝛽\betaitalic_β-W/C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT heterostructures. The anti-damping is accompanied by a gigantic ∼similar-to\sim∼115%percent\%% enhancement in the spin-pumping induced output voltage owing to the molecular hybridization. The non-collinear Density Functional Theory calculations confirm the long-range enhancement of SOC of β𝛽\betaitalic_β-W upon the chemisorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules, which in turn can also enhance the SOC at the CFB/β𝛽\betaitalic_β-W interface in CFB/β𝛽\betaitalic_β-W/C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT heterostructures. The combined amplification of bulk as well interfacial SOC upon molecular hybridization stabilizes the anti-damping and enhanced spin-to-charge conversion, which can pave the way for the fabrication of power efficient spintronics devices.",[],['India']
"Organic semiconductors (OSCs) are suitable materials for spintronics applications as they form a spinterface when placed next to a ferromagnet, which in turn leads to novel functionalities. The evolution of spinterface can tune the global magnetic anisotropy, magnetization reversal, magnetization dynamics etc. Planar
tris(8-hydroxy-
quinoline)aluminium (Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT) OSC has shown tremendous potential for spintronics application, thanks to its efficient spin-polarized current transport ability. Here, we establish the spinterface when the Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT molecules are deposited on amorphous ferromagnet Co2020{}_{20}start_FLOATSUBSCRIPT 20 end_FLOATSUBSCRIPTFe6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPTB2020{}_{20}start_FLOATSUBSCRIPT 20 end_FLOATSUBSCRIPT(CFB). The π𝜋\piitalic_π-d𝑑ditalic_d hybridization in CFB/Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT enhances the coercive field and significantly modifies the shape and size of the magnetic domains. A∼similar-to\sim∼ 100%percent\%% increase in uniaxial anisotropic energies and a reduction in magnetic damping are also evident owing to the strong interfacial hybridization.",[],['India']
"Understanding the physical properties of stars, and putting these properties into the context of stellar evolution, is a core challenge in astronomical research. A key visualization in studying stellar evolution is the Hertzsprung-Russell diagram (HRD), organizing data about stellar luminosity and colour into a form that is informative about stellar structure and evolution. However, connecting the HRD with other sources of information, including stellar time series, is an outstanding challenge. Here we present a new method to turn stellar time series into sound. This method encodes physically meaningful features such that auditory comparisons between sonifications of different stars preserve astrophysical differences between them. We present an interactive multimedia version of the HRD that combines both visual and auditory components and that allows exploration of different types of stars both on and off the main sequence through both visual and auditory media.",[],[]
"Motivated by classical Alexander invariants of affine hypersurface complements, we endow certain finite dimensional quotients of the homology of abelian covers of complex algebraic varieties with a canonical and functorial mixed Hodge structure (MHS). More precisely, we focus on covers which arise algebraically in the following way: if U𝑈Uitalic_U is a smooth connected complex algebraic variety and G𝐺Gitalic_G is a complex semiabelian variety, the pullback of the exponential map by an algebraic morphism f:U→G:𝑓→𝑈𝐺f:U\to Gitalic_f : italic_U → italic_G yields a covering space π:Uf→U:𝜋→superscript𝑈𝑓𝑈\pi:U^{f}\to Uitalic_π : italic_U start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT → italic_U whose group of deck transformations is π1⁢(G)subscript𝜋1𝐺\pi_{1}(G)italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_G ). The new MHS are compatible with Deligne’s MHS on the homology of U𝑈Uitalic_U through the covering map π𝜋\piitalic_π and satisfy a direct sum decomposition as MHS into generalized eigenspaces by the action of deck transformations. This provides a vast generalization of the previous results regarding univariable Alexander modules of the authors, Geske, Maxim and Wang. Lastly, we reduce the problem of whether the first Betti number of the Milnor fiber of a central hyperplane arrangement complement is combinatorial to a question about the Hodge filtration of certain MHS defined in this paper, providing evidence that the new structures contain interesting information.","['abelian cover', 'Alexander module', 'mixed', 'Hodge structure', 'thickened complex', 'hyperplane arrangements', 'jump loci']",[]
"Several disciplines, like the social sciences, epidemiology, sentiment analysis, or market research, are interested in knowing the distribution of the classes in a population rather than the individual labels of the members thereof. Quantification is the supervised machine learning task concerned with obtaining accurate predictors of class prevalence, and to do so particularly in the presence of label shift. The distribution-matching (DM) approaches represent one of the most important families among the quantification methods that have been proposed in the literature so far. Current DM approaches model the involved populations by means of histograms of posterior probabilities. In this paper, we argue that their application to the multiclass setting is suboptimal since the histograms become class-specific, thus missing the opportunity to model inter-class information that may exist in the data. We propose a new representation mechanism based on multivariate densities that we model via kernel density estimation (KDE). The experiments we have carried out show our method, dubbed KDEy, yields superior quantification performance with respect to previous DM approaches. We also investigate the KDE-based representation within the maximum likelihood framework and show KDEy often shows superior performance with respect to the expectation-maximization method for quantification, arguably the strongest contender in the quantification arena to date.",[],[]
"The dyadic representation of any singular integral operator, as an average of dyadic model operators, has found many applications. While for many purposes it is enough to have such a representation for a “suitable class” of test functions, we show that, under quite general assumptions (essentially minimal ones to make sense of the formula), the representation is actually valid for all pairs (f,g)∈Lp⁢(ℝd)×Lp′⁢(ℝd)𝑓𝑔superscript𝐿𝑝superscriptℝ𝑑superscript𝐿superscript𝑝′superscriptℝ𝑑(f,g)\in L^{p}(\mathbb{R}^{d})\times L^{p^{\prime}}(\mathbb{R}^{d})( italic_f , italic_g ) ∈ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) × italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ), not just test functions.","['Singular integral', 'dyadic shift']",[]
"Consider Hermitian and symmetric random band matrices H=(σx⁢y⁢Ax⁢y)𝐻subscript𝜎𝑥𝑦subscript𝐴𝑥𝑦H=(\sigma_{xy}A_{xy})italic_H = ( italic_σ start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT ) on the d𝑑ditalic_d-dimensional lattice (ℤ/L⁢ℤ)dsuperscriptℤ𝐿ℤ𝑑\left(\mathbb{Z}/{L\mathbb{Z}}\right)^{d}( blackboard_Z / italic_L blackboard_Z ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, where Ax⁢y=Ay⁢x¯subscript𝐴𝑥𝑦¯subscript𝐴𝑦𝑥A_{xy}=\overline{A_{yx}}italic_A start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT = over¯ start_ARG italic_A start_POSTSUBSCRIPT italic_y italic_x end_POSTSUBSCRIPT end_ARG are independent uniformly distributed random variables on S1superscript𝑆1S^{1}italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT or {+1,−1}11\{+1,-1\}{ + 1 , - 1 }, and the variance profile σx⁢y2subscriptsuperscript𝜎2𝑥𝑦\sigma^{2}_{xy}italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT is characterized by the bandwidth W𝑊Witalic_W and α𝛼\alphaitalic_α-stable density with α∈(0,2]𝛼02\alpha\in(0,2]italic_α ∈ ( 0 , 2 ].
We investigate local eigenvalue statistics at the spectral edge as W→∞→𝑊W\to\inftyitalic_W → ∞ and observe the critical dimension dc=3⁢αsubscript𝑑𝑐3𝛼d_{c}=3\alphaitalic_d start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 3 italic_α and the critical bandwidth Wc=L(1−d3⁢α)+subscript𝑊𝑐superscript𝐿subscript1𝑑3𝛼W_{c}=L^{(1-\frac{d}{3\alpha})_{+}}italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = italic_L start_POSTSUPERSCRIPT ( 1 - divide start_ARG italic_d end_ARG start_ARG 3 italic_α end_ARG ) start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, possibly with a log⁡L𝐿\log Lroman_log italic_L correction when d=α𝑑𝛼d=\alphaitalic_d = italic_α or 2⁢α2𝛼2\alpha2 italic_α. In the Hermitian case, we establish that
(i) when d<2⁢α𝑑2𝛼d<2\alphaitalic_d < 2 italic_α, GUE edge, interpolating, and Poisson statistics emerge in the supercritical (W≫Wcmuch-greater-than𝑊subscript𝑊𝑐W\gg W_{c}italic_W ≫ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT), critical (W∼Wcsimilar-to𝑊subscript𝑊𝑐W\sim W_{c}italic_W ∼ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT), and subcritical (W≪Wcmuch-less-than𝑊subscript𝑊𝑐W\ll W_{c}italic_W ≪ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT) regimes, respectively;
(ii) when d≥2⁢α𝑑2𝛼d\geq 2\alphaitalic_d ≥ 2 italic_α, as long as W≥L13+ϵ𝑊superscript𝐿13italic-ϵW\geq L^{\frac{1}{3}+\epsilon}italic_W ≥ italic_L start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 3 end_ARG + italic_ϵ end_POSTSUPERSCRIPT for a small constant ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, GUE edge universality holds.
In the symmetric case, we also establish similar but subtle phenomena. In both d=1𝑑1d=1italic_d = 1 and α=2𝛼2\alpha=2italic_α = 2, the subcritical and supercritical results have been proven by Sodin for the band model with a cutoff variance profile [Sod10]. Our proof builds upon Sodin’s program and new techniques of taming the singularity of Feynman diagrams and graph integrals through a connection to the ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT model.",[],[]
"Random Batch Methods (RBM) for mean-field interacting particle systems enable the reduction of the quadratic computational cost associated with particle interactions to a near-linear cost. The essence of these algorithms lies in the random partitioning of the particle ensemble into smaller batches at each time step. The interaction of each particle within these batches is then evolved until the subsequent time step. This approach effectively decreases the computational cost by an order of magnitude while increasing the amount of fluctuations due to the random partitioning. In this work, we propose a variance reduction technique for RBM applied to nonlocal PDEs of Fokker-Planck type based on a control variate strategy. The core idea is to construct a surrogate model that can be computed on the full set of particles at a linear cost while maintaining enough correlations with the original particle dynamics. Examples from models of collective behavior in opinion spreading and swarming dynamics demonstrate the great potential of the present approach.
Keywords: Random batch methods, control variate methods, surrogate models, collective behavior, nonlocal PDEs",[],[]
"We review the method for constructing local relativistic fields corresponding to the Bargmann-Wigner wave functions that describe
the unitary irreducible representations of the 4⁢D4𝐷4D4 italic_D Poincaré group.
The method is based on the use of the generalized Wigner operator
connecting the wave functions of induced representations and local relativistic fields.
Applications of this operator for constructing
massive local relativistic fields as well as massless helicity local fields and massless local infinite spin fields are considered.",[],[]
"In this talk, we give the lattice regularized formulation of the mixed ’t Hooft anomaly between the ℤNsubscriptℤ𝑁\mathbb{Z}_{N}blackboard_Z start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT 1111-form symmetry and the θ𝜃\thetaitalic_θ periodicity for 4444d pure Yang-Mills theory, which was originally discussed by Gaiotto et al. in the continuum description.
For this purpose, we define the topological charge of the lattice S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) gauge theory coupled with the background ℤNsubscriptℤ𝑁\mathbb{Z}_{N}blackboard_Z start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT 2222-form gauge fields Bpsubscript𝐵𝑝B_{p}italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT by generalizing Lüscher’s construction of the S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) topological charge.
We show that this lattice topological charge enjoys the fractional 1/N1𝑁1/N1 / italic_N shift completely characterized by the background gauge field Bpsubscript𝐵𝑝B_{p}italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, and this rigorously proves the mixed ’t Hooft anomaly with the finite lattice spacings.
As a consequence, the Yang-Mills vacua at θ𝜃\thetaitalic_θ and θ+2⁢π𝜃2𝜋\theta+2\piitalic_θ + 2 italic_π are distinct as the symmetry-protected topological states when the confinement is assumed.",[],[]
"Surgical tool segmentation and action recognition are fundamental building blocks in many computer-assisted intervention applications, ranging from surgical skills assessment to decision support systems. Nowadays, learning-based action recognition and segmentation approaches outperform classical methods, relying, however, on large, annotated datasets. Furthermore, action recognition and tool segmentation algorithms are often trained and make predictions in isolation from each other, without exploiting potential cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we release the first multimodal, publicly available, in-vivo, dataset for surgical action recognition and semantic instrumentation segmentation, containing 50 suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The aim of the challenge is twofold. First, to enable researchers to leverage the scale of the provided dataset and develop robust and highly accurate single-task action recognition and tool segmentation approaches in the surgical domain. Second, to further explore the potential of multitask-based learning approaches and determine their comparative advantage against their single-task counterparts. A total of 12 teams participated in the challenge, contributing 7 action recognition methods, 9 instrument segmentation techniques, and 4 multitask approaches that integrated both action recognition and instrument segmentation.",[],[]
"We characterize the sequences of complex numbers (zn)n∈ℕsubscriptsubscript𝑧𝑛𝑛ℕ(z_{n})_{n\in\mathbb{N}}( italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT and the locally complete (D⁢F)𝐷𝐹(DF)( italic_D italic_F )-spaces E𝐸Eitalic_E such that for each (en)n∈ℕ∈Eℕsubscriptsubscript𝑒𝑛𝑛ℕsuperscript𝐸ℕ(e_{n})_{n\in\mathbb{N}}\in E^{\mathbb{N}}( italic_e start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT ∈ italic_E start_POSTSUPERSCRIPT blackboard_N end_POSTSUPERSCRIPT there exists an E𝐸Eitalic_E-valued function 𝐟𝐟\mathbf{f}bold_f on (0,∞)0(0,\infty)( 0 , ∞ ) (satisfying a mild regularity condition) such that




∫0∞tzn⁢𝐟⁢(t)⁢𝑑t=en,∀n∈ℕ,formulae-sequencesuperscriptsubscript0superscript𝑡subscript𝑧𝑛𝐟𝑡differential-d𝑡subscript𝑒𝑛for-all𝑛ℕ\int_{0}^{\infty}t^{z_{n}}\mathbf{f}(t)dt=e_{n},\qquad\forall n\in\mathbb{N},∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_f ( italic_t ) italic_d italic_t = italic_e start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , ∀ italic_n ∈ blackboard_N ,



where the integral should be understood as a Pettis integral. Moreover, in this case, we show that there always exists a solution 𝐟𝐟\mathbf{f}bold_f that is smooth on (0,∞)0(0,\infty)( 0 , ∞ ) and satisfies certain optimal growth bounds near 00 and ∞\infty∞.
The scalar-valued case (E=ℂ)𝐸ℂ(E=\mathbb{C})( italic_E = blackboard_C ) was treated by Durán [13]. Our work is based upon his result.",['Stieltjes moment problem weighted spaces of (vector-valued) smooth functions linear topological invariants vector-valued integration'],[]
"By virtue of being atomically thin, the electronic properties of heterostructures built from two-dimensional materials are strongly influenced by atomic relaxation where the atomic layers should be thought of as membranes rather than rigid 2D crystals. We develop an analytical treatment of lattice relaxation for twisted 2D moiré materials obtaining semi-analytical results for lattice displacements, real and momentum space moiré potentials, pseudomagnetic fields and electronic band structures. We benchmark our results for twisted bilayer graphene and twisted homobilayers of tungsten diselenide using large-scale molecular dynamics simulations finding that our theory is valid for magic angle twisted bilayer graphene (angles ≳1∘greater-than-or-equivalent-toabsentsuperscript1\gtrsim 1^{\circ}≳ 1 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT), and for twisted TMDs for twist angles ≳greater-than-or-equivalent-to\gtrsim≳ 7 degrees.",[],[]
,[],[]
"We construct the deformation quantization with separation of variables on the Grassmannian G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ). The star product on G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ) can be explicitly determined as the solution of the recurrence relations for G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ) given by Hara and one of the authors (A. S.). To give the solution of the recurrence relations, it is necessary to solve a system of linear equations at each order. However, to give the concrete expression of the general term is not easy because the variables increase with the order of the differentiation of the star product. For this reason, there has been no formula to express the general term of the recurrence relations. In this paper, by overcoming this problem by transforming the recurrence relations into simpler ones, we obtain the formula for the general term. We solve the recurrence relations by using creation and annihilation operators on a Fock space. From this solution, we obtain the explicit formula of the star product with separation of variables on G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ).",[],[]
"We study the flow stability and spatio-temporal spectral dynamics of cellulose nanocrystal (CNC) suspensions in a custom Taylor-Couette flow cell using the intrinsic shear induced birefringence and liquid crystalline properties of CNC suspensions for flow visualizations for the first time. The analysis is performed at constant ramped speed inputs of the independently rotating cylinders for several cases ranging from only inner or outer rotating cylinders to three counter-rotation cases. All CNC suspensions have measurable elastic and shear thinning, both increasing with CNC concentration. We show that the flow patterns recorded are essentially Newtonian-like, with non-Newtonian effects ranging from a decrease in wavenumbers to altering the critical parameters for the onset of instability modes. Outer cylinder rotation flow cases are stable for all concentrations whereas inner cylinder rotation flow cases transition to axisymmetric and azimuthally periodic secondary flows. However, unstable counter-rotation cases become unstable to asymmetric spiral modes. With increasing CNC concentration a counter-rotation case was found where azimuthally periodic wavy patterns transition to asymmetric spiral modes. In contrast to polymeric solutions of similar low to moderate elasticity and shear thinning, the shear-thinning region of CNC suspensions is expected to lead to the breakdown of the chiral nematic phase, whose elastic constants constitute the dominant structural elasticity mechanism. Thus, we interpret the Taylor-Couette stability of the CNC suspensions as dominated by their shear-thinning character due to the expected loss of elasticity in nonlinear flow conditions.",[],"['Switzerland', 'Sweden']"
,[],[]
"This paper aims to introduce and analyze the Viz system in a comprehensive way, a novel system architecture that integrates Quantized Low-Rank Adapters (QLoRA) to fine-tune large language models (LLM) within a legally compliant and resource efficient marketplace. Viz represents a significant contribution to the field of artificial intelligence, particularly in addressing the challenges of computational efficiency, legal compliance, and economic sustainability in the utilization and monetization of LLMs. The paper delineates the scholarly discourse and developments that have informed the creation of Viz, focusing primarily on the advancements in LLM models, copyright issues in AI training The New York Times Company (2023), and the evolution of model fine-tuning techniques, particularly low-rank adapters and quantized low-rank adapters, to create a sustainable and economically compliant framework for LLM utilization.The economic model it proposes benefits content creators, AI developers, and end-users, delineating a harmonious integration of technology, economy, and law, offering a comprehensive solution to the complex challenges of today’s AI landscape.",[],[]
,[],[]
"Higher-order cellular automata (HOCA) are a type of cellular automata that evolve over multiple time steps. These HOCA generate intricate patterns within the spacetime lattice, which can be utilized to create symmetry-protected topological (SPT) phases. The symmetries of these phases are not global, but act on lower-dimensional subsystems of the lattice, such as lines or fractals. These are referred to as HOCA generated SPT (HGSPT) phases. These phases naturally encompass previously studied phases with subsystem symmetries, including symmetry-protected topological phases protected by symmetries supported on regular (e.g., line-like, membrane-like) and fractal subsystems.
Moreover, these phases include models with subsystem symmetries that extend beyond previously studied phases. They include mixed-subsystem SPT (MSPT) that possess two types of subsystem symmetries simultaneously (for example, fractal and line-like subsystem symmetries or two different fractal symmetries), and chaotic SPT (CSPT) that have chaos-like symmetries, beyond the classification of fractal or regular subsystems.
We propose that each HOCA pattern with a finite initial condition can be represented by a mathematical object X=(d,M)𝑋𝑑𝑀X=(d,M)italic_X = ( italic_d , italic_M ), and HOCA rules 𝐟𝐟\mathbf{f}bold_f can be categorized into different classes [𝐟]delimited-[]𝐟[\mathbf{f}][ bold_f ] based on the pattern that the rule can generate. The class of the HOCA rule of a given HGSPT can be identified by what we dub as the multi-point strange correlator, as a generalization of the strange correlator. We have raised a general procedure to construct multi-point strange correlators to detect the nontrivial SPT orders in the gapped ground states of HGSPT models and the their classes.",[],['China']
"We consider a Josephson junction built with the two-dimensional semi-Dirac semimetal, which features a hybrid of linear and quadratic dispersion around a nodal point. We model the weak link between the two superconducting regions by a Dirac delta potential because it mimics the thin-barrier limit of a superconductor-barrier-superconductor configuration. Assuming a homogeneous pairing in each region, we set up the BdG formalism for electronlike and holelike quasiparticles propagating along the quadratic-in-momentum dispersion direction. This allows us to compute the discrete bound-state energy spectrum ε𝜀\varepsilonitalic_ε of the subgap Andreev states localized at the junction.
In contrast with the Josephson effect investigated for propagation along linearly dispersing directions,
we find a pair of doubly degenerate Andreev bound states. Using the dependence of ε𝜀\varepsilonitalic_ε on the superconducting phase difference ϕitalic-ϕ\phiitalic_ϕ, we compute the variation of Josephson current as a function of ϕitalic-ϕ\phiitalic_ϕ.",[],['India']
,[],[]
"Amplification of quantum transfer and ratchet–type processes are important for quantum technologies. We also expect that quantum ratchet works in quantum photosynthesis, where possible role of quantum effects is now widely discussed but the underlying dynamical processes are still not clearly known. In this work, we study a model of amplification of quantum transfer and making it directed which we call the quantum ratchet model. The model is based on a special quantum control master equation with dynamics induced by a feedback-type process. The ratchet effect is achieved in the quantum control model with dissipation and sink, where the Hamiltonian depends on vibrations in the energy difference synchronized with transitions between energy levels. A similarity between this model and the model of coherent transport in quantum photosynthesis, where the time dependence of the Hamiltonian arises due to vibrons, is studied. Amplitude and frequency of the oscillating vibron together with the dephasing rate are the parameters of the quantum ratchet which determine its efficiency. We study with which parameters the quantum ratchet minimizes the exction recombination time and show that the experimentally known values of the parameters of the photosynthetic reaction center correspond to values of the parameters of the quantum ratchet which realize a local minimum of the exciton recombination time. We also find another values of the parameters of the quantum ratchet minimizing the exciton recombination time, which corresponds to a twice smaller frequency of the vibron compared to that observed in experiments.",[],[]
"The classical notion of twisted product is studied in the context of partial actions, in particular, we show that the globalization of a partial action is a twisted product. In addition, we establish conditions for the metrizability of twisted products, and some homotopy and categorical properties are proved. Furthermore, sufficient conditions for the enveloping space to be an equivariant absolute neighborhood extensor are also studied.",[],[]
"The family of Matérn kernels are often used in spatial statistics, function approximation and Gaussian process methods in machine learning.
One reason for their popularity is the presence of a smoothness parameter that controls, for example, optimal error bounds for kriging and posterior contraction rates in Gaussian process regression.
On closed Riemannian manifolds, we show that the smoothness parameter can be consistently estimated from the maximizer(s) of the Gaussian likelihood when the underlying data are from point evaluations of a Gaussian process and, perhaps surprisingly, even when the data comprise evaluations of a non-Gaussian process.
The points at which the process is observed need not have any particular spatial structure beyond quasi-uniformity.
Our methods are based on results from approximation theory for the Sobolev scale of Hilbert spaces.
Moreover, we generalize a well-known equivalence of measures phenomenon related to Matérn kernels to the non-Gaussian case by using Kakutani’s theorem.","['62M30', '62F12', '60G30', '62R30', 'Whittle–Matérn kernel', 'Parameter estimation', 'Equivalence of measures', 'Maximum likelihood']",[]
,[],[]
,[],[]
"It is believed that for metric-like models in the KPZ class the following property holds: with probability one, starting from any point, there are at most two semi-infinite geodesics with the same direction that do not coalesce. Until now, such a result was only proved for one model - exponential LPP [Cou11] using its inherent connection to the totally asymmetric exclusion process. We prove that the above property holds for the directed landscape, the universal scaling limit of models in the KPZ class. Our proof reduces the problem to one on line ensembles and therefore paves the way to show similar results for other metric-like models in the KPZ class. Finally, combining our result with the ones in [BSS22, Bha23] we obtain the full qualitative geometric description of infinite geodesics in the directed landscape.",[],[]
"In this study we employ staggered fermions to calculate the two-pion taste singlet states at rest. Leveraging the Clebsch-Gordan coefficients of the symmetry group associated with staggered fermions, we effectively compute the π⁢π𝜋𝜋\pi\piitalic_π italic_π contributions to the resting ρ𝜌\rhoitalic_ρ-meson correlator. To discern the distinct energy states involved, we adopt a generalized eigenvalue problem-solving approach. This work will provide insight into the important role played by the two-pion contribution to the anomalous magnetic moment of the muon.
In this paper we present our group theoretic considerations and preliminary results on the contribution of two-pion states to the rho meson correlation function.",[],[]
,[],[]
"Numerous statistical methods have been developed to explore genomic imprinting and maternal effects,
which are causes of parent-of-origin patterns in complex human diseases. However, most of them either
only model one of these two confounded epigenetic effects, or make strong yet unrealistic assumptions
about the population to avoid over- parameterization. A recent partial likelihood method (LIME)
can identify both epigenetic effects based on case-control family data without those assumptions.
Theoretical and empirical studies have shown its validity and robustness. However, because LIME
obtains parameter estimation by maximizing partial likelihood, it is interesting to compare its efficiency
with full likelihood maximizer. To overcome the difficulty in over-parameterization when using full
likelihood, in this study we propose a Monte Carlo Expectation Maximization (MCEM) method to
detect imprinting and maternal effects jointly. Those unknown mating type probabilities, the nuisance
parameters, can be considered as latent variables in EM algorithm. Monte Carlo samples are used to
numerically approximate the expectation function that cannot be solved algebraically. Our simulation
results show that though this MCEM algorithm takes longer computational time, and can give higher bias in some simulations compared to LIME, it can generally detect both epigenetic effects with higher power and smaller standard error which demonstrates that it can be a good complement of LIME method.",[],[]
"The main result of this note is that the shift of the parameter by 1 in the parameter space of decomposing measures in the problem of harmonic analysis on the infinite-dimensional unitary group corresponds to the taking of the reduced Palm measure at infinity for our decomposing measures. The proof proceeds by finite-dimensional approximation of our measures by orthogonal polynomial ensembles. The key remark is that the taking the reduced Palm measure commutes with the scaling limit transition from finite to infinite particle systems.{NoHyper}
††Keywords: determinantal point processes, Palm measure, infinite-dimensional unitary group, orthogonal polynomial ensemble, integrable kernel, Neretin theorem, Hua—Pickrell measure, confluent hypergeometric kernel, Borodin—Olshanski conjecture

MSC: Primary 60G55; Secondary 05E10

The author was supported by a grant of the Government of the Russian Federation for the state support of scientific research, carried out under the supervision of leading scientists, agreement 075-15-2021-602.",[],[]
"Entanglement swapping (ES) between memory repeater links is critical for establishing quantum networks via quantum repeaters. So far, ES with atomic-ensemble-based memories has not been achieved. Here, we experimentally demonstrated ES between two entangled pairs of spin-wave memories via Duan-Lukin-Cirac-Zoller scheme. With a cloud of cold atoms inserted in a cavity, we produce non-classically-correlated spin-wave-photon pairs in 12 spatial modes and then prepare two entangled pairs of spin-wave memories via a multiplexed scheme. Via single-photon Bell measurement on retrieved fields from two memories, we project the two remaining memories never entangled previously into an entangled state with the measured concurrence of 𝒞=0.0124±0.003𝒞plus-or-minus0.01240.003{\cal C}=0.0124\pm 0.003caligraphic_C = 0.0124 ± 0.003. The successful probability of ES in our scheme is increased by three times, compared with that in non-multiplexed scheme. Our presented work shows that the generation of entanglement (𝒞>0𝒞0{\cal C}>0caligraphic_C > 0) between the remaining memory ensembles requires the average cross-correlation function of the spin-wave-photon pairs to be ≥30absent30\geq 30≥ 30.",[],['China']
"Numerous statistical methods have been developed to explore genomic imprinting and maternal effects, which are causes of parent-of-origin patterns in complex human diseases. Most of the methods, however, either only model one of these two confounded epigenetic effects, or make strong yet unrealistic assumptions about the population to avoid over- parameterization. A recent partial likelihood method (L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT) can identify both epigenetic effects based on discordant sibpair family data without those assumptions. Theoretical and empirical studies have shown its validity and robustness. As L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT method obtains parameter estimation by maximizing partial likelihood, it is interesting to compare its efficiency with full likelihood maximizer. To overcome the difficulty in over-parameterization when using full likelihood, this study proposes a discordant sib-pair design based Monte Carlo Expectation Maximization (M⁢C⁢E⁢MD⁢S⁢P𝑀𝐶𝐸subscript𝑀𝐷𝑆𝑃MCEM_{DSP}italic_M italic_C italic_E italic_M start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT) method to detect imprinting and maternal effects jointly. Those unknown mating type probabilities, the nuisance parameters, are considered as latent variables in EM algorithm. Monte Carlo samples are used to numerically approximate the expectation function that cannot be solved algebraically. Our simulation results show that though this M⁢C⁢E⁢MD⁢S⁢P𝑀𝐶𝐸subscript𝑀𝐷𝑆𝑃MCEM_{DSP}italic_M italic_C italic_E italic_M start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT algorithm takes longer computation time, it can generally detect both epigenetic effects with higher power, which demonstrates that it can be a good complement of L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT method.",[],[]
"Accurate air quality forecasting is of paramount importance in the domains of public health, environmental monitoring and protection, and urban planning. However, existing methods often fail to effectively utilize information across different scales (varying spatial distances or temporal periods). Spatially, previous methods struggle to integrate information between individual monitoring stations and the overall city-scale, lacking flexibility in their interactions. Temporally, existing techniques often overlook or do not fully consider the periodic nature of variations in air quality, thus disregarding valuable insights across different time scales. To address these limitations, we present a novel Multi-spatial Multi-temporal air quality forecasting method based on Graph Convolutional Networks and Gated Recurrent Units (M2G2), bridging the gap in air quality forecasting across spatial and temporal scales. The proposed framework consists of two modules: Multi-scale Spatial GCN (MS-GCN) for spatial information fusion and Multi-scale Temporal GRU(MT-GRU) for temporal information integration. In the spatial dimension, the MS-GCN module employs a bidirectional learnable structure and a residual structure, enabling comprehensive information exchange between individual monitoring stations and the city-scale graph. Regarding the temporal dimension, the MT-GRU module adaptively combines information from different temporal scales through parallel hidden states. Leveraging meteorological indicators and four air quality indicators, we present comprehensive comparative analyses and ablation experiments, showcasing the higher accuracy of M2G2 in comparison to nine currently available advanced approaches across all aspects. The improvements of M2G2 over the second-best method on MAE and RMSE are as follows: PM2.5: (6.22%, 6.63%, 9.71%) and (7.72%, 6.67%, 10.45%), PM10subscriptPM10{\rm PM}_{10}roman_PM start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT: (5.78%, 5.52%, 8.26%) and (6.43%, 5.68%, 7.73%, NO2subscriptNO2{\rm NO}_{2}roman_NO start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT: (5.40%, 9.73%, 19.45%) and (5.07%, 7.76%, 16.60%), O3subscriptO3{\rm O}_{3}roman_O start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT: (7.61%, 7.17%, 10.37%) and (6.46%, 6.86%, 9.79%). Furthermore, we demonstrate the effectiveness of each module of M2G2 by ablation study. Our proposed approach not only addresses the limitations of existing methods but also showcases its potential for advancing air quality forecasting using deep learning techniques.",[],"['Sweden', 'China']"
"This study is centered on precisely calculating analytical critical points for rotating Bardeen-AdS black holes, examining scenarios with and without external dark field contributions. Importantly, this study represents the inaugural attempt to address the computation of critical points specifically for this category of black holes. Our primary focus is on investigating the impact resulting from variations in the charge of nonlinear electrodynamics on the critical phenomena of rotating Bardeen black holes, incorporating the influence of quintessence field contributions. The analytical investigation is concentrated on the horizon radius, employing two distinct approaches to simplify the complexity and length of the calculations. Furthermore, our examination extends to deciphering the intricate relationship between dark energy and critical phenomena. This includes visually portraying a range of critical behaviors while detailing a recent discovery regarding how the intensity of quintessence affects phase transitions. The shifts in these transitions conform to either a concave or convex function, a characteristic dependent on the sign of quintessence intensity.",[],[]
"Deep learning techniques have been applied in the context of image super-resolution (SR), achieving remarkable advances in terms of reconstruction performance. Existing techniques typically employ highly complex model structures which result in large model sizes and slow inference speeds. This often leads to high energy consumption and restricts their adoption for practical applications. To address this issue, this work employs a three-stage workflow for compressing deep SR models which significantly reduces their memory requirement. Restoration performance has been maintained through teacher-student knowledge distillation using a newly designed distillation loss. We have applied this approach to two popular image super-resolution networks, SwinIR and EDSR, to demonstrate its effectiveness. The resulting compact models, SwinIRmini and EDSRmini, attain an 89% and 96% reduction in both model size and floating-point operations (FLOPs) respectively, compared to their original versions. They also retain competitive super-resolution performance compared to their original models and other commonly used SR approaches. The source code and pre-trained models for these two lightweight SR approaches are released at https://pikapi22.github.io/CDISM/.","['Image super-resolution', 'complexity reduction', 'model compression', 'knowledge distillation']",[]
"In continual learning from demonstration (CLfD), a robot learns a sequence of real-world motion skills continually from human demonstrations. Recently, hypernetworks have been successful in solving this problem. In this paper, we perform an exploratory study of the effects of different optimizers, initializers, and network architectures on the continual learning performance of hypernetworks for CLfD. Our results show that adaptive learning rate optimizers work well, but initializers specially designed for hypernetworks offer no advantages for CLfD. We also show that hypernetworks that are capable of stable trajectory predictions are robust to different network architectures. Our open-source code is available at https://github.com/sebastianbergner/ExploringCLFD.",[],[]
"The Influence Maximization problem under the Independent Cascade model (IC) is considered. The problem asks for a minimal set of vertices to serve as seed set from which a maximum influence propagation is expected.
New seed-set selection methods are introduced based on the notions of a d𝑑ditalic_d-packing and vertex centrality. In particular, we focus on selecting seed-vertices that are far apart and whose influence-values are the highest in their local communities. Our best results are achieved via an initial computation of a d𝑑ditalic_d-Packing followed by selecting either vertices of high degree or high centrality in their respective closed neighborhoods.
This overall Pack and Measure approach proves highly effective as a seed selection method.",[],['Lebanon']
"Given the recent advances in quantum technology, the complexity of quantum states is an important notion. The idea of the Krylov spread complexity has come into focus recently with the goal of capturing this in a quantitative way. The present paper sheds new light on the Krylov complexity measure by exploring it in the context of continuous-time quantum-walks on graphs. A close relationship between Krylov spread complexity and the concept of limiting-distributions for quantum-walks is established. Moreover, using a graph optimization algorithm, quantum-walk graphs are constructed that have minimal and maximal (long-time average) Krylov 𝒞¯¯𝒞\bar{\mathcal{C}}over¯ start_ARG caligraphic_C end_ARG-complexity. This reveals an empirical upper bound for the 𝒞¯¯𝒞\bar{\mathcal{C}}over¯ start_ARG caligraphic_C end_ARG-complexity as a function of Hilbert space dimension and an exact lower bound.",[],['Germany']
"The aim of this note is to estimate the tail of the distribution of the number of particles in an interval under determinantal and Pfaffian point processes. The main result of the note is that the square of the number of particles under the determinantal point process whose correlation kernel is an entire function of finite order has sub-Poissonian tails. The same result also holds in the symplectic Pfaffian case. As a corollary, sub-Poissonian estimates are also obtained for exponential moments of additive functionals over pairs of particles.",[],[]
"We show that under standard assumptions on the isotropy groups of an integer GKM
manifold, the equivariant Stiefel–Whitney classes of the action are determined
by the GKM graph. This is achieved via a GKM-style description of the
equivariant cohomology with coefficients in a finite field ℤpsubscriptℤ𝑝\mathbb{Z}_{p}blackboard_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT even though in this setting the
restriction map to the fixed point set is not necessarily injective. This closes a gap in our
argument why the GKM graph of a 6666-dimensional integer GKM manifold determines
its nonequivariant diffeomorphism type. We introduce combinatorial
Stiefel–Whitney classes of GKM graphs and use them to derive a nontrivial
obstruction to realizability of GKM graphs in dimension 8888 and higher.",[],[]
"We introduce GraphGPT, a novel model for Graph learning by self-supervised Generative Pre-training Transformers.
Our model transforms each graph or sampled subgraph into a sequence of tokens representing the node, edge and attributes reversibly using the Eulerian path first.
Then we feed the tokens into a standard transformer decoder and pre-train it with the next-token-prediction (NTP) task.
Lastly, we fine-tune the GraphGPT model with the supervised tasks.
This intuitive, yet effective model achieves superior or close results to the state-of-the-art methods for the graph-, edge- and node-level tasks on the large scale molecular dataset PCQM4Mv2, the protein-protein association dataset ogbl-ppa and the ogbn-proteins dataset from the Open Graph Benchmark (OGB).
Furthermore, the generative pre-training enables us to train GraphGPT up to 400M+ parameters with consistently increasing performance, which is beyond the capability of GNNs and previous graph transformers.
The source code and pre-trained checkpoints will be released soon111https://github.com/alibaba/graph-gpt to pave the way for the graph foundation model research, and also to assist the scientific discovery in pharmaceutical, chemistry, material and bio-informatics domains, etc.",[],[]
"We demonstrate that non-Hermitian perturbations can probe topological phase transitions and unambiguously detect non-Abelian zero modes. We show that under carefully designed non-Hermitian perturbations, the Loschmidt echo(LE) decays into 1/N where N is the ground state degeneracy in the topological non-trivial phase, while it approaches 1 in the trivial phase. This distinction is robust against small parameter deviations in the non-Hermitian perturbations. We further study four well-known models that support Majorana or parafermionic zero modes. By calculating their dynamical responses to specific non-Hermitian perturbations, we prove that the steady-state LE can indeed differentiate between different phases. This method avoids the ambiguity introduced by trivial zero-energy states and thus provides an alternative and promising way to demonstrate the emergence of topologically non-trivial phases. The experimental realizations of non-Hermitian perturbations are discussed.",[],['China']
"Recently, Steinberg used discrete Morse theory to give a new proof of a theorem of Symonds that the orbit space of the poset of nontrivial p𝑝pitalic_p-subgroups of a finite group is contractible. We extend Steinberg’s argument in two ways, covering more general versions of the theorem that were already known. In particular, following a strategy of Libman, we give a discrete Morse theoretic argument for the contractibility of the orbit space of a saturated fusion system.",[],[]
,[],[]
"The paper considers the convergence of the complex block Jacobi diagonalization methods under the large set of the generalized serial pivot strategies. The global convergence of the block methods for Hermitian, normal and J𝐽Jitalic_J-Hermitian matrices is proven. In order to obtain the convergence results for the block methods that solve other eigenvalue problems, such as the generalized eigenvalue problem, we consider the convergence of a general block iterative process which uses the complex block Jacobi annihilators and operators.","['complex block', 'Jacobi method', 'complex block', 'Jacobi operators', 'global convergence', 'Hermitian matrices', 'normal matrices', 'J-Hermitian matrices']",[]
"In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered substantial attention due to its potential impact on financial markets and investment strategies. This paper propose a comparative study on hybrid machine learning algorithms and leverage on enhancing model interpretability. Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM), decision tree regressors are introduced. Through the grounded experiments, we observe linear regressor achieves the best performance among candidate models. For the interpretability, we carry out a systematic overview on the preprocessing techniques of time-series statistics, including decomposition, auto-correlational function, exponential triple forecasting, which aim to excavate latent relations and complex patterns appeared in the financial time-series forecasting. We believe this work may derive more attention and inspire more researches in the realm of time-series analysis and its realistic applications.",[],[]
"Speech emotion recognition (SER) has received a great deal of attention in recent years in the context of spontaneous conversations. While there have been notable results on datasets like the well-known corpus of naturalistic dyadic conversations, IEMOCAP, for both the case of categorical and dimensional emotions, there are few papers which try to predict both paradigms at the same time. Therefore, in this work, we aim to highlight the performance contribution of multi-task learning by proposing a multi-task, multi-modal system that predicts categorical and dimensional emotions. The results emphasise the importance of cross-regularisation between the two types of emotions. Our approach consists of a multi-task, multi-modal architecture that uses parallel feature refinement through self-attention for the feature of each modality. In order to fuse the features, our model introduces a set of learnable bridge tokens that merge the acoustic and linguistic features with the help of cross-attention. Our experiments for categorical emotions on 10-fold validation yield results comparable to the current state-of-the-art. In our configuration, our multi-task approach provides better results compared to learning each paradigm separately. On top of that, our best performing model achieves a high result for valence compared to the previous multi-task experiments.",[],['France']
"We prove that the anisotropy of quadratic forms over any global field of characteristic not equal to 2222 is diophantine, by using a generalization of the method of Koenigsmann, and some known results in diophantine sets and quadratic forms.",[],[]
"This paper presents a new technique to study the adsorption and desorption of ions and electrons on insulating surfaces in the presence of strong electric fields in cryoliquids. The experimental design consists of a compact cryostat coupled with a sensitive electro-optical Kerr device to monitor the stability of the electric fields. The behavior of nitrogen and helium ions on a poly(methyl methacrylate) (PMMA) surface was compared to a PMMA surface coated with a mixture of deuterated polystyrene and deuterated polybutadiene. Ion accumulation and removal on these surfaces were unambiguously observed. Within the precision of the data, both surfaces behave similarly for the physisorbed ions. The setup was also used to measure the (quasi-)static dielectric constant of PMMA at T = 70 K. The impact of the ion adsorption on the search for a neutron permanent electric dipole moment in a cryogenic environment, like the nEDM@SNS experiment, is discussed.",[],"['Germany', 'Canada']"
"In this paper we study short-time behavior of the at-the-money implied volatility for Inverse and Quanto Inverse European options with fixed strike price.
The asset price is assumed to follow a general stochastic volatility process. Using techniques of the Malliavin calculus such as the anticipating Itô’s formula we first compute the level of the implied volatility of the option when the maturity converges to zero. Then, we find a short maturity asymptotic formula for the skew of the implied volatility that depends on the roughness of the volatility model. We apply our general results to the SABR and fractional Bergomi models, and provide some numerical simulations that confirm the accurateness of the asymptotic formula for the skew.",[],[]
,[],[]
"For an ideal I𝐼Iitalic_I in a Noetherian ring R𝑅Ritalic_R, the Fitting ideals Fittj⁡(I)subscriptFitt𝑗𝐼\operatorname{Fitt}_{j}(I)roman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) are studied. We discuss the question of when Fittj⁡(I)=IsubscriptFitt𝑗𝐼𝐼\operatorname{Fitt}_{j}(I)=Iroman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) = italic_I or Fittj⁡(I)=IsubscriptFitt𝑗𝐼𝐼\sqrt{\operatorname{Fitt}_{j}(I)}=\sqrt{I}square-root start_ARG roman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) end_ARG = square-root start_ARG italic_I end_ARG for some j𝑗jitalic_j. A classical case is the Hilbert-Burch theorem when j=1𝑗1j=1italic_j = 1 and I𝐼Iitalic_I is a perfect ideal of grade 2222 in a local ring.","['Fitting ideal', 'Hilbert-Burch', 'Theorem', 'canonical module']",[]
"We present a general convex relaxation approach to study a wide class of Unbalanced Optimal Transport problems for finite non-negative measures with possibly different masses. These are obtained as the lower semicontinuous and convex envelope of a cost for non-negative Dirac masses.
New general primal-dual formulations, optimality conditions, and metric-topological properties are carefully studied and discussed.","['Unbalanced', 'Optimal', 'Transport', 'Kantorovich-Monge problem', 'Optimality conditions']",[]
"Fix a positive integer n𝑛nitalic_n, a real number p∈(0,1]𝑝01p\in(0,1]italic_p ∈ ( 0 , 1 ], and a (perhaps random)
hypergraph ℋℋ\mathcal{H}caligraphic_H on [n]delimited-[]𝑛[n][ italic_n ].
We introduce and investigate the following
random multigraph model, which we denote 𝔾⁢(n,p;ℋ)𝔾𝑛𝑝ℋ\mathbb{G}(n,p\,;\,\mathcal{H})blackboard_G ( italic_n , italic_p ; caligraphic_H ):
begin with an empty graph on n𝑛nitalic_n vertices, which are labelled by the set [n]delimited-[]𝑛[n][ italic_n ].
For every H∈ℋ𝐻ℋH\in\mathcal{H}italic_H ∈ caligraphic_H choose, independently from previous choices, a doubleton from H𝐻Hitalic_H, say D={i,j}⊂H𝐷𝑖𝑗𝐻D=\{i,j\}\subset Hitalic_D = { italic_i , italic_j } ⊂ italic_H, uniformly at random and then introduce an edge
between the vertices i𝑖iitalic_i and j𝑗jitalic_j in the graph
with probability p𝑝pitalic_p, where each edge is introduced independently of all other edges.",[],[]
,[],[]
"Context:The recent parameterisation by the GSP-Spec module of Gaia/Radial Velocity Spectrometer stellar spectra has produced an homogeneous catalogue of about 174,000 Asymptotic Giant Branch (AGB) stars. Among the 13 chemical elements presented in this Gaia third data release, the abundance of two of them (cerium and neodynium) have been estimated in most of these AGB. These two species are formed by slow neutron captures (s𝑠sitalic_s-process) in the interior of low- and intermediate-mass stars. They belong to the family of second peak s𝑠sitalic_s-process elements.
Aims:We study the content and production rate of Ce and Nd in AGB stars, using the atmospheric parameters and chemical abundances derived by the GSP-Spec module.
Methods:We define a working sample of 19,544 AGB stars having high-quality Ce and/or Nd abundances, selected by applying a specific combination of the GSP-Spec quality flags. We compare these abundances with the yield production predicted by AGB evolutionary models.
Results:We first confirmed that the majority of the working sample is composed of AGB stars by estimating their absolute magnitude in the K𝐾Kitalic_K-band and their properties in a Gaia-2MASS diagram. We also checked that these stars are oxygen-rich AGBs, as assumed during the GSP-Spec parameterisation. A good correlation between the Ce and Nd abundances is found, confirming the high quality of the derived abundances and that these species indeed belong to the same s𝑠sitalic_s-process family. We also found higher Ce and Nd abundances for more evolved AGB stars of similar metallicity, illustrating the successive mixing episodes enriching the AGB surface in s𝑠sitalic_s-process elements formed deeper in their stellar interior. We then compared the observed Ce and Nd abundances with FRUITY and Monash AGB yields and found that the higher Ce and Nd abundances can not be explained by AGBs of mass higher than 5 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. On the contrary, the yields predicted by both models for AGB with an initial mass between ∼similar-to\sim∼1.5 and ∼similar-to\sim∼2.5 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT and metallicities between ∼similar-to\sim∼-0.5 and ∼similar-to\sim∼0.0 dex are fully compatible with the observed GSP-Spec  abundances.
Conclusions:This work, based on the largest catalogue of high-quality second-peak s𝑠sitalic_s-elements abundances in oxygen-rich AGB, allows to constrain evolutionary models and confirms the fundamental role played by low- and intermediate-mass stars in the enrichment of the Universe in these chemical species.","['Galaxy: abundances', 'disc', 'halo', 'Stars: abundances', 'evolution', 'AGB and post-AGB']",[]
"RGB, infrared, multispectral, and other modal data fundamentally represent different observational approaches to the same geographic object. Therefore, leveraging multimodal data is an inherent requirement for comprehending geographic objects. However, for a long time, due to the high heterogeneity in structure and semantics among various spatiotemporal modal data, the joint interpretation of multimodal spatiotemporal data has been an extremely challenging problem. The primary challenge resides in striking a trade-off between the cohesion and autonomy of diverse modalities, and this trade-off exhibits a progressively nonlinear nature as the number of modalities expands. Inspired by the human cognitive system and linguistic philosophy, where perceptual signals from the five senses converge into language, we introduce the Language as Reference Framework (LaRF), a fundamental principle for constructing a multimodal unified model, aiming to strike a trade-off between the cohesion and autonomy among different modalities. Building upon this, we propose a multimodal spatiotemporal general artificial intelligence model, called AllSpark. Our model integrates thirteen different modalities into a unified framework, including one-dimensional (text, code), two-dimensional (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs, trajectory, oblique photography), and three-dimensional (point clouds, videos) modalities. To achieve modal cohesion, AllSpark uniformly maps diverse modal features to the language modality. In addition, we design modality-specific prompts to guide multi-modal large language models in accurately perceiving multimodal data. To maintain modality autonomy, AllSpark introduces modality-specific encoders to extract the tokens of various spatiotemporal modalities. And modal bridge is employed to achieve dimensional projection from each modality to the language modality. Finally, observing a gap between the model’s interpretation and downstream tasks, we designed task heads to enhance the model’s generalization capability on specific downstream tasks. Experiments indicate that AllSpark, without expert knowledge of the most spatiotemporal modalities and utilizing a unified structure, achieves competitive accuracy in modalities such as RGB and trajectory compared to state-of-the-art models. Moreover, AllSpark showcases excellent adaptability in modalities like MSI, HSI, PointCloud, Table, Code, and Graph. AllSpark demonstrates the potential and possibility of constructing general artificial intelligence with a large language model. This approach contributes to the shift in research paradigm in spatiotemporal intelligence, transitioning from a modality-specific and task-specific paradigm to a general paradigm.",[],[]
"We study chance constrained optimization problems minx⁡f⁢(x)subscript𝑥𝑓𝑥\min_{x}f(x)roman_min start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x ) s.t. P⁢({θ:g⁢(x,θ)≤0})≥1−ϵ𝑃conditional-set𝜃𝑔𝑥𝜃01italic-ϵP(\mathopen{}\mathclose{{}\left\{\theta:g(x,\theta)\leq 0}\right\})\geq 1-\epsilonitalic_P ( { italic_θ : italic_g ( italic_x , italic_θ ) ≤ 0 } ) ≥ 1 - italic_ϵ where ϵ∈(0,1)italic-ϵ01\epsilon\in(0,1)italic_ϵ ∈ ( 0 , 1 ) is the violation probability, when the distribution P𝑃Pitalic_P is not known to the decision maker (DM). When the DM has access to a set of distributions 𝒰𝒰\mathcal{U}caligraphic_U such that P𝑃Pitalic_P is contained in 𝒰𝒰\mathcal{U}caligraphic_U, then the problem is known as the ambiguous chance-constrained problem [1]. We study ambiguous chance-constrained problem for the case when 𝒰𝒰\mathcal{U}caligraphic_U is of the form {μ:μ⁢(y)ν⁢(y)≤C,∀y∈Θ,μ⁢(y)≥0}conditional-set𝜇formulae-sequence𝜇𝑦𝜈𝑦𝐶formulae-sequencefor-all𝑦Θ𝜇𝑦0\mathopen{}\mathclose{{}\left\{\mu:\frac{\mu(y)}{\nu(y)}\leq C,\forall y\in%
\Theta,\mu(y)\geq 0}\right\}{ italic_μ : divide start_ARG italic_μ ( italic_y ) end_ARG start_ARG italic_ν ( italic_y ) end_ARG ≤ italic_C , ∀ italic_y ∈ roman_Θ , italic_μ ( italic_y ) ≥ 0 }, where ν𝜈\nuitalic_ν is a “reference distribution.” We show that in this case the original problem can be “well-approximated” by a sampled problem in which N𝑁Nitalic_N i.i.d. samples of θ𝜃\thetaitalic_θ are drawn from ν𝜈\nuitalic_ν, and the original constraint is replaced with g⁢(x,θi)≤0,i=1,2,…,Nformulae-sequence𝑔𝑥subscript𝜃𝑖0𝑖12…𝑁g(x,\theta_{i})\leq 0,~{}i=1,2,\ldots,Nitalic_g ( italic_x , italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ≤ 0 , italic_i = 1 , 2 , … , italic_N. We also derive the sample complexity associated with this approximation, i.e., for ϵ,δ>0italic-ϵ𝛿0\epsilon,\delta>0italic_ϵ , italic_δ > 0 the number of samples which must be drawn from ν𝜈\nuitalic_ν so that with a probability greater than 1−δ1𝛿1-\delta1 - italic_δ (over the randomness of ν𝜈\nuitalic_ν), the solution obtained by solving the sampled program yields an ϵitalic-ϵ\epsilonitalic_ϵ-feasible solution for the original chance constrained problem.","['Robust optimization', 'Chance constrained problems', 'Ambiguous chance constrained problems', 'Randomized algorithms', 'VC theory', 'Scenario approach.']",[]
"For a positive integer m𝑚mitalic_m and a finite non-negative Borel measure μ𝜇\muitalic_μ on the unit circle, we study the Hadamard multipliers of higher order weighted Dirichlet-type spaces ℋμ,msubscriptℋ𝜇𝑚\mathcal{H}_{\mu,m}caligraphic_H start_POSTSUBSCRIPT italic_μ , italic_m end_POSTSUBSCRIPT. We show that if α>12,𝛼12\alpha>\frac{1}{2},italic_α > divide start_ARG 1 end_ARG start_ARG 2 end_ARG , then for any f𝑓fitalic_f in ℋμ,m,subscriptℋ𝜇𝑚\mathcal{H}_{\mu,m},caligraphic_H start_POSTSUBSCRIPT italic_μ , italic_m end_POSTSUBSCRIPT , the sequence of generalized Cesàro sums {σnα⁢[f]}superscriptsubscript𝜎𝑛𝛼delimited-[]𝑓\{\sigma_{n}^{\alpha}[f]\}{ italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT [ italic_f ] } converges to f𝑓fitalic_f. We further show that if α=12𝛼12\alpha=\frac{1}{2}italic_α = divide start_ARG 1 end_ARG start_ARG 2 end_ARG then for the Dirac delta measure supported at any point on the unit circle, the previous statement breaks down for every positive integer m𝑚mitalic_m.","['Weighted', 'Dirichlet-type integrals', 'Cesàro mean', 'Hadamard multiplication']",[]
,[],[]
"The poset of copies of relational structure 𝕏𝕏{\mathbb{X}}blackboard_X is the partial order ⟨ℙ⁢(𝕏),⊂⟩ℙ𝕏\langle{\mathbb{P}}({\mathbb{X}}),\subset\rangle⟨ blackboard_P ( blackboard_X ) , ⊂ ⟩,
where ℙ⁢(𝕏):={f⁢[X]:f∈Emb(𝕏)}assignℙ𝕏conditional-set𝑓delimited-[]𝑋𝑓Emb𝕏{\mathbb{P}}({\mathbb{X}}):=\{f[X]:f\in\mathop{\rm Emb}\nolimits({\mathbb{X}})\}blackboard_P ( blackboard_X ) := { italic_f [ italic_X ] : italic_f ∈ roman_Emb ( blackboard_X ) }.
We consider the classifications of structures related to the similarities of their posets of copies, in particular, related to isomorphism of their Boolean completions.
The aim of the paper is to extend the known results concerning linear orders to a much larger class of monomorphic structures.

2020 MSC:
06A05, 06A10, 03E40, 03E35. 
Keywords: linear order, poset of copies, monomorphic structure, forcing.",[],[]
"This work presents 𝙵𝚊𝚌𝚎𝚇𝙵𝚊𝚌𝚎𝚇\mathtt{FaceX}typewriter_FaceX framework, a novel facial generalist model capable of handling diverse facial tasks simultaneously.
To achieve this goal, we initially formulate a unified facial representation for a broad spectrum of facial editing tasks, which macroscopically decomposes a face into fundamental identity, intra-personal variation, and environmental factors.
Based on this, we introduce Facial Omni-Representation Decomposing (FORD) for seamless manipulation of various facial components, microscopically decomposing the core aspects of most facial editing tasks.
Furthermore, by leveraging the prior of a pretrained StableDiffusion (SD) to enhance generation quality and accelerate training, we design Facial Omni-Representation Steering (FORS) to first assemble unified facial representations and then effectively steer the SD-aware generation process by the efficient Facial Representation Controller (FRC).
Our versatile 𝙵𝚊𝚌𝚎𝚇𝙵𝚊𝚌𝚎𝚇\mathtt{FaceX}typewriter_FaceX achieves competitive performance compared to elaborate task-specific models on popular facial editing tasks.
Full codes and models are available at https://github.com/diffusion-facex/FaceX.",[],[]
"Reasonably large perturbations may push a power grid from its stable synchronous state into an undesirable state. Identifying vulnerabilities in power grids by studying power grid stability against such perturbations can aid in preventing future blackouts. We use two stability measures — stability bound, which deals with a system’s asymptotic behaviour, and survivability bound, which deals with a system’s transient behaviour, to provide information about the strength of perturbations that destabilize the system. Using these stability measures, we have found that certain nodes in tree-like structures have low asymptotic stability, while nodes with a high number of connections generally have low transient stability.",[],[]
"In this work we state a result that relates the cohomology groups of a Lie algebra 𝔤𝔤\mathfrak{g}fraktur_g and a current Lie algebra 𝔤⊗𝒮tensor-product𝔤𝒮\mathfrak{g}\otimes\mathcal{S}fraktur_g ⊗ caligraphic_S, by means of a short exact sequence – similar to the universal coefficients theorem for modules –, where 𝒮𝒮\mathcal{S}caligraphic_S is a finite dimensional, commutative and associative algebra with unit over a field 𝔽𝔽\mathbb{F}blackboard_F. Although this result can be applied to any Lie algebra, as by-product we determine the cohomology group of 𝔤⊗𝒮tensor-product𝔤𝒮\mathfrak{g}\otimes\mathcal{S}fraktur_g ⊗ caligraphic_S, where 𝔤𝔤\mathfrak{g}fraktur_g is a semisimple Lie algebra.","['Lie algebras cohomology', 'Current', 'Lie algebras', 'Tensor product', 'Associative and commutative algebras semisimple', 'Lie algebras.']",[]
,[],[]
"Recently, the pulsar timing array (PTA) collaborations, including CPTA, EPTA, NANOGrav, and PPTA, announced that they detected a stochastic gravitational wave background spectrum in the nHz band. This may be relevant to the cosmological phase transition suggested by some models. Magnetic monopoles and primordial black holes (PBHs), two unsolved mysteries in the universe, may also have their production related to the cosmological phase transition.
Inspired by that, we revisit the model proposed by Stojkovic and Freese, which involves PBHs accretion to solve the cosmological magnetic monopole problem. We further develop it by considering the increase in the mass of the PBHs during accretion and taking the effect of Hawking radiation into account. With these new considerations, we find that solutions to the problem still exist within a certain parameter space. In addition, we also generalize the analysis to PBHs with an extended distribution in mass. This may be a more interesting scenario because PBHs that have accreted magnetic monopoles might produce observable electromagnetic signals if they are massive enough to survive in the late universe.",[],['China']
,"['Integrals', 'Gradshteyn and', 'Ryzhik', 'method of brackets']",[]
"This paper introduces Sobolev spaces over Gelfand pairs in the framework of hypergroups. The Sobolev spaces in question are constructed from the Fourier transform on hypergroup Gelfand pairs. Mainly, the paper focuses on the investigation of Sobolev embedding results.",[],[]
"In this paper, we introduce a new class of the kernels of the integral transforms of the Laplace convolution type that we call symmetrical Sonin kernels. For a symmetrical Sonin kernel given in terms of some elementary or special functions, its associated kernel has the same form with possibly different parameter values. Several known and new kernels of this type are derived by means of the Sonin method in the time domain and using the Laplace integral transform in the frequency domain. The new symmetrical Sonin kernels are provided in terms of the Wright function and some extensions of the Horn confluent hypergeometric functions in two variables.",[],[]
"We study the 2-offer semirandom 3-uniform hypergraph model on n𝑛nitalic_n vertices.
At each step, we are presented with 2 uniformly random vertices.
We choose any other vertex, thus creating a hyperedge of size 3.
We show a strategy that constructs a perfect matching, and another that constructs a loose Hamilton cycle, both succeeding
asymptotically almost surely
within Θ⁢(n)Θ𝑛\Theta(n)roman_Θ ( italic_n ) steps.
Both results extend to s𝑠sitalic_s-uniform hypergraphs.
Much of the analysis is done on an auxiliary graph
that is a uniform k𝑘kitalic_k-out subgraph of a random bipartite graph,
and this tool may be useful in other contexts.",[],[]
"We provide a comprehensive analysis of the acceleration of magnetic monopoles in intergalactic magnetic fields.
We demonstrate that monopoles with intermediate to low masses
can be accelerated to relativistic velocities. This can significantly affect direct and indirect searches for magnetic monopoles. As an example, we show that the Parker bound is relaxed in the presence of intergalactic fields. We also find that a cosmic population of monopoles can produce significant backreaction on the intergalactic fields.",[],[]
"We describe QGLAB, a new MATLAB package for analyzing partial differential equations on quantum graphs. The software is built on the existing, object-oriented MATLAB directed-graph class, inheriting its structure and adding additional easy-to-use features. The package allows one to construct a quantum graph and accurately compute the spectrum of elliptic operators, solutions to Poisson problems, the linear and nonlinear time evolution of a variety of PDEs, the continuation of branches of steady states (including locating and switching branches at bifurcations) and more. It uses a unified framework to implement finite-difference and Chebyshev discretizations of differential operators on a quantum graph. For simplicity, the package overloads many built-in MATLAB functions to work on the class.",[],[]
"Neurological conditions are a major source of movement disorders. Motion modelling and variability analysis have the potential to identify pathology but require profound data. We introduce a systematic dataset of 3D center-out task-space trajectories of human hand transport movements in a natural setting. The transport tasks of this study consist of grasping a cylindric object from a unified start position and transporting it to one of nine target locations in unconstrained operational space. The measurement procedure is automatized to record ten trials per target location. With that, the dataset consists of 90 movement trajectories for each hand of 31 participants without known movement disorders. The participants are aged between 21 and 78 years, covering a wide range. Data are recorded redundantly by both an optical tracking system and an IMU sensor. As opposed to the stationary capturing system, the IMU can be considered as a portable, low-cost and energy-efficient alternative to be implemented on embedded systems.",[],['Germany']
,[],[]
"We study a class of time-dependent backgrounds in string theory which consist of marginal deformations of minimal strings on AdS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. For such backgrounds, we compute the three-point amplitudes and analyze their properties.",[],[]
"The Photometric objects Around Cosmic webs (PAC) approach developed in Xu et al. (2022b) has the advantage of making full use of spectroscopic and deeper photometric surveys. With the merits of PAC, the excess surface density n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT of neighboring galaxies can be measured down to stellar mass 1010.80⁢M⊙superscript1010.80subscript𝑀direct-product10^{10.80}\,M_{\odot}10 start_POSTSUPERSCRIPT 10.80 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT around quasars at redshift 0.8<zs<1.00.8subscript𝑧s1.00.8<z_{\rm{s}}<1.00.8 < italic_z start_POSTSUBSCRIPT roman_s end_POSTSUBSCRIPT < 1.0, with the data from the Sloan Digital Sky Survey IV (SDSS-IV) extended Baryon Oscillation Spectroscopic Survey (eBOSS) and the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging Surveys. We find that n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT generally increases quite steeply with the decrease of the separation. Using subhalo abundance matching method, we can accurately model the n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT both on small and large scales. We show that the steep increase of the n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT towards the quasars requires that a large fraction fsate=0.29−0.06+0.05subscript𝑓satesuperscriptsubscript0.290.060.05f_{\mathrm{sate}}=0.29_{-0.06}^{+0.05}italic_f start_POSTSUBSCRIPT roman_sate end_POSTSUBSCRIPT = 0.29 start_POSTSUBSCRIPT - 0.06 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + 0.05 end_POSTSUPERSCRIPT of quasars should be satellites in massive halos, and find that this fraction measurement is insensitive to the assumptions of our modeling. This high satellite fraction indicates that the subhalos have nearly the same probability to host quasars as the halos for the same (infall) halo mass, and the large scale environment has negligible effect on the quasar activity. We show that even with this high satellite fraction, each massive halo on average does not host more than one satellite quasar due to the sparsity of quasars.","['AGN host galaxies(2017) —', 'Stellar mass function(1612) —', 'Quasars(1319) —', 'Active galaxies(17)']",['China']
"In this study, we introduce the first-of-its-kind class of tests for detecting change points in the distribution of a sequence of independent matrix-valued random variables. The tests are constructed using the weighted square integral difference of the empirical orthogonal Hankel transforms. The test statistics have a convenient closed-form expression, making them easy to implement in practice. We present their limiting properties and demonstrate their quality through an extensive simulation study. We utilize these tests for change point detection in cryptocurrency markets to showcase their practical use. The detection of change points in this context can have various applications in constructing and analyzing novel trading systems.",[],[]
"Let T𝑇Titalic_T be the Koopman operator of a measure preserving transformation θ𝜃\thetaitalic_θ of a probability
space (X,Σ,μ)𝑋Σ𝜇(X,\Sigma,\mu)( italic_X , roman_Σ , italic_μ ). We study the convergence properties of the averages
Mn⁢f:=1n⁢∑k=0n−1Tk⁢fassignsubscript𝑀𝑛𝑓1𝑛superscriptsubscript𝑘0𝑛1superscript𝑇𝑘𝑓M_{n}f:=\frac{1}{n}\sum_{k=0}^{n-1}T^{k}fitalic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f := divide start_ARG 1 end_ARG start_ARG italic_n end_ARG ∑ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT italic_T start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_f when f∈Lr⁢(μ)𝑓superscript𝐿𝑟𝜇f\in L^{r}(\mu)italic_f ∈ italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( italic_μ ), 0<r<10𝑟10<r<10 < italic_r < 1. We prove that if
∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0, then f∈(I−T)⁢Lr¯𝑓¯𝐼𝑇superscript𝐿𝑟f\in\overline{(I-T)L^{r}}italic_f ∈ over¯ start_ARG ( italic_I - italic_T ) italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT end_ARG, and show that the converse
fails whenever θ𝜃\thetaitalic_θ is ergodic aperiodic. When θ𝜃\thetaitalic_θ is invertible ergodic aperiodic,
we show that for 0<r<10𝑟10<r<10 < italic_r < 1 there exists fr∈(I−T)⁢Lrsubscript𝑓𝑟𝐼𝑇superscript𝐿𝑟f_{r}\in(I-T)L^{r}italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ∈ ( italic_I - italic_T ) italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT for which Mn⁢frsubscript𝑀𝑛subscript𝑓𝑟M_{n}f_{r}italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT does not converge a.e. (although ∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0). We further establish that for 1≤p<1r,1𝑝1𝑟1\leq p<\frac{1}{r},1 ≤ italic_p < divide start_ARG 1 end_ARG start_ARG italic_r end_ARG , there is a dense Gδsubscript𝐺𝛿G_{\delta}italic_G start_POSTSUBSCRIPT italic_δ end_POSTSUBSCRIPT subset
ℱ⊂Lp⁢(X,μ)ℱsuperscript𝐿𝑝𝑋𝜇{\mathcal{F}}\subset L^{p}(X,\mu)caligraphic_F ⊂ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_μ ) such that lim supn|Tn⁢h|nr=∞subscriptlimit-supremum𝑛superscript𝑇𝑛ℎsuperscript𝑛𝑟\limsup_{n}\frac{|T^{n}h|}{n^{r}}=\inftylim sup start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT divide start_ARG | italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_h | end_ARG start_ARG italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT end_ARG = ∞ a.e.
for any h∈ℱℎℱh\in{\mathcal{F}}italic_h ∈ caligraphic_F.
When T𝑇Titalic_T is induced by an irrational rotation of 𝕋𝕋\mathbb{T}blackboard_T, the Hardy spaces Hr⁢(𝕋)superscript𝐻𝑟𝕋H^{r}(\mathbb{T})italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T )
are T𝑇Titalic_T-invariant. For 0<r<10𝑟10<r<10 < italic_r < 1, we prove that
Hr⁢(𝕋)={c⁢o⁢n⁢s⁢t⁢a⁢n⁢t⁢s}⊕(I−T)⁢Hr⁢(𝕋)¯superscript𝐻𝑟𝕋direct-sum𝑐𝑜𝑛𝑠𝑡𝑎𝑛𝑡𝑠¯𝐼𝑇superscript𝐻𝑟𝕋H^{r}(\mathbb{T})=\{constants\}\oplus\overline{(I-T)H^{r}(\mathbb{T})}italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) = { italic_c italic_o italic_n italic_s italic_t italic_a italic_n italic_t italic_s } ⊕ over¯ start_ARG ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) end_ARG, and
∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0 for f∈(I−T)⁢Hr⁢(𝕋)¯𝑓¯𝐼𝑇superscript𝐻𝑟𝕋f\in\overline{(I-T)H^{r}(\mathbb{T})}italic_f ∈ over¯ start_ARG ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) end_ARG. However, there exists
f∈(I−T)⁢Hr⁢(𝕋)𝑓𝐼𝑇superscript𝐻𝑟𝕋f\in(I-T)H^{r}(\mathbb{T})italic_f ∈ ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) such that Mn⁢fsubscript𝑀𝑛𝑓M_{n}fitalic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f does not converge a.e.","['ergodic theorem', 'measure preserving transformations', 'non-integrable functions', 'Lr\u2062(μ)superscript𝐿𝑟𝜇L^{r}(\\mu)italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( italic_μ ) with 0<r<10𝑟10<r<10 < italic_r < 1', 'circle rotations', 'Hardy spaces', 'Hr\u2062(𝕋)superscript𝐻𝑟𝕋H^{r}(\\mathbb{T})italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T )']",[]
"Introduction Modelling of relative treatment effects is an important aspect to consider when extrapolating the long-term survival outcomes of treatments. Flexible parametric models offer the ability to accurately model the observed data, however, the extrapolated relative treatment effects and subsequent survival function may lack face validity. Methods We investigate the ability of change-point survival models to estimate changes in the relative treatment effects, specifically treatment delay, loss of treatment effects and converging hazards. These models are implemented using standard Bayesian statistical software and propagate the uncertainty associate with all model parameters including the change-point location. A simulation study was conducted to assess the predictive performance of these models compared with other parametric survival models. Change-point survival models were applied to three datasets, two of which were used in previous health technology assessments. Results Change-point survival models typically provided improved extrapolated survival predictions, particularly when the changes in relative treatment effects are large. When applied to the real world examples they provided good fit to the observed data while and in some situations produced more clinically plausible extrapolations than those generated by flexible spline models. Change-point models also provided support to a previously implemented modelling approach which was justified by visual inspection only and not goodness of fit to the observed data. Conclusions We believe change-point survival models offer the ability to flexibly model observed data while also modelling and investigating clinically plausible scenarios with respect to the relative treatment effects.",[],[]
"Decision making in modern stochastic systems, including e-commerce platforms, financial markets, and healthcare systems, has evolved into a multifaceted process that involves information acquisition and adaptive information sources. This paper initiates a study on this integrated process, where these elements are not only fundamental but also interact in a complex and dynamically intertwined manner.
We introduce a relatively simple model, which, however, captures the novel elements we consider. Specifically, a decision maker (DM) can choose between an established product A𝐴Aitalic_A with a known value and a new product B𝐵Bitalic_B with an unknown value. The DM can observe signals about the unknown value of product B𝐵Bitalic_B and can also opt to exchange it for product A𝐴Aitalic_A if B𝐵Bitalic_B is initially chosen. Mathematically, the model gives rise to a sequential optimal stopping problem with two different informational regimes (before and after buying product B𝐵Bitalic_B), differentiated by the initial, coarser signal and the subsequent, finer one. We analyze the underlying problems using predominantly viscosity solution techniques, differing from the existing literature on information acquisition which is based on traditional optimal stopping techniques. Additionally, our modeling approach offers a novel framework for developing more complex interactions among decisions, information sources, and information costs through a sequence of nested obstacles.",[],[]
"In this paper we study a natural generalization of symplectic toric manifolds in the context of regular Poisson manifolds of compact types. To be more precise, we consider a class of multiplicity-free Hamiltonian actions by regular proper symplectic groupoids that we call faithful. Given such a groupoid, we classify its faithful multiplicity-free Hamiltonian actions in terms of what we call Delzant subspaces of its orbit space –
certain ‘suborbifolds with corners’ satisfying the Delzant condition relative to the integral affine orbifold structure of the orbit space. This encompasses both the classification of symplectic toric manifolds (due to Delzant) in terms of Delzant polytopes
and the classification of proper Lagrangian fibrations over an integral affine base manifold (due to Duistermaat) in terms of a sheaf cohomology group. Each Delzant subspace comes with an orbifold version of this cohomology, the degree one part of which classifies faithful multiplicity-free Hamiltonian actions with momentum map image equal to the Delzant subspace, provided there exists such an action. The obstruction to existence is encoded by a degree two class in this cohomology: the Lagrangian Dixmier-Douady class. In addition to the above, we introduce another invariant, which leads to a variation of our classification result involving only classical sheaf cohomology and the group cohomology of certain modules for the isotropy groups of the groupoid.",[],[]
,[],[]
"In this paper we investigate the problem of the distributivity of Kurepa trees. We show that it is consistent that there are Kurepa trees and for every Kurepa tree there is a small forcing notion which adds a branch to it without collapsing cardinals. On the other hand, we derive a proper forcing notion for making an arbitrary Kurepa tree into a non-distributive tree without collapsing ℵ1subscriptℵ1\aleph_{1}roman_ℵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and ℵ2subscriptℵ2\aleph_{2}roman_ℵ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.",[],[]
,[],[]
"In this paper, we consider exact WKB analysis to a 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T symmetric quantum mechanics defined by the potential, V⁢(x)=ω2⁢x2+g⁢x2⁢(i⁢x)ε=2𝑉𝑥superscript𝜔2superscript𝑥2𝑔superscript𝑥2superscript𝑖𝑥𝜀2V(x)=\omega^{2}x^{2}+gx^{2}(ix)^{\varepsilon=2}italic_V ( italic_x ) = italic_ω start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_g italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_i italic_x ) start_POSTSUPERSCRIPT italic_ε = 2 end_POSTSUPERSCRIPT with ω∈ℝ≥0𝜔subscriptℝabsent0\omega\in{\mathbb{R}}_{\geq 0}italic_ω ∈ blackboard_R start_POSTSUBSCRIPT ≥ 0 end_POSTSUBSCRIPT, g∈ℝ>0𝑔subscriptℝabsent0g\in{\mathbb{R}}_{>0}italic_g ∈ blackboard_R start_POSTSUBSCRIPT > 0 end_POSTSUBSCRIPT.
We in particular aim to verify a conjecture proposed by Ai-Bender-Sarkar (ABS),
that pertains to a relation between D𝐷Ditalic_D-dimensional 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T-symmetric theories and analytic continuation (AC) of Hermitian theories concerning the energy spectrum or Euclidean partition function.
For the purpose, we construct energy quantization conditions by exact WKB analysis and write down their transseries solution by solving the conditions.
By performing alien calculus to the energy solutions, we verify validity of the ABS conjecture and seek a possibility of its alternative form by Borel resummation theory if it is violated.
Our results claim that the validity of the ABS conjecture drastically changes depending on whether ω>0𝜔0\omega>0italic_ω > 0 or ω=0𝜔0\omega=0italic_ω = 0: If ω>0𝜔0{\omega}>0italic_ω > 0, then the ABS conjecture is violated when exceeding the semi-classical level, but its alternative form is constructable by Borel resummation theory.
The 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T and the AC energies are related to each other by a one-parameter Stokes automorphism, and a median resummed form, which corresponds to a formal exact solution, of the AC energy (resp. 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T energy) is directly obtained by acting Borel resummation to a transseries solution of the 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T energy (resp. AC energy).
If ω=0𝜔0\omega=0italic_ω = 0, then, with respect to the inverse energy level-expansion, not only perturbative/non-perturbative structures of the 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T and the AC energies but also their perturbative parts do not match with each other.
These energies are independent solutions, and no alternative form of the ABS conjecture can be reformulated by Borel resummation theory.",[],[]
"We propose a semi-supervised text classifier based on self-training using one positive and one negative property of neural networks. One of the weaknesses of self-training is the semantic drift problem, where noisy pseudo-labels accumulate over iterations and consequently the error rate soars. In order to tackle this challenge, we reshape the role of pseudo-labels and create a hierarchical order of information. In addition, a crucial step in self-training is to use the classifier confidence prediction to select the best candidate pseudo-labels. This step cannot be efficiently done by neural networks, because it is known that their output is poorly calibrated. To overcome this challenge, we propose a hybrid metric to replace the plain confidence measurement. Our metric takes into account the prediction uncertainty via a subsampling technique. We evaluate our model in a set of five standard benchmarks, and show that it significantly outperforms a set of ten diverse baseline models. Furthermore, we show that the improvement achieved by our model is additive to language model pretraining, which is a widely used technique for using unlabeled documents. Our code is available at https://github.com/p-karisani/RST.",[],[]
"A wide range of implicit time integration methods, including multi-step, implicit
Runge-Kutta, and Galerkin finite-time element schemes, is evaluated in the context
of chaotic dynamical systems. The schemes are applied to solve the Lorenz equations,
the equation of motion of a Duffing oscillator, and the Kuramoto-Sivashinsky system,
with the goal of finding the most computationally efficient method that
results in the least expensive model for a chosen level of accuracy. It is found
that the quasi-period of a chaotic system strongly limits the
time-step size that can be used in the simulations, and all schemes fail
once the time-step size reaches a significant fraction of that period. In these conditions,
the computational cost per time-step becomes one of the most important factors
determining the efficiency of the schemes. The cheaper, second-order schemes
are shown to have an advantage over the higher-order schemes at large time-step sizes, with one
possible exception being the fourth-order continuous Galerkin scheme. The higher-order schemes become more efficient than the lower-order schemes as accuracy requirements tighten. If going
beyond the second-order is necessary for reasons other than computational
efficiency, the fourth-order methods are shown to perform better than the third-order
ones at all time-step sizes.",[],[]
"Bayesian inference provides a rigorous framework to encapsulate our knowledge and uncertainty
regarding various physical quantities in a well-defined and self-contained manner. Utilising modern
tools, such Bayesian models can be constructed with a remarkable flexibility, leaving us totally free
to carefully choose which assumption should be strictly enforced and which should on the contrary
be relaxed. The practical evaluation of these assumptions, together with the data-driven selection
or averaging of models, also appears in a very natural way.
In this presentation, I discuss its application in the context of lattice QCD and its common
statistical problems. As a concrete illustration, I present a few parametric and non-parametric
hierarchical models applied to actual correlator data, from single exponential fits to spectral functions.",[],[]
"We study the completion of approximately low rank matrices with entries missing not at random (MNAR). In the context of typical large-dimensional statistical settings, we establish a framework for the performance analysis of the nuclear norm minimization (ℓ1*superscriptsubscriptℓ1\ell_{1}^{*}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT) algorithm. Our framework produces exact estimates of the worst-case residual root mean squared error (RMSE) and the associated phase transitions (PT), with both exhibiting remarkably simple characterizations. Our results enable to precisely quantify the impact of key system parameters, including data heterogeneity, size of the missing block, and deviation from ideal low rankness, on the accuracy of ℓ1*superscriptsubscriptℓ1\ell_{1}^{*}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-based matrix completion. To validate our theoretical worst-case RMSE estimates, we conduct numerical simulations, demonstrating close agreement with their numerical counterparts.","['62B10', '94A16', '62D10', 'Matrix', 'Completion', 'Approximately low rank', 'Phase transitions', 'Nuclear norm']",[]
"Large Language Models (LLMs), particularly those similar to ChatGPT, have significantly influenced the field of Natural Language Processing (NLP). While these models excel in general language tasks, their performance in domain-specific downstream tasks such as biomedical and clinical Named Entity Recognition (NER), Relation Extraction (RE), and Medical Natural Language Inference (NLI) is still evolving. In this context, our study investigates the potential of instruction tuning for biomedical language processing, applying this technique to two general LLMs of substantial scale. We present a comprehensive, instruction-based model trained on a dataset that consists of approximately 200,000200000200,000200 , 000 instruction-focused samples. This dataset represents a carefully curated compilation of existing data, meticulously adapted and reformatted to align with the specific requirements of our instruction-based tasks. This initiative represents an important step in utilising such models to achieve results on par with specialised encoder-only models like BioBERT and BioClinicalBERT for various classical biomedical NLP tasks. Our work includes an analysis of the dataset’s composition and its impact on model performance, providing insights into the intricacies of instruction tuning. By sharing our codes, models, and the distinctively assembled instruction-based dataset, we seek to encourage ongoing research and development in this area.",[],[]
,[],[]
,[],[]
"Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut purus elit,
vestibulum ut, placerat ac, adipiscing vitae, felis. Curabitur dictum
gravida mauris. Nam arcu libero, nonummy eget, consectetuer id,
vulputate a, magna. Donec vehicula augue eu neque. Pellentesque habitant
morbi tristique senectus et netus et malesuada fames ac turpis egestas.
Mauris ut leo. Cras viverra metus rhoncus sem. Nulla et lectus
vestibulum urna fringilla ultrices. Phasellus eu tellus sit amet tortor
gravida placerat. Integer sapien est, iaculis in, pretium quis, viverra
ac, nunc. Praesent eget sem vel leo ultrices bibendum. Aenean faucibus.
Morbi dolor nulla, malesuada eu, pulvinar at, mollis ac, nulla.
Curabitur auctor semper nulla. Donec varius orci eget risus. Duis nibh
mi, congue eu, accumsan eleifend, sagittis quis, diam. Duis eget orci
sit amet orci dignissim rutrum.",[],[]
"In the arena of privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) has outstripped the objective perturbation mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD requires a non-trivial privacy overhead (for privately tuning the model’s hyperparameters) and a computational complexity which might be extravagant for simple models such as linear and logistic regression. This paper revamps the objective perturbation mechanism with tighter privacy analyses and new computational tools that boost it to perform competitively with DP-SGD on unconstrained convex generalized linear problems.",[],[]
"For a semibounded sesquilinear form 𝔱𝔱{\mathfrak{t}}fraktur_t in a Hilbert space ℌℌ{\mathfrak{H}}fraktur_H
there exists a representing map Q𝑄Qitalic_Q from ℌℌ{\mathfrak{H}}fraktur_H to another Hilbert space 𝔎𝔎{\mathfrak{K}}fraktur_K,
such that 𝔱⁢[φ,ψ]−c⁢(φ,ψ)=(Q⁢φ,Q⁢ψ)𝔱𝜑𝜓𝑐𝜑𝜓𝑄𝜑𝑄𝜓{\mathfrak{t}}[\varphi,\psi]-c(\varphi,\psi)\!=\!(Q\varphi,Q\psi)fraktur_t [ italic_φ , italic_ψ ] - italic_c ( italic_φ , italic_ψ ) = ( italic_Q italic_φ , italic_Q italic_ψ ),
φ,ψ∈dom⁢𝔱𝜑𝜓dom𝔱\varphi,\psi\in{\rm dom\,}{\mathfrak{t}}italic_φ , italic_ψ ∈ roman_dom fraktur_t, with c∈ℝ𝑐ℝc\in{\mathbb{R}}italic_c ∈ blackboard_R a lower bound of 𝔱𝔱{\mathfrak{t}}fraktur_t.
Representing maps offer a simplifying tool to study general semibounded forms.
By means of representing maps closedness, closability, and singularity of 𝔱𝔱{\mathfrak{t}}fraktur_t
are immediately translated into the corresponding properties of the operator Q𝑄Qitalic_Q, and vice versa.
Also properties of sum decompositions 𝔱=𝔱1+𝔱2𝔱subscript𝔱1subscript𝔱2{\mathfrak{t}}={\mathfrak{t}}_{1}+{\mathfrak{t}}_{2}fraktur_t = fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of
a nonnegative form 𝔱𝔱{\mathfrak{t}}fraktur_t with two other nonnegative forms 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in ℌℌ{\mathfrak{H}}fraktur_H
can be analyzed by means of associated nonnegative contractions K∈𝐁⁢(𝔎)𝐾𝐁𝔎K\in{\mathbf{B}}({\mathfrak{K}})italic_K ∈ bold_B ( fraktur_K ).
This helps, for instance, to establish an explicit operator theoretic characterization
for the summands 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to be, or not to be, mutually singular.
Such sum decompositions are used to study characteristic properties of the so-called Lebesgue type
decompositions of semibounded forms 𝔱𝔱{\mathfrak{t}}fraktur_t, where 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is closable and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT singular;
in particular, this includes the Lebesgue decomposition of a semibounded form due to B. Simon.
Furthermore, for a semibounded form 𝔱𝔱{\mathfrak{t}}fraktur_t with its representing map Q𝑄Qitalic_Q
it will be shown that the corresponding semibounded selfadjoint relation Q*⁢Q**+csuperscript𝑄superscript𝑄absent𝑐Q^{*}Q^{**}+citalic_Q start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT * * end_POSTSUPERSCRIPT + italic_c
is uniquely determined by a limit version of the classical representation theorem for the form 𝔱𝔱{\mathfrak{t}}fraktur_t,
being studied by W. Arendt and T. ter Elst in a sectorial context.
Via representing maps a full treatment is given of the convergence of monotone
sequences of semibounded forms.","['Semibounded form', 'closability', 'singularity', 'Lebesgue type decompositions of forms', 'representing map', 'representation theorem']",[]
"We provide a step towards classifying Riemannian four-manifolds in which the curvature tensor has zero
divergence, or – equivalently – the Ricci tensor Ric satisfies the
Codazzi equation. Every known compact manifold of this type belongs to one
of five otherwise-familiar classes of examples. The main result
consists in showing that, if such a manifold (not necessarily compact or even
complete) lies outside of the five classes – a non-vacuous assumption –
then, at all points of a dense open subset, Ric has four distinct eigenvalues,
while suitable local coordinates simultaneously diagonalize Ric, the metric
and, in a natural sense, also the curvature tensor. Furthermore,
in a local orthonormal frame formed by Ricci eigenvectors, the connection form
(or, curvature tensor) has just twelve (or, respectively, six)
possibly-nonzero components, which together satisfy a specific system, not
depending on the point, of homogeneous polynomial equations. A part of the
classification problem is thus reduced to a question in real algebraic
geometry.","['harmonic curvature', 'Codazzi tensor']",[]
"Non-relativistic quantum mechanical scattering from an inverse square
potential in two spatial dimensions leads to a novel representation
of the Bernoulli numbers.",[],[]
,[],[]
"High-demand LLM inference services (e.g., ChatGPT and BARD) support a wide range of requests from short chat conversations to long document reading.
To ensure that all client requests are processed fairly, most major LLM inference services have request rate limits, to ensure that no client can dominate the request queue.
However, this rudimentary notion of fairness also results in under-utilization of the resources and poor client experience when there is spare capacity.
While there is a rich literature on fair scheduling, serving LLMs presents new challenges due to their unpredictable request lengths and their unique batching characteristics on parallel accelerators.
This paper introduces the definition of LLM serving fairness based on a cost function that accounts for the number of input and output tokens processed.
To achieve fairness in serving, we propose a novel scheduling algorithm, the Virtual Token Counter (VTC), a fair scheduler based on the continuous batching mechanism.
We prove a 2×2\times2 × tight upper bound on the service difference between two backlogged clients, adhering to the requirement of work-conserving.
Through extensive experiments, we demonstrate the superior performance of VTC in ensuring fairness, especially in contrast to other baseline methods, which exhibit shortcomings under various conditions.",[],[]
"Composite Higgs models are a class of models proposed to address the hierarchy and naturalness problems associated with the Standard Model fundamental scalar Higgs. S⁢U⁢(2)𝑆𝑈2SU(2)italic_S italic_U ( 2 ) with two fundamental flavours is a minimal model for the composite Higgs sector which is not yet ruled out by experimental data. We present lattice results for S⁢U⁢(2)𝑆𝑈2SU(2)italic_S italic_U ( 2 ) with two fundamental mass degenerate flavours. For the fermion action we use the new exponential clover Wilson fermion action, which offers O⁢(a)𝑂𝑎O(a)italic_O ( italic_a ) improvement. We discuss tuning the cSWsubscript𝑐SWc_{\mathrm{SW}}italic_c start_POSTSUBSCRIPT roman_SW end_POSTSUBSCRIPT parameter through Schrödinger functional simulations, the scale setting of the ensembles using the Wilson gauge flow, and the low energy spectroscopy of the theory including the masses of the pseudoscalar isotriplet Goldstone bosons and the vector isotriplet.",[],[]
,[],[]
"A low-energy enhancement (LEE) has been observed in the deexcitation γ𝛾\gammaitalic_γ-ray strength function (γ𝛾\gammaitalic_γSF) of compound nuclei. The LEE has been a subject of intense experimental and theoretical interest since its discovery, and, if the LEE persists in heavy neutron-rich nuclei, it would have significant effects on calculations of r-process nucleosynthesis. Standard configuration-interaction (CI) shell-model calculations in medium-mass nuclei have attributed the LEE to the magnetic dipole γ𝛾\gammaitalic_γSF but such calculations are computationally intractable in heavy nuclei. We review a combination of beyond-mean-field many-body methods within the framework of the CI shell model that enables the calculation of γ𝛾\gammaitalic_γSF in heavy nuclei, and discuss the recent theoretical identification of a LEE in the magnetic dipole γ𝛾\gammaitalic_γSF of lanthanide isotopes.",[],[]
"Within the ViSE (Voting in Stochastic Environment) model, we study the effectiveness of majority voting in various environments.
By the pit of losses paradox, majority decisions in apparently hostile environments systematically reduce the capital of society.
In such cases, the basic action of “rejecting all proposals without voting” outperforms simple majority. We reveal another pit of losses appearing in favorable environments. Here, the simple action of “accepting all proposals without voting” is superior to simple majority, which thus causes a loss compared to total acceptance. We show that the second pit of losses is a mirror image of the pit of losses in hostile environments and explain this phenomenon.
Technically, we consider a voting society consisting of individual agents whose strategy is supporting all proposals that increase their capital and a group whose members vote for the increase of the total group capital. According to the main result, the expected capital gain of each agent in the environment whose proposal generator ξ𝜉\xiitalic_ξ has mean μ>0𝜇0\mu>0italic_μ > 0 exceeds by μ𝜇\muitalic_μ their expected capital gain with generator −ξ𝜉-\xi- italic_ξ. This result extends to the shift-based families of generators with symmetric distributions. The difference by μ𝜇\muitalic_μ causes symmetry relative to the basic action that rejects/accepts all proposals in unfavorable/favorable environments.",[],[]
"Simplicity bias is an intriguing phenomenon prevalent in various input-output maps, characterized by a preference for simpler, more regular, or symmetric outputs. Notably, these maps typically feature high-probability outputs with simple patterns, whereas complex patterns are exponentially less probable. This bias has been extensively examined and attributed to principles derived from algorithmic information theory and algorithmic probability. In a significant advancement, it has been demonstrated that the renowned logistic map xk+1=μ⁢xk⁢(1−xk)subscript𝑥𝑘1𝜇subscript𝑥𝑘1subscript𝑥𝑘x_{k+1}=\mu x_{k}(1-x_{k})italic_x start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT = italic_μ italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( 1 - italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), a staple in dynamical systems theory, and other one-dimensional maps exhibit simplicity bias when conceptualized as input-output systems. Building upon this foundational work, our research delves into the manifestations of simplicity bias within the random logistic map, specifically focusing on scenarios involving additive noise. This investigation is driven by the overarching goal of formulating a comprehensive theory for the prediction and analysis of time series.
Our primary contributions are multifaceted. We discover that simplicity bias is observable in the random logistic map for specific ranges of μ𝜇\muitalic_μ and noise magnitudes. Additionally, we find that this bias persists even with the introduction of small measurement noise, though it diminishes as noise levels increase. Our studies also revisit the phenomenon of noise-induced chaos, particularly when μ=3.83𝜇3.83\mu=3.83italic_μ = 3.83, revealing its characteristics through complexity-probability plots. Intriguingly, we employ the logistic map to underscore a paradoxical aspect of data analysis: more data adhering to a consistent trend can occasionally lead to reduced confidence in extrapolation predictions, challenging conventional wisdom.
We propose that adopting a probability-complexity perspective in analyzing dynamical systems could significantly enrich statistical learning theories related to series prediction and analysis. This approach not only facilitates a deeper understanding of simplicity bias and its implications but also paves the way for novel methodologies in forecasting complex systems behavior, especially in scenarios dominated by uncertainty and stochasticity.
Keywords: Random dynamical systems; algorithmic probability; simplicity bias; time series; machine learning",[],[]
"This paper considers a multi-group multicasting scenario facilitated by a reconfigurable intelligent surface (RIS). We propose a fast and scalable algorithm for the joint design of the base station (BS) multicast beamforming and the RIS passive beamforming to minimize the transmit power subject to the quality-of-service (QoS) constraints. By exploring the structure of the joint optimization problem, we show that this QoS problem can be broken into a BS multicast QoS subproblem and an RIS max-min-fair (MMF) multicast subproblem, which are solved alternatingly. In our proposed algorithm, we utilize the optimal multicast beamforming structure to obtain the BS beamformers efficiently. Furthermore, we reformulate the challenging RIS multicast subproblem and employ a first-order projected subgradient algorithm (PSA) to solve it, which yields closed-form updates. Simulation results show the efficacy of our proposed algorithm in performance and computational cost compared to other alternative methods.",[],['Canada']
"Recent advances in large language models (LLMs) have led to the development of various evaluation benchmarks. These benchmarks typically rely on a single instruction template for evaluating all LLMs on a specific task.
In this paper, we comprehensively analyze the brittleness of results obtained via single-prompt evaluations across 6.5M instances, involving 20 different LLMs and 39 tasks from 3 benchmarks. To improve robustness of the analysis, we propose to evaluate LLMs with a set of diverse prompts instead. We discuss tailored evaluation metrics for specific use cases (e.g., LLM developers vs. developers interested in a specific downstream task), ensuring a more reliable and meaningful assessment of LLM capabilities. We then implement these criteria and conduct evaluations of multiple models, providing insights into the true strengths and limitations of current LLMs.",[],[]
"We introduce a method to reconstruct full rapidity distributions of charged particle multiplicity and net proton yields, crucial for constraining the longitudinal dynamics of nuclear matter created in the beam energy scan program. Employing rapidity distributions within a multistage hydrodynamic model calibrated for Au+Au collisions at sNN=7.7−200subscript𝑠NN7.7200\sqrt{s_{\mathrm{NN}}}=7.7-200\,square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 7.7 - 200GeV, we estimate the total energy and baryon number deposited into the collision fireball, offering insights into initial dynamics and the identification of nuclear remnants. We explore the potential of rapidity-dependent measurements in probing equations of state at finite chemical potentials. Furthermore, we compare the freeze-out parameters derived from both hydrodynamics and thermal models, highlighting that the parameters extracted via thermal models represent averaged properties across rapidities.",[],['Canada']
"Generalizing the concept of the Macaulay inverse system, we introduce a way to describe localizations of an ideal in a polynomial ring. This leads to an approach to the differential primary decomposition as a description of the affine scheme defined by the ideal.",[],[]
"Let π:Y→X:𝜋→𝑌𝑋\pi:Y\rightarrow Xitalic_π : italic_Y → italic_X be a continuous surjection between compact
Hausdorff spaces Y𝑌Yitalic_Y and X𝑋Xitalic_X which is irreducible in the sense that if
F⊊Y𝐹𝑌F\subsetneq Yitalic_F ⊊ italic_Y is closed, then π⁢(F)≠X𝜋𝐹𝑋\pi(F)\neq Xitalic_π ( italic_F ) ≠ italic_X. We exhibit isomorphisms between
various Boolean algebras associated to this data: the regular open
sets of X𝑋Xitalic_X, the regular
open sets of Y𝑌Yitalic_Y, the regular ideals of C⁢(X)𝐶𝑋C(X)italic_C ( italic_X ) and the regular
ideals of C⁢(Y)𝐶𝑌C(Y)italic_C ( italic_Y ).
We call X𝑋Xitalic_X and Y𝑌Yitalic_Y Boolean equivalent if the
regular open sets of X𝑋Xitalic_X and the regular open sets of Y𝑌Yitalic_Y are isomorphic
Boolean algebras. We give a characterization of when two compact
metrizable spaces are Boolean equivalent; this
characterization may be viewed as a topological version of the characterization of
standard Borel spaces.","['Irreducible mappings', 'regular open sets', 'regular ideals', 'Boolean algebras']",[]
"Sub-sampling is applied to simulated T1subscript𝑇1T_{1}italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-D𝐷Ditalic_D NMR signals and its influence on inversion performance is evaluated. For this different levels of sub-sampling were employed ranging from the fully sampled signal down to only less than two percent of the original data points. This was combined with multiple sample schemes including fully random sampling, truncation and a combination of both. To compare the performance of different inversion algorithms, the so-generated sub-sampled signals were inverted using Tikhonov regularization, modified total generalized variation (MTGV) regularization, deep learning and a combination of deep learning and Tikhonov regularization. Further, the influence of the chosen cost function on the relative inversion performance was investigated. Overall, it could be shown that for a vast majority of instances, deep learning clearly outperforms regularization based inversion methods, if the signal is fully or close to fully sampled. However, in the case of significantly sub-sampled signals regularization yields better inversion performance than its deep learning counterpart with MTGV clearly prevailing over Tikhonov. Additionally, fully random sampling could be identified as the best overall sampling scheme independent of the inversion method. Finally, it could also be shown that the choice of cost function does vastly influence the relative rankings of the tested inversion algorithms highlighting the importance of choosing the cost function accordingly to experimental intentions.",[],[]
"We develop a framework relating semiorthogonal de-compositions of a triangulated category 𝒞𝒞\mathcal{C}caligraphic_C to paths in its space of stability conditions. We prove that when 𝒞𝒞\mathcal{C}caligraphic_C is the homotopy category of a smooth and proper pre-triangulated dg-category, every semiorthogonal decomposition whose semiorthogonal factors admit a Bridgeland stability condition can be obtained from our framework.",[],[]
"Much is known about when a locally optimal solution depends in a
single-valued Lipschitz continuous way on the problem’s parameters,
including tilt perturbations. Much less is known, however, about when
that solution and a uniquely determined multiplier vector associated with
it exhibit that dependence as a primal-dual pair. In classical nonlinear
programming, such advantageous behavior is tied to the combination of the
standard strong second-order sufficient condition (SSOC) for local
optimality and the linear independent gradient condition (LIGC) on the
active constraint gradients. But although second-order sufficient
conditons have successfully been extended far beyond nonlinear programming,
insights into what should replace constraint gradient independence as the
extended dual counterpart have been lacking.

The exact answer is provided here for a wide range of optimization
problems in finite dimensions. Behind it are advances in how coderivatives
and strict graphical derivatives can be deployed. New results about
strong metric regularity in solving variational inequalities and
generalized equations are obtained from that as well.


Keywords: 
second-order variational analysis,
local optimality,
primal-dual stability,
tilt stability,
full stability,
metric regularity,
Kummer’s inverse theorem,
implicit mapping theorems,
graphically Lipschitzian mappings,
crypto-continuity,
strict graphical derivatives,
coderivatives,
variational sufficiency.",[],[]
,[],[]
,[],[]
"Score distillation has emerged as one of the most prevalent approaches for text-to-3D asset synthesis.
Essentially, score distillation updates 3D parameters by lifting and back-propagating scores averaged over different views.
In this paper, we reveal that the gradient estimation in score distillation is inherent to high variance.
Through the lens of variance reduction, the effectiveness of SDS and VSD can be interpreted as applications of various control variates to the Monte Carlo estimator of the distilled score.
Motivated by this rethinking and based on Stein’s identity, we propose a more general solution to reduce variance for score distillation, termed Stein Score Distillation (SSD). SSD incorporates control variates constructed by Stein identity,
allowing for arbitrary baseline functions. This enables us to include flexible guidance priors and network architectures to explicitly optimize for variance reduction.
In our experiments, the overall pipeline, dubbed SteinDreamer, is implemented by instantiating the control variate with a monocular depth estimator.
The results suggest that SSD can effectively reduce the distillation variance and consistently improve visual quality for both object- and scene-level generation.
Moreover, we demonstrate that SteinDreamer achieves faster convergence than existing methods due to more stable gradient updates.
Project page: vita-group.github.io/SteinDreamer/.",[],[]
"We consider the problem of tracking multiple, unknown, and time-varying numbers of objects using a distributed network of heterogeneous sensors. In an effort to derive a formulation for practical settings, we consider limited and unknown sensor field-of-views (FoVs), sensors with limited local computational resources and communication channel capacity. The resulting distributed multi-object tracking algorithm involves solving an NP-hard multidimensional assignment problem either optimally for small-size problems or sub-optimally for general practical problems. For general problems, we propose an efficient distributed multi-object tracking algorithm that performs track-to-track fusion using a clustering-based analysis of the state space transformed into a density space to mitigate the complexity of the assignment problem. The proposed algorithm can more efficiently group local track estimates for fusion than existing approaches. To ensure we achieve globally consistent identities for tracks across a network of nodes as objects move between FoVs, we develop a graph-based algorithm to achieve label consensus and minimise track segmentation. Numerical experiments with a synthetic and a real-world trajectory dataset demonstrate that our proposed method is significantly more computationally efficient than state-of-the-art solutions, achieving similar tracking accuracy and bandwidth requirements but with improved label consistency.",[],[]
,[],[]
"We prove that a complete solution to the Ricci flow on M×[−T,0)𝑀𝑇0M\times[-T,0)italic_M × [ - italic_T , 0 ) which has quadratic curvature decay on some end of M𝑀Mitalic_M
and converges locally smoothly to the end of a cone on that neighborhood as t↗0↗𝑡0t\nearrow 0italic_t ↗ 0 must be a gradient shrinking soliton.",[],[]
"Camera traps are valuable tools in animal ecology for biodiversity monitoring and conservation.
However, challenges like poor generalization to deployment at new unseen locations limit their practical application.
Images are naturally associated with heterogeneous forms of context possibly in different modalities.
In this work, we leverage the structured context associated with the camera trap images to improve out-of-distribution generalization for the task of species identification in camera traps.
For example, a photo of a wild animal may be associated with information about where and when it was taken, as well as structured biology knowledge about the animal species.
While typically overlooked by existing work, bringing back such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization.
However, effectively integrating such heterogeneous context into the visual domain is a challenging problem.
To address this, we propose a novel framework that reformulates species classification as link prediction in a multimodal knowledge graph (KG).
This framework seamlessly integrates various forms of multimodal context for visual recognition.
We apply this framework for out-of-distribution species classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets and achieve competitive performance with state-of-the-art approaches. Furthermore, our framework successfully incorporates biological taxonomy for improved generalization and enhances sample efficiency for recognizing under-represented species.111Code and data will be released on GitHub.",[],[]
"We present a review of personality in neural conversational agents (CAs), also called chatbots. First, we define Personality, Persona, and Profile. We explain all personality schemes which have been used in CAs, and list models under the scheme(s) which they use. Second we describe 21 datasets which have been developed in recent CA personality research. Third, we define the methods used to embody personality in a CA, and review recent models using them. Fourth, we survey some relevant reviews on CAs, personality, and related topics. Finally, we draw conclusions and identify some research challenges for this important emerging field.",[],[]
"This is a report on JamCoders, a four-week long computer-science camp for high school
students in Jamaica. The camp teaches college-level
coding and algorithms, and targets academically excellent students in grades
9–11 (ages 14–17).
Qualitative assessment shows that the camp was, in general terms, a success. We
reflect on the background and academic structure of the camp and share key
takeaways on designing and operating a successful camp. We analyze data
collected before, during and after the camp and map the effects of
demographic differences on student performance in camp. We conclude with a
discussion on possible improvements on our approach.",[],[]
"Bayesian neural networks (BNNs) are a principled approach to modeling predictive uncertainties in deep learning, which are important in safety-critical applications.
Since exact Bayesian inference over the weights in a BNN is intractable, various approximate inference methods exist, among which sampling methods such as Hamiltonian Monte Carlo (HMC) are often considered the gold standard.
While HMC provides high-quality samples, it lacks interpretable summary statistics because its sample mean and variance is meaningless in neural networks due to permutation symmetry.
In this paper, we first show that the role of permutations can be meaningfully quantified by a number of transpositions metric.
We then show that the recently proposed rebasin method (ainsworth2022git, ) allows us to summarize HMC samples into a compact representation that provides a meaningful explicit uncertainty estimate for each weight in a neural network, thus unifying sampling methods with variational inference.
We show that this compact representation allows us to compare trained BNNs directly in weight space across sampling methods and variational inference, and to efficiently prune neural networks trained without explicit Bayesian frameworks by exploiting uncertainty estimates from HMC.",[],[]
"We establish that the summability of the series ∑εnsubscript𝜀𝑛\sum\varepsilon_{n}∑ italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is the necessary and sufficient criterion ensuring that every
(1+εn)1subscript𝜀𝑛(1+\varepsilon_{n})( 1 + italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) Markushevich basis in a separable Hilbert space is a Riesz basis. Further we show that if n⁢εn→∞→𝑛subscript𝜀𝑛n\varepsilon_{n}\to\inftyitalic_n italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT → ∞, then in ℓ2subscriptℓ2\ell_{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT there exists a (1+εn)1subscript𝜀𝑛(1+\varepsilon_{n})( 1 + italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )
Markushevich basis that under any permutation is non-equivalent to a Schauder basis. We extend this result to any separable Banach space. Finally we provide examples of Auerbach bases in
1-symmetric separable Banach spaces whose no permutations are equivalent to any Schauder basis or (depending on the space) any unconditional Schauder basis.",[],[]
"Conventional diagonalization methods to calculate nuclear energy levels in the framework of the configuration-interaction (CI) shell model approach are prohibited in very large model spaces. The shell model Monte Carlo (SMMC) is a powerful technique for calculating thermal and ground-state observables of nuclei in very large model spaces, but it is challenging to extract nuclear spectra in this approach. We present a novel method to extract low-lying energy levels for given values of a set of good quantum numbers such as spin and parity. The method is based on imaginary-time one-body density correlation matrices that satisfy asymptotically a generalized eigenvalue problem. We validate the method in a light nucleus that allows comparison with exact diagonalization results of the CI shell model Hamiltonian. The method is applicable to other finite-size quantum many-body systems that can be described within a CI shell model approach.",[],[]
"In this paper we completely describe the winning and losing conditions different from the only “trivial” conditions known before. In other words, we solve the open question of finding a complete nontrivial Schmidt diagram. In addition, we give the new bounds for two family of sets: one related to frequencies of digits in base-2222 expansions, and one connected to the set of the badly approximable numbers.",[],[]
,[],[]
"In this paper, we focus on the One-shot Novel View Synthesis (O-NVS) task which targets synthesizing photo-realistic novel views given only one reference image per scene. Previous One-shot Generalizable Neural Radiance Fields (OG-NeRF) methods solve this task in an inference-time finetuning-free manner, yet suffer the blurry issue due to the encoder-only architecture that highly relies on the limited reference image. On the other hand, recent diffusion-based image-to-3d methods show vivid plausible results via distilling pre-trained 2D diffusion models into a 3D representation, yet require tedious per-scene optimization. Targeting these issues, we propose the GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF, a Generative Detail compensation framework via GAN and Diffusion that is both inference-time finetuning-free and with vivid plausible details.
In detail, following a coarse-to-fine strategy, GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF is mainly composed of a One-stage Parallel Pipeline (OPP) and a 3D-consistent Detail Enhancer (Diff3DE). At the coarse stage, OPP first efficiently inserts the GAN model into the existing OG-NeRF pipeline for primarily relieving the blurry issue with in-distribution priors captured from the training dataset, achieving a good balance between sharpness (LPIPS, FID) and fidelity (PSNR, SSIM). Then, at the fine stage, Diff3DE further leverages the pre-trained image diffusion models to complement rich out-distribution details while maintaining decent 3D consistency.
Extensive experiments on both the synthetic and real-world datasets show that GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF noticeably improves the details while without per-scene finetuning.","['One-shot novel view synthesis', 'generalizable neural radiance fields', '3D reconstruction', 'GAN', 'diffusion model.']",[]
"Deep Metric Learning (DML) plays an important role in modern computer vision research, where we learn a distance metric for a set of image representations. Recent DML techniques utilize the proxy to interact with the corresponding image samples in the embedding space. However, existing proxy-based DML methods focus on learning individual proxy-to-sample distance while the overall distribution of samples and proxies lacks attention. In this paper, we present a novel proxy-based DML framework that focuses on aligning the sample and proxy distributions to improve the efficiency of proxy-based DML losses. Specifically, we propose the Data-Augmented Domain Adaptation (DADA) method to adapt the domain gap between the group of samples and proxies. To the best of our knowledge, we are the first to leverage domain adaptation to boost the performance of proxy-based DML. We show that our method can be easily plugged into existing proxy-based DML losses. Our experiments on benchmarks, including the popular CUB-200-2011, CARS196, Stanford Online Products, and In-Shop Clothes Retrieval, show that our learning algorithm significantly improves the existing proxy losses and achieves superior results compared to the existing methods. Our code is available at https://github.com/Noahsark/DADA",[],[]
"This supplementary material provides additional material not contained in the main paper. Section S.1 delivers proofs of the results for characterizing distributional parallel trends in Appendix LABEL:ssec:appendixA. Section S.2 describes the required derivatives for implementing the Delta method, facilitating the computation of standard errors associated with estimated treatment effects. Section S.3 outlines technical assumptions and results for the estimation of our semiparametric model in the absence of misreporting. Section S.4
presents a decomposition of another possible causal quantity, characterized by the difference between potential self-reported outcome distributions under treatment and control. Finally, Sections S.5 and S.6 display additional simulation and empirical results, respectively.",[],[]
"We study the evolution with collision energy of the parameters describing the two-pion correlation function in the context of relativistic heavy-ion collisions within the NICA energy range. To this end, we perform UrQMD simulations to produce samples of pions from 5×1065superscript1065\times 10^{6}5 × 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT Bi+Bi collisions for each of the studied energies. The effects of the quantum correlations are introduced using the correlation afterburner code CRAB. We fit the correlation function using Gaussian, Lorentzian and symmetric Lévy distributions and show that for all collision energies the latter provides the best fit. We separate the sample into pions coming from primary processes and pions originating from the decay of long-lived resonances and show that the source size for the latter is significantly larger than for the former, which is consistent with the core-halo picture of pion production. We then simulate the effects of a non-ideal detector introducing a momentum smearing parameter representing the minimum pair momentum and thus a maximum source size that can be resolved. By resorting again to the core-halo picture, we show that the values of the correlation function intercept parameter are affected by the presence of a significant fraction of core pions coming from the decay of long-lived but slow moving resonances. We argue that the study of the evolution of these two core components with the collision energy can provide useful insights to look for signs of criticality in correlation function studies.",[],['Mexico']
"The study of ψ−limit-from𝜓\psi-italic_ψ -hyperholomorphic functions defined on domains in ℝ4superscriptℝ4\mathbb{R}^{4}blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT with values in ℍℍ\mathbb{H}blackboard_H, namely null-solutions of the ψ−limit-from𝜓\psi-italic_ψ -Fueter operator, is a topic which captured great interest in quaternionic analysis. This class of functions is more general than that of Fueter regular functions.
In the setting of (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus, also known as post quantum calculus, we introduce a deformation of the ψ−limit-from𝜓\psi-italic_ψ -Fueter operator written in terms of suitable difference operators, which reduces to a deformed q𝑞qitalic_q calculus when q′=1superscript𝑞′1q^{\prime}=1italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 1. We also prove the Stokes and Borel-Pompeiu formulas in this context.
This work is the first investigation of results in quaternionic analysis in the setting of the (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus theory.

Keywords. (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus, Stokes formula, Borel-Pompeiu formula, quaternionic analysis
MSC 2020. Primary: 30G30; 30G35, 05A30, Secondary: 46S05, 47S05",[],[]
"We get multiplicity of normalized solutions for the fractional Schrödinger equation



{(−Δ)s⁢u+V⁢(ε⁢x)⁢u=λ⁢u+h⁢(ε⁢x)⁢f⁢(u)in⁢ℝN,∫ℝN|u|2⁢𝑑x=a,casessuperscriptΔ𝑠𝑢𝑉𝜀𝑥𝑢𝜆𝑢ℎ𝜀𝑥𝑓𝑢insuperscriptℝ𝑁subscriptsuperscriptℝ𝑁superscript𝑢2differential-d𝑥𝑎missing-subexpression\displaystyle\left\{\begin{array}[]{ll}(-\Delta)^{s}u+V(\varepsilon x)u=%
\lambda u+h(\varepsilon x)f(u)&\mbox{in}\ \mathbb{R}^{N},\\
\displaystyle\int_{\mathbb{R}^{N}}|u|^{2}dx=a,\end{array}\right.{ start_ARRAY start_ROW start_CELL ( - roman_Δ ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT italic_u + italic_V ( italic_ε italic_x ) italic_u = italic_λ italic_u + italic_h ( italic_ε italic_x ) italic_f ( italic_u ) end_CELL start_CELL in blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT , end_CELL end_ROW start_ROW start_CELL ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_x = italic_a , end_CELL start_CELL end_CELL end_ROW end_ARRAY



where (−Δ)ssuperscriptΔ𝑠(-\Delta)^{s}( - roman_Δ ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT is the fractional Laplacian, s∈(0,1)𝑠01s\in(0,1)italic_s ∈ ( 0 , 1 ), a,ε>0𝑎𝜀0a,\varepsilon>0italic_a , italic_ε > 0, λ∈ℝ𝜆ℝ\lambda\in\mathbb{R}italic_λ ∈ blackboard_R is an unknown parameter that appears as a Lagrange multiplier,
V,h:ℝN→[0,+∞):𝑉ℎ→superscriptℝ𝑁0V,h:\mathbb{R}^{N}\rightarrow[0,+\infty)italic_V , italic_h : blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → [ 0 , + ∞ ) are bounded and continuous, and f𝑓fitalic_f is continuous function with L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-subcritical growth. We prove that
the numbers of normalized solutions are at least the numbers of global maximum points of hℎhitalic_h when ε𝜀\varepsilonitalic_ε is small enough.","['Fractional', 'Laplacian', 'Normalized solution', 'Mass critical exponent']",[]
"Federated Learning (FL) enables collaborative model training among participants while guaranteeing the privacy of raw data. Mainstream FL methodologies overlook the dynamic nature of real-world data, particularly its tendency to grow in volume and diversify in classes over time. This oversight results in FL methods suffering from catastrophic forgetting, where models inadvertently discard previously learned information upon assimilating new data.
In response to this challenge, we propose a novel Federated Class-Incremental Learning (FCIL) method, named FCIL with New-Class Augmented Self-Distillation (FedNASD). FedNASD combines new class scores, which are inferred from current models, with historical models’ predictions. Based on the combined past and present knowledge, it incorporates self-distillation over models on clients, aiming to achieve effective knowledge transfer from historical models to current models. Theoretical analysis demonstrates that FedNASD is equivalent to modeling old class scores as conditional probabilities in the absence of new classes. Additionally, it reconciles the predictions of new classes with current models to refine the conditional probabilities of historical scores where new classes do not exist. Empirical experiments demonstrate the superiority of FedNASD over four baseline algorithms in reducing the average forgetting rate and boosting global accuracy.",[],[]
"We are concerned with the existence of normalized solutions for a class of generalized Chern-Simons-Schrödinger type problems
with supercritical exponential growth



{−Δ⁢u+λ⁢u+A0⁢u+∑j=12Aj2⁢u=f⁢(u),∂1A2−∂2A1=−12⁢|u|2,∂1A1+∂2A2=0,∂1A0=A2⁢|u|2,∂2A0=−A1⁢|u|2,∫ℝ2|u|2⁢𝑑x=a2,casesΔ𝑢𝜆𝑢subscript𝐴0𝑢superscriptsubscript𝑗12superscriptsubscript𝐴𝑗2𝑢𝑓𝑢missing-subexpressionformulae-sequencesubscript1subscript𝐴2subscript2subscript𝐴112superscript𝑢2subscript1subscript𝐴1subscript2subscript𝐴20missing-subexpressionformulae-sequencesubscript1subscript𝐴0subscript𝐴2superscript𝑢2subscript2subscript𝐴0subscript𝐴1superscript𝑢2missing-subexpressionsubscriptsuperscriptℝ2superscript𝑢2differential-d𝑥superscript𝑎2missing-subexpression\left\{\begin{array}[]{ll}\displaystyle-\Delta u+\lambda u+A_{0}u+\sum\limits_%
{j=1}^{2}A_{j}^{2}u=f(u),\\
\displaystyle\partial_{1}A_{2}-\partial_{2}A_{1}=-\frac{1}{2}|u|^{2},%
\leavevmode\nobreak\ \partial_{1}A_{1}+\partial_{2}A_{2}=0,\\
\displaystyle\partial_{1}A_{0}=A_{2}|u|^{2},\leavevmode\nobreak\ \partial_{2}A%
_{0}=-A_{1}|u|^{2},\\
\displaystyle\int_{\mathbb{R}^{2}}|u|^{2}dx=a^{2},\end{array}\right.{ start_ARRAY start_ROW start_CELL - roman_Δ italic_u + italic_λ italic_u + italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_u + ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_u = italic_f ( italic_u ) , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - divide start_ARG 1 end_ARG start_ARG 2 end_ARG | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = - italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_x = italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , end_CELL start_CELL end_CELL end_ROW end_ARRAY



where a≠0𝑎0a\neq 0italic_a ≠ 0, λ∈ℝ𝜆ℝ\lambda\in\mathbb{R}italic_λ ∈ blackboard_R is known as the Lagrange multiplier
and f∈𝒞1⁢(ℝ)𝑓superscript𝒞1ℝf\in\mathcal{C}^{1}(\mathbb{R})italic_f ∈ caligraphic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( blackboard_R ) denotes the nonlinearity that fulfills the
supercritical exponential growth in the Trudinger-Moser sense at infinity.
Under suitable assumptions, combining the constrained minimization approach together with the homotopy stable family and elliptic regularity theory,
we obtain that the problem has at least a ground state solution.","['Normalized solutions', 'Chern-Simons-Schrödinger system', 'Trudinger-Moser inequality', 'Constrained minimization approach', 'Ground state solution', 'Variational method.']",[]
,[],[]
"Several reports in education have called for transforming physics learning environments by promoting sensemaking of real-world scenarios in light of curricular ideas. Recent advancements in Generative-Artificial Intelligence has garnered increasing traction in educators’ community by virtue of its potential in transforming STEM learning. In this exploratory study, we adopt a mixed-methods approach in comparatively examining student- and AI-generated responses to two different formats of a physics problem through the cognitive lenses of sensemaking and mechanistic reasoning. The student data is derived from think-aloud interviews of introductory students and the AI data comes from ChatGPT’s solutions collected using Zero shot approach. The results highlight AI responses to evidence most features of the two processes through well-structured solutions and student responses to effectively leverage representations in their solutions through iterative refinement of arguments. In other words, while AI responses reflect how physics is talked about, the student responses reflect how physics is practiced. Implications of these results in light of development and deployment of AI systems in physics pedagogy are discussed.",[],[]
,[],[]
"We propose a Safe Adversarial Trained Actor Critic (SATAC) algorithm for offline reinforcement learning (RL) with general function approximation in the presence of limited data coverage. SATAC operates as a two-player Stackelberg game featuring a refined objective function. The actor (leader player) optimizes the policy against two adversarially trained value critics (follower players), who focus on scenarios where the actor’s performance is inferior to the behavior policy. Our framework provides both theoretical guarantees and a robust deep-RL implementation. Theoretically, we demonstrate that when the actor employs a no-regret optimization oracle, SATAC achieves two guarantees: (i)𝑖(i)( italic_i ) For the first time in the offline RL setting, we establish that SATAC can produce a policy that outperforms the behavior policy while maintaining the same level of safety, which is critical to designing an algorithm for offline RL. (i⁢i)𝑖𝑖(ii)( italic_i italic_i ) We demonstrate that the algorithm guarantees policy improvement across a broad range of hyperparameters, indicating its practical robustness. Additionally, we offer a practical version of SATAC and compare it with existing state-of-the-art offline safe-RL algorithms in continuous control environments. SATAC outperforms all baselines across a range of tasks, thus validating the theoretical performance.",[],[]
,[],[]
"As artificial intelligence (AI) applications continue to expand, there is a growing need for deep neural network (DNN) models. Although DNN models deployed at the edge are promising to provide AI as a service with low latency, their cooperation is yet to be explored. In this paper, we consider the DNN service providers share their computing resources as well as their models’ parameters and allow other DNNs to offload their computations without mirroring. We propose a novel algorithm called coordinated DNNs on edge (CoDE) that facilitates coordination among DNN services by creating multi-task DNNs out of individual models. CoDE aims to find the optimal path that results in the lowest possible cost, where the cost reflects the inference delay, model accuracy, and local computation workload. With CoDE, DNN models can make new paths for inference by using their own or other models’ parameters. We then evaluate the performance of CoDE through numerical experiments. The results demonstrate a 75%percent7575\%75 % reduction in the local service computation workload while degrading the accuracy by only 2%percent22\%2 % and having the same inference time in a balanced load condition. Under heavy load, CoDE can further decrease the inference time by 30%percent3030\%30 % while the accuracy is reduced by only 4%percent44\%4 %.","['AI as a service', 'computation offloading', 'multi-task', 'DNNs', 'service coordination.']",[]
"Integrating sharded blockchain with IoT presents a solution for trust issues and optimized data flow. Sharding boosts blockchain scalability by dividing its nodes into parallel shards, yet it’s vulnerable to the 1%percent11\%1 % attacks where dishonest nodes target a shard to corrupt the entire blockchain. Balancing security with scalability is pivotal for such systems. Deep Reinforcement Learning (DRL) adeptly handles dynamic, complex systems and multi-dimensional optimization.
This paper introduces a Trust-based and DRL-driven (TbDd) framework, crafted to counter shard collusion risks and dynamically adjust node allocation, enhancing throughput while maintaining network security. With a comprehensive trust evaluation mechanism, TbDd discerns node types and performs targeted resharding against potential threats. The model maximizes tolerance for dishonest nodes, optimizes node movement frequency, ensures even node distribution in shards, and balances sharding risks. Rigorous evaluations prove TbDd’s superiority over conventional random-, community-, and trust-based sharding methods in shard risk equilibrium and reducing cross-shard transactions.","['blockchain', 'sharding', 'collusion attacks', 'trustworthiness', 'deep reinforcement learning', 'internet-of-things']",[]
"Neural networks are increasingly finding their way into the realm of graphs and modeling relationships between features. Concurrently graph neural network explanation approaches are being invented to uncover relationships between the nodes of the graphs. However, there is a disparity between the existing attribution methods, and it is unclear which attribution to trust. Therefore research has introduced evaluation experiments that assess them from different perspectives. In this work, we assess attribution methods from a perspective not previously explored in the graph domain: retraining. The core idea is to retrain the network on important (or not important) relationships as identified by the attributions and evaluate how networks can generalize based on these relationships. We reformulate the retraining framework to sidestep issues lurking in the previous formulation and propose guidelines for correct analysis. We run our analysis on four state-of-the-art GNN attribution methods and five synthetic and real-world graph classification datasets. The analysis reveals that attributions perform variably depending on the dataset and the network. Most importantly, we observe that the famous GNNExplainer performs similarly to an arbitrary designation of edge importance. The study concludes that the retraining evaluation cannot be used as a generalized benchmark and recommends it as a toolset to evaluate attributions on a specifically addressed network, dataset, and sparsity. Our code is publically available.111
https://github.com/alirezadizaji/GraphROAR",[],[]
"Realizing photonic graph states, crucial in various quantum protocols, is challenging due to the absence of deterministic entangling gates in linear optics. To address this, emitter qubits are leveraged to establish and transfer the entanglement to photons. We introduce an optimization method for such protocols based on the local Clifford equivalency of states and the graph-shape correlated generation cost parameters. Employing this method, we achieve a 50% reduction in use of the 2-qubit gates for generation of the repeater graph states and a 65% reduction in the total gate count for 15-node random dense graphs.",[],['Canada']
"We introduce a new notion of a periodic pencil of flat connections on a smooth algebraic variety X𝑋Xitalic_X. This is a family ∇(s1,…,sn)∇subscript𝑠1…subscript𝑠𝑛\nabla(s_{1},...,s_{n})∇ ( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) of flat connections on a trivial vector bundle on X𝑋Xitalic_X depending linearly on parameters s1,…,snsubscript𝑠1…subscript𝑠𝑛s_{1},...,s_{n}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and generically invariant, up to isomorphism, under the shifts si↦si+1maps-tosubscript𝑠𝑖subscript𝑠𝑖1s_{i}\mapsto s_{i}+1italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ↦ italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 for all i𝑖iitalic_i. If
in addition ∇∇\nabla∇ has regular singularities, we call it a quasi-motivic pencil. We
use tools from complex analysis to establish various remarkable properties of such pencils over ℂℂ\mathbb{C}blackboard_C. For example, we show that the monodromy of a quasi-motivic pencil is defined over the field of algebraic functions in e2⁢π⁢i⁢sjsuperscript𝑒2𝜋𝑖subscript𝑠𝑗e^{2\pi is_{j}}italic_e start_POSTSUPERSCRIPT 2 italic_π italic_i italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, and that its singularities are
constrained to an arrangement of hyperplanes with integer normal vectors. Then we show that many important examples of families of flat connections, such as Knizhnik-Zamolodchikov, Dunkl, and Casimir connections, are quasi-motivic and thus periodic pencils.
Besides being interesting in its own right, the periodic property of a pencil of flat connections turns out to be very useful in computing the eigenvalues of the p𝑝pitalic_p-curvature of its reduction to positive characteristic. This will be done in our forthcoming paper [EV2].",[],[]
,[],[]
,[],[]
"Relative pose estimation for RGBD cameras is crucial in a number of applications. Previous approaches either rely on the RGB aspect of the images to estimate pose thus not fully making use of depth in the estimation process or estimate pose from the 3D cloud of points that each image produces, thus not making full use of RGB information. This paper shows that if one pair of correspondences is hypothesized from the RGB-based ranked-ordered correspondence list, then the space of remaining correspondences is restricted to corresponding pairs of curves nested around the hypothesized correspondence, implicitly capturing depth consistency. This simple Geometric Depth Constraint (GDC)  significantly reduces potential matches. In effect this becomes a filter on possible correspondences that helps reduce the number of outliers and thus expedites RANSAC significantly. As such, the same budget of time allows for more RANSAC iterations and therefore additional robustness and a significant speedup. In addition, the paper proposed a Nested RANSAC approach that also speeds up the process, as shown through experiments on TUM, ICL-NUIM, and RGBD Scenes v2 datasets.",[],[]
"We study the Marcinkiewicz-Zygmund strong law of large numbers for the cubic partial sums of the discrete Fourier transform of random
fields. We establish Marcinkiewicz–Zygmund types rate of convergence for the discrete Fourier transform of random
fields under weaker conditions than identical distribution.",[],[]
"This paper introduces a novel hierarchical Bayesian model specifically designed to address challenges in Inverse Uncertainty Quantification (IUQ) for time-dependent problems in nuclear Thermal Hydraulics (TH) systems. The unique characteristics of time-dependent data, such as high dimensionality and correlation in model outputs requires special attention in the IUQ process. By integrating Gaussian Processes (GP) with Principal Component Analysis (PCA), we efficiently construct surrogate models that effectively handle the complexity of dynamic TH systems. Additionally, we incorporate Neural Network (NN) models for time series regression, enhancing the computational accuracy and facilitating derivative calculations for efficient posterior sampling using the Hamiltonian Monte Carlo Method - No U-Turn Sampler (NUTS).
We demonstrate the effectiveness of this hierarchical Bayesian approach using the transient experiments in the PSBT benchmark. Our results show improved estimates of PMPs’ posterior distributions and a reduced tendency for over-fitting, compared to conventional single-level Bayesian models. This approach offers a promising framework for extending IUQ to more complex, time-dependent problems.",[],[]
"During times of increasing antibiotic resistance and the spread of infectious diseases like COVID-19, it is important to classify genes related to antibiotic resistance. As natural language processing has advanced with transformer-based language models, many language models that learn characteristics of nucleotide sequences have also emerged. These models show good performance in classifying various features of nucleotide sequences. When classifying nucleotide sequences, not only the sequence itself, but also various background knowledge is utilized. In this study, we use not only a nucleotide sequence-based language model but also a text language model based on PubMed articles to reflect more biological background knowledge in the model. We propose a method to fine-tune the nucleotide sequence language model and the text language model based on various databases of antibiotic resistance genes. We also propose an LLM-based augmentation technique to supplement the data and an ensemble method to effectively combine the two models. We also propose a benchmark for evaluating the model. Our method achieved better performance than the nucleotide sequence language model in the drug resistance class prediction.",[],[]
"A quantum stochastic differential equation (qsde) on Fock space over L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT differential 1111-forms is given from the small “time” flow of which the trace of the connection Laplacian heat kernel for the spinor endomorphism bundle can be computed over any compact Ricci-flat Riemannian manifold. The existence of the stochastic flow is established by adapting the construction from [14]. When the manifold supports a parallel spinor – Ricci-flatness is a required integrability condition for parallel spinors, the trace of Dirac Laplacian heat kernel of the spinor bundle can be recovered. For 4444-manifolds, this corresponds to the spectral action, and realizes Einstein-Hilbert action as a stochastic flow.",[],[]
"Wind is one kind of high-efficient, environmentally-friendly and cost-effective energy source.
Wind power, as one of the largest renewable energy in the world, has been playing a more and more important role in supplying electricity.
Though growing dramatically in recent years, the amount of generated wind power can be directly or latently affected by multiple uncertain factors, such as wind speed, wind direction, temperatures, etc.
More importantly, there exist very complicated dependencies of the generated power on the latent composition of these multiple time-evolving variables,
which are always ignored by existing works and thus largely hinder the prediction performances.
To this end, we propose DEWP, a novel Deep Expansion learning for Wind Power forecasting framework to carefully model the complicated dependencies with adequate expressiveness.
DEWP starts with a stack-by-stack architecture, where each stack is composed of (i) a variable expansion block that makes use of convolutional layers to capture dependencies among multiple variables;
(ii) a time expansion block that applies Fourier series and backcast/forecast mechanism to learn temporal dependencies in sequential patterns.
These two tailored blocks expand raw inputs into different latent feature spaces which can model different levels of dependencies of time-evolving sequential data.
Moreover, we propose an inference block corresponding for each stack, which applies multi-head self-attentions to acquire attentive features and maps expanded latent representations into generated wind power.
In addition, to make DEWP more expressive in handling deep neural architectures, we adapt doubly residue learning to process stack-by-stack outputs. Accurate wind power forecasting is then better achieved through fine-grained outputs by continuously removing stack residues and accumulating useful stack forecasts.
Finally, we present extensive experiments in the real-world wind power forecasting application on two datasets from two different turbines, in order to demonstrate the effectiveness of our approach.","['Wind', 'Power', 'Forecasting', 'Time', 'Series', 'Forecasting', 'Deep', 'Learning']",['China']
"We prove that the highest density of non-overlapping translates of a given centrally symmetric convex domain relative to its outer parallel domain of given outer radius is attained by a lattice packing in the Euclidean plane. This generalizes some earlier (classical) results. Sharp upper bounds are proved for the analogue problem on congruent circular disks in the spherical (resp., hyperbolic) plane and on congruent balls in Euclidean 3333-space.",[],[]
"We present magnetostriction and thermal expansion measurements on multiferroic (Ni0.930.93{}_{0.93}start_FLOATSUBSCRIPT 0.93 end_FLOATSUBSCRIPTCo0.070.07{}_{0.07}start_FLOATSUBSCRIPT 0.07 end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT. The high field phase diagrams up to 33 T along the a𝑎aitalic_a, b𝑏bitalic_b and c𝑐citalic_c directions are built. For H//a𝑎aitalic_a, as the magnetic field increasing, two intermediate phases appear between the incommensurate phase and the paramagnetic phase at about 7 K, and then a magnetically induced phase appears above the paramagnetic phase. For H//b𝑏bitalic_b, a thermal expansion measurement indicates a mutation in the spin lattice coupling of the high field phases. The interlaced phase boundary suggests a mixed state in the optical high field phase. For H//c𝑐citalic_c, an intermediate phase between the commensurate phase and the incommensurate phase is detected. A nonlinear boundary between the intermediate phase and the low temperature incommensurate phase, and a clear boundary between the commensurate phase and the paramagnetic phase are found. These results indicate that doping Co2+limit-from2{}^{2+}start_FLOATSUPERSCRIPT 2 + end_FLOATSUPERSCRIPT breaks the weak ferromagnetic moment of the commensurate phase, which exists in the parent compound Ni33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT and (Ni0.90.9{}_{0.9}start_FLOATSUBSCRIPT 0.9 end_FLOATSUBSCRIPTCo0.10.1{}_{0.1}start_FLOATSUBSCRIPT 0.1 end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT. This nonlinear influence reflects complicated spin modulation in Ni33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT by doping Co2+limit-from2{}^{2+}start_FLOATSUPERSCRIPT 2 + end_FLOATSUPERSCRIPT.",[],['China']
,[],[]
"We give an example for the Kuznetsov-Shinder conjecture, with infinitely many non-isomorphic but L-equivalent varieties.",[],[]
,[],[]
"Smart contracts are computer programs running on blockchains to automate the transaction execution between users.
The absence of contract specifications poses a real challenge to the correctness verification of
smart contracts.
Program invariants are properties that are always preserved throughout the execution, which
characterize an important aspect of the program behaviors.
In this paper, we propose a novel invariant generation framework, InvCon+, for Solidity smart
contracts.
InvCon+ extends the existing invariant detector, InvCon, to automatically produce verified
contract invariants based on both dynamic inference and static verification.
Unlike InvCon+, InvCon only produces likely invariants, which have a high probability to hold,
yet are still not verified against the contract code.
Particularly, InvCon+ is able to infer more expressive invariants that capture richer semantic
relations of contract code.
We evaluate InvCon+ on 361 ERC20 and 10 ERC721 real-world contracts, as well as common
ERC20 vulnerability benchmarks.
The experimental results indicate that InvCon+ efficiently produces high-quality invariant
specifications, which can be used to secure smart contracts from common vulnerabilities.","['Smart contract', 'invariant detection.']",['Singapore']
"Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings.","['Random walk', 'inductive graph representation learning', 'node identity embedding', 'node position embedding.']",[]
"Traditional video steganography methods are based on modifying the covert space for embedding, whereas we propose an innovative approach that embeds secret message within semantic feature for steganography during the video editing process.
Although existing traditional video steganography methods display a certain level of security and embedding capacity, they lack adequate robustness against common distortions in online social networks (OSNs).
In this paper, we introduce an end-to-end robust generative video steganography network (RoGVS), which achieves visual editing by modifying semantic feature of videos to embed secret message. We employ face-swapping scenario to showcase the visual editing effects. We first design a secret message embedding module to adaptively hide secret message into the semantic feature of videos.
Extensive experiments display that the proposed RoGVS method applied to facial video datasets demonstrate its superiority over existing video and image steganography techniques in terms of both robustness and capacity.",[],[]
"Deceptive images can be shared in seconds with social networking services, posing substantial risks. Tampering traces, such as boundary artifacts and high-frequency information, have been significantly emphasized by massive networks in the Image Manipulation Localization (IML) field. However, they are prone to image post-processing operations, which limit the generalization and robustness of existing methods.
We present a novel Prompt-IML framework. We observe that humans tend to discern the authenticity of an image based on both semantic and high-frequency information, inspired by which, the proposed framework leverages rich semantic knowledge from pre-trained visual foundation models to assist IML.
We are the first to design a framework that utilizes visual foundation models specially for the IML task.
Moreover, we design a Feature Alignment and Fusion module to align and fuse features of semantic features with high-frequency features, which aims at locating tampered regions from multiple perspectives. Experimental results demonstrate that our model can achieve better performance on eight typical fake image datasets and outstanding robustness.",[],[]
"We obtain a global rigidity result for abelian partially hyperbolic higher rank actions on certain 2−limit-from22-2 -step nilmanifolds XΓsubscript𝑋ΓX_{\Gamma}italic_X start_POSTSUBSCRIPT roman_Γ end_POSTSUBSCRIPT. We show that, under certain natural assumptions, all such actions are C∞−limit-fromsuperscript𝐶C^{\infty}-italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT -conjugated to an affine model. Along the way, we also prove two results of independent interest. We describe fibered partially hyperbolic diffeomorphisms on XΓsubscript𝑋ΓX_{\Gamma}italic_X start_POSTSUBSCRIPT roman_Γ end_POSTSUBSCRIPT and we show that topological conjugacies between partially hyperbolic actions and higher rank affine actions are C∞superscript𝐶C^{\infty}italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. As a consequence, we obtain a centralizer rigidity result, and we classify all possible centralizers for any C1−limit-fromsuperscript𝐶1C^{1}-italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT -small perturbation of an irreducible, affine partially hyperbolic map on such manifolds.",[],[]
"In this paper, we prove the existence of periodic solutions with any prescribed minimal period T>0𝑇0T>0italic_T > 0
for even second order Hamiltonian systems and convex first order Hamiltonian systems under the weak Nehari
condition instead of Ambrosetti-Rabinowitz’s. To this end, we shall develop the method of Nehari manifold to directly deal with a
frequently occurring problem where the Nehari manifold is not a manifold.",[],[]
"We present iDARR, a scalable iterative Data-Adaptive RKHS Regularization method, for solving ill-posed linear inverse problems. The method searches for solutions in subspaces where the true solution can be identified, with the data-adaptive RKHS penalizing the spaces of small singular values. At the core of the method is a new generalized Golub-Kahan bidiagonalization procedure that recursively constructs orthonormal bases for a sequence of RKHS-restricted Krylov subspaces. The method is scalable with a complexity of O⁢(k⁢m⁢n)𝑂𝑘𝑚𝑛O(kmn)italic_O ( italic_k italic_m italic_n ) for m𝑚mitalic_m-by-n𝑛nitalic_n matrices with k𝑘kitalic_k denoting the iteration numbers. Numerical tests on the Fredholm integral equation and 2D image deblurring show that it outperforms the widely used L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and l2superscript𝑙2l^{2}italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT norms, producing stable accurate solutions consistently converging when the noise level decays.",[],"['Australia', 'China']"
"The Alternating Direction Method of Multipliers (ADMM) has gained significant attention across a broad spectrum of machine learning applications. Incorporating the over-relaxation technique shows potential for enhancing the convergence rate of ADMM. However, determining optimal algorithmic parameters, including both the associated penalty and relaxation parameters, often relies on empirical approaches tailored to specific problem domains and contextual scenarios. Incorrect parameter selection can significantly hinder ADMM’s convergence rate. To address this challenge, in this paper we first propose a general approach to optimize the value of penalty parameter, followed by a novel closed-form formula to compute the optimal relaxation parameter in the context of linear quadratic problems (LQPs). We then experimentally validate our parameter selection methods through random instantiations and diverse imaging applications, encompassing diffeomorphic image registration, image deblurring, and MRI reconstruction.",[],[]
"Acquisition and processing of point clouds (PCs) is a crucial enabler for many emerging applications reliant on 3D spatial data, such as robot navigation, autonomous vehicles, and augmented reality. In most scenarios, PCs acquired by remote sensors must be transmitted to an edge server for fusion, segmentation, or inference. Wireless transmission of PCs not only puts on increased burden on the already congested wireless spectrum, but also confronts a unique set of challenges arising from the irregular and unstructured nature of PCs. In this paper, we meticulously delineate these challenges and offer a comprehensive examination of existing solutions while candidly acknowledging their inherent limitations. In response to these intricacies, we proffer four pragmatic solution frameworks, spanning advanced techniques, hybrid schemes, and distributed data aggregation approaches. In doing so, our goal is to chart a path toward efficient, reliable, and low-latency wireless PC transmission.","['Wireless point cloud transmission', 'point cloud compression', 'semantic communication', 'DeepJSCC', 'NeRF.']",[]
"As available data increases, so too does the demand to discover new datasets to solve new problems.
Existing studies using a base dataset and a keyword search often yield coarse-grained results where significant information overlaps and non-relevant data occur.
They also implicitly assume that a user can purchase all datasets found, which is rarely true in practice.
Therefore, achieving dataset discovery results with less redundancy using more fine-grained information needs and a budget is desirable.
To achieve this, we study the problem of finding a set of datasets that maximize distinctiveness based on a user’s fine-grained information needs while keeping the total price of the datasets within a user-defined budget. Note that the user may also have a base dataset that they want to expand.
Here,
the user’s fine-grained information needs are expressed as a query set and the distinctiveness score for a set of datasets, which is the number of distinct tuples produced by running the query set on the datasets which are do not overlap with the base dataset.
First, we prove the NP-hardness of this problem.
Then, we develop a greedy algorithm that achieves an approximation of (1−e−1)/21superscript𝑒12(1-e^{-1})/2( 1 - italic_e start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) / 2.
But this algorithm is neither efficient nor scalable as it frequently computes the exact distinctiveness during dataset selection, which requires every tuple for the query result overlap in multiple datasets to be tested.
To address this limitation, we propose an efficient and effective machine-learning-based (ML-based) algorithm to estimate the distinctiveness for a set of datasets, without the need for testing every tuple.
The proposed algorithm is the first to support cardinality estimation (CE) for a query set on multiple datasets, as previous studies only support CE for a single query on a single dataset, and cannot effectively identify query result overlaps in multiple datasets.
Extensive experiments using five real-world data pools demonstrate that our greedy algorithm using ML-based distinctiveness estimation outperforms all other baselines in both effectiveness and efficiency.",[],[]
,[],[]
"With the increasing number of fast-electric vehicle charging stations (fast-EVCSs) and the popularization of information technology, electricity price competition between fast-EVCSs is highly expected, in which the utilization of public and/or privacy-preserved information will play a crucial role. Self-interest electric vehicle (EV) users, on the other hand, try to select a fast-EVCS for charging in a way to maximize their utilities based on electricity price, estimated waiting time, and their state of charge. While existing studies have largely focused on finding equilibrium prices, this study proposes a personalized dynamic pricing policy (PeDP) for a fast-EVCS to maximize revenue using a reinforcement learning (RL) approach. We first propose a multiple fast-EVCSs competing simulation environment to model the selfish behavior of EV users using a game-based charging station selection model with a monetary utility function. In the environment, we propose a Q-learning-based PeDP to maximize fast-EVCS’ revenue. Through numerical simulations based on the environment: (1) we identify the importance of waiting time in the EV charging market by comparing the classic Bertrand competition model with the proposed PeDP for fast-EVCSs (from the system perspective); (2) we evaluate the performance of the proposed PeDP and analyze the effects of the information on the policy (from the service provider perspective); and (3) it can be seen that privacy-preserved information sharing can be misused by artificial intelligence-based PeDP in a certain situation in the EV charging market (from the customer perspective).",[],[]
"Automatic recognition of dysarthric speech remains a highly challenging task to date.
Neuro-motor conditions and co-occurring physical disabilities create difficulty in large-scale data collection for ASR system development.
Adapting SSL pre-trained ASR models to limited dysarthric speech via data-intensive parameter fine-tuning leads to poor generalization.
To this end, this paper presents an extensive comparative study of various data augmentation approaches to improve the robustness of pre-trained ASR model fine-tuning to dysarthric speech.
These include: a) conventional speaker-independent perturbation of impaired speech; b) speaker-dependent speed perturbation, or GAN-based adversarial perturbation of normal, control speech based on their time alignment against parallel dysarthric speech; c) novel Spectral basis GAN-based adversarial data augmentation operating on non-parallel data.
Experiments conducted on the UASpeech corpus suggest GAN-based data augmentation consistently outperforms fine-tuned Wav2vec2.0 and HuBERT models using no data augmentation and
speed perturbation across different data expansion operating points by statistically significant word error rate (WER) reductions up to 2.01% and 0.96% absolute (9.03% and 4.63% relative) respectively on the UASpeech test set of 16 dysarthric speakers.
After cross-system outputs rescoring, the best system produced the lowest published WER of 16.53% (46.47% on very low intelligibility) on UASpeech.",[],[]
"The recent transformer-based models have dominated the Referring Video Object Segmentation (RVOS) task due to the superior performance. Most prior works adopt unified DETR framework to generate segmentation masks in query-to-instance manner. In this work, we integrate strengths of that leading RVOS models to build up an effective paradigm. We first obtain binary mask sequences from the RVOS models. To improve the consistency and quality of masks, we propose Two-Stage Multi-Model Fusion strategy. Each stage rationally ensembles RVOS models based on framework design as well as training strategy, and leverages different video object segmentation (VOS) models to enhance mask coherence by object propagation mechanism. Our method achieves 75.7%percent75.775.7\%75.7 % 𝒥&ℱ𝒥ℱ\mathcal{J}\&\mathcal{F}caligraphic_J & caligraphic_F on Ref-Youtube-VOS validation set and 70%percent7070\%70 % 𝒥&ℱ𝒥ℱ\mathcal{J}\&\mathcal{F}caligraphic_J & caligraphic_F on test set, which ranks 1st place on 5th Large-scale Video Object Segmentation Challenge (ICCV 2023) track 3. Code is available at https://github.com/RobertLuo1/iccv2023_RVOS_Challenge.",[],[]
,[],[]
"We present a deterministic n2+o⁢(1)superscript𝑛2𝑜1n^{2+o(1)}italic_n start_POSTSUPERSCRIPT 2 + italic_o ( 1 ) end_POSTSUPERSCRIPT-time algorithm that approximates the crossing number of any graph G𝐺Gitalic_G of order n𝑛nitalic_n up to an additive error of o⁢(n4)𝑜superscript𝑛4o(n^{4})italic_o ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ). We also provide a randomized polynomial-time algorithm that constructs a drawing of G𝐺Gitalic_G with cr⁢(G)+o⁢(n4)cr𝐺𝑜superscript𝑛4\text{cr}(G)+o(n^{4})cr ( italic_G ) + italic_o ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) crossings. These results are made interesting by the well known fact that every dense n𝑛nitalic_n-vertex graph has crossing number Θ⁢(n4)Θsuperscript𝑛4\Theta(n^{4})roman_Θ ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ). Our work builds on a technique developed by Fox, Pach and Súk [18], who obtained very similar results for the rectilinear crossing number.
The results in [18] and in this paper imply that the (normalized) crossing and rectilinear crossing numbers are estimable parameters. Motivated by this, we introduce two graphon parameters, the crossing density and the rectilinear crossing density, and then we prove that, in a precise sense, these are the correct continuous analogs of the crossing and rectilinear crossing numbers of graphs.",[],[]
"In this work, we study the δ𝛿\deltaitalic_δ-chromatic number of a graph which is the chromatic number of the δ𝛿\deltaitalic_δ-complement of a graph.
We give a structure of the δ𝛿\deltaitalic_δ-complements and sharp bounds on the δ𝛿\deltaitalic_δ-chromatic numbers of the Cartesian products of graphs.
Furthermore, we compute the δ𝛿\deltaitalic_δ-chromatic numbers of various classes of Cartesian product graphs, including the Cartesian products between cycles, paths, and stars.",[],[]
"Monte Carlo integration is fundamental in scientific and statistical computation, but requires reliable samples from the target distribution, which poses a substantial challenge in the case of multi-modal distributions. Existing methods often involve time-consuming tuning, and typically lack tailored estimators for efficient use of the samples. This paper adapts the Warp-U transformation (Wang et al., 2022) to form multi-modal sampling strategy called Warp-U sampling. It constructs a stochastic map to transport a multi-modal density into a uni-modal one, and subsequently inverts the transport but with new stochasticity injected. For efficient use of the samples for normalising constant estimation, we propose (i) an unbiased estimation scheme based coupled chains, where the Warp-U sampling is used to reduce the coupling time; and (ii) a stochastic Warp-U bridge sampling estimator, which improves its deterministic counterpart given in Wang et al. (2022). Our overall approach requires less tuning and is easier to apply than common alternatives. Theoretically, we establish the ergodicity of our sampling algorithm and that our stochastic Warp-U bridge sampling estimator has greater (asymptotic) precision per CPU second compared to the Warp-U bridge estimator of Wang et al. (2022) under practical conditions. The advantages and current limitations of our approach are demonstrated through simulation studies and an application to exoplanet detection.",[],[]
,[],[]
"In this article, we firstly analyze the electromagnetic form factors of the vector heavy-light mesons to the pseudoscalar heavy-light mesons in the framework of three-point QCD sum rules, where the contributions of vacuum condensate terms ⟨q¯⁢q⟩delimited-⟨⟩¯𝑞𝑞\langle\overline{q}q\rangle⟨ over¯ start_ARG italic_q end_ARG italic_q ⟩, ⟨q¯⁢gs⁢σ⁢G⁢q⟩delimited-⟨⟩¯𝑞subscript𝑔𝑠𝜎𝐺𝑞\langle\overline{q}g_{s}\sigma Gq\rangle⟨ over¯ start_ARG italic_q end_ARG italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_σ italic_G italic_q ⟩, ⟨gs2⁢G2⟩delimited-⟨⟩superscriptsubscript𝑔𝑠2superscript𝐺2\langle g_{s}^{2}G^{2}\rangle⟨ italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⟩, ⟨f3⁢G3⟩delimited-⟨⟩superscript𝑓3superscript𝐺3\langle f^{3}G^{3}\rangle⟨ italic_f start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ⟩ and ⟨q¯⁢q⟩⁢⟨gs2⁢G2⟩delimited-⟨⟩¯𝑞𝑞delimited-⟨⟩superscriptsubscript𝑔𝑠2superscript𝐺2\langle\overline{q}q\rangle\langle g_{s}^{2}G^{2}\rangle⟨ over¯ start_ARG italic_q end_ARG italic_q ⟩ ⟨ italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⟩ are considered. With these results, we also obtain the radiative decay widths of the vector heavy-light mesons and then compare our results with those of other collaboration’s. The final results about the radiative decay widths are Γ⁢(D*0→D0⁢γ)=1.74−0.37+0.40Γ→superscript𝐷absent0superscript𝐷0𝛾subscriptsuperscript1.740.400.37\Gamma(D^{*0}\to D^{0}\gamma)=1.74^{+0.40}_{-0.37}roman_Γ ( italic_D start_POSTSUPERSCRIPT * 0 end_POSTSUPERSCRIPT → italic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_γ ) = 1.74 start_POSTSUPERSCRIPT + 0.40 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.37 end_POSTSUBSCRIPT keV, Γ⁢(D*+→D+⁢γ)=0.17−0.07+0.08Γ→superscript𝐷absentsuperscript𝐷𝛾subscriptsuperscript0.170.080.07\Gamma(D^{*+}\to D^{+}\gamma)=0.17^{+0.08}_{-0.07}roman_Γ ( italic_D start_POSTSUPERSCRIPT * + end_POSTSUPERSCRIPT → italic_D start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_γ ) = 0.17 start_POSTSUPERSCRIPT + 0.08 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.07 end_POSTSUBSCRIPT keV, Γ⁢(Ds*→Ds⁢γ)=0.027−0.026+0.062Γ→superscriptsubscript𝐷𝑠subscript𝐷𝑠𝛾subscriptsuperscript0.0270.0620.026\Gamma(D_{s}^{*}\to D_{s}\gamma)=0.027^{+0.062}_{-0.026}roman_Γ ( italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT → italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_γ ) = 0.027 start_POSTSUPERSCRIPT + 0.062 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.026 end_POSTSUBSCRIPT keV, Γ⁢(B*0→B0⁢γ)=0.018−0.005+0.006Γ→superscript𝐵absent0superscript𝐵0𝛾subscriptsuperscript0.0180.0060.005\Gamma(B^{*0}\to B^{0}\gamma)=0.018^{+0.006}_{-0.005}roman_Γ ( italic_B start_POSTSUPERSCRIPT * 0 end_POSTSUPERSCRIPT → italic_B start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_γ ) = 0.018 start_POSTSUPERSCRIPT + 0.006 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.005 end_POSTSUBSCRIPT keV, Γ⁢(B*+→B+⁢γ)=0.015−0.007+0.007Γ→superscript𝐵absentsuperscript𝐵𝛾subscriptsuperscript0.0150.0070.007\Gamma(B^{*+}\to B^{+}\gamma)=0.015^{+0.007}_{-0.007}roman_Γ ( italic_B start_POSTSUPERSCRIPT * + end_POSTSUPERSCRIPT → italic_B start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_γ ) = 0.015 start_POSTSUPERSCRIPT + 0.007 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.007 end_POSTSUBSCRIPT keV and Γ⁢(Bs*→Bs⁢γ)=0.016−0.004+0.003Γ→subscriptsuperscript𝐵𝑠subscript𝐵𝑠𝛾subscriptsuperscript0.0160.0030.004\Gamma(B^{*}_{s}\to B_{s}\gamma)=0.016^{+0.003}_{-0.004}roman_Γ ( italic_B start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT → italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_γ ) = 0.016 start_POSTSUPERSCRIPT + 0.003 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.004 end_POSTSUBSCRIPT keV.",[],['China']
"Metabolic cybergenetics is a promising concept that interfaces gene expression and cellular metabolism with computers for real-time dynamic metabolic control. The focus is on control at the transcriptional level, serving as a means to modulate intracellular metabolic fluxes. Recent strategies in this field have employed constraint-based dynamic models for process optimization, control, and estimation. However, this results in bilevel dynamic optimization problems, which pose considerable numerical and conceptual challenges. In this study, we present an alternative hybrid physics-informed dynamic modeling framework for metabolic cybergenetics, aimed at simplifying optimization, control, and estimation tasks. By utilizing machine-learning surrogates, our approach effectively embeds the physics of metabolic networks into the process rates of structurally simpler macro-kinetic models coupled with gene expression. These surrogates, informed by flux balance analysis, link the domains of manipulatable intracellular enzymes to metabolic exchange fluxes. This ensures that critical knowledge captured by the system’s metabolic network is preserved. The resulting models can be integrated into metabolic cybergenetic schemes involving single-level optimizations. Additionally, the hybrid modeling approach maintains the number of system states at a necessary minimum, easing the burden of process monitoring and estimation. Our hybrid physics-informed metabolic cybergenetic framework is demonstrated using a computational case study on the optogenetically-assisted production of itaconate by Escherichia coli.",[],[]
,[],[]
"In this paper, we propose an orthogonal block wise Kaczmarz (POBK) algorithm based on preprocessing techniques to solve large-scale sparse linear systems A⁢x=f𝐴𝑥𝑓Ax=fitalic_A italic_x = italic_f. Firstly, the Reverse Cuthill McKee Algorithm (RCM) algorithm is used to preprocess the linear system, and then a new partitioning strategy is proposed to divide orthogonal blocks into one category, in order to accelerate the convergence rate of the Kaczmarz algorithm. The convergence of the POBK algorithm has been theoretically proven, and a theoretical analysis of its faster convergence is also provided. In addition, the experimental results confirm that this algorithm is far superior to GRBK, RBK(k), and GREBK(k) algorithms in both iteration steps (IT) and CPU time aspects.",[],[]
"We prove a large deviation principle for the slow-fast rough differential equations under the controlled rough path framework. The driver rough paths are lifted from the mixed fractional Brownian motion with Hurst parameter H∈(1/3,1/2)𝐻1312H\in(1/3,1/2)italic_H ∈ ( 1 / 3 , 1 / 2 ). Our approach is based on the continuity of the solution mapping and the variational framework for mixed fractional Brownian motion. By utilizing the variational representation, our problem is transformed into a qualitative property of the controlled system. In particular, the fast rough differential equation coincides with Itô SDE almost surely, which possesses a unique invariant probability measure with frozen slow component. We then demonstrate the weak convergence of the controlled slow component by averaging with respect to the invariant measure of the fast equation and exploiting the continuity of the solution mapping.

Keywords.
Rough paths, Slow-fast system, Large deviation principle, Fractional Brownian motion, Weak convergence.
AMS Math Classification.
60F10, 60G15, 60H10.",[],[]
,[],"['Singapore', 'India']"
"Exploring continuous time crystals (CTCs) within the symmetric subspace of spin systems has been a subject of intensive research in recent times. Thus far, the stability of the time-crystal phase outside the symmetric subspace in such spin systems has gone largely unexplored. Here, we investigate the effect of including the asymmetric subspaces on the dynamics of CTCs in a driven dissipative spin model. This results in multistability, and the dynamics becomes dependent on the initial state. Remarkably, this multistability leads to exotic synchronization regimes such as chimera states and cluster synchronization in an ensemble of coupled identical CTCs.",[],"['Japan', 'Switzerland', 'India']"
":Pre-training, which utilizes extensive and varied datasets, is a critical factor in the success of Large Language Models (LLMs) across numerous applications. However, the detailed makeup of these datasets is often not disclosed, leading to concerns about data security and potential misuse. This is particularly relevant when copyrighted material, still under legal protection, is used inappropriately, either intentionally or unintentionally, infringing on the rights of the authors.
In this paper, we introduce a detailed framework designed to detect and assess the presence of content from potentially copyrighted books within the training datasets of LLMs. This framework also provides a confidence estimation for the likelihood of each content sample’s inclusion. To validate our approach, we conduct a series of simulated experiments, the results of which affirm the framework’s effectiveness in identifying and addressing instances of content misuse in LLM training processes. Furthermore, we investigate the presence of recognizable quotes from famous literary works within these datasets. The outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of LLMs, highlighting the need for more transparent and responsible data management practices in this field.",[],"['Singapore', 'Australia', 'China']"
"Let Qi⁢(i=1,2)subscript𝑄𝑖𝑖12Q_{i}(i=1,2)italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_i = 1 , 2 ) be 2⁢g2𝑔2g2 italic_g dimensional quadrics in ℙ2⁢g+1superscriptℙ2𝑔1\mathbb{P}^{2g+1}blackboard_P start_POSTSUPERSCRIPT 2 italic_g + 1 end_POSTSUPERSCRIPT and let Y𝑌Yitalic_Y be the smooth intersection Q1∩Q2subscript𝑄1subscript𝑄2Q_{1}\cap Q_{2}italic_Q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∩ italic_Q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. We associate the linear subspace in Y𝑌Yitalic_Y with vector bundles on the hyperelliptic curve C𝐶Citalic_C of genus g𝑔gitalic_g by the left adjoint functor of Φ:Db⁢(C)→Db⁢(Y):Φ→superscript𝐷𝑏𝐶superscript𝐷𝑏𝑌\Phi:D^{b}(C)\rightarrow D^{b}(Y)roman_Φ : italic_D start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ( italic_C ) → italic_D start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ( italic_Y ). As an application, we give a different proof of the classification of line bundles and stable bundles of rank 2222 on hyperelliptic curves given by Desale and Ramanan. When g=3𝑔3g=3italic_g = 3, we show that the projection functor induces a closed embedding α:Y→S⁢UCs⁢(4,h):𝛼→𝑌𝑆subscriptsuperscript𝑈𝑠𝐶4ℎ\alpha:Y\rightarrow SU^{s}_{C}(4,h)italic_α : italic_Y → italic_S italic_U start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( 4 , italic_h ) into the moduli space of stable bundles on C𝐶Citalic_C of rank 4444 of fixed determinant.","['Derived categories', 'Kuznetsov components', 'intersection of quadrics', 'linear subspaces', 'moduli space of vector bundles']",[]
,[],[]
"Let 𝔤𝔤\mathfrak{g}fraktur_g be a complex finite-dimensional simple Lie algebra and let 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT be the corresponding generalized Takiff algebra. This paper studies the affine variety 𝐟+𝔟l𝐟subscript𝔟𝑙{\bf f}+\mathfrak{b}_{l}bold_f + fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT where 𝐟𝐟{\bf f}bold_f is similar to a principal nilpotent element of 𝔤𝔤\mathfrak{g}fraktur_g and 𝔟lsubscript𝔟𝑙\mathfrak{b}_{l}fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT is a subalgebra corresponding to the Borel subalgebra 𝔟𝔟\mathfrak{b}fraktur_b of 𝔤𝔤\mathfrak{g}fraktur_g. Inspired by Kostant’s work then we deal with two questions. One of them is to construct the Whittaker model for the Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT-invariants of symmetric algebra S⁢(𝔤l)𝑆subscript𝔤𝑙S(\mathfrak{g}_{l})italic_S ( fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) where Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT is the adjoint group of 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT and Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT acts on S⁢(𝔤l)𝑆subscript𝔤𝑙S(\mathfrak{g}_{l})italic_S ( fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) by coadjoint action, and then to classify all nonsingular Whittaker modules over 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT. Another one is to describe the symplectic structure of the manifold Z⊆𝐟+𝔟l𝑍𝐟subscript𝔟𝑙Z\subseteq{\bf f}+\mathfrak{b}_{l}italic_Z ⊆ bold_f + fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT of normalized Jacobi elements. Then the Hamiltonian corresponding to a fundamental invariant provides a class of hyperbolic Toda lattices. In particular, a simplest example describes the state of a dynamical system consisting of a positive mass particle and a negative mass particle.",[],[]
"Several works related to crowdsourcing have been proposed in the direction where the task executers are to perform the tasks within the stipulated
deadlines. Though the deadlines are set, it may be a practical scenario that
majority of the task executers submit the tasks as late as possible. This
situation where the task executers may delay their task submission is termed
as procrastination in behavioural economics. In many applications, these
late submission of tasks may be problematic for task providers. So here, the
participating agents (both task providers and task executers) are articulated
with the procrastination issue. In literature, how to prevent this procrastina-
tion within the deadline is not addressed in crowdsourcing scenario. However,
in a bipartite graph setting one procrastination aware scheduling is proposed
but balanced job (task and job will synonymously be used) distribution in
different slots (also termed as schedules) is not considered there. In this
paper, a procrastination aware scheduling of jobs is proliferated by propos-
ing an (randomized) algorithm in crowdsourcing scenario (also applicable in
mobile and spatial crowdsourcing). Our algorithm ensures that balancing of
jobs in different schedules are maintained. Our scheme is compared with the
existing algorithm through extensive simulation and in terms of balancing
effect, our proposed algorithm outperforms the existing one. Analytically it
is shown that our proposed algorithm maintains the balanced distribution.",[],[]
"This paper proposes a smooth-trajectory estimator for the labelled multi-Bernoulli (LMB) filter by exploiting the special structure of the generalised labelled multi-Bernoulli (GLMB) filter. We devise a simple and intuitive approach to store the best association map when approximating the GLMB random finite set (RFS) to the LMB RFS. In particular, we construct a smooth-trajectory estimator (i.e., an estimator over the entire trajectories of labelled estimates) for the LMB filter based on the history of the best association map and all of the measurements up to the current time. Experimental results under two challenging scenarios demonstrate significant tracking accuracy improvements with negligible additional computational time compared to the conventional LMB filter. The source code is publicly available at https://tinyurl.com/ste-lmb, aimed at promoting advancements in MOT algorithms.","['Labelled multi-Bernoulli filter', 'estimator', 'smoothing', 'STE-LMB', 'RFS.']",[]
"Sequences with low/zero ambiguity zone (LAZ/ZAZ) properties are useful for modern wireless communication and radar systems operating in mobile environments.
This paper first presents a new family of ZAZ sequence sets by generalizing an earlier construction of zero correlation zone (ZCZ) sequences arising from perfect nonlinear functions. We then introduce a second family of ZAZ sequence sets with comb-like spectrum, whereby the local Doppler resilience is ensured by their inherent spectral nulls in the frequency-domain.
Finally, LAZ sequence sets are obtained thanks to its connection with a novel class of mapping functions.
These proposed unimodular ZAZ and LAZ sets are cyclically distinct and asymptotically optimal with respect to the existing theoretical bounds.","['Unimodular sequence', 'low ambiguity zone (LAZ)', 'zero ambiguity zone (ZAZ)', 'comb-like spectrum', 'wireless communication', 'radar system.']",[]
,[],[]
"Space AI has become increasingly important and sometimes even necessary for government, businesses, and society. An active research topic under this mission is integrating federated learning (FL) with satellite communications (SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively train a machine learning model. However, the special communication environment of SatCom leads to a very slow FL training process up to days and weeks. This paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed parameter servers (𝒫⁢𝒮𝒫𝒮\mathcal{PS}caligraphic_P caligraphic_Ss) to enhance satellite visibility, and (2) introduces non-orthogonal multiple access (NOMA) into LEO to enable fast and bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a new communication topology that exploits HAPs to bridge satellites among different orbits to mitigate the Doppler shift, and (4) a new FL model aggregation scheme that optimally balances models between different orbits and shells. Moreover, we (5) derive a closed-form expression of the outage probability for satellites in near and far shells, as well as for the entire system. Our extensive simulations have validated the mathematical analysis and demonstrated the superior performance of NomaFedHAP in achieving fast and efficient FL model convergence with high accuracy as compared to the state-of-the-art.","['Low', 'Earth orbit (LEO)', 'federated', 'Learning', 'high altitude platform (HAP)', 'non-orthogonal multiple', 'Access (NOMA).']",[]
"In the present paper, we investigate some exact cosmological models in Myrzakulov F⁢(R,T)𝐹𝑅𝑇F(R,T)italic_F ( italic_R , italic_T ) gravity theory. We have considered the arbitrary function F⁢(R,T)=R+λ⁢T𝐹𝑅𝑇𝑅𝜆𝑇F(R,T)=R+\lambda Titalic_F ( italic_R , italic_T ) = italic_R + italic_λ italic_T where λ𝜆\lambdaitalic_λ is an arbitrary constant, R,T𝑅𝑇R,Titalic_R , italic_T are respectively, the Ricci-scalar curvature and the torsion. We have solved the field equations in a flat FLRW spacetime manifold for Hubble parameter and using the MCMC analysis, we have estimated the best fit values of model parameters with 1−σ,2−σ,3−σ1𝜎2𝜎3𝜎1-\sigma,2-\sigma,3-\sigma1 - italic_σ , 2 - italic_σ , 3 - italic_σ regions, for two observational datasets like H⁢(z)𝐻𝑧H(z)italic_H ( italic_z ) and Pantheon SNe Ia datasets. Using these best fit values of model parameters, we have done the result analysis and discussion of the model. We have found a transit phase decelerating-accelerating universe model with transition redshifts zt=0.532,0.435subscript𝑧𝑡0.5320.435z_{t}=0.532,0.435italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.532 , 0.435. The effective dark energy equation of state varies as −1≤ωd⁢e≤−0.9931subscript𝜔𝑑𝑒0.993-1\leq\omega_{de}\leq-0.993- 1 ≤ italic_ω start_POSTSUBSCRIPT italic_d italic_e end_POSTSUBSCRIPT ≤ - 0.993 and the present age of the universe is found as t0=13.92,13.65subscript𝑡013.9213.65t_{0}=13.92,13.65italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 13.92 , 13.65 Gyrs, respectively for two datasets.",[],[]
"We estimate the Big Bang nucleosynthesis (BBN) constraint on the majoron-like particle J𝐽Jitalic_J in the mass range between 1⁢MeV1MeV1\,{\rm MeV}1 roman_MeV to 10⁢GeV10GeV10\,{\rm GeV}10 roman_GeV which dominantly decays into the standard model neutrinos.
For a lifetime shorter than 1⁢sec1sec1\,{\rm sec}1 roman_sec, the majoron heats up the background plasma by injecting neutrinos and changes the relation of photon temperature and background neutrino temperature, resulting in a deficit of \ce⁢H4⁢e\cesuperscript𝐻4𝑒\ce{{}^{4}He}start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT italic_H italic_e abundance and an enhancement of deuterium abundance.
When the majoron lifetime is longer than 1⁢sec1sec1\,{\rm sec}1 roman_sec, the injected neutrinos directly convert protons to neutrons, and consequently, the deuterium becomes overabundant.
In both cases, the overabundance of deuterium provides the strongest constraint and it excludes the parameter range where the \ce⁢L7⁢i\cesuperscript𝐿7𝑖\ce{{}^{7}Li}start_FLOATSUPERSCRIPT 7 end_FLOATSUPERSCRIPT italic_L italic_i abundance can be explained.
We also estimate other cosmological constraints and compare them with the BBN bound.",[],[]
"Hypergraphs are a representation of complex systems involving interactions among more than two entities and allow to investigation of higher-order structure and dynamics in real-world complex systems.
Community structure is a common property observed in empirical networks in various domains.
Stochastic block models have been employed to investigate community structure in networks.
Node attribute data, often accompanying network data, has been found to potentially enhance the learning of community structure in dyadic networks.
In this study, we develop a statistical framework that incorporates node attribute data into the learning of community structure in a hypergraph, employing a stochastic block model.
We demonstrate that our model, which we refer to as HyperNEO, enhances the learning of community structure in synthetic and empirical hypergraphs when node attributes are sufficiently associated with the communities.
Furthermore, we found that applying a dimensionality reduction method, UMAP, to the learned representations obtained using stochastic block models, including our model, maps nodes into a two-dimensional vector space while largely preserving community structure in empirical hypergraphs.
We expect that our framework will broaden the investigation and understanding of higher-order community structure in real-world complex systems.",[],['Japan']
"The revolution of natural language processing via large language models has motivated its use in multidisciplinary areas that include social sciences and humanities and more specifically, comparative religion. Sentiment analysis provides a mechanism to study the emotions expressed in text. Recently, sentiment analysis has been used to study and compare translations of the Bhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we use sentiment analysis for studying selected chapters of the Bible. These chapters are known as the Sermon on the Mount. We utilize a pre-trained language model for sentiment analysis by reviewing five translations of the Sermon on the Mount, which include the King James version, the New International Version, the New Revised Standard Version, the Lamsa Version, and the Basic English Version. We provide a chapter-by-chapter and verse-by-verse comparison using sentiment and semantic analysis and review the major sentiments expressed. Our results highlight the varying sentiments across the chapters and verses. We found that the vocabulary of the respective translations is significantly different. We detected different levels of humour, optimism, and empathy in the respective chapters that were used by Jesus to deliver his message.",[],[]
"While large language models (LLMs) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. As a significant aspect of LLM alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of LLMs. To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs’ responses to instructions with various constraints. We construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. Specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. Finally, we automate the entire evaluation process to facilitate further developments. Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time. We provide extensive evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs. We believe this benchmark will facilitate research into improving the controllability of LLMs’ responses to instructions. Our data and code are available at https://github.com/Xt-cyh/CoDI-Eval.",[],[]
,[],[]
"Cancer diagnosis is a well-studied problem in machine learning since early detection of cancer is often the determining factor in prognosis. Supervised deep learning achieves excellent results in cancer image classification, usually through transfer learning. However, these models require large amounts of labelled data and for several types of cancer, large labelled datasets do not exist.
In this paper, we demonstrate that a model pre-trained using a self-supervised learning algorithm known as Barlow Twins can outperform the conventional supervised transfer learning pipeline. We juxtapose two base models: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a self-supervised fashion on ImageNet. Both are subsequently fine tuned on a small labelled skin lesion dataset and evaluated on a large test set.
We achieve a mean test accuracy of 70% for self-supervised transfer in comparison to 66% for supervised transfer. Interestingly, boosting performance further is possible by self-supervised pretraining a second time (on unlabelled skin lesion images) before subsequent fine tuning. This hints at an alternative path to collecting more labelled data in settings where this is challenging - namely just collecting more unlabelled images. Our framework is applicable to cancer image classification models in the low-labelled data regime.",[],[]
"Non-decoupling effects of heavy scalars and vector fields play an important role
in the indirect search of Beyond the Standard Model (BSM) physics at
the LHC.
By exploiting some new differential equations for the 1-PI
amplitudes, we show that such non-decoupling effects are absent
for quite a general class of effective field theories involving dimension six
two-derivatives and dimension eight
four-derivatives operators, once resummation
in certain BSM couplings is taken into account and
some particular regimes of the relevant couplings are considered.",[],['Italy']
"We consider a rational elliptic surface with a relatively minimal fibration. We compute the number of integral sections in the above rational elliptic surface. As an application, we obtain an estimate of polynomial solutions of some equations.",[],['China']
"Semi-Supervised Object Detection (SSOD) has achieved resounding success by leveraging unlabeled data to improve detection performance.
However, in Open Scene Semi-Supervised Object Detection (O-SSOD), unlabeled data may contains unknown objects not observed in the labeled data, which will increase uncertainty in the model’s predictions for known objects.
It is detrimental to the current methods that mainly rely on self-training, as more uncertainty leads to the lower localization and classification precision of pseudo labels.
To this end, we propose Credible Teacher, an end-to-end framework.
Credible Teacher adopts an interactive teaching mechanism using flexible labels to prevent uncertain pseudo labels from misleading the model and gradually reduces its uncertainty through the guidance of other credible pseudo labels.
Empirical results have demonstrated our method effectively restrains the adverse effect caused by O-SSOD and significantly outperforms existing counterparts.",[],[]
"General U⁢(1)𝑈1U(1)italic_U ( 1 ) extension of the Standard Model (SM) is a well motivated beyond the Standard Model(BSM) scenario where three generations of right handed neutrinos (RHNs) are introduced to cancel gauge and mixed gauge-gravity anomalies. After the U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT is broken, RHNs participate in the seesaw mechanism to generate light neutrino masses satisfying neutrino oscillation data. In addition to that, a neutral gauge boson Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is evolved which interacts with the left and right handed fermions differently manifesting chiral nature of the model which could be probed in future collider experiments. As a result, if we consider μ+⁢e−superscript𝜇superscript𝑒\mu^{+}e^{-}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and μ+⁢μ+superscript𝜇superscript𝜇\mu^{+}\mu^{+}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT collisions in μ𝜇\muitalic_μTRISTAN experiment Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT mediated 2→2→222\to 22 → 2 scattering will appear in t−limit-from𝑡t-italic_t - and u−limit-from𝑢u-italic_u -channels depending on the initial and final states being accompanied by the photon and Z𝑍Zitalic_Z mediated interactions. This will result well motivated resulting forward dominant scenarios giving rise to sizable left-right asymmetry. Estimating constrains on general U⁢(1)𝑈1U(1)italic_U ( 1 ) coupling from LEP-II and LHC for different U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT charges, we calculate differential and integrated scattering cross section and left-right asymmetry for μ+⁢e−→μ+⁢e−→superscript𝜇superscript𝑒superscript𝜇superscript𝑒\mu^{+}e^{-}\to\mu^{+}e^{-}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT → italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and μ+⁢μ+→μ+⁢μ+→superscript𝜇superscript𝜇superscript𝜇superscript𝜇\mu^{+}\mu^{+}\to\mu^{+}\mu^{+}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT → italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT processes which could be probed at μ𝜇\muitalic_μTRISTAN experiment further enlightening the interaction between Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and charged leptons and the U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT breaking scale.",[],['Japan']
"The chemical compositions of stars encode the history of the universe
and are thus fundamental for advancing our knowledge of astrophysics and cosmology.
However, measurements of elemental abundances ratios, and our interpretations of them, strongly depend on the physical assumptions that dictate the generation of synthetic stellar spectra. Three-dimensional radiation-hydrodynamic (3D RHD) “box-in-a-star” simulations of stellar atmospheres offer a more realistic representation of surface convection occurring in late-type stars compared to traditional one-dimensional (1D) hydrostatic models. As evident from a multitude of observational tests, the coupling of 3D RHD models with line-formation in non-local thermodynamic equilibrium (non-LTE) today provides a solid foundation for abundance analysis for many elements. This review describes the ongoing and transformational work to advance the state-of-the-art and replace 1D LTE spectrum synthesis with its 3D non-LTE counterpart. In summary: 




•

3D and non-LTE effects are intricately coupled and consistent modelling thereof is necessary for high-precision abundances, which is currently feasible for individual elements in large surveys. Mean 3D (⟨⁢3⁢D⁢⟩⟨3D⟩\rm\textlangle 3D\textrangle{}⟨ 3 roman_D ⟩) models are not adequate as substitutes.

•

The solar abundance debate is presently dominated by choices and systematic uncertainties that are not specific to 3D non-LTE modelling.

•

3D non-LTE abundance corrections have a profound impact on our understanding of FGK-type stars, exoplanets, and the nucleosynthetic origins of the elements.",[],[]
,[],[]
"Quantum walks have emerged as a transformative paradigm in quantum information processing and can be applied to various graph problems. This study explores discrete-time quantum walks on simplicial complexes, a higher-order generalization of graph structures. Simplicial complexes, encoding higher-order interactions through simplices, offer a richer topological representation of complex systems. Leveraging algebraic topology and discrete-time quantum walk, we present a quantum walk algorithm for detecting higher-order community structures called simplicial communities. We utilize the Fourier coin to produce entangled translation states among adjacent simplices in a simplicial complex. The potential of our quantum algorithm is tested on Zachary’s karate club network. This study may contribute to understanding complex systems at the intersection of algebraic topology and quantum algorithms.",[],[]
,[],[]
"In recent years, text-to-video retrieval methods based on CLIP have experienced rapid development. The primary direction of evolution is to exploit the much wider gamut of visual and textual cues to achieve alignment. Concretely, those methods with impressive performance often design a heavy fusion block for sentence (words)-video (frames) interaction, regardless of the prohibitive computation complexity. Nevertheless, these approaches are not optimal in terms of feature utilization and retrieval efficiency.
To address this issue, we adopt multi-granularity visual feature learning, ensuring the model’s comprehensiveness in capturing visual content features spanning from abstract to detailed levels during the training phase. To better leverage the multi-granularity features, we devise a two-stage retrieval architecture in the retrieval phase. This solution ingeniously balances the coarse and fine granularity of retrieval content. Moreover, it also strikes a harmonious equilibrium between retrieval effectiveness and efficiency.
Specifically, in training phase, we design a parameter-free text-gated interaction block (TIB) for fine-grained video representation learning and embed an extra Pearson Constraint to optimize cross-modal representation learning. In retrieval phase, we use coarse-grained video representations for fast recall of top-k candidates, which are then reranked by fine-grained video representations.
Extensive experiments on four benchmarks demonstrate the efficiency and effectiveness. Notably, our method achieves comparable performance with the current state-of-the-art methods while being nearly 50 times faster.",[],[]
"In this paper, a viscous shock wave under space-periodic perturbation
of 1-D isentropic Navier-Stokes system in the half space is investigated. It is shown that if the initial
periodic perturbation around the viscous shock wave is small, then the solution time
asymptotically tends to a viscous shock wave with a shift partially determined by the
periodic oscillations. Moreover, the strength of the shock wave could be arbitrarily large. This result essentially improves the previous work ”A. Matsumura, M. Mei, Convergence to travelling fronts of solutions of the p-system with viscosity in the presence of a boundary. Arch. Ration. Mech. Anal. 146 (1999), no. 1, 1-22.” where the strength of shock wave is sufficiently small and the initial periodic oscillations vanish.","['Impermeable wall problem', 'Large amplitude shock', 'Space-periodic perturbation', 'Asymptotic stability']",[]
"Black hole solutions of general relativity exhibit a symmetry for the static perturbations around these spacetimes, known as “ladder symmetry”. This symmetry proves useful in constructing a tower of solutions for perturbations and elucidating their general properties. Specifically, the presence of this symmetry leads to vanishing of the tidal love number associated with black holes. In this work, we find the most general spherical symmetric and static black hole spacetime that accommodates this ladder symmetry for scalar perturbation. Furthermore, we extend our calculations beyond spherical symmetry to find the class of stationary Konoplya-Rezzola-Zhidenko black holes, which also possess a similar ladder structure.",[],['India']
,[],[]
"Let G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ) be a connected graph and dG⁢(u,v)subscript𝑑𝐺𝑢𝑣d_{G}(u,v)italic_d start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_u , italic_v ) be the shortest distance between the vertices u𝑢uitalic_u and v𝑣vitalic_v in G𝐺Gitalic_G. A set S={s1,s2,…,sn}⊂V⁢(G)𝑆subscript𝑠1subscript𝑠2…subscript𝑠𝑛𝑉𝐺S=\{s_{1},s_{2},\ldots,s_{n}\}\subset V(G)italic_S = { italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ⊂ italic_V ( italic_G ) is said to be a resolving set if for all distinct vertices u,v𝑢𝑣u,vitalic_u , italic_v of G𝐺Gitalic_G, there exist an element s∈S𝑠𝑆s\in Sitalic_s ∈ italic_S such that d⁢(s,u)≠d⁢(s,v)𝑑𝑠𝑢𝑑𝑠𝑣d(s,u)\neq d(s,v)italic_d ( italic_s , italic_u ) ≠ italic_d ( italic_s , italic_v ). The minimum cardinality of a resolving set for a graph G𝐺Gitalic_G is called the metric dimension of G𝐺Gitalic_G and it is denoted by β⁢(G)𝛽𝐺\beta{(G)}italic_β ( italic_G ). A resolving set having β⁢(G)𝛽𝐺\beta{(G)}italic_β ( italic_G ) number of vertices is named as metric basis of G𝐺Gitalic_G. The metric dimension problem is to find a metric basis in a graph G𝐺Gitalic_G, and it has several real-life applications in network theory, telecommunication,
image processing, pattern recognition, and many other fields. In this article, we
consider cube of trees T3=(V,E)superscript𝑇3𝑉𝐸T^{3}=(V,E)italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT = ( italic_V , italic_E ), where any two vertices u,v𝑢𝑣u,vitalic_u , italic_v are adjacent if and only if the distance between them is less than equal to three in T𝑇Titalic_T.
We establish the necessary and sufficient conditions of a vertex subset of V𝑉Vitalic_V to become a resolving set for T3superscript𝑇3T^{3}italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. This helps determine the tight bounds (upper and lower) for the metric dimension of T3superscript𝑇3T^{3}italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Then, for certain well-known cubes of trees, such as caterpillars, lobsters, spiders, and d𝑑ditalic_d-regular trees, we establish the boundaries of the metric dimension. Further, we characterize some restricted families of cube of trees satisfying
β⁢(T3)=β⁢(T)𝛽superscript𝑇3𝛽𝑇\beta{(T^{3})}=\beta{(T)}italic_β ( italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) = italic_β ( italic_T ). We provide a construction showing the existence of a cube of tree attaining every positive integer value as their metric dimension.",[],[]
,[],[]
"We implement a test of MOND and Verlinde’s Emergent Gravity using the galaxy cluster SMACS J0723-7327, which has been recently imaged using the eROSITA X-ray telescope as well as with JWST. We test MOND using two independent methods. The first method involves comparing the dynamical MOND mass and baryonic mass, while the second method entails a comparison of the MOND-estimated temperature with the observed temperature. We then compare the unseen mass predicted by Emergent Gravity with the estimated dark matter mass. We find that MOND is able to explain the mass discrepancy at large radii but not in the central regions. The observed temperature profile is also in slight disagreement with that in the MOND paradigm. Likewise the Emergent Gravity Theory shows a marginal discrepancy in accurately accounting for the dynamical mass in the inner regions. Our results are qualitatively consistent with the earlier tests on other clusters.",[],['India']
"Nonlocal self-similarity (NSS) is an important prior that has been successfully applied in multi-dimensional data processing tasks, e.g., image and video recovery. However, existing NSS-based methods are solely suitable for meshgrid data such as images and videos, but are not suitable for emerging off-meshgrid data, e.g., point cloud and climate data. In this work, we revisit the NSS from the continuous representation perspective and propose a novel Continuous Representation-based NonLocal method (termed as CRNL), which has two innovative features as compared with classical nonlocal methods. First, based on the continuous representation, our CRNL unifies the measure of self-similarity for on-meshgrid and off-meshgrid data and thus is naturally suitable for both of them. Second, the nonlocal continuous groups can be more compactly and efficiently represented by the coupled low-rank function factorization, which simultaneously exploits the similarity within each group and across different groups, while classical nonlocal methods neglect the similarity across groups. This elaborately designed coupled mechanism allows our method to enjoy favorable performance over conventional NSS methods in terms of both effectiveness and efficiency. Extensive multi-dimensional data processing experiments on-meshgrid (e.g., image inpainting and image denoising) and off-meshgrid (e.g., climate data prediction and point cloud recovery) validate the versatility, effectiveness, and efficiency of our CRNL as compared with state-of-the-art methods.","['Nonlocal self-similarity', 'low-rank model', 'tensor', 'Tucker factorization\nimage restoration', 'multivariate regression.']",[]
"The aim of this article is to study the Clairaut anti-invariant Riemannian maps from/to Kähler manifolds admitting Ricci solitons. We find the curvature relations and calculate the Ricci tensor under different conditions. We obtain conditions for the range and kernel of these maps to be Einstein. Next, we find the scalar curvature for range. Finally, we give some non-trivial examples of Clairaut anti-invariant Riemannian maps from/to Kähler manifolds admitting Ricci solitons.",[],[]
"Integer sorting is a fundamental problem in computer science.
This paper studies parallel integer sort both in theory and in practice.
In theory, we show tighter bounds for a class of
existing practical integer sort algorithms, which provides a solid
theoretical foundation for their widespread usage
in practice and strong performance.
In practice, we design a new integer sorting algorithm,
DovetailSort, that is theoretically-efficient and has good practical performance.
In particular, DovetailSort overcomes a common challenge in existing
parallel integer sorting algorithms, which is the difficulty of detecting and
taking advantage of duplicate keys.
The key insight in DovetailSort is to combine algorithmic ideas from
both integer- and comparison-sorting algorithms.
In our experiments, DovetailSort achieves competitive or better
performance than existing state-of-the-art parallel integer and
comparison sorting algorithms on various synthetic and real-world
datasets.","['Integer', 'Sort', 'Radix', 'Sort', 'Sorting', 'Algorithms', 'Parallel', 'Algorithms']",[]
"Generating 3D human models directly from text helps reduce the cost and time of character modeling.
However, achieving multi-attribute controllable and realistic 3D human avatar generation is still challenging due to feature coupling and the scarcity of realistic 3D human avatar datasets.
To address these issues, we propose Text2Avatar, which can generate realistic-style 3D avatars based on the coupled text prompts.
Text2Avatar leverages a discrete codebook as an intermediate feature to establish a connection between text and avatars, enabling the disentanglement of features.
Furthermore, to alleviate the scarcity of realistic style 3D human avatar data, we utilize a pre-trained unconditional 3D human avatar generation model to obtain a large amount of 3D avatar pseudo data, which allows Text2Avatar to achieve realistic style generation.
Experimental results demonstrate that our method can generate realistic 3D avatars from coupled textual data, which is challenging for other existing methods in this field.",[],[]
"In planar superconductor thin films, the places of nucleation and arrangements of moving vortices are determined by structural defects. However, various applications of superconductors require reconfigurable steering of fluxons, which is hard to realize with geometrically predefined vortex pinning landscapes. Here, on the basis of the time-dependent Ginzburg-Landau equation, we present an approach for steering of vortex chains and vortex jets in superconductor nanotubes containing a slit. The idea is based on tilting of the magnetic field 𝐁𝐁\mathbf{B}bold_B at an angle α𝛼\alphaitalic_α in the plane perpendicular to the axis of a nanotube carrying an azimuthal transport current. Namely, while at α=0∘𝛼superscript0\alpha=0^{\circ}italic_α = 0 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT vortices move paraxially in opposite directions within each half-tube, an increase of α𝛼\alphaitalic_α displaces the areas with the close-to-maximum normal component |Bn|subscript𝐵n|B_{\mathrm{n}}|| italic_B start_POSTSUBSCRIPT roman_n end_POSTSUBSCRIPT | to the close(opposite)-to-slit regions, giving rise to descending (ascending) branches in the induced-voltage frequency spectrum fU⁢(α)subscript𝑓U𝛼f_{\mathrm{U}}(\alpha)italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT ( italic_α ). At lower B𝐵Bitalic_B, upon reaching the critical angle αcsubscript𝛼c\alpha_{\mathrm{c}}italic_α start_POSTSUBSCRIPT roman_c end_POSTSUBSCRIPT, close-to-slit vortex chains disappear, yielding fUsubscript𝑓Uf_{\mathrm{U}}italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT of the n⁢f1𝑛subscript𝑓1nf_{1}italic_n italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-type (n≥1𝑛1n\geq 1italic_n ≥ 1: an integer; f1subscript𝑓1f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: vortex nucleation frequency). At higher B𝐵Bitalic_B, fUsubscript𝑓Uf_{\mathrm{U}}italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT is largely blurry because of multifurcations of vortex trajectories, leading to the coexistence of a vortex jet with two vortex chains at α=90∘𝛼superscript90\alpha=90^{\circ}italic_α = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT. In addition to prospects for tuning of GHz-frequency spectra and steering of vortices as information bits, our findings lay foundations for on-demand tuning of vortex arrangements in 3D superconductor membranes in tilted magnetic fields.",[],"['Germany', 'Austria']"
"Intelligent Transportation System (ITS) is vital in improving traffic congestion, reducing traffic accidents, optimizing urban planning, etc.
However, due to the complexity of the traffic network, traditional machine learning and statistical methods are relegated to the background.
With the advent of the artificial intelligence era, many deep learning frameworks have made remarkable progress in various fields and are now considered effective methods in many areas.
As a deep learning method, Graph Neural Networks (GNNs) have emerged as a highly competitive method in the ITS field since 2019 due to their strong ability to model graph-related problems. As a result, more and more scholars pay attention to the applications of GNNs in transportation domains, which have shown excellent performance.
However, most of the research in this area is still concentrated on traffic forecasting, while other ITS domains, such as autonomous vehicles and urban planning, still require more attention.
This paper aims to review the applications of GNNs in six representative and emerging ITS domains: traffic forecasting, autonomous vehicles, traffic signal control, transportation safety, demand prediction, and parking management. We have reviewed extensive graph-related studies from 2018 to 2023, summarized their methods, features, and contributions, and presented them in informative tables or lists.
Finally, we have identified the challenges of applying GNNs to ITS and suggested potential future directions.","['Traffic', 'Flow', 'Prediction', 'Graph', 'Neural', 'Network', 'Spatio-temporal', 'Analysis']",['China']
"Magnetization dynamics in magnetic materials are well described by the modified semiclassical Landau-Lifshitz-Gilbert (LLG) equation, which includes the magnetic damping 𝜶^^𝜶\hat{\bm{\alpha}}over^ start_ARG bold_italic_α end_ARG and the magnetic moment of inertia 𝐈^^𝐈\hat{\bm{\mathrm{I}}}over^ start_ARG bold_I end_ARG tensors as key parameters. Both parameters are material-specific and physically represent the time scales of damping of precession and nutation in magnetization dynamics. 𝜶^^𝜶\hat{\bm{\alpha}}over^ start_ARG bold_italic_α end_ARG and 𝐈^^𝐈\hat{\bm{\mathrm{I}}}over^ start_ARG bold_I end_ARG can be calculated quantum mechanically within the framework of the torque-torque correlation model. The quantities required for the calculation are torque matrix elements, the real and imaginary parts of the Green’s function and its derivatives. Here, we calculate these parameters for the elemental magnets such as Fe, Co and Ni in an ab initio framework using density functional theory and Wannier functions. We also propose a method to calculate the torque matrix elements within the Wannier framework. We demonstrate the effectiveness of the method by comparing it with the experiments and the previous ab initio and empirical studies and show its potential to improve our understanding of spin dynamics and to facilitate the design of spintronic devices.",[],['India']
"Context:
For decades, the spectral variations of β𝛽\beta\>italic_βPictoris have been modelled as the result of the evaporation of
exocomets close to the star, termed falling evaporating bodies (FEBs). Resonant perturbations by a
hypothetical giant planet have been proposed to explain the dynamical origin of these stargrazers. The disk is
now known to harbour two giant planets, β𝛽\beta\>italic_βPic b and c, orbiting the star at 9.9 au and 2.7 au. While the former almost matches the planet formerly suspected, the recent discovery of the latter complicates the picture.
Aims:We first question the stability of the two-planet system. Then we investigate the dynamics of a disk of
planetesimals orbiting the star together with both planets to check the validity of the FEB generation mechanism.
Methods:Symplectic N-body simulations are used to first determine which regions of the planetesimal disk are dynamically stable and which are not. Then we focus on regions where disk particles are able to reach high eccentricities, mainly thanks to resonant mechanisms.
Results:The first result is that the system is dynamically stable. Both planets may temporarily fall in 7:1 mean motion
resonance (MMR). Then, simulations with a disk of particles reveal that the whole region extending between
∼1.5similar-toabsent1.5\sim 1.5\,∼ 1.5au and ∼25similar-toabsent25\sim 25\,∼ 25au is unstable to planetary perturbations. However, a disk below 1.5 au survives, which
appears to constitute an active source of FEBs via high-order MMRs with β𝛽\beta\>italic_βPic c. In this new picture, β𝛽\beta\>italic_βPic b acts as a distant perturber that helps sustain the whole process.
Conclusions:Our new simulations rule out the preceding FEB generation mechanism model, which placed their origin
at around 4–5 au. Conversely, FEBs are likely to originate from a region much further in and related to MMRs with β𝛽\beta\>italic_βPic c. That mechanism also appears to last longer, as new planetesimals are able to continuously enter the MMRs and evolve towards the FEB state. Subsequently, the physical nature of the FEBs may differ from that previously thought, and presumably may not be icy.","['Stars: circumstellar matter –', 'Stars: planetary systems –', 'Stars individual: β𝛽\\beta\\>italic_βPic–', 'Methods: numerical –', 'Celestial mechanics –', 'Planets and satellites: dynamical evolution and stability']",[]
"A placement of chess pieces on a chessboard is called dominating, if each
free square of the chessboard is under attack by at least one
piece. In this contribution we compute the number of dominating
arrangements of k𝑘kitalic_k rooks on an n×m𝑛𝑚n\times mitalic_n × italic_m chessboard. To this end we derive an
expression for the corresponding generating function, the
domination polynomial of the n×m𝑛𝑚n\times mitalic_n × italic_m rook graph.",[],[]
,[],[]
"With the increasing availability of consumer depth sensors, 3D face recognition (FR)
has attracted more and more attention. However, the data acquired by these sensors
are often coarse and noisy, making them impractical to use directly.
In this paper, we introduce an innovative Depth map denoising network (DMDNet) based on
the Denoising Implicit Image Function (DIIF) to reduce noise and enhance
the quality of facial depth images for low-quality 3D FR.
After generating clean depth faces using DMDNet,
we further design a powerful recognition network
called Lightweight Depth and Normal Fusion network (LDNFNet),
which incorporates a multi-branch fusion block to learn unique and complementary
features between different modalities such as depth and normal images.
Comprehensive experiments conducted on four distinct low-quality databases demonstrate the
effectiveness and robustness of our proposed methods.
Furthermore, when combining DMDNet and LDNFNet, we achieve state-of-the-art results on
the Lock3DFace database.",[],[]
"In this paper, we obtain an improved upper bound involving the systole and area for the volume entropy of a Riemannian surface. As a result, we show that every orientable and closed Riemannian surface of genus g≥17𝑔17g\geq 17italic_g ≥ 17 satisfies Loewner’s systolic ratio inequality.
Keywords: Systole; Loewner’s inequality; entropy.
MSC2020: 53C23, 37C35.",[],[]
"We present a summary of the full calculation of the axial, scalar and tensor flavor diagonal charges of the nucleon carried out using Wilson-clover fermions on eight ensembles generated using 2+1+1-flavors of highly improved staggered quarks (HISQ) by the MILC collaboration. We also give results for the 3×3333\times 33 × 3 matrix of renormalization factors between the RI-sMOM and MS¯¯MS\overline{\rm MS}over¯ start_ARG roman_MS end_ARG scheme for the 2+1 flavor theory that include flavor mixing. Preliminary results for gA,S,Tu,d,ssuperscriptsubscript𝑔𝐴𝑆𝑇𝑢𝑑𝑠g_{A,S,T}^{u,d,s}italic_g start_POSTSUBSCRIPT italic_A , italic_S , italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u , italic_d , italic_s end_POSTSUPERSCRIPT are presented in the MS¯¯MS\overline{\rm MS}over¯ start_ARG roman_MS end_ARG scheme at scale 2 GeV.",[],[]
"Accurate medical image segmentation is essential for clinical quantification, disease diagnosis, treatment planning and many other applications. Both convolution-based and transformer-based u-shaped architectures have made significant success in various medical image segmentation tasks. The former can efficiently learn local information of images while requiring much more image-specific inductive biases inherent to convolution operation. The latter can effectively capture long-range dependency at different feature scales using self-attention, whereas it typically encounters the challenges of quadratic compute and memory requirements with sequence length increasing. To address this problem, through integrating the merits of these two paradigms in a well-designed u-shaped architecture, we propose a hybrid yet effective CNN-Transformer network, named BRAU-Net++, for an accurate medical image segmentation task. Specifically, BRAU-Net++ uses bi-level routing attention as the core building block to design our u-shaped encoder-decoder structure, in which both encoder and decoder are hierarchically constructed, so as to learn global semantic information while reducing computational complexity. Furthermore, this network restructures skip connection by incorporating channel-spatial attention which adopts convolution operations, aiming to minimize local spatial information loss and amplify global dimension-interaction of multi-scale features. Extensive experiments on three public benchmark datasets demonstrate that our proposed approach surpasses other state-of-the-art methods including its baseline: BRAU-Net under almost all evaluation metrics. We achieve the average Dice-Similarity Coefficient (DSC) of 82.47, 90.10, and 92.94 on Synapse multi-organ segmentation, ISIC-2018 Challenge, and CVC-ClinicDB, as well as the mIoU of 84.01 and 88.17 on ISIC-2018 Challenge and CVC-ClinicDB, respectively. The codes will be available on GitHub.",[],[]
,[],[]
"We showed with J. P. Gollin that if a (possibly infinite) homogeneous linear equation system has only the trivial solution, then there exists
an injective function from the variables to the equations such that each variable has non-zero coefficient in its image. Shortly after a more
elementary proof was found by Aharoni and Guo. In this note we present a very short matroid-theoretic proof which we believe is the simplest
possible proof of this theorem.",[],[]
"We investigate the impact of different connectivities on the decoherence time in quantum systems under quasi-static Heisenberg noise. We considered three types of fundamental units, including node, stick and triangle and connect them into rings, chains, and trees. We find that rings exhibit greater stability compared to chains, contrary to the expectation that higher average connectivity leads to decreased stability. Additionally, the “stick” configuration is more stable than the “triangle” configuration. We also observe similar trends in entanglement entropy and return probability, indicating their potential use in characterizing decoherence time. Our findings provide insights into the interplay between connectivity and stability in quantum systems, with implications for the design of robust quantum technologies and quantum error correction strategies.",[],['China']
,[],[]
"We have analyzed Chandra and Suzaku observations of the globular cluster Terzan 6,
made when the recurrent transient GRS 1747–312 was in quiescence. Our analysis reveals the presence of a second eclipsing, bursting neutron-star low-mass X-ray binary in the central regions of the cluster, in addition to GRS 1747–312. The new source, which we name Terzan 6 X2, is located very close to GRS 1747–312 (∼similar-to\sim∼0.7″ away) in the 2021 Chandra images. The detection of a 5.14 ks-long eclipse in the light curve of X2 at a time not predicted by the ephemeris of GRS 1747–312 confirms that it is an unrelated source. Using the Suzaku light curve from 2009, which in addition to a type-I X-ray burst also showed an eclipse-like feature, we constrain the orbital period to be longer than 16.27 h. The 0.5–10 keV luminosities of X2 vary in the range of ∼similar-to\sim∼0.24–5.9×1034absentsuperscript1034\times 10^{34}× 10 start_POSTSUPERSCRIPT 34 end_POSTSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT on time scales of months to years.
We have identified a plausible optical counterpart of X2 in HST F606W and F814W images. This star varied by 2.7 mag in V606subscript𝑉606V_{\rm 606}italic_V start_POSTSUBSCRIPT 606 end_POSTSUBSCRIPT between epochs separated by years. In the cluster color-magnitude diagram, the variable counterpart lies in the blue-straggler region when it was optically bright, about 1.1–1.7 mag above the main-sequence turn-off. From the orbital period–density relation of Roche-lobe filling stars we find the mass-donor radius to be ≳0.8greater-than-or-equivalent-toabsent0.8\gtrsim 0.8≳ 0.8 R⊙subscript𝑅direct-productR_{\odot}italic_R start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.",[],"['Australia', 'Netherlands', 'Canada']"
"Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary diseases. However, manual interpretation of these images is time-consuming and error-prone. Automated systems utilizing convolutional neural networks (CNNs) have shown promise in improving the accuracy and efficiency of chest X-ray image classification. While previous work has mainly focused on using feature maps from the final convolution layer, there is a need to explore the benefits of leveraging additional layers for improved disease classification. Extracting robust features from limited medical image datasets remains a critical challenge. In this paper, we propose a novel deep learning-based multilayer multimodal fusion model that emphasizes extracting features from different layers and fusing them. Our disease detection model considers the discriminatory information captured by each layer. Furthermore, we propose the fusion of different-sized feature maps (FDSFM) module to effectively merge feature maps from diverse layers. The proposed model achieves a significantly higher accuracy of 97.21% and 99.60% for both three-class and two-class classifications, respectively. The proposed multilayer multimodal fusion model, along with the FDSFM module, holds promise for accurate disease classification and can also be extended to other disease classifications in chest X-ray images.",[],[]
"Existing deep-learning-based methods for nighttime video deraining rely on synthetic data due to the absence of real-world paired data. However, the intricacies of the real world, particularly with the presence of light effects and low-light regions affected by noise, create significant domain gaps, hampering synthetic-trained models in removing rain streaks properly and leading to over-saturation and color shifts. Motivated by this, we introduce NightRain, a novel nighttime video deraining method with adaptive-rain-removal and adaptive-correction. Our adaptive-rain-removal uses unlabeled rain videos to enable our model to derain real-world rain videos, particularly in regions affected by complex light effects. The idea is to allow our model to obtain rain-free regions based on the confidence scores. Once rain-free regions and the corresponding regions from our input are obtained, we can have region-based paired real data. These paired data are used to train our model using a teacher-student framework, allowing the model to iteratively learn from less challenging regions to more challenging regions. Our adaptive-correction aims to rectify errors in our model’s predictions, such as over-saturation and color shifts. The idea is to learn from clear night input training videos based on the differences or distance between those input videos and their corresponding predictions. Our model learns from these differences, compelling our model to correct the errors. From extensive experiments, our method demonstrates state-of-the-art performance. It achieves a PSNR of 26.73dB, surpassing existing nighttime video deraining methods by a substantial margin of 13.7%.",[],[]
"The perfectly matched layers method is a well known truncation technique for its efficiency and convenience in numerical implementations of wave scattering problems in unbounded domains. In this paper, we study the convergence of the perfectly matched layers (PML) for wave scattering from a local perturbation of an open waveguide in ℝ+2subscriptsuperscriptℝ2\mathbb{R}^{2}_{+}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, where the refractive index is a function which is periodic along the axis of the waveguide and equals to one above a finite height. The problem is challenging due to the existence of guided waves, and a typical way to deal with the difficulty is to apply the limiting absorption principle. Based on the Floquet-Bloch transform and a curve deformation theory, the solution from the limiting absorption principle is rewritten as the integral of a coupled family of quasi-periodic problems with respect to the quasi-periodicity parameter on a particularly designed curve. By comparing the Dirichlet-to-Neumann maps on a straight line above the locally perturbed periodic layer, we finally show that the PML method converges exponentially with respect to the PML parameter. Finally, the numerical examples are shown to illustrate the theoretical results.",[],[]
,[],[]
"In this work the effect of anisotropy on computational complexity is considered by CA proposal in holographic two-sided black brane dual of a strongly coupled gauge theory. It is shown that due to confinement-deconfinement phase transition there are two different behaviors: by increase in anisotropy there would be an increase in complexity growth rate in small anisotropy and a decreases in the complexity growth rate in large anisotropy. In the extreme case the very large anisotropy leads to the unity of the complexity growth rate and complexity itself, it means that in this case getting the target state from the reference state is reachable by no effort. Moreover, we suggest that 1M⁢d⁢Cd⁢t1𝑀𝑑𝐶𝑑𝑡\frac{1}{M}\frac{dC}{dt}divide start_ARG 1 end_ARG start_ARG italic_M end_ARG divide start_ARG italic_d italic_C end_ARG start_ARG italic_d italic_t end_ARG is a better representation of system degrees of freedom rather than the complexity growth rate d⁢Cd⁢t𝑑𝐶𝑑𝑡\frac{dC}{dt}divide start_ARG italic_d italic_C end_ARG start_ARG italic_d italic_t end_ARG and show that how it is related to inverse anisotropic catalysis. In addition, we consider the one-sided black brane dual to the quantum quench and showed that increase in anisotropy comes with decrease in complexity regardless of the anisotropy value which is due to the fact that the system do not experience a phase transition.",[],[]
"The distributional analysis of Euclidean algorithms was carried out by Baladi and Vallée.
They showed the asymptotic normality of the number of division steps and associated costs in the Euclidean algorithm as a random variable on the set of rational numbers with bounded denominator based on the transfer operator methods. We extend their result to the Euclidean algorithm over appropriate imaginary quadratic fields by studying dynamics of the nearest integer complex continued fraction map, which is piecewise analytic and expanding but not a full branch map. By observing a finite Markov partition with a regular CW-structure, which enables us to associate the transfer operator acting on a direct sum of spaces of C1superscript𝐶1C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT-functions, we obtain the limit Gaussian distribution as well as residual equidistribution.",[],[]
"The structure of a network has a major effect on dynamical processes on that network. Many studies of the interplay between network structure and dynamics have focused on models of phenomena such as disease spread, opinion formation and changes, coupled oscillators, and random walks. In parallel to these developments, there have been many studies of wave propagation and other spatially extended processes on networks. These latter studies consider metric networks, in which the edges are associated with real intervals. Metric networks give a mathematical framework to describe dynamical processes that include both temporal and spatial evolution of some quantity of interest — such as the concentration of a diffusing substance or the amplitude of a wave — by using edge-specific intervals that quantify distance information between nodes. Dynamical processes on metric networks often take the form of partial differential equations (PDEs). In this paper, we present a collection of techniques and paradigmatic linear PDEs that are useful to investigate the interplay between structure and dynamics in metric networks. We start by considering a time-independent Schrödinger equation. We then use both finite-difference and spectral approaches to study the Poisson, heat, and wave equations as paradigmatic examples of elliptic, parabolic, and hyperbolic PDE problems on metric networks. Our spectral approach is able to account for degenerate eigenmodes. In our numerical experiments, we consider metric networks with up to about 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT nodes and about 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT edges. A key contribution of our paper is to increase the accessibility of studying PDEs on metric networks. Software that implements our numerical approaches is available at https://gitlab.com/ComputationalScience/metric-networks.",[],[]
"Diffusion Models (DMs) represent a significant advancement in image Super-Resolution (SR), aligning technical image quality more closely with human preferences and expanding SR applications.
DMs address critical limitations of previous methods, enhancing overall realism and details in SR images.
However, DMs suffer from color-shifting issues, and their high computational costs call for efficient sampling alternatives, underscoring the challenge of balancing computational efficiency and image quality.
This survey gives an overview of DMs applied to image SR and offers a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field.
It presents a unified view of DM fundamentals and explores research directions, including alternative input domains, conditioning strategies, guidance, corruption spaces, and zero-shot methods.
This survey provides insights into the evolution of image SR with DMs, addressing current trends, challenges, and future directions in this rapidly evolving field.","['Diffusion', 'Models', 'Image', 'Super-Resolution', 'Artificial', 'Intelligence', 'Survey.']",[]
"String matching algorithms in the presence of abbreviations, such as in Stock Keeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In this paper, we present a unified architecture for SKU search that provides both a real-time suggestion system (based on a Trie data structure) as well as a lower latency search system (making use of character level TF-IDF in combination with language model vector embeddings) where users initiate the search process explicitly. We carry out ablation studies that justify designing a complex search system composed of multiple components to address the delicate trade-off between speed and accuracy. Using SKU search in the Dynamics CRM as an example, we show how our system vastly outperforms, in all aspects, the results provided by the default search engine. Finally, we show how SKU descriptions may be enhanced via generative text models (using gpt-3.5-turbo) so that the consumers of the search results may get more context and a generally better experience when presented with the results of their SKU search.
Keywords: String matching ; Data structures ; Large Language Models ; Search Engine Architecture",[],[]
"The hadro-chemistry of bottom quarks produced in hadronic collisions encodes valuable information on the mechanism of color-neutralization in these reactions. We first compute the chemistry of bottom-hadrons in high-energy p⁢p𝑝𝑝ppitalic_p italic_p collisions employing statistical hadronization with a largely augmented set of states beyond the currently measured spectrum. This enables a comprehensive prediction of fragmentation fractions of weakly decaying bottom hadrons for the first time and a satisfactory explanation of the existing measurements in p⁢p𝑝𝑝ppitalic_p italic_p collisions at the LHC. Utilizing the bottom hadro-chemistry thus obtained as the baseline, we then perform transport simulations of bottom quarks in the hot QCD matter created in PbPb collisions at the LHC energy and calculate the pertinent bottom-hadron observables. The transverse momentum (pTsubscript𝑝𝑇p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) dependent modifications of the bottom baryon-to-meson ratio (Λb0/B−superscriptsubscriptΛ𝑏0superscript𝐵\Lambda_{b}^{0}/B^{-}roman_Λ start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT / italic_B start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT) relative to their p⁢p𝑝𝑝ppitalic_p italic_p counterparts are highlighted as a result of bottom quark diffusion and hadronization in the Quark-Gluon Plasma (QGP). We finally summarize the heavy quark (charm vs bottom) diffusion coefficients as extracted from transport simulations and compare them to result from recent full lattice QCD computations.",[],[]
,[],[]
"The effective extraction of spatial-angular features plays a crucial role in light field image super-resolution (LFSR) tasks, and the introduction of convolution and Transformers leads to significant improvement in this area. Nevertheless, due to the large 4D data volume of light field images, many existing methods opted to decompose the data into a number of lower-dimensional subspaces and perform Transformers in each sub-space individually. As a side effect, these methods inadvertently restrict the self-attention mechanisms to a One-to-One scheme accessing only a limited subset of LF data, explicitly preventing comprehensive optimization on all spatial and angular cues. In this paper, we identify this limitation as subspace isolation and introduce a novel Many-to-Many Transformer (M2MT) to address it. M2MT aggregates angular information in the spatial subspace before performing the self-attention mechanism. It enables complete access to all information across all sub-aperture images (SAIs) in a light field image. Consequently, M2MT is enabled to comprehensively capture long-range correlation dependencies. With M2MT as the pivotal component, we develop a simple yet effective M2MT network for LFSR. Our experimental results demonstrate that M2MT achieves state-of-the-art performance across various public datasets. We further conduct in-depth analysis using local attribution maps (LAM) to obtain visual interpretability, and the results validate that M2MT is empowered with a truly non-local context in both spatial and angular subspaces to mitigate subspace isolation and acquire effective spatial-angular representation.","['Light field', 'Super-resolution', 'Image processing', 'Deep learning.']",[]
"Existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (LLMs) with expected outcomes. However, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. Furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for LLMs to effectively utilize tools.
To tackle this issue, we propose ToolEyes, a fine-grained system tailored for the evaluation of the LLMs’ tool learning capabilities in authentic scenarios. The system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to LLMs in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization.
Additionally, ToolEyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between LLMs and the physical world. Evaluations involving ten LLMs across three categories reveal a preference for specific scenarios and limited cognitive abilities in tool learning.
Intriguingly, expanding the model size even exacerbates the hindrance to tool learning.
These findings offer instructive insights aimed at advancing the field of tool learning. The data is available at https://github.com/Junjie-Ye/ToolEyes.git.",[],[]
,[],[]
"Walsh coefficients have been applied extensively
to biallelic systems for quantifying
pairwise and higher order epistasis,
in particular for demonstrating
the empirical importance of
higher order interactions.
Circuits, or minimal dependence
relations,
and related approaches
that use triangulations
of polytopes
have also been applied
to biallelic systems.
Here we
provide biological interpretations of
Walsh coefficients for several alleles,
and discuss circuits in the same general
setting.",[],[]
"Deep learning for Hamiltonian regression of quantum systems in material research necessitates satisfying the covariance laws, among which achieving SO(3)-equivariance without sacrificing the expressiveness of networks remains an elusive challenge due to the restriction to non-linear mappings on guaranteeing theoretical equivariance. To alleviate the covariance-expressiveness dilemma, we propose a hybrid framework with two cascaded regression stages. The first stage, with a theoretically-guaranteed covariant neural network modeling symmetry properties of 3D atom systems, yields theoretically covariant features and baseline Hamiltonian predictions, assisting the second stage in learning covariance. Meanwhile, the second stage, powered by a non-linear 3D graph Transformer network we propose for structural modeling of 3D atomic systems, refines the first stage’s output as a fine-grained prediction of Hamiltonians with better expressiveness capability. The combination of a theoretically covariant yet inevitably less expressive model with a highly expressive non-linear network enables precise, generalizable predictions while maintaining robust covariance under coordinate transformations. Our method achieves state-of-the-art performance in Hamiltonian prediction for electronic structure calculations, confirmed through experiments on five crystalline material databases.",[],[]
"The standard Radon transform of holomorphic functions is not always well defined, as the integration of such functions over planes may not converge. In this paper, we introduce new Radon-type transforms of co-(real)dimension 2222 for harmonic and holomorphic functions on the unit ball. These transforms are abstractly defined as orthogonal projections onto spaces of complex harmonic and holomorphic plane waves, respectively. The inversion formulas are derived based on the dual transform, while the latter is defined as an integration on a complex Stiefel manifold. Our transforms are extended to the Fock space and give rise to a new transform defined on the entire L2⁢(ℝn)superscript𝐿2superscriptℝ𝑛L^{2}(\mathbb{R}^{n})italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) through the Segal-Bargmann transform. Furthermore, we develop these transforms for Hermitian monogenic functions on the unit ball, thereby refining the Szegö-Radon transform for monogenic functions introduced by Colombo, Sabadini and Sommen.",[],[]
,[],[]
"Whether a PTAS (polynomial-time approximation scheme) exists for equilibriums of games has been an open question,
which relates to the practicality of methods in algorithmic game theory and the problem of non-stationarity in training and curse of dimensionality in multi-agent reinforcement learning.
This paper introduces our theory that implies a method that is sufficient and necessary to be the PTAS for perfect equilibriums of dynamic games.
The theory consists of cone interior dynamic programming and primal-dual unbiased regret minimization.
The former enables the dynamic programming operator to iteratively converge to a perfect equilibrium based on a concept called policy cone.
The latter enables the line search method to approximate a Nash equilibrium based on two concepts called primal-dual bias and unbiased central path, solving a subproblem of the former.
Validity of our discovery is cross-corroborated by a combination of theorem proofs, graphs of the three core concepts, and experimental results.",[],[]
,[],[]
"The generalized inverse Gaussian, denoted
GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ), is a flexible family of distributions that includes the gamma, inverse gamma, and inverse Gaussian distributions as special cases. In this article, we derive two novel mixture representations for the GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ): one that expresses the distribution as a continuous mixture of inverse Gaussians and another one that expresses it as a continuous mixture of truncated exponentials. Beyond their conceptual interest, these representations are useful for random number generation. We use the first representation to derive a geometrically ergodic Gibbs sampler whose stationary distribution is GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ), and the second one to define a recursive algorithm to generate exact independent draws from the distribution for half-integer p𝑝pitalic_p. Additionally, the second representation gives rise to a recursive algorithm for evaluating the cumulative distribution function of the GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ) for half-integer p𝑝pitalic_p. The algorithms are simple and can be easily implemented in standard programming languages.",[],[]
"We propose a general mechanism to realize nematic superconductivity (SC) and reveal its exotic vestigial phases in the quasi-crystal (QC). Starting from a Penrose Hubbard model, our microscopic studies suggest that the Kohn-Luttinger mechanism driven SC in the QC is usually gapless due to violation of Anderson’s theorem, rendering that both chiral and nematic SCs are common. The nematic SC in the QC can support novel vestigial phases driven by pairing phase fluctuations above its Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Our combined renormalization group and Monte-Carlo studies provide a phase diagram in which, besides the conventional charge-4e SC, two critical vestigial phases emerge, i.e. the quasi-nematic (Q-N) SC and Q-N metal. In the two Q-N phases, the discrete lattice rotation symmetry is counter-intuitively “quasi-broken” with power-law decaying orientation correlations. They separate the phase diagram into various phases connected via Brezinskii-Kosterlitz-Thouless (BKT) transitions. These remarkable critical vestigial phases, which resemble the intermediate BKT phase in the q𝑞qitalic_q-state (q≥5𝑞5q\geq 5italic_q ≥ 5) clock model, are consequence of the five- (or higher-) fold anisotropy field brought about by the unique QC symmetry, which are absent in conventional crystalline materials.",[],['China']
"Machine translation systems have been widely adopted in our daily life, making life easier and more convenient. Unfortunately, erroneous translations may result in severe consequences, such as financial losses.
This requires to improve the accuracy and the reliability of machine translation systems.
However, it is challenging to test machine translation systems because of the complexity and intractability of the underlying neural models.
To tackle these challenges, we propose a novel metamorphic testing approach by syntactic tree pruning (STP) to validate machine translation systems.
Our key insight is that a pruned sentence should have similar crucial semantics compared with the original sentence.
Specifically, STP
(1) proposes a core semantics-preserving pruning strategy by basic sentence structures and dependency relations on the level of syntactic tree representation;
(2) generates source sentence pairs based on the metamorphic relation;
(3) reports suspicious issues whose translations break the consistency property by a bag-of-words model.
We further evaluate STP on two state-of-the-art machine translation systems (i.e., Google Translate and Bing Microsoft Translator) with 1,200 source sentences as inputs.
The results show that STP accurately finds 5,073 unique erroneous translations in Google Translate and 5,100 unique erroneous translations in Bing Microsoft Translator (400% more than state-of-the-art techniques), with 64.5% and 65.4% precision, respectively.
The reported erroneous translations vary in types and more than 90% of them are not found by state-of-the-art techniques.
There are 9,393 erroneous translations unique to STP, which is 711.9% more than state-of-the-art techniques.
Moreover, STP is quite effective in detecting translation errors for the original sentences with a recall reaching 74.0%, improving state-of-the-art techniques by 55.1% on average.","['Software testing', 'Machine translation', 'Metamorphic testing']",['China']
"In this contribution we deal with Gaussian quadrature rules based on orthogonal polynomials associated with a weight function w⁢(x)=xα⁢e−x𝑤𝑥superscript𝑥𝛼superscript𝑒𝑥w(x)=x^{\alpha}e^{-x}italic_w ( italic_x ) = italic_x start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_x end_POSTSUPERSCRIPT supported on an interval (0,z)0𝑧(0,z)( 0 , italic_z ), z>0.𝑧0z>0.italic_z > 0 . The modified Chebyshev algorithm is used in order to test the accuracy in the computation of the coefficients of the three-term recurrence relation, the zeros and weights, as well as the dependence on the parameter z.𝑧z.italic_z .","['Truncated', 'Laguerre polynomials', 'Symmetrization process', 'Quadrature formula']",[]
"Post-stack seismic inversion is a widely used technique to retrieve high-resolution acoustic impedance models from migrated seismic data. Its modelling operator assumes that a migrated seismic data can be generated from the convolution of a source wavelet and the time derivative of the acoustic impedance model. Given the band-limited nature of the seismic wavelet, the convolutional model acts as a filtering operator on the acoustic impedance model, thereby making the problem of retrieving acoustic impedances from seismic data ambiguous. In order to compensate for missing frequencies, post-stack seismic inversion is often regularized, meaning that prior information about the structure of the subsurface is included in the inversion process. Recently, the Plug-and-Play methodology has gained wide interest in the inverse problem community as a new form of implicit regularization, often outperforming state-of-the-art regularization. Plug-and-Play can be applied to any proximal algorithm by simply replacing the proximal operator of the regularizer with any denoiser of choice. We propose to use Plug-and-Play regularization with a 2D pre-trained, deep denoiser for 2D post-stack seismic inversion. Additionally, we show that a generalization of Plug-and-Play, called Multi-Agent Consensus Equilibrium, can be adopted to solve 3D post-stack inversion whilst leveraging the same 2D pre-trained denoiser used in the 2D case. More precisely, Multi-Agent Consensus Equilibrium combines the results of applying such 2D denoiser in the inline, crossline, and time directions in an optimal manner. We verify the proposed methods on a portion of the SEAM Phase 1 velocity model and the Sleipner field dataset.",[],[]
"X-ray binaries are known to launch powerful accretion disk winds that can have significant impact on the binary systems and their surroundings. To quantify the impact and determine the launching mechanisms of these outflows, we need to measure the wind plasma number density, an important ingredient in the theoretical disk wind models. While X-ray spectroscopy is a crucial tool to understanding the wind properties, such as their velocity and ionization, in nearly all cases, we lack the signal-to-noise to constrain the plasma number density, weakening the constraints on outflow location and mass outflow rate. We present a new approach to determine this number density in the X-ray binary Hercules X-1 by measuring the speed of the wind ionization response to time-variable illuminating continuum. Hercules X-1 is powered by a highly magnetized neutron star, pulsating with a period of 1.24 s. We show that the wind number density in Hercules X-1 is sufficiently high to respond to these pulsations by modeling the ionization response with the time-dependent photoionization model tpho. We then perform a pulse-resolved analysis of the best-quality XMM-Newton observation of Hercules X-1 and directly detect the wind response, confirming that the wind density is at least 1012superscript101210^{12}10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT. Finally, we simulate XRISM observations of Hercules X-1 and show that they will allow us to accurately measure the number density at different locations within the outflow. With XRISM we will rule out ∼3similar-toabsent3\sim 3∼ 3 orders of magnitude in density parameter space, constraining the wind mass outflow rate, energetics, and its launching mechanism.",['Accretion (14)'],"['Germany', 'Italy']"
"The crux of graph classification lies in the effective representation learning for the entire graph. Typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. Such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. In this work, we propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the Graph Neural Memory designed to distill a compact graph representation from node features of the backbone. We first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. Then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. Thus, our model can learn more effective graph representation. We demonstrate the merits of SAR-GNN by extensive experiments on seven datasets across various types of graph data. Code will be released.",[],[]
"Patient representation learning based on electronic health records (EHR) is a critical task for disease prediction. This task aims to effectively extract useful information on dynamic features. Although various existing works have achieved remarkable progress, the model performance can be further improved by fully extracting the trends, variations, and the correlation between the trends and variations in dynamic features. In addition, sparse visit records limit the performance of deep learning models. To address these issues, we propose the Multi-perspective Patient Representation Extractor (MPRE) for disease prediction. Specifically, we propose Frequency Transformation Module (FTM) to extract the trend and variation information of dynamic features in the time-frequency domain, which can enhance the feature representation. In the 2D Multi-Extraction Network (2D MEN), we form the 2D temporal tensor based on trend and variation. Then, the correlations between trend and variation are captured by the proposed dilated operation. Moreover, we propose the First-Order Difference Attention Mechanism (FODAM) to calculate the contributions of differences in adjacent variations to the disease diagnosis adaptively. To evaluate the performance of MPRE and baseline methods, we conduct extensive experiments on two real-world public datasets. The experiment results show that MPRE outperforms state-of-the-art baseline methods in terms of AUROC and AUPRC.","['Disease', 'Prediction', 'Patient', 'Representation', 'Visit', 'Records']",[]
"Conversational AI software products, such as chat-bot and digital assistant, have been widely used in our daily life. With the power of recent advance of artificial intelligence, such products can generate more vivid conversation with users. However, it can also generate speech that contain bias and stereotype. Previous works on detecting the bias in conversational AI system are either based on training a specific classification model, which can not guarantee the accuracy, or based on human annotation, which need much effort and can not be widely used. In this paper, we propose BiasAsker, a novel testing method that can automatically find the bias in conversational AI software by asking questions. Experimental results show that BiasAsker can reveal up to xxx bias on widely deplored software products and research models.","['Software testing', 'metamorphic relations', 'NLP software', 'Chatbot', 'Conversational', 'AI']",[]
"Recently, an anomalous temperature evolution of spin wave excitations
has been observed in a van der Waals metallic ferromagnet Fe33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTGeTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT (FGT)
[S. Bao, et al., Phys. Rev. X 12, 011022 (2022)], whose theoretical
understanding yet remains elusive. Here we study the spin dynamics of a
ferromagnetic Kondo-Heisenberg lattice model at finite temperature, and propose
a mechanism of magnon damping that explains the intriguing experimental results.
In particular, we find the magnon damping rate γ⁢(T)𝛾𝑇\gamma(T)italic_γ ( italic_T ) firstly decreases as
temperature lowers, due to the reduced magnon-magnon scatterings. It then
reaches a minimum at Td*superscriptsubscript𝑇dT_{\rm d}^{*}italic_T start_POSTSUBSCRIPT roman_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, and rises up again following a logarithmic
scaling γ⁢(T)∼ln⁡((T0/T))similar-to𝛾𝑇subscript𝑇0𝑇\gamma(T)\sim\ln{(T_{0}/T)}italic_γ ( italic_T ) ∼ roman_ln ( start_ARG ( italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT / italic_T ) end_ARG ) (with T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT a constant) for T<Td*𝑇superscriptsubscript𝑇dT<T_{\rm d}^{*}italic_T < italic_T start_POSTSUBSCRIPT roman_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT,
which can be attributed to electron-magnon scatterings of spin-flip type.
Moreover, we obtain the phase diagram containing the ferromagnetic and Kondo
insulator phases by varying the Kondo coupling, which may be relevant for experiments
on pressured FGT. The presence of a magnon damping minimum and
logarithmic scaling at low temperature indicates the emergence of the Kondo
effect reflected in the collective excitations of local moments in a Kondo lattice system.",[],['China']
"Let n,d∈\mathbb⁢N𝑛𝑑\mathbb𝑁n,d\in\mathbb{N}italic_n , italic_d ∈ italic_N and n>d𝑛𝑑n>ditalic_n > italic_d. An (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino is a box I1×⋯×Insubscript𝐼1⋯subscript𝐼𝑛I_{1}\times\cdots\times I_{n}italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × ⋯ × italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that Ij∈{[0,1],[1,2]}subscript𝐼𝑗0112I_{j}\in\{[0,1],[1,2]\}italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ { [ 0 , 1 ] , [ 1 , 2 ] } for all j∈N⊂[n]𝑗𝑁delimited-[]𝑛j\in N\subset[n]italic_j ∈ italic_N ⊂ [ italic_n ] with |N|=d𝑁𝑑|N|=d| italic_N | = italic_d and Ii=[0,2]subscript𝐼𝑖02I_{i}=[0,2]italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ 0 , 2 ] for every i∈[n]∖N𝑖delimited-[]𝑛𝑁i\in[n]\setminus Nitalic_i ∈ [ italic_n ] ∖ italic_N. If A𝐴Aitalic_A and B𝐵Bitalic_B are two (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes such that A∪B𝐴𝐵A\cup Bitalic_A ∪ italic_B is an (n−(d−1))𝑛𝑑1(n-(d-1))( italic_n - ( italic_d - 1 ) )-domino, then A,B𝐴𝐵A,Bitalic_A , italic_B is called a twin pair. If C,D𝐶𝐷C,Ditalic_C , italic_D are two (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes which form a twin pair such that A∪B=C∪D𝐴𝐵𝐶𝐷A\cup B=C\cup Ditalic_A ∪ italic_B = italic_C ∪ italic_D and {C,D}≠{A,B}𝐶𝐷𝐴𝐵\{C,D\}\neq\{A,B\}{ italic_C , italic_D } ≠ { italic_A , italic_B }, then the pair C,D𝐶𝐷C,Ditalic_C , italic_D is called a flip of A,B𝐴𝐵A,Bitalic_A , italic_B. A family 𝒟𝒟\mathscr{D}script_D of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes is a tiling of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT if interiors of every two members of 𝒟𝒟\mathscr{D}script_D are disjoint and ⋃B∈𝒟B=[0,2]nsubscript𝐵𝒟𝐵superscript02𝑛\bigcup_{B\in\mathscr{D}}B=[0,2]^{n}⋃ start_POSTSUBSCRIPT italic_B ∈ script_D end_POSTSUBSCRIPT italic_B = [ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. An (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tiling 𝒟′superscript𝒟′\mathscr{D}^{\prime}script_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is obtained from an (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tiling 𝒟𝒟\mathscr{D}script_D by a flip, if there is a twin pair A,B∈𝒟𝐴𝐵𝒟A,B\in\mathscr{D}italic_A , italic_B ∈ script_D such that 𝒟′=(𝒟∖{A,B})∪{C,D}superscript𝒟′𝒟𝐴𝐵𝐶𝐷\mathscr{D}^{\prime}=(\mathscr{D}\setminus\{A,B\})\cup\{C,D\}script_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( script_D ∖ { italic_A , italic_B } ) ∪ { italic_C , italic_D }, where C,D𝐶𝐷C,Ditalic_C , italic_D is a flip of A,B𝐴𝐵A,Bitalic_A , italic_B. A family of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tilings of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is flip-connected, if for every two members 𝒟,ℰ𝒟ℰ\mathscr{D},\mathscr{E}script_D , script_E of this family the tiling ℰℰ\mathscr{E}script_E can be obtained from 𝒟𝒟\mathscr{D}script_D by a sequence of flips. In the paper some flip-connected class of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tilings of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is described.",[],[]
"A Howe curve is defined as the normalization of the fiber product over a projective line of two hyperelliptic curves.
Howe curves are very useful to produce important classes of curves over fields of positive characteristic, e.g., maximal, superspecial, or supersingular ones.
Determining their feasible equations explicitly is a basic problem, and it has been solved in the hyperelliptic case and in the non-hyperelliptic case with genus not greater than 4444.
In this paper, we construct an explicit plane sextic model for non-hyperelliptic Howe curves of genus 5555.
We also determine the number and type of singularities on our sextic model, and prove that the singularities are generically 4444 double points.
Our results together with Moriya-Kudo’s recent ones imply that for each s∈{2,3,4,5}𝑠2345s\in\{2,3,4,5\}italic_s ∈ { 2 , 3 , 4 , 5 }, there exists a non-hyperellptic curve H𝐻Hitalic_H of genus 5555 with Aut⁢(H)⊃𝐕4subscript𝐕4Aut𝐻\mathrm{Aut}(H)\supset\mathbf{V}_{4}roman_Aut ( italic_H ) ⊃ bold_V start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT such that its associated plane sextic has s𝑠sitalic_s double points.",[],[]
"Conversational AI software products, such as chat-bot and digital assistant, have been widely used in our daily life. With the power of recent advance of artificial intelligence, such products can generate more vivid conversation with users. However, it can also generate speech that contain bias and stereotype. Previous works on detecting the bias in conversational AI system are either based on training a specific classification model, which can not guarantee the accuracy, or based on human annotation, which need much effort and can not be widely used. In this paper, we propose BiasAsker, a novel testing method that can automatically find the bias in conversational AI software by asking questions. Experimental results show that BiasAsker can reveal up to xxx bias on widely deplored software products and research models.","['Software testing', 'metamorphic relations', 'NLP software', 'Chatbot', 'Conversational', 'AI']",[]
"Structural global parameter identifiability indicates whether one can determine a parameter’s value in an ODE model from given inputs and outputs. If a given model has parameters for which there is exactly one value, such parameters are called identifiable. We present a procedure for replacing, if possible, a given ODE model involving not identifiable parameters by an equivalent one such that the new set of parameters is identifiable. We first derive this as an algorithm for one-dimensional ODE models and then reuse this approach for higher-dimensional models.",[],[]
"Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel metamorphic testing framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on any changes related to gender, race, and age. BiasPainter adopts a testing oracle that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models.
To evaluate the effectiveness of BiasPainter, we use BiasPainter to test five widely-used commercial image generation software and models, such as stable diffusion and Midjourney. Experimental results show that 100% of the generated test cases can successfully trigger social bias in image generation models. According to our human evaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection, which is significantly higher than the results reported in previous work. Additionally, BiasPainter provides interesting and valuable insights from evaluating the fairness of image generation models, which is helpful for developers to improve the models in the future. All the code, data, and experimental results will be released to facilitate future research.",[],['China']
"We continue the survey initiated in Kimura:2020bed  to explore the Bethe/Gauge correspondence between supersymmetric SO/Sp gauge theories in 2d/3d/4d and open spin chain with integrable boundaries. We collect the known Bethe ansatz equations of different types of spin chains with general boundaries that have been analyzed in the literature, and compare them with the vacua equations of the quiver gauge theories. It seems that not all the vacua equations of quiver gauge theory with BCD-type gauge groups can be realized as some known Bethe ansatz equations of integrable spin chain models.",[],[]
"Cryptography is the study of securing information. It is the physical process that scrambles the information by rearrangement and substitution of content, so that it becomes difficult for anyone to understand. In today’s world, security has become an inevitable part of our day-to-day life, right from normal browsing to performing critical payment transactions. Hackers work endlessly to break the security present in the apps/websites on which we perform day-to-day operations and salvage valuable information. Because of this, many illegal activities have taken place which affect the user. One such illegal activity is tapping the voice communication between two users. If left unencrypted, the communication between the users is compromised, thereby causing issues. One way to prevent this act is to encrypt the audio in that the contents cannot have tampered with unless the receiver has the valid key to decrypt it. The proposed solution termed ”HexE” aims to create a puzzle-based algorithm which would encrypt and decrypt the audio files without manipulating the file header, thus securing the contents. The algorithm works on an NxN SuDoKu-based puzzle which is accepted both by the sender and receiver. Using the timestamp of the event (UNIX based), a grid from the puzzle is chosen which in turn will act as the key for both encryption and decryption. If the timestamp is slightly adjusted, the process will end up in failure during decryption, thus ensuring confidentiality. Another approach to secure the audio files is to implement IPFS (Inter Planetary File System) alongside the puzzle algorithm in which the encrypted audio is stored on it and the receiver can fetch the audio provided if the valid IPFS Hash of the file is present. In this way, the audio file is secured.",[],[]
"It is challenging but highly desired to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus exclusively on specific restoration or enhancement tasks, being insufficient in exploiting multi-image. Motivated by that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize bracketing photography to unify restoration and enhancement tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. The dataset, code, and pre-trained models are available at https://github.com/cszhilu1998/BracketIRE.",[],[]
"Let G𝐺Gitalic_G be a finite group, and g∈G𝑔𝐺g\in Gitalic_g ∈ italic_G. Then g𝑔gitalic_g is said to be a vanishing element of G𝐺Gitalic_G, if there exists an irreducible character χ𝜒\chiitalic_χ of G𝐺Gitalic_G such that χ⁢(g)=0𝜒𝑔0\chi(g)=0italic_χ ( italic_g ) = 0. Denote by Vo⁢(G)Vo𝐺{\rm Vo}(G)roman_Vo ( italic_G ) the set of the orders of vanishing elements of G𝐺Gitalic_G. We say a non-abelian group G𝐺Gitalic_G is V-recognizable, if any group N𝑁Nitalic_N with Vo⁢(N)=Vo⁢(G)Vo𝑁Vo𝐺{\rm Vo}(N)={\rm Vo}(G)roman_Vo ( italic_N ) = roman_Vo ( italic_G ) is isomorphic to G𝐺Gitalic_G. In this paper, we investigate the V-recognizability of E8⁢(p)subscript𝐸8𝑝E_{8}(p)italic_E start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ( italic_p ), where p𝑝pitalic_p is a prime number. As an application, among the 610 primes p𝑝pitalic_p with p<10000𝑝10000p<10000italic_p < 10000 and p≡0,1,4(mod5)𝑝01annotated4moduloabsent5p\equiv 0,1,4\,(\!\!\!\mod 5)italic_p ≡ 0 , 1 , 4 ( roman_mod 5 ), we obtain that the method is always valid for confirming the V-recognizability of E8⁢(p)subscript𝐸8𝑝E_{8}(p)italic_E start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ( italic_p ) for all such p𝑝pitalic_p but 919,1289,1931,3911,4691,538191912891931391146915381919,1289,1931,3911,4691,5381919 , 1289 , 1931 , 3911 , 4691 , 5381 and 7589758975897589.",[],[]
"With the onset of the era of gravitational-wave (GW) astronomy, the search for continuous gravitational waves (CGWs), which remain undetected to date, has intensified in more ways than one. Rapidly rotating neutron stars with non-axisymmetrical deformations are the main targets for CGW searches. The extent of this quadrupolar deformation is measured by the maximum ellipticity that can be sustained by the crust of a neutron star and it places an upper limit on the CGW amplitudes emitted by such systems. In this paper, following previous works on this subject, we calculate the maximum ellipticity of a neutron star generated by the Lorentz force exerted on it by the internal magnetic fields. We show that the ellipticity of stars deformed by such a Lorentz force is of the same order of magnitude as previous theoretical and astrophysical constraints. We also consider if this ellipticity can be further enhanced by crustal surface currents. We discover that this is indeed true; surface currents at crustal boundaries are instrumental towards enhancing the ellipticity of magnetized neutron stars.",[],[]
"In this paper, we present a theoretical, experimental, and numerical study of the dynamics of cavitation bubbles inside a droplet suspended in another host fluid. On the theoretical side, we provided a modified Rayleigh collapse time and natural frequency for spherical bubbles in our particular context, characterized by the density ratio between the two liquids and the bubble-to-droplet size ratio. Regarding the experimental aspect, experiments were carried out for laser-induced cavitation bubbles inside oil-in-water (O/W) or water-in-oil (W/O) droplets. Two distinct fluid-mixing mechanisms were unveiled in the two systems, respectively. In the case of O/W droplets, a liquid jet emerges around the end of the bubble collapse phase, effectively penetrating the droplet interface. We offer a detailed analysis of the criteria governing jet penetration, involving the standoff parameter and impact velocity of the bubble jet on the droplet surface. Conversely, in the scenario involving W/O droplets, the bubble traverses the droplet interior, inducing global motion and eventually leading to droplet pinch-off when the local Weber number exceeds a critical value. This phenomenon is elucidated through the equilibrium between interfacial and kinetic energies. Lastly, our boundary integral model faithfully reproduces the essential physics of nonspherical bubble dynamics observed in the experiments. We conduct a parametric study spanning a wide parameter space to investigate bubble-droplet interactions. The insights from this study could serve as a valuable reference for practical applications in the field of ultrasonic emulsification, pharmacy, etc.",[],['China']
"Vector-like quarks have been predicted in various new physics scenarios beyond the Standard Model (SM). In a simplified modelling of a (B,Y)𝐵𝑌(B,Y)( italic_B , italic_Y ) doublet including a vector-like quark Y𝑌Yitalic_Y, with charge −4343-\frac{4}{3}- divide start_ARG 4 end_ARG start_ARG 3 end_ARGe, there are only two free parameters: the Y𝑌Yitalic_Y coupling κYsubscript𝜅𝑌\kappa_{Y}italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT and mass mYsubscript𝑚𝑌m_{Y}italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. In the five flavor scheme, we investigate the single production of the Y𝑌Yitalic_Y state decaying into W⁢b𝑊𝑏Wbitalic_W italic_b at the
Large Hadron Collider (LHC) Run-III and High-Luminosity LHC (HL-LHC) operating at s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 14 TeV, the possible High-Energy LHC (HE-LHC) with s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 27 TeV as well as the Future Circular Collider in hadron-hadron mode (FCC-hh) with s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 100 TeV. Through detailed signal-to-background analyses and detector simulations, we assess the exclusion capabilities of the Y𝑌Yitalic_Y state at the different colliders.
We find that this can be improved significantly with increasing collision energy, especially at the HE-LHC and FCC-hh, both demonstrating an obvious advantage with respect to the HL-LHC case
in the case of high mYsubscript𝑚𝑌m_{Y}italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. Assuming a 10% systematic uncertainty on the background event rate, the exclusion capabilities are summarized as follows:
(1) the LHC Run-III can exclude the correlated regions of κY∈[0.044,0.5]subscript𝜅𝑌0.0440.5\kappa_{Y}\in[0.044,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.044 , 0.5 ] and mY∈[1000⁢ GeV,3099⁢ GeV]subscript𝑚𝑌1000 GeV3099 GeVm_{Y}\in[1000\text{ GeV},3099\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 3099 GeV ] with integrated luminosity L=300⁢ fb−1𝐿300superscript fb1L=300\text{ fb}^{-1}italic_L = 300 fb start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT;
(2) the HL-LHC can exclude the correlated regions of κY∈[0.027,0.5]subscript𝜅𝑌0.0270.5\kappa_{Y}\in[0.027,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.027 , 0.5 ] and mY∈[1000⁢ GeV,3653⁢ GeV]subscript𝑚𝑌1000 GeV3653 GeVm_{Y}\in[1000\text{ GeV},3653\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 3653 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT;
(3) the HE-LHC can exclude the correlated regions of κY∈[0.030,0.5]subscript𝜅𝑌0.0300.5\kappa_{Y}\in[0.030,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.030 , 0.5 ] and mY∈[1000⁢ GeV,4936⁢ GeV]subscript𝑚𝑌1000 GeV4936 GeVm_{Y}\in[1000\text{ GeV},4936\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 4936 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT;
(4) the FCC-hh can exclude the correlated regions of κY∈[0.051,0.5]subscript𝜅𝑌0.0510.5\kappa_{Y}\in[0.051,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.051 , 0.5 ] and mY∈[1000⁢ GeV,6610⁢ GeV]subscript𝑚𝑌1000 GeV6610 GeVm_{Y}\in[1000\text{ GeV},6610\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 6610 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT.",[],[]
"We discuss the gravitational wave (GW) spectra predicted from
the electroweak scalegenesis of the Higgs portal type
with a large number of dark chiral flavors, which many flavor QCD would underlie and give the dynamical explanation of the negative Higgs portal coupling required to trigger the electroweak symmetry breaking.
We employ the linear-sigma model as the low-energy description of dark many flavor QCD and show that the model undergoes ultra-supercooling due to the produced
strong first-order thermal phase transition along the (approximately realized) flat direction based on the Gildener-Weinberg mechanism.
Passing through evaluation of the bubble nucleation/percolation, we address
the reheating and relaxation processes, which are generically non-thermal and nonadiabatic.
Parametrizing the reheating epoch in terms of the efolding number, we propose
proper formulae for the redshift effects on the GW frequencies and signal
spectra.
It then turns out that the ultra-supercooling predicted from the Higgs-portal scalegenesis generically
yields none of GW signals with the frequencies as low as nano Hz, instead, prefers to give the higher frequency signals,
which still keeps the future prospected detection sensitivity, like at LISA, BBO, and DECIGO, etc.
We also find that with large flavors in the dark sector, the GW signals are made further smaller
and the peak frequencies higher.
Characteristic phenomenological consequences related to
the multiple chiral scalars include the prediction of dark pions
with the mass much less than TeV scale, which is also briefly addressed.",[],"['Japan', 'China']"
,[],[]
"Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors.
To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover, the proposed method leverages variational inference for Dirichlet process mixtures to ensure efficient and fast computation. Empirical studies with benchmark datasets demonstrate that our method outperforms existing approaches for unsupervised outlier detection.",[],[]
"In this paper, we establish some reciprocity formulas for certain generalized Hardy sums by using the Fourier series technique and some properties of the periodic zeta function and Lerch zeta function. It turns out that one of Hardy’s reciprocity theorems is deduced as a special case.",[],[]
"Text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. We review popular methods for text analysis, ranging from
topic modeling to the recent neural language models.
In particular, we review Topic-SCORE, a statistical approach to topic modeling, and discuss how to use it to analyze MADStat - a dataset on statistical publications
that we collected and cleaned.
The application of Topic-SCORE and other methods on MADStat leads to interesting findings.
For example,
11111111 representative topics in statistics are identified.
For each journal, the evolution of
topic weights over time can be visualized, and these results are used to analyze the trends in
statistical research. In particular, we propose a new statistical model for ranking the citation impacts of 11111111 topics, and we also
build a cross-topic citation graph to illustrate how research results on different topics spread to one another.
The results on MADStat provide a data-driven picture of the statistical
research in 1975197519751975–2015201520152015, from a text analysis perspective.",[],[]
"In recent years, edge computing has served as a paradigm that enables many future technologies like AI, Robotics, IoT, and high-speed wireless sensor networks (like 5G) by connecting cloud computing facilities and services to the end users. Especially in medical and healthcare applications, it provides remote patient monitoring and increases voluminous multimedia.
From the robotics angle, robot-assisted therapy (RAT) is an active-assistive robotic technology in rehabilitation robotics, attracting many researchers to study and benefit people with disability like autism spectrum disorder (ASD) children.
However, the main challenge of RAT is that the model capable of detecting the affective states of ASD people exists and can recall individual preferences. Moreover, involving expert diagnosis and recommendations to guide robots in updating the therapy approach to adapt to different statuses and scenarios is a crucial part of the ASD therapy process. This paper proposes the architecture of edge cognitive computing by combining human experts and assisted robots collaborating in the same framework to help ASD patients with long-term support. By integrating the real-time computing and analysis of a new cognitive robotic model for ASD therapy, the proposed architecture can achieve a seamless remote diagnosis, round-the-clock symptom monitoring, emergency warning, therapy alteration, and advanced assistance.",[],[]
"Herschend–Liu–Nakaoka introduced the concept of n𝑛nitalic_n-exangulated categories as higher-dimensional analogues of extriangulated categories defined by Nakaoka–Palu. The class of n𝑛nitalic_n-exangulated categories contains n𝑛nitalic_n-exact categories and (n+2)𝑛2(n+2)( italic_n + 2 )-angulated categories as specific examples. In this article, we introduce the notion of hereditary n𝑛nitalic_n-exangulated categories, which generalize hereditary extriangulated categories. We provide two classes of hereditary n𝑛nitalic_n-exangulated categories through closed subfunctors. Additionally, we define the concept of 00-Auslander n𝑛nitalic_n-exangulated categories and discuss the circumstances under which these two classes of hereditary n𝑛nitalic_n-exangulated categories become 00-Auslander.

Keywords: (n+2)𝑛2(n+2)( italic_n + 2 )-angulated category; n𝑛nitalic_n-exact category; hereditary n𝑛nitalic_n-exangulated category; 00-Auslander n𝑛nitalic_n-exangulated category; closed subfunctor

 2020 Mathematics Subject Classification: 18G80; 18E10",[],[]
"Lawson’s iteration is a classical and effective method for solving the linear (polynomial) minimax approximation in the complex plane. Extension of Lawson’s iteration for the rational minimax approximation with both computationally high efficiency and theoretical guarantee is challenging. A recent work [L.-H. Zhang, L. Yang, W. H. Yang and Y.-N. Zhang, A convex dual programming for the rational minimax approximation and Lawson’s iteration, 2023, https://arxiv.org/pdf/2308.06991v1] reveals that Lawson’s iteration can be viewed as a method for solving the dual problem of the original rational minimax approximation, and a new type of Lawson’s iteration was proposed. Such a dual problem is guaranteed to obtain the original minimax solution under Ruttan’s sufficient condition, and numerically, the proposed Lawson’s iteration was observed to converge monotonically with respect to the dual objective function. In this paper, we perform theoretical convergence analysis for Lawson’s iteration for both the linear and rational minimax approximations. In particular, we show that


 (i)

for the linear minimax approximation, the near-optimal Lawson exponent β𝛽\betaitalic_β in Lawson’s iteration is β=1𝛽1\beta=1italic_β = 1, and




(ii)

for the rational minimax approximation, the proposed Lawson’s iteration converges monotonically with respect to the dual objective function for any sufficiently small β>0𝛽0\beta>0italic_β > 0, and the convergent solution fulfills the complementary slackness: all nodes associated with positive weights achieve the maximum error.",[],[]
"Temporal validity is an important property of text that is useful for many downstream applications, such as recommender systems, conversational AI, or story understanding. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, in many cases, additional contextual information, such as sentences in a story or posts on a social media profile, can be collected from the available text stream. This contextual information may greatly alter the duration for which a statement is expected to be valid. We propose Temporal Validity Change Prediction, a natural language processing task benchmarking the capability of machine learning models to detect contextual statements that induce such change. We create a dataset consisting of temporal target statements sourced from Twitter and crowdsource sample context statements. We then benchmark a set of transformer-based language models on our dataset. Finally, we experiment with temporal validity duration prediction as an auxiliary task to improve the performance of the state-of-the-art model.",[],[]
"Riemann-Cartan geometries are metric based geometries admitting a non-zero torsion tensor. These geometries have been investigated as geometric frameworks for potential theories in physics including quantum gravity theories and have many important differences when compared to Riemannian geometries. One notable difference, is the number of symmetries for a Riemann-Cartan geometry is potentially smaller than the number of Killing vector fields for the metric. In this paper we will review the investigation of symmetries in Riemann-Cartan geometries and the mathematical tools used to determine geometries that admit a given group of symmetries. As an illustration we will determine all static spherically symmetric and all stationary spherically symmetric Riemann-Cartan geometries. Further, we will determine the subclasses of spherically symmetric Riemann-Cartan geometries that admit a seven-dimensional group of symmetries.",[],['Norway']
,[],[]
"We investigate evolution of a flat Emergent Universe (EU) obtained with a non-linear equation of state (nEoS) in Einstein’s general theory of Relativity. The nEoS is equivalent to three different types of barotropic cosmic fluid, which is known from the nEoS parameter. The EU began expanding initially with no interaction among the cosmic fluids. Assuming an interaction that sets in at a time t>ti𝑡subscript𝑡𝑖t>t_{i}italic_t > italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT among the fluid components, we study the evolution of the EU that leads to the present observed universe. A dynamical system analysis is performed to characterize the cosmological evolution and the stable behavior of the critical points of the autonomous system for an EU with or without interaction. The autonomous system of ordinary differential equations of the field equations are used to derive the evolution using dimensionless parameters. We determine critical points, and we analyze the stability of the critical points, drawing the phase portraits. The density parameters and the corresponding cosmological parameters are obtained for both the non-interacting and interacting phases to explore the dynamics of evolution.
Key Words : Emergent Universe, Dynamical analysis, Cosmological Parameters",[],['India']
"The notion of Frobenius Betti numbers generalizes the Hilbert-Kunz multiplicity theory and serves as an invariant that measures singularity.
However, the explicit computation of the Frobenius Betti numbers of rings has been limited to very few specific cases. This article focuses on the explicit computation of Frobenius Betti numbers of Cohen-Macaulay graded rings of finite Cohen-Macaulay type.","['Frobenius', 'Betti number', 'Hilbert-Kunz multiplicity', 'finite', 'Cohen-Macaulay type']",[]
"We consider dilute Bose gases on the three dimensional unit torus that interact through a pair potential with scattering length of order Nκ−1superscript𝑁𝜅1N^{\kappa-1}italic_N start_POSTSUPERSCRIPT italic_κ - 1 end_POSTSUPERSCRIPT, for some κ>0𝜅0\kappa>0italic_κ > 0. For the range κ∈[0,143)𝜅0143\kappa\in[0,\frac{1}{43})italic_κ ∈ [ 0 , divide start_ARG 1 end_ARG start_ARG 43 end_ARG ), [1] proves complete BEC of low energy states into the zero momentum mode based on a unitary renormalization through operator exponentials that are quartic in creation and annihilation operators. In this paper, we give a new and self-contained proof of BEC of the ground state for κ∈[0,120)𝜅0120\kappa\in[0,\frac{1}{20})italic_κ ∈ [ 0 , divide start_ARG 1 end_ARG start_ARG 20 end_ARG ) by combining some of the key ideas of [1] with the novel diagonalization approach introduced recently in [16], which is based on the Schur complement formula. In particular, our proof avoids the use of operator exponentials and is significantly simpler than [1].",[],[]
"Superradiant Raman scattering of Rubidium atoms has been explored in the experiment [Nature 484, 78 (2012)] to prove the concept of the superradiant laser, which attracts significant attentions in quantum metrology due to the expected ultra-narrow linewidth down to millihertz. To better understand the physics involved in this experiment, we have developed a quantum master equation theory by treating the Rubidium atoms as three-level systems, and coupling them with a dressed laser and an optical cavity. Our simulations show different superradiant Raman scattering pulses for the systems within the crossover and strong coupling regime, and the shifted and broader spectrum of the steady-state Raman scattering. Thus, our studies provide a unified view on the superradiant Raman scattering pulses, and an alternative explanation to the broad spectrum of the steady-state Raman scattering, as observed in the experiment. In future, our theory can be readily applied to study other interesting phenomena relying on the superradiant Raman scattering, such as magnetic field sensing, real-time tracking of quantum phase, Dicke phase transition of non-equilibrium dynamics and so on.",[],['China']
"We show that a “generic” finite metric space can be identified by the asymptotic behavior of the magnitude function.
In particular, almost every finite set in Euclidean space can be determined by the magnitude function.",[],[]
,[],[]
"The high cost of full-parameter fine-tuning (FFT) of Large Language Models (LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods. However, it remains unclear which methods provide the best cost-performance trade-off at different model scales. We introduce Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. Through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that FFT generally leads to the best downstream performance across all scales, and PEFT methods differ significantly in their efficacy based on the model scale. LoRA usually offers the most favorable trade-off between cost and performance. Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. At last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. We find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance.",[],[]
"Understanding human actions from videos of first-person view poses significant challenges. Most prior approaches explore representation learning on egocentric videos only, while overlooking the potential benefit of exploiting existing large-scale third-person videos.
In this paper,
(1) we develop EgoInstructor, a retrieval-augmented multimodal captioning model that automatically retrieves semantically relevant third-person instructional videos to enhance the video captioning of egocentric videos.
(2) For training the cross-view retrieval module, we devise an automatic pipeline to discover ego-exo video pairs from distinct large-scale egocentric and exocentric datasets.
(3) We train the cross-view retrieval module with a novel EgoExoNCE loss that pulls egocentric and exocentric video features closer by aligning them to shared text features that describe similar actions.
(4) Through extensive experiments, our cross-view retrieval module demonstrates superior performance across seven benchmarks. Regarding egocentric video captioning, EgoInstructor exhibits significant improvements by leveraging third-person videos as references.",[],[]
"The group of homeomorphisms of the closed interval that are orientation preserving, absolutely continuous and have an absolutely continuous inverse was shown by Solecki to admit a natural Polish group topology τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT. We observe that, more generally, under some conditions on a compact space endowed with a finite Borel measure an analogous Polish group topology can be defined on the subgroup of the homeomorphism group which push forward the measure to another one with which it is mutually absolutely continuous.

We use a probabilistic argument involving approximations by supmartingale processes to show that in many cases there is no group topology between τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT and the restriction τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT of the compact-open topology.
This applies, in particular, to any compact topological manifold equipped with an Oxtoby-Ulam measure and to the Cantor space endowed with some natural Borel measures.
In fact, we show that in such cases any separable group topology strictly finer than τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT has to be also finer than τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT. For one-dimensional manifolds well-known arguments show that the compact-open topology is a minimum Hausdroff group topology on the group, which implies that τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT and τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT are the only Hausdorff group topologies coarser than τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT.

We also show that while Solecki’s example is not Roelcke precompact, the group of bi-absolutely continuous homeomorphisms of the Cantor space endowed with the measure given by the Fräissé limit of the class of measured boolean algebras with rational probability measures is Roelcke precompact.",[],[]
"The momentum ray transform Imksuperscriptsubscript𝐼𝑚𝑘I_{m}^{k}italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT integrates a rank m𝑚mitalic_m symmetric tensor field f𝑓fitalic_f on ℝnsuperscriptℝ𝑛{{\mathbb{R}}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT over lines with the weight tksuperscript𝑡𝑘t^{k}italic_t start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT,
Imk⁢f⁢(x,ξ)=∫−∞∞tk⁢⟨f⁢(x+t⁢ξ),ξm⟩⁢dtsuperscriptsubscript𝐼𝑚𝑘𝑓𝑥𝜉superscriptsubscriptsuperscript𝑡𝑘𝑓𝑥𝑡𝜉superscript𝜉𝑚differential-d𝑡I_{m}^{k}f(x,\xi)=\int_{-\infty}^{\infty}t^{k}\langle f(x+t\xi),\xi^{m}\rangle%
\,\mathrm{d}titalic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_f ( italic_x , italic_ξ ) = ∫ start_POSTSUBSCRIPT - ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ⟨ italic_f ( italic_x + italic_t italic_ξ ) , italic_ξ start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ⟩ roman_d italic_t.
We compute the normal operator Nmk=(Imk)⁢Imk*superscriptsubscript𝑁𝑚𝑘superscriptsubscript𝐼𝑚𝑘superscriptsuperscriptsubscript𝐼𝑚𝑘N_{m}^{k}=(I_{m}^{k}){}^{*}I_{m}^{k}italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = ( italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT and present an inversion formula recovering a rank m𝑚mitalic_m tensor field f𝑓fitalic_f from the data (Nm0⁢f,…,Nmm⁢f)superscriptsubscript𝑁𝑚0𝑓…superscriptsubscript𝑁𝑚𝑚𝑓(N_{m}^{0}f,\dots,N_{m}^{m}f)( italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_f , … , italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_f ).
Keywords. Ray transform, inverse problems, symmetric tensor fields, tensor tomography, momentum ray transform.
Mathematics Subject Classification (2020): Primary 44A12, Secondary 53C65.",[],[]
"We discuss how grand unification can be probed with experiments at low energies using quantum sensors. Specifically, we show that scalar multiplets coupled to the gauge sector of a grand unified theory provide a mechanism for a time-varying unified coupling which has low-energy consequences which can be probed with quantum sensors. We then assume that the multiplets represent ultra light dark matter. Constraints on ultra light dark matter couplings to regular matter are extracted using atomic clock comparisons, pulsar timing arrays (NANOGrav) and MICROSCOPE.",[],[]
"With the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect the privacy of inference data and model parameters. However, the application of SMPC in Privacy-Preserving Inference (PPI) for large language models, particularly those based on the Transformer architecture, often leads to considerable slowdowns or declines in performance. This is largely due to the multitude of nonlinear operations in the Transformer architecture, which are not well-suited to SMPC and are difficult to circumvent or optimize effectively. To address this concern, we introduce an advanced optimization framework called SecFormer, designed to strike an optimal balance between performance and efficiency in PPI for Transformer models. By implementing knowledge distillation techniques, we successfully eliminate the high-cost exponential and maximum operations in PPI without sacrificing model performance. Additionally, we have developed a suite of efficient SMPC protocols that utilize segmented polynomials and Goldschmidt’s method to handle other complex nonlinear functions within PPI, such as GeLU, LayerNorm, and Softmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer in performance, showing improvements of 5.6%percent5.65.6\%5.6 % and 24.2%percent24.224.2\%24.2 % for BERTBASEBASE{}_{\text{BASE}}start_FLOATSUBSCRIPT BASE end_FLOATSUBSCRIPT and BERTLARGELARGE{}_{\text{LARGE}}start_FLOATSUBSCRIPT LARGE end_FLOATSUBSCRIPT, respectively. In terms of efficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its effectiveness and speed.",[],[]
,[],[]
,[],[]
"Harnessing the advantages of shared entanglement for sending quantum messages often requires the implementation of complex two-particle entangled measurements. We investigate entanglement advantages in protocols that use only the simplest two-particle measurements, namely product measurements. For experiments in which only the dimension of the message is known, we show that robust entanglement advantages are possible, but that they are fundamentally limited by Einstein-Podolsky-Rosen steering. Subsequently, we propose a natural extension of the standard scenario for these experiments and show that it circumvents this limitation. This leads us to prove entanglement advantages from every entangled two-qubit Werner state, evidence its generalisation to high-dimensional systems and establish a connection to quantum teleportation. Our results reveal the power of product measurements for generating quantum correlations in entanglement-assisted communication and they pave the way for practical semi-device-independent entanglement certification well-beyond the constraints of Einstein-Podolsky-Rosen steering.",[],"['Austria', 'Sweden']"
"Pre-trained recommendation models (PRMs) have attracted widespread attention recently. However, their totally different model structure, huge model size and computation cost hinder their application in practical recommender systems.
Hence, it is highly essential to explore how to practically utilize PRMs in real-world recommendations.
In this paper, we propose a novel joint knowledge distillation from different pre-trained recommendation models named PRM-KD for recommendation, which takes full advantages of diverse PRMs as teacher models for enhancing student models efficiently.
Specifically, PRM-KD jointly distills diverse informative knowledge from multiple representative PRMs such as UniSRec, Recformer, and UniM22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPTRec. The knowledge from the above PRMs are then smartly integrated into the student recommendation model considering their confidence and consistency.
We further verify the universality of PRM-KD with various types of student models, including sequential recommendation, feature interaction, and graph-based models.
Extensive experiments on five real-world datasets demonstrate the effectiveness and efficacy of PRM-KD, which could be viewed as an economical shortcut in practically and conveniently making full use of different PRMs in online systems.","['Knowledge', 'Distillation', 'Pre-trained', 'Recommendation.']",[]
,[],[]
,[],[]
"Factor importance measures the impact of each feature on output prediction accuracy. Many existing works focus on the model-based importance, but an important feature in one learning algorithm may hold little significance in another model. Hence, a factor importance measure ought to characterize the feature’s predictive potential without relying on a specific prediction algorithm. Such algorithm-agnostic importance is termed as intrinsic importance in Williamson et al. (2023), but their estimator again requires model fitting. To bypass the modeling step, we present the equivalence between predictiveness potential and total Sobol’ indices from global sensitivity analysis, and introduce a novel consistent estimator that can be directly estimated from noisy data. Integrating with forward selection and backward elimination gives rise to FIRST, Factor Importance Ranking and Selection using Total (Sobol’) indices. Extensive simulations are provided to demonstrate the effectiveness of FIRST on regression and binary classification problems, and a clear advantage over the state-of-the-art methods.",[],[]
"We improve the best known upper bound for the bracketing number of d𝑑ditalic_d-dimensional axis-parallel boxes anchored in 00
(or, put differently, of lower left orthants intersected with the d𝑑ditalic_d-dimensional unit cube [0,1]dsuperscript01𝑑[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT).
More precisely, we provide a better upper bound for the cardinality of an algorithmic bracketing cover construction due to Eric Thiémard, which
forms the core of his algorithm to approximate the star discrepancy of arbitrary point sets from
[E. Thiémard, An algorithm to compute bounds for the star discrepancy, J. Complexity 17 (2001), 850 – 880].
Moreover, the new upper bound for the bracketing number of anchored axis-parallel boxes yields an improved upper bound for the bracketing number of arbitrary axis-parallel boxes in [0,1]dsuperscript01𝑑[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT.
In our upper bounds all constants are fully explicit.",[],[]
"Context:Stellar evolution theory predicts the existence of He-core remnants of the primary components of intermediate-mass close binaries that lost most of their H/He envelopes due to the mass exchange. They are expected to be observed as (1 – 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT hot He-rich stars located in the HRD between sdOB and WR-stars. Several thousands of such stars are expected to exist in the Galaxy, but none of them have been identified so far.
Aims:We aim to provide comprehensive predictions of the numbers and fundamental properties of He-stars and their companions in the Galaxy. This is a necessary first step to guide observations, to enable a comparison between evolutionary models and observed populations, and to determine the feedback of He-stars in the Galaxy.
Methods: We expanded the previously considered space of parameters of progenitors of He-stars and applied a population synthesis based on a grid of models computed by the code MESA.
Results:The estimated number of Galactic binaries hosting (1 – 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT He-stars is ≃20 000similar-to-or-equalsabsent20000\simeq 20\,000≃ 20 000; it declines to
≃3 000similar-to-or-equalsabsent3000\simeq 3\,000≃ 3 000 for mass
  ∼>superscriptsimilar-to\buildrel>\over{\sim}start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG > end_ARG end_RELOP   2 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. The decisive factor that defines the number of
He-stars is runaway mass loss after Roche lobe overflow by primary components, resulting in formation of common envelopes and merger of components. He-stars are much less numerous than expected, since a fraction of close binaries with M1,0∼<superscriptsimilar-tosubscript𝑀10absentM_{1,0}\ {\raise-2.15277pt\hbox{$\buildrel<\over{\sim}$}}\ italic_M start_POSTSUBSCRIPT 1 , 0 end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG < end_ARG end_RELOP(5 - 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT produce subdwarfs with masses ≲1less-than-or-similar-toabsent1\lesssim 1≲ 1 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.
Conclusions:Overwhelming majority of He-stars reside in binaries with an early-type companions and can be identified neither by the UV excess nor by emission features.
The large periods of a significant fraction of binaries hosting stripped stars (  ∼>superscriptsimilar-to\buildrel>\over{\sim}start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG > end_ARG end_RELOP   several hundred days) also hamper their discovery.","['Stars: evolution –', 'Stars: mass-loss –', 'Methods: numerical']",[]
"We show that there exists a complete local Noetherian normal domain of prime characteristic whose perfection is a non-coherent GCD domain, answering a question of Patankar in the negative concerning characterizations of F𝐹Fitalic_F-coherent rings. This recovers and extends a result of Glaz using tight closure methods.",[],[]
,[],[]
"We investigate quadratic quasinormal mode coupling in black hole spacetime through numerical simulations of single perturbed black holes using both numerical relativity and second-order black hole perturbation theory.
Focusing on the dominant ℓ=|m|=2ℓ𝑚2\ell=|m|=2roman_ℓ = | italic_m | = 2 quadrupolar modes, we find good agreement (within ∼10%similar-toabsentpercent10\sim 10\%∼ 10 %) between these approaches, with discrepancies attributed to truncation error and uncertainties from mode fitting.
Our results align with earlier studies extracting the coupling coefficients from select binary black hole merger simulations, showing consistency for the same remnant spins.
Notably, the coupling coefficient is insensitive to a diverse range of initial data, including configurations that led to a significant (up to 5%percent55\%5 %) increase in the remnant black hole mass.
These findings present opportunities for testing the nonlinear dynamics of general relativity with ground-based gravitational wave observatories.
Lastly, we provide evidence of a bifurcation in coupling coefficients between counter-rotating and co-rotating quasinormal modes as black hole spin increases.",[],"['Germany', 'Canada']"
"Urban air mobility (UAM), a transformative concept for the transport of passengers and cargo, faces several integration challenges in complex urban environments. Community acceptance of aircraft noise is among the most noticeable of these challenges when launching or scaling up a UAM system. Properly managing community noise is fundamental to establishing a UAM system that is environmentally and socially sustainable. In this work, we develop a holistic and equitable approach to manage UAM air traffic and its community noise impact in urban environments. The proposed approach is a hybrid approach that considers a mix of different noise mitigation strategies, including limiting the number of operations, cruising at higher altitudes, and ambient noise masking. We tackle the problem through the lens of network system control and formulate a multi-objective optimization model for managing traffic flow in a multi-layer UAM network while concurrently pursuing demand fulfillment, noise control, and energy saving. Further, we use a social welfare function in the optimization model as the basis for the efficiency-fairness trade-off in both demand fulfillment and noise control. We apply the proposed approach to a comprehensive case study in the city of Austin and perform design trade-offs through both visual and quantitative analyses.",[],[]
"This work is about a partition problem which is an instance of the distance magic graph labeling problem.
Given positive integers n,k𝑛𝑘n,kitalic_n , italic_k and p1≤p2≤⋯≤pksubscript𝑝1subscript𝑝2⋯subscript𝑝𝑘p_{1}\leq p_{2}\leq\cdots\leq p_{k}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ ⋯ ≤ italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that p1+⋯+pk=nsubscript𝑝1⋯subscript𝑝𝑘𝑛p_{1}+\cdots+p_{k}=nitalic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ⋯ + italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n and k𝑘kitalic_k divides ∑i=1nisuperscriptsubscript𝑖1𝑛𝑖\sum_{i=1}^{n}i∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_i, we study the problem of characterizing the cases where it is possible to find a partition of the set {1,2,…,n}12…𝑛\{1,2,\ldots,n\}{ 1 , 2 , … , italic_n } into k𝑘kitalic_k subsets of respective sizes p1,…,pksubscript𝑝1…subscript𝑝𝑘p_{1},\dots,p_{k}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, such that the element sum in each subset is equal.
Using a computerized search we found examples showing that the necessary condition, ∑i=1p1+⋯+pj(n−i+1)≥j⁢(n+12)/ksuperscriptsubscript𝑖1subscript𝑝1⋯subscript𝑝𝑗𝑛𝑖1𝑗binomial𝑛12𝑘\sum_{i=1}^{p_{1}+\cdots+p_{j}}(n-i+1)\geq j{\binom{n+1}{2}}/k∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ⋯ + italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_n - italic_i + 1 ) ≥ italic_j ( FRACOP start_ARG italic_n + 1 end_ARG start_ARG 2 end_ARG ) / italic_k for all j=1,…,k𝑗1…𝑘j=1,\ldots,kitalic_j = 1 , … , italic_k,
is not generally sufficient, refuting a past conjecture.
Moreover, we show that there are infinitely many such counter-examples.
The question whether there is a simple characterization is left open and for all we know the corresponding decision problem might be NP-complete.",[],[]
"We have used data from the Outer Galaxy High-Resolution Survey (OGHReS) to refine the velocities, distances, and physical properties of a large sample of 3 584 clumps detected in far infrared/submillimetre emission in the Hi-GAL survey located in the ℓ=250⁢°−280⁢°ℓ250°280°\ell=250\degr-280\degrroman_ℓ = 250 ° - 280 ° region of the Galactic plane. Using 1212{}^{12}start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPTCO and 1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCO spectra, we have determined reliable velocities to 3 412 clumps (95 per cent of the sample). In comparison to the velocities from the Hi-GAL catalogue, we find good agreement for 80 per cent of the sample (within 5 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT). Using the higher resolution and sensitivity of OGHReS has allowed us to correct the velocity for 632 clumps and provide velocities for 687 clumps for which no velocity had been previously allocated. The velocities are used with a rotation curve to refine the distances to the clumps and to calculate the clumps’ properties using a distance-dependent gas-to-dust ratio. We have determined reliable physical parameters for 3 200 outer Galaxy dense clumps (∼similar-to\sim∼90 per cent of the Hi-GAL sources in the region). We find a trend of decreasing luminosity-to-mass ratio with increasing Galactocentric distance, suggesting the star formation efficiency is lower in the outer Galaxy or that it is resulting in more lower mass stars than in the inner Galaxy. We also find a similar surface density for protostellar clumps located in the inner and outer Galaxy, revealing that the surface density requirements for star formation are the same across the Galactic disc.",[],[]
"Federated Learning (FL) is a machine-learning approach enabling collaborative model training across multiple decentralized edge devices that hold local data samples, all without exchanging these samples. This collaborative process occurs under the supervision of a central server orchestrating the training or via a peer-to-peer network. The significance of FL is particularly pronounced in industries such as healthcare and finance, where data privacy holds paramount importance.
However, training a model under the Federated learning setting brings forth several challenges, with one of the most prominent being the heterogeneity of data distribution among the edge devices. The data is typically non-independently and non-identically distributed (non-IID), thereby presenting challenges to model convergence. This report delves into the issues arising from non-IID and heterogeneous data and explores current algorithms designed to address these challenges.",[],[]
"A degree one element of the Orlik-Solomon algebra of a
hyperplane arrangement defines a cochain complex
known as the Aomoto complex. The Aomoto complex
can be considerd as the “linear approximation” of the
twisted cochain complex with coefficients in
a complex rank one local system.
In this paper, we discuss q𝑞qitalic_q-deformations of the Aomoto complex.
The q𝑞qitalic_q-deformation is defined by replacing the entries of
representation matrices of the coboundary maps with their
q𝑞qitalic_q-analogues.
While the resulting maps do not generally defines cochain complexes,
for certain special basis derived from
real structures, the q𝑞qitalic_q-deformation becomes again
a cochain complex.
Moreover, it exhibits universality in the sense that
any specialization of q𝑞qitalic_q to a complex number yields
the cochain complex computing the corresponding local system
cohomology group.","['Hyperplane arrangements', 'Aomoto complex', 'local system cohomology', 'q𝑞qitalic_q-deformation']",[]
"Nowadays, dialogue systems are used in many fields of industry and research. There are successful instances of these systems, such as Apple Siri, Google Assistant, and IBM Watson. Task-oriented dialogue system is a category of these, that are used in specific tasks. They can perform tasks such as booking plane tickets or making restaurant reservations. Shopping is one of the most popular areas on these systems. The bot replaces the human salesperson and interacts with the customers by speaking. To train the models behind the scenes of these systems, annotated data is needed. In this paper, we developed a dataset of dialogues in the Persian language through crowd-sourcing. We annotated these dialogues to train a model. This dataset contains nearly 22k utterances in 15 different domains and 1061 dialogues. This is the largest Persian dataset in this field, which is provided freely so that future researchers can use it. Also, we proposed some baseline models for natural language understanding (NLU) tasks. These models perform two tasks for NLU: intent classification and entity extraction. The F-1 score metric obtained for intent classification is around 91% and for entity extraction is around 93%, which can be a baseline for future research.



Keywords: Task-oriented dialogue systems, Shopping systems, Persian dataset, Annotating, Crowd-sourcing, Chatbots, Natural Language Understanding (NLU)",[],[]
"This report on axisymmetric ultraspherical/Gegenbauer polynomials [Geg77] and their use in Ambisonic directivity design in 2D and 3D presents an alternative mathematical formalism to what can be read in, e.g., my and Matthias Frank’s book on Ambisonics or Jérôme Daniel’s thesis, Gary Elko’s differential array book chapters, or Boaz Rafaely’s spherical microphone array book. 

My original—but discarded—intention was to already include ultraspherical polynomials in the Ambisonics book to pursue a simple thought: retrieving suitable axisymmetric continuous-direction functions that serve the discrete-direction metrics for experimental psychoacoustic findings in spatial audio uniformly, for any number DD\mathrm{D}roman_D of space dimensions, of course typically D=2,3D23\mathrm{D}=2,3roman_D = 2 , 3. But the cost for this natural way to understand spherical/circular polynomials and their directional sampling was too high. This would have required carrying out both the derivations of two entire formalisms from scratch, the ultraspherical/Gegenbauer polynomials and the circular/spherical harmonics, of which only the latter ones define the Ambisonic format. 

Nevertheless, ultraspherical/Gegenbauer polynomials are highly valuable when designing axisymmetric beams and understanding spherical t𝑡titalic_t designs that this report will shed some light on what circular, spherical, and ultraspherical axisymmetric polynomials are. While mathematically interesting by themselves already, they can be useful in spherical beamforming as described in the literature on spherical and differential microphone arrays, e.g. [Raf19, Elk00, Elk04].
What are polynomials bases for axisymmetric functions, say axisymmetric harmonics (or ultraspherical or Gegenbauer) polynomials? How can they be utilized to define Ambisonic order weightings or spherical beamformers? 

In this report, these ultraspherical/Gegenbauer polynomials will be used to uniformly derive for arbitrary dimensions DD\mathrm{D}roman_D the various directivity designs or Ambisonic order weightings known from literature: max-DI/basic [Dan01], max-rEsubscript𝑟Er_{\mathrm{E}}italic_r start_POSTSUBSCRIPT roman_E end_POSTSUBSCRIPT [Dan01], supercardioid [Raf19, Elk00, Elk04], cardioid/inphase [Dan01]. Is there a way to relate higher-order cardioids and supercardioids? How could one define directivity patterns with an on-axis flatness constraint?",[],[]
"By 2050, it is predicted that there will be 9 billion people on the planet, which will call for more production, lower costs, and the preservation of natural resources. It is anticipated that atypical occurrences and climate change will pose severe risks to agricultural output. It follows that a 70% or more significant rise in food output is anticipated. Smart farming, often known as agriculture 4.0, is a tech-driven revolution in agriculture with the goal of raising industry production and efficiency. Four primary trends are responsible for it: food waste, climate change, population shifts, and resource scarcity. The agriculture industry is changing as a result of the adoption of emerging technologies. Using cutting-edge technology like IoT, AI, and other sensors, smart farming transforms traditional production methods and international agricultural policies. The objective is to establish a value chain that is optimized to facilitate enhanced monitoring and decreased labor expenses. The agricultural sector has seen tremendous transformation as a result of the fourth industrial revolution, which has combined traditional farming methods with cutting-edge technology to increase productivity, sustainability, and efficiency. To effectively utilize the potential of technology gadgets in the agriculture sector, collaboration between governments, private sector entities, and other stakeholders is necessary. This paper covers Agriculture 4.0, looks at its possible benefits and drawbacks of the implementation methodologies, compatibility, reliability, and investigates the several digital tools that are being utilized to change the agriculture industry and how to mitigate the challenges.","['Smart', 'Farming', 'Agriculture 4.0', 'Precision', 'Farming', 'Sustainable', 'IoT', 'Security', 'Sensor']",[]
"This paper proposes an algorithm to calculate the maximal probability of unsafety with respect to trajectories of a stochastic process and a hazard set. The unsafe probability estimation problem is cast as a primal-dual pair of infinite-dimensional linear programs in occupation measures and continuous functions. This convex relaxation is nonconservative (to the true probability of unsafety) under compactness and regularity conditions in dynamics. The continuous-function linear program is linked to existing probability-certifying barrier certificates of safety.
Risk contours for initial conditions of the stochastic process may be generated by suitably modifying the objective of the continuous-function program, forming an interpretable and visual representation of stochastic safety for test initial conditions. All infinite-dimensional linear programs are truncated to finite dimension by the Moment-Sum-of-Squares hierarchy of semidefinite programs. Unsafe-probability estimation and risk contours are generated for example stochastic processes.",[],[]
"Deep learning is the current de facto state of the art in tomographic imaging. A common approach is to feed the result of a simple inversion, for example the backprojection, to a convolutional neural network (CNN) which then computes the reconstruction. Despite strong results on “in-distribution” test data similar to the training data, backprojection from sparse-view data delocalizes singularities, so these approaches require a large receptive field to perform well. As a consequence, they overfit to certain global structures which leads to poor generalization on out-of-distribution (OOD) samples. Moreover, their memory complexity and training time scale unfavorably with image resolution, making them impractical for application at realistic clinical resolutions, especially in 3D: a standard U-Net requires a substantial 140GB of memory and 2600 seconds per epoch on a research-grade GPU when training on 1024 ×\times× 1024 images. In this paper, we introduce Glimpse, a local processing neural network for computed tomography which reconstructs a pixel value by feeding only the measurements associated with the neighborhood of the pixel to a simple MLP. While achieving comparable or better performance with successful CNNs like the U-Net on in-distribution test data, Glimpse significantly outperforms them on OOD samples while maintaining a memory footprint almost independent of image resolution; 5GB memory suffices to train on 1024 ×\times× 1024 images. Further, we built Glimpse to be fully differentiable, which enables feats such as recovery of accurate projection angles if they are out of calibration.","['Deep', 'Learning', 'Computed', 'Tomography', 'MLP', 'Uncalibrated', 'Imaging']",[]
"For a space X𝑋Xitalic_X let 𝒦⁢(X)𝒦𝑋\mathcal{K}(X)caligraphic_K ( italic_X ) be the set of compact subsets of X𝑋Xitalic_X ordered by inclusion. A map ϕ:𝒦⁢(X)→𝒦⁢(Y):italic-ϕ→𝒦𝑋𝒦𝑌\phi:\mathcal{K}(X)\to\mathcal{K}(Y)italic_ϕ : caligraphic_K ( italic_X ) → caligraphic_K ( italic_Y ) is a relative Tukey quotient if it carries compact covers to compact covers. When there is such a Tukey quotient write (X,𝒦⁢(X))≥T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))\geq_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ), and write (X,𝒦⁢(X))=T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))=_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) = start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ) if (X,𝒦⁢(X))≥T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))\geq_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ) and vice versa.
We investigate the initial structure of pairs (X,𝒦⁢(X))𝑋𝒦𝑋(X,\mathcal{K}(X))( italic_X , caligraphic_K ( italic_X ) ) under the relative Tukey order, focussing on the case of separable metrizable spaces. Connections are made to Menger spaces.
Applications are given demonstrating the diversity of free topological groups, and related free objects, over separable metrizable spaces. It is shown a topological group G𝐺Gitalic_G has the countable chain condition if it is either σ𝜎\sigmaitalic_σ-pseudocompact or for some separable metrizable M𝑀Mitalic_M, we have 𝒦⁢(M)≥T(G,𝒦⁢(G))subscript𝑇𝒦𝑀𝐺𝒦𝐺\mathcal{K}(M)\geq_{T}(G,\mathcal{K}(G))caligraphic_K ( italic_M ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_G , caligraphic_K ( italic_G ) ).
Keywords: Tukey order, compact covers, separable metrizable space.
MSC Classification: 03E04, 06A07, 22A05, 54D30, 54D45, 54E35, 54H11.",[],[]
"We study the structure of the asymptotic expansion of the probability that a
combinatorial object is connected.
We show that the coefficients appearing in those asymptotics are integers and
can be interpreted as the counting sequences of other derivative
combinatorial classes.
The general result applies to rapidly growing combinatorial structures, which we
call gargantuan, that also admit a sequence decomposition.
The result is then applied to several models of graphs, of surfaces
(square-tiled surfaces, combinatorial maps), and to geometric models of
higher dimension (constellations, graph encoded manifolds).
The corresponding derivative combinatorial classes are irreducible
(multi)tournaments, indecomposable (multi)permutations and indecomposable
perfect (multi)matchings.",[],[]
"High-frequency wide-bandwidth cellular communications over mmW and sub-THz offer the opportunity for high data rates, however, it also presents high pathloss, resulting in limited coverage. To mitigate the coverage limitations, high-gain beamforming is essential. Implementation of beamforming involves a large number of antennas, which introduces analog beam constraint, i.e., only one frequency-flat beam is generated per transceiver chain (TRx). Recently introduced joint phase-time array (JPTA) architecture, which utilizes both true time delay (TTD) units and phase shifters (PSs), alleviates analog beam constraint by creating multiple frequency-dependent beams per TRx, for scheduling multiple users at different directions in a frequency-division manner. One class of previous studies offered solutions with “rainbow” beams, which tend to allocate a small bandwidth per beam direction. Another class focused on uniform linear array (ULA) antenna architecture, whose frequency-dependent beams were designed along a single axis of either azimuth or elevation direction. In this paper, we present a novel 3D beamforming codebook design aimed at maximizing beamforming gain to steer radiation toward desired azimuth and elevation directions, as well as across sub-bands partitioned according to scheduled users’ bandwidth requirements. We provide both analytical solutions and iterative algorithms to design the PSs and TTD units for a desired subband beam pattern. Through simulations of the beamforming gain, we observe that our proposed solutions outperform the state-of-the-art solutions reported elsewhere.
††This work was done in part while O. Yildiz was an intern at Samsung Research America.","['True time delay', 'beamforming', 'millimeter wave', '3D', 'joint phase-time array', 'uniform planar array']",[]
"Important: This paper does NOT advocate for the use of large language models (LLMs) in therapeutic settings, NOR establish their readiness. Instead, our objective is to enable systematic characterization and assessment of the behavior of current LLMs when they are used for therapy. 
††footnotetext: * Equal contribution
The emergence of ChatGPT and other large language models (LLMs) has greatly increased interest in utilizing LLMs as therapists to support individuals struggling with mental health challenges. However, due to the lack of systematic studies, our understanding of how LLM therapists behave, i.e., ways in which they respond to clients, is significantly limited. Understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences. In this paper, we propose Bolt, a novel computational framework to study the conversational behavior of LLMs when employed as therapists. We develop an in-context learning method to quantitatively measure the behavior of LLMs based on 13 different psychotherapy techniques including reflections, questions, solutions, normalizing, and psychoeducation. Subsequently, we compare the behavior of LLM therapists against that of high- and low-quality human therapy, and study how their behavior can be modulated to better reflect behaviors observed in high-quality therapy. Our analysis of GPT and Llama-variants reveals that these LLMs often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions, which is against typical recommendations. At the same time, unlike low-quality therapy, LLMs reflect significantly more upon clients’ needs and strengths. Our analysis framework suggests that despite the ability of LLMs to generate anecdotal examples that appear similar to human therapists, LLM therapists are currently not fully consistent with high-quality care, and thus require additional research to ensure quality care.",[],[]
"We consider a toy model for the study of monitored dynamics in a many-body quantum systems. We study the stochastic Schrodinger equation resulting from the continuous monitoring with a rate ΓΓ\Gammaroman_Γ of a random hermitian operator chosen at every time from the gaussian unitary ensemble (GUE). Due to invariance by unitary transformations, the dynamics of the eigenvalues {λα}α=1nsuperscriptsubscriptsubscript𝜆𝛼𝛼1𝑛\{\lambda_{\alpha}\}_{\alpha=1}^{n}{ italic_λ start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_α = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT of the density matrix can be decoupled from that of the eigenvectors. Thus, stochastic equations are derived that exactly describe the dynamics of λ𝜆\lambdaitalic_λ’s. We consider two regimes: in the presence of an extra dephasing term, which can be generated by imperfect quantum measurements, the density matrix has a stationary distribution, and we show that in the limit of large sizes the distribution of λ𝜆\lambdaitalic_λ’s is described by an inverse Marchenko Pastur distribution.
In the case of perfect measurements instead,
purification eventually occurs and we focus on finite-time dynamics. In this case, remarkably, we find an exact solution for the joint probability distribution of λ𝜆\lambdaitalic_λ’s at each time t𝑡titalic_t and for each size n𝑛nitalic_n. Two relevant regimes emerge: at small times t⁢Γ=O⁢(1)𝑡Γ𝑂1t\Gamma=O(1)italic_t roman_Γ = italic_O ( 1 ), the spectrum is in a Coulomb gas regime, with a well-defined continuous spectral distribution in the limit of n→∞→𝑛n\to\inftyitalic_n → ∞. In that case, all moments of the density matrix become self-averaging and it is possible to characterize the entanglement spectrum exactly. In the limit of large times t⁢Γ=O⁢(n)𝑡Γ𝑂𝑛t\Gamma=O(n)italic_t roman_Γ = italic_O ( italic_n ) one enters instead a regime in which the eigenvalues are exponentially separated log⁡(λα/λβ)=O⁢(Γ⁢t/n)subscript𝜆𝛼subscript𝜆𝛽𝑂Γ𝑡𝑛\log(\lambda_{\alpha}/\lambda_{\beta})=O(\Gamma t/n)roman_log ( italic_λ start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT / italic_λ start_POSTSUBSCRIPT italic_β end_POSTSUBSCRIPT ) = italic_O ( roman_Γ italic_t / italic_n ), but fluctuations ∼O⁢(Γ⁢t/n)similar-toabsent𝑂Γ𝑡𝑛\sim O(\sqrt{\Gamma t/n})∼ italic_O ( square-root start_ARG roman_Γ italic_t / italic_n end_ARG ) play an essential role. We are still able to characterize the asymptotic behaviors of entanglement entropy in this regime.",[],['France']
,[],[]
"We introduce Starcoder, a graph-aware autoencoder ensemble framework, with associated formalisms and tooling, designed to facilitate deep learning for scholarship in the humanities. By composing sub-architectures to produce a model isomorphic to a humanistic domain we maintain interpretability while providing function signatures for each sub-architectural choice, allowing both traditional and computational researchers to collaborate without disrupting established practices. We illustrate a practical application of our approach to a historical study of the American post-Atlantic slave trade, and make several specific technical contributions: a novel hybrid graph-convolutional autoencoder mechanism, batching policies for common graph topologies, and masking techniques for particular use-cases. The effectiveness of the framework for broadening participation of diverse domains is demonstrated by a growing suite of two dozen studies, both collaborations with humanists and established tasks from machine learning literature, spanning a variety of fields and data modalities. We make performance comparisons of several different architectural choices and conclude with an ambitious list of imminent next steps for this research.","['Machine', 'Learning', 'Humanities']",[]
"Neural Radiance Fields (NeRF) has shown its remarkable performance in neural rendering-based novel view synthesis. However, NeRF suffers from severe visual quality degradation when the input images have been captured under imperfect conditions, such as poor illumination, defocus blurring and lens aberrations. Especially, defocus blur is quite common in the images when they are normally captured using cameras. Although few recent studies have proposed to render sharp images of considerably high-quality, yet they still face many key challenges. In particular, those methods have employed a Multi-Layer Perceptron (MLP) based NeRF which requires tremendous computational time. To overcome these shortcomings, this paper proposes a novel technique Sharp-NeRF—a grid-based NeRF that renders clean and sharp images from the input blurry images within a half an hour training. To do so, we used several grid-based kernels to accurately model the sharpness/blurriness of the scene. The sharpness level of the pixels is computed to learn the spatially varying blur kernels. We have conducted experiments on the benchmarks consisting of blurry images and have evaluated full-reference and non-reference metrics. The qualitative and quantitative results have revealed that our approach renders the sharp novel views with vivid colors and fine details, and it has considerably faster training time than the previous works. Our code is available at https://github.com/benhenryL/SharpNeRF.",[],[]
"Resource allocation of wide-area internet networks is inherently a combinatorial optimization problem that if solved quickly, could provide near real-time adaptive control of internet-protocol traffic ensuring increased network efficacy and robustness, while minimizing energy requirements coming from power-hungry transceivers. In recent works we demonstrated how such a problem could be cast as a quadratic unconstrained binary optimization (QUBO) problem that can be embedded onto the D-Wave Advantage™  quantum annealer system, demonstrating proof of principle. Our initial studies left open the possibility for improvement of D-Wave solutions via judicious choices of system run parameters. Here we report on our investigations for optimizing these system parameters, and how we incorporate machine learning (ML) techniques to further improve on the quality of solutions. In particular, we use the Hamming distance to investigate correlations between various system-run parameters and solution vectors. We then apply a decision tree neural network (NN) to learn these correlations, with the goal of using the neural network to provide further guesses to solution vectors. We successfully implement this NN in a simple integer linear programming (ILP) example, demonstrating how the NN can fully map out the solution space was not captured by D-Wave. We find, however, for the 3-node network problem the NN is not able to enhance the quality of space of solutions.
\helveticabold


1 Keywords:

discrete optimization,
integer linear program,
machine learning,
quantum annealing,
quantum computing,
resource allocation,
wide-area networks",[],[]
"We prove that every partially ordered set on n𝑛nitalic_n elements
contains k𝑘kitalic_k subsets A1,A2,…,Aksubscript𝐴1subscript𝐴2…subscript𝐴𝑘A_{1},A_{2},\dots,A_{k}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that either each of these subsets has size Ω⁢(n/k5)Ω𝑛superscript𝑘5\Omega(n/k^{5})roman_Ω ( italic_n / italic_k start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT ) and, for every i<j𝑖𝑗i<jitalic_i < italic_j, every element in Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is less than or equal to every element in Ajsubscript𝐴𝑗A_{j}italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, or each of these subsets has size Ω⁢(n/(k2⁢log⁡n))Ω𝑛superscript𝑘2𝑛\Omega(n/(k^{2}\log n))roman_Ω ( italic_n / ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n ) )
and, for every i≠j𝑖𝑗i\not=jitalic_i ≠ italic_j, every element in Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is incomparable with every element in Ajsubscript𝐴𝑗A_{j}italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for i≠j𝑖𝑗i\neq jitalic_i ≠ italic_j. This answers a question of the first author from 2006. As a corollary, we prove for each positive integer hℎhitalic_h there is Chsubscript𝐶ℎC_{h}italic_C start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT such that for any hℎhitalic_h partial orders <1,<2,…,<hsubscript1subscript2…subscriptℎ<_{1},<_{2},\dots,<_{h}< start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , < start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , < start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT on a set of n𝑛nitalic_n elements, there exists k𝑘kitalic_k subsets A1,A2,…,Aksubscript𝐴1subscript𝐴2…subscript𝐴𝑘A_{1},A_{2},\dots,A_{k}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT each of size at least n/(k⁢log⁡n)Ch𝑛superscript𝑘𝑛subscript𝐶ℎn/(k\log n)^{C_{h}}italic_n / ( italic_k roman_log italic_n ) start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT end_POSTSUPERSCRIPT such that for each partial order <ℓsubscriptℓ<_{\ell}< start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT, either a1<ℓa2<ℓ⋯<ℓaksubscriptℓsubscript𝑎1subscript𝑎2subscriptℓ⋯subscriptℓsubscript𝑎𝑘a_{1}<_{\ell}a_{2}<_{\ell}\dots<_{\ell}a_{k}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ⋯ < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT for any tuple of elements (a1,a2,…,ak)∈A1×A2×⋯×Aksubscript𝑎1subscript𝑎2…subscript𝑎𝑘subscript𝐴1subscript𝐴2⋯subscript𝐴𝑘(a_{1},a_{2},\dots,a_{k})\in A_{1}\times A_{2}\times\dots\times A_{k}( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ∈ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × ⋯ × italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, or a1>ℓa2>ℓ⋯>ℓaksubscriptℓsubscript𝑎1subscript𝑎2subscriptℓ⋯subscriptℓsubscript𝑎𝑘a_{1}>_{\ell}a_{2}>_{\ell}\dots>_{\ell}a_{k}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ⋯ > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT for any (a1,a2,…,ak)∈A1×A2×⋯×Aksubscript𝑎1subscript𝑎2…subscript𝑎𝑘subscript𝐴1subscript𝐴2⋯subscript𝐴𝑘(a_{1},a_{2},\dots,a_{k})\in A_{1}\times A_{2}\times\dots\times A_{k}( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ∈ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × ⋯ × italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, or aisubscript𝑎𝑖a_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is incomparable with ajsubscript𝑎𝑗a_{j}italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for any i≠j𝑖𝑗i\neq jitalic_i ≠ italic_j, ai∈Aisubscript𝑎𝑖subscript𝐴𝑖a_{i}\in A_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and aj∈Ajsubscript𝑎𝑗subscript𝐴𝑗a_{j}\in A_{j}italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. This improves on a 2009 result of Pach and the first author motivated by problems in discrete geometry.",[],[]
"We consider the problem of sampling discrete field configurations ϕitalic-ϕ\phiitalic_ϕ from the Boltzmann distribution [d⁢ϕ]⁢Z−1⁢e−S⁢[ϕ]delimited-[]𝑑italic-ϕsuperscript𝑍1superscript𝑒𝑆delimited-[]italic-ϕ[d\phi]Z^{-1}e^{-S[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S [ italic_ϕ ] end_POSTSUPERSCRIPT, where S𝑆Sitalic_S is the lattice-discretization of the continuous Euclidean action 𝒮𝒮\mathcal{S}caligraphic_S of some quantum field theory. Since such densities arise as the approximation of the underlying functional density [𝒟⁢ϕ⁢(x)]⁢𝒵−1⁢e−𝒮⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscript𝒵1superscript𝑒𝒮delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}^{-1}e^{-\mathcal{S}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator 𝒱tsubscript𝒱𝑡\mathcal{V}_{t}caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT whose time integral provides a mapping between the functional distributions of the free theory [𝒟⁢ϕ⁢(x)]⁢𝒵0−1⁢e−𝒮0⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscriptsubscript𝒵01superscript𝑒subscript𝒮0delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}_{0}^{-1}e^{-\mathcal{S}_{0}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT and of the target theory [𝒟⁢ϕ⁢(x)]⁢𝒵−1⁢e−𝒮⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscript𝒵1superscript𝑒𝒮delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}^{-1}e^{-\mathcal{S}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT.
Whenever a particular lattice is chosen, the operator 𝒱tsubscript𝒱𝑡\mathcal{V}_{t}caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT can be discretized to a finite dimensional, time-dependent vector field Vtsubscript𝑉𝑡V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT which in turn induces a continuous normalizing flow between finite dimensional distributions over the chosen lattice. This flow can then be trained to be a diffeormorphism between the discretized free and target theories [d⁢ϕ]⁢Z0−1⁢e−S0⁢[ϕ]delimited-[]𝑑italic-ϕsuperscriptsubscript𝑍01superscript𝑒subscript𝑆0delimited-[]italic-ϕ[d\phi]Z_{0}^{-1}e^{-S_{0}[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT [ italic_ϕ ] end_POSTSUPERSCRIPT, [d⁢ϕ]⁢Z−1⁢e−S⁢[ϕ]delimited-[]𝑑italic-ϕsuperscript𝑍1superscript𝑒𝑆delimited-[]italic-ϕ[d\phi]Z^{-1}e^{-S[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S [ italic_ϕ ] end_POSTSUPERSCRIPT. We run experiments on the ϕ4superscriptitalic-ϕ4\phi^{4}italic_ϕ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT-theory to explore to what extent such operator-based flow architectures generalize to lattice sizes they were not trained on and show that pretraining on smaller lattices can lead to speedup over training only a target lattice size.",[],[]
"The dichromatic number χ⁢(G→)𝜒→𝐺\chi(\vec{G})italic_χ ( over→ start_ARG italic_G end_ARG ) of a digraph G→→𝐺\vec{G}over→ start_ARG italic_G end_ARG is the minimum number of colors needed to color the vertices V⁢(G→)𝑉→𝐺V(\vec{G})italic_V ( over→ start_ARG italic_G end_ARG ) in such a way that no monochromatic directed cycle is obtained. In this note, for any k∈ℕ𝑘ℕk\in\mathbb{N}italic_k ∈ blackboard_N, we give a simple construction of tournaments with dichromatic number exactly equal to k𝑘kitalic_k. The proofs are based on a combinatorial lemma on partitioning a checkerboard which may be of independent interest. We also generalize our finite construction to give an elementary construction of a complete digraph of cardinality equal to the cardinality of ℝℝ\mathbb{R}blackboard_R and having an uncountable dichromatic number. Furthermore, we also construct an oriented balanced complete n𝑛nitalic_n-partite graph K→n(m)subscriptsuperscript→𝐾𝑚𝑛\vec{K}^{(m)}_{n}over→ start_ARG italic_K end_ARG start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, such that the minimum number of colors needed to color its vertices such that there is no monochromatic directed triangle is greater than or equal to n⁢m/(n+2⁢m−2)𝑛𝑚𝑛2𝑚2nm/(n+2m-2)italic_n italic_m / ( italic_n + 2 italic_m - 2 ).",[],[]
"Control design of autonomous vehicles (AVs) has mostly focused on achieving a prespecified goal for an individually controlled AV or for a swarm of cooperatively controlled AVs. However, the impact of autonomous driving on human-driven vehicles (HVs) has been largely ignored in AV controller synthesis, which could result in egoistic AV behavior detrimental to the safety of passengers and surrounding traffic. In this study we develop a general framework for socially compliant control design of AVs with a useful metric of social psychology, called social value orientation (SVO), allowing AVs to leverage their impact on the behavior of the following HVs. This is critical since AVs that behave in a socially compliant manner enable human drivers to comprehend their actions and respond appropriately. Within the proposed framework, we define the utilities of the controlled AV and its following vehicle, to be maximized in a weighted fashion determined by the AV’s SVO. The utility maximization covers an array of design objectives given the goal of the AV and the benefits for the following HV stemming from the courtesy of socially compliant AV controls. An optimal control problem is then formulated to maximize the utility function defined, which is numerically solved using Pontryagin’s minimum principle with optimality guarantees. The methodology developed is applied to synthesize socially compliant control for eco-driving of AVs. A set of numerical results are presented to show the mechanism and effectiveness of the proposed approach using real-world experimental data collected on Highway 55 in Minnesota.",[],[]
"We give a brief survey of the results on coarse or uniform embeddings of Banach spaces into c0⁢(Γ)subscript𝑐0Γc_{0}(\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ ) and the point character of Banach spaces.
In the process we prove several new results in this direction (for example we determine the point character of the spaces Lp⁢(μ)subscript𝐿𝑝𝜇L_{p}(\mu)italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_μ ), 1≤p≤21𝑝21\leq p\leq 21 ≤ italic_p ≤ 2)
solving open problems posed by C. Avart, P. Komjáth, and V. Rödl and by G. Godefroy, G. Lancien, and V. Zizler.
In particular, we show that X=Lp⁢(μ)𝑋subscript𝐿𝑝𝜇X=L_{p}(\mu)italic_X = italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_μ ), 1≤p<∞1𝑝1\leq p<\infty1 ≤ italic_p < ∞, bi-Lipschitz embeds into c0⁢(Γ)subscript𝑐0Γc_{0}(\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ ) if and only if dens⁡X<ωωdens𝑋subscript𝜔𝜔\operatorname{dens}X<\omega_{\omega}roman_dens italic_X < italic_ω start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT.","['point character', 'uniform embeddings into c0\u2062(Γ)subscript𝑐0Γc_{0}(\\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ )']",[]
"The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. Grounded in theory of multimedia learning, this paper explores the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs could range from content creation to tailored support for learning, fostering competencies in scientific practices, and providing assessment and feedback. These scenarios are not limited to text-based and uni-modal formats but can be multimodal, increasing thus personalization, accessibility, and potential learning effectiveness. Besides many opportunities, challenges such as data protection and ethical considerations become more salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educator’s role, ensuring thus an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs on the evolving role of educators and to extend the discourse beyond science education to other disciplines. Through the exploration of potentials, challenges, and future implications, we aim to contribute to a preliminary understanding of the transformative trajectory of MLLMs in science education and beyond.","['Artificial', 'Intelligence', 'Large', 'Language', 'Models (LLMs)', 'ChatGPT', 'Multimodal', 'Learning', 'Cognitive', 'Theory of', 'Multimedia', 'Learning', 'Science', 'Education']",['Germany']
"Despite significant progress in deep learning-based optical flow methods, accurately estimating large displacements and repetitive patterns remains a challenge. The limitations of local features and similarity search patterns used in these algorithms contribute to this issue. Additionally, some existing methods suffer from slow runtime and excessive graphic memory consumption. To address these problems, this paper proposes a novel approach based on the RAFT framework. The proposed Attention-based Feature Localization (AFL) approach incorporates the attention mechanism to handle global feature extraction and address repetitive patterns. It introduces an operator for matching pixels with corresponding counterparts in the second frame and assigning accurate flow values. Furthermore, an Amorphous Lookup Operator (ALO) is proposed to enhance convergence speed and improve RAFT’s ability to handle large displacements by reducing data redundancy in its search operator and expanding the search space for similarity extraction. The proposed method, Efficient RAFT (Ef-RAFT), achieves significant improvements of 10% on the Sintel dataset and 5% on the KITTI dataset over RAFT. Remarkably, these enhancements are attained with a modest 33% reduction in speed and a mere 13% increase in memory usage. The code is available at: https://github.com/n3slami/Ef-RAFT","['Optical', 'Flow', 'Large', 'Displacement', 'Repetitive', 'Patterns', 'Attention', 'Mechanism', 'Deep', 'Neural', 'Networks']",[]
"Recent studies in Radiance Fields have paved the robust way for novel view synthesis with their photorealistic rendering quality. Nevertheless, they usually employ neural networks and volumetric rendering, which are costly to train and impede their broad use in various real-time applications due to the lengthy rendering time.
Lately 3D Gaussians splatting-based approach has been proposed to model the 3D scene, and it achieves remarkable visual quality while rendering the images in real-time. However, it suffers from severe degradation in the rendering quality if the training images are blurry. Blurriness commonly occurs due to the lens defocusing, object motion, and camera shake, and it inevitably intervenes in clean image acquisition. Several previous studies have attempted to render clean and sharp images from blurry input images using neural fields. The majority of those works, however, are designed only for volumetric rendering-based neural radiance fields and are not straightforwardly applicable to rasterization-based 3D Gaussian splatting methods.
Thus, we propose a novel real-time deblurring framework, deblurring 3D Gaussian Splatting, using a small Multi-Layer Perceptron (MLP) that manipulates the covariance of each 3D Gaussian to model the scene blurriness. While deblurring 3D Gaussian Splatting can still enjoy real-time rendering, it can reconstruct fine and sharp details from blurry images. A variety of experiments have been conducted on the benchmark, and the results have revealed the effectiveness of our approach for deblurring. Qualitative results are available at https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/",[],[]
"This paper presents the CMB angular power spectrum obtained using the CAMB code for three different models of inflation: the Starobinsky inflationary model, the generalized Starobinsky inflationary model, and the chaotic inflationary model with a step. The results are compared with the most recent data reported for the Planck mission. An analysis of the large (l≲90less-than-or-similar-to𝑙90l\lesssim 90italic_l ≲ 90), intermediate (90≲l≲900less-than-or-similar-to90𝑙less-than-or-similar-to90090\lesssim l\lesssim 90090 ≲ italic_l ≲ 900), and small (l≳900greater-than-or-equivalent-to𝑙900l\gtrsim 900italic_l ≳ 900) angular scales is performed. We report the position of the peaks in the intermediate region so as the cosmological parameters obtained in each of the models: age of the universe, ΩmsubscriptΩ𝑚\Omega_{m}roman_Ω start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, ΩbsubscriptΩ𝑏\Omega_{b}roman_Ω start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT, ΩΛsubscriptΩΛ\Omega_{\Lambda}roman_Ω start_POSTSUBSCRIPT roman_Λ end_POSTSUBSCRIPT, ΩKsubscriptΩ𝐾\Omega_{K}roman_Ω start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT and nSsubscript𝑛Sn_{\mathrm{S}}italic_n start_POSTSUBSCRIPT roman_S end_POSTSUBSCRIPT.",[],[]
"The heterochaos baker maps are piecewise affine maps of the unit square or cube introduced by Saiki et al. [59],
to provide a hands-on, elementary understanding of complicated phenomena in systems of large degrees of freedom.
We review recent progress on a dynamical systems theory of the heterochaos baker maps, and present new results on properties of measures of maximal entropy and the underlying Lebesgue measure.
We address several conjectures and questions that may illuminate new aspects of heterochaos and inspire future research.",[],[]
"In recent years, the techniques of analytic combinatorics in several variables (ACSV) have been applied to determine asymptotics for several families of lattice path models restricted to the orthant ℕdsuperscriptℕ𝑑\mathbb{N}^{d}blackboard_N start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and defined by step sets 𝒮⊂{−1,0,1}d∖{𝟎}𝒮superscript101𝑑0\mathcal{S}\subset\{-1,0,1\}^{d}\setminus\{\mathbf{0}\}caligraphic_S ⊂ { - 1 , 0 , 1 } start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ∖ { bold_0 }. Using the theory of ACSV for smooth singular sets, Melczer and Mishna determined asymptotics for the number of walks in any model whose set of steps 𝒮𝒮\mathcal{S}caligraphic_S is ‘highly symmetric’ (symmetric over every axis). Building on this work, Melczer and Wilson determined asymptotics for all models where 𝒮𝒮\mathcal{S}caligraphic_S is ‘mostly symmetric’ (symmetric over all but one axis) except for models whose set of steps have a vector sum of zero but are not highly symmetric. In this paper we complete the asymptotic classification of the mostly symmetric case by analyzing a family of saddle-point-like integrals whose amplitudes are singular near their saddle points.",[],[]
"Locally harmonic manifolds are Riemannian manifolds in which small geodesic spheres are isoparametric hypersurfaces, i.e., hypersurfaces whose nearby parallel hypersurfaces are of constant mean curvature. Flat and rank one symmetric spaces are examples of harmonic manifolds. Damek–Ricci spaces are non-compact harmonic manifolds, most of which are non-symmetric. Taking the limit of an “inflating” sphere through a point p𝑝pitalic_p in a Damek–Ricci space as the center of the sphere runs out to infinity along a geodesic half-line γ𝛾\gammaitalic_γ starting from p𝑝pitalic_p, we get a horosphere. Similarly to spheres, horospheres are also isoparametric hypersurfaces. In this paper, we define the sphere-like hypersurfaces obtained by “overinflating the horospheres” by pushing the center of the sphere beyond the point at infinity of γ𝛾\gammaitalic_γ along a virtual prolongation of γ𝛾\gammaitalic_γ. They give a new family of isoparametric hypersurfaces in Damek–Ricci spaces connecting geodesic spheres to some of the isoparametric hypersurfaces constructed by J. C. Díaz-Ramos and M. Domínguez-Vázquez [17] in Damek–Ricci spaces. We study the geometric properties of these isoparametric hypersurfaces, in particular their homogeneity and the totally geodesic condition for their focal varieties.","['Isoparametric hypersurface', 'focal variety', 'Damek–Ricci space', 'mean curvature']",[]
,[],[]
"Accurately selecting and estimating smooth functional effects in additive models with potentially many functions is a challenging task. We introduce a novel Demmler-Reinsch basis expansion to model the functional effects that allows us to orthogonally decompose an effect into its linear and nonlinear parts. We show that our representation allows to consistently estimate both parts as opposed to commonly employed mixed model representations. Equipping the reparameterized regression coefficients with normal beta prime spike and slab priors allows us to determine whether a continuous covariate has a linear, a nonlinear or no effect at all. We provide new theoretical results for the prior and a compelling explanation for its superior Markov chain Monte Carlo mixing performance compared to the spike-and-slab group lasso. We establish an efficient posterior estimation scheme and illustrate our approach along effect selection on the hazard rate of a time-to-event response in the geoadditive Cox regression model in simulations and data on survival with leukemia.",[],[]
"We translate Giovanni Curi’s predicative least fixed point theorem into type theory. There are benefits to having a type theoretic formulation apart from the potential for routine formalization. By taking advantage of (higher) inductive types, we have skirted the painstaking set theoretic constructions and as a result believe our presentation is conceptually clearer. Additionally, due the predicative admissibility of (higher) inductive types we take a step towards the \saysystem independent derivation that Curi calls for in his conclusion. To conclude the paper we explore a condition on monotone maps that guarantees they are ‘generated’ in a sense we make precise. This allows for an alternative statement of the least fixed point theorem which goes beyond the version found in Curi’s work.",[],[]
"In 2008, L. Zádori proved that the subspace lattice Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) of a vector space V𝑉Vitalic_V of finite dimension at least 3333 over a finite field F𝐹Fitalic_F has a 5-element generating set, i.e., Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is 5-generated. We extend his result to all 1111-generated fields; in particular, to all fields F𝐹Fitalic_F such that the extension from the prime field of F𝐹Fitalic_F to F𝐹Fitalic_F is of finite degree.
Furthermore, we prove that if the field F𝐹Fitalic_F is t𝑡titalic_t-generated for some finite or infinite cardinal number t𝑡titalic_t, d≥3𝑑3d\geq 3italic_d ≥ 3 denotes the finite dimension of V𝑉Vitalic_V, and
m𝑚mitalic_m is the least cardinal such that m⁢(d−1)𝑚𝑑1m(d-1)italic_m ( italic_d - 1 ) is at least t𝑡titalic_t, then Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is (4+m)4𝑚(4+m)( 4 + italic_m )-generated and the k𝑘kitalic_k-th direct power of Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is (5+m)5𝑚(5+m)( 5 + italic_m )-generated for many positive integers k𝑘kitalic_k; for all positive integers k𝑘kitalic_k if F𝐹Fitalic_F is infinite. In particular, if t𝑡titalic_t is finite, then Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is 5-generated for all but finitely many values of d𝑑ditalic_d.
We prove also that, for a fixed d𝑑ditalic_d, as t𝑡titalic_t (now the minimum number of elements generating F𝐹Fitalic_F) tends to infinity or is infinite, then so does or so is the minimum number of elements of the generating sets of Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ), respectively.
Finally, let n𝑛nitalic_n be a positive integer.
For i=1,…,n𝑖1…𝑛i=1,\dots,nitalic_i = 1 , … , italic_n, let pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be a prime number or 0, and let Visubscript𝑉𝑖V_{i}italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the 3-dimensional vector space over the prime field of characteristic pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. We prove that the direct product of the lattices Sub⁢(V1)Subsubscript𝑉1\textup{Sub}(V_{1})Sub ( italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), …, Sub⁢(Vn)Subsubscript𝑉𝑛\textup{Sub}(V_{n})Sub ( italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) is 4-generated if and only if each of the numbers p1subscript𝑝1p_{1}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, …, pnsubscript𝑝𝑛p_{n}italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT occurs in the sequence p1subscript𝑝1p_{1}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, …, pnsubscript𝑝𝑛p_{n}italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT at most four times. Neither this direct product nor any of the subspace lattices Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) above is 3-generated.","['Small generating set', 'four element generating set', 'subspace lattice', 'projective space', 'coordinatization of lattices', 'field extension']",[]
"In distributed radar systems, when several transmitters radiate simultaneously,
the reflected signals
need to be distinguished at the receivers to detect various targets. If the transmit signals are in different frequency bands, they require a large overall bandwidth.
Instead, a set of pseudo-orthogonal waveforms derived from the Zadoff-Chu (ZC) sequences could be accommodated in the same band, enabling the efficient use of available bandwidth for better range resolution.
In such a design, special care must be given to the ‘near-far’ problem, where a reflection could possibly become difficult to detect due to the presence of stronger reflections.
In this work, a scheme to detect multiple targets in such distributed radar systems is proposed.
It performs successive cancellations (SC) starting from the strong, detectable reflections in the domain of the Discrete Chirp-Fourier Transform (DCFT) after compensating for Doppler shifts, enabling the subsequent detections of weaker targets which are not trivially detectable.
Numerical
simulations corroborate the efficacy and usefulness
of the proposed method in detecting weak target reflections.","['Distributed', 'Radar', 'Multistatic', 'Radar', 'Multi-Target', 'Detection', 'Zadoff-Chu', 'Sequences', 'Successive', 'Cancellation', 'Discrete', 'Chirp-Fourier', 'Transform (DCFT).']",[]
"We propose a semi-analytic Stokes expansion ansatz for finite-depth
standing water waves and devise a recursive algorithm to solve the
system of differential equations governing the expansion
coefficients. We implement the algorithm on a supercomputer using
arbitrary-precision arithmetic. The Stokes expansion introduces
hyperbolic trigonometric terms that require exponentiation of power
series. We handle this efficiently using Bell polynomials. Under mild
assumptions on the fluid depth, we prove that there are no exact
resonances, though small divisors may occur. Sudden changes in growth
rate in the expansion coefficients are found to correspond to
imperfect bifurcations observed when families of standing waves are
computed using a shooting method. A direct connection between small
divisors in the recursive algorithm and imperfect bifurcations in the
solution curves is observed, where the small divisor excites
higher-frequency parasitic standing waves that oscillate on top of the
main wave. A 109th order Padé approximation maintains 25–30 digits
of accuracy on both sides of the first imperfect bifurcation
encountered for the unit-depth problem. This suggests that even if the
Stokes expansion is divergent, there may be a closely related
convergent sequence of rational approximations.","['standing water waves finite depth semi-analytic', 'Stokes\nexpansion conformal map bifurcation']",[]
"The nearly continuous stream of miniature comets dominated by the
Kreutz sungrazers has been an unexpected great bonanza for cometary
science initiated by the launch of the Solar and Heliospheric Observatory
(SOHO) in 1995. Over the nearly 30 years since the time, no serious attempt
has been made to formulate a self-consistent model for the formation and
evolution of this stream of Kreutz comets — the goal of the present two-part
investigation. Part I describes historical highlights of the research
that has been relevant to the problem of SOHO sungrazers (including the major
contributions by Hubbard, Kreutz, and Marsden) and furnishes preliminaries
of diagnostic value that are intended to facilitate, and provide critical
information for, the work in Part II. Formerly noted issues, such as the
high frequency of close pairs in the SOHO database, are proposed to be
products of a broader process of swarming, seen in both the nodal longitude
and time. I present examples of tight swarms revealed by high arrival rates
of the SOHO Kreutz sungrazers, primarily from Population I.","['Subject headings: individual comets:', 'X/1106', 'C1', 'C/1843', 'D1', 'C/1880', 'C1', 'C/1882', 'R1', 'C/1963', 'R1', 'C/1965', 'S1', 'C/1970', 'K1', 'C/2011', 'W3 methods: data analysis']",[]
"The proposed Laser Interferometer Space Antenna (LISA) mission is tasked with the detection and characterization of gravitational waves from various sources in the universe. This endeavor is challenged by transient displacement and acceleration noise artifacts, commonly called glitches. Uncalibrated glitches impact the interferometric measurements and decrease the signal quality of LISA’s time-delay interferometry (TDI) data used for astrophysical data analysis. The paper introduces a novel calibration pipeline that employs a neural network ensemble to detect, characterize, and mitigate transient glitches of diverse morphologies. A convolutional neural network is designed for anomaly detection, accurately identifying and temporally pinpointing anomalies within the TDI time series. Then, a hybrid neural network is developed to differentiate between gravitational wave bursts and glitches, while a long short-term memory (LSTM) network architecture is deployed for glitch estimation. The LSTM network acts as a TDI inverter by processing noisy TDI data to obtain the underlying glitch dynamics. Finally, the inferred noise transient is subtracted from the interferometric measurements, enhancing data integrity and reducing biases in the parameter estimation of astronomical targets. We propose a low-latency solution featuring generalized LSTM networks primed for rapid response data processing and alert service in high-demand scenarios like predicting binary black hole mergers. The research highlights the critical role of machine learning in advancing methodologies for data calibration and astrophysical analysis in LISA.",[],['Switzerland']
"We present a lightweight and affordable motion capture method based on two smartwatches and a head-mounted camera. In contrast to the existing approaches that use six or more expert-level IMU devices, our approach is much more cost-effective and convenient. Our method can make wearable motion capture accessible to everyone, enabling 3D full-body motion capture in diverse environments.
As a key idea to overcome the extreme sparsity and ambiguities of sensor inputs, we integrate 6D head poses obtained from the head-mounted cameras for motion estimation.
To enable capture in expansive indoor and outdoor scenes, we propose an algorithm to track and update floor level changes to define head poses, coupled with a multi-stage Transformer-based regression module.
We also introduce novel strategies leveraging visual cues of egocentric images to further enhance the motion capture quality while reducing ambiguities.
We demonstrate the performance of our method on various challenging scenarios, including complex outdoor environments and everyday motions including object interactions and social interactions among multiple individuals.",[],[]
"We study two-site deconstructions of the S⁢U⁢(2)L𝑆𝑈subscript2𝐿SU(2)_{L}italic_S italic_U ( 2 ) start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT gauge group factor of the SM. Models based on this approach can explain the hierarchies of the quark masses and CKM mixing between the third and light families if these fields are localised on different sites, leading to a global accidental U⁢(2)q×U⁢(3)u×U⁢(3)d𝑈subscript2𝑞𝑈subscript3𝑢𝑈subscript3𝑑U(2)_{q}\times U(3)_{u}\times U(3)_{d}italic_U ( 2 ) start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT × italic_U ( 3 ) start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT × italic_U ( 3 ) start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT flavour symmetry. This symmetry prevents dangerously large effects in flavour observables, making a TeV scale realisation possible. Given the structure of PMNS matrix in the neutrino sector, we explore different possibilities for the arrangement of the leptons on the two sites, and consider different models with U⁢(2)ℓ𝑈subscript2ℓU(2)_{\ell}italic_U ( 2 ) start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT or U⁢(3)ℓ𝑈subscript3ℓU(3)_{\ell}italic_U ( 3 ) start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT flavour symmetries. The phenomenology of the models is mostly governed by a massive vector triplet of S⁢U⁢(2)L𝑆𝑈subscript2𝐿SU(2)_{L}italic_S italic_U ( 2 ) start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT. We study the interesting interplay between LHC searches and precision observables. In particular, one of the models can give a sizeable lepton flavour universal effect in the Wilson coefficient C9subscript𝐶9C_{9}italic_C start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT
while naturally suppressing contributions to C10subscript𝐶10C_{10}italic_C start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT,
as suggested by current b→s⁢ℓ+⁢ℓ−→𝑏𝑠superscriptℓsuperscriptℓb\to s\ell^{+}\ell^{-}italic_b → italic_s roman_ℓ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT roman_ℓ start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT data, predicting simultaneously a mild positive shift in the W𝑊Witalic_W boson mass.",[],"['Spain', 'Italy', 'Switzerland', 'Poland']"
"In the evolution of Vision-Language Pre-training, shifting from short-text comprehension to encompassing extended textual contexts is pivotal.
Recent autoregressive vision-language models like [2, 14], leveraging the long-context capability of Large Language Models, have excelled in few-shot text generation tasks but face challenges in alignment tasks.
Addressing this gap, we introduce the contrastive loss into text generation models, presenting the COntrastive-Streamlined MultimOdal framework (CosMo), strategically partitioning the language model into dedicated unimodal text processing and adept multimodal data handling components.
CosMo, our unified framework, merges unimodal and multimodal elements, enhancing model performance for tasks involving textual and visual data while notably reducing learnable parameters.
However, these models demand extensive long-text datasets, yet the availability of high-quality long-text video datasets remains limited.
To bridge this gap, this work introduces Howto-Interlink7M, an inaugural interleaved video-text dataset featuring comprehensive captions, marking a significant step forward.
Demonstrating its impact, we illustrate how Howto-Interlink7M enhances model performance in image-text tasks.
With 34% learnable parameters and utilizing 72% of the available data, our model demonstrates significant superiority over OpenFlamingo [3].
For instance, in the 4-shot flickr captioning task, performance notably improves from 57.2% to 65.1%.
The contributions of CosMo and Howto-Interlink7M are underscored by notable performance gains across 14 diverse downstream datasets encompassing both image-text and video-text tasks.",[],[]
"Given the difficulty of manually annotating motion in video, the current best motion estimation methods are trained with synthetic data, and therefore struggle somewhat due to a train/test gap. Self-supervised methods hold the promise of training directly on real video, but typically perform worse. These include methods trained with warp error (i.e., color constancy) combined with smoothness terms, and methods that encourage cycle-consistency in the estimates (i.e., tracking backwards should yield the opposite trajectory as tracking forwards). In this work, we take on the challenge of improving state-of-the-art supervised models with self-supervised training. We find that when the initialization is supervised weights, most existing self-supervision techniques actually make performance worse instead of better, which suggests that the benefit of seeing the new data is overshadowed by the noise in the training signal. Focusing on obtaining a “clean” training signal from real-world unlabelled video, we propose to separate label-making and training into two distinct stages. In the first stage, we use the pre-trained model to estimate motion in a video, and then select the subset of motion estimates which we can verify with cycle-consistency. This produces a sparse but accurate pseudo-labelling of the video. In the second stage, we fine-tune the model to reproduce these outputs, while also applying augmentations on the input. We complement this boot-strapping method with simple techniques that densify and re-balance the pseudo-labels, ensuring that we do not merely train on “easy” tracks. We show that our method yields reliable gains over fully-supervised methods in real videos, for both short-term (flow-based) and long-range (multi-frame) pixel tracking.",[],[]
"We study the holographic complexity of a pair of asymptotically dS universes in the presence of axion matter, to characterize these observables in more general spacetimes. The system is prepared in a two-copy Hartle-Hawking state by slicing an Euclidean wormhole, which entangles the two universes. We derive the evolution of codimension-1 Complexity=Anything proposals by anchoring the probes to a worldline observer in each of the universes and connecting them through the Euclidean wormhole. We investigate how the axion charge competes with the cosmological constant in the time evolution of complexity. When the complexity proposal equals the volume of an extremal surface, its evolution is determined by the scale factor of the axion-dS universe, and as a result, the observable might increase nearly exponentially for low axion charge, while it decreases to a vanishing value as one approaches the maximal axion charge allowed by de Sitter space.",[],[]
"In this paper, we introduce the notion of the diagonal property and the weak point property for an ind-variety. We prove that the ind-varieties of higher rank divisors of integral slopes on a smooth projective curve have the weak point property. Moreover, we show that the ind-variety of (1,n)1𝑛(1,n)( 1 , italic_n )-divisors has the diagonal property. Furthermore, we obtain that the Hilbert schemes associated to the good partitions of a constant polynomial satisfy the diagonal property. In the process of obtaining this, we provide the exact number of such Hilbert schemes up to isomorphism by proving that the multi symmetric products associated to two distinct partitions of a positive integer n𝑛nitalic_n are not isomorphic.",[],[]
"Light and sound waves have the fascinating property that they can move objects through the transfer of linear or angular momentum. This ability has led to the development of optical and acoustic tweezers, with applications ranging from biomedical engineering to quantum optics. Although impressive manipulation results have been achieved, the stringent requirement for a highly controlled, low-reverberant, and static environment still hinders the applicability of these techniques in many scenarios. Here, we overcome this challenge and demonstrate the manipulation of objects in disordered and dynamic media, by optimally tailoring the momentum of sound waves iteratively in the far field. The method does not require information about the object’s physical properties or the spatial structure of the surrounding medium but relies only on a real-time scattering matrix measurement and a positional guidestar. Our experiment demonstrates the possibility of optimally moving and rotating objects, extending the reach of wave-based object manipulation to complex and dynamic scattering media. We envision new opportunities for biomedical applications, sensing, or manufacturing.","['Object manipulation', 'wave-momentum shaping', 'scattering', 'adaptive acoustics.']","['Austria', 'Switzerland', 'France', 'Kazakhstan']"
,[],['Germany']
"These instructions give you guidelines for preparing papers for
IEEE Transactions and Journals. Use this document as a template if you are
using LATEX. Otherwise, use this document as an
instruction set. The electronic file of your paper will be formatted further
at IEEE. Paper titles should be written in uppercase and lowercase letters,
not all uppercase. Avoid writing long formulas with subscripts in the title;
short formulas that identify the elements are fine (e.g., ”Nd–Fe–B”). Do
not write “(Invited)” in the title. Full names of authors are preferred in
the author field, but are not required. Put a space between authors’
initials. The abstract must be a concise yet comprehensive reflection of
what is in your article. In particular, the abstract must be self-contained,
without abbreviations, footnotes, or references. It should be a microcosm of
the full article. The abstract must be between 150–250 words. Be sure that
you adhere to these limits; otherwise, you will need to edit your abstract
accordingly. The abstract must be written as one paragraph, and should not
contain displayed mathematical equations or tabular material. The abstract
should include three or four different keywords or phrases, as this will
help readers to find it. It is important to avoid over-repetition of such
phrases as this can result in a page being rejected by search engines.
Ensure that your abstract reads well and is grammatically correct.","['Enter key words or phrases in alphabetical\norder', 'separated by commas.', 'For a list of suggested keywords', 'send a blank\ne-mail to keywords@ieee.org or visit http://www.ieee.org/organizations/pubs/ani_prod/keywrd98.txt']",[]
,[],[]
"Climate change and global warming have been trending topics worldwide since the Eco-92 conference. However, little progress has been made in reducing greenhouse gases (GHGs). The problems and challenges related to emissions are complex and require a concerted and comprehensive effort to address them. Emissions reporting is a critical component of GHG reduction policy and is therefore the focus of this work.
It is crucial to improve the process efficiency of emissions reporting in order to achieve better emissions reduction results, as there is a direct link between effective emissions policies implemented by cities and emissions reduction (or increase) due to the effectiveness of these policies. Hence, to achieve this goal, this work proposes a series of steps to investigate, search and develop performance indicators (PIs) for emissions reporting. These performance indicators are based on the data provided by cities on the processes they go through to address emission problems. PIs can be used to guide and optimize the policies responsible for implementing emission reduction measures at the city level. Therefore, the main goal of this work is two-fold: (i) to propose an emission reporting evaluation model to leverage emissions reporting overall quality and (ii) to use artificial intelligence (AI) to support the initiatives that improve emissions reporting.
Thus, this work presents an Emissions Reporting Maturity Model (ERMM) for examining, clustering, and analysing data from emissions reporting initiatives to help the cities to deal with climate change and global warming challenges. The model is built using Capability Maturity Model (CMM) concepts and uses artificial intelligence clustering technologies, performance indicator candidates and a qualitative analysis approach to find the data flow along the emissions-related processes implemented by cities. The Performance Indicator Development Process (PIDP) proposed in this work provides ways to leverage the quality of the available data necessary for the execution of the evaluations identified by the ERMM. Hence, the PIDP supports the preparation of the data from emissions-related databases, the classification of the data according to similarities highlighted by different clustering techniques, and the identification of performance indicator candidates, which are strengthened by a qualitative analysis of selected data samples.
Thus, the main goal of ERRM is to evaluate and classify the cities regarding the emission reporting processes, pointing out the drawbacks and challenges faced by other cities from different contexts, and at the end to help them to leverage the underlying emissions-related processes and emissions mitigation initiatives.",[],[]
"This letter proposes the experimental validation of an optimisation method for periodic metasurfaces. A previous study showed the design and simulation of a classical anomalous reflecting metasurface and enlightened the parasitic reflection induced by the translational invariances of the structure. The method applies to periodic structures, in the framework of the Floquet analysis. It consists of the exploitation of the Floquet type simulation outputs of a periodic element of the structure to predict the behaviour of the complete structure in terms of radar cross section (RCS). The proposed application focuses on the reduction of the RCS level of the structure in one particular Floquet direction. The fabricated metasurfaces and experimental setup are presented with the associated measurements. The well-agreeing simulation and experimental results validate the proposed optimization procedure.",[],['France']
"The metaverse is expected to provide immersive entertainment, education, and business applications. However, virtual reality (VR) transmission over wireless networks is data- and computation-intensive, making it critical to introduce novel solutions that meet stringent quality-of-service requirements. With recent advances in edge intelligence and deep learning, we have developed a novel multi-view synthesizing framework that can efficiently provide computation, storage, and communication resources for wireless content delivery in the metaverse.
We propose a three-dimensional (3D)-aware generative model that uses collections of single-view images. These single-view images are transmitted to a group of users with overlapping fields of view, which avoids massive content transmission compared to transmitting tiles or whole 3D models. We then present a federated learning approach to guarantee an efficient learning process. The training performance can be improved by characterizing the vertical and horizontal data samples with a large latent feature space, while low-latency communication can be achieved with a reduced number of transmitted parameters during federated learning.
We also propose a federated transfer learning framework to enable fast domain adaptation to different target domains. Simulation results have demonstrated the effectiveness of our proposed federated multi-view synthesizing framework for VR content delivery.","['Metaverse', 'virtual reality', 'multi-view synthesizing', 'federated learning', 'deep learning.']",[]
"Recent progress in quantum technologies with ultracold atoms has been propelled by spatially fine-tuned control of lasers and diffraction-limited imaging. The state-of-the-art precision of optical alignment to achieve this fine-tuning is reaching the limits of manual control. Here, we show how to automate this process. One of the elementary techniques of manual alignment of optics is cross-walking of laser beams. Here, we generalize this technique to multi-variable cross-walking. Mathematically, this is a variant of the well-known Alternating Minimization (AM) algorithm in convex optimization and is closely related to the Gauss-Seidel algorithm. Therefore, we refer to our multi-variable cross-walking algorithm as the modified AM algorithm. While cross-walking more than two variables manually is challenging, one can do this easily for machine-controlled variables. We apply this algorithm to mechanically align high numerical aperture (NA) objectives and show that we can produce high-quality diffraction-limited tweezers and point spread functions (PSF). After a rudimentary coarse alignment, the algorithm takes about 1111 hour to align the optics to produce high-quality tweezers. Moreover, we use the same algorithm to optimize the shape of a deformable mirror along with the mechanical variables and show that it can be used to correct for optical aberrations produced, for example, by glass thickness when producing tweezers and imaging point sources. The shape of the deformable mirror is parametrized using the first 14141414 non-trivial Zernike polynomials, and the corresponding coefficients are optimized together with the mechanical alignment variables. We show PSF with a Strehl ratio close to 1111 and tweezers with a Strehl ratio >0.8absent0.8>0.8> 0.8. The algorithm demonstrates exceptional robustness, effectively operating in the presence of significant mechanical fluctuations induced by a noisy environment.",[],[]
,[],[]
,[],[]
,[],[]
"The magnetic state of UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT was determined experimentally to be anti-ferromagnetic. Starting from this experimental fact, researchers have calculated other properties within the Hubbard-corrected density-functional theory, DFT+U. Up to now, the Hubbard parameters for UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT were usually so chosen that the calculations give good results for some experimental data.
Also, to our knowledge there exists no valid theoretical research report on the energetically stable magnetic state of this system. In present work, employing the new method which is based on density-functional perturbation theory, we have determined self-consistently the Hubbard parameters and ground-state energies for UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT crystal in both ferromagnetic and anti-ferromagnetic configurations, and the calculated results show that UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT crystal energetically favors an anti-ferromagnetic state with a small energy difference.
In all the calculations the PBE-sol approximation was used for the exchange-correlation energy functional.","['Uranium dioxide', 'Ferromagnetism', 'Anti-ferromagnetism', 'Density-Functional', 'Theory', 'Hubbard', 'Model', 'Mott', 'Insulator', 'DFT+U.']",[]
"Data science pipelines commonly utilize dataframe and array operations for tasks such as data preprocessing, analysis, and machine learning. The most popular tools for these tasks are pandas and NumPy. However, these tools are limited to executing on a single node, making them unsuitable for processing large-scale data.
Several systems have attempted to distribute data science applications to clusters while maintaining interfaces similar to single-node libraries, enabling data scientists to scale their workloads without significant effort. However, existing systems often struggle with processing large datasets due to Out-of-Memory (OOM) problems caused by poor data partitioning.
To overcome these challenges, we develop Xorbits, a high-performance, scalable data science framework specifically designed to distribute data science workloads across clusters while retaining familiar APIs. The key differentiator of Xorbits is its ability to dynamically switch between graph construction and graph execution.
Xorbits has been successfully deployed in production environments with up to 5k CPU cores. Its applications span various domains, including user behavior analysis and recommendation systems in the e-commerce sector, as well as credit assessment and risk management in the finance industry.
Users can easily scale their data science workloads by simply changing the import line of their pandas and NumPy code.
Our experiments demonstrate that Xorbits can effectively process very large datasets without encountering OOM or data-skewing problems.
Over the fastest state-of-the-art solutions, Xorbits achieves an impressive 2.66×\times× speedup on average. In terms of API coverage, Xorbits attains a compatibility rate of 96.7%, surpassing the fastest framework by an impressive margin of 60 percentage points.
Xorbits is available at https://github.com/xorbitsai/xorbits.","['scalable data science', 'dataframe', 'array', 'tiling', 'computation graph']",[]
"For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. In this paper, we provide quantifier-free necessary and sufficient conditions for two symmetric matrices to realize a given eigenvalue configuration. The basic idea is to generate a set of polynomials in the entries of the two matrices whose roots can be counted to uniquely determine the eigenvalue configuration.
This result can be seen as a
generalization of Descartes’ rule of signs to the case of two real univariate polynomials.",[],['Spain']
"In this paper we show how tensor networks help in developing explainability of machine learning algorithms. Specifically, we develop an unsupervised clustering algorithm based on Matrix Product States (MPS) and apply it in the context of a real use-case of adversary-generated threat intelligence. Our investigation proves that MPS rival traditional deep learning models such as autoencoders and GANs in terms of performance, while providing much richer model interpretability. Our approach naturally facilitates the extraction of feature-wise probabilities, Von Neumann Entropy, and mutual information, offering a compelling narrative for classification of anomalies and fostering an unprecedented level of transparency and interpretability, something fundamental to understand the rationale behind artificial intelligence decisions.",[],['Spain']
"J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ production in high-energy hadronic collisions is sensitive to both perturbative and non-perturbative aspects of quantum chromodynamics (QCD) calculations. The production of a heavy-quark pair is well-described by perturbative QCD, whereas the
formation of the bound state involves non-perturbative processes, treated in different ways by various available theoretical models. ALICE can measure inclusive J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ at both forward and midrapidity down to low pTsubscript𝑝T{p_{\rm T}}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT and the prompt and non-prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ separation can be performed at midrapidity. The study of the production of non-prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ originating from the decay of beauty hadrons, besides allowing to isolate the prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ cross section from the inclusive J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ cross section, can be used to estimate open beauty-hadron production. Heavy-flavour particle production in pp collisions as a function of charged-particle multiplicity can provide insight into the processes occuring in the collision at the partonic level, as well as the interplay between the hard and soft mechanisms in particle production.",[],[]
"In the evolving field of machine learning, video generation has witnessed significant advancements with autoregressive-based transformer models and diffusion models, known for synthesizing dynamic and realistic scenes. However, these models often face challenges with prolonged inference times, even for generating short video clips such as GIFs. This paper introduces FlashVideo, a novel framework tailored for swift Text-to-Video generation. FlashVideo represents the first successful adaptation of the RetNet architecture for video generation, bringing a unique approach to the field. Leveraging the RetNet-based architecture, FlashVideo reduces the time complexity of inference from 𝒪⁢(L2)𝒪superscript𝐿2\mathcal{O}(L^{2})caligraphic_O ( italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to 𝒪⁢(L)𝒪𝐿\mathcal{O}(L)caligraphic_O ( italic_L ) for a sequence of length L𝐿Litalic_L, significantly accelerating inference speed. Additionally, we adopt a redundant-free frame interpolation method, enhancing the efficiency of frame interpolation. Our comprehensive experiments demonstrate that FlashVideo achieves a ×9.17absent9.17\times 9.17× 9.17 efficiency improvement over a traditional autoregressive-based transformer model, and its inference speed is of the same order of magnitude as that of BERT-based transformer models.",[],[]
"Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern. Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources. We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget. The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model’s memory of the original input. A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields. P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments. Experimental results indicate P2F’s robust capability to obfuscate LLM’s memory, attaining a forgetfulness score of around 90% without any utility loss. This represents an enhancement of up to 63% when contrasted with the naive direct instruction technique, highlighting P2F’s efficacy in mitigating memory retention of sensitive information within LLMs. Our findings establish the first benchmark in the novel field of the LLM forgetting task, representing a meaningful advancement in privacy preservation in the emerging LLM domain.",[],[]
"Identifying spatially complete planar primitives from visual data is a crucial task in computer vision.
Prior methods are largely restricted to either 2D segment recovery or simplifying 3D structures, even with extensive plane annotations.
We present PlanarNeRF, a novel framework capable of detecting dense 3D planes through online learning.
Drawing upon the neural field representation, PlanarNeRF brings three major contributions.
First, it enhances 3D plane detection with concurrent appearance and geometry knowledge.
Second, a lightweight plane fitting module is proposed to estimate plane parameters.
Third, a novel global memory bank structure with an update mechanism is introduced, ensuring consistent cross-frame correspondence.
The flexible architecture of PlanarNeRF allows it to function in both 2D-supervised and self-supervised solutions, in each of which it can effectively learn from sparse training signals, significantly improving training efficiency.
Through extensive experiments, we demonstrate the effectiveness of PlanarNeRF in various scenarios and remarkable improvement over existing works.",[],[]
,[],[]
"Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives, elucidating the underlying probabilistic graphical models in each class and presenting a standardized methodology for their derivation from first principles. The analysis also indicates a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a novel lower bound which is proven to reliably penalize the most important failure modes. Furthermore, this newly proposed lower bound enables the training of a standard backbone architecture without the necessity for asymmetric elements such as stop gradients, momentum encoders, or specialized clustering layers—typically introduced to avoid learning trivial solutions. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, thus showing that our objective function allows to outperform existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that GEDI can be integrated into a neural-symbolic framework to mitigate the reasoning shortcut problem and to learn higher quality symbolic representations thanks to the enhanced classification performance.",[],[]
"We investigate the temperature effects in an imbalanced superfluid atomic Fermi gas. We consider a bilayer system of two-component dipolar fermionic atoms with one layer containing atoms of one component and the other layer the atoms of other component with an imbalance between the populations of the two components. This imbalance results in uniform and nonuniform superfluid phases such as phase-separated BCS, Fulde-Ferrel-Larkin-Ovchinnikov (FFLO), Sarma and normal Fermi liquid phases for different system parameters. Using the mean-field BCS theory together with the superfluid mass-density criterion we classify different phases in thermodynamic phase diagram. Our results indicate that for a dipolar Fermi system the Sarma phase is stable for large imbalance at finite temperature below the critical temperature, and the FFLO phase is stable for intermediate imbalance on the BCS side of a BCS-BCE crossover. The phase diagram in the temperature and population imbalance plane indicate three Lifshitz points: one corresponding to coexistance of BCS, FFLO and normal Fermi liquid phase while the other two correspond to the coexistance of the Sarma phase, FFLO phase and normal Fermi phase for dipolar interactions.",[],['India']
"The ability of snapshot compressive imaging (SCI) systems to efficiently capture high-dimensional (HD) data depends on the advent of novel optical designs to sample the HD data as two-dimensional (2D) compressed measurements. Nonetheless, the traditional SCI scheme is fundamentally limited, due to the complete disregard for high-level information in the sampling process. To tackle this issue, in this paper,
we pave the first mile toward the advanced design of adaptive coding masks for SCI. Specifically, we propose an efficient and effective algorithm to generate coding masks with the assistance of saliency detection, in a low-cost and low-power fashion.
Experiments demonstrate the effectiveness and efficiency of our approach.
Code is available at: https://github.com/IndigoPurple/SASA.",[],[]
"Analyzing connections between brain regions of interest (ROI) is vital to detect neurological disorders such as autism or schizophrenia. Recent advancements employ graph neural networks (GNNs) to utilize graph structures in brains, improving detection performances. Current methods use correlation measures between ROI’s blood-oxygen-level-dependent (BOLD) signals to generate the graph structure. Other methods use the training samples to learn the optimal graph structure through end-to-end learning. However, implementing those methods independently leads to some issues with noisy data for the correlation graphs and overfitting problems for the optimal graph. In this work, we proposed Bargrain (balanced graph structure for brains), which models two graph structures: filtered correlation matrix and optimal sample graph using graph convolution networks (GCNs). This approach aims to get advantages from both graphs and address the limitations of only relying on a single type of structure. Based on our extensive experiment, Bargrain outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.","['Brain', 'Network', 'Classification', 'Graph', 'Learning', 'Graph', 'Neural', 'Networks', 'Disease', 'Detection']",[]
"The generative priors of pre-trained latent diffusion models have demonstrated great potential to enhance the perceptual quality of image super-resolution (SR) results. Unfortunately, the existing diffusion prior-based SR methods encounter a common problem, i.e., they tend to generate rather different outputs for the same low-resolution image with different noise samples. Such stochasticity is desired for text-to-image generation tasks but problematic for SR tasks, where the image contents are expected to be well preserved. To improve the stability of diffusion prior-based SR, we propose to employ the diffusion models to refine image structures, while employing the generative adversarial training to enhance image fine details. Specifically, we propose a non-uniform timestep learning strategy to train a compact diffusion network, which has high efficiency and stability to reproduce the image main structures, and finetune the pre-trained decoder of variational auto-encoder (VAE) by adversarial training for detail enhancement. Extensive experiments show that our proposed method, namely content consistent super-resolution (CCSR), can significantly reduce the stochasticity of diffusion prior-based SR, improving the content consistency of SR outputs and speeding up the image generation process. Codes and models can be found at https://github.com/csslc/CCSR.",[],[]
"We report the measurement of the cross sections for e+⁢e−→hadrons→superscript𝑒superscript𝑒hadronse^{+}e^{-}\rightarrow{\rm hadrons}italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT → roman_hadrons at
center-of-mass (c.m.) energies from 3.645 to 3.871 GeV.
We observe a new resonance ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 ) in the cross sections for the
first time, and observe the ℛ⁢(3760)ℛ3760\mathcal{R}(3760)caligraphic_R ( 3760 ) resonance with high significance
in the cross sections.
The ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 ) has a mass of (3804.5±0.9±0.9)plus-or-minus3804.50.90.9(3804.5\pm 0.9\pm 0.9)( 3804.5 ± 0.9 ± 0.9 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT,
a total width of (5.4±3.5±3.2)plus-or-minus5.43.53.2(5.4\pm 3.5\pm 3.2)( 5.4 ± 3.5 ± 3.2 ) MeV,
and an electronic partial width of (19.4±7.4±12.1)plus-or-minus19.47.412.1(19.4\pm 7.4\pm 12.1)( 19.4 ± 7.4 ± 12.1 ) eV.
Its significance is 7.7⁢σ7.7𝜎7.7\sigma7.7 italic_σ. The ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 )
could be interpreted as a hadro-charmonium resonance predicted by Quantum Chromodynamics (QCD).
In addition, we measure the mass (3751.9±3.8±2.8)plus-or-minus3751.93.82.8(3751.9\pm 3.8\pm 2.8)( 3751.9 ± 3.8 ± 2.8 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT,
the total width (32.8±5.8±8.7)plus-or-minus32.85.88.7(32.8\pm 5.8\pm 8.7)( 32.8 ± 5.8 ± 8.7 ) MeV,
and the electronic partial width (184±75±86)plus-or-minus1847586(184\pm 75\pm 86)( 184 ± 75 ± 86 ) eV with improved precision
for the ℛ⁢(3760)ℛ3760\mathcal{R}(3760)caligraphic_R ( 3760 ). Furthermore, for the ℛ⁢(3780)ℛ3780\mathcal{R}(3780)caligraphic_R ( 3780 ) we measure the mass
(3778.7±0.5±0.3)plus-or-minus3778.70.50.3(3778.7\pm 0.5\pm 0.3)( 3778.7 ± 0.5 ± 0.3 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and total width
(20.3±0.8±1.7)plus-or-minus20.30.81.7(20.3\pm 0.8\pm 1.7)( 20.3 ± 0.8 ± 1.7 ) MeV with improved precision,
and the electronic partial width (265±69±83)plus-or-minus2656983(265\pm 69\pm 83)( 265 ± 69 ± 83 ) eV.
The ℛ⁢(3780)ℛ3780\mathcal{R}(3780)caligraphic_R ( 3780 ) can be interpreted as the 13⁢D1superscript13subscript𝐷11^{3}D_{1}1 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT state of charmonium.
Its mass and total width differ significantly from the corresponding
fitted values given by the Particle Data Group in 2022 by
7.1 and 3.2 times the uncertainties for ψ⁢(3770)𝜓3770\psi(3770)italic_ψ ( 3770 ), respectively.
ψ⁢(3770)𝜓3770\psi(3770)italic_ψ ( 3770 ) has been interpreted as the 13⁢D1superscript13subscript𝐷11^{3}D_{1}1 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT state for 45 years.",[],[]
"In the absence of data protection measures, software applications lead to privacy breaches, posing threats to end-users and software organisations. Privacy Enhancing Technologies (PETs) are technical measures that protect personal data, thus minimising such privacy breaches. However, for software applications to deliver data protection using PETs, software developers should actively and correctly incorporate PETs into the software they develop. Therefore, to uncover ways to encourage and support developers to embed PETs into software, this Systematic Literature Review (SLR) analyses 39 empirical studies on developers’ privacy practices. It reports the usage of six PETs in software application scenarios. Then, it discusses challenges developers face when integrating PETs into software, ranging from intrinsic challenges, such as the unawareness of PETs, to extrinsic challenges, such as the increased development cost. Next, the SLR presents the existing solutions to address these challenges, along with the limitations of the solutions. Further, it outlines future research avenues to better understand PETs from a developer perspective and minimise the challenges developers face when incorporating PETs into software.","['Privacy', 'Enhancing', 'Technologies', 'data protection', 'developers', 'secure computation']",['Australia']
,[],[]
,[],[]
"Rush hour and sustained traffic flows in eight cities are studied using the IBM Mega
Traffic Simulator to understand the importance of road structures and vehicle
acceleration in the prevention of gridlock. Individual cars among the tens of
thousands launched are monitored at every simulation time step using live streaming
data transfer from the simulation software to analysis software on another computer.
A measure of gridlock is the fraction of cars moving at less than 30% of their
local road speed. Plots of this fraction versus the instantaneous number of cars on
the road show hysteresis during rush hour simulations, indicating that it can take
twice as long to unravel clogged roads as fill them. The area under the hysteresis
loop is used as a measure of gridlock to compare different cities normalized to the
same central areas. The differences between cities, combined with differences
between idealized models using square or triangular road grids, indicate that
gridlock tends to occur most when there are a small number of long roads that
channel large fractions of traffic. These long roads help light traffic flow but
they make heavy flows worse. Increasing the speed on these long roads makes gridlock
even worse in heavy conditions. City throughput rates are also modeled using a
smooth ramp up to a constant vehicle launch rate. Models with increasing
acceleration for the same road speeds show clear improvements in city traffic flow
as a result of faster interactions at intersections and merging points. However,
these improvements are relatively small when the gridlock is caused by long roads
having many cars waiting to exit at the same intersection. In general, gridlock in
our models begins at intersections regardless of the available road space in the
network.","['traffic', 'cities', 'simulation', 'agent based', 'gridlock']",[]
,[],[]
"Electrostatic force actuation is a key component of the system of geodesic reference test masses (TM) for the LISA orbiting gravitational wave observatory and in particular for performance at low frequencies, below 1 mHz, where the observatory sensitivity is limited by stray force noise. The system needs to apply forces of order 10−99{}^{-9}start_FLOATSUPERSCRIPT - 9 end_FLOATSUPERSCRIPT N while limiting fluctuations in the measurement band to levels approaching 10−1515{}^{-15}start_FLOATSUPERSCRIPT - 15 end_FLOATSUPERSCRIPT N/Hz1/212{}^{1/2}start_FLOATSUPERSCRIPT 1 / 2 end_FLOATSUPERSCRIPT. We present here the LISA actuation system design, based on audio-frequency voltage carrier signals, and results of its in-flight performance test with the LISA Pathfinder test mission. In LISA, TM force actuation is used to align the otherwise free-falling TM to the spacecraft-mounted optical metrology system, without any forcing along the critical gravitational wave-sensitive interferometry axes. In LISA Pathfinder, on the other hand, the actuation was used also to stabilize the TM along the critical x𝑥xitalic_x axis joining the two TM, with the commanded actuation force entering directly into the mission’s main differential acceleration science observable. The mission allowed demonstration of the full compatibility of the electrostatic actuation system with the LISA observatory requirements, including dedicated measurement campaigns to amplify, isolate, and quantify the two main force noise contributions from the actuation system, from actuator gain noise and from low frequency “in band” voltage fluctuations. These campaigns have shown actuation force noise to be a relevant, but not dominant, noise source in LISA Pathfinder and have allowed performance projections for the conditions expected in the LISA mission.",[],[]
"Reservoir computing is a machine learning technique which has been shown to be able to replicate the chaotic attractor, including the fractal dimension and the entire Lyapunov spectrum, of the dynamical system on which it is trained. We quantitatively relate the generalized synchronization dynamics of a driven reservoir computer during the training stage to the performance of the autonomous reservoir computer at the attractor reconstruction task. We show that, for successful attractor reconstruction and Lyapunov exponent estimation, the largest conditional Lyapunov exponent of the driven reservoir must be significantly smaller (more negative) than the smallest (most negative) Lyapunov exponent of the true system. We find that the maximal conditional Lyapunov exponent of the reservoir depends strongly on the spectral radius of the reservoir adjacency matrix, and therefore, for attractor reconstruction and Lyapunov exponent estimation, small spectral radius reservoir computers perform better in general. Our arguments are supported by numerical examples on well-known chaotic systems.",[],[]
,[],[]
"Searches for spacetime variations of fundamental constants have entered an era of unprecedented precision. New, high quality quasar spectra require increasingly refined analytic methods. In this article, a continuation in a series to establish robust and unbiased methodologies, we explore how convergence criteria in non-linear least squares optimisation impact on quasar absorption system measurements of the fine structure constant α𝛼\alphaitalic_α. Given previous claims for high-precision constraints, we critically examine the veracity of a so-called “blinding” approach, in which α𝛼\alphaitalic_α is fixed at the terrestrial value during the model building process, releasing it as a free parameter only after the “final” absorption system kinematic structure has been obtained. We show that this approach results in an extended flat canyon in χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-α𝛼\alphaitalic_α space, such that convergence is unlikely to be reached, even after as many as 1000 iterations. The fix is straightforward: α𝛼\alphaitalic_α must be treated as a free parameter from the earliest possible stages of absorption system model building. The implication of the results presented here is that all previous measurements that have used initially-fixed α𝛼\alphaitalic_α should be reworked.",[],[]
"We report unbiased AI measurements of the fine structure constant α𝛼\alphaitalic_α in two proximate absorption regions in the spectrum of the quasar HE0515−--4414. The data are high resolution, high signal to noise, and laser frequency comb calibrated, obtained using the ESPRESSO spectrograph on the VLT. The high quality of the data and proximity of the regions motivate a differential comparison, exploring the possibility of spatial variations of fundamental constants, as predicted in some theories. We show that if the magnesium isotopic relative abundances are terrestrial, the fine structure constants in these two systems differ at the 7σ𝜎\sigmaitalic_σ level. A 3σ𝜎\sigmaitalic_σ discrepancy between the two measurements persists even for the extreme non-terrestrial case of 100% 2424{}^{24}start_FLOATSUPERSCRIPT 24 end_FLOATSUPERSCRIPTMg, if shared by both systems. However, if Mg isotopic abundances take independent values in these two proximate systems, one terrestrial, the other with no heavy isotopes, both can be reconciled with a terrestrial α𝛼\alphaitalic_α, and the discrepancy between the two measurements falls to 2σ𝜎\sigmaitalic_σ. We discuss varying constant and varying isotope interpretations and resolutions to this conundrum for future high precision measurements.","['Cosmology: cosmological parameters –', 'Cosmology: dark energy –', 'Cosmology: dark matter –', 'Galaxies: intercluster medium –', 'Electroweak interaction']","['Italy', 'Australia']"
,[],[]
"In this work, we consider the atypical non-equilibrium state found in [1708.06328] which holographically represents a behind-the-horizon excitation in a blackhole spacetime. The special feature of this state is that it looks like an equilibrium state when probed by a class of low-energy operators. First, we retrieve this property using the uniformization mapping in the limit of large central charge, in the process we are able to derive rather than presume approximate thermal physics.
Furthermore, in the large-c and high-energy limit we realize these excitations as elements of the commutant algebra of a GNS representation of the light operator algebra. Instead of analytically continuing a mixed heavy-light Euclidean correlator to a Lorentzian correlator, we identify the Euclidean correlator as a GNS linear form and interpret the Lorentzian correlator as a vacuum expectation value of representatives of the light operator algebra on the GNS vacuum.","['Conformal', 'Field', 'Theory', 'AdS/CFT', 'von', 'Neumann', 'Algebras']",[]
,[],[]
"Let g1,…,gMsubscript𝑔1…subscript𝑔𝑀g_{1},\dots,g_{M}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_g start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT be additive functions for which there exist nonconstant polynomials G1,…,GMsubscript𝐺1…subscript𝐺𝑀G_{1},\dots,G_{M}italic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_G start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT satisfying gi⁢(p)=Gi⁢(p)subscript𝑔𝑖𝑝subscript𝐺𝑖𝑝g_{i}(p)=G_{i}(p)italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_p ) = italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_p ) for all primes p𝑝pitalic_p and all i∈{1,…,M}𝑖1…𝑀i\in\{1,\dots,M\}italic_i ∈ { 1 , … , italic_M }. Under fairly general and nearly optimal hypotheses, we show that the functions g1,…,gMsubscript𝑔1…subscript𝑔𝑀g_{1},\dots,g_{M}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_g start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT are jointly
equidistributed among the residue classes to moduli q𝑞qitalic_q varying uniformly up to a fixed but arbitrary power of log⁡x𝑥\log xroman_log italic_x. Thus, we obtain analogues of the Siegel-Walfisz Theorem for primes in arithmetic progressions, but with primes replaced by values of such additive functions.
Our results partially extend work of Delange from fixed moduli to varying moduli, and also generalize recent work done for a single additive function.","['additive function', 'uniform distribution', 'equidistribution', 'joint distribution', 'joint equidistribution']",[]
"The proliferation of social network data has unlocked unprecedented opportunities for extensive, data-driven exploration of human behavior. The structural intricacies of social networks offer insights into various computational social science issues, particularly concerning social influence and information diffusion. However, modeling large-scale social network data comes with computational challenges. Though large language models make it easier than ever to model textual content, any advanced network representation methods struggle with scalability and efficient deployment to out-of-sample users. In response, we introduce a novel approach tailored for modeling social network data in user detection tasks. This innovative method integrates localized social network interactions with the capabilities of large language models. Operating under the premise of social network homophily, which posits that socially connected users share similarities, our approach is designed to address these challenges. We conduct a thorough evaluation of our method across seven real-world social network datasets, spanning a diverse range of topics and detection tasks, showcasing its applicability to advance research in computational social science.","['Social', 'Network', 'User', 'Detection', 'User', 'Behavior', 'Network', 'Homophily']",[]
"Federated learning (FL) underpins advancements in privacy-preserving distributed computing by collaboratively training neural networks without exposing clients’ raw data. Current FL paradigms primarily focus on unimodal data, while exploiting the knowledge from distributed multimodal data remains largely unexplored. Existing multimodal FL (MFL) solutions are mainly designed for statistical or modality heterogeneity from the input side, however, have yet to solve the fundamental issue, ‘modality imbalance’, in distributed conditions, which can lead to inadequate information exploitation and heterogeneous knowledge aggregation on different modalities.In this paper, we propose a novel Cross-Modal Infiltration Federated Learning (FedCMI) framework that effectively alleviates modality imbalance and knowledge heterogeneity via knowledge transfer from the global dominant modality. To avoid the loss of information in the weak modality due to merely imitating the behavior of dominant modality, we design the two-projector module to integrate the knowledge from dominant modality while still promoting the local feature exploitation of weak modality. In addition, we introduce a class-wise temperature adaptation scheme to achieve fair performance across different classes. Extensive experiments over popular datasets are conducted and give us a gratifying confirmation of the proposed framework for fully exploring the information of each modality in MFL.",[],[]
"Using martingale theory, we compute, in very few lines, exact analytical expressions for various first-exit-time statistics associated with one-dimensional biased diffusion. Examples include the distribution for the first-exit time from an interval, moments for the first-exit site, and functionals of the position, which involve memory and time integration. As a key example, we compute analytically the mean area swept by a biased diffusion until it escapes an interval that may be asymmetric and have arbitrary length. The mean area allows us to derive the hitherto unexplored cross-correlation function between the first-exit time and the first-exit site, which vanishes only for exit problems from symmetric intervals. As a colophon, we explore connections of our results with gambling, showing that betting on the time-integrated value of a losing game it is possible to design a strategy that leads to a net average win.","['Martingale theory', 'First-passage processes', 'Brownian motion']",['Italy']
"Within recent approaches to text-to-video (T2V) generation, achieving controllability in the synthesized video is often a challenge. Typically, this issue is addressed by providing low-level per-frame guidance in the form of edge maps, depth maps, or an existing video to be altered. However, the process of obtaining such guidance can be labor-intensive. This paper focuses on enhancing controllability in video synthesis by employing straightforward bounding boxes to guide the subject in various ways, all without the need for neural network training, finetuning, optimization at inference time, or the use of pre-existing videos. Our algorithm, TrailBlazer, is constructed upon a pre-trained (T2V) model, and easy to implement.111Our project page: https://hohonu-vicml.github.io/Trailblazer.Page/ The subject is directed by a bounding box through the proposed spatial and temporal attention map editing. Moreover, we introduce the concept of keyframing, allowing the subject trajectory and overall appearance to be guided by both a moving bounding box and corresponding prompts, without the need to provide a detailed mask. The method is efficient, with negligible additional computation relative to the underlying pre-trained model. Despite the simplicity of the bounding box guidance, the resulting motion is surprisingly natural, with emergent effects including perspective and movement toward the virtual camera as the box size increases.",[],[]
"As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data.
Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training.
This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities.
In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures and more.
Then, we systematically investigate its wide-ranging applications across domains.
Furthermore, we also explore the commonalities and differences between masked modeling methods in different fields.
Toward the end of this paper, we conclude by discussing the limitations of current techniques and point out several potential avenues for advancing masked modeling research.
A paper list project with this survey is available at https://github.com/Lupin1998/Awesome-MIM.","['Self-supervised', 'Learning', 'Masked', 'Modeling', 'Generative', 'Model', 'Natural', 'Language', 'Processing', 'Audio and', 'Speech', 'Graph']",[]
"Let R𝑅Ritalic_R be a commutative ring with identity and a fixed invertible element q12superscript𝑞12q^{\frac{1}{2}}italic_q start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT, and suppose q+q−1𝑞superscript𝑞1q+q^{-1}italic_q + italic_q start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is invertible in R𝑅Ritalic_R. For each planar surface Σ0,n+1subscriptΣ0𝑛1\Sigma_{0,n+1}roman_Σ start_POSTSUBSCRIPT 0 , italic_n + 1 end_POSTSUBSCRIPT, we present its Kauffman bracket skein algebra over R𝑅Ritalic_R by explicit generators and relations. The presentation is independent of R𝑅Ritalic_R, and can be considered as a quantization of the trace algebra of n𝑛nitalic_n generic 2×2222\times 22 × 2 unimodular matrices.
Keywords: planar surface; Kauffman bracket skein algebra; character variety; quantization; presentation 
MSC2020: 57K16, 57K31",[],[]
,[],[]
"Sperm whales (Physeter macrocephalus) navigate underwater with a series of impulsive, click-like sounds known as echolocation clicks. These clicks are characterized by a multipulse structure (MPS) that serves as a distinctive pattern. In this work, we use the stability of the MPS as a detection metric for recognizing and classifying the presence of clicks in noisy environments. To distinguish between noise transients and to handle simultaneous emissions from multiple sperm whales, our approach clusters a time series of MPS measures while removing potential clicks that do not fulfil the limits of inter-click interval, duration and spectrum.
 As a result, our approach can handle high noise transients and low signal-to-noise ratio. The performance of our detection approach is examined using three datasets: seven months of recordings from the Mediterranean Sea containing manually verified ambient noise; several days of manually labelled data collected from the Dominica Island containing approximately 40,000 clicks from multiple sperm whales; and a dataset from the Bahamas containing 1,203 labelled clicks from a single sperm whale. Comparing with the results of two benchmark detectors, a better trade-off between precision and recall is observed as well as a significant reduction in false detection rates, especially in noisy environments. To ensure reproducibility, we provide our database of labelled clicks along with our implementation code.","['Sperm whale clicks', 'passive acoustic monitoring (PAM)', 'real-time detection', 'Inter-pulse interval (IPI)', 'Inter-click interval (ICI).']","['Croatia', 'Israel']"
"Video grounding aims to localize a spatio-temporal section in a video corresponding to an input text query. This paper addresses a critical limitation in current video grounding methodologies by introducing an Open-Vocabulary Spatio-Temporal Video Grounding task. Unlike prevalent closed-set approaches that struggle with open-vocabulary scenarios due to limited training data and predefined vocabularies, our model leverages pre-trained representations from foundational spatial grounding models. This empowers it to effectively bridge the semantic gap between natural language and diverse visual content, achieving strong performance in closed-set and open-vocabulary settings. Our contributions include a novel spatio-temporal video grounding model, surpassing state-of-the-art results in closed-set evaluations on multiple datasets and demonstrating superior performance in open-vocabulary scenarios.
Notably, the proposed model outperforms state-of-the-art methods in closed-set settings on VidSTG (Declarative and Interrogative) and HC-STVG (V1 and V2) datasets. Furthermore, in open-vocabulary evaluations on HC-STVG V1 and YouCook-Interactions, our model surpasses the recent best-performing models by 4.26 m_vIoU and 1.83% accuracy, demonstrating its efficacy in handling diverse linguistic and visual concepts for improved video understanding. Our codes will be released at https://github.com/TalalWasim/Video-GroundingDINO.",[],[]
"This paper uses the MIMIC-IV dataset to examine the fairness and bias in an XGBoost binary classification model predicting the Intensive Care Unit (ICU) length of stay (LOS). Highlighting the critical role of the ICU in managing critically ill patients, the study addresses the growing strain on ICU capacity. It emphasizes the significance of LOS prediction for resource allocation. The research reveals class imbalances in the dataset across demographic attributes and employs data preprocessing and feature extraction. While the XGBoost model performs well overall, disparities across race and insurance attributes reflect the need for tailored assessments and continuous monitoring. The paper concludes with recommendations for fairness-aware machine learning techniques for mitigating biases and the need for collaborative efforts among healthcare professionals and data scientists.",[],[]
"For different alternating-sign multi-pulse trains electric fields with oscillation, the effects of the electric field pulse number and the relative phase of the combined electric field on pair production are investigated by solving quantum Vlasov equation.
It is found that the number density of created particles in the combined electric fields is increased by more than one order of magnitude compared to the results without oscillating structure for both zero transverse momentum and full momentum space.
In the case of zero transverse momentum, the created particles longitudinal momentum spectrum are monochromatic for large pulse numbers and some suitable relative phases. The number density depends nonlinearly on the relative phase that enables the optimal relative phase parameters for the number density. Moreover, for the full momentum space, the created particles number density and momentum spectrum under different multi-pulse trains electric fields are given and discussed. We also find that the number density as a function of pulse number satisfies the power law with index 5.3425.3425.3425.342 for the strong but slowly varying electric field with large pulse numbers.",[],['China']
,[],[]
,[],[]
"We prove the compactness of the set of solutions to the CR Yamabe problem on a compact strictly pseudoconvex CR manifold of dimension three whose blow-up manifolds at every point have positive p-mass.
As a corollary we deduce that compactness holds for CR-embeddable manifolds which are not CR-equivalent to S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT.
The theorem is proved by blow-up analysis.",[],[]
"Fine-tuning Large Language Models (LLMs) adapts a trained model to specific downstream tasks, significantly improving task-specific performance. Supervised Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce desired answers. However, LLMs trained with SFT sometimes make simple mistakes and result in hallucinations on reasoning tasks such as question-answering. Without external feedback, it is difficult for SFT to learn a good mapping between the question and the desired answer, especially with a small dataset. This paper introduces an alternative to SFT called Natural Language Feedback for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they will receive from an annotator — we find that requiring such reflection can significantly improve the accuracy in in-domain question-answering tasks, providing a promising direction for the application of natural language feedback in the realm of SFT LLMs. Additional ablation studies show that the portion of human-annotated data in the annotated datasets affects the fine-tuning performance.",[],[]
"Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure. Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices. Furthermore, we devise a pre-training objective that learns to infill text segments. This approach allows us to address irregular layouts and heterogeneous content frequently encountered in visual documents. The pre-trained model is fine-tuned using a large-scale instruction dataset, covering four core document intelligence tasks. We demonstrate that our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.",[],[]
"Despite the remarkable performance of score distillation in text-to-3D generation, such techniques notoriously suffer from view inconsistency issues, also known as “Janus” artifact, where the generated objects fake each view with multiple front faces.
Although empirically effective methods have approached this problem via score debiasing or prompt engineering, a more rigorous perspective to explain and tackle this problem remains elusive.
In this paper, we reveal that the existing score distillation-based text-to-3D generation frameworks degenerate to maximal likelihood seeking on each view independently and thus suffer from the mode collapse problem, manifesting as the Janus artifact in practice.
To tame mode collapse, we improve score distillation by re-establishing in entropy term in the corresponding variational objective, which is applied to the distribution of rendered images. Maximizing the entropy encourages diversity among different views in generated 3D assets, thereby mitigating the Janus problem.
Based on this new objective, we derive a new update rule for 3D score distillation, dubbed Entropic Score Distillation (ESD).
We theoretically reveal that ESD can be simplified and implemented by just adopting the classifier-free guidance trick upon variational score distillation.
Although embarrassingly straightforward, our extensive experiments successfully demonstrate that ESD can be an effective treatment for Janus artifacts in score distillation.",[],[]
"Motion segmentation is a complex yet indispensable task in autonomous driving. The challenges introduced by the ego-motion of the cameras, radial distortion in fisheye lenses, and the need for temporal consistency make the task more complicated, rendering traditional and standard Convolutional Neural Network (CNN) approaches less effective. The consequent laborious data labeling, representation of diverse and uncommon scenarios, and extensive data capture requirements underscore the imperative of synthetic data for improving machine learning model performance. To this end, we employ the PD-WoodScape synthetic dataset developed by Parallel Domain, alongside the WoodScape fisheye dataset.
Thus, we present the WoodScape fisheye motion segmentation challenge for autonomous driving, held as part of the CVPR 2023 Workshop on Omnidirectional Computer Vision (OmniCV).
As one of the first competitions focused on fisheye motion segmentation, we aim to explore and evaluate the potential and impact of utilizing synthetic data in this domain.
In this paper, we provide a detailed analysis on the competition which attracted the participation of 112 global teams and a total of 234 submissions. This study delineates the complexities inherent in the task of motion segmentation, emphasizes the significance of fisheye datasets, articulate the necessity for synthetic datasets and the resultant domain gap they engender, outlining the foundational blueprint for devising successful solutions. Subsequently, we delve into the details of the baseline experiments and winning methods evaluating their qualitative and quantitative results, providing with useful insights.",[],[]
,[],[]
"Window-based transformers have demonstrated strong ability in large-scale point cloud understanding by capturing context-aware representations with affordable attention computation in a more localized manner. However, because of the sparse nature
of point clouds, the number of voxels per window varies significantly. Current methods partition the voxels in each window into multiple subsets of equal size, which cost expensive overhead in sorting and padding the voxels, making them run slower than sparse convolution based methods. In this paper, we present ScatterFormer, which, for the first time to our best knowledge, could directly perform attention on voxel sets with variable length. The key of ScatterFormer lies in the innovative Scatter Linear Attention (SLA) module, which leverages the linear attention mechanism to process in parallel all voxels scattered in different windows. Harnessing the hierarchical computation units of the GPU and matrix blocking algorithm, we reduce the latency of the proposed SLA module to less than 1 ms on moderate GPUs. Besides, we develop a cross-window interaction module to simultaneously enhance the local representation and allow the information flow across windows, eliminating the need for window shifting. Our proposed ScatterFormer demonstrates 73 mAP (L2) on the large-scale Waymo Open Dataset and 70.5 NDS on the NuScenes dataset, running at an outstanding detection rate of 28 FPS. Code is available at https://github.com/skyhehe123/ScatterFormer.",[],[]
"Using the Hydro-Coal-Frag model that combines hydrodynamics at low pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, quark coalescence at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, and the LBT transport model at high pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, we study the spectra and elliptic flow of identified hadrons in high multiplicity p–Pb and p–p collisions at the Large Hadron Collider (LHC). In p–Pb collisions, the Hydro-Coal-Frag model gives a good description of the differential elliptic flow over the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT range from 0 to 6 GeV and the approximate number of constituent quark (NCQ) scaling at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT. Although Hydro-Coal-Frag model can also roughly describe the elliptic flow in high multiplicity p–p collisions with the quark coalescence process, the larger contribution from the string fragmentations leads to a notable violation of the NCQ scaling of v2subscript𝑣2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT as observed in the experiment. Comparison runs of the Hydro-Frag model without the coalescence process demonstrate that regardless the parameter adjustments, the Hydro-Frag model cannot simultaneously describe the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT spectra and the elliptic flow of identified hadrons in either p–Pb collisions or p–p collisions. The calculations in this paper thus provide support for the existence of partonic degrees of freedom and the possible formation of the QGP in the small systems created at the LHC.",[],['China']
"Structure formation heralds the era of deviation of the matter content of the Universe away from thermal equilibrium, so the gravitational contribution to entropy, in the form of Weyl curvature, must become active in order for the overall entropy of the Universe to remain increasing. The tidal and frame dragging sectors of the Weyl tensor must inevitably both be present in this dynamic environment, as they mutually induce each other. The frame dragging effect is able to impress vorticity onto the plasma current arising due to the mass disparity between electrons and protons, which in turn begets a magnetic field from none. We show that this gravity-driven magnetogenesis mechanism, besides being able to operate outside of galaxies, thus facilitate large coherence length scales, may be able to generate the field strength necessary to seed dynamo processes.",[],['China']
,[],[]
,[],[]
"Hybrid model predictive control with both continuous and discrete variables is widely applicable to robotic control tasks, especially those involving contact with the environment. Due to the combinatorial complexity, the solving speed of hybrid MPC can be insufficient for real-time applications. In this paper, we proposed a hybrid MPC solver based on Generalized Benders Decomposition (GBD). The algorithm enumerates and stores cutting planes online inside a finite buffer. After a short cold-start phase, the stored cuts provide warm-starts for the new problem instances to enhance the solving speed. Despite the disturbance and randomly changing environment, the solving speed maintains. Leveraging on the sparsity of feasibility cuts, we also propose a fast algorithm for Benders master problems. Our solver is validated through controlling a cart-pole system with randomly moving soft contact walls, and a free-flying robot navigating around obstacles. The results show that with significantly less data than previous works, the solver reaches competitive speeds to the off-the-shelf solver Gurobi despite the Python overhead.",[],[]
"Using a sample of (10087±44)×106plus-or-minus1008744superscript106(10087\pm 44)\times 10^{6}( 10087 ± 44 ) × 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT J/ψ𝐽𝜓J/\psiitalic_J / italic_ψ events collected with the BESIII detector at the BEPCII collider, a partial wave analysis on the decay J/ψ→γ⁢γ⁢ϕ→𝐽𝜓𝛾𝛾italic-ϕJ/\psi\rightarrow\gamma\gamma\phiitalic_J / italic_ψ → italic_γ italic_γ italic_ϕ is performed to investigate the intermediate resonances in J/ψ→γ⁢X,X→γ⁢ϕformulae-sequence→𝐽𝜓𝛾𝑋→𝑋𝛾italic-ϕJ/\psi\rightarrow\gamma X,X\rightarrow\gamma\phiitalic_J / italic_ψ → italic_γ italic_X , italic_X → italic_γ italic_ϕ. The resonances f1⁢(1285)subscript𝑓11285f_{1}(1285)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1285 ), η⁢(1405)𝜂1405\eta(1405)italic_η ( 1405 ), f1⁢(1420)subscript𝑓11420f_{1}(1420)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1420 ), f1⁢(1510)subscript𝑓11510f_{1}(1510)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1510 ), f2⁢(1525)subscript𝑓21525f_{2}(1525)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1525 ), X⁢(1835)𝑋1835X(1835)italic_X ( 1835 ), f2⁢(1950)subscript𝑓21950f_{2}(1950)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1950 ), f2⁢(2010)subscript𝑓22010f_{2}(2010)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 2010 ), f0⁢(2200)subscript𝑓02200f_{0}(2200)italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( 2200 ) and ηcsubscript𝜂𝑐\eta_{c}italic_η start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT are observed with statistical significance greater than 5σ𝜎\sigmaitalic_σ. The product branching fractions ℬ⁢(J/ψ→γ⁢X,X→γ⁢ϕ)ℬformulae-sequence→𝐽𝜓𝛾𝑋→𝑋𝛾italic-ϕ\mathcal{B}(J/\psi\rightarrow\gamma X,X\rightarrow\gamma\phi)caligraphic_B ( italic_J / italic_ψ → italic_γ italic_X , italic_X → italic_γ italic_ϕ ) are reported. The resonance parameters of η⁢(1405)𝜂1405\eta(1405)italic_η ( 1405 ) and X⁢(1835)𝑋1835X(1835)italic_X ( 1835 ) are also measured.",[],[]
,[],[]
"We investigate the interference of two-dimensional Bose-Einstein condensates in micro-gravity, which influenced by the interaction strength, initial momentum, gravitational potential and phase difference. We demonstrate that the gravitational potential from the Earth can change the density distribution and phase distribution of the condensate’s wave function. As time evolves, a portion of the gravitational potential energy of the microscopic particles can be converted into kinetic energy, which changes the motion of the microscopic particles, and leads to the varying of the density and phase distribution of the wave function.
Nevertheless, the influences of the Earth’s gravity on the wave function can be eliminated by the micro-gravity environment, which confirmed by many micro-gravity cold atom experiments.
Our results present the influences of gravity and other parameters on interference of Bose-Einstein condensates, which help us to reveal the intrinsic natures of the related theoretical predictions and experimental phenomena. Furthermore, our work builds a bridge between the related physical phenomena and our physical intuition about the Bose-Einstein condensates in micro-gravity environment.",[],['China']
"Self-supervised pre-training paradigms have been extensively explored in the field of
skeleton-based action recognition. In particular, methods based on
masked prediction have pushed the performance of pre-training to a new height.
However, these methods take low-level features, such as raw joint coordinates or
temporal motion, as prediction targets for the masked regions, which is suboptimal.
In this paper, we show that using high-level contextualized features as prediction
targets can achieve superior performance. Specifically, we propose Skeleton2vec,
a simple and efficient self-supervised 3D action representation learning framework,
which utilizes a transformer-based teacher encoder taking unmasked training samples as
input to create latent contextualized representations as prediction targets.
Benefiting from the self-attention mechanism, the latent representations generated by
the teacher encoder can incorporate the global context of the entire training samples,
leading to a richer training task.
Additionally, considering the high temporal correlations in skeleton sequences, we propose a
motion-aware tube masking strategy which divides the skeleton sequence into
several tubes and performs persistent masking within each tube based on motion priors,
thus forcing the model to build long-range spatio-temporal connections and focus on
action-semantic richer regions. Extensive experiments on NTU-60, NTU-120, and PKU-MMD
datasets demonstrate that our proposed Skeleton2vec outperforms previous methods and
achieves state-of-the-art results.
The source code of Skeleton2vec is available at https://github.com/Ruizhuo-Xu/Skeleton2vec.",[],[]
,[],[]
"Shape modeling research in Computer Graphics has been an active area for decades. The ability to create and edit complex 3D shapes has been of key importance in Computer-Aided Design, Animation, Architecture, and Entertainment. With the growing popularity of Virtual and Augmented Reality, new applications and tools have been developed for artistic content creation; real-time interactive shape modeling has become increasingly important for a continuum of virtual and augmented reality environments (eXtended Reality (XR)). Shape modeling in XR opens new possibilities for intuitive design and shape modeling in an accessible way. Artificial Intelligence (AI) approaches generating shape information from text prompts are set to change how artists create and edit 3D models. There has been a substantial body of research on interactive 3D shape modeling. However, there is no recent extensive review of the existing techniques and what AI shape generation means for shape modeling in interactive XR environments. In this state-of-the-art paper, we fill this research gap in the literature by surveying free-form shape modeling work in XR, with a focus on sculpting and 3D sketching, the most intuitive forms of free-form shape modeling. We classify and discuss these works across five dimensions: contribution of the articles, domain setting, interaction tool, auto-completion, and collaborative designing. The paper concludes by discussing the disconnect between interactive 3D sculpting and sketching and how this will likely evolve with the prevalence of AI shape-generation tools in the future.",[],[]
"We construct a local Noetherian splinter (in fact, a weakly F𝐹Fitalic_F-regular domain) in prime characteristic which is not catenary, which we view as an analogue of a theorem of Ogoma in equal characteristic zero. Moreover, we construct a weakly F𝐹Fitalic_F-regular local UFD which is not Cohen–Macaulay. Both of these examples are obtained via finding sufficient conditions ensuring that a complete local ring of prime characteristic is the completion of some weakly F𝐹Fitalic_F-regular local domain, which we expect to be of independent interest.",[],[]
"In standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients’ blood using microscopes. These isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. This methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. Contemporary leukocyte detection methods exhibit limitations in dealing with images with fewer leukocyte features and the disparity in scale among different leukocytes, leading to unsatisfactory results in most instances. To address these issues, this paper proposes an innovative method of leukocyte detection: the Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte scale disparity, we designed the High-level Screening-feature Fusion Pyramid (HS-FPN), enabling multi-level fusion. This model uses high-level features as weights to filter low-level feature information via a channel attention module and then merges the screened information with the high-level features, thus enhancing the model’s feature expression capability. Further, we address the issue of leukocyte feature scarcity by incorporating a multi-scale deformable self-attention module in the encoder and using the self-attention and cross-deformable attention mechanisms in the decoder, which aids in the extraction of the global features of the leukocyte feature maps. The effectiveness, superiority, and generalizability of the proposed MFDS-DETR method are confirmed through comparisons with other cutting-edge leukocyte detection models using the private WBCDD, public LISC and BCCD datasets. Our source code and private WBCCD dataset are available at https://github.com/JustlfC03/MFDS-DETR.",[],[]
The Aragón Artacho–Campoy algorithm (AACA) is a new method for finding zeros of sums of monotone operators. In this paper we complete the analysis of [2] and [1] by providing study of the two possible Aragón Artacho–Campoy operators.,[],[]
"Open Source Intelligence (OSINT) investigations, which rely entirely on publicly available data such as social media, play an increasingly important role in solving crimes and holding governments accountable. The growing volume of data and complex nature of tasks, however, means there is a pressing need to scale and speed up OSINT investigations. Expert-led crowdsourcing approaches show promise, but tend to either focus on narrow tasks or domains, or require resource-intense, long-term relationships between expert investigators and crowds. We address this gap by providing a flexible framework that enables investigators across domains to enlist crowdsourced support for discovery and verification of OSINT. We use a design-based research (DBR) approach to develop OSINT Research Studios (ORS), a sociotechnical system in which novice crowds are trained to support professional investigators with complex OSINT investigations. Through our qualitative evaluation, we found that ORS facilitates ethical and effective OSINT investigations across multiple domains.
We also discuss broader implications of expert–crowd collaboration and opportunities for future work.","['OSINT', 'open source intelligence', 'design-based research', 'social media investigation', 'collaboration', 'crowdsourcing']",[]
"This paper presents GenH2R, a framework for learning generalizable vision-based human-to-robot (H2R) handover skills. The goal is to equip robots with the ability to reliably receive objects with unseen geometry handed over by humans in various complex trajectories. We acquire such generalizability by learning H2R handover at scale with a comprehensive solution including procedural simulation assets creation, automated demonstration generation, and effective imitation learning. We leverage large-scale 3D model repositories, dexterous grasp generation methods, and curve-based 3D animation to create an H2R handover simulation environment named GenH2R-Sim, surpassing the number of scenes in existing simulators by three orders of magnitude. We further introduce a distillation-friendly demonstration generation method that automatically generates a million high-quality demonstrations suitable for learning. Finally, we present a 4D imitation learning method augmented by a future forecasting objective to distill demonstrations into a visuo-motor handover policy. Experimental evaluations in both simulators and the real world demonstrate significant improvements (at least +10% success rate) over baselines in all cases.",[],[]
"In the paper we prove generalization of Schlömilch’s and Zetel’s theorems about concurrent lines in a triangle. This generalization is obtained as a corollary of sharp geometric inequality about the ratio of triangular areas which is proved using discrete variant of Hölder’s inequality. Also a new sharp refinement of J.F. Rigby’s inequality, which itself generalized Möbius theorem about the areas of triangles formed by cevians of a triangle, is proved.",[],[]
"The high energy (Regge) limit provides a playground for understanding all loop structures of scattering amplitudes, and plays an important role in the description of many phenomenologically relevant cross-sections.
While well understood in the planar limit, the structure of non-planar corrections introduces many fascinating complexities, for which a general organizing principle is still lacking.
We study the structure of multi-reggeon exchanges in the context of the effective field theory for forward scattering, and derive their factorization into collinear operators (impact factors) and soft operators.
We derive the structure of the renormalization group consistency equations in the effective theory, showing how the anomalous dimensions of the soft operators are related to those of the collinear operators, allowing us to derive renormalization group equations in the Regge limit purely from a collinear perspective.
The rigidity of the consistency equations provides considerable insight into the all orders organization of Regge amplitudes in the effective theory, as well as its relation to other approaches. Along the way we derive a number of technical results that improve the understanding of the effective theory.
We illustrate this collinear perspective by re-deriving all the standard BFKL equations for two-Glauber exchange from purely collinear calculations, and we show that this perspective provides a number of conceptual and computational advantages as compared to the standard view from soft or Glauber physics.
We anticipate that this formulation in terms of collinear operators will enable a better understanding of the relation between BFKL and DGLAP in gauge theories, and facilitate the analysis of renormalization group evolution equations describing Reggeization beyond next-to-leading order.",[],[]
"We develop a numerical approach to compute polar parity perturbations within fully relativistic models of black hole systems embedded in generic, spherically symmetric, anisotropic fluids. We apply this framework to study gravitational wave generation and propagation from extreme mass-ratio inspirals in the presence of several astrophysically relevant dark matter models, namely the Hernquist, Navarro-Frenk-White, and Einasto profiles. We also study dark matter spike profiles obtained from a fully relativistic calculation of the adiabatic growth of a BH within the Hernquist profile, and provide a closed-form analytic fit of these profiles. Our analysis completes prior numerical work in the axial sector, yielding a fully numerical pipeline to study black hole environmental effects. We study the dependence of the fluxes on the DM halo mass and compactness. We find that, unlike the axial case, polar fluxes are not adequately described by simple gravitational-redshift effects, thus offering an exciting avenue for the study of black hole environments with gravitational waves.",[],"['Portugal', 'Denmark', 'Italy']"
"The elusive polarized microwave signal from the Fermi bubbles is disentangled from the more extended polarized lobes, which similarly emanate from the Galactic plane but stretch farther west of the bubbles.
The ∼20%similar-toabsentpercent20\sim 20\%∼ 20 % synchrotron polarization reveals magnetic fields preferentially parallel to the bubble edges, as expected downstream of a strong shock.
The ∼20%similar-toabsentpercent20\sim 20\%∼ 20 % polarization of thermal dust emission is similarly oriented, constraining grain alignment in an extreme environment.
We argue that the larger lobes arise from an older Galactic-center, likely supermassive black-hole, outburst.",[],[]
"We present the UV-to-NIR size evolution of a sample of 161 quiescent galaxies with M*>1010⁢M☉subscript𝑀superscript1010subscript𝑀☉M_{*}>10^{10}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT > 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT over 0.5<z<50.5𝑧50.5<z<50.5 < italic_z < 5. With deep multi-band NIRCam images in GOODS-South from JADES, we measure the effective radii (Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT) of the galaxies at rest-frame 0.3, 0.5 and 1µmµm\micronroman_µm. On average, we find that quiescent galaxies are 45% (15%) more compact at rest-frame 1µmµm\micronroman_µm than they are at 0.3µmµm\micronroman_µm (0.5µmµm\micronroman_µm). Regardless of wavelengths, the Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT of quiescent galaxies strongly evolves with redshift, and this evolution depends on stellar mass. For lower-mass quiescent galaxies with M*=1010−1010.6⁢M☉subscript𝑀superscript1010superscript1010.6subscript𝑀☉M_{*}=10^{10}-10^{10.6}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT - 10 start_POSTSUPERSCRIPT 10.6 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT, the evolution follows Re∝(1+z)−1.1proportional-tosubscript𝑅𝑒superscript1𝑧1.1R_{e}\propto(1+z)^{-1.1}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z ) start_POSTSUPERSCRIPT - 1.1 end_POSTSUPERSCRIPT, whereas it becomes steeper, following Re∝(1+z)−1.7proportional-tosubscript𝑅𝑒superscript1𝑧1.7R_{e}\propto(1+z)^{-1.7}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z ) start_POSTSUPERSCRIPT - 1.7 end_POSTSUPERSCRIPT, for higher-mass quiescent galaxies with M*>1010.6⁢M☉subscript𝑀superscript1010.6subscript𝑀☉M_{*}>10^{10.6}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT > 10 start_POSTSUPERSCRIPT 10.6 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT. To constrain the physical mechanisms driving the apparent size evolution, we study the relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and the formation redshift (zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT) of quiescent galaxies. For lower-mass quiescent galaxies, this relationship is broadly consistent with Re∝(1+zform)−1proportional-tosubscript𝑅𝑒superscript1subscript𝑧form1R_{e}\propto(1+z_{\rm{form}})^{-1}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, in line with the expectation of the progenitor effect. For higher-mass quiescent galaxies, the relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT depends on stellar age. Older quiescent galaxies have a steeper relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT than that expected from the progenitor effect alone, suggesting that mergers and/or post-quenching continuous gas accretion drive additional size growth in very massive systems. We find that the z>3𝑧3z>3italic_z > 3 quiescent galaxies in our sample are very compact, with mass surface densities Σe≳1010⁢M☉/kpc2greater-than-or-equivalent-tosubscriptΣ𝑒superscript1010subscript𝑀☉superscriptkpc2\Sigma_{e}\gtrsim 10^{10}M_{\sun}/\rm{kpc}^{2}roman_Σ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ≳ 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT / roman_kpc start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, and their Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT are possibly even smaller than anticipated from the size evolution measured for lower-redshift quiescent galaxies. Finally, we take a close look at the structure of GS-9209, one of the earliest confirmed massive quiescent galaxies at zspec∼4.7similar-tosubscript𝑧spec4.7z_{\rm{spec}}\sim 4.7italic_z start_POSTSUBSCRIPT roman_spec end_POSTSUBSCRIPT ∼ 4.7. From UV to NIR, GS-9209 becomes increasingly compact, and its light profile becomes more spheroidal, showing that the color gradient is already present in this earliest massive quiescent galaxy.","['Galaxy formation(595)', 'Galaxy evolution(594)', 'Galaxy structure(622)', 'High-redshift galaxies(734)']","['Australia', 'Canada', 'France', 'Spain', 'Germany', 'Italy']"
"We present a differentiable model that explicitly models boundaries—including contours, corners and junctions—using a new mechanism that we call boundary attention. We show that our model provides accurate results even when the boundary signal is very weak or is swamped by noise. Compared to previous classical methods for finding faint boundaries, our model has the advantages of being differentiable; being scalable to larger images; and automatically adapting to an appropriate level of geometric detail in each part of an image. Compared to previous deep methods for finding boundaries via end-to-end training, it has the advantages of providing sub-pixel precision, being more resilient to noise, and being able to process any image at its native resolution and aspect ratio.",[],[]
"The importance of the information in the direct sound to human perception of spatial sound sources is an ongoing research topic. The classification between direct sound and diffuse or reverberant sound forms the basis of numerous studies in the field of spatial audio. In particular, parametric spatial audio representation methods use this classification and employ signal processing in order to enhance the audio quality at reproduction. However, current literature does not provide information concerning the impact of ideal direct sound representation on externalization, in the context of Ambisonics. This paper aims to assess the importance of the spatial information in the direct sound in the externalization of a sound field when using binaural reproduction. This is done in the spherical harmonics (SH) domain, where an ideal direct sound representation within an otherwise Ambisonics signal is simulated, and its perceived externalization is evaluated in a formal listening test. This investigation leads to the conclusion that externalization of a first order Ambisonics signal may be significantly improved by enhancing the direct sound component, up to a level similar to a third order Ambisonics signal.",[],['Israel']
"We show that the half-ball in ℝ4superscriptℝ4\mathbb{R}^{4}blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT can be conformally changed so that the only contribution to the Gauss–Bonnet formula is a constant term at the corner.
This may be seen as a fourth-order Cherrier–Escobar-type problem on the half-ball.","['Bilaplacian', 'manifolds with corners', 'corner regularity', 'Gauss-Bonnet', 'Q𝑄Qitalic_Q-curvature', 'T𝑇Titalic_T-curvature', 'U𝑈Uitalic_U-curvature']",[]
"A weak formulation is devised for the K⁢(m,n)𝐾𝑚𝑛K(m,n)italic_K ( italic_m , italic_n ) equation
which is a nonlinearly dispersive generalization of the gKdV equation
having compacton solutions.
With this formulation, explicit weak compacton solutions are derived,
including ones that do not exist as classical (strong) solutions.
Similar results are obtained for a nonlinearly dispersive generalization of the gKP equation in two dimensions,
which possesses line compacton solutions.",[],[]
"We employ a deep learning method to deduce the bulk spacetime from boundary optical conductivity. We apply the neural ordinary differential equation technique, tailored for continuous functions such as the metric, to the typical class of holographic condensed matter models featuring broken translations: linear-axion models. We successfully extract the bulk metric from the boundary holographic optical conductivity. Furthermore, as an example for real material, we use experimental optical conductivity of UPd2⁢Al3subscriptUPd2subscriptAl3\text{UPd}_{2}\text{Al}_{3}UPd start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Al start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, a representative of heavy fermion metals in strongly correlated electron systems, and construct the corresponding bulk metric. To our knowledge, our work is the first illustration of deep learning bulk spacetime from boundary holographic or experimental conductivity data.",[],[]
"Given a player is guaranteed the same payoff for each delivery path in a single-cube delivery network, the player’s best response is to randomly divide all goods and deliver them to all other nodes, and the best response satisfies the Kuhn-Tucker condition. The state of the delivery network is randomly complete. If congestion costs are introduced to the player’s maximization problem in a multi-cubic delivery network, the congestion paradox arises where all coordinates become congested as long as the previous assumptions about payoffs are maintained.
Keywords:
Network theory; Optimal transport; Cubic network; 3D network; Congestion; Transaction cost; Transportation; UAM; Urban air mobility; AAM; Advanced air mobility; Drone; Flying car 
JEL Classification: 
R41; D23; L14.",[],[]
"We present the numerical codes 𝖳𝖠𝖴𝖱𝖴𝖲𝗉𝖺𝗏subscript𝖳𝖠𝖴𝖱𝖴𝖲𝗉𝖺𝗏\textsf{TAURUS}_{\textsf{pav}}TAURUS start_POSTSUBSCRIPT pav end_POSTSUBSCRIPT and 𝖳𝖠𝖴𝖱𝖴𝖲𝗆𝗂𝗑subscript𝖳𝖠𝖴𝖱𝖴𝖲𝗆𝗂𝗑\textsf{TAURUS}_{\textsf{mix}}TAURUS start_POSTSUBSCRIPT mix end_POSTSUBSCRIPT that, combined, perform the configuration mixing of symmetry-projected real general Bogoliubov quasiparticle states represented in a spherical harmonic oscillator basis. The model space considered is invariant under spatial and isospin rotations but no specific set of orbits is assumed such that the codes can carry out both valence-space and no-core calculations.
In addition, no number parity is assumed for the Bogoliubov quasiparticle states such that the codes can be used to describe even-even, odd-even and odd-odd nuclei.
To demonstrate the potential of the codes, we perform an example no-core calculation of 2424{}^{24}start_FLOATSUPERSCRIPT 24 end_FLOATSUPERSCRIPTMg using a modern microscopic interaction.",[],[]
"This paper investigates the relationship between scientific innovation in biomedical sciences and its impact on industrial activities, focusing on how the historical impact and content of scientific papers influenced future funding and innovation grant application content for small businesses. The research incorporates bibliometric analyses along with SBIR (Small Business Innovation Research) data to yield a holistic view of the science-industry interface. By evaluating the influence of scientific innovation on industry across 10,873 biomedical topics and taking into account their taxonomic relationships, we present an in-depth exploration of science-industry interactions where we quantify the temporal effects and impact latency of scientific advancements on industrial activities, spanning from 2010 to 2021. Our findings indicate that scientific progress substantially influenced industrial innovation funding and the direction of industrial innovation activities. Approximately 76% and 73% of topics showed a correlation and Granger-causality between scientific interest in papers and future funding allocations to relevant small businesses. Moreover, around 74% of topics demonstrated an association between the semantic content of scientific abstracts and future grant applications. Overall, the work contributes to a more nuanced and comprehensive understanding of the science-industry interface, opening avenues for more strategic resource allocation and policy developments aimed at fostering innovation.",[],[]
"We study entanglement entropy in a non-relativistic Schrödinger field theory at finite temperature and electric charge using the principle of gauge/gravity duality. The spacetime geometry is obtained from a charged AdS black hole by a null Melvin twist. By using an appropriate modification of the holographic Ryu-Takayanagi formula, we calculate the entanglement entropy, mutual information, and entanglement wedge cross-section for the simplest strip subsystem. The entanglement measures show non-trivial dependence on the black hole parameters.",[],[]
,[],[]
"The EM algorithm is a powerful tool for maximum likelihood estimation with missing data. In practice, the calculations required for the EM algorithm are often intractable. We review numerous methods to circumvent this intractability, all of which are based on Monte Carlo simulation. We focus our attention on the Monte Carlo EM (MCEM) algorithm and its various implementations. We also discuss some related methods like stochastic approximation and Monte Carlo maximum likelihood. Generating the Monte Carlo samples necessary for these methods is, in general, a hard problem. As such, we review several simulation strategies which can be used to address this challenge.
Given the wide range of methods available for approximating the EM, it can be challenging to select which one to use. We review numerous comparisons between these methods from a wide range of sources, and offer guidance on synthesizing the findings. Finally, we give some directions for future research to fill important gaps in the existing literature on the MCEM algorithm and related methods.",[],[]
"Let M=Sn/Γ𝑀superscript𝑆𝑛ΓM=S^{n}/\Gammaitalic_M = italic_S start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT / roman_Γ and h∈π1⁢(M)ℎsubscript𝜋1𝑀h\in\pi_{1}(M)italic_h ∈ italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_M ) be a non-trivial element of finite order p𝑝pitalic_p, where the integers n,p≥2𝑛𝑝2n,p\geq 2italic_n , italic_p ≥ 2 and ΓΓ\Gammaroman_Γ is a finite abelian group which acts on the sphere freely and isometrically. Therefore M𝑀Mitalic_M is diffeomorphic to a compact space form which is a typical non-simply connected manifold. For Γ=ℤ2Γsubscriptℤ2\Gamma=\mathbb{Z}_{2}roman_Γ = blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, we obtain there are at least two non-contractible closed geodesics on ℝ⁢P2ℝsuperscript𝑃2\mathbb{R}P^{2}blackboard_R italic_P start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT whose lengths are bounded by geometry of the manifold from above. Moreover, suppose g0subscript𝑔0g_{0}italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is standard Riemannian metric. We prove that there exists at least n𝑛nitalic_n prime non-contractible closed geodesics on (M,F)𝑀𝐹(M,F)( italic_M , italic_F ) of prescribed class [h]delimited-[]ℎ[h][ italic_h ] without self-intersections, provided F2<(λ+1λ)2⁢g0superscript𝐹2superscript𝜆1𝜆2subscript𝑔0F^{2}<(\frac{\lambda+1}{\lambda})^{2}g_{0}italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT < ( divide start_ARG italic_λ + 1 end_ARG start_ARG italic_λ end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and



(λλ+1)2<K≤1⁢ for n is odd or ⁢ 0<K≤1⁢ for n is even,superscript𝜆𝜆12𝐾1 for n is odd or  0𝐾1 for n is even(\frac{\lambda}{\lambda+1})^{2}<K\leq 1\text{ for $n$ is odd or }\;0<K\leq 1%
\text{ for $n$ is even},( divide start_ARG italic_λ end_ARG start_ARG italic_λ + 1 end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT < italic_K ≤ 1 for italic_n is odd or 0 < italic_K ≤ 1 for italic_n is even ,



where λ𝜆\lambdaitalic_λ is the reversibility and K𝐾Kitalic_K is the flag curvature. Some results on stability are obtained.
Key words: Compact space forms; Non-contractible closed geodesics; Equivariant Morse theory; Self-intersections

AMS Subject Classification: 53C22, 58E05, 58E10.",[],[]
"Amount of information in SAT is estimated and compared with the amount
of information in the fixed code algorithms.
A remark on SAT Kolmogorov complexity is made.
It is argued that SAT can be polynomial-time solvable, or not,
depending on the solving algorithm information content.",[],[]
"The laws that govern the nature often set certain limits or bans. Approaching those limits is a common paradigm of breakthroughs in human knowledge and technological application, such as time slowing to a stop as one approaches the speed of light, electrons flowing freely with no resistance as one approaches the absolute zero, and an event horizon arising as one approaches a black hole. A well-known ban concerning the statistical mechanics of cooperative phenomena, such as ice melting into water, is the nonexistence of phase transition at finite temperature in the Ising model with short-range interactions in one dimension. Yet, little is known about whether this forbidden transition could be approached arbitrarily closely at fixed finite temperature. To explore such asymptoticity, the notion of marginal phase transition (MPT) was introduced recently, and both the spontaneous MPT and the field-induced MPT were discovered respectively in ladder and single-chain Ising models decorated with geometric frustration. Here I push the limit down to the minimal single-chain Ising model—without geometric frustration—in a magnetic field; then, a hidden frustration is revealed to drive the first-order MPT with large latent heat. Furthermore, as one approaches the zero field, MPT appears continuous with no latent heat, displays abrupt change in sublattice magnetization and a kink-like minimum in overall magnetization with temperature, and vanishes when the field drops below a threshold. These findings deepen our understanding of cooperative phenomena via the doubly forbidden and open new avenues to the design and engineering of the Ising systems with the different types of MPT for exploring exotic phenomena and low-dimensional device applications.",[],[]
"Portfolio’s optimal drivers for diversification are common causes of the constituents’ correlations. A closed-form formula for the conditional probability of the portfolio given its optimal common drivers is presented, with each pair constituent-common driver joint distribution modelled by Gaussian copulas. A conditional risk-neutral PDE is obtained for this conditional probability as a system of copulas’ PDEs, allowing for dynamical risk management of a portfolio as shown in the experiments. Implied conditional portfolio volatilities and implied weights are new risk metrics that can be dynamically monitored from the PDEs or obtained from their solution.",[],[]
,[],[]
,[],[]
"Say we have a collection of independent random variables X0,…,Xnsubscript𝑋0…subscript𝑋𝑛X_{0},\ldots,X_{n}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_X start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT,
where X0∼𝒩⁢(μ0,σ02)similar-tosubscript𝑋0𝒩subscript𝜇0superscriptsubscript𝜎02X_{0}\sim\mathcal{N}\left(\mu_{0},\sigma_{0}^{2}\right)italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∼ caligraphic_N ( italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ),
but Xi∼𝒩⁢(μ,σ2)similar-tosubscript𝑋𝑖𝒩𝜇superscript𝜎2X_{i}\sim\mathcal{N}\left(\mu,\sigma^{2}\right)italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∼ caligraphic_N ( italic_μ , italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), for 1≤i≤n1𝑖𝑛1\leq i\leq n1 ≤ italic_i ≤ italic_n.
We characterize the distribution of R0≔1+∑i=1n𝟏{Xi≤X0}≔subscript𝑅01superscriptsubscript𝑖1𝑛subscript1subscript𝑋𝑖subscript𝑋0R_{0}\coloneqq 1+\sum_{i=1}^{n}\mathbf{1}_{\left\{X_{i}\leq X_{0}\right\}}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≔ 1 + ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_1 start_POSTSUBSCRIPT { italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT } end_POSTSUBSCRIPT,
the rank of the random variable whose distribution potentially differs
from that of the others—the odd normal out. We show that R0−1subscript𝑅01R_{0}-1italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - 1
is approximately beta-binomial, an approximation that becomes equality
as σ/σ0𝜎subscript𝜎0\nicefrac{{\sigma}}{{\sigma_{0}}}/ start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG or (μ−μ0)/σ0𝜇subscript𝜇0subscript𝜎0\nicefrac{{\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}/ start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG
become large or small. The intra-class correlation of the approximating
beta-binomial depends on Pr⁡(X1≤X0)Prsubscript𝑋1subscript𝑋0\Pr\left(X_{1}\leq X_{0}\right)roman_Pr ( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and Pr⁡(X1≤X0,X2≤X0)Prsubscript𝑋1subscript𝑋0subscript𝑋2subscript𝑋0\Pr\left(X_{1}\leq X_{0},X_{2}\leq X_{0}\right)roman_Pr ( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ).
Our approach relies on the conjugacy of the beta distribution for
the binomial: Φ⁢((X0−μ)/σ)Φsubscript𝑋0𝜇𝜎\Phi\left(\nicefrac{{\left(X_{0}-\mu\right)}}{{\sigma}}\right)roman_Φ ( / start_ARG ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - italic_μ ) end_ARG start_ARG italic_σ end_ARG )
is approximately Beta⁢(α⁢(σ/σ0,(μ−μ0)/σ0),β⁢(σ/σ0,(μ−μ0)/σ0))Beta𝛼𝜎subscript𝜎0𝜇subscript𝜇0subscript𝜎0𝛽𝜎subscript𝜎0𝜇subscript𝜇0subscript𝜎0\mathrm{Beta}\left(\alpha\left(\nicefrac{{\sigma}}{{\sigma_{0}}},\nicefrac{{%
\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}\right),\beta\left(\nicefrac{{\sigma}}%
{{\sigma_{0}}},\nicefrac{{\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}\right)\right)roman_Beta ( italic_α ( / start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , / start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ) , italic_β ( / start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , / start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ) )
for functions α,β>0𝛼𝛽0\alpha,\beta>0italic_α , italic_β > 0. We study the distributions of the
in-normal ranks. Throughout, simulations corroborate the formulae
we derive.",[],[]
"We compute explicitly the MTW tensor (or cross curvature) for the optimal transport problem on ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT with a cost function of form 𝖼⁢(x,y)=𝗎⁢(x𝔱⁢y)𝖼𝑥𝑦𝗎superscript𝑥𝔱𝑦\mathsf{c}(x,y)=\mathsf{u}(x^{\mathfrak{t}}y)sansserif_c ( italic_x , italic_y ) = sansserif_u ( italic_x start_POSTSUPERSCRIPT fraktur_t end_POSTSUPERSCRIPT italic_y ), where 𝗎𝗎\mathsf{u}sansserif_u is a scalar function with inverse 𝗌𝗌\mathsf{s}sansserif_s, x𝔱⁢ysuperscript𝑥𝔱𝑦x^{\mathfrak{t}}yitalic_x start_POSTSUPERSCRIPT fraktur_t end_POSTSUPERSCRIPT italic_y is a nondegenerate bilinear pairing of vectors x,y𝑥𝑦x,yitalic_x , italic_y belonging to an open subset of ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. The condition that the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a fourth-order nonlinear ODE, which could be reduced to a linear ODE of the form 𝗌(2)−S⁢𝗌(1)+P⁢𝗌=0superscript𝗌2𝑆superscript𝗌1𝑃𝗌0\mathsf{s}^{(2)}-S\mathsf{s}^{(1)}+P\mathsf{s}=0sansserif_s start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT - italic_S sansserif_s start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT + italic_P sansserif_s = 0 with constant coefficients P𝑃Pitalic_P and S𝑆Sitalic_S. The resulting inverse functions include Lambert and generalized inverse hyperbolic/trigonometric functions. The square Euclidean metric and log\logroman_log-type costs are equivalent to instances of these solutions. The optimal map for the family is also explicit. For cost functions of a similar form on a hyperboloid model of the hyperbolic space and unit sphere, we also express this tensor in terms of algebraic expressions in derivatives of 𝗌𝗌\mathsf{s}sansserif_s using the Gauss-Codazzi equation, obtaining new families of strictly regular costs for these manifolds, including new families of power function costs. We analyze the sinh\sinhroman_sinh-type hyperbolic cost, providing examples of 𝖼𝖼\mathsf{c}sansserif_c-convex functions and divergence.","['Optimal transport', 'convex potential', 'divergence', 'Ma-Trudinger-Wang tensor', 'sectional curvature.']",[]
"Optical Fabry-Perot cavity with a movable mirror is a paradigmatic
optomechanical systems. While usually the mirror is supported by a
mechanical spring, it has been shown that it is possible to keep one
of the mirrors in a stable equilibrium purely by optical levitation
without any mechanical support. In this work we expand previous studies
of nonlinear dynamics of such a system by demonstrating a possibility
for mechanical parametric instability and emergence of the “phonon
laser” phenomenon.",[],['Israel']
,[],[]
"The study of cometary composition is important for understanding our solar system’s early evolutionary processes. Carbon dioxide (CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT) is a common hypervolatile in comets that can drive activity but is more difficult to study than other hypervolatiles due to severe telluric absorption. CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT can only be directly observed from space-borne assets. Therefore, a proxy is needed to measure CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT abundances in comets using ground-based observations. The flux ratio of the [O i] 5577 Å line to the sum of the [O i] 6300 Å and [O i] 6364 Å lines (hereafter referred to as the [O i] line ratio) has, with some success, been used in the past as such a proxy. We present an [O i] line ratio analysis of comet 45P/Honda–Mrkos–Pajdušáková (HMP), using data obtained with the Tull Coudé Spectrograph on the 2.7-meter Harlan J. Smith telescope at McDonald Observatory, taken from UT February 21-23, 2017 when the comet was at heliocentric distances of 1.12-1.15 AU. HMP is a hyperactive Jupiter family comet (JFC). Icy grains driven out by CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT sublimation have been proposed as a driver of hyperactivity, but the CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT abundance of HMP has not been measured. From our [O i] line ratio measurements, we find a CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT/H22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO ratio for HMP of 22.9±1.4%plus-or-minus22.9percent1.422.9\pm 1.4\%22.9 ± 1.4 %. We compare the CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT/H22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO ratios to the active fractions of the nine comets (including HMP) in the literature that have data for both values. We find no correlation. These findings imply that CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT sublimation driving out icy grains is not the only factor influencing active fractions for cometary nuclei.","['Comets (280) —', 'Comae (271) —', 'Carbon dioxide (196) —', 'Comet volatiles (2162) —', 'Short period comets (1452)']",[]
"In this paper, we generalize the well-known hyperbolic numbers to
certain numeric structures scaled by the real numbers. Under our scaling
of ℝℝ\mathbb{R}blackboard_R, the usual hyperbolic numbers are understood to be
our 1111-scaled hyperbolic numbers. If a scale t𝑡titalic_t is not positive
in ℝℝ\mathbb{R}blackboard_R, then our t𝑡titalic_t-scaled hyperbolic numbers have similar
numerical structures with those of the complex numbers of ℂℂ\mathbb{C}blackboard_C,
however, if a scale is positive in ℝℝ\mathbb{R}blackboard_R, then their numerical
properties are similar to those of the classical hyperbolic numbers.
We here understand scaled-hyperbolic numbers as elements of the scaled-hypercomplex
rings {ℍt}t∈ℝsubscriptsubscriptℍ𝑡𝑡ℝ\left\{\mathbb{H}_{t}\right\}_{t\in\mathbb{R}}{ blackboard_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t ∈ blackboard_R end_POSTSUBSCRIPT, introduced
in [1]. This scaled-hyperbolic analysis is done by algebra, analysis,
operator theory, operator-algebra theory and free probability on scaled-hypercomplex
numbers.","['Scaled', 'Hypercomplex', 'Rings', 'Scaled', 'Hypercomplex', 'Monoids', 'Scaled', 'Hyperbolic', 'Numbers', 'Free', 'Probability']",[]
,[],[]
"This study investigates the integration of assistive therapeutic robotics, wearable sensors, and spatial sensors within an intelligent environment tailored for dementia care. The feasibility study aims to assess the collective impact of these technologies in enhancing care giving by seamlessly integrating supportive technology in the background. The wearable sensors track physiological data, while spatial sensors monitor geo-spatial information, integrated into a system supporting residents without necessitating technical expertise. The designed space fosters various activities, including robot interactions, medication delivery, physical exercises like walking on a treadmill (Bruce protocol), entertainment, and household tasks, promoting cognitive stimulation through puzzles. Physiological data revealed significant participant engagement during robot interactions, indicating the potential effectiveness of robot-assisted activities in enhancing the quality of life for residents.","['Humanoid', 'Robot', 'Pepper robot', 'dementia friendly living space', 'Alzheimer’s care giving', 'Electrodermal activity', 'EDA', 'Physiological data']",[]
"We present the results of a sensitive search for high-velocity gas in interstellar absorption lines associated with the Cygnus Loop supernova remnant (SNR). We examine high-resolution, high signal-to-noise ratio optical spectra of six stars in the Cygnus Loop region with distances greater than ∼similar-to\sim∼700 pc. All stars show low-velocity Na i and Ca ii absorption. However, only one star, HD 198301, exhibits high-velocity Ca ii absorption components, at velocities of +62, +82, and +96 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. The distance to this star of ∼similar-to\sim∼870 pc helps to constrain the distance to the receding edge of the Cygnus Loop’s expanding shock front. One of our targets, HD 335334, was previously thought to exhibit high positive and high negative velocity interstellar Na i and Ca ii absorption. This was one factor leading Fesen et al. to derive a distance to the Cygnus Loop of 725±15plus-or-minus72515725\pm 15725 ± 15 pc. However, we find that HD 335334 is in fact a double-line spectroscopic binary and shows no evidence of high-velocity interstellar absorption. As such, the distance to HD 335334 cannot be used to constrain the distance to the Cygnus Loop. Our detection of Ca ii absorption approaching 100 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT toward HD 198301 is the first conclusive detection of high-velocity absorption from a low ionization species associated with the Cygnus Loop SNR. A large jump in the Na i column density toward BD+31 4218, a star located beyond the northwestern boundary of the Cygnus Loop, helps to constrain the distance to a large molecular cloud complex with which the Cygnus Loop is evidently interacting.",[],[]
"Structured data in the form of tabular datasets contain features that are distinct and discrete, with varying individual and relative importances to the target. Combinations of one or more features may be more predictive and meaningful than simple individual feature contributions. R’s mixed effect linear models library allows users to provide such interactive feature combinations in the model design. However, given many features and possible interactions to select from, model selection becomes an exponentially difficult task. We aim to automate the model selection process for predictions on tabular datasets incorporating feature interactions while keeping computational costs small. The framework includes two distinct approaches for feature selection: a Priority-based Random Grid Search and a Greedy Search method. The Priority-based approach efficiently explores feature combinations using prior probabilities to guide the search. The Greedy method builds the solution iteratively by adding or removing features based on their impact. Experiments on synthetic demonstrate the ability to effectively capture predictive feature combinations. Code is available at 111https://github.com/AmballaAvinash/ModelSelection.",[],[]
"Cold, neutral interstellar gas, the reservoir for star formation, is
traced through the absorption of the 21-centimetre continuum
radiation by neutral hydrogen (HI). Although detected in one
hundred cases in the host galaxies of distant radio sources, only
recently have column densities approaching the maximum value
observed in Lyman-α𝛼\alphaitalic_α absorption systems (NHI∼1022similar-tosubscript𝑁HIsuperscript1022N_{\text{HI}}\sim 10^{22}italic_N start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT ∼ 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−2superscriptcm2\hbox{{\rm cm}}^{-2}cm start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT) been found. Here we explore the implications these
have for the hypothesis that the detection rate of HI absorption is
dominated by photo-ionisation from the active galactic nucleus
(AGN). We find, with the addition all of the current searches for
HI absorption at z≥0.1𝑧0.1z\geq 0.1italic_z ≥ 0.1, a strong correlation between
the HI absorption strength and the ionising photon rate, with the
maximum value at which HI is detected remaining close to the theoretical value
in which all of the neutral gas would be ionised in a large spiral
galaxy (QHI=2.9×1056subscript𝑄HI2.9superscript1056Q_{\text{HI}}=2.9\times 10^{56}italic_Q start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT = 2.9 × 10 start_POSTSUPERSCRIPT 56 end_POSTSUPERSCRIPT ionising photons s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT).
We also rule out other effects (excitation by the radio
continuum and changing gas properties) as the dominant cause for
the decrease in the detection rate with redshift. Furthermore, from the
maximum theoretical column density we find that the five high
column density systems have spin temperatures close to those of the
Milky Way (Tspin∼<300superscriptsimilar-tosubscript𝑇spin300T_{\rm spin}\stackrel{{\scriptstyle<}}{{{}_{\sim}}}300italic_T start_POSTSUBSCRIPT roman_spin end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG start_FLOATSUBSCRIPT ∼ end_FLOATSUBSCRIPT end_ARG start_ARG < end_ARG end_RELOP 300 K), whereas, from our model of a
gaseous galactic disk, the HI detection at QHI=2.9×1056subscript𝑄HI2.9superscript1056Q_{\text{HI}}=2.9\times 10^{56}italic_Q start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT = 2.9 × 10 start_POSTSUPERSCRIPT 56 end_POSTSUPERSCRIPT s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT yields Tspin∼10 000similar-tosubscript𝑇spin10000T_{\rm spin}\sim 10\,000italic_T start_POSTSUBSCRIPT roman_spin end_POSTSUBSCRIPT ∼ 10 000 K,
consistent with the gas being highly ionised.",[],[]
,[],[]
"The recognition of human activities based on WiFi Channel State Information (CSI) enables contactless and visual privacy-preserving sensing in indoor environments. However, poor model generalization, due to varying environmental conditions and sensing hardware, is a well-known problem in this space. To address this issue, in this work, data augmentation techniques commonly used in image-based learning are applied to WiFi CSI to investigate their effects on model generalization performance in cross-scenario and cross-system settings. In particular, we focus on the generalization between line-of-sight (LOS) and non-line-of-sight (NLOS) through-wall scenarios, as well as on the generalization between different antenna systems, which remains under-explored. We collect and make publicly available a dataset of CSI amplitude spectrograms of human activities. Utilizing this data, an ablation study is conducted in which activity recognition models based on the EfficientNetV2 architecture are trained, allowing us to assess the effects of each augmentation on model generalization performance. The gathered results show that specific combinations of simple data augmentation techniques applied to CSI amplitude data can significantly improve cross-scenario and cross-system generalization.","['Data', 'Augmentation', 'Model', 'Generalization', 'Human', 'Activity', 'Recognition', 'WiFi', 'Channel', 'State', 'Information']",[]
"Exploring generative model training for synthetic tabular data, specifically in sequential contexts such as credit card transaction data, presents significant challenges. This paper addresses these challenges, focusing on attaining both high fidelity to actual data and optimal utility for machine learning tasks. We introduce five pre-processing schemas to enhance the training of the Conditional Probabilistic Auto-Regressive Model (CPAR), demonstrating incremental improvements in the synthetic data’s fidelity and utility. Upon achieving satisfactory fidelity levels, our attention shifts to training fraud detection models tailored for time-series data, evaluating the utility of the synthetic data. Our findings offer valuable insights and practical guidelines for synthetic data practitioners in the finance sector, transitioning from real to synthetic datasets for training purposes, and illuminating broader methodologies for synthesizing credit card transaction time series.",[],[]
,[],[]
"We show that the seemingly different methods used to derive non-Lorentzian (Galilean and Carrollian) gravitational theories from Lorentzian ones are equivalent. Specifically, the pre-nonrelativistic and the pre-ultralocal parametrizations can be constructed from the gauging of the Galilei and Carroll algebras, respectively. Also, the pre-ultralocal approach of taking the Carrollian limit is equivalent to performing the ADM decomposition and then setting the signature of the Lorentzian manifold to zero. We use this uniqueness to write a generic expansion for the curvature tensors and construct Galilean and Carrollian limits of all metric theories of gravity of finite order ranging from the f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity to a completely generic higher derivative theory, the f⁢(gμ⁢ν,Rμ⁢ν⁢σ⁢ρ,∇μ)𝑓subscript𝑔𝜇𝜈subscript𝑅𝜇𝜈𝜎𝜌subscript∇𝜇f(g_{\mu\nu},R_{\mu\nu\sigma\rho},\nabla_{\mu})italic_f ( italic_g start_POSTSUBSCRIPT italic_μ italic_ν end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_μ italic_ν italic_σ italic_ρ end_POSTSUBSCRIPT , ∇ start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT ) gravity. We present an algorithm for calculation of the n𝑛nitalic_n-th order of the Galilean and Carrollian expansions that transforms this problem into a constrained optimization problem. We also derive the condition under which a gravitational theory becomes a modification of general relativity in both limits simultaneously.",[],[]
"After making correct, and then improving, our definition of the category of irregular mixed Hodge modules thanks to Mochizuki’s recent results, we show how these results allow us to obtain Kodaira-Saito-type vanishing theorems for the irregular Hodge filtration of irregular mixed Hodge modules.",[],[]
"Recently, Bemrose et al. [2] developed a theory of weaving frames, which was motivated by a problem regarding distributed signal processing. In this present article, we introduce the atomic g𝑔gitalic_g-system and we generalize some of the known results in continuous L𝐿Litalic_L-frames, weaving continuous and weaving continuous g𝑔gitalic_g-frames, also we study weaving continuous L𝐿Litalic_L-g𝑔gitalic_g-frames in Hilbert spaces.
Moreover, we study the behaviour continuous L𝐿Litalic_L-g𝑔gitalic_g-frames under some perturbations, and we show that approximate L𝐿Litalic_L-duals are stable under small perturbation and that it is possible to remove some elements of a woven continuous L𝐿Litalic_L-g𝑔gitalic_g-frame and still have a woven continuous L𝐿Litalic_L-g𝑔gitalic_g-frame.","['Continuous', 'K𝐾Kitalic_K-frames', 'Continuous g𝑔gitalic_g-frames', 'Weaving continuous', 'K𝐾Kitalic_K-g𝑔gitalic_g-frames', 'perturbation.']",[]
"Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a naïve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",[],[]
"Recent advancements in deep neural networks have markedly enhanced the
performance of computer vision tasks, yet the specialized nature of
these networks often necessitates extensive data and high computational
power. Addressing these requirements, this study presents a novel neural
network model adept at optical character recognition (OCR) across
diverse domains, leveraging the strengths of multi-task learning to
improve efficiency and generalization. The model is designed to achieve
rapid adaptation to new domains, maintain a compact size conducive to
reduced computational resource demand, ensure high accuracy, retain
knowledge from previous learning experiences, and allow for
domain-specific performance improvements without the need to retrain
entirely. Rigorous evaluation on open datasets has validated the model’s
ability to significantly lower the number of trainable parameters
without sacrificing performance, indicating its potential as a scalable
and adaptable solution in the field of computer vision, particularly for
applications in optical text recognition.",[],[]
,[],[]
,[],[]
"Devising procedures for downstream task-oriented generative model selections is an unresolved problem of practical importance. Existing studies focused on the utility of a single family of generative models. They provided limited insights on how synthetic data practitioners select the best family generative models for synthetic training tasks given a specific combination of machine learning model class and performance metric. In this paper, we approach the downstream task-oriented generative model selections problem in the case of training fraud detection models and investigate the best practice given different combinations of model interpretability and model performance constraints. Our investigation supports that, while both Neural Network(NN)-based and Bayesian Network(BN)-based generative models are both good to complete synthetic training task under loose model interpretability constrain, the BN-based generative models is better than NN-based when synthetic training fraud detection model under strict model interpretability constrain. Our results provides practical guidance for machine learning practitioner who is interested in replacing their training dataset from real to synthetic, and shed lights on more general downstream task-oriented generative model selection problems.",[],[]
,[],[]
,[],[]
"We analyse XMM-Newton RGS spectra of Wolf-Rayet (WR) 140, an archetype long-period eccentric WR+O colliding wind binary.
We evaluate the spectra of O and Fe emission lines and find that the plasmas emitting these lines have the largest approaching velocities with the largest velocity dispersions
between phases 0.935 and 0.968 where the inferior conjunction of the O star occurs.
This behaviour is the same as
that of the Ne line-emission plasma presented in our previous paper.
We perform diagnosis of electron number density nesubscript𝑛en_{\rm e}italic_n start_POSTSUBSCRIPT roman_e end_POSTSUBSCRIPT using He-like triplet lines of O and Ne-like Fe-L lines.
The former results in a conservative upper limit of ne≲1010less-than-or-similar-tosubscript𝑛esuperscript1010n_{\rm e}\lesssim 10^{10}italic_n start_POSTSUBSCRIPT roman_e end_POSTSUBSCRIPT ≲ 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT-101212{}^{12}start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT on the O line-emission site, while the latter can not impose any constraint on the Fe line-emission site because of statistical limitations.
We calculate the line-of-sight velocity and its dispersion separately along the shock cone. By comparing the observed and calculated line-of-sight velocities,
we update the distance of the Ne line-emission site from the stagnation point.
By assuming radiative cooling of the Ne line-emission plasma using the observed temperature and the local stellar wind density, we estimate the line-emission site extends along the shock cone by at most ±plus-or-minus\pm±58 per cent (phase 0.816) of the distance from the stagnation point.
In this framework, excess of the observed velocity dispersion over the calculated one is ascribed to
turbulence in the hot-shocked plasma at earlier orbital phases of 0.816, 0.912, and 0.935, with the largest velocity dispersion of 340-630 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT at phase 0.912.",[],[]
,[],['China']
"Neural radiance fields (NeRFs) are promising 3D representations for scenes, objects, and humans. However, most existing methods require multi-view inputs and per-scene training, which limits their real-life applications. Moreover, current methods focus on single-subject cases, leaving scenes of interacting hands that involve severe inter-hand occlusions and challenging view variations remain unsolved. To tackle these issues, this paper proposes a generalizable visibility-aware NeRF (VA-NeRF) framework for interacting hands. Specifically, given an image of interacting hands as input, our VA-NeRF first obtains a mesh-based representation of hands and extracts their corresponding geometric and textural features. Subsequently, a feature fusion module that exploits the visibility of query points and mesh vertices is introduced to adaptively merge features of both hands, enabling the recovery of features in unseen areas. Additionally, our VA-NeRF is optimized together with a novel discriminator within an adversarial learning paradigm. In contrast to conventional discriminators that predict a single real/fake label for the synthesized image, the proposed discriminator generates a pixel-wise visibility map, providing fine-grained supervision for unseen areas and encouraging the VA-NeRF to improve the visual quality of synthesized images. Experiments on the Interhand2.6M dataset demonstrate that our proposed VA-NeRF outperforms conventional NeRFs significantly. Project Page: https://github.com/XuanHuang0/VANeRF.",[],[]
,[],[]
,[],[]
"Ramanujan’s celebrated partition congruences modulo ℓ∈{5,7,11}ℓ5711\ell\in\{5,7,11\}roman_ℓ ∈ { 5 , 7 , 11 } assert that



p⁢(ℓ⁢n+δℓ)≡0(modℓ),𝑝ℓ𝑛subscript𝛿ℓannotated0pmodℓp(\ell n+\delta_{\ell})\equiv 0\pmod{\ell},italic_p ( roman_ℓ italic_n + italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) ≡ 0 start_MODIFIER ( roman_mod start_ARG roman_ℓ end_ARG ) end_MODIFIER ,



where 0<δℓ<ℓ0subscript𝛿ℓℓ0<\delta_{\ell}<\ell0 < italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT < roman_ℓ satisfies 24⁢δℓ≡1(modℓ).24subscript𝛿ℓannotated1pmodℓ24\delta_{\ell}\equiv 1\pmod{\ell}.24 italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ≡ 1 start_MODIFIER ( roman_mod start_ARG roman_ℓ end_ARG ) end_MODIFIER . By proving Subbarao’s Conjecture, Radu showed that there are no such congruences when it comes to parity. There are infinitely many odd (resp. even) partition numbers in every arithmetic progression.
For primes ℓ≥5,ℓ5\ell\geq 5,roman_ℓ ≥ 5 , we give a new proof of the conclusion that there are infinitely many m𝑚mitalic_m for which p⁢(ℓ⁢m+δℓ)𝑝ℓ𝑚subscript𝛿ℓp(\ell m+\delta_{\ell})italic_p ( roman_ℓ italic_m + italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) is odd. This proof uses a generalization, due to the second author and Ramsey, of a result of Mazur in his classic paper on the Eisenstein ideal. We also refine a classical criterion of Sturm for modular form congruences, which allows us to show that the smallest such m𝑚mitalic_m satisfies m<(ℓ2−1)/24,𝑚superscriptℓ2124m<(\ell^{2}-1)/24,italic_m < ( roman_ℓ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 1 ) / 24 ,
representing a significant improvement to the previous bound.",['partition function congruences'],[]
"A hybrid encryption (HE) system is an efficient public key encryption system for arbitrarily long messages.
An HE system consists of a public key component called
key encapsulation mechanism (KEM), and a symmetric key component called data encapsulation mechanism (DEM). The HE encryption algorithm uses a KEM generated key k to encapsulate the message using DEM, and send the ciphertext together with the encapsulaton of k, to the decryptor who decapsulates k and uses it to decapsulate the message using the corresponding KEM and DEM components. The KEM/DEM composition theorem proves that if KEM and DEM satisfy well-defined security notions, then HE will be secure with well defined security.
We introduce HE in correlated randomness model where the encryption and decryption algorithms have samples of correlated random variables that are partially leaked to the adversary. Security of the new KEM/DEM paradigm is defined against computationally unbounded or polynomially bounded adversaries. We define iKEM and cKEM with respective information theoretic computational security, and prove a composition theorem for them and a computationally secure DEM, resulting in secure HEs with proved computational security (CPA and CCA) and without any computational assumption.
We construct two iKEMs that provably satisfy the required security notions of the composition theorem.
The iKEMs are used to construct two efficient quantum-resistant HEs when used with an AES based DEM.
We also define and construct combiners with proved security that combine the new KEM/DEM paradigm of HE with the traditional public key based paradigm of HE.","['Post-quantum cryptography', 'Hybrid encryption', 'Correlated randomness model', 'Encapsulation', 'Mechanism.']",[]
"Stochastic gravitational-wave (GW) background (SGWB) contains information about
the early Universe and astrophysical processes. The recent evidence of SGWB by
pulsar timing arrays in the nanohertz band is a breakthrough in the GW
astronomy. For ground-based GW detectors, while unfortunately in data analysis
the SGWB can be masked by loud GW events from compact binary coalescences
(CBCs). Assuming a next-generation ground-based GW detector network, we
investigate the potential for detecting the astrophysical and cosmological SGWB
with non-CBC origins by subtracting recovered foreground signals of loud CBC
events. As an extension of the studies by Sachdev et al. (2020) and Zhou
et al. (2023), we incorporate aligned spin parameters in our waveform
model. Because of the inclusion of spins, we obtain significantly more
pessimistic results than the previous work, where the residual energy density of
foreground is even larger than the original background. The degeneracy between
the spin parameters and symmetric mass ratio is strong in the parameter
estimation process and it contributes most to the imperfect foreground
subtraction. Our results have important implications for assessing the
detectability of SGWB from non-CBC origins for ground-based GW detectors.",[],['China']
"In this note, we mainly focus on real and complex algebras, and occasionally on algebras over general fields. We show how to develop the spectral theory in the context of complex (resp. real) alternative topological algebras.
Along the way, the spectral theory is used to prove the counterparts of the well-known theorems of Gelfand-Mazur, Frobenius, and Zorn in the setting of topological alternative algebras whose topological duals separate their elements. We prove that vector space norms on quadratic real algebras are uniquely determined under a mild condition on the norms; more precisely, given a positive integer k>1𝑘1k>1italic_k > 1, on any real quadratic algebra, there exists at most one nonzero vector space norm, say, ∥.∥\|.\|∥ . ∥, satisfying the identity ‖ak‖=‖a‖knormsuperscript𝑎𝑘superscriptnorm𝑎𝑘\|a^{k}\|=\|a\|^{k}∥ italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∥ = ∥ italic_a ∥ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT on the algebra. A consequence of this result is that given a positive integer k>1𝑘1k>1italic_k > 1, the Euclidean norm |.||.|| . | on ℝnsubscriptℝ𝑛\mathbb{R}_{n}blackboard_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, the
real Cayley-Dickson algebra of dimension 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, is the only nonzero real vector space norm satisfying the identity |xk|=|x|ksuperscript𝑥𝑘superscript𝑥𝑘|x^{k}|=|x|^{k}| italic_x start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | = | italic_x | start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT on ℝnsubscriptℝ𝑛\mathbb{R}_{n}blackboard_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Among other things, we present simple proofs of the algebraic versions of the celebrated theorems of Frobenius, Zorn, and Gelfand-Mazur, and revisit their topological counterparts, e.g., theorems of Albert, Kaplansky, and Urbanik-Wright to name a few, in several settings.","['nonassociative algebras', 'power-associative/alternative algebras', 'division algebras', 'topologicalormed/C*- algebras', 'spectrum', 'real', 'complex', 'quaternion', 'octonion numbers', 'Frobenius/Zorn/Gelfand-Mazur theorems']",[]
,[],[]
"The causal inference literature frequently focuses on estimating the mean of the potential outcome, whereas the quantiles of the potential outcome may carry important additional information. We propose a universal approach, based on the inverse estimating equations, to generalize a wide class of causal inference solutions from estimating the mean of the potential outcome to its quantiles.
We assume that an identifying moment function is available to identify the mean of the threshold-transformed potential outcome, based on which a convenient construction of the estimating equation of quantiles of potential outcome is proposed. In addition, we also give a general construction of the efficient influence functions of the mean and quantiles of potential outcomes, and identify their connection. We motivate estimators for the quantile estimands with the efficient influence function, and develop their asymptotic properties when either parametric models or data-adaptive machine learners are used to estimate the nuisance functions. A broad implication of our results is that one can rework the existing result for mean causal estimands to facilitate causal inference on quantiles, rather than starting from scratch. Our results are illustrated by several examples.",[],[]
"The rise of multimodal large language models (MLLMs) has spurred interest in language-based driving tasks. However, existing research typically focuses on limited tasks and often omits key multi-view and temporal information which is crucial for robust autonomous driving. To bridge these gaps, we introduce NuInstruct, a novel dataset with 91K multi-view video-QA pairs across 17 subtasks, where each task demands holistic information ( e.g., temporal, multi-view, and spatial), significantly elevating the challenge level. To obtain NuInstruct, we propose a novel SQL-based method to generate instruction-response pairs automatically, which is inspired by the driving logical progression of humans. We further present BEV-InMLLM, an end-to-end method for efficiently deriving instruction-aware Bird’s-Eye-View (BEV) features, language-aligned for large language models. BEV-InMLLM integrates multi-view, spatial awareness, and temporal semantics to enhance MLLMs’ capabilities on NuInstruct tasks. Moreover, our proposed BEV injection module is a plug-and-play method for existing MLLMs. Our experiments on NuInstruct demonstrate that BEV-InMLLM significantly outperforms existing MLLMs, e.g. 9%percent99\%9 % improvement on various tasks. We plan to release our NuInstruct for future research development.",[],[]
"Since distribution shifts are likely to occur after a model’s deployment and can drastically decrease the model’s performance, online test-time adaptation (TTA) continues to update the model during test-time, leveraging the current test data. In real-world scenarios, test data streams are not always independent and identically distributed (i.i.d.). Instead, they are frequently temporally correlated, making them non-i.i.d. Many existing methods struggle to cope with this scenario. In response, we propose a diversity-aware and category-balanced buffer that can simulate an i.i.d. data stream, even in non-i.i.d. scenarios. Combined with a diversity and entropy-weighted entropy loss, we show that a stable adaptation is possible on a wide range of corruptions and natural domain shifts, based on ImageNet. We achieve state-of-the-art results on most considered benchmarks.",[],[]
"We study properties of the Maxwell electromagnetic invariant
in the external region of spinning and charged horizonless stars.
We analytically find that the minimum negative
value of the Maxwell electromagnetic invariant is obtained
on the equator of the star surface.
We are interested in scalar fields
non-minimally coupled to the Maxwell electromagnetic invariant.
The negative enough Maxwell electromagnetic invariant can lead to a
negative effective mass term, which forms a
binding potential well for the scalar field.
It means that the scalar field
coupled to the Maxwell electromagnetic invariant may mostly
exist around the surface of the star on the equator.",[],['China']
,[],[]
"More than one hundred tidal disruption events (TDEs) have been detected at multi-bands, which can be viewed as extreme laboratories to investigate the accretion physics and gravity in the immediate vicinity of massive black holes (MBHs). Future transient surveys are expected to detect several tens of thousands of TDEs, among which a small fraction may be strongly gravitationally lensed by intervening galaxies. In this paper, we statistically etsimate the detection rate of lensed TDEs, with dependence on the limiting magnitude of the transient all-sky surveys searching for them. We find that the requisite limiting magnitude for an all-sky transient survey to observe at least 1111 yr−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT is ≳21.3greater-than-or-equivalent-toabsent21.3\gtrsim 21.3≳ 21.3, 21.221.221.221.2, and 21.521.521.521.5 mag in the u-, g-, and z-bands, respectively. If the limiting magnitude of the all-sky survey can reach ∼25−26similar-toabsent2526\sim 25-26∼ 25 - 26 mag in the u-, g-, and z-bands, the detection rate can be upto about several tens to hundreds per year. The discovery and identification of the first image of the lensed TDE can be taken as an early-warning of the second and other subsequent images, which may enable detailed monitoring of the pre-peak photometry and spectroscopy evolution of the TDE. The additional early-stage information may help to constrain the dynamical and radiation processes involving in the TDEs.","['Accretion (14)', 'Gravitational lensing (670)', 'Supermassive black holes (1663)', 'Tidal disruption (1696)', 'Time domain astronomy(2019)', 'Transient sources (1851)']",['China']
"In this paper we first show that among all double-toroidal and triple-toroidal finite graphs only K8⊔9⁢K1square-unionsubscript𝐾89subscript𝐾1K_{8}\sqcup 9K_{1}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, K8⊔5⁢K2square-unionsubscript𝐾85subscript𝐾2K_{8}\sqcup 5K_{2}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 5 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, K8⊔3⁢K4square-unionsubscript𝐾83subscript𝐾4K_{8}\sqcup 3K_{4}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 3 italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT, K8⊔9⁢K3square-unionsubscript𝐾89subscript𝐾3K_{8}\sqcup 9K_{3}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 italic_K start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, K8⊔9⁢(K1∨3⁢K2)square-unionsubscript𝐾89subscript𝐾13subscript𝐾2K_{8}\sqcup 9(K_{1}\vee 3K_{2})italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 ( italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∨ 3 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ), 3⁢K63subscript𝐾63K_{6}3 italic_K start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and 3⁢K6⊔4⁢K4⊔6⁢K2square-union3subscript𝐾64subscript𝐾46subscript𝐾23K_{6}\sqcup 4K_{4}\sqcup 6K_{2}3 italic_K start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT ⊔ 4 italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ⊔ 6 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT can be realized as commuting graphs of finite groups. As consequences of our results we also show that for any finite non-abelian group G𝐺Gitalic_G if the commuting graph of G𝐺Gitalic_G (denoted by Γc⁢(G)subscriptΓ𝑐𝐺\Gamma_{c}(G)roman_Γ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_G )) is double-toroidal or triple-toroidal then Γc⁢(G)subscriptΓ𝑐𝐺\Gamma_{c}(G)roman_Γ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_G ) and its complement satisfy Hansen-Vukičević Conjecture and E-LE conjecture. In the process we find a non-complete graph, namely the non-commuting graph of the group (ℤ3×ℤ3)⋊Q8right-normal-factor-semidirect-productsubscriptℤ3subscriptℤ3subscript𝑄8(\mathbb{Z}_{3}\times\mathbb{Z}_{3})\rtimes Q_{8}( blackboard_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT × blackboard_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) ⋊ italic_Q start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT, that is hyperenergetic. This gives a new counter example to a conjecture of Gutman regarding hyperenergetic graphs.",[],[]
,[],[]
,[],[]
"The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones).
To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm.
Then, considering two kinds of representative and heterogeneous attack
mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we implement another instance called MMIA-SafeCompress by
extending SafeCompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. We conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. The results show the effectiveness and generalizability of our framework. We also discuss how to adapt SafeCompress to other attacks besides membership inference attack, demonstrating the flexibility of SafeCompress.","['AI software safe compression', 'test-driven development', 'heterogeneous membership inference attack.']",[]
"The sensitivity of Impact Factors (IFs) to journal size causes systematic bias in IF rankings, in a process akin to stacking the cards: A random “journal” of n𝑛nitalic_n papers can attain a range of IF values that decreases rapidly with size, as ∼1/nsimilar-toabsent1𝑛\sim 1/\sqrt{n}∼ 1 / square-root start_ARG italic_n end_ARG . The Central Limit Theorem, which underlies this effect, allows us also to correct for it by standardizing citation averages for scale and subject in a geometrically intuitive manner analogous to calculating the z𝑧zitalic_z-score. We thus propose the ΦΦ\Phiroman_Φ index, a standardized scale- and subject-independent citation average. The ΦΦ\Phiroman_Φ index passes the “random sample test”, a simple check for scale and subject independence that we argue ought to be used for every citation indicator. We present ΦΦ\Phiroman_Φ index rankings for 12,173 journals using data from the 2020 Journal Citation Reports. We show how scale standardization alone affects rankings, then we demonstrate the additional effect of subject standardization for monodisciplinary journals, and we discuss how to treat multidisciplinary journals.
ΦΦ\Phiroman_Φ index rankings offer a clear improvement over IF rankings. And because the ΦΦ\Phiroman_Φ index methodology is general, it can also be applied to compare individual researchers, universities, or countries.",[],[]
"This paper concerns the scattering problem for a nonlinear medium of compact support, D𝐷Ditalic_D, with second-harmonic generation. Such a medium, when probed with monochromatic light beams at frequency ω𝜔\omegaitalic_ω, generates additional waves at frequency 2⁢ω2𝜔2\omega2 italic_ω. The response of the medium is governed by a system of two coupled semilinear partial differential equations for the electric fields at frequency ω𝜔\omegaitalic_ω and 2⁢ω2𝜔2\omega2 italic_ω. We investigate whether there are situations in which the generated 2⁢ω2𝜔2\omega2 italic_ω wave is localized inside D𝐷Ditalic_D, that is, the nonlinear interaction of the medium with the probing wave is invisible to an outside observer. This leads to the analysis of a semilinear elliptic system formulated in D𝐷Ditalic_D with non-standard boundary conditions. The analysis presented here sets up a mathematical framework needed to investigate a multitude of questions related to nonlinear scattering with second-harmonic generation.",[],[]
"With copper-substituted lead apatite below room temperature, we observe diamagnetic dc magnetization under magnetic field of 25 Oe with remarkable bifurcation between zero-field-cooling and field-cooling measurements, and under 200 Oe it changes to be paramagnetism. A glassy memory effect is found during cooling. Typical hysteresis loops for superconductors are detected below 250 K, along with an asymmetry between forward and backward sweep of magnetic field. Our experiment suggests at room temperature the Meissner effect is possibly present in this material.",[],['China']
"We discuss the critical points of modular forms, or more generally the zeros of quasimodular forms of depth 1111 for PSL2⁢(ℤ)subscriptPSL2ℤ\mathrm{PSL}_{2}(\mathbb{Z})roman_PSL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_Z ). In particular, we consider the derivatives of the unique weight k𝑘kitalic_k modular forms fksubscript𝑓𝑘f_{k}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with the maximal number of consecutive zero Fourier coefficients following the constant 1111. Our main results state that (1) every zero of a depth 1111 quasimodular form near the derivative of the Eisenstein series in the standard fundamental domain lies on the geodesic segment {z∈ℍ:ℜ⁡(z)=1/2}conditional-set𝑧ℍ𝑧12\{z\in\mathbb{H}:\Re(z)=1/2\}{ italic_z ∈ blackboard_H : roman_ℜ ( italic_z ) = 1 / 2 }, and (2) more than half of zeros of fksubscript𝑓𝑘f_{k}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in the standard fundamental domain lie on the geodesic segment {z∈ℍ:ℜ⁡(z)=1/2}conditional-set𝑧ℍ𝑧12\{z\in\mathbb{H}:\Re(z)=1/2\}{ italic_z ∈ blackboard_H : roman_ℜ ( italic_z ) = 1 / 2 } for large enough k𝑘kitalic_k with k≡0(mod12)𝑘annotated0pmod12k\equiv 0\pmod{12}italic_k ≡ 0 start_MODIFIER ( roman_mod start_ARG 12 end_ARG ) end_MODIFIER.",[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
"Text-to-image diffusion models have demonstrated unprecedented abilities at flexible and realistic image synthesis.
However, the iterative process required to produce a single image is costly and incurs a high latency, prompting researchers to further investigate its efficiency.
Typically, improvements in latency have been achieved in two ways: (1) training smaller models through knowledge distillation (KD); and (2) adopting techniques from ODE-theory to facilitate larger step sizes.
In contrast, we propose a training-free approach that does not alter the step-size of the sampler.
Specifically, we find the repeated calculation of attention maps to be both costly and redundant; therefore, we propose a structured reuse of attention maps during sampling.
Our initial reuse policy is motivated by rudimentary ODE-theory, which suggests that reuse is most suitable late in the sampling procedure.
After noting a number of limitations in this theoretical approach, we empirically search for a better policy.
Unlike methods that rely on KD, our reuse policies can easily be adapted to a variety of setups in a plug-and-play manner.
Furthermore, when applied to Stable Diffusion-1.5, our reuse policies reduce latency with minimal repercussions on sample quality.",[],[]
,[],[]
"Unsupervised Anomaly Detection (UAD) with incremental training is crucial in industrial manufacturing, as unpredictable defects make obtaining sufficient labeled data infeasible.
However, continual learning methods primarily rely on supervised annotations, while the application in UAD is limited due to the absence of supervision.
Current UAD methods train separate models for different classes sequentially, leading to catastrophic forgetting and a heavy computational burden.
To address this issue, we introduce a novel Unsupervised Continual Anomaly Detection framework called UCAD, which equips the UAD with continual learning capability through contrastively-learned prompts.
In the proposed UCAD, we design a Continual Prompting Module (CPM) by utilizing a concise key-prompt-knowledge memory bank to guide task-invariant ‘anomaly’ model predictions using task-specific ‘normal’ knowledge.
Moreover, Structure-based Contrastive Learning (SCL) is designed with the Segment Anything Model (SAM) to improve prompt learning and anomaly segmentation results.
Specifically, by treating SAM’s masks as structure, we draw features within the same mask closer and push others apart for general feature representations.
We conduct comprehensive experiments and set the benchmark on unsupervised continual anomaly detection and segmentation, demonstrating that our method is significantly better than anomaly detection methods, even with rehearsal training.
The code will be available at https://github.com/shirowalker/UCAD.",[],[]
"Programming problems can be solved in a multitude of functionally correct ways, but the quality of these solutions (e.g. readability, maintainability) can vary immensely.
When code quality is poor, symptoms emerge in the form of ‘code smells’, which are specific negative characteristics (e.g. duplicate code) that can be resolved by applying refactoring patterns.
Many undergraduate computing curricula train students on this software engineering practice, often doing so via exercises on unfamiliar instructor-provided code.
Our observation, however, is that this makes it harder for novices to internalise refactoring as part of their own development practices.
In this paper, we propose a new approach to teaching refactoring, in which students must first complete a programming exercise constrained to ensure they will produce a code smell.
This simple intervention is based on the idea that learning refactoring is easier if students are familiar with the code (having built it), that it brings refactoring closer to their regular development practice, and that it presents a powerful opportunity to learn from a ‘mistake’.
We designed and conducted a study with 35 novice undergraduates in which they completed various refactoring exercises alternately taught using a traditional and our ‘mistake-based’ approach, finding that students were significantly more effective and confident at completing exercises using the latter.","['Refactoring', 'code smells', 'code quality', 'software maintenance', 'software engineering', 'mistake-based learning', 'undergraduate course']",['Singapore']
"In this paper, our objective is to present a constraining principle governing the spectral properties of the sample covariance matrix. This principle exhibits harmonious behavior across diverse limiting frameworks, eliminating the need for constraints on the rates of dimension p𝑝pitalic_p and sample size n𝑛nitalic_n, as long as they both tend to infinity. We accomplish this by employing a suitable normalization technique on the original sample covariance matrix. Following this, we establish a harmonic central limit theorem for linear spectral statistics within this expansive framework. This achievement effectively eliminates the necessity for a bounded spectral norm on the population covariance matrix and relaxes constraints on the rates of dimension p𝑝pitalic_p and sample size n𝑛nitalic_n, thereby significantly broadening the applicability of these results in the field of high-dimensional statistics. We illustrate the power of the established results by considering the test for covariance structure under high dimensionality, freeing both p𝑝pitalic_p and n𝑛nitalic_n.","['62H15', '62B20', '62D10', 'ultra-high dimension\ncovariance matrix central limit theorem limiting spectral distribution linear spectral statistics', 'M-P law']",[]
"Recent research at CHU Sainte-Justine’s Pediatric Critical Care Unit (PICU) has revealed that traditional machine learning methods, such as semi-supervised label propagation and K-nearest neighbors, outperform Transformer-based models in artifact detection from PPG signals, mainly when data is limited. This study addresses the underutilization of abundant unlabeled data by employing self-supervised learning (SSL) to extract latent features from these data, followed by fine-tuning on labeled data. Our experiments demonstrate that SSL significantly enhances the Transformer model’s ability to learn representations, thereby improving its robustness in artifact classification tasks. Among various SSL techniques—including masking, contrastive learning, and DINO (self-distillation with no labels)—contrastive learning exhibited the most stable and superior performance in small PPG datasets. Further, we delve into optimizing contrastive loss functions, which are crucial for contrastive SSL. Inspired by InfoNCE, we introduce a novel contrastive loss function that facilitates smoother training and better convergence, thereby enhancing performance in artifact classification. In summary, this study establishes the efficacy of SSL in leveraging unlabeled data, particularly in enhancing the capabilities of the Transformer model. This approach holds promise for broader applications in PICU environments, where annotated data is often limited.","['clinical', 'PPG signals', 'self-supervised', 'contrastive learning', 'imbalanced classes', 'and artifact detection.']",[]
"In this paper, we investigate k𝑘kitalic_k-nonseparable (2≤k≤n)2𝑘𝑛(2\leq k\leq n)( 2 ≤ italic_k ≤ italic_n ) entanglement measures based on geometric mean of all entanglement values of k𝑘kitalic_k-partitions in n𝑛nitalic_n-partite quantum systems. We define a class of entanglement measures called k𝑘kitalic_k-GM concurrence which explicitly detect all k𝑘kitalic_k-nonseparable states in multipartite systems. It is rigorously shown that the k𝑘kitalic_k-GM concurrence complies with all the conditions of an entanglement measure. Compared to k𝑘kitalic_k-ME concurrence [Phys. Rev. A 86, 062323 (2012)], the measures proposed by us emerge several different aspects, embodying that (i) k𝑘kitalic_k-GM concurrence can reflect the differences in entanglement but k𝑘kitalic_k-ME concurrence fails at times, (ii) k𝑘kitalic_k-GM concurrence does not arise sharp peaks when the pure state being measured varies continuously, while k𝑘kitalic_k-ME concurrence appears discontinuity points, (iii) the entanglement order is sometimes distinct. In addition, we establish the relation between k𝑘kitalic_k-ME concurrence and k𝑘kitalic_k-GM concurrence, and further derive a strong lower bound on the k𝑘kitalic_k-GM concurrence by exploiting the permutationally invariant part of a quantum state. Furthermore, we parameterize k𝑘kitalic_k-GM concurrence to obtain two categories of more generalized entanglement measures, q𝑞qitalic_q-k𝑘kitalic_k-GM concurrence (q>1,2≤k≤n)formulae-sequence𝑞12𝑘𝑛(q>1,2\leq k\leq n)( italic_q > 1 , 2 ≤ italic_k ≤ italic_n ) and α𝛼\alphaitalic_α-k𝑘kitalic_k-GM concurrence (0≤α<1,2≤k≤n)formulae-sequence0𝛼12𝑘𝑛(0\leq\alpha<1,2\leq k\leq n)( 0 ≤ italic_α < 1 , 2 ≤ italic_k ≤ italic_n ), which fulfill the properties possessed by k𝑘kitalic_k-GM concurrence as well. Moreover, α𝛼\alphaitalic_α-2222-GM concurrence (0<α<1)0𝛼1(0<\alpha<1)( 0 < italic_α < 1 ), as a type of genuine multipartite entanglement measures, is proven in detail satisfying the requirement that the GHZ state is more entangled than the W𝑊Witalic_W state in multiqubit systems.",[],['China']
"In our previous work, we introduced McKinsey-Tarski algebras (MT-algebras for short) as an alternative pointfree approach to topology. Here we study local compactness in MT-algebras.
We establish the Hofmann-Mislove theorem
for sober MT-algebras, using which we develop the MT-algebra versions of such well-known dualities in pointfree topology as
Hofmann-Lawson, Isbell, and Stone dualities. This yields
a new perspective on these classic results.","['Interior operator', 'pointfree topology', 'duality theory', 'local compactness', 'compactness']",[]
,[],[]
,[],[]
,[],[]
"Personalized PageRank (PPR) is an extensively studied and applied node proximity measure in graphs.
For a pair of nodes s𝑠sitalic_s and t𝑡titalic_t on a graph G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ), the PPR value π⁢(s,t)𝜋𝑠𝑡\pi(s,t)italic_π ( italic_s , italic_t ) is defined as the probability that an α𝛼\alphaitalic_α-discounted random walk from s𝑠sitalic_s terminates at t𝑡titalic_t, where the walk terminates with probability α𝛼\alphaitalic_α at each step.
We study the classic Single-Source PPR query, which asks for PPR approximations from a given source node s𝑠sitalic_s to all nodes in the graph.
Specifically, we aim to provide approximations with absolute error guarantees, ensuring that the resultant PPR estimates π^⁢(s,t)^𝜋𝑠𝑡\hat{\pi}(s,t)over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) satisfy maxt∈V⁡|π^⁢(s,t)−π⁢(s,t)|≤εsubscript𝑡𝑉^𝜋𝑠𝑡𝜋𝑠𝑡𝜀\max_{t\in V}\big{|}\hat{\pi}(s,t)-\pi(s,t)\big{|}\leq\varepsilonroman_max start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT | over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) - italic_π ( italic_s , italic_t ) | ≤ italic_ε for a given error bound ε𝜀\varepsilonitalic_ε.
We propose an algorithm that achieves this with high probability, with an expected running time of


•

O~⁢(m/ε)~𝑂𝑚𝜀\widetilde{O}\big{(}\sqrt{m}/\varepsilon\big{)}over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_m end_ARG / italic_ε ) for directed graphs333O~⁢(⋅)~𝑂⋅\widetilde{O}(\cdot)over~ start_ARG italic_O end_ARG ( ⋅ ) suppresses polylog⁡(n)polylog𝑛\operatorname{polylog}(n)roman_polylog ( italic_n ) factors., where m=|E|𝑚𝐸m=|E|italic_m = | italic_E |;



•

O~⁢(dmax/ε)~𝑂subscript𝑑𝜀\widetilde{O}\big{(}\sqrt{d_{\max}}/\varepsilon\big{)}over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_d start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT end_ARG / italic_ε ) for undirected graphs, where dmaxsubscript𝑑d_{\max}italic_d start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum node degree in the graph;



•

O~⁢(nγ−1/2/ε)~𝑂superscript𝑛𝛾12𝜀\widetilde{O}\left(n^{\gamma-1/2}/\varepsilon\right)over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT italic_γ - 1 / 2 end_POSTSUPERSCRIPT / italic_ε ) for power-law graphs, where n=|V|𝑛𝑉n=|V|italic_n = | italic_V | and γ∈(12,1)𝛾121\gamma\in\left(\frac{1}{2},1\right)italic_γ ∈ ( divide start_ARG 1 end_ARG start_ARG 2 end_ARG , 1 ) is the extent of the power law.



These sublinear bounds improve upon existing results.
We also study the case when degree-normalized absolute error guarantees are desired, requiring maxt∈V⁡|π^⁢(s,t)/d⁢(t)−π⁢(s,t)/d⁢(t)|≤εdsubscript𝑡𝑉^𝜋𝑠𝑡𝑑𝑡𝜋𝑠𝑡𝑑𝑡subscript𝜀𝑑\max_{t\in V}\big{|}\hat{\pi}(s,t)/d(t)-\pi(s,t)/d(t)\big{|}\leq\varepsilon_{d}roman_max start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT | over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) / italic_d ( italic_t ) - italic_π ( italic_s , italic_t ) / italic_d ( italic_t ) | ≤ italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT for a given error bound εdsubscript𝜀𝑑\varepsilon_{d}italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, where the graph is undirected and d⁢(t)𝑑𝑡d(t)italic_d ( italic_t ) is the degree of node t𝑡titalic_t.
We give an algorithm that provides this error guarantee with high probability, achieving an expected complexity of O~⁢(∑t∈Vπ⁢(s,t)/d⁢(t)/εd)~𝑂subscript𝑡𝑉𝜋𝑠𝑡𝑑𝑡subscript𝜀𝑑\widetilde{O}\left(\sqrt{\sum_{t\in V}\pi(s,t)/d(t)}\big{/}\varepsilon_{d}\right)over~ start_ARG italic_O end_ARG ( square-root start_ARG ∑ start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT italic_π ( italic_s , italic_t ) / italic_d ( italic_t ) end_ARG / italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ).
This improves over the previously known O⁢(1/εd)𝑂1subscript𝜀𝑑O(1/\varepsilon_{d})italic_O ( 1 / italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) complexity.",[],[]
,[],[]
,[],[]
,[],[]
"Suicide is recognized as one of the most serious concerns in the modern society. Suicide causes tragedy that affects countries, communities, and families. There are many factors that lead to suicidal ideations. Early detection of suicidal ideations can help to prevent suicide occurrence by providing the victim with the required professional support, especially when the victim does not recognize the danger of having suicidal ideations. As technology usage has increased, people share and express their ideations digitally via social media, chatbots, and other digital platforms. In this paper, we proposed a novel, simple deep learning-based model to detect suicidal ideations in digital content, mainly focusing on chatbots as the primary data source. In addition, we provide a framework that employs the proposed suicide detection integration with a chatbot-based support system.","['Suicide', 'deep learning', 'chatbot', 'natural language processing', 'detection']",[]
,[],[]
,[],[]
,[],[]
"This work is inspired by Shareshian and Wachs’s exquisite formula for the chromatic symmetric function of paths. We develop a composition method to unearth neat noncommutative analogs of chromatic symmetric functions. A symmetric function is e𝑒eitalic_e-positive if and only if it has a ΛΛ\Lambdaroman_Λ-positive noncommutative analog. We bring to light short and sweet ΛΛ\Lambdaroman_Λ-positive noncommutative analogs for the chromatic symmetric functions of tadpoles and barbells, with cycles and lollipops as specifications. Using these elegant formulas and the composition method, we discover a new family of e𝑒eitalic_e-positive graphs and call them hats, which are the unicyclic graphs obtained by adding an edge to a path. A compact ribbon Schur analog for cycles is also obtained as a by-product.","['chromatic symmetric functions', 'e𝑒eitalic_e-positivity', 'noncommutative symmetric functions', 'Stanley–Stembridge conjecture', 'Schur positivity']",[]
"We present the mean star formation histories (SFHs) of 148 dwarf lenticular galaxies (dS0s) derived from SDSS spectra. The SFHs of dS0s are characterized by multiple bursts of star formation, including an initial burst at a lookback time of ∼14similar-toabsent14\sim 14∼ 14 Gyr for most galaxies. Stars formed during the first star-forming phase which ends at a lookback time of 6.3 Gyr primarily consist of old, metal-poor (Z=0.0004) stars , contributing to ∼60%similar-toabsentpercent60\sim 60\%∼ 60 % of the stellar mass and ∼30%similar-toabsentpercent30\sim 30\%∼ 30 % of the luminosity. The almost absence of extremely metal poor (Z=0.0001) stars seems to be due to pre-enrichment during the re-ionization era. Star formation gradually decreases during this initial period. In contrast, during the second period of star formation, there is an increase in star formation activity, peaking at a lookback time of 2.5 Gyr before declining again. Most moderately old stellar populations with intermediate metallicity were formed during this phase. We observe a strong dependence of SFHs on the mass and u-r color of dS0 galaxies but no significant dependence on morphological properties such as the presence or absence of outer spiral arms and nucleation. The star formation history of dS0 galaxies shares many similarities with that of dE galaxies, and many of them are believed to have originated from late-type galaxies.
galaxies.",[],[]
,[],[]
"A graph G𝐺Gitalic_G is k𝑘kitalic_k-factor-critical if G−S𝐺𝑆G-Sitalic_G - italic_S has a perfect matching for any
k𝑘kitalic_k-subset S𝑆Sitalic_S of the vertex set of G𝐺Gitalic_G. In this paper, we investigate the factor-criticality of graphs with fixed minimum degree and provide sufficient conditions for such graphs
to be k𝑘kitalic_k-factor-critical in terms of spectral radius and signless Laplacian spectral radius. 

Keywords: factor-critical graph, minimum degree, spectral radius, signless Laplacian spectral radius",[],[]
"We investigate the quantum phase transition in the alternating XY chain with the XZY+YZX type of three-spin interactions. We present the exact solution derived by means of the Jordan-Wigner transformation and study the average magnetization, spin correlations, and von Neumann entropy to establish the phase diagram. By examining the nearest-neighbor transverse spin correlation, we probe that in the phase with zero magnetization (ZM), the spins within a supercell tend to point to opposite directions of the external field, but between the nearest-neighbor supercells are distributed randomly. This is the reason for the magnetization vanishing in the ZM phase under the alternating hopping interaction. In addition, we also investigate the influence of the three-site interaction, and find that the ZM phase is absent as the strength of the three-site interaction increases. Our findings shed light on the complex behavior of the alternating XY chain and provide valuable insights for future studies.",[],['China']
,[],[]
"A new position is introduced and studied for the convolution of log-concave functions, which may be regarded as a functional analogue of the maximum intersection position of convex bodies introduced and studied by Artstein-Avidan and Katzin (2018) and Artstein-Avidan and Putterman (2022). Our main result is a John-type theorem for the maximal intersection position of a pair of log-concave functions, including the corresponding decomposition of the identity. The main result holds under very weak assumptions on the functions; in particular, the functions considered may both have unbounded supports.","['convex body', 'convolution', 'isotropic', 'John position', 'log-concave', 'maximal intersection position']",[]
"Semantic segmentation models trained on annotated data fail to generalize well when the input data distribution changes over extended time period, leading to requiring re-training to maintain performance. Classic Unsupervised domain adaptation (UDA) attempts to address a similar problem when there is target domain with no annotated data points through transferring knowledge from a source domain with annotated data. We develop an online UDA algorithm for semantic segmentation of images that improves model generalization on unannotated domains in scenarios where source data access is restricted during adaptation. We perform model adaptation is by minimizing the distributional distance between the source latent features and the target features in a shared embedding space. Our solution promotes a shared domain-agnostic latent feature space between the two domains, which allows for classifier generalization on the target dataset. To alleviate the need of access to source samples during adaptation, we approximate the source latent feature distribution via an appropriate surrogate distribution, in this case a Gassian mixture model (GMM). We evaluate our approach on well established semantic segmentation datasets and demonstrate it compares favorably against state-of-the-art (SOTA) UDA semantic segmentation methods.111Partial results of this work were presented in the AAAI Conference Stan and Rostami (2021b).",[],[]
"The correctness of a compiler affects the correctness of every program written in the language, and thus must be thoroughly evaluated. Existing automatic compiler testing methods however either rely on weak oracles (e.g., a program behaves the same if only dead code is modified), or require substantial initial effort (e.g., having a complete operational language semantics).
While the former prevents a comprehensive correctness evaluation, the latter makes those methods irrelevant in practice.
In this work, we propose an axiomatic semantics based approach for testing compilers, called PTE. The idea is to incrementally develop a set of “axioms” capturing anecdotes of the language semantics in the form of (precondition, transformation, expectation) triples, which allows us to test the compiler automatically. Such axioms are written in the same language whose compiler is under test, and can be developed either based on the language specification, or by generalizing the bug reports. PTE has been applied to a newly developed compiler (i.e., Cangjie) and a mature compiler (i.e., Java), and successfully identified 42 implementation bugs and 9 potential language design issues.","['Compiler testing', 'language semantics', 'automated testing']","['Singapore', 'China']"
"Let BunBun{\operatorname{Bun}}roman_Bun be the moduli stack of rank 2222 bundles with fixed determinant on a smooth proper curve C𝐶Citalic_C over a local field F𝐹Fitalic_F.
We show how to associate with a Schwartz κ𝜅\kappaitalic_κ-density,
for Re⁡(κ)≥1/2Re𝜅12{\operatorname{Re}}(\kappa)\geq 1/2roman_Re ( italic_κ ) ≥ 1 / 2,
a smooth function on the corresponding coarse moduli space of very stable bundles.
In the non-archimedean case we also prove that the stack BunBun{\operatorname{Bun}}roman_Bun is κ𝜅\kappaitalic_κ-bounded in the sense of [4, Def. 2.10] for any κ∈ℂ𝜅ℂ\kappa\in\operatorname{\mathbb{C}}italic_κ ∈ blackboard_C.",[],[]
"The full array of the Large High Altitude Air Shower Observatory (LHAASO) has been in operation since July 2021. For its kilometer-square array (KM2A), we have optimized the selection criteria for very high and ultra-high energy γ𝛾\gammaitalic_γ-rays, using the data collected from August 2021 to August 2022, resulting in an improvement on significance of about 15%percent\%% compared with previous cuts. With the implementation of these new selection criteria, the angular resolution is also significantly improved by approximately 10%percent\%% at tens of TeV. Other aspects of the full KM2A array performance, such as the pointing error are also calibrated using the Crab Nebula. The resulting energy spectrum of the Crab Nebula in the energy range of 10-1000 TeV can be well fitted by a log-parabola model, which is consistent with the previous results from LHAASO and other experiments.","['γ𝛾\\gammaitalic_γ-ray', 'Crab', 'Nebula significance.']","['Ireland', 'Switzerland', 'France', 'Germany', 'Thailand', 'China']"
,[],[]
"The remarkable advancements in artificial intelligence (AI), primarily driven by deep neural networks, have significantly impacted various aspects of our lives. However, the current challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability call for the development of next-generation AI systems. Neuro-symbolic AI (NSAI) emerges as a promising paradigm, fusing neural, symbolic, and probabilistic approaches to enhance interpretability, robustness, and trustworthiness while facilitating learning from much less data. Recent NSAI systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we provide a systematic review of recent progress in NSAI and analyze the performance characteristics and computational operators of NSAI models. Furthermore, we discuss the challenges and potential future directions of NSAI from both system and architectural perspectives.",[],[]
,[],[]
"Event-based cameras provide accurate and high temporal resolution measurements for performing computer vision tasks in challenging scenarios, such as high-dynamic range environments and fast-motion maneuvers. Despite their advantages, utilizing deep learning for event-based vision encounters a significant obstacle due to the scarcity of annotated data caused by the relatively recent emergence of event-based cameras. To overcome this limitation, leveraging the knowledge available from annotated data obtained with conventional frame-based cameras presents an effective solution based on unsupervised domain adaptation. We propose a new algorithm tailored for adapting a deep neural network trained on annotated frame-based data to generalize well on event-based unannotated data. Our approach incorporates uncorrelated conditioning and self-supervised learning in an adversarial learning scheme to close the gap between the two source and target domains. By applying self-supervised learning, the algorithm learns to align the representations of event-based data with those from frame-based camera data, thereby facilitating knowledge transfer.
Furthermore, the inclusion of uncorrelated conditioning ensures that the adapted model effectively distinguishes between event-based and conventional data, enhancing its ability to classify event-based images accurately.
Through empirical experimentation and evaluation, we demonstrate that our algorithm surpasses existing approaches designed for the same purpose using two benchmarks. The superior performance of our solution is attributed to its ability to effectively utilize annotated data from frame-based cameras and transfer the acquired knowledge to the event-based vision domain.
111This paper is based on results partially presented at the 2023 International Conference on Computer Vision jian2023unsupervised .",[],[]
"It has been an unanswered question how many dusty galaxies have been undetected from the state-of-the-art observational surveys. JWST enables us to detect faint IR galaxies that have prominent polycyclic aromatic hydrocarbon (PAH) features in the mid-IR wavelengths. PAH is a valuable tracer of star formation and dust properties in the mid-infrared wavelength. The JWST Cosmic Evolution Early Release Science (CEERS) fields provide us with wavelength coverage from 7.7 to 21 μ𝜇\muitalic_μm using six photometric bands of the mid-infrared instrument (MIRI). We have identified galaxies dominated by mid-IR emission from PAHs, termed PAH galaxies. From our multi-band photometry catalogue, we selected ten PAH galaxies displaying high flux ratios of log⁡(S15/S10)>0.8subscript𝑆15subscript𝑆100.8\log(S_{15}/S_{10})>0.8roman_log ( italic_S start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) > 0.8. The SED fitting analysis indicates that these galaxies are star-forming galaxies with total IR luminosities of 1010superscript101010^{10}10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT ∼similar-to\sim∼ 1011.5superscript1011.510^{11.5}10 start_POSTSUPERSCRIPT 11.5 end_POSTSUPERSCRIPT L⊙subscript𝐿direct-productL_{\odot}italic_L start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT at z ∼1similar-toabsent1\sim 1∼ 1. The morphology of PAH galaxies does not show any clear signatures of major merging or interaction within the MIRI resolution. The majority of them are on the star-formation main sequence at z∼1similar-to𝑧1z\sim 1italic_z ∼ 1. Our result demonstrates that JWST can detect PAH emissions from normal star-forming galaxies at z∼1similar-to𝑧1z\sim 1italic_z ∼ 1, in addition to ultra-luminous infrared galaxies (ULIRGs) or luminous infrared galaxies (LIRGs).",[],[]
"Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments of text-audio alignment in TTA. Our findings reveal Auffusion’s superior capability in generating audios that accurately match textual descriptions, which further demonstrated in several related tasks, such as audio style transfer, inpainting and other manipulations. Project page is available at https://auffusion.github.io.",[],[]
"In the stratified or partially premixed piloted jet flames, previous experimental and p⁢r⁢i⁢o⁢r⁢i𝑝𝑟𝑖𝑜𝑟𝑖prioriitalic_p italic_r italic_i italic_o italic_r italic_i studies have identified a strong correlation between mixture fraction and progress variable. In the framework of large-eddy simulation (LES) and flamelet-generated manifolds (FGM) approach, a joint probability density function (PDF) method is constructed to characterize subgrid correlations. To pave the way for high dimensional tabulation modeling, a deep residual network (ResNet) is trained, dramatically reducing the memory footprint of tabulation. The Message Passing Interface (MPI) shared memory technique is applied to load the original chemical table during parallel computations. Application of LES to a partially pre-vaporized ethanol spray flame demonstrates good agreement with experimental results. Consideration of the subgrid correlation results in a noticeable improvement in temperature prediction. Calculations using ResNet show a notable consistency with those using chemical tables. Visualization of enthalpy highlights the significance of non-adiabatic tabulation in modeling liquid fuel combustion. The unscaled progress variable is selected to better describe the chemical reaction rate in the blending zone of an air stream and a pilot stream with the product of a fully burnt lean fuel mixture. The impact of the source term due to evaporation in the transport equation of the progress variable is validated. The correlation coefficient is found to significantly influence the chemical reaction rate. The subgrid-scale interaction between liquid fuel evaporation and subgrid correlation is elucidated.",[],[]
"As a higher analogue of the edge ideal of a graph, we study the t𝑡titalic_t-connected ideal JtsubscriptJ𝑡\operatorname{J}_{t}roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This is the monomial ideal generated by the connected subsets of size t𝑡titalic_t. For trees, we show that JtsubscriptJ𝑡\operatorname{J}_{t}roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT has a linear resolution iff the tree is t𝑡titalic_t-gap-free, and that this is equivalent to having linear quotients. We then show that if G𝐺Gitalic_G is any gap-free and t𝑡titalic_t-claw-free graph, then Jt⁡(G)subscriptJ𝑡𝐺\operatorname{J}_{t}(G)roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_G ) has linear quotients and hence, linear resolution.","['Independence complex', 'Stanley-Reisner ideal', 'edge ideal', 'linear resolution', 'shellable', 'linear quotients']",[]
"We investigate the power iteration algorithm for the tensor PCA model introduced in [RM14]. Previous work studying the properties of tensor power iteration is either limited to a constant number of iterations, or requires a non-trivial data-independent initialization. In this paper, we move beyond these limitations and analyze the dynamics of randomly initialized tensor power iteration up to polynomially many steps. Our contributions are threefold: First, we establish sharp bounds on the number of iterations required for power method to converge to the planted signal, for a broad range of the signal-to-noise ratios. Second, our analysis reveals that the actual algorithmic threshold for power iteration is smaller than the one conjectured in literature by a polylog⁢(n)polylog𝑛\mathrm{polylog}(n)roman_polylog ( italic_n ) factor, where n𝑛nitalic_n is the ambient dimension. Finally, we propose a simple and effective stopping criterion for power iteration, which provably outputs a solution that is highly correlated with the true signal. Extensive numerical experiments verify our theoretical results.",[],[]
"This paper presents a series of new results for domain adaptation in the multi-view learning
setting. The incorporation of multiple views in the domain adaptation was paid little attention in the previous studies. In this way, we propose an analysis of generalization bounds with Pac-Bayesian theory to consolidate the two paradigms, which are currently treated separately. Firstly, building on previous work by Germain et al. [7, 8], we adapt the distance between distribution proposed by Germain et al. for domain adaptation with the concept of multi-view learning. Thus, we introduce a novel distance that is tailored for the multi-view domain adaptation setting. Then, we give Pac-Bayesian bounds for estimating the introduced divergence. Finally, we compare the different new bounds with the previous studies.","['PAC-Bayesian', 'Domain', 'Adaptation', 'Multi-view', 'Learning.']",[]
"The homogenization of eigenvalues of non-Hermitian Maxwell operators is studied by the H-convergence method. It is assumed that the Maxwell systems are equipped with suitable m-dissipative boundary conditions, namely, with Leontovich or generalized impedance boundary conditions of the form 𝐧×𝐄=Z⁢[(𝐧×𝐇)×𝐧]𝐧𝐄𝑍delimited-[]𝐧𝐇𝐧\mathbf{n}\times\mathbf{E}=Z[(\mathbf{n}\times\mathbf{H})\times\mathbf{n}]bold_n × bold_E = italic_Z [ ( bold_n × bold_H ) × bold_n ]. We show that, for a wide class of impedance operators Z𝑍Zitalic_Z, the nonzero spectrum of the corresponding Maxwell operator is discrete. To this end, a new continuous embedding theorem for domains of Maxwell operators is obtained. We prove the convergence of eigenvalues to an eigenvalue of a homogenized Maxwell operator under the assumption of the H-convergence of the material tensor-fields. This result is applied then to the existence of optimizers for eigenvalue optimization problems and to the existence of an eigenvalue-free region around zero. Connections with unique (and nonunique) continuation results are discussed.",[],[]
,[],[]
"We investigate the minimal Kitaev spin liquid on a single hexagon with three
Ising-type exchange interactions proportional to Kxsubscript𝐾𝑥K_{x}italic_K start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT, Kysubscript𝐾𝑦K_{y}italic_K start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT and Kzsubscript𝐾𝑧K_{z}italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT. In the limit Kz=0subscript𝐾𝑧0K_{z}=0italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT = 0, we find 32-fold zero-energy states, leading to 10
free Majorana fermions, and hence, 5 qubits are constructed. These qubits
are protected by particle-hole symmetry even for Kz≠0subscript𝐾𝑧0K_{z}\neq 0italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ≠ 0. Braiding of
these Majorana fermions is possible by temporally controlling a
spin-correlation Hamiltonian. In addition, the fusion is possible by
measuring the spin correlation. By switching on the Heisenberg interaction
together with magnetic field, only one zero-energy state persists, which can
be used as an initialization of qubits. Furthermore, it is shown that 3⁢L+23𝐿23L+23 italic_L + 2
qubits are constructed on the Kitaev spin liquid model on connected L𝐿Litalic_L
hexagons. All the processes of initialization, operation and readout of
qubits are executable in terms of spin operators.",[],['Japan']
"In this paper we construct new indecomposable motivic cycles in the group Hℳ3⁢(X,ℚ⁢(2))subscriptsuperscript𝐻3ℳ𝑋ℚ2H^{3}_{{\mathcal{M}}}(X,{\mathds{Q}}(2))italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT caligraphic_M end_POSTSUBSCRIPT ( italic_X , blackboard_Q ( 2 ) ) where X𝑋Xitalic_X is a degree 2222 K⁢3𝐾3K3italic_K 3 surface. This generalizes our construction in [Sre22] for Kummer surfaces of Abelian surfaces as well as the recent work of Ma and Sato [MS23] on degree 2222 K⁢3𝐾3K3italic_K 3 surfaces.",[],[]
"Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517517517517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specific languages, our approach facilitates the development of practical NLG applications for African communities. The findings of this study contribute to advancing NLP research in low-resource settings, enabling greater accessibility and inclusion for African languages in a rapidly expanding digital landscape. We will publicly release our models for research. 111https://github.com/UBC-NLP/Cheetah†† ⋆⋆{}^{\star}start_FLOATSUPERSCRIPT ⋆ end_FLOATSUPERSCRIPT Authors contributed equally.",[],[]
"The goal of Continual Learning (CL) is to continuously learn from new data streams and accomplish the corresponding tasks.
Previously studied CL assumes that data are given in sequence nose-to-tail for different tasks, thus indeed belonging to Serial Continual Learning (SCL).
This paper studies the novel paradigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios, where a diverse set of tasks is encountered at different time points.
PCL presents challenges due to the training of an unspecified number of tasks with varying learning progress, leading to the difficulty of guaranteeing effective model updates for all encountered tasks.
In our previous conference work, we focused on measuring and reducing the discrepancy among gradients in a multi-objective optimization problem, which, however, may still contain negative transfers in every model update.
To address this issue, in the dynamic multi-objective optimization problem, we introduce task-specific elastic factors to adjust the descent direction towards the Pareto front.
The proposed method, called Elastic Multi-Gradient Descent (EMGD), ensures that each update follows an appropriate Pareto descent direction, minimizing any negative impact on previously learned tasks.
To balance the training between old and new tasks, we also propose a memory editing mechanism guided by the gradient computed using EMGD. This editing process updates the stored data points, reducing interference in the Pareto descent direction from previous tasks.
Experiments on public datasets validate the effectiveness of our EMGD in the PCL setting.","['parallel continual learning', 'catastrophic forgetting', 'training conflict', 'multi-objective optimization', 'Pareto optimum.']",[]
"In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language.
To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model’s level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model’s response quality is conducted, considering aspects such as accuracy, fluency, informativeness, logical coherence, and harmlessness, based on LLM-Eval, a benchmarks consisting instruction tasks from 17 diverse categories.
Our evaluation results demonstrate that comparable performance to state-of-the-art transfer models can be achieved with less than 1%percent11\%1 % of the pretraining data, both in terms of knowledge alignment and response quality. Furthermore, the experimental outcomes across the thirteen low-resource languages also exhibit similar trends. We anticipate that the conclusions revealed by the experiments will aid the community in developing non-English LLMs.",[],[]
"Automatic Modulation Recognition (AMR) plays a crucial role in wireless communication systems.
Deep learning AMR strategies have achieved tremendous success in recent years.
Modulated signals exhibit long temporal dependencies, and extracting global features is crucial in identifying modulation schemes.
Traditionally, human experts analyze patterns in constellation diagrams to classify modulation schemes.
Classical convolutional-based networks, due to their limited receptive fields, excel at extracting local features but struggle to capture global relationships.
To address this limitation, we introduce a novel hybrid deep framework named TLDNN, which incorporates the architectures of the transformer and long short-term memory (LSTM).
We utilize the self-attention mechanism of the transformer to model the global correlations in signal sequences while employing LSTM to enhance the capture of temporal dependencies.
To mitigate the impact like RF fingerprint features and channel characteristics on model generalization, we propose data augmentation strategies known as segment substitution (SS) to enhance the model’s robustness to modulation-related features.
Experimental results on widely-used datasets demonstrate that our method achieves state-of-the-art performance and exhibits significant advantages in terms of complexity. Our proposed framework serves as a foundational backbone that can be extended to different datasets.
We have verified the effectiveness of our augmentation approach in enhancing the generalization of the models, particularly in few-shot scenarios.
Code is available at https://github.com/AMR-Master/TLDNN.","['Automatic modulation recognition', 'transformer', 'LSTM', 'deep learning', 'data augmentation']",[]
We prove a reciprocity relation for the twisted second moment of the Riemann Zeta function. This provides an analogue to a formula of Conrey for Dirichlet L𝐿Litalic_L-functions.,"['Riemann', 'Zeta function', 'Dirichlet', 'L𝐿Litalic_L-functions', 'twisted second moment', 'reciprocity relation']",[]
"We study the Boltzmann equation in a smooth bounded domain featuring a mixed boundary condition. Specifically, gas particles experience specular reflection in two parallel plates, while diffusive reflection occurs in the remaining portion between these two specular regions. The boundary is assumed to be motionless and isothermal. Our main focus is on constructing global-in-time small-amplitude solutions around global Maxwellians for the corresponding initial-boundary value problem. The proof relies on the L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT hypocoercivity at the linear level, utilizing the weak formulation and various functional inequalities on the test functions, such as Poincaré and Korn inequalities. It also extends to the linear problem involving Maxwell boundary conditions, where the accommodation coefficient can be a piecewise constant function on the boundary, allowing for more general bounded domains. Moreover, we develop a delicate application of the L2−L∞superscript𝐿2superscript𝐿L^{2}-L^{\infty}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_L start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT bootstrap argument, which relies on the specific geometry of our domains, to effectively handle this mixed-type boundary condition.","['Boltzmann equation', 'global existence', 'long time asymptotics', 'mixed boundary conditions']",[]
,[],[]
"Given an idempotent p𝑝pitalic_p in a Banach algebra and following the study in [6] of p-invertibility, we
consider here left p-invertibility, right p-invertibility and p-invertibility in the Calkin Algebra 𝒞⁢(X),𝒞𝑋\mathcal{C}(X),caligraphic_C ( italic_X ) ,
where X𝑋Xitalic_X is a Banach space. Then we define and study left and right generalized Drazin invertibility
and we characterize left and right Drazin invertible elements in the Calkin algebra. Globally, this leads to define and characterize the classes of P-Fredholm, pseudo B-Fredholm and weak B-Fredholm operators.",[],[]
"The recent development on large language models makes automatically constructing small programs possible. It thus has the potential to free software engineers from low-level coding and allow us to focus on the perhaps more interesting parts of software development, such as requirement engineering and system testing. In this project, we develop a prototype named AISD (AI-aided Software Development), which is capable of taking high-level (potentially vague) user requirements as inputs, generates detailed use cases, prototype system designs, and subsequently system implementation. Different from existing attempts, AISD is designed to keep the user in the loop, i.e., by repeatedly taking user feedback on use cases, high-level system designs, and prototype implementations through system testing. AISD has been evaluated with a novel benchmark of non-trivial software projects. The experimental results suggest that it might be possible to imagine a future where software engineering is reduced to requirement engineering and system testing only.","['Requirement engineering', 'system testing', 'large language model', 'code generation']","['Singapore', 'China']"
"Studying the relations between entanglement and coherence is essential in many quantum information applications. For this, we consider the concurrence, intrinsic concurrence and first-order coherence, and evaluate the proposed trade-off relations between them. In particular, we study the temporal evolution of a general two-qubit XYZ Heisenberg model with asymmetric spin-orbit interaction under decoherence and analyze the trade-off relations of quantum resource theory.
For XYZ Heisenberg model, we confirm that the trade-off relation between intrinsic concurrence and first-order coherence holds. Furthermore, we show that the lower bound of intrinsic concurrence is universally valid, but the upper bound is generally not.
These relations in Heisenberg models can provide a way to explore how quantum resources are distributed in spins, which may inspire future applications in quantum information processing.","['Trade-off relations', 'First-order coherence', 'Intrinsic concurrence', 'Heisenberg models']",['Qatar']
"We propose a robust hypothesis testing procedure for the predictability of multiple predictors that could be highly persistent. Our method improves the popular extended instrumental variable (IVX) testing (Phillips and Lee,, 2013; Kostakis et al.,, 2015) in that, besides addressing the two bias effects found in Hosseinkouchack and Demetrescu, (2021), we find and deal with the variance-enlargement effect. We show that two types of higher-order terms induce these distortion effects in the test statistic, leading to significant over-rejection for one-sided tests and tests in multiple predictive regressions. Our improved IVX-based test includes three steps to tackle all the issues above regarding finite sample bias and variance terms. Thus, the test statistics perform well in size control, while its power performance is comparable with the original IVX. Monte Carlo simulations and an empirical study on the predictability of bond risk premia are provided to demonstrate the effectiveness of the newly proposed approach.",[],[]
"The demand for the retrieval of complex scene data in autonomous driving is increasing, especially as passenger vehicles have been equipped with the ability to navigate urban settings, with the imperative to address long-tail scenarios. Meanwhile, under the pre-existing two dimensional image retrieval method, some problems may arise with scene retrieval, such as lack of global feature representation and subpar text retrieval ability. To address these issues, we have proposed BEV-CLIP, the first multimodal Bird’s-Eye View(BEV) retrieval methodology that utilizes descriptive text as an input to retrieve corresponding scenes. This methodology applies the semantic feature extraction abilities of a large language model (LLM) to facilitate zero-shot retrieval of extensive text descriptions, and incorporates semi-structured information from a knowledge graph to improve the semantic richness and variety of the language embedding. Our experiments result in 87.66% accuracy on NuScenes dataset in text-to-BEV feature retrieval. The demonstrated cases in our paper support that our retrieval method is also indicated to be effective in identifying certain long-tail corner scenes.",[],[]
"Due to the poor illumination and the difficulty in annotating, nighttime conditions pose a significant challenge for autonomous vehicle perception systems. Unsupervised domain adaptation (UDA) has been widely applied to semantic segmentation on such images to adapt models from normal conditions to target nighttime-condition domains. Self-training (ST) is a paradigm in UDA, where a momentum teacher is utilized for pseudo-label prediction, but a confirmation bias issue exists. Because the one-directional knowledge transfer from a single teacher is insufficient to adapt to a large domain shift. To mitigate this issue, we propose to alleviate domain gap by incrementally considering style influence and illumination change. Therefore, we introduce a one-stage Dual-Teacher Bi-directional Self-training (DTBS) framework for smooth knowledge transfer and feedback. Based on two teacher models, we present a novel pipeline to respectively decouple style and illumination shift. In addition, we propose a new Re-weight exponential moving average (EMA) to merge the knowledge of style and illumination factors, and provide feedback to the student model. In this way, our method can be embedded in other UDA methods to enhance their performance. For example, the Cityscapes to ACDC night task yielded 53.8 mIoU (%), which corresponds to an improvement of +5% over the previous state-of-the-art. The code is available at https://github.com/hf618/DTBS.",[],[]
"The safe operation of most tokamaks, especially the largen sized ones, rely on the feedback control of the vertical displacement events (VDEs). However, most these feedback control systems are based on the axisymmetric VDE models. In this work, we use NIMROD simulations to study the roles of non-axisymmetric perturbations in free drift vertical displacement events on EAST. The high-n𝑛nitalic_n modes in non-axisymmetric VDE grow first, which drive the formation of high-n𝑛nitalic_n magnetic island chains. Subsequently, the magnetic island chains grow and overlap with each other, leading to the destruction of the magnetic flux surface, which induces a minor disruption and accelerates the start of the following major disruption. The magnetic island and the stochastic magnetic field allow the toroidally asymmetric poloidal plasma current to jet towards the hoop force direction, forming the finger and filamentary structures. Such a plasma current asymmetry strongly depends on the anisotropy in thermal transport coefficients.",[],[]
"We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.
Keywords: Legal Language Processing, Topic Models, Text-as-Data, Domain Name Disputes, European Court of Human Rights",[],[]
"In this paper, we propose an iterative convolution-thresholding method (ICTM) based on prediction-correction for solving the topology optimization problem in steady-state heat transfer equations. The problem is formulated as a constrained minimization problem of the complementary energy, incorporating a perimeter/surface-area regularization term, while satisfying a steady-state heat transfer equation. The decision variables of the optimization problem represent the domains of different materials and are represented by indicator functions. The perimeter/surface-area term of the domain is approximated using Gaussian kernel convolution with indicator functions. In each iteration, the indicator function is updated using a prediction-correction approach. The prediction step is based on the variation of the objective functional by imposing the constraints, while the correction step ensures the monotonically decreasing behavior of the objective functional. Numerical results demonstrate the efficiency and robustness of our proposed method, particularly when compared to classical approaches based on the ICTM.",[],[]
"In robust optimization problems, the magnitude of perturbations is relatively small.
Consequently, solutions within certain regions are less likely to represent the robust optima when perturbations are introduced.
Hence, a more efficient search process would benefit from increased opportunities to explore promising regions where global optima or good local optima are situated.
In this paper, we introduce a novel robust evolutionary algorithm named the dual-stage robust evolutionary algorithm (DREA) aimed at discovering robust solutions.
DREA operates in two stages: the peak-detection stage and the robust solution-searching stage.
The primary objective of the peak-detection stage is to identify peaks in the fitness landscape of the original optimization problem.
Conversely, the robust solution-searching stage focuses on swiftly identifying the robust optimal solution using information obtained from the peaks discovered in the initial stage.
These two stages collectively enable the proposed DREA to efficiently obtain the robust optimal solution for the optimization problem.
This approach achieves a balance between solution optimality and robustness by separating the search processes for optimal and robust optimal solutions.
Experimental results demonstrate that DREA significantly outperforms five state-of-the-art algorithms across 18 test problems characterized by diverse complexities.
Moreover, when evaluated on higher-dimensional robust optimization problems (100-D𝐷Ditalic_D and 200-D𝐷Ditalic_D), DREA also demonstrates superior performance compared to all five counterpart algorithms.","['Evolutionary robust optimization', 'evolutionary algorithm', 'dual-stage strategy', 'peak detection']",[]
It is shown that the category of fuzzy ordered sets and order-preserving maps valued in the quantale based on a continuous triangular norm on the unit interval contains a largest Cartesian closed and stable subconstruct which contains all crisp ordered sets.,[],[]
"In this paper, we present Coyote C++, a fully automated white-box unit testing tool for C and C++. Whereas existing tools have struggled to realize unit test generation for C++, Coyote C++ is able to produce high coverage results from unit test generation at a testing speed of over 10,000 statements per hour. This impressive feat is made possible by the combination of a powerful concolic execution engine with sophisticated automated test harness generation. Additionally, the GUI of Coyote C++ displays detailed code coverage visualizations and provides various configuration features for users seeking to manually optimize their coverage results. Combining potent one-click automated testing with rich support for manual tweaking, Coyote C++ is the first automated testing tool that is practical enough to make automated testing of C++ code truly viable in industrial applications.","['Software', 'Testing', 'Test case generation', 'Automated unit test generation', 'Symbolic execution', 'C++']",[]
"Medical data collected for making a diagnostic decision are typically multi-modal and provide complementary perspectives of a subject. A computer-aided diagnosis system welcomes multi-modal inputs; however, how to effectively fuse such multi-modal data is a challenging task and attracts a lot of attention in the medical research field. In this paper, we propose a transformer-based framework, called Alifuse, for aligning and fusing multi-modal medical data. Specifically, we convert images and unstructured and structured texts into vision and language tokens, and use intramodal and intermodal attention mechanisms to learn holistic representations of all imaging and non-imaging data for classification. We apply Alifuse to classify Alzheimer’s disease and obtain state-of-the-art performance on five public datasets, by outperforming eight baselines. The source code will be available online later.",[],[]
"Monocular 3D object detection poses a significant challenge due to the lack of depth information in RGB images.
Many existing methods strive to enhance the object depth estimation performance by allocating additional parameters for object depth estimation, utilizing extra modules or data.
In contrast, we introduce a novel metric learning scheme that encourages the model to extract depth-discriminative features regardless of the visual attributes without increasing inference time and model size.
Our method employs the distance-preserving function to organize the feature space manifold in relation to ground-truth object depth.
The proposed (K,B,ϵ)𝐾𝐵italic-ϵ(K,B,\epsilon)( italic_K , italic_B , italic_ϵ )-quasi-isometric loss leverages predetermined pairwise distance restriction as guidance for adjusting the distance among object descriptors without disrupting the non-linearity of the natural feature manifold.
Moreover, we introduce an auxiliary head for object-wise depth estimation, which enhances depth quality while maintaining the inference time.
The broad applicability of our method is demonstrated through experiments that show improvements in overall performance when integrated into various baselines.
The results show that our method consistently improves the performance of various baselines by 25.27% and 4.54% on average across KITTI and Waymo, respectively.",[],[]
"Recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. These models have demonstrated significant improvements by fine-tuning on downstream tasks. However, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. In this paper, we propose a parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog retrieval. Specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model CLIP.
Besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data.
To facilitate various types of retrieval, we also design multiple experts to learn mappings from CLIP outputs to multi-modal representation space, with each expert being responsible to one specific retrieval type. Extensive experiments show that DialCLIP achieves state-of-the-art performance on two widely recognized benchmark datasets (i.e., PhotoChat and MMDialog) by tuning a mere 0.04% of the total parameters. These results highlight the efficacy and efficiency of our proposed approach, underscoring its potential to advance the field of multi-modal dialog retrieval.",[],[]
,[],[]
"Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the ”luc bat” genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the ”luc bat” genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.","['GPT-3', 'poem generation', 'BLOOM', 'Vietnamese', 'quantization', 'LoRa']",[]
,[],[]
,[],[]
"Visual-inertial SLAM is essential in various fields, such as AR/VR, uncrewed aerial vehicles, industrial robots, and autonomous driving. The fusion of a camera and inertial measurement unit (IMU) can make up for the shortcomings of a signal sensor, which significantly improves the accuracy and robustness of localization in challenging environments. Robust tracking and accurate inertial parameter estimation are the basis for the stable operation of the system. This article presents PLE-SLAM, an entirely precise and real-time visual-inertial SLAM algorithm based on point-line features and efficient IMU initialization. First, we introduce line features in a point-based visual-inertial SLAM system. We use parallel computing methods to extract features and compute descriptors to ensure real-time performance. Second, the proposed system estimates gyroscope bias with rotation pre-integration and point and line observations. Accelerometer bias and gravity direction are solved by an analytical method. After initialization, all inertial parameters are refined through maximum a posteriori (MAP) estimation. Moreover, we open a dynamic feature elimination thread to improve the adaptability to dynamic environments and use CNN, bag-of-words and GNN to detect loops and match features. Excellent wide baseline matching capability of DNN-based matching method and illumination robustness significantly improve loop detection recall and loop inter-frame pose estimation. The front-end and back-end are designed for hardware acceleration. The experiments are performed on public datasets, and the results show that the proposed system is one of the state-of-the-art methods in complex scenarios.","['Visual-inertial', 'SLAM', 'point-line features', 'IMU initializaton', 'challenging environments.']",[]
"In this paper, we are concerned with n𝑛nitalic_n-component Ginzburg-Landau equations on ℝ2superscriptℝ2{\mathbb{R}^{2}}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.
By introducing a diffusion constant for each component, we discuss that the n𝑛nitalic_n-component equations are different from n𝑛nitalic_n-copies of the single Ginzburg-Landau equations.
Then, the results of Brezis-Merle-Riviere for the single Ginzburg-Landau equation can be nontrivially extended to the multi-component case.
First, we show that if the solutions have their gradients in L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT space, they are trivial solutions.
Second, we prove that if the potential is square summable, then it has quantized integrals, i.e., there exists one-to-one correspondence between the possible values of the potential energy and ℕnsuperscriptℕ𝑛\mathbb{N}^{n}blackboard_N start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT.
Third, we show that different diffusion coefficients in the system are important to obtain nontrivial solutions of n𝑛nitalic_n-component equations.",[],[]
"Aircraft landing time (ALT) prediction is crucial for air traffic management, especially for arrival aircraft sequencing on the runway. In this study, a trajectory image-based deep learning method is proposed to predict ALTs for the aircraft entering the research airspace that covers the Terminal Maneuvering Area (TMA). Specifically, the trajectories of all airborne arrival aircraft within the temporal capture window are used to generate an image with the target aircraft trajectory labeled as red and all background aircraft trajectory labeled as blue. The trajectory images contain various information, including the aircraft position, speed, heading, relative distances, and arrival traffic flows. It enables us to use state-of-the-art deep convolution neural networks for ALT modeling. We also use real-time runway usage obtained from the trajectory data and the external information such as aircraft types and weather conditions as additional inputs. Moreover, a convolution neural network (CNN) based module is designed for automatic holding-related featurizing, which takes the trajectory images, the leading aircraft holding status, and their time and speed gap at the research airspace boundary as its inputs. Its output is further fed into the final end-to-end ALT prediction. The proposed ALT prediction approach is applied to Singapore Changi Airport (ICAO Code: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from November 1 to November 30, 2022. Experimental results show that by integrating the holding featurization, we can reduce the mean absolute error (MAE) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of 96.1%, with 79.4% of the predictions errors being less than 60 seconds.","['Air', 'Traffic', 'Management', 'Aircraft', 'Landing', 'Time', 'Trajectory', 'Image', 'Convolution', 'Neural', 'Networks.']",['Singapore']
"Natural policy gradient (NPG) and its variants are widely-used policy search methods in reinforcement learning. Inspired by prior work, a new NPG variant coined NPG-HM is developed in this paper, which utilizes the Hessian-aided momentum technique for variance reduction, while the sub-problem is solved via the stochastic gradient descent method.
It is shown that NPG-HM can achieve the global last iterate ϵitalic-ϵ\epsilonitalic_ϵ-optimality with a sample complexity of 𝒪⁢(ϵ−2)𝒪superscriptitalic-ϵ2{\cal O}(\epsilon^{-2})caligraphic_O ( italic_ϵ start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT ), which is the best known result for natural policy gradient type methods under the generic Fisher non-degenerate policy parameterizations. The convergence analysis is built upon a relaxed weak gradient dominance property tailored for NPG under the compatible function approximation framework, as well as a neat way to decompose the error when handling the sub-problem. Moreover, numerical experiments on Mujoco-based environments demonstrate the superior performance of NPG-HM over other state-of-the-art policy gradient methods.",[],['China']
"Revolutionized by the transformer architecture, natural language processing (NLP) has received unprecedented attention. While advancements in NLP models have led to extensive research into their backdoor vulnerabilities, the potential for these advancements to introduce new backdoor threats remains unexplored. This paper proposes Imperio111“Imperio” is a spell from the Harry Potter series that allows the caster to control another’s actions., which harnesses the language understanding capabilities of NLP models to enrich backdoor attacks. Imperio provides a new model control experience. It empowers the adversary to control the victim model with arbitrary output through language-guided instructions. This is achieved using a language model to fuel a conditional trigger generator, with optimizations designed to extend its language understanding capabilities to backdoor instruction interpretation and execution. Our experiments across three datasets, five attacks, and nine defenses confirm Imperio’s effectiveness. It can produce contextually adaptive triggers from text descriptions and control the victim model with desired outputs, even in scenarios not encountered during training. The attack maintains a high success rate across complex datasets without compromising the accuracy of clean inputs and also exhibits resilience against representative defenses. The source code is available at https://khchow.com/Imperio.","['Large', 'Language', 'Models', 'Backdoor', 'Attacks', 'Poisoning', 'Attacks', 'AI', 'Security']",[]
"Given two measures μ,ν𝜇𝜈\mu,\nuitalic_μ , italic_ν on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT that satisfy Carleman’s condition, we provide a numerical
scheme to approximate as closely as desired the total variation distance between μ𝜇\muitalic_μ and ν𝜈\nuitalic_ν.
It consists of solving a sequence (hierarchy) of convex relaxations whose associated sequence of optimal values
converges to the total variation distance, an additional illustration
of the versatility of the Moment-SOS hierarchy.
Indeed each relaxation in the hierarchy
is a semidefinite program whose size increases
with the number of involved moments. It has an optimal solution which
is a couple of degree-2⁢n2𝑛2n2 italic_n pseudo-moments which converge, as n𝑛nitalic_n grows, to
moments of the Hahn-Jordan decomposition of μ−ν𝜇𝜈\mu-\nuitalic_μ - italic_ν.",[],[]
,[],[]
"We study the quantitative stability of the mapping that to a measure associates its
pushforward measure by a fixed (non-smooth) optimal transport map. We exhibit a tight
Hölder-behavior for
this operation under minimal assumptions.
Our proof essentially relies on a new bound that quantifies the size of
the singular sets of a convex and Lipschitz continuous function on a bounded domain.",[],[]
"This paper presents the development of a specialized chatbot for materials science, leveraging the Llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the S2ORC dataset.
The methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot’s capabilities.
The chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science.
We make the four trained checkpoints (7B, 13B, with or without chat ability) freely available to the research community at https://github.com/Xianjun-Yang/Quokka.",[],[]
,[],[]
"The Gaia DR3 parallax approach was used to estimate the absolute parameters of 2375 δ𝛿\deltaitalic_δ Scuti stars from the ASAS catalog. The selected stars have a variety of observational characteristics, with a higher than 80% probability of being δ𝛿\deltaitalic_δ Scuti stars. We have displayed all the stars in the Hertzsprung-Russell (H-R) diagram along with the δ𝛿\deltaitalic_δ Scuti instability strip, the Zero Age Main Sequence (ZAMS), and the Terminal-Age Main Sequence (TAMS). Then, we determined which fundamental and overtone modes each star belongs to using pulsation constant (Q𝑄Qitalic_Q) calculations. In addition, we evaluated the parameters in the Q𝑄Qitalic_Q calculation equation using three machine learning methods, which showed that surface gravity and temperature have the greatest effect on its calculation. The Period-Luminosity (P−L𝑃𝐿P-Litalic_P - italic_L) relationship of the δ𝛿\deltaitalic_δ Scuti stars was also revisited. Eventually, using least squares linear regression, we made four linear fits for fundamental and overtone modes and updated their relationships.","['δ𝛿\\deltaitalic_δ', 'Scuti variable stars', 'Fundamental parameters', 'Data analysis']","['Italy', 'Canada']"
"This paper investigates intelligent reflecting surface (IRS)-aided multi-antenna wireless powered communications in a multi-link interference channel, where multiple IRSs are deployed to enhance the downlink/uplink communications between each pair of hybrid access point (HAP) and wireless device. Our objective is to maximize the system sum throughput by optimizing the allocation of communication resources. To attain this objective and meanwhile balance the performance-cost tradeoff, we propose three transmission schemes: the IRS-aided asynchronous (Asy) scheme, the IRS-aided time-division multiple access (TDMA) scheme, and the IRS-aided synchronous (Syn) scheme. For the resulting three non-convex design problems, we propose a general algorithmic framework capable of addressing all of them.
Numerical results show that our proposed IRS-aided schemes noticeably surpass their counterparts without IRSs in both system sum throughput and total transmission energy consumption at the HAPs. Moreover, although the IRS-aided Asy scheme consistently achieves the highest sum throughput, the IRS-aided TDMA scheme is more appealing in scenarios with substantial cross-link interference and limited IRS elements, while the IRS-aided Syn scheme is preferable in low cross-link interference scenarios.","['IRS', 'wireless powered communications', 'interference channel', 'resource allocation.']",[]
"Hyperspectral anomaly detection (HAD) aims to localize pixel points whose spectral features differ from the background. HAD is essential in scenarios of unknown or camouflaged target features, such as water quality monitoring, crop growth monitoring and camouflaged target detection, where prior information of targets is difficult to obtain. Existing HAD methods aim to objectively detect and distinguish background and anomalous spectra, which can be achieved almost effortlessly by human perception. However, the underlying processes of human visual perception are thought to be quite complex. In this paper, we analyze hyperspectral image (HSI) features under human visual perception, and transfer the solution process of HAD to the more robust feature space for the first time. Specifically, we propose a small target aware detector (STAD), which introduces saliency maps to capture HSI features closer to human visual perception. STAD not only extracts more anomalous representations, but also reduces the impact of low-confidence regions through a proposed small target filter (STF). Furthermore, considering the possibility of HAD algorithms being applied to edge devices, we propose a full connected network to convolutional network knowledge distillation strategy. It can learn the spectral and spatial features of the HSI while lightening the network. We train the network on the HAD100 training set and validate the proposed method on the HAD100 test set. Our method provides a new solution space for HAD that is closer to human visual perception with high confidence. Sufficient experiments on real HSI with multiple method comparisons demonstrate the excellent performance and unique potential of the proposed method. The code is available at https://github.com/majitao-xd/STAD-HAD.","['Anomaly detection', 'visual perception', 'saliency map', 'hyperspectral images.']",[]
"In this paper, we introduce an algorithm designed to solve a Multilevel MOnoObjective Linear Programming Problem (ML(MO)OLPP). Our approach is a refined adaptation of Sinha and Sinha’s linear programming method, incorporating the development of an ""interval reduction map"" that precisely refines decision variable intervals based on the influence of the preceding level’s decision maker. Each construction stage is meticulously examined. The effectiveness of the algorithm is validated through a detailed numerical example, illustrating its practical applicability in resource management challenges. With a specific focus on vaccination planning within long-term care facilities and its relevance to the COVID-19 pandemic, our study addresses the optimization of resource allocation, placing a strong emphasis on the equitable distribution of COVID-19 vaccines.",[],[]
"Context:
Aims:We studied the manifestation of decayless oscillations in 3D simulations of coronal loops, driven by random motions.
Methods:Using the PLUTO code, we ran magnetohydrodynamic (MHD) simulations of a straight gravitationally stratified flux tube, with its footpoints embedded in chromospheric plasma. We consider transverse waves drivers with a horizontally polarised red noise power-law spectrum.
Results:Our broadband drivers lead to the excitation of standing waves with frequencies equal to the fundamental standing kink mode and its harmonics. These standing kink oscillations have non-decaying amplitudes, and spectra that depend on the characteristics of the loops, with the latter amplifying the resonant frequencies from the drivers. We thus report for the first time in 3D simulations the manifestation of decayless oscillations from broadband drivers. The spatial and temporal evolution of our oscillation spectra reveals the manifestation of a half harmonic, which exhibits half the frequency of the identified fundamental mode with a similar spatial profile. Our results suggest that this mode is related to the presence of the transition region in our model and could be interpreted as being the equivalent to the fundamental mode of standing sound waves driven on pipes closed at one end.
Conclusions:The potential existence of this half harmonic has important implications for coronal seismology, since misinterpreting it for the fundamental mode of the system can lead to false estimations of the average kink speed profile along oscillating loops. Finally, its detection could potentially give us a tool for distinguishing between different excitation and driving mechanisms of decayless oscillations in observations.","['magnetohydrodynamics (MHD) waves', 'Sun: atmosphere', 'Sun: magnetic fields methods: numerical']",[]
,[],[]
"Cryo-electron microscopy (cryo-EM) has achieved near-atomic level resolution of biomolecules by reconstructing 2D micrographs. However, the resolution and accuracy of the reconstructed particles are significantly reduced due to the extremely low signal-to-noise ratio (SNR) and complex noise structure of cryo-EM images. In this paper, we introduce a diffusion model with post-processing framework to effectively denoise and restore single particle cryo-EM images. Our method outperforms the state-of-the-art (SOTA) denoising methods by effectively removing structural noise that has not been addressed before. Additionally, more accurate and high-resolution three-dimensional reconstruction structures can be obtained from denoised cryo-EM images.",[],[]
,[],[]
"We present a fast and high-quality codec language model for parallel audio generation. While SoundStorm, a state-of-the-art parallel audio generation model, accelerates inference speed compared to autoregressive models, it still suffers from slow inference due to iterative sampling. To resolve this problem, we propose Group-Masked Language Modeling (G-MLM) and Group Iterative Parallel Decoding (G-IPD) for efficient parallel audio generation. Both the training and sampling schemes enable the model to synthesize high-quality audio with a small number of iterations by effectively modeling the group-wise conditional dependencies. In addition, our model employs a cross-attention-based architecture to capture the speaker style of the prompt voice and improves computational efficiency. Experimental results demonstrate that our proposed model outperforms the baselines in prompt-based audio generation.","['Parallel audio generation', 'neural audio codec']",[]
,[],[]
"Joint Communication and Sensing (JCAS) is taking its first shape in WLAN sensing under IEEE 802.11bf, where standardized WLAN signals and protocols are exploited to enable radar-like sensing. However, an overlooked problem in JCAS, and specifically in WLAN Sensing, is the sensitivity of the system to a deceptive jammer, which introduces phantom targets to mislead the victim radar receiver. Standardized waveforms and sensing parameters make the system vulnerable to physical layer attacks. Moreover, orthogonal frequency-division multiplexing (OFDM) makes deceptive jamming even easier as it allows digitally generated artificial range/Doppler maps. This paper studies deceptive jamming in JCAS, with a special focus on WLAN Sensing. The provided mathematical models give insights into how to design jamming signals and their impact on the sensing system. Numerical analyses illustrate various distortions caused by deceptive jamming, while the experimental results validate the need for meticulous JCAS design to protect the system against physical layer attacks in the form of deceptive jamming.","['Joint', 'Communication and', 'Sensing', 'WLAN', 'Sensing', 'deceptive jamming', 'physical layer security', 'OFDM radars.']","['Belgium', 'Sweden']"
"Face recognition systems have raised concerns due to their vulnerability to different presentation attacks, and system security has become an increasingly critical concern.
Although many face anti-spoofing (FAS) methods perform well in intra-dataset scenarios, their generalization remains a challenge. To address this issue, some methods adopt domain adversarial training (DAT) to extract domain-invariant features. However, the competition between the encoder and the domain discriminator can cause the network to be difficult to train and converge. In this paper, we propose a domain adversarial attack (DAA) method to mitigate the training instability problem by adding perturbations to the input images, which makes them indistinguishable across domains and enables domain alignment.
Moreover, since models trained on limited data and types of attacks cannot generalize well to unknown attacks, we propose a dual perceptual and generative knowledge distillation framework for face anti-spoofing that utilizes pre-trained face-related models containing rich face priors.
Specifically, we adopt two different face-related models as teachers to transfer knowledge to the target student model. The pre-trained teacher models are not from the task of face anti-spoofing but from perceptual and generative tasks, respectively, which implicitly augment the data.
By combining both DAA and dual-teacher knowledge distillation, we develop a dual teacher knowledge distillation with domain alignment framework (DTDA) for face anti-spoofing.
The advantage of our proposed method has been verified through extensive ablation studies and comparison with state-of-the-art methods on public datasets across multiple protocols.","['Face', 'Anti-Spoofing', 'Knowledge', 'Distillation', 'Domain', 'Generalization', 'Adversarial', 'Attack']",[]
"For an input graph G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ) and a source vertex s∈V𝑠𝑉s\in Vitalic_s ∈ italic_V, the α𝛼\alphaitalic_α-approximate vertex fault-tolerant distance sensitivity oracle (α𝛼\alphaitalic_α-VSDO) answers an α𝛼\alphaitalic_α-approximate distance from s𝑠sitalic_s to t𝑡titalic_t in G−x𝐺𝑥G-xitalic_G - italic_x for any query (x,t)𝑥𝑡(x,t)( italic_x , italic_t ). It is a data structure version of the so-called single-source replacement path problem (SSRP). In this paper, we present a new nearly linear time algorithm of constructing the (1+ϵ)1italic-ϵ(1+\epsilon)( 1 + italic_ϵ )-VSDO for any weighted directed graph of n𝑛nitalic_n vertices and m𝑚mitalic_m edges with integer weights in range [1,W]1𝑊[1,W][ 1 , italic_W ], and any positive constant ϵ∈(0,1]italic-ϵ01\epsilon\in(0,1]italic_ϵ ∈ ( 0 , 1 ]. More precisely, the presented oracle attains O~⁢(m/ϵ+n/ϵ2)~𝑂𝑚italic-ϵ𝑛superscriptitalic-ϵ2\tilde{O}(m/\epsilon+n/\epsilon^{2})over~ start_ARG italic_O end_ARG ( italic_m / italic_ϵ + italic_n / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) construction time,
O~⁢(n/ϵ)~𝑂𝑛italic-ϵ\tilde{O}(n/\epsilon)over~ start_ARG italic_O end_ARG ( italic_n / italic_ϵ ) size, and O~⁢(1/ϵ)~𝑂1italic-ϵ\tilde{O}(1/\epsilon)over~ start_ARG italic_O end_ARG ( 1 / italic_ϵ ) query time for any polynomially-bounded W𝑊Witalic_W. To the best of our knowledge, this is the first non-trivial result for SSRP/VSDO beating the trivial O~⁢(m⁢n)~𝑂𝑚𝑛\tilde{O}(mn)over~ start_ARG italic_O end_ARG ( italic_m italic_n ) computation time for directed graphs with polynomially-bounded edge weights. Such a result has been unknown so far even for the setting of (1+ϵ)1italic-ϵ(1+\epsilon)( 1 + italic_ϵ )-approximation. It also implies that the known barrier of Ω⁢(m⁢n)Ω𝑚𝑛\Omega(m\sqrt{n})roman_Ω ( italic_m square-root start_ARG italic_n end_ARG ) time for the exact SSRP by Chechik and Magen [ICALP2020] does not apply to the case of approximation.",[],[]
,[],[]
"One of the major challenges in particle physics and cosmology is understanding why there is an asymmetry between matter and antimatter in the Universe. One possible explanation for this phenomenon is thermal leptogenesis, which involves the addition of at least two right-handed neutrinos (RHNs) to the standard model. Another possible explanation is baryogenesis through the hypermagnetic fields which involves the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly and helical hypermagnetic fields in the early Universe.
In this paper, after reviewing the thermal leptogenesis and baryogenesis through the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly, we investigate the simplest model that combines these two scenarios and explore the parameter space for optimal results.
Our results show that the combined scenario permits a specific region of parameter space that is not covered by either one separately. In fact, the minimum required mass scale of the RHN and strength of initial hypermagnetic helicity are reduced by one order of magnitude in our model.
Moreover, we find that in the combined scenario, leptogenesis and baryogenesis through the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly can either amplify or reduce the effect of each other, i.e., the generated asymmetry, depending on the sign of the helical hypermagnetic fields.
Finally, we show the surprising result that a drastic amplification can occur even when the initial abundance of RHN is its equilibrium value for leptogenesis.",[],[]
,[],[]
"Urban transformations have profound societal impact on both individuals and communities at large. Accurately assessing these shifts is essential for understanding their underlying causes and ensuring sustainable urban planning. Traditional measurements often encounter constraints in spatial and temporal granularity, failing to capture real-time physical changes. While street view imagery, capturing the heartbeat of urban spaces from a pedestrian point of view, can add as a high-definition, up-to-date, and on-the-ground visual proxy of urban change. We curate the largest street view time series dataset to date, and propose an end-to-end change detection model to effectively capture physical alterations in the built environment at scale. We demonstrate the effectiveness of our proposed method by benchmark comparisons with previous literature and implementing it at the city-wide level. Our approach has the potential to supplement existing dataset and serve as a fine-grained and accurate assessment of urban change.",[],[]
"Comparative opinion mining is a specialized field of sentiment analysis that aims to identify and extract sentiments expressed comparatively. To address this task, we propose an approach that consists of solving three sequential sub-tasks: (i) identifying comparative sentence, i.e., if a sentence has a comparative meaning, (ii) extracting comparative elements, i.e., what are comparison subjects, objects, aspects, predicates, and (iii) classifying comparison types which contribute to a deeper comprehension of user sentiments in Vietnamese product reviews. Our method is ranked fifth at the Vietnamese Language and Speech Processing (VLSP) 2023 challenge on Comparative Opinion Mining (ComOM) from Vietnamese Product Reviews (Le et al., 2023). For reproducing the result, the code can be found at https://github.com/hallie304/VLSP23-Comparative-Opinion-Mining",[],[]
"The limit q𝑞qitalic_q-Durrmeyer operator, D∞,q,subscript𝐷𝑞D_{\infty,q},italic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT , was introduced and its approximation properties were investigated by V. Gupta in 2008 during a study of q𝑞qitalic_q-analogues for the Bernstein-Durrmeyer operator. In the present work, this operator is investigated from a different perspective. More precisely, the growth estimates are derived for the entire functions comprising the range of D∞,qsubscript𝐷𝑞D_{\infty,q}italic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT. The interrelation between the analytic properties of a function f𝑓fitalic_f and the rate of growth for D∞,q⁢fsubscript𝐷𝑞𝑓D_{\infty,q}fitalic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT italic_f are established, and the sharpness of the obtained results are demonstrated.",[],[]
"Following [It12] and [It15], we construct two super-extensions of the usual tensor algebra through the super-actions of symmetric groups and Hecke algebras respectively. For each extension, we consider a special type of derivations coming from covectors, and study the the space generated, in some special manner, by these derivations and operators from left multiplication by vectors and permutations. Duality theorems of these spaces and the super-actions are proved. As an application, we provide a new proof of the Schur-Sergeev duality theorem, as well as its quantum version.",[],[]
"Recently, the Floquet Na3⁢BisubscriptNa3Bi{\rm Na_{3}Bi}roman_Na start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT roman_Bi-type material has been proposed as an ideal platform for realizing various phases, i.e., the spin-degenerate Dirac semimetal (DSM) can be turned into the Weyl semimetal (WSM), and even to the Weyl half-metal (WHM)xiaoshi . Instead of the conventional electrical methods, we use the RKKY interaction to characterize the topological phase transitions in this paper. It is found that detecting the Ising term JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT is feasible for distinguishing the phase transition of DSM/WSM, since the emergence of JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT is induced by the broken spin degeneracy. For the case with impurities deposited on z𝑧zitalic_z axis (the line connecting the Weyl points), the Heisenberg term JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT coexists with JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT in the WSM, while JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is filtered out and only JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT survives in the WHM. This magnetic filtering effect is a reflection of the fully spin-polarized property (one spin band is in the WSM phase while the other is gapped) of the WHM, and it can act a signal to capture the phase transition of WSM/WHM. This signal can not be disturbed unless the direction of the impurities greatly deviates from z𝑧zitalic_z axis. Interestingly, as the impurities are moved into the x𝑥xitalic_x-y𝑦yitalic_y plane, there arises another signal (a dip structure for JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT at the phase boundary), which can also identify the phase transition of WSM/WHM. Furthermore, we have verified that all magnetic signals are robust to the term that breaks the electron-hole symmetry. Besides characterizing the phase transitions, our results also suggest that the Floquet DSMs are power platforms for controlling the magnetic interaction.",[],['China']
"We establish the unique ergodicity of the Markov chain generated by the stochastic theta method (STM) with θ∈[1/2,1]𝜃121\theta\in[1/2,1]italic_θ ∈ [ 1 / 2 , 1 ] for monotone SODEs, without growth restriction on the coefficients, driven by nondegenerate multiplicative noise.
The main ingredient of the arguments lies in the construction of new Lyapunov functions, involving the coefficients, the stepsize, and θ𝜃\thetaitalic_θ, and the irreducibility and the strong Feller property for the STM.
We also generalize the arguments to the STM and its Galerkin-based full discretizations for a class of monotone SPDEs driven by infinite-dimensional nondegenerate multiplicative trace-class noise.
Applying these results to the stochastic Allen–Cahn equation indicates that its drift-implicit Euler scheme is uniquely ergodic for any interface thickness, which gives an affirmative answer to a question proposed in (J. Cui, J. Hong, and L. Sun, Stochastic Process. Appl. (2021): 55–93).
Numerical experiments verify our theoretical results.","['monotone stochastic differential equation', 'numerical invariant measure', 'numerical ergodicity', 'stochastic', 'Allen–Cahn equation', 'Lyapunov structure']",[]
"In this paper, reconfigurable intelligent surface (RIS) is employed in a millimeter wave (mmWave) integrated sensing and communications (ISAC) system. To alleviate the multi-hop attenuation, the semi-self sensing RIS approach is adopted, wherein sensors are configured at the RIS to receive the radar echo signal. Focusing on the estimation accuracy, the Crame´´e\acute{\text{e}}over´ start_ARG e end_ARGr-Rao bound (CRB) for estimating the direction-of-the-angles is derived as the metric for sensing performance. A joint optimization problem on hybrid beamforming and RIS phase shifts is proposed to minimize the CRB, while maintaining satisfactory communication performance evaluated by the achievable data rate. The CRB minimization problem is first transformed as a more tractable form based on Fisher information matrix (FIM). To solve the complex non-convex problem, a double layer loop algorithm is proposed based on penalty concave-convex procedure (penalty-CCCP) and block coordinate descent (BCD) method with two sub-problems. Successive convex approximation (SCA) algorithm and second order cone (SOC) constraints are employed to tackle the non-convexity in the hybrid beamforming optimization. To optimize the unit modulus constrained analog beamforming and phase shifts, manifold optimization (MO) is adopted. Finally, the numerical results verify the effectiveness of the proposed CRB minimization algorithm, and show the performance improvement compared with other baselines. Additionally, the proposed hybrid beamforming algorithm can achieve approximately 96% of the sensing performance exhibited by the full digital approach within only a limited number of radio frequency (RF) chains.","['Integrated sensing and communications', 'reconfigurable intelligent surface', 'millimeter wave', 'Crame´´e\\acute{\\text{e}}over´ start_ARG e end_ARGr-Rao bound', 'beamforming.']",[]
"Rust relies on its unique ownership mechanism to ensure thread and memory safety. However, numerous potential security vulnerabilities persist in practical applications. New language features in Rust pose new challenges for vulnerability detection. This paper proposes a static deadlock detection method tailored for Rust programs, aiming to identify various deadlock types, including double lock, conflict lock, and deadlock associated with conditional variables. With due consideration for Rust’s ownership and lifetimes, we first complete the pointer analysis. Then, based on the obtained points-to information, we analyze dependencies among variables to identify potential deadlocks. We develop a tool and conduct experiments based on the proposed method. The experimental results demonstrate that our method outperforms existing deadlock detection methods in precision.","['Rust', 'Programs', 'Static', 'Analysis', 'Deadlock', 'Detection']",['China']
,[],[]
"Extinction is the elephant in the room that almost everyone tries to avoid when analyzing optical/IR data: astronomers
tend to find a quick fix for it that the referee will accept, but that does not mean such a solution is correct or even
optimal. In this contribution I address three important issues related to extinction that are commonly ignored and
present current and future solutions for them: [1] Extinction produces non-linear photometric effects, [2] the extinction
law changes between sightlines, and [3] not all families of extinction laws have the same accuracy.",[],[]
"With the rapid evolution of the Text-to-Image (T2I) model in recent years, their unsatisfactory generation result has become a challenge. However, uniformly refining AI-Generated Images (AIGIs) of different qualities not only limited optimization capabilities for low-quality AIGIs but also brought negative optimization to high-quality AIGIs. To address this issue, a quality-award refiner named Q-Refine111The code will be released on https://github.com/Q-Future/Q-Refine is proposed. Based on the preference of the Human Visual System (HVS), Q-Refine uses the Image Quality Assessment (IQA) metric to guide the refining process for the first time, and modify images of different qualities through three adaptive pipelines. Experimental shows that for mainstream T2I models, Q-Refine can perform effective optimization to AIGIs of different qualities. It can be a general refiner to optimize AIGIs from both fidelity and aesthetic quality levels, thus expanding the application of the T2I generation models.",[],[]
,[],[]
"The prediction of rolling bearing lifespan is of significant importance in industrial production. However, the scarcity of high-quality, full lifecycle data has been a major constraint in achieving precise predictions. To address this challenge, this paper introduces the CVGAN model, a novel framework capable of generating one-dimensional vibration signals in both horizontal and vertical directions, conditioned on historical vibration data and remaining useful life. In addition, we propose an autoregressive generation method that can iteratively utilize previously generated vibration information to guide the generation of current signals. The effectiveness of the CVGAN model is validated through experiments conducted on the PHM 2012 dataset. Our findings demonstrate that the CVGAN model, in terms of both MMD and FID metrics, outperforms many advanced methods in both autoregressive and non-autoregressive generation modes. Notably, training using the full lifecycle data generated by the CVGAN model significantly improves the performance of the predictive model. This result highlights the effectiveness of the data generated by CVGans in enhancing the predictive power of these models.",[],[]
"We prove a van der Corput lemma for non-atomic self-similar measures μ𝜇\muitalic_μ. As an application, we show that the correlations of all finite orders of (xnmod1)n≥1subscriptmodulosuperscript𝑥𝑛1𝑛1(x^{n}\mod 1)_{n\geq 1}( italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_mod 1 ) start_POSTSUBSCRIPT italic_n ≥ 1 end_POSTSUBSCRIPT converge to the Poissonian model for μ𝜇\muitalic_μ-a.e. x𝑥xitalic_x, assuming x>1𝑥1x>1italic_x > 1. We also complete a recent result of Algom, Rodriguez Hertz, and Wang (obtained simultaneously by Baker and Banaji), showing that any self-conformal measure with respect to a non-affine real analytic IFS has polynomial Fourier decay.",[],[]
,[],[]
"Shocks are often invoked as heating mechanisms in astrophysical systems, with both adiabatic compression and dissipative heating that leading to temperature increases.
Whilst shocks are reasonably well understood for ideal magnetohydrodynamic (MHD) systems, in many astrophysical plasmas, radiation is an important phenomena, which can allow energy to leave the system. As such, energy becomes non-conservative which can fundamentally change the behaviour of shocks. The energy emitted through optically-thin radiation post-shock can exceed the thermal energy increase, resulting in shocks that reduce the temperature of the medium, i.e., cooling shocks that have a net decrease in temperature across the interface.
In this paper, semi-analytical solutions for radiative shocks are derived to demonstrate that both cooling (temperature decreasing) and heating (temperature increasing) shock solutions are possible in radiative MHD. Numerical simulations of magnetic reconnection with optically-thin radiative losses also yield both heating and cooling shocks in roughly equal abundances. The detected cooling shocks feature a significantly lower pressure jump across the shock than their heating counterparts. The compression at the shock front leads to locally-enhanced radiative losses, resulting in significant cooling within a few grid cells in the upstream and downstream directions.
The presence of temperature-reducing (cooling) shocks is critical in determining the thermal evolution, and heating or cooling, across a wealth of radiative astrophysical plasmas.",[],[]
"Discovering the symbols and rules that can be used in long-horizon planning from a robot’s unsupervised exploration of its environment and continuous sensorimotor experience is a challenging task. The previous studies proposed learning symbols from single or paired object interactions and planning with these symbols. In this work, we propose a system that learns rules with discovered object and relational symbols that encode an arbitrary number of objects and the relations between them, converts those rules to Planning Domain Description Language (PDDL), and generates plans that involve affordances of the arbitrary number of objects to achieve tasks. We validated our system with box-shaped objects in different sizes and showed that the system can develop a symbolic knowledge of pick-up, carry, and place operations, taking into account object compounds in different configurations, such as boxes would be carried together with a larger box that they are placed on. We also compared our method with the state-of-the-art methods and showed that planning with the operators defined over relational symbols gives better planning performance compared to the baselines.",[],[]
"Tree-based models have been successfully applied to a wide variety of tasks, including time series forecasting.
They are increasingly in demand and widely accepted because of their comparatively high level of interpretability. However, many of them suffer from the overfitting problem, which limits their application in real-world decision-making. This problem becomes even more severe in online-forecasting settings where time series observations are incrementally acquired, and the
distributions from which they are drawn may keep changing over time. In this context, we propose a novel method for the online selection of tree-based models using the TreeSHAP explainability method in the task of time series forecasting. We start with an arbitrary set of different tree-based models. Then, we outline a performance-based ranking with a coherent design to make TreeSHAP able to specialize the tree-based forecasters across different regions in the input time series. In this framework, adequate model selection is performed online, adaptively following drift detection in the time series. In addition, explainability is supported on three levels, namely online input importance, model selection, and model output explanation. An extensive empirical study on various real-world datasets demonstrates that our method achieves excellent or on-par results in comparison to the state-of-the-art approaches as well as several baselines.","['Online', 'Model', 'Selection', 'Tree-based', 'Models', 'Time', 'Series', 'Forecasting', 'TreeSHAP', 'Explainability']",[]
"We study the effect of a resetting point randomly distributed around the origin on the mean first passage time of a Brownian searcher moving in one dimension. We compare the search efficiency with that corresponding to reset to the origin and find that the mean first passage time of the latter can be larger or smaller than the distributed case, depending on whether the resetting points are symmetrically or asymmetrically distributed. In particular, we prove the existence of an optimal reset rate that minimizes the mean first-passage time for distributed resetting to a finite interval if the target is located outside this interval. When the target position belongs to the resetting interval or it is infinite then no optimal reset rate exists, but there is an optimal resetting interval width or resetting characteristic scale which minimizes the mean first-passage time. We also show that the first-passage density averaged over the resetting points depends on its first moment only. As a consequence, there is an equivalent point such that the first-passage problem with resetting to that point is statistically equivalent to the case of distributed resetting. We end our study by analyzing the fluctuations of the first-passage times for these cases. All our analytical results are verified through numerical simulations.",[],['Spain']
"We present a general construction of pseudo-hermitian matrices
in an arbitrary large, but finite dimensional vector space. The positive-definite
metric which ensures reality of the entire spectra of a pseudo-hermitian operator,
and is used for defining a modified inner-product in the associated vector space
is also presented. The construction for an N𝑁Nitalic_N dimensional vector space is based on the generators of S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) in the
fundamental representation and the identity operator. We apply the results to
construct a generic pseudo-hermitian lattice model of size N𝑁Nitalic_N with balanced loss-gain.
The system is amenable to periodic as well as open boundary conditions and by construction,
admits entirely real spectra along with unitary time-evolution. The tight binding and
Su-Schrieffer-Heeger(SSH) models with nearest neighbour(NN) and next-nearest
neighbour(NNN) interaction with balanced loss-gain appear as limiting cases.",[],['India']
"Compared to the generations up to 4G, whose main focus was on broadband and
coverage aspects, 5G has expanded the scope of wireless cellular systems towards
embracing two new types of connectivity: massive machine-type communication
(mMTC) and ultra-reliable low-latency communications (URLLC).
This paper will
discuss the possible evolution of these two types of connectivity within the
umbrella of 6G wireless systems. The paper consists of three parts. The first
part deals with the connectivity for a massive number of devices.
While mMTC research in 5G was predominantly focused on the problem of uncoordinated access in the uplink for a
large number of devices,
the traffic patterns in 6G may become more symmetric,
leading to closed-loop massive connectivity.
One of the drivers for this type of
traffic patterns is distributed/decentralized learning and inference.
The second part of the paper will discuss the evolution of wireless connectivity
for critical services. While latency and reliability are tightly coupled in 5G,
6G will support a variety of safety critical control applications with different types of
timing requirements, as evidenced by the emergence of metrics related to
information freshness and information value. Additionally, ensuring ultra-high reliability for safety critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel AI-based techniques, incorporating optimization theory, explainable AI, generative AI and digital twins.
The third part will analyze the coexistence of massive connectivity and critical services.
Specifically, we will consider scenarios in which a massive number of devices need to support
traffic patterns of mixed criticality. This will be followed by a discussion
about the management of wireless resources shared by services with different
criticality.",[],[]
"Recently, text-to-image (T2I) synthesis has undergone significant advancements, particularly with the emergence of Large Language Models (LLM) and their enhancement in Large Vision Models (LVM), greatly enhancing the instruction-following capabilities of traditional T2I models.
Nevertheless, previous methods focus on improving generation quality but introduce unsafe factors into prompts. We explore that appending specific camera descriptions to prompts can enhance safety performance.
Consequently, we propose a simple and safe prompt engineering method (SSP) to improve image generation quality by providing optimal camera descriptions.
Specifically, we create a dataset from multi-datasets as original prompts. To select the optimal camera, we design an optimal camera matching approach and implement a classifier for original prompts capable of automatically matching. Appending camera descriptions to original prompts generates optimized prompts for further LVM image generation.
Experiments demonstrate that SSP improves semantic consistency by an average of 16% compared to others and safety metrics by 48.9%.",[],[]
"This paper studies the reduction by symmetry of variational problems on Lie groups and Riemannian homogeneous spaces. We derive the reduced equations of motion in the case of Lie groups endowed with a left-invariant metric, and on Lie groups that admits a bi-invariant metric. We repeated this analysis for Riemannian homogeneous spaces, where we derive the reduced equations by considering an alternative variational problem written in terms of a connection on the horizontal bundle of the underlying Lie group. We study also the case that the underlying Lie group admits a bi-invariant metric, and consider the special case that the homogeneous space is in fact a Riemannian symmetric space. These ideas are applied to geodesics for a rigid body on S⁢O⁢(3)𝑆𝑂3SO(3)italic_S italic_O ( 3 ) to derive geodesic equations on the dual of its Lie algebra (a vector space), the heavy-top in S⁢E⁢(3)𝑆𝐸3SE(3)italic_S italic_E ( 3 ) to derive reduced equations of motion on the unit sphere S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, geodesics on S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT as a Riemannian symmetric space endowed with a bi-invariant metric and optimal control problems for applications to robotic manipulators.",[],[]
"In this paper, we present a novel generative task: joint scene graph - image generation.
While previous works have explored image generation conditioned on scene graphs or layouts, our task is distinctive and important as it involves generating scene graphs themselves unconditionally from noise, enabling efficient and interpretable control for image generation.
Our task is challenging, requiring the generation of plausible scene graphs with heterogeneous attributes for nodes (objects) and edges (relations among objects), including continuous object bounding boxes and discrete object and relation categories.
We introduce a novel diffusion model, DiffuseSG, that jointly models the adjacency matrix along with heterogeneous node and edge attributes.
We explore various types of encodings for the categorical data, relaxing it into a continuous space.
With a graph transformer being the denoiser, DiffuseSG successively denoises the scene graph representation in a continuous space and discretizes the final representation to generate the clean scene graph.
Additionally, we introduce an IoU regularization to enhance the empirical performance.
Our model significantly outperforms existing methods in scene graph generation on the Visual Genome and COCO-Stuff datasets,
both on standard and newly introduced metrics that better capture the problem complexity.
Moreover, we demonstrate the additional benefits of our model in two downstream applications:
1) excelling in a series of scene graph completion tasks, and
2) improving scene graph detection models by using extra training samples generated from DiffuseSG.",[],[]
"Given a dynamical system (X,T)𝑋𝑇(X,T)( italic_X , italic_T ) and a family 𝖨⊆𝒫⁢(ω)𝖨𝒫𝜔\mathsf{I}\subseteq\mathcal{P}(\omega)sansserif_I ⊆ caligraphic_P ( italic_ω ) of  “small”  sets of nonnegative integers, a point x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X is said to be 𝖨𝖨\mathsf{I}sansserif_I-strong universal if for each y∈X𝑦𝑋y\in Xitalic_y ∈ italic_X there exists a subsequence (Tn⁢x:n∈A):superscript𝑇𝑛𝑥𝑛𝐴(T^{n}x:n\in A)( italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x : italic_n ∈ italic_A ) of its orbit which is convergent to y𝑦yitalic_y and, in addition, the set of indexes A𝐴Aitalic_A is “not small,” 
that is, A∉𝖨𝐴𝖨A\notin\mathsf{I}italic_A ∉ sansserif_I.
An analoguous definition is given for 𝖨𝖨\mathsf{I}sansserif_I-strong recurrence. In this work, we provide several
structural properties and
relationships between 𝖨𝖨\mathsf{I}sansserif_I-strong universality, 𝖨𝖨\mathsf{I}sansserif_I-strong recurrence, and the corresponding ordinary notions of 𝖨𝖨\mathsf{I}sansserif_I-universality and 𝖨𝖨\mathsf{I}sansserif_I-recurrence.
As applications,
we provide sufficient conditions which ensure the equivalence between the above notions and the property that each nonempty open set contains some cluster point of some orbit. In addition, we show that if T𝑇Titalic_T is a homomorphism on a Fréchet space X𝑋Xitalic_X and there exists a dense set of vectors with null orbit, then for each y∈X𝑦𝑋y\in Xitalic_y ∈ italic_X the set of all vectors x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X such that limn∈ATn⁢x=ysubscript𝑛𝐴superscript𝑇𝑛𝑥𝑦\lim_{n\in A}T^{n}x=yroman_lim start_POSTSUBSCRIPT italic_n ∈ italic_A end_POSTSUBSCRIPT italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x = italic_y for some A⊆ω𝐴𝜔A\subseteq\omegaitalic_A ⊆ italic_ω with nonzero upper asymptotic density is either empty or comeager. 
In the special case of linear dynamical systems on Banach spaces with a dense set of uniformly recurrent vectors, we obtain that T𝑇Titalic_T is upper frequently hypercyclic if and only if there exists a hypercyclic vector x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X for which limn∈ATn⁢x=0subscript𝑛𝐴superscript𝑇𝑛𝑥0\lim_{n\in A}T^{n}x=0roman_lim start_POSTSUBSCRIPT italic_n ∈ italic_A end_POSTSUBSCRIPT italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x = 0 for some A⊆ω𝐴𝜔A\subseteq\omegaitalic_A ⊆ italic_ω with nonzero upper asymptotic density.","['Analytic', 'P-ideal nonlinear dynamical system', 'Furstenberg families universality and recurrence dense orbit.']",[]
"Suppose that {λn}n=1∞superscriptsubscriptsubscript𝜆𝑛𝑛1\{\lambda_{n}\}_{n=1}^{\infty}{ italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is a sequence of distinct positive real numbers
satisfying the conditions inf{λn+1−λn}>0,subscript𝜆𝑛1subscript𝜆𝑛0\{\lambda_{n+1}-\lambda_{n}\}>0,{ italic_λ start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT - italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } > 0 , and
∑n=1∞λn−1<∞.superscriptsubscript𝑛1superscriptsubscript𝜆𝑛1\sum_{n=1}^{\infty}\lambda_{n}^{-1}<\infty.∑ start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT < ∞ .
We prove that the exponential system {eλn⁢t}n=1∞superscriptsubscriptsuperscript𝑒subscript𝜆𝑛𝑡𝑛1\{e^{\lambda_{n}t}\}_{n=1}^{\infty}{ italic_e start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_t end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is hereditarily complete in
the closure of the subspace spanned by {eλn⁢t}n=1∞superscriptsubscriptsuperscript𝑒subscript𝜆𝑛𝑡𝑛1\{e^{\lambda_{n}t}\}_{n=1}^{\infty}{ italic_e start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_t end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT in the space L2⁢(a,b)superscript𝐿2𝑎𝑏L^{2}(a,b)italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_a , italic_b ).
We also give an example of a class of compact non-normal operators defined on this closure which admit spectral synthesis.",[],[]
,[],[]
"In recent years, two-stage multimodal object detection methods based on deep learning have garnered significant attention.
However, these existing deep learning methods exhibit a notable decrease in detection accuracy when faced with occluded 3D objects. Additionally, the current two-stage methods struggle to converge quickly during model training.
This paper introduces HPC-Net, a high-precision and rapidly convergent object detection network.
HPC-Net comprises three key components: (1) RP (Replaceable Pooling), which enhances the network’s detection accuracy, speed, robustness, and generalizability by incorporating pooling methods that can be flexibly replaced on 3D voxels and 2D BEV images.
(2) DACConv (Depth Accelerated Convergence Convolution), which integrates two convolution strategies—one for each input feature map and one for each input channel—to maintain the network’s feature extraction ability (i.e., high accuracy) while significantly accelerating convergence speed.
(3) MEFEM (Multi-Scale Extended Receptive Field Feature Extraction Module), which addresses the challenge of low detection accuracy for 3D objects with high occlusion and truncation by employing a multi-scale feature fusion strategy and expanding the receptive field of the feature extraction module.
Our HPC-Net currently holds the top position111As of the paper’s completion date, October 10, 2023 in the KITTI Car 2D Object Detection Ranking. In the KITTI Car 3D Object Detection Ranking, our HPC-Net currently ranks fourth overall and first in hard mode.",[],[]
"Linear codes are widely studied in coding theory as they have nice applications in distributed storage, combinatorics, lattices, cryptography and so on.
Constructing linear codes with desirable properties is an interesting research topic. In this paper, based on the augmentation technique, we present two families of linear codes from some functions over finite fields. The first family of linear codes is constructed from monomial functions over finite fields. The locality of them is determined and the weight distributions of two subfamilies of the codes are also given. An infinite family of almost optimal recoverable codes and some optimal recoverable codes are obtained from the linear codes. In particular, the two subfamilies of the codes are proved to be both optimally or almost optimally extendable and self-orthogonal.
The second family of linear codes is constructed from weakly regular bent functions over finite fields and their weight distribution is determined. This family of codes is proved to have locality 3 for some cases and is conjectured to have locality 2 for other cases. Particularly, two families of optimal locally recoverable codes are derived from the linear codes. Besides, this family of codes is also proved to be both optimally or almost optimally extendable and self-orthogonal.",[],[]
"Given an ideal ℐℐ\mathcal{I}caligraphic_I on ω𝜔\omegaitalic_ω and a bounded real sequence 𝒙𝒙\bm{x}bold_italic_x, we denote by core𝒙⁢(ℐ)subscriptcore𝒙ℐ\mathrm{core}_{\bm{x}}(\mathcal{I})roman_core start_POSTSUBSCRIPT bold_italic_x end_POSTSUBSCRIPT ( caligraphic_I ) the smallest interval [a,b]𝑎𝑏[a,b][ italic_a , italic_b ] such that {n∈ω:xn∉[a−ε,b+ε]}∈ℐconditional-set𝑛𝜔subscript𝑥𝑛𝑎𝜀𝑏𝜀ℐ\{n\in\omega:x_{n}\notin[a-\varepsilon,b+\varepsilon]\}\in\mathcal{I}{ italic_n ∈ italic_ω : italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∉ [ italic_a - italic_ε , italic_b + italic_ε ] } ∈ caligraphic_I for all ε>0𝜀0\varepsilon>0italic_ε > 0 (which corresponds to the interval [lim inf𝒙,lim sup𝒙]limit-infimum𝒙limit-supremum𝒙[\,\liminf\bm{x},\limsup\bm{x}\,][ lim inf bold_italic_x , lim sup bold_italic_x ] if ℐℐ\mathcal{I}caligraphic_I is the ideal FinFin\mathrm{Fin}roman_Fin of finite subsets of ω𝜔\omegaitalic_ω).
First, we characterize all the infinite real matrices A𝐴Aitalic_A such that



coreA⁢𝒙⁢(𝒥)=core𝒙⁢(ℐ)subscriptcore𝐴𝒙𝒥subscriptcore𝒙ℐ\mathrm{core}_{A\bm{x}}(\mathcal{J})=\mathrm{core}_{\bm{x}}(\mathcal{I})roman_core start_POSTSUBSCRIPT italic_A bold_italic_x end_POSTSUBSCRIPT ( caligraphic_J ) = roman_core start_POSTSUBSCRIPT bold_italic_x end_POSTSUBSCRIPT ( caligraphic_I )



for all bounded sequences 𝒙𝒙\bm{x}bold_italic_x, provided that 𝒥𝒥\mathcal{J}caligraphic_J is a countably generated ideal on ω𝜔\omegaitalic_ω and A𝐴Aitalic_A maps bounded sequences into bounded sequences.
Such characterization fails if both ℐℐ\mathcal{I}caligraphic_I and 𝒥𝒥\mathcal{J}caligraphic_J are the ideal of asymptotic density zero sets.
Next, we show that such equality is possible for distinct ideals ℐ,𝒥ℐ𝒥\mathcal{I},\mathcal{J}caligraphic_I , caligraphic_J, answering an open question in [J. Math. Anal. Appl. 321 (2006), 515–523]. Lastly, we prove that, if 𝒥=Fin𝒥Fin\mathcal{J}=\mathrm{Fin}caligraphic_J = roman_Fin, the above equality holds for some matrix A𝐴Aitalic_A if and only if ℐ=FinℐFin\mathcal{I}=\mathrm{Fin}caligraphic_I = roman_Fin or ℐ=Fin⊕𝒫⁢(ω)ℐdirect-sumFin𝒫𝜔\mathcal{I}=\mathrm{Fin}\oplus\mathcal{P}(\omega)caligraphic_I = roman_Fin ⊕ caligraphic_P ( italic_ω ).","['Ideal convergence summability regular matrices', 'Rudin–Keisler order ideal core.']",[]
"Let F⁢(t),G⁢(t)∈ℚ⁢(t)𝐹𝑡𝐺𝑡ℚ𝑡F(t),G(t)\in\mathbb{Q}(t)italic_F ( italic_t ) , italic_G ( italic_t ) ∈ blackboard_Q ( italic_t ) be rational functions such that F⁢(t),G⁢(t)𝐹𝑡𝐺𝑡F(t),G(t)italic_F ( italic_t ) , italic_G ( italic_t ) and the constant function 1111 are linearly independent over ℚℚ\mathbb{Q}blackboard_Q, we prove an asymptotic formula for the number of the three term rational function progressions of the form x,x+F⁢(y),x+G⁢(y)𝑥𝑥𝐹𝑦𝑥𝐺𝑦x,x+F(y),x+G(y)italic_x , italic_x + italic_F ( italic_y ) , italic_x + italic_G ( italic_y ) in subsets of 𝔽psubscript𝔽𝑝\mathbb{F}_{p}blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT. The main new ingredient is an algebraic geometry version of PET induction that bypasses Weyl’s differencing. This answers a question of Bourgain and Chang.",[],[]
"Controlling molecular reactivity by shaped laser pulses is a long-standing goal in chemistry. Here we suggest a direct optimal control approach which combines external pulse optimization with other control parameters arising in the upcoming field of vibro-polaritonic chemistry, for enhanced controllability
The direct optimal control approach is characterized by a simultaneous simulation and optimization paradigm, meaning that the equations of motion are discretized and converted into a set of holonomic constraints for a nonlinear optimization problem given by the control functional. Compared with indirect optimal control this procedure offers great flexibility such as final time or Hamiltonian parameter optimization. Simultaneous direct optimal control (SimDOC) theory will be applied to a model system describing H-atom transfer in a lossy Fabry-Pérot cavity under vibrational strong coupling conditions. Specifically, optimization of the cavity coupling strength and thus of the control landscape will be demonstrated.",[],['Germany']
"In this paper we consider a fourth order nonlinear parabolic delayed problem
modelling a quasi-instantaneous turn-over of linkages in the context
of cell-motility.
The model depends on a small
parameter ε𝜀\varepsilonitalic_ε which represents a typical time scale of the memory effect.
We first prove global existence and uniqueness of solutions for ε𝜀\varepsilonitalic_ε fixed.
This is achieved by combining suitable fixed-point and energy arguments and by uncovering a nonlocal in time, integral conserved quantity.
After giving a complete classification of steady states in terms of elliptic functions,
we next show that every solution converges to a steady state as t→∞→𝑡t\to\inftyitalic_t → ∞.
When ε→0→𝜀0\varepsilon\to 0italic_ε → 0,
we then establish convergence results on finite time intervals, showing
that the solution tends in a suitable sense
towards the solution of a parabolic problem without delay.
Moreover, we establish the convergence of energies as ε→0→𝜀0\varepsilon\to 0italic_ε → 0,
which enables us to show
that, for ε𝜀\varepsilonitalic_ε small enough,
the ε𝜀\varepsilonitalic_ε-dependent
problem inherits part of the large time asymptotics of the limiting parabolic problem.",[],[]
"In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms. This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs. The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs). The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs). With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN. A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL. Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.","['Space-air-ground integrated networks', 'edge computing', 'resource allocation', 'unmanned aerial vehicle', 'deep reinforcement learning.']",[]
"Including Artificial Neural Networks (ANNs) in embedded systems at the edge allows applications to exploit Artificial Intelligence (AI) capabilities directly within devices operating at the network periphery, facilitating real-time decision-making. Especially critical in domains such as autonomous vehicles, industrial automation, and healthcare, the use of ANNs can enable these systems to process substantial data volumes locally, thereby reducing latency and power consumption. Moreover, it enhances privacy and security by containing sensitive data within the confines of the edge device.
The adoption of Spiking Neural Networks (SNNs) in these environments offers a promising computing paradigm, mimicking the behavior of biological neurons and efficiently handling dynamic, time-sensitive data. However, deploying efficient SNNs in resource-constrained edge environments requires hardware accelerators, such as solutions based on Field Programmable Gate Arrays (FPGAs), that provide high parallelism and reconfigurability.
This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized SNNs accelerators on FPGAs for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNNs, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Dataset (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGAs, and power consumption, draining only 180mW for a complete inference on an input image. The latency is comparable to the ones observed in the state-of-the-art, with 780μ𝜇\muitalic_μs/img. To the authors’ knowledge, Spiker+ is the first SNNs accelerator tested on the SHD. In this case, the accelerator requires 18,268 logic cells and 51 BRAMs, with an overall power consumption of 430mW and a latency of 54 μ𝜇\muitalic_μs for a complete inference on input data. This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications.","['Spiking', 'Neural', 'Networks', 'LIF', 'FPGA', 'Neuromorphic accelerator', 'Edge computing', 'Artificial', 'Intelligence', 'Frugal', 'AI.']",[]
"Plane-based Geometric Algebra (PGA) has revealed points in a d𝑑ditalic_d-dimensional pseudo-Euclidean space ℝp,q,1subscriptℝ𝑝𝑞1\mathbb{R}_{p,q,1}blackboard_R start_POSTSUBSCRIPT italic_p , italic_q , 1 end_POSTSUBSCRIPT to be represented by d𝑑ditalic_d-blades rather than vectors.
This discovery allows points to be factored into d𝑑ditalic_d orthogonal hyperplanes, establishing points as pseudoscalars of a local geometric algebra ℝp⁢qsubscriptℝ𝑝𝑞\mathbb{R}_{pq}blackboard_R start_POSTSUBSCRIPT italic_p italic_q end_POSTSUBSCRIPT.
Astonishingly, the non-uniqueness of this factorization reveals the existence of a local Spin⁢(p,q)Spin𝑝𝑞\textup{Spin}({p,q})Spin ( italic_p , italic_q ) geometric gauge group at each point.
Moreover, a point can alternatively be factored into a product of the elements of the Cartan subalgebra of 𝔰⁢𝔭⁢𝔦⁢𝔫⁢(p,q)𝔰𝔭𝔦𝔫𝑝𝑞\mathfrak{spin}({p,q})fraktur_s fraktur_p fraktur_i fraktur_n ( italic_p , italic_q ), which are traditionally used to label spinor representations.
Therefore, points reveal previously hidden geometric foundations for some of quantum field theory’s mysteries.
This work outlines the impact of PGA on the study of spinor representations in any number of dimensions, and is the first in a research programme exploring the consequences of this insight.",[],[]
"This work presents a novel semantic transmission framework in wireless networks, leveraging the joint processing technique. Our framework enables multiple cooperating base stations to efficiently transmit semantic information to multiple users simultaneously. To enhance the semantic communication efficiency of the transmission framework, we formulate an optimization problem with the objective of maximizing the semantic spectral efficiency of the framework and propose a low-complexity dynamic semantic mapping and resource allocation algorithm. This algorithm, based on deep reinforcement learning and alternative optimization, achieves near-optimal performance while reducing computational complexity. Simulation results validate the effectiveness of the proposed algorithm, bridging the research gap and facilitating the practical implementation of semantic communication systems.","['Semantic communication', 'spectral efficiency', 'joint processing', 'resource allocation', 'deep reinforcement learning.']",[]
,[],[]
"This paper introduces HAAQI-Net, a non-intrusive deep learning model for music quality assessment tailored to hearing aid users. In contrast to traditional methods like the Hearing Aid Audio Quality Index (HAAQI), HAAQI-Net utilizes a Bidirectional Long Short-Term Memory (BLSTM) with attention. It takes an assessed music sample and a hearing loss pattern as input, generating a predicted HAAQI score. The model employs the pre-trained Bidirectional Encoder representation from Audio Transformers (BEATs) for acoustic feature extraction. Comparing predicted scores with ground truth, HAAQI-Net achieves a Longitudinal Concordance Correlation (LCC) of 0.92570.92570.92570.9257, Spearman’s Rank Correlation Coefficient (SRCC) of 0.93940.93940.93940.9394, and Mean Squared Error (MSE) of 0.00800.00800.00800.0080. Notably, this high performance comes with a substantial reduction in inference time: from 62.5262.5262.5262.52 seconds (by HAAQI) to 2.712.712.712.71 seconds (by HAAQI-Net), serving as an efficient music quality assessment model for hearing aid users.",[],[]
,[],[]
,[],[]
"We present a new high-probability PAC-Bayes oracle bound for unbounded losses. This result can be understood as a PAC-Bayes version of the Chernoff bound. The proof technique relies on uniformly bounding the tail of certain random variable based on the Cramér transform of the loss. We highlight two applications of our main result. First, we show that our bound solves the open problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we show that our approach allows working with flexible assumptions on the loss function, resulting in novel bounds that generalize previous ones and can be minimized to obtain Gibbs-like posteriors.","['Machine', 'Learning', 'ICML']",[]
"We study search games between a mobile Searcher and an immobile Hider in which the Searcher aims to minimize some payoff, which is either the time to find the Hider (the search time), or a normalized search time. We consider a new setting in which the Searcher has some potentially erroneous information, or prediction on the Hider’s position. Specifically, we study tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and the robustness (i.e., the worst case expected payoff assuming that the prediction is adversarially generated). We show how to apply this framework in search games over both discrete and continuous, as well as bounded and unbounded spaces. Specifically, we prove optimal consistency/robustness tradeoffs for three fundamental search games, namely searching in a number of discrete locations, expanding search in a tree network, and searching in the infinite line. Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations.",[],[]
"The growing trend towards specialization has led to a proliferation of accelerators and alternative processing devices. When embedded in conventional computer architectures, the PCIe link connecting the CPU to these devices becomes a bottleneck. Several proposals for alternative designs have been put forward, with these efforts having now converged into the Compute Express Link (CXL) specification. CXL is an interconnect protocol on top of PCIe with a more modern and powerful interface. While still on version 1.0 in terms of commercial availability, the potential of CXL to radically change the underlying architecture has already attracted considerable attention. This attention has been focused mainly on the possibility of using CXL to build a shared memory system among the machines in a rack. We argue, however, that such benefits are just the beginning of more significant changes that will have a major impact on database engines and data processing systems. In a nutshell, while the cloud favored scale-out approaches, CXL brings back scale-up architectures. In the paper we describe how CXL enables such architectures, and the research challenges associated with the emerging scale-up, heterogeneous hardware platforms.",[],['Switzerland']
"One unique feature of nonlinear dynamical systems is the existence of superharmonic and subharmonic resonances in addition to primary resonances. In this study, an effective vibration testing methodology is introduced for the experimental identification of these secondary resonances. The proposed method relies on phase-locked loop control combined with adaptive filters for online Fourier decomposition. To this end, the concept of a resonant phase lag is exploited to define the target phase lag to be followed during the experimental continuation process. The method is demonstrated using two systems featuring cubic nonlinearities, namely a numerical Duffing oscillator and a physical experiment comprising a clamped-clamped thin beam. The obtained results highlight that the control scheme can accurately characterize secondary resonances as well as track their backbone curves.
A particularly salient feature of the developed algorithm is that, starting from the rest position, it facilitates an automatic and smooth dynamic state transfer toward one point of a subharmonic isolated branch, hence, inducing branch switching.",[],[]
"In this paper, we propose a model enabling the creation of a social graph corresponding to real society. The procedure uses data describing the real social relations in the community, like marital status or number of kids. Results show the power-law behavior of the distribution of links and, typical for small worlds, the independence of the clustering coefficient on the size of the graph.",[],['Poland']
"For a Fano manifold,
We consider the geometric quantization of the Kähler-Ricci flow
and the associated entropy functional.
Convergence to the original flow and entropy is established.
It is also possible to
formulate the finite-dimensional analogue of the optimal degeneration for the anti-canonical polarization.",[],[]
"Context
It is commonly accepted that the quality of requirements specifications impacts subsequent software engineering activities.
However, we still lack empirical evidence to support organizations in deciding whether their requirements are good enough or impede subsequent activities.
Objective
We aim to contribute empirical evidence to the effect that requirements quality defects have on a software engineering activity that depends on this requirement.
Method
We replicate a controlled experiment in which 25 participants from industry and university generate domain models from four natural language requirements containing different quality defects.
We evaluate the resulting models using both frequentist and Bayesian data analysis.
Results
Contrary to our expectations, our results show that the use of passive voice only has a minor impact on the resulting domain models.
The use of ambiguous pronouns, however, shows a strong effect on various properties of the resulting domain models.
Most notably, ambiguous pronouns lead to incorrect associations in domain models.
Conclusion
Despite being equally advised against by literature and frequentist methods, the Bayesian data analysis shows that the two investigated quality defects have vastly different impacts on software engineering activities and, hence, deserve different levels of attention.
Our employed method can be further utilized by researchers to improve reliable, detailed empirical evidence on requirements quality.","['Requirements', 'Engineering', 'Requirements', 'Quality', 'Experiment', 'Replication', 'Bayesian', 'Data', 'Analysis']",[]
"Marker code is an effective coding scheme to protect data from insertions and deletions. It has potential applications in future storage systems, such as DNA storage and racetrack memory. When decoding marker codes, perfect channel state information (CSI), i.e., insertion and deletion probabilities, are required to detect insertion and deletion errors. Sometimes, the perfect CSI is not easy to obtain or the accurate channel model is unknown. Therefore, it is deserved to develop detecting algorithms for marker code without the knowledge of perfect CSI. In this paper, we propose two CSI-agnostic detecting algorithms for marker code based on deep learning. The first one is a model-driven deep learning method, which deep unfolds the original iterative detecting algorithm of marker code. In this method, CSI become weights in neural networks and these weights can be learned from training data. The second one is a data-driven method which is an end-to-end system based on the deep bidirectional gated recurrent unit network. Simulation results show that error performances of the proposed methods are significantly better than that of the original detection algorithm with CSI uncertainty. Furthermore, the proposed data-driven method exhibits better error performances than other methods for unknown channel models.","['Bidirectional gated recurrent unit (bi-GRU)', 'deep unfolding', 'insertions and deletions', 'marker codes', 'model-driven deep learning.']",[]
"TOPCAT is a desktop GUI tool for working with tabular data
such as source catalogues. Among other capabilities it provides
a rich set of visualisation options suitable for interactive
exploration of large datasets.
The latest release introduces a Corner Plot window which displays
a grid of linked scatter-plot-like and histogram-like plots for
all pair and single combinations from a supplied list of coordinates.",[],[]
"In the present study, we perform direct numerical simulations of compressible turbulent boundary
layers at the free stream Mach number of 2∼6similar-to262\sim 62 ∼ 6 laden with dilute phase of spherical particles
to investigate the Mach number effects on particle transport and dynamics.
Most of the phenomena observed and well-recognized for inertia particles in incompressible
wall-bounded turbulent flows, such as the near-wall preferential accumulation and clustering
beneath the low-speed streaks, the flatter mean velocity profiles and the trend variation of the
particle velocity fluctuations, are identified in the compressible turbulent boundary layer as well.
However, we find that the compressibility effects are significant for large inertia particles.
As the Mach number increases, the near-wall accumulation and the small-scale clustering
are alleviated, which is probably caused by the variation of the fluid density and viscosity
that are crucial to particle dynamics.
This can be affected by the fact that the forces acting on the particles with
the viscous Stokes number greater than 500 are modulated by the comparatively
high particle Mach numbers in the near-wall region.
This is also the reason for the abatement of the streamwise particle velocity fluctuation
intensities with the Mach numbers.",[],['China']
"The Job shop scheduling problem (JSSP) plays a pivotal role in industrial applications,
such as signal processing (SP) and steel manufacturing,
involving sequencing machines and jobs to maximize scheduling
efficiency. Before, JSSP was solved using manually defined circuits by variational quantum algorithm (VQA).
Finding a good circuit architecture is task-specific and time-consuming.
Differentiable quantum architecture search (DQAS) is a gradient-based framework
that can automatically design circuits.
However, DQAS is only tested on quantum approximate optimization algorithm (QAOA)
and error mitigation tasks.
Whether DQAS applies to JSSP based on a more flexible algorithm, such as
variational quantum eigensolver (VQE), is still open for optimization problems.
In this work, we redefine the operation pool and extend DQAS to a framework JSSP-DQAS
by evaluating circuits to
generate circuits for JSSP automatically.
The experiments conclude that JSSP-DQAS can automatically find
noise-resilient circuit architectures that perform much better than manually designed
circuits. It helps to improve the efficiency of solving JSSP.",[],[]
"Utilizing the recently established connection between Palatini-like gravity and linear Generalized Uncertainty Principle (GUP) models, we have formulated an approach that facilitates the examination of Bose gases. Our primary focus is on the ideal Bose-Einstein condensate and liquid helium, chosen as illustrative examples to underscore the feasibility of tabletop experiments in assessing gravity models. The non-interacting Bose-Einstein condensate imposes constraints on linear GUP and Palatini f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity (Eddington-inspired Born-Infeld gravity) within the ranges of −1012≲σ≲3×1024⁢ s/kg mless-than-or-similar-tosuperscript1012𝜎less-than-or-similar-to3superscript1024 skg m-10^{12}\lesssim\sigma\lesssim 3\times 10^{24}{\text{ s}}/{\text{kg m}}- 10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT ≲ italic_σ ≲ 3 × 10 start_POSTSUPERSCRIPT 24 end_POSTSUPERSCRIPT s / kg m and −10−1≲β¯≲1011⁢ m2less-than-or-similar-tosuperscript101¯𝛽less-than-or-similar-tosuperscript1011superscript m2-10^{-1}\lesssim\bar{\beta}\lesssim 10^{11}\text{ m}^{2}- 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≲ over¯ start_ARG italic_β end_ARG ≲ 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (−4×10−1≲ϵ≲4×1011⁢ m2less-than-or-similar-to4superscript101italic-ϵless-than-or-similar-to4superscript1011superscript m2-4\times 10^{-1}\lesssim\epsilon\lesssim 4\times 10^{11}\text{ m}^{2}- 4 × 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≲ italic_ϵ ≲ 4 × 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT), respectively.
In contrast, the properties of liquid helium suggest more realistic bounds, specifically −1023≲σ≲1023⁢ s/kg mless-than-or-similar-tosuperscript1023𝜎less-than-or-similar-tosuperscript1023 skg m-10^{23}\lesssim\sigma\lesssim 10^{23}{\text{ s}}/{\text{kg m}}- 10 start_POSTSUPERSCRIPT 23 end_POSTSUPERSCRIPT ≲ italic_σ ≲ 10 start_POSTSUPERSCRIPT 23 end_POSTSUPERSCRIPT s / kg m and −109≲β¯≲109⁢ m2less-than-or-similar-tosuperscript109¯𝛽less-than-or-similar-tosuperscript109superscript m2-10^{9}\lesssim\bar{\beta}\lesssim 10^{9}\text{ m}^{2}- 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT ≲ over¯ start_ARG italic_β end_ARG ≲ 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. Additionally, we argue that the newly developed method employing Earth seismic waves provides improved constraints for quantum and modified gravity by approximately one order of magnitude.",[],['Spain']
,[],[]
"We study the problem of estimating the frequencies of several complex sinusoids with constant amplitude (CA) (also called constant modulus) from multichannel signals of their superposition. To exploit the CA property for frequency estimation in the framework of atomic norm minimization (ANM), we introduce multiple positive-semidefinite block matrices composed of Hankel and Toeplitz submatrices and formulate the ANM problem as a convex structured low-rank approximation (SLRA) problem. The proposed SLRA is a semidefinite programming and has substantial differences from existing such formulations without using the CA property. The proposed approach is termed as SLRA-based ANM for CA frequency estimation (SACA). We provide theoretical guarantees and extensive simulations that validate the advantages of SACA.",[],[]
"In current studies for testing Bell inequalities at colliders, the reconstruction of spin correlations from scattering cross-sections relies on the bilinear form of the spin correlations, and not all local hidden variable models (LHVMs) have such a property. To demonstrate that a general LHVM cannot be rule out via scattering cross-section data, we propose a specific LHVM, which can exactly duplicate the same scattering cross-section for particle production and decay as the standard quantum theory, making it indistinguishable at colliders in principle. Despite of this, we find that reconstructing spin correlations through scattering cross-sections can still rule out a broad class of LHVMs, e.g., those models employing classical spin correlations as a surrogate for quantum spin correlations.",[],['China']
"Multi-class colorectal tissue classification is a challenging problem that is typically addressed in a setting, where it is assumed that ample amounts of training data is available. However, manual annotation of fine-grained colorectal tissue samples of multiple classes, especially the rare ones like stromal tumor and anal cancer is laborious and expensive. To address this, we propose a knowledge distillation-based approach, named KD-CTCNet, that effectively captures local texture information from few tissue samples, through a distillation loss, to improve the standard CNN features. The resulting enriched feature representation achieves improved classification performance specifically in low data regimes. Extensive experiments on two public datasets of colorectal tissues reveal the merits of the proposed contributions, with a consistent gain achieved over different approaches across low data settings.
The code and models are publicly available on GitHub.","['Colorectal', 'Tissue', 'Classification', 'Low', 'Data', 'Regimes']",[]
"The electromagnetic inverse problem has long been a research hotspot. This study aims to reverse radar view angles in synthetic aperture radar (SAR) images given a target model. Nonetheless, the scarcity of SAR data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches. To address these challenges, we propose an interactive deep reinforcement learning (DRL) framework, where an electromagnetic simulator named differentiable SAR render (DSR) is embedded to facilitate the interaction between the agent and the environment, simulating a human-like process of angle prediction. Specifically, DSR generates SAR images at arbitrary view angles in real time. And the differences in sequential and semantic aspects between the view angle-corresponding images are leveraged to construct the state space in DRL, which effectively suppress the complex background interference, enhance the sensitivity to temporal variations, and improve the capability to capture fine-grained information. Additionally, in order to maintain the stability and convergence of our method, a series of reward mechanisms, such as memory difference, smoothing and boundary penalty, are utilized to form the final reward function. Extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method. When utilized in the cross-domain area, the proposed method greatly mitigates inconsistency between simulated and real domains, outperforming reference methods significantly.","['Deep reinforcement learning (DRL)', 'differentiable', 'SAR render (DSR)', 'synthetic aperture radar (SAR)', 'radar view angles']",[]
"In this article, we construct a 16161616-dimensional sedenion-like associative algebra, which is an even subalgebra of 25superscript252^{5}2 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT-dimensional Clifford algebra C⁢l5,0𝐶subscript𝑙50Cl_{5,0}italic_C italic_l start_POSTSUBSCRIPT 5 , 0 end_POSTSUBSCRIPT. We define the norm on sedenion-like algebra and show that its sixteen-dimensional elements preserves the norm relation ∥S⁢T∥=∥S∥⁢∥T∥delimited-∥∥𝑆𝑇delimited-∥∥𝑆delimited-∥∥𝑇\lVert ST\rVert=\lVert S\rVert\lVert T\rVert∥ italic_S italic_T ∥ = ∥ italic_S ∥ ∥ italic_T ∥ under the condition Sr⁢Sd†+Sr†⁢Sd=0subscript𝑆𝑟superscriptsubscript𝑆𝑑†superscriptsubscript𝑆𝑟†subscript𝑆𝑑0S_{r}S_{d}^{\dagger}+S_{r}^{\dagger}S_{d}=0italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT + italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = 0, where Sr,Sdsubscript𝑆𝑟subscript𝑆𝑑S_{r},~{}S_{d}italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT denote the real and dual part of an octonion-like number S𝑆Sitalic_S respectively and S†superscript𝑆†S^{\dagger}italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT is the transpose of S𝑆Sitalic_S. The elements of this sedenion-like algebra can be written as dual octonion like numbers called split bioctonion-like algebra and S⁢S†𝑆superscript𝑆†SS^{\dagger}italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT is commutative [i.e. S⁢S†=S†⁢S𝑆superscript𝑆†superscript𝑆†𝑆SS^{\dagger}=S^{\dagger}Sitalic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT = italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_S and (S⁢S†)⁢T=T⁢(S⁢S†)𝑆superscript𝑆†𝑇𝑇𝑆superscript𝑆†(SS^{\dagger})T=T(SS^{\dagger})( italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ) italic_T = italic_T ( italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT )], for any two octonion-like/sedenion-like numbers S𝑆Sitalic_S and T𝑇Titalic_T. We define the operations coproduct △△\bigtriangleup△, counit ϵitalic-ϵ\epsilonitalic_ϵ and antipode S𝑆Sitalic_S on octonion-like/sedenion-like algebra to construct the Hopf algebra structure on it. We also show that 8888-dimensional octonion-like associative seminormed division algebra is a ℤ24/2superscriptsubscriptℤ242\mathbb{Z}_{2}^{4}/2blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT / 2-graded quasialgebra and 16161616 dimensional sedenion-like algebra is a ℤ25/2superscriptsubscriptℤ252\mathbb{Z}_{2}^{5}/2blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT / 2-graded quasialgebra.",[],[]
,[],[]
"Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels. A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular. In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules.
In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one’s true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FedQV against poisoning attacks. It also shows that combining FedQV with unequal voting “budgets” according to a reputation score increases its performance benefits even further. Finally, we show that FedQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.",[],[]
The effect of a finite volume presents itself both in heavy ion experiments as well as in recent model calculations. The magnitude is sensitive to the proximity of a nearby critical point. We calculate the finite volume effects at finite temperature in continuum QCD using lattice simulations. We focus on the vicinity of the chiral crossover. We investigate the impact of finite volumes at zero and small chemical potentials on the QCD transition through the chiral observables.,[],[]
"In this paper, we provide some characterizations of strong pseudoconvexity by the boundary behavior of intrinsic invariants for smoothly bounded pseudoconvex domains of finite type in ℂ2superscriptℂ2\mathbb{C}^{2}blackboard_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. As a consequence, if such domain is biholomorphically equivalent to a quotient of the unit ball, then it is strongly pseudoconvex.","['Strong pseudoconvexity', 'Holomorphic sectional curvature', 'Pseudoconvex domains', 'Finite type']",[]
,[],[]
"Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration’s non-stationary nature.
This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing’s inherent and operational parameters. We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. Based on this, we design a time-frequency convolutional neural network (TF-CNN) to diagnose various faults in rolling-element bearings.
Our experimental findings undeniably demonstrate the superior performance of TF-CNN in comparison to recently developed techniques. They also assert its versatility in capturing fault-relevant non-stationary features that couple with speed changes and show its exceptional resilience to noise, consistently surpassing competing methods across various signal-to-noise ratios and performance metrics. Altogether, the TF-CNN achieves substantial accuracy improvements up to 15%, in severe noise conditions.","['Bearing fault', 'damage detection', 'deep learning', 'time-frequency analysis', 'variable speed.']",[]
"We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars. Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3D generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3D humans without relying on pre-existing 3D or 2D assets. To address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3D generative model from synthetic 2D data. During inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3D shapes. Specifically, En3D comprises three modules: a 3D generator that accurately models generalizable 3D humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical UV partitioning and a differentiable rasterizer. Experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity. We also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation.",[],[]
"We describe a basis for free Lie superalgebras which uses the theory of basic
commutators. The only description of bases for free Lie superalgbras that I
have found in the literature is in the book Infinite Dimensional Lie
Superalgebras by Bahturin et al. [1]. Their bases make use of the theory of
Shirshov bases in free Lie algebras, and I believe that there is a case for
writing up an alternative approach using basic commutators. An additional reason
for publishing this note is that I use the basis described here in a
forthcoming paper where I prove that 5-Engel Lie algebras of characteristic
p𝑝pitalic_p for p>7𝑝7p>7italic_p > 7 are nilpotent of class at most 11.",[],[]
"Simulating high-resolution Synthetic Aperture Radar (SAR) images in complex scenes has consistently presented a significant research challenge. The development of a microwave-domain surface scattering model and its reversibility are poised to play a pivotal role in enhancing the authenticity of SAR image simulations and facilitating the reconstruction of target parameters. Drawing inspiration from the field of computer graphics, this paper proposes a surface microwave rendering model that comprehensively considers both Specular and Diffuse contributions. The model is analytically represented by the coherent spatially varying bidirectional scattering distribution function (CSVBSDF) based on the Kirchhoff approximation (KA) and the perturbation method (SPM). And SAR imaging is achieved through the synergistic combination of ray tracing and fast mapping projection techniques. Furthermore, a differentiable ray tracing (DRT) engine based on SAR images was constructed for CSVBSDF surface scattering parameter learning. Within this SAR image simulation engine, the use of differentiable reverse ray tracing enables the rapid estimation of parameter gradients from SAR images. The effectiveness of this approach has been validated through simulations and comparisons with real SAR images. By learning the surface scattering parameters, substantial enhancements in SAR image simulation performance under various observation conditions have been demonstrated.","['bidirectional scattering distribution function', 'differentiable ray tracing', 'surface microwave rendering model', 'synthetic aperture radar (SAR).']",[]
"This paper studies the fundamental limit of semantic communications over the discrete memoryless channel. We consider the scenario to send a semantic source consisting of an observation state and its corresponding semantic state, both of which are recovered at the receiver. To derive the performance limitation, we adopt the semantic rate-distortion function (SRDF) to study the relationship among the minimum compression rate, observation distortion, semantic distortion, and channel capacity. For the case with unknown semantic source distribution, while only a set of the source samples is available, we propose a neural-network-based method by leveraging the generative networks to learn the semantic source distribution. Furthermore, for a special case where the semantic state is a deterministic function of the observation, we design a cascade neural network to estimate the SRDF. For the case with perfectly known semantic source distribution, we propose a general Blahut-Arimoto algorithm to effectively compute the SRDF. Finally, experimental results validate our proposed algorithms for the scenarios with ideal Gaussian semantic source and some practical datasets.","['Semantic communications', 'semantic rate-distortion', 'generative network', 'Blahut-Arimoto algorithm.']",[]
"Context:Plasmoid-mediated reconnection plays a fundamental role in different solar atmospheric phenomena.
Numerical reproduction of this process is therefore essential for developing robust solar models.
Aims:Our goal is to assess plasmoid-mediated reconnection across various numerical resistivity models in order to investigate how plasmoid numbers and reconnection rates depend on the Lundquist number.
Methods:We used the Bifrost code to drive magnetic reconnection in a 2D coronal fan-spine topology, carrying out a parametric study of several experiments with different numerical resolution and resistivity models. We employed three anomalous resistivity models: (1) the original hyper-diffusion from Bifrost, (2) a resistivity proportional to current density, and (3) a resistivity quadratically proportional to electron drift velocity. For comparisons, experiments with uniform resistivity were also run.
Results:Plasmoid-mediated reconnection is obtained in most of the experiments. With uniform resistivity, increasing the resolution reveals higher plasmoid frequency with weaker scaling to the Lundquist number, obtaining 7.9-12 plasmoids per minute for SL∈[1.8×104,2.6×105]subscript𝑆L1.8superscript1042.6superscript105S_{\mathrm{L}}\in[1.8\times 10^{4},2.6\times 10^{5}]italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT ∈ [ 1.8 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT , 2.6 × 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT ] with a scaling of SL0.210superscriptsubscript𝑆L0.210S_{\mathrm{L}}^{0.210}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.210 end_POSTSUPERSCRIPT in the highest-resolution resistivity cases, transcending into Petschek reconnection in the high-SLsubscript𝑆LS_{\mathrm{L}}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT limit (where the diffusive effects of the resistivity become small compared to the non-uniform viscosity)
and Sweet-Parker reconnection in the low-SLsubscript𝑆LS_{\mathrm{L}}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT limit. Anomalous resistivity leads to similar results even with lower resolution. The drift-velocity-dependent resistivity excellently reproduces Petschek reconnection for any Lundquist number, and similar results are seen with resistivity
proportional to current-density though with slightly lower reconnection rates and plasmoid numbers.
Among the different resistivity models applied on the given numerical resolution, the hyper-diffusion model reproduced plasmoid characteristics in closest resemblance to those obtained with uniform resistivity at a significantly higher resolution.
Conclusions:","['\nmagnetohydrodynamics (MHD) –\nmagnetic reconnection –\nmethods: numerical –', 'Sun: atmosphere –', 'Sun: corona –', 'Sun: magnetic fields']",[]
,[],[]
"Modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of Vision-Language Self-Supervised Learning (VL-SSL) with large pre-trained models to learn versatile medical vision representations. However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders. To address both issues, we introduce the backbone-agnostic Adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight Adaptor module for cross-modal learning. Experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90%percent9090\%90 % compared to current pre-training approaches. Notably, when fine-tuned with just 1%percent11\%1 % of data, Adaptor outperforms several Transformer-based methods trained on full datasets in medical image segmentation.",[],[]
"Deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides. Conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment. To overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory. Our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (DBH). Compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas. We evaluated our method on a comprehensive dataset of 400 trees and achieved a DBH estimation accuracy with an error rate of less than 2.5%. Our method holds significant potential for substantially improving forest management practices. By enhancing the accuracy and efficiency of tree inventory, our model empowers urban management to mitigate the adverse effects of deforestation and climate change.","['Urban deforestation', 'street trees inventory', 'deep learning', 'mobile phones', 'DBH', 'ABG', 'CNN']",[]
"Identifying labels that did not appear during training, known as multi-label zero-shot learning, is a non-trivial task in computer vision. To this end, recent studies have attempted to explore the multi-modal knowledge of vision-language pre-training (VLP) models by knowledge distillation, allowing to recognize unseen labels in an open-vocabulary manner. However, experimental evidence shows that knowledge distillation is suboptimal and provides limited performance gain in unseen label prediction. In this paper, a novel query-based knowledge sharing paradigm is proposed to explore the multi-modal knowledge from the pretrained VLP model for open-vocabulary multi-label classification. Specifically, a set of learnable label-agnostic query tokens is trained to extract critical vision knowledge from the input image, and further shared across all labels, allowing them to select tokens of interest as visual clues for recognition. Besides, we propose an effective prompt pool for robust label embedding, and reformulate the standard ranking learning into a form of classification to allow the magnitude of feature vectors for matching, which both significantly benefit label recognition. Experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively.",[],[]
"In this work, we study the renormalization of nonlocal quark bilinear operators containing an asymmetric staple-shaped Wilson line at the one-loop level in both lattice and continuum perturbation theory. These operators enter the first-principle calculation of transverse momentum-dependent parton distribution functions (TMDPDFs) in lattice QCD using the formulation of Large Momentum Effective Theory. We provide appropriate RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT-type conditions that address the power and logarithmic divergences, as well as the mixing among staple operators of different Dirac structures, using a number of different possible projectors. A variant of RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT, including calculations of rectangular Wilson loops, which cancel the pinch-pole singularities of the staple operators at infinite length and reduce residual power divergences, is also employed. We calculate at one-loop order the conversion matrix, which relates the quasi-TMDPDFs in the RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT-type schemes to the reference scheme MS¯¯MS{\overline{\rm MS}}over¯ start_ARG roman_MS end_ARG for arbitrary values of the renormalization momentum scale and of the dimensions of the staple.",[],['Cyprus']
"Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we
propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account. Extensive experiments on six benchmark datasets show the effectiveness of our model. Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.",[],[]
,[],[]
"In first-price and all-pay auctions under the standard symmetric independent private-values model, we show that the unique Bayesian Coarse Correlated Equilibrium with symmetric, differentiable and strictly increasing bidding strategies is the unique strict Bayesian Nash Equilibrium. Interestingly, this result does not require assumptions on the prior distribution. The proof is based on a dual bound of the infinite-dimensional linear program. Numerical experiments without restrictions on bidding strategies show that for first-price auctions and discretisations up to 21 of the type and bid space, increasing discretisation sizes actually increase the concentration of Bayesian Coarse Correlated Equilibrium over the Bayesian Nash Equilibrium, so long as the prior c.d.f. is concave. Such a concentration is also observed for all-pay auctions, independent of the prior distribution. Overall, our results imply that the equilibria of these important class of auctions are indeed learnable.",[],[]
"This talk is on a refined investigation on light flavor meson-baryon scatterings, using a dynamical coupled-channel approach, i.e. the JÃlich-Bonn model. The previous channel space of π⁢N𝜋𝑁\pi Nitalic_π italic_N, π⁢Δ𝜋Δ\pi\Deltaitalic_π roman_Δ, σ⁢N𝜎𝑁\sigma Nitalic_σ italic_N, ρ⁢N𝜌𝑁\rho Nitalic_ρ italic_N, η⁢N𝜂𝑁\eta Nitalic_η italic_N, K⁢Λ𝐾ΛK\Lambdaitalic_K roman_Λ and K⁢Σ𝐾ΣK\Sigmaitalic_K roman_Σ is extended by adding the ω⁢N𝜔𝑁\omega Nitalic_ω italic_N final state. The spectra of N*superscript𝑁N^{*}italic_N start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and ΔΔ\Deltaroman_Δ resonances are extracted, based on the result of a global fit to a worldwide collection of data, in the energy region from the π⁢N𝜋𝑁\pi Nitalic_π italic_N threshold to center-of-mass energy z=2.3𝑧2.3z=2.3italic_z = 2.3 GeV (approximately 300300300300 parameters against 9000900090009000 data points). A negative value of the ω⁢N𝜔𝑁\omega Nitalic_ω italic_N elastic spin-averaged scattering length has been extracted.",[],[]
"Quantum emitters such as atoms or quantum dots are excellent sources of indistinguishable single photons for quantum technologies. However, upon coherent excitation, the emitted photonic state can include a vacuum component in a superposition with the one-photon component. Here, we study how the presence of such coherence with vacuum impacts photonic quantum information processing, starting with Hong-Ou-Mandel (HOM) interference that is central to quantum photonic technology. We first demonstrate that when coherence with vacuum is present, it causes a systematic error in the measurement of photon indistinguishability, an effect that has previously been overlooked and impacts some results in the literature. Using a proper normalisation method we show how this can be corrected. Our complete analysis of HOM interference also reveals a coherent phenomenon that results in path entanglement between photons in presence of coherence with vacuum. This type of phenomenon appears when multiple interfering wavepackets are only partially measured, a scenario that is key for heralded quantum gates implementation. To illustrate its impact on information processing, we simulate a heralded controlled-NOT gate and show that the presence of coherence with vacuum can actually improve the fidelity compared to incoherent photon losses. Our work reveals that the lack of a photon cannot always be accounted for by a simple loss mechanism, and that coherence with vacuum must be considered to properly explain error processes in photon-based quantum information processing.",[],"['Spain', 'France']"
"We use the entropy method to analyze the nonlinear dynamics and stability of a continuum kinetic model of an active nematic suspension. From the time evolution of the relative entropy – an energy-like quantity in the kinetic model – we derive a variational bound on relative entropy fluctuations that can be expressed in terms of orientational order parameters. From this bound we show isotropic suspensions are nonlinearly stable for sufficiently low activity, and derive upper bounds on spatiotemporal averages in the unstable regime that are consistent with fully nonlinear simulations. This work highlights the self-organizing role of activity in particle suspensions, and places limits on how organized such systems can be.",[],[]
"Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map. Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments. We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynamic environments.",[],[]
,[],[]
"This talk focuses on a recent work aiming at determining the composition of certain N*superscript𝑁N^{*}italic_N start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and ΔΔ\Deltaroman_Δ resonances, i.e. whether they are compact states formed directly by quarks and gluons, or composite generated from the meson-baryon interaction. The information of the resonance poles is provided by a comprehensive coupled-channel approach, the Jülich-Bonn model. Thirteen states that are significant in this approach are studied. Two criteria for each state are adopted in this paper, the comparison thereof roughly indicates the model uncertainties. It is found that the conclusions for eight resonances are relatively certain: N⁢(1535)⁢12−𝑁1535superscript12N(1535)\frac{1}{2}^{-}italic_N ( 1535 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT, N⁢(1440)⁢12+𝑁1440superscript12N(1440)\frac{1}{2}^{+}italic_N ( 1440 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, N⁢(1710)⁢12+𝑁1710superscript12N(1710)\frac{1}{2}^{+}italic_N ( 1710 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, and N⁢(1520)⁢32−𝑁1520superscript32N(1520)\frac{3}{2}^{-}italic_N ( 1520 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT tend
to be composite; whereas N⁢(1650)⁢12−𝑁1650superscript12N(1650)\frac{1}{2}^{-}italic_N ( 1650 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT, N⁢(1900)⁢32+𝑁1900superscript32N(1900)\frac{3}{2}^{+}italic_N ( 1900 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, N⁢(1680)⁢52+𝑁1680superscript52N(1680)\frac{5}{2}^{+}italic_N ( 1680 ) divide start_ARG 5 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, and
Δ⁢(1600)⁢32+Δ1600superscript32\Delta(1600)\frac{3}{2}^{+}roman_Δ ( 1600 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT tend to be compact.",[],[]
"In many recent works, the potential of Exploratory Landscape Analysis (ELA) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated. These numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from High-level Property Prediction to Automated Algorithm Selection and Automated Algorithm Configuration. Without ELA features, analyzing and understanding the characteristics of single-objective continuous optimization problems would be impossible.
Yet, despite their undisputed usefulness, ELA features suffer from several drawbacks. These include, in particular, (1.) a strong correlation between multiple features, as well as (2.) its very limited applicability to multi-objective continuous optimization problems. As a remedy, recent works proposed deep learning-based approaches as alternatives to ELA. In these works, e.g., point-cloud transformers were used to characterize an optimization problem’s fitness landscape. However, these approaches require a large amount of labeled training data.

Within this work, we propose a hybrid approach, Deep-ELA, which combines (the benefits of) deep learning and ELA features. Specifically, we pre-trained four transformers on millions of randomly generated optimization problems to learn deep representations of the landscapes of continuous single- and multi-objective optimization problems. Our proposed framework can either be used out-of-the-box for analyzing single- and multi-objective continuous optimization problems, or subsequently fine-tuned to various tasks focussing on algorithm behavior and problem understanding.",[],[]
"Recently,  Xu and Zhou (2023) introduced a constructive approach for exploring computational hardness, proving that SAT requires exhaustive search.
In light of certain misinterpretations concerning the contributions and proofs in that paper, we focus on providing detailed explanations in this work.
We begin by delineating the core innovation of the constructive approach, shedding light on the pivotal concept of algorithm designability.
We address the overlooked white-box diagonalization method and highlight the concept of an almost independent solution space.
In response to specific misunderstandings, such as the concerns surrounding the assumptions of Lemma 3.1, we offer comprehensive clarifications aimed at improving the comprehension of the proof.
We are grateful for the feedback received on our prior paper and hope this work can foster a more well-informed discussion.",[],[]
"We establish that the charmed hadrons start dissociating at the chiral crossover temperature, Tp⁢csubscript𝑇𝑝𝑐{T_{pc}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT, leading to the appearance of charm degrees freedom carrying fractional baryon number. Our method is based on analyzing the second and fourth-order cumulants of charm (C𝐶{C}italic_C) fluctuations, and their correlations with baryon number (B𝐵{B}italic_B), electric charge (Q𝑄{Q}italic_Q) and strangeness (S𝑆{S}italic_S) fluctuations. The first-time calculation of the Q⁢C𝑄𝐶{QC}italic_Q italic_C correlations on the high statistics datasets of the HotQCD Collaboration enables us to disentangle the contributions from different electrically-charged charm subsectors in the hadronic phase. In particular, we see an enhancement over the PDG expectation in the fractional contribution of the |Q|=2𝑄2{|Q|}=2| italic_Q | = 2 charm subsector to the total charm partial pressure for T<Tp⁢c𝑇subscript𝑇𝑝𝑐{T<T_{pc}}italic_T < italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT; this enhancement is in agreement with the Quark Model extended Hadron Resonance Gas (QM-HRG) model calculations. Furthermore, the agreement of QM-HRG calculations with the projections onto charmed baryonic and mesonic correlations in different charm subsectors indicates the existence of not-yet-discovered charmed hadrons in all charm subsectors below Tp⁢csubscript𝑇𝑝𝑐{T_{pc}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT. We aim at determining the relevant degrees of freedom in temperature range Tp⁢c<T<340⁢ MeVsubscript𝑇𝑝𝑐𝑇340 MeV{T_{pc}<T<340\text{ MeV}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT < italic_T < 340 MeV by assuming the existence of a non-interacting gas of charmed quasi-particles composed of meson, baryon and quark-like excitations above Tp⁢csubscript𝑇𝑝𝑐T_{pc}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT. Our data suggest that the particles with quantum numbers consistent with quarks start appearing at Tp⁢csubscript𝑇𝑝𝑐T_{pc}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT.",[],[]
"Buffer-aided cooperative networks (BACNs) have garnered significant attention due to their potential applications in beyond fifth generation (B5G) or sixth generation (6G) critical scenarios. This article explores various typical application scenarios of buffer-aided relaying in B5G/6G networks to emphasize the importance of incorporating BACN. Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture. To address the challenges, we propose leveraging deep learning-based methods for the design and operation of B5G/6G networks with BACN, deviating from conventional buffer-aided relay selection approaches. In particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (DRL) and decentralized DRL in buffer-aided non-terrestrial networks.
Finally, we outline future research directions in B5G/6G that pertain to the utilization of BACN.",[],[]
,[],[]
"Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pipelines.",[],[]
"This paper studies the convergence of the mirror descent algorithm for finite horizon stochastic control problems with measure-valued control processes.
The control objective involves a convex regularisation function, denoted as hℎhitalic_h, with regularisation strength determined by the weight τ≥0𝜏0\tau\geq 0italic_τ ≥ 0.
The setting covers regularised relaxed control problems.
Under suitable conditions, we establish the relative smoothness and convexity of the control objective with respect to the Bregman divergence of hℎhitalic_h, and prove linear convergence of the algorithm for τ=0𝜏0\tau=0italic_τ = 0 and exponential convergence for τ>0𝜏0\tau>0italic_τ > 0.
The results apply to common regularisers including relative entropy, χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-divergence, and entropic Wasserstein costs.
This validates recent reinforcement learning heuristics that adding regularisation accelerates the convergence of gradient methods.
The proof exploits careful regularity estimates of backward stochastic differential equations in the bounded mean oscillation norm.","['Mirror descent', 'stochastic control', 'convergence rate analysis', 'Bregman divergence', 'Pontryagin’s optimality principle']",[]
"Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. [1]. The experiments we carried out confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes. Noticeably, the JMA attack is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in a complex multilabel classification scenario with 20 labels, a capability that is out of reach of all the attacks proposed so far. As a further advantage, the JMA attack usually requires very few iterations, thus resulting more efficient than existing methods.","['Adversarial', 'Examples', 'Deep', 'Learning', 'Security', 'Adversarial', 'Machine', 'Learning', 'Multi-Label', 'Classification', 'Mahalanobis', 'Distance', 'Non-Negative', 'Least', 'Square', 'Problems']",[]
"Skin lesions are classified in benign or malignant. Among the malignant, melanoma is a very aggressive cancer and the major cause of deaths. So, early diagnosis of skin cancer is very desired. In the last few years, there is a growing interest in computer aided diagnostic (CAD) using most image and clinical data of the lesion. Although we have seen an increasing progress in CAD of skin lesions, these sources of information present limitations due to their inability to provide information of the molecular structure of the lesion. NIR spectroscopy may provide an alternative source of information to automated CAD of skin lesions. The most commonly used techniques and classification algorithms used in spectroscopy are Principal Component Analysis (PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support Vector Machines (SVM). Nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (MDL) to spectroscopy. One of the main limitations to apply MDL to spectroscopy is the lack of public datasets. Since there is no public dataset of NIR spectral data to skin lesions, as far as we know, an effort has been made and a new dataset named NIR-SC-UFES, has been collected, annotated and analyzed generating the gold-standard for classification of NIR spectral data to skin cancer. Next, the machine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional neural network (1D-CNN) and standard algorithms as SVM and PLS-DA were investigated to classify cancer and non-cancer skin lesions. Experimental results indicate the best performance obtained by LightGBM with pre-processing using standard normal variate (SNV), feature extraction and data augmentation with Generative Adversarial Networks (GAN) providing values of 0.839 for balanced accuracy, 0.851 for recall, 0.852 for precision, and 0.850 for F-score. The obtained results indicate the first steps in CAD of skin lesions aiming the automated triage of patients with skin lesions in vivo using NIR spectral data.",[],[]
"The current approach to fetal anomaly screening is based on biometric
measurements derived from individually selected ultrasound images.
In this paper, we introduce a paradigm shift that attains human-level
performance in biometric measurement by aggregating automatically
extracted biometrics from every frame across an entire scan, with
no need for operator intervention. We use a convolutional neural network
to classify each frame of an ultrasound video recording. We then measure
fetal biometrics in every frame where appropriate anatomy is visible.
We use a Bayesian method to estimate the true value of each biometric
from a large number of measurements and probabilistically reject outliers.
We performed a retrospective experiment on 1457 recordings (comprising
48 million frames) of 20-week ultrasound scans, estimated fetal biometrics
in those scans and compared our estimates to the measurements sonographers
took during the scan. Our method achieves human-level performance
in estimating fetal biometrics and estimates well-calibrated credible
intervals in which the true biometric value is expected to lie.","['Ultrasound', 'Fetal imaging', 'Machine learning', 'Bayesian estimation', 'Biometric measurement']",[]
"We present a new procedure to identify observations of known
objects in large data sets of unlinked detections. It begins with
a Keplerian integrals method that allows us to link two tracklets,
computing preliminary orbits, even when the tracklets are
separated in time by a few years. In the second step, we
represent the results in a ‘graph’ where the tracklets are the
nodes and the preliminary orbits are the edges. Then, acceptable
‘3-cycles’ are identified and a least squares orbit is computed
for each of them. Finally, we construct sequences of n≥4𝑛4n\geq 4italic_n ≥ 4
tracklets by searching through the orbits of nearby 3-cycles and
attempting to attribute the remaining tracklets. We calculate the
technique’s efficiency at identifying unknown objects using real
detections that attempt to mimic key parameters of the Minor
Planet Center’s Isolated Tracklet File (ITF) and then apply the
procedure to the ITF to identify tens of thousands of new
objects.

Keywords: Orbit determination, Keplerian
integrals methods, Linkage problem, Asteroid surveys.",[],"['Spain', 'Italy']"
"Recently, two monolayer magnetic materials, i.e., FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT and NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, have been successfully fabricated. Despite that they have the same atomic structure, the two monolayers exhibit distinct magnetic properties. FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT holds an out-of-plane zigzag antiferromagnetic (AFM-ZZ) structure, while NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT exhibits an in-plane AFM-ZZ structure. However, there is no theoretical model which can properly describe its magnetic ground state due to the lack of a full understanding of its magnetic interactions. Here, by combining the first-principles calculations and the newly developed machine learning method, we construct an exact spin Hamiltonian of the two magnetic materials. Different from the previous studies which failed to fully consider the spin-orbit coupling effect, we find that the AFM-ZZ ground state in FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT is stabilized by competing ferromagnetic nearest-neighbor and antiferromagnetic third nearest-neighbor exchange interactions, and combining single-ion anisotropy. Whereas, the often ignored nearest-neighbor biquadratic exchange is responsible for the in-plane AFM-ZZ ground state in NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. We additionally calculate spin-wave spectrum of AFM-ZZ structure in the two monolayers based on the exact spin Hamiltonian, which can be directly verified by the experimental investigation. Our work provides a theoretical framework for the origin of AFM-ZZ ground state in two-dimensional materials.",[],['China']
"With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus. However, challenges such as attacks on model parameters and the lack of incentive mechanisms hinder the effectiveness of federated learning. Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training. Blockchain ensures that model parameters stored in the InterPlanetary File System (IPFS) remain unaltered. A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning. Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training clients. Security analysis and experimental results demonstrate that PPBFL outperforms baseline methods in both model performance and security.","['Federated', 'Learning', 'Blockchain', 'Differential', 'Privacy', 'InterPlanetary', 'File', 'System']",[]
"Rattling phonon modes are known to be origin of various anomalous physical properties such as superconductivity, suppression of thermal conductivity, enhancement of specific heat etc. By means of DFT+U𝑈Uitalic_U calculations we directly show presence of the
rattling mode in the quadruple perovskites CuCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV44{}_{4}start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPTO1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT and CuCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTFe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTRe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT and argue that this can develop in others as well. It is demonstrated that Cu ions at A𝐴Aitalic_A sites vibrate in the center of the icosahedral oxygen O1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT cages and the corresponding potential has a complicated form with many local minima.",[],[]
"A method is presented for estimating and reconstructing the sound field within a room using physics-informed neural networks. By incorporating a limited set of experimental room impulse responses as training data, this approach combines neural network processing capabilities with the underlying physics of sound propagation, as articulated by the wave equation. The network’s ability to estimate particle velocity and intensity, in addition to sound pressure, demonstrates its capacity to represent the flow of acoustic energy and completely characterise the sound field with only a few measurements. Additionally, an investigation into the potential of this network as a tool for improving acoustic simulations is conducted. This is due to its profficiency in offering grid-free sound field mappings with minimal inference time. Furthermore, a study is carried out which encompasses comparative analyses against current approaches for sound field reconstruction. Specifically, the proposed approach is evaluated against both data-driven techniques and elementary wave-based regression methods. The results demonstrate that the physics-informed neural network stands out when reconstructing the early part of the room impulse response, while simultaneously allowing for complete sound field characterisation in the time domain.",[],['Denmark']
,[],[]
"Crowd counting has gained significant popularity due to its practical applications. However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps. Additionally, they also struggle with high-density images.
To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet).
Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals.
This study designs a fusion module, named Fine-Grained Feature Pyramid (FGFP), that is used to fuse feature maps extracted by the backbone of FGENet.
The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual.
At the end, FGENet establishes correspondences between prediction points and ground truth points by employing the Hungarian algorithm.
For training FGENet, we design a robust loss function, named Three-Task Combination (TTC), to mitigate the impact of annotation noise. Extensive experiments are conducted on four widely used crowd counting datasets.
Experimental results demonstrate the effectiveness of FGENet. Notably, our method achieves a remarkable improvement of 3.14 points in Mean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing its superiority over the existing state-of-the-art methods. Even more impressively, FGENet surpasses previous benchmarks on the UCF_CC_50 dataset with an astounding enhancement of 30.16 points in MAE.","['Crowd counting', 'Computer vision', 'Convolutional neural network.']",[]
"Let U𝑈Uitalic_U be a smooth connected complex algebraic variety, and let f:U→ℂ*:𝑓→𝑈superscriptℂf\colon U\to{\mathbb{C}}^{*}italic_f : italic_U → blackboard_C start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT be an algebraic map. To the pair (U,f)𝑈𝑓(U,f)( italic_U , italic_f ) one can associate an infinite cyclic cover Ufsuperscript𝑈𝑓U^{f}italic_U start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT, and (homology) Alexander modules are defined as the homology groups of this cover. In two recent works, the first of which is joint with Geske, Maxim and Wang, we developed two different ways to put a mixed Hodge structure on Alexander modules. Since they are not finite dimensional in general, each approach replaces the Alexander module by a different finite dimensional module: one of them takes the torsion submodule, the other takes finite dimensional quotients, and the constructions are not directly comparable. In this note, we show that both constructions are compatible, in the sense that the map from the torsion to the quotients is a mixed Hodge structure morphism.","['infinite cyclic cover', 'Alexander module', 'mixed', 'Hodge structure', 'thickened complex']",[]
"We investigate the behaviour of two recent methods for the computation
of preliminary orbits. These methods are based on the conservation
laws of Kepler’s problem, and enable the linkage of very short arcs of
optical observations even when they are separated in time by a few
years. Our analysis is performed using both synthetic and real data
of 822 main belt asteroids. The differences between computed and true
orbital elements have been analysed for the true linkages, as well as
the occurrence of alternative solutions. Some metrics have been
introduced to quantify the results, with the aim of discarding as many
of the false linkages as possible and keeping the vast majority of
true ones. These numerical experiments provide thresholds for the
metrics which take advantage of the knowledge of the ground
truth: the values of these thresholds can be used in normal
operation mode, when we do not know the correct values of the orbital
elements and whether the linkages are true or false.",[],['Italy']
"We derive a formula to calculate the local change to the log of any density of states for smooth real observables. Using this in Monte-Carlo simulations, we are able to calculate the expectation value of the observable with a precision often better than standard sampling. The method can be applied to previously generated configurations, as long as the analysis uses the same action used to generate the configurations. We show that for observables such as Wilson line correlators, errors are reduced by up to 4 times.",[],[]
"This paper studies the algebraic structure of a new class of hyperplane arrangement 𝒜𝒜\mathscr{A}script_A obtained by deleting two hyperplanes from a free arrangement.
We provide information on the minimal free resolutions of
the logarithmic derivation module of 𝒜𝒜\mathscr{A}script_A,
which can be used to compute a lower bound for the graded Betti numbers of the resolution.
Specifically, for the three-dimensional case,
we determine
the minimal free resolution of
the logarithmic derivation module of 𝒜𝒜\mathscr{A}script_A.
We present illustrative examples of our main theorems to provide insights into the relationship between algebraic and combinatorial properties for close-to-free arrangements.",[],[]
"We consider the following convective Neumann systems:



(S){−Δp1⁢u1+|∇u1|p1u1+δ1=f1⁢(x,u1,u2,∇u1,∇u2)in⁢Ω,−Δp2⁢u2+|∇u2|p2u2+δ2=f2⁢(x,u1,u2,∇u1,∇u2)in⁢Ω,|∇u1|p1−2⁢∂u1∂η=0=|∇u2|p2−2⁢∂u2∂ηon⁢∂Ω,ScasessubscriptΔsubscript𝑝1subscript𝑢1superscript∇subscript𝑢1subscript𝑝1subscript𝑢1subscript𝛿1subscript𝑓1𝑥subscript𝑢1subscript𝑢2∇subscript𝑢1∇subscript𝑢2inΩsubscriptΔsubscript𝑝2subscript𝑢2superscript∇subscript𝑢2subscript𝑝2subscript𝑢2subscript𝛿2subscript𝑓2𝑥subscript𝑢1subscript𝑢2∇subscript𝑢1∇subscript𝑢2inΩsuperscript∇subscript𝑢1subscript𝑝12subscript𝑢1𝜂0superscript∇subscript𝑢2subscript𝑝22subscript𝑢2𝜂onΩ\left(\mathrm{S}\right)\qquad\left\{\begin{array}[]{ll}-\Delta_{p_{1}}u_{1}+%
\frac{|\nabla u_{1}|^{p_{1}}}{u_{1}+\delta_{1}}=f_{1}(x,u_{1},u_{2},\nabla u_{%
1},\nabla u_{2})&\text{in}\;\Omega,\\
-\Delta_{p_{2}}u_{2}+\frac{|\nabla u_{2}|^{p_{2}}}{u_{2}+\delta_{2}}=f_{2}(x,u%
_{1},u_{2},\nabla u_{1},\nabla u_{2})&\text{in}\;\Omega,\\
|\nabla u_{1}|^{p_{1}-2}\frac{\partial u_{1}}{\partial\eta}=0=|\nabla u_{2}|^{%
p_{2}-2}\frac{\partial u_{2}}{\partial\eta}&\text{on}\;\partial\Omega,\end{%
array}\right.( roman_S ) { start_ARRAY start_ROW start_CELL - roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + divide start_ARG | ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_ARG start_ARG italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG = italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x , italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_CELL start_CELL in roman_Ω , end_CELL end_ROW start_ROW start_CELL - roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + divide start_ARG | ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_ARG start_ARG italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG = italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x , italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_CELL start_CELL in roman_Ω , end_CELL end_ROW start_ROW start_CELL | ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT divide start_ARG ∂ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG ∂ italic_η end_ARG = 0 = | ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT divide start_ARG ∂ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG ∂ italic_η end_ARG end_CELL start_CELL on ∂ roman_Ω , end_CELL end_ROW end_ARRAY



where ΩΩ\Omegaroman_Ω is a bounded domain in ℝNsuperscriptℝ𝑁\mathbb{R}^{N}blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT (N≥2𝑁2N\geq 2italic_N ≥ 2) with a
smooth boundary ∂ΩΩ\partial\Omega∂ roman_Ω, δ1,δ2>0subscript𝛿1subscript𝛿20\delta_{1},\,\delta_{2}>0italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0 are small parameters, η𝜂\etaitalic_η
is the outward unit vector normal to ∂Ω,Ω\partial\Omega,∂ roman_Ω ,
f1,f2:Ω×ℝ2×ℝ2⁢N→ℝ:subscript𝑓1subscript𝑓2→Ωsuperscriptℝ2superscriptℝ2𝑁ℝf_{1},\,f_{2}:\Omega\times\mathbb{R}^{2}\times\mathbb{R}^{2N}\rightarrow%
\mathbb{R}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : roman_Ω × blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT 2 italic_N end_POSTSUPERSCRIPT → blackboard_R are
Carathéodory
functions that satisfy certain growth conditions,
and
ΔpisubscriptΔsubscript𝑝𝑖\Delta_{p_{i}}roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT (1<pi<N,1subscript𝑝𝑖𝑁1<p_{i}<N,1 < italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_N , for i=1,2𝑖12i=1,2italic_i = 1 , 2)
are the p𝑝pitalic_p-Laplace operators
Δpi⁢ui=div⁢(|∇ui|pi−2⁢∇ui)subscriptΔsubscript𝑝𝑖subscript𝑢𝑖divsuperscript∇subscript𝑢𝑖subscript𝑝𝑖2∇subscript𝑢𝑖\Delta_{p_{i}}u_{i}=\mathrm{div}(|\nabla u_{i}|^{p_{i}-2}\nabla u_{i})roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_div ( | ∇ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT ∇ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), for every⁢ui∈W1,pi⁢(Ω).for everysubscript𝑢𝑖superscript𝑊1subscript𝑝𝑖Ω\hbox{for every}\,u_{i}\in W^{1,p_{i}}(\Omega).for every italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_W start_POSTSUPERSCRIPT 1 , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) .
In order to prove the existence of solutions to such systems, we use a sub-supersolution method. We also obtain nodal solutions
by constructing appropriate sub-solution and super-solution pairs. To the best of our knowledge, such systems have not been studied yet.
Keywords and phrases:
Neumann elliptic system; gradient dependence; sub-solution and super-solution method; nodal solution.
Math. Subj. Classif. (2020):  35J62, 35J92.",[],[]
"Traditional manual detection for solder joint defect is no longer applied during industrial production due to low efficiency, inconsistent evaluation, high cost and lack of real-time data. A new approach has been proposed to address the issues of low accuracy, high false detection rates and computational cost of solder joint defect detection in surface mount technology of industrial scenarios. The proposed solution is a hybrid attention mechanism designed specifically for the solder joint defect detection algorithm to improve quality control in the manufacturing process by increasing the accuracy while reducing the computational cost. The hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features. The coordinate attention mechanism enhances the connection between different channels and reduces location information loss. The hybrid attention mechanism enhances the capability of the network to perceive long-distance position information and learn local features. The improved algorithm model has good detection ability for solder joint defect detection, with mAP reaching 91.5%, 4.3% higher than the You Only Look Once version 5 algorithm and better than other comparative algorithms. Compared to other versions, mean Average Precision, Precision, Recall, and Frame per Seconds indicators have also improved. The improvement of detection accuracy can be achieved while meeting real-time detection requirements.","['Solder joint defect', 'feature fusion', 'self-attention mechanism', 'feature pyramid network']",[]
In this paper we analyze a space-time unfitted finite element method for the discretization of scalar surface partial differential equations on evolving surfaces. For higher order approximations of the evolving surface we use the technique of (iso)parametric mappings for which a level set representation of the evolving surface is essential. We derive basic results in which certain geometric characteristics of the exact space-time surface are related to corresponding ones of the numerical surface approximation. These results are used in a complete error analysis of a higher order space-time TraceFEM.,[],[]
"Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method. While attracting lots of attention, NeRF faces critical issues such as information confidentiality and security. Steganography is a technique used to embed information in another object as a means of protecting information security. Currently, there are few related studies on NeRF steganography, facing challenges in low steganography quality, model weight damage, and a limited amount of steganographic information. This paper proposes a novel NeRF steganography method based on trainable noise: Noise-NeRF. Furthermore, we propose the Adaptive Pixel Selection strategy and Pixel Perturbation strategy to improve the steganography quality and efficiency. The extensive experiments on open-source datasets show that Noise-NeRF provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography.","['neural radiation fields', 'steganography', 'implicit neural representation']",[]
"As more IoT applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge. However, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management.
To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework. The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading. Considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay.
A cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration. Based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration.
Through a customized IoT application workflow instance, experimental results show that KCES is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks.","['Workflow scheduling', 'cloud-edge collaboration', 'resource collaboration', 'application collaboration', 'horizontal roaming', 'vertical offloading.']",[]
"Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models.
However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance.
Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input.
Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality.
In this work, we propose a  zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs.
\AcZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets.
To improve the quality of unsupervised responses, we propose a  master-slave alignment (MSA) module to prune these responses.
Experiments on eight datasets and five tasks show that ZOE consistently outperforms existing methods in mitigating four types of position biases.
Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective.",[],[]
"Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer.
To provide sufficient learning support, modern MTL uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks.
However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks.
In this work, we challenge this setup and show that MTL can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task.
We explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching.
To demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets.
Our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases.
In all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when MT model’s performance is worse than that of at least one single-task model).",[],[]
"Context:Interstellar dust particles, in particular carbonaceous nano-grains (like polycyclic aromatic hydrocarbons, fullerenes, and amorphous hydrogenated carbon), are critical players for the composition, energy budget, and dynamics of the interstellar medium (ISM). The dust properties, specifically the composition and size of dust grains are not static; instead, they exhibit considerable evolution triggered by variations in local physical conditions such as the density and gas temperature within the ISM, as is the case in photon-dominated regions (PDRs). The evolution of dust and its impact on the local physical and chemical conditions is thus a key question for understanding the first stages of star formation.
Aims:From the extensive spectral and imaging data of the JWST PDRs4All program, we study the emission of dust grains within the Orion Bar — a well-known, highly far-UV (FUV)-irradiated PDR situated at the intersection between cold, dense molecular clouds, and warm ionized regions. The Orion Bar because of its edge-on geometry provides an exceptional benchmark for characterizing dust evolution and the associated driving processes under varying physical conditions. Our goal is to constrain the local properties of dust by comparing its emission to models. Taking advantage of the recent JWST data, in particular the spectroscopy of dust emission, we identify new constraints on dust and further previous works of dust modelling.
Methods:To characterize interstellar dust across the Orion Bar, we follow its emission as traced by JWST NIRCam (at 3.35 and 4.8 μ𝜇\muitalic_μm) and MIRI (at 7.7, 11.3, 15.0, and 25.5 μ𝜇\muitalic_μm) broad band images, along with NIRSpec and MRS spectroscopic observations. First, we constrain the minimum size and hydrogen content of carbon nano-grains from a comparison between the observed dust emission spectra and the predictions of the Heterogeneous dust Evolution Model for Interstellar Solids (THEMIS) coupled to the numerical code DustEM.
Using this dust model, we then perform 3D radiative transfer simulations of dust emission with the SOC code (Scattering with OpenCL) and compare to data obtained along well chosen profiles across the Orion Bar.
Results:The JWST data allows us, for the first time, to spatially resolve the steep variation of dust emission at the illuminated edge of the Orion Bar PDR. By considering a dust model with carbonaceous nano-grains and submicronic coated silicate grains, we derive unprecedented constraints on the properties of across the Orion Bar. To explain the observed emission profiles with our simulations, we find that the nano-grains must be strongly depleted with an abundance (relative to the gas) 15 times less than in the diffuse ISM. The NIRSpec and MRS spectroscopic observations reveal variations in the hydrogenation of the carbon nano-grains. The lowest hydrogenation levels are found in the vicinity of the illuminating stars suggesting photo-processing while more hydrogenated nano-grains are found in the cold and dense molecular region, potentially indicative of larger grains.
Conclusions:","[' infrared:', 'ISM / dust', 'extinction / photon-dominated region (PDR) /', 'ISM: individual objects:', 'Orion', 'Bar / radiative transfer']",[]
"By systematic theoretical calculations, we have revealed an excitonic insulator (EI) in a van der Waals layered compound Ta2⁢Pd3⁢Te5subscriptTa2subscriptPd3subscriptTe5\rm{Ta_{2}Pd_{3}Te_{5}}roman_Ta start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_Pd start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT roman_Te start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT. First-principles calculations show that the monolayer is a nearly zero-gap semiconductor. Due to the like symmetry of the band-edge states, the 2D polarization α2⁢Dsubscript𝛼2𝐷\alpha_{2D}italic_α start_POSTSUBSCRIPT 2 italic_D end_POSTSUBSCRIPT would be finite as the band gap goes to zero, allowing for the EI state in the compound. Using the first-principles many-body perturbation theory, the G⁢W𝐺𝑊GWitalic_G italic_W-BSE calculation shows that the exciton binding energy Ebsubscript𝐸𝑏E_{b}italic_E start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT is larger than the single-particle band gap Egsubscript𝐸𝑔E_{g}italic_E start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT, indicating the excitonic instability.
Additionally, no structure instability is found in the phonon spectrum of this material.",[],['China']
,[],[]
"Recently, intelligent reflecting surface (IRS)-aided millimeter-wave (mmWave) and terahertz (THz) communications are considered in the wireless community. This paper aims to design a beam-based multiple-access strategy for this new paradigm. Its key idea is to make use of multiple sub-arrays over a hybrid digital-analog array to form independent beams, each of which is steered towards the desired direction to mitigate inter-user interference and suppress unwanted signal reflection. The proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use). Consequently, it can substantially boost the system capacity, as verified by Monte-Carlo simulations.",[],['Germany']
"The Riviera model is a combinatorial model for a settlement along a coastline, introduced recently by the authors. Of most interest are the so-called jammed states, where no more houses can be built without violating the condition that every house needs to have free space to at least one of its sides. In this paper, we introduce new agents (predators and altruists) that want to build houses once the settlement is already in the jammed state. Their behavior is governed by a different set of rules, and this allows them to build new houses even though the settlement is jammed. Our main focus is to detect jammed configurations that are resistant to predators, to altruists, and to both predators and altruists. We provide bivariate generating functions, and complexity functions (configurational entropies) for such jammed configurations. We also discuss this problem in the two-dimensional setting of a combinatorial settlement planning model that was also recently introduced by the authors, and of which the Riviera model is just a special case.","['generating functions', 'complexity function', 'configurational entropy', 'jammed configuration', 'maximal packing', 'settlement model', 'equilibrium lattice systems']",[]
"Accretion-powered X-ray pulsars offer a unique opportunity to study physics under extreme conditions. To fully exploit this potential, the interrelated problems of modelling radiative transport and the dynamical structure of the accretion flow must, however, be solved. This task is challenging both from a theoretical and observational point of view and is further complicated by a lack of direct correspondence between the properties of emission emerging from the neutron star and observed far away from it. In general, a mixture of emission from both poles of the neutron star viewed from different angles is indeed observed at some or even all phases of the pulse cycle. It is essential, therefore, to reconstruct the contributions of each pole to the observed flux in order to test and refine models describing the formation of the spectra and pulse profiles of X-ray pulsars. In this paper we propose a novel data-driven approach to address this problem using the pulse-to-pulse variability in the observed flux, and demonstrate its application to RXTE observations of the bright persistent X-ray pulsar Cen~X$-$3. We then discuss the comparison of our results with previous work attempting to solve the same problem and how they can be qualitatively interpreted in the framework of a toy model describing emission from the poles of a neutron star.","['Methods: data analysis –', 'X-rays: binaries –\npulsars: individual:', 'Cen~X$-$3–', 'Stars: neutron']",[]
,[],[]
"Homodyne measurement is a crucial tool widely used to address continuous variables for bosonic quantum systems. While an ideal homodyne detection provides a powerful analysis, e.g. to effectively measure quadrature amplitudes of light in quantum optics, it relies on the use of a strong reference field, the so-called local oscillator typically in a coherent state. Such a strong coherent local oscillator may not be readily available particularly for a massive quantum system like Bose-Einstein condensate (BEC), posing a substantial challenge in dealing with continuous variables appropriately. It is necessary to establish a practical framework that includes the effects of non-ideal local oscillators for a rigorous assessment of various quantum tests and applications. We here develop entanglement criteria beyond Gaussian regime applicable for this realistic homodyne measurement that do not require assumptions on the state of local oscillators. We discuss the working conditions of homodyne detection to effectively detect non-Gaussian quantum entanglement under various states of local oscillators.",[],['Qatar']
"The time resolution of the second monolithic silicon pixel prototype produced for the MONOLITH H2020 ERC Advanced project was studied using a femtosecond laser.
The ASIC contains a matrix of hexagonal pixels with 100 μ𝜇\muitalic_μm pitch, readout by low-noise and very fast SiGe HBT frontend electronics.
Silicon wafers with 50 μ𝜇\muitalic_μm thick epilayer with a resistivity of 350 ΩΩ\Omegaroman_Ωcm were used to produce a fully depleted sensor.
At the highest frontend power density tested of 2.7 W/cm22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT, the time resolution with the femtosecond laser pulses was found to be 45 ps for signals generated by 1200 electrons, and 3 ps in the case of 11k electrons, which corresponds approximately to 0.4 and 3.5 times the most probable value of the charge generated by a minimum-ionizing particle.
The results were compared with testbeam data taken with the same prototype to evaluate the time jitter produced by the fluctuations of the charge collection.",[],[]
"The NASA New Horizons Venetia Burney Student Dust Counter (SDC) measures dust particle impacts along the spacecraft’s flight path for grains with mass ≥\geq≥ 10−12superscript101210^{-12}10 start_POSTSUPERSCRIPT - 12 end_POSTSUPERSCRIPT g, mapping out their spatial density distribution. We present the latest SDC dust density, size distribution, and flux measurements through 55 au and compare them to numerical model predictions. Kuiper Belt Objects (KBOs) are thought to be the dominant source of interplanetary dust particles (IDP) in the outer solar system due to both collisions between KBOs, and their continual bombardment by interstellar dust particles (ISD).
Continued measurements through 55 au show higher than model-predicted dust fluxes as New Horizons approaches the putative outer edge of the Kuiper Belt (KB). We discuss potential explanations for the growing deviation: radiation pressure stretches the dust distribution to further heliocentric distances than its parent body distribution; icy dust grains undergo photo-sputtering that rapidly increases their response to radiation pressure forces and pushes them further away from the sun; and the distribution of KBOs may extend much further than existing observations suggest. Ongoing SDC measurements at even larger heliocentric distances will continue to constrain the contributions of dust production in the KB. Continued SDC measurements remain crucial for understanding the Kuiper Belt and the interpretation of observations of dust disks around other stars.","['Kuiper', 'Belt', 'Interplanetary', 'Dust', 'PVDF', 'New', 'Horizons']",[]
"We develop a Bayesian modeling framework to address a pressing real-life problem faced by the police in tackling insurgent gangs. Unlike criminals associated with common crimes such as robbery, theft or street crime, insurgent gangs are trained in sophisticated arms and strategise against the government to weaken its resolve. They are constantly on the move, operating over large areas causing damage to national properties and terrorizing ordinary citizens. Different from the more commonly addressed problem of modeling crime-events, our context requires that an approach be formulated to model the movement of insurgent gangs, which is more valuable to the police forces in preempting their activities and nabbing them. This paper evolved as a collaborative work with the Indian police to help augment their tactics with a systematic method, by integrating past data on observed gang-locations with the expert knowledge of the police officers. A methodological challenge in modeling the movement of insurgent gangs is that the data on their locations is incomplete, since they are observable only at some irregularly separated time-points. Based on a weighted kernel density formulation for temporal data, we analytically derive the closed form of the likelihood, conditional on incomplete past observed data. Building on the current tactics used by the police, we device an approach for constructing an expert-prior on gang-locations, along with a sequential Bayesian procedure for estimation and prediction. We also propose a new metric for predictive assessment that complements another known metric used in similar problems.",[],[]
"Graphs are typical non-Euclidean data of complex structures.
In recent years, Riemannian graph representation learning has
emerged as an exciting alternative to Euclidean ones.
However, Riemannian methods are still in an early stage:
most of them
present a single curvature (radius) regardless of structural complexity,
suffer from numerical instability due to the exponential/logarithmic map,
and lack the ability to capture motif regularity.
In light of the issues above, we propose the problem of Motif-aware Riemannian Graph Representation Learning,
seeking a numerically stable encoder to capture motif regularity in a diverse-curvature manifold without labels.
To this end, we present a novel Motif-aware Riemannian model with Generative-Contrastive learning (MotifRGC),
which conducts a minmax game in Riemannian manifold in a self-supervised manner.
First, we propose a new type of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold by a product layer with the diversified factor,
and replace the exponential/logarithmic map by a stable kernel layer.
Second,
we introduce a motif-aware Riemannian generative-contrastive learning
to capture motif regularity in the constructed manifold and learn motif-aware node representation without external labels.
Empirical results show the superiority of MofitRGC.",[],[]
"Graph Neural Networks (GNNs) are widely applied across various domains, yet they perform poorly in deep layers. Existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation. In this paper, we delve into the neighborhood propagation mechanism of GNNs and discover that the real root cause of GNNs’ performance degradation in deep layers lies in ineffective neighborhood feature propagation. This propagation leads to an exponential growth of a node’s current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes. To address this issue, we introduce Graph Elimination Networks (GENs), which employ a specific algorithm to eliminate redundancies during neighborhood propagation. We demonstrate that GENs can enhance nodes’ perception of distant neighborhoods and extend the depth of network propagation. Extensive experiments show that GENs outperform the state-of-the-art methods on various graph-level and node-level datasets.","['Graph', 'Neural', 'Network', 'Deep', 'Graph', 'Neural', 'Network', 'Graph', 'Self-Attention', 'Subgraph', 'Self-Attention', 'Algorithm', 'Framework']",['China']
"Survival analysis can sometimes involve individuals who will not experience the event of interest, forming what is known as the “cured group”. Identifying such individuals is not always possible beforehand, as they provide only right-censored data. Ignoring the presence of the cured group can introduce bias in the final model. This paper presents a method for estimating a semiparametric additive hazards model that accounts for the cured fraction. Unlike regression coefficients in a hazard ratio model, those in an additive hazard model measure hazard differences. The proposed method uses a primal-dual interior point algorithm to obtain constrained maximum penalized likelihood estimates of the model parameters, including the regression coefficients and the baseline hazard, subject to certain non-negativity constraints.


Keywords: Additive hazards model; Mixture cure model; Interval censoring; Maximum penalized likelihood estimation;
Automatic smoothing.",[],"['Australia', 'China']"
"The notions of predictability and visibility are essential in the mathematical formulation of wave particle duality. The work of Jakob and Bergou [Phys. Rev. A 76, 052107] generalises these notions for higher-dimensional quantum systems, which were initially defined for qubits, and subsequently proves a complementarity relation between predictability and visibility. By defining the single-party information content of a quantum system as the addition of predictability and visibility, and assuming that entanglement in a bipartite system in the form of concurrence mutually excludes the single-party information, the authors have proposed a complementarity relation between the concurrence and the single-party information content. We show that the information content of a quantum system defined by Jakob and Bergou is nothing but the Hilbert-Schmidt distance between the state of the quantum system of our consideration and the maximally mixed state. Motivated by the fact that the trace distance is a good measure of distance as compared to the Hilbert-Schmidt distance from the information theoretic point of view, we, in this work, define the information content of a quantum system as the trace distance between the quantum state and the maximally mixed state. We then employ the quantum Pinsker’s inequality and the reverse Pinsker’s inequality to derive a new complementarity and a reverse complementarity relation between the single-party information content and the entanglement present in a bipartite quantum system in a pure state. As a consequence of our findings, we show that for a bipartite system in a pure state, its entanglement and the predictabilities and visibilities associated with the subsystems cannot be arbitrarily small as well as arbitrarily large.",[],['India']
"Measurement incompatibility has proved to be an important resource for information processing tasks. In this work, we analyze various levels of incompatibility of measurement sets. We provide operational classification of measurement incompatibility with respect to two elementary classical operations, viz., coarse-graining of measurement outcomes and convex mixing of different measurements. We derive analytical criteria for determining when a set of projective measurements is fully incompatible with respect to coarse-graining or convex mixing. Robustness against white noise is investigated for mutually unbiased bases that can sustain full incompatibility. Furthermore, we propose operational witnesses for different levels of incompatibility subject to classical operations, using the input-output statistics of Bell-type experiments as well as experiments in the prepare-and-measure scenario.",[],['India']
,[],[]
"The size of the smallest k𝑘kitalic_k-regular graph of girth g𝑔gitalic_g is denoted by the well studied function n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ).
We suggest generalizing this function to n⁢(H,g)𝑛𝐻𝑔n(H,g)italic_n ( italic_H , italic_g ), defined as the smallest size girth g𝑔gitalic_g graph covering the, possibly non-regular, graph H𝐻Hitalic_H.
We prove that the two main combinatorial bounds on n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ), the Moore lower bound and the Erdös Sachs upper bound,
carry over to the new setting of lifts, even in their non-asymptotic form.
We also consider two other generalizations of n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ):
i) The smallest size girth g𝑔gitalic_g graph sharing a universal cover with H𝐻Hitalic_H. We prove that it is the same as n⁢(H,g)𝑛𝐻𝑔n(H,g)italic_n ( italic_H , italic_g ) up to a multiplicative constant.
ii) The smallest size girth g𝑔gitalic_g graph with a prescribed degree distribution. We discuss this known generalization and argue that the new suggested definitions are superior.

We conclude with experimental results for a specific base graph and with some conjectures and open problems.",[],[]
"As written by statistician George Box ”All models are wrong, but some are useful”, standard diffusion derivation or Feynman path ensembles use nonphysical nowhere differentiable trajectories of infinite kinetic energy - what seems wrong, bringing question of differences if doing it more right this article is focused on. To consider ensembles of more physical trajectories, we can work in (x,v)𝑥𝑣(x,v)( italic_x , italic_v ) phase space like in Langevin equation with velocity controlling spatial steps, here also controlled with spatial potential V⁢(x)𝑉𝑥V(x)italic_V ( italic_x ). There will be discussed and compared 4 approaches to predict stationary probability distributions: using Boltzmann ensemble of points in space (GRW - generic random walk) or in phase space (psGRW), and analogously Boltzmann ensemble of paths in space (MERW - maximal entropy random walk) and in phase space (psMERW). They have qualitatively different predictions, hopefully allowing to decide the most appropriate for various settings by distinguishing them experimentally. Path ensembles have much stronger Anderson-like localization exactly as in quantum ground state, proposed novel in phase space has additionally increased density of velocity as in potential gradient, decreased toward barrier. While MERW is thermodynamically in agreement with quantum mechanics, psMERW suggests slight corrections from consideration of more physical trajectories, which seem natural - reduced velocities toward close barriers, increased down potential gradients.",[],[]
"Accurate determination of mass-loss rates from massive stars is important to understanding stellar and galactic
evolution and enrichment of the interstellar medium. Large-scale structure and variability in stellar winds have significant effects on mass-loss rates. Time-series observations provide direct quantification of such variability. Observations of this nature are available for some Galactic early supergiant stars but not yet for stars in lower metallicity environments such as the Magellanic Clouds. We utilise ultraviolet spectra from the Hubble Space Telescope ULLYSES program to demonstrate that the presence of structure in stellar winds of supergiant stars at low metallicities may be discerned from single-epoch spectra. We find evidence that, for given stellar luminosities and mean stellar wind optical depths, structure is more prevalent at higher metallicities. We confirm, at Large Magellanic Cloud (0.5 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT), Small Magellanic Cloud (0.2 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) and lower (0.14 – 0.1 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) metallicities, earlier Galactic results that there does not appear to be correlation between the degree of structure in stellar winds of massive stars and stellar effective temperature. Similar lack of correlation is found with regard to terminal velocity of stellar winds. Additional and revised values for radial velocities of stars and terminal velocities of stellar winds are presented. Direct evidence of temporal variability, on timescales of several days, in stellar wind at low metallicity is found. We illustrate that narrow absorption components in wind-formed profiles of Galactic OB stellar spectra remain common in early B supergiant spectra at low metallicities, providing means for better constraining hot, massive star mass-loss rates.",[],[]
"We prove that the pushforwards of a very general class of fractal measures μ𝜇\muitalic_μ on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT under a large family of non-linear maps F:ℝd→ℝ:𝐹→superscriptℝ𝑑ℝF\colon\mathbb{R}^{d}\to\mathbb{R}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R exhibit polynomial Fourier decay: there exist C,η>0𝐶𝜂0C,\eta>0italic_C , italic_η > 0 such that |F⁢μ^⁢(ξ)|≤C⁢|ξ|−η^𝐹𝜇𝜉𝐶superscript𝜉𝜂|\widehat{F\mu}(\xi)|\leq C|\xi|^{-\eta}| over^ start_ARG italic_F italic_μ end_ARG ( italic_ξ ) | ≤ italic_C | italic_ξ | start_POSTSUPERSCRIPT - italic_η end_POSTSUPERSCRIPT for all ξ≠0𝜉0\xi\neq 0italic_ξ ≠ 0.
Using this, we prove that if Φ={φa:[0,1]→[0,1]}a∈𝒜Φsubscriptconditional-setsubscript𝜑𝑎→0101𝑎𝒜\Phi=\{\varphi_{a}\colon[0,1]\to[0,1]\}_{a\in\mathcal{A}}roman_Φ = { italic_φ start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT : [ 0 , 1 ] → [ 0 , 1 ] } start_POSTSUBSCRIPT italic_a ∈ caligraphic_A end_POSTSUBSCRIPT is an iterated function system consisting of analytic contractions, and there exists a∈𝒜𝑎𝒜a\in\mathcal{A}italic_a ∈ caligraphic_A such that φasubscript𝜑𝑎\varphi_{a}italic_φ start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT is not an affine map, then every non-atomic self-conformal measure for ΦΦ\Phiroman_Φ has polynomial Fourier decay; this result was obtained simultaneously by Algom, Rodriguez Hertz, and Wang.
We prove applications related to the Fourier uniqueness problem, Fractal Uncertainty Principles, and normal numbers in fractal sets.",[],[]
"Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees. A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers). In this study we propose a contrastive approach for learning a binary event encoder from continuous time series data. As a preliminary result, we show that our approach has some potential in learning a valuable encoder.",[],['Denmark']
"The sequential interaction network usually find itself in a variety of applications, e.g., recommender system. Herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature Euclidean space.
Despite the promising results achieved by previous methods, a range of significant issues still largely remains open:
On the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference?
On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously?
On the learning paradigm, can we get rid of the label information costly to acquire?
To address the aforementioned issues, we propose a novel Contrastive model for Sequential Interaction Network learning on Co-Evolving RiEmannian spaces, CSincere.
To the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network.
In CSincere, we formulate a Cross-Space Aggregation for message-passing across representation spaces of different Riemannian geometries,
and design a Neural Curvature Estimator based on Ricci curvatures for modeling the space evolvement over time.
Thereafter, we present a Reweighed Co-Contrast between the temporal views of the sequential network,
so that the couple of Riemannian spaces interact with each other for the interaction prediction without labels.
Empirical results on 5 public datasets show the superiority of CSincere over the state-of-the-art methods.",[],[]
"RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving. Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results. However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training. The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information. To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack. TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively. TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization. In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales. Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.",[],[]
"Solving the holography equation has long been a numerical task. While effective, the numeric approach has its own set of limitations. Relying solely on numerical approaches often obscures the intricate interplay and influence of the individual terms within the equation. This not only hampers a deeper understanding of the underlying physics but also makes it challenging to predict or control specific outcomes.
In this study, we address these challenges by leveraging our recently published Glückstad and Madsen (2023) updated Fraunhofer diffraction expression. This approach allows us to derive an analytic solution for complex-valued phase disks in on-axis holography. This solution facilitates the direct computation of each term’s influence within the holographic equation, paving the way for a more profound comprehension and application of the holographic process. When compared to experimental results and the numeric Fresnel diffraction solution, our analytic approach shows impressive accuracy, considering the inherent approximations. Notably, it remains precise for Fresnel numbers that extend well beyond the traditionally accepted boundaries of the Fraunhofer regime.",[],[]
"This work provides an error analysis of quantum Krylov algorithms based on real-time evolutions, subject to generic errors in the outputs of the quantum circuits.
We establish a collective noise rate to summarize those errors, and prove that the resulting errors in the ground state energy estimates are leading-order linear in that noise rate.
This resolves a misalignment between known numerics, which exhibit this linear scaling, and prior theoretical analysis, which only provably obtained square-root scaling.
Our main technique is expressing generic errors in terms of an effective target Hamiltonian studied in an effective Krylov space.
These results provide a theoretical framework for understanding the main features of quantum Krylov errors.",[],[]
"The early identification of diseases in cocoa pods is an important task to guarantee the production of high-quality cocoa. The use of artificial intelligence techniques such as machine learning, computer vision and deep learning are promising solutions to help identify and classify diseases in cocoa pods. In this paper we introduce the development and evaluation of a deep learning computational model applied to the identification of diseases in cocoa pods, focusing on “monilia” and “black pod” diseases. An exhaustive review of state-of-the-art of computational models was carried out, based on scientific articles related to the identification of plant diseases using computer vision and deep learning techniques. As a result of the search, EfficientDet-Lite4, an efficient and lightweight model for object detection, was selected. A dataset, including images of both healthy and diseased cocoa pods, has been utilized to train the model to detect and pinpoint disease manifestations with considerable accuracy. Significant enhancements in the model training and evaluation demonstrate the capability of recognizing and classifying diseases through image analysis. Furthermore, the functionalities of the model were integrated into an Android native mobile with an user-friendly interface, allowing to younger or inexperienced farmers a fast and accuracy identification of health status of cocoa pods.",[],[]
"Building upon previous works of Proudfoot and Ramos, and using the categorical framework of Sam and Snowden, we extend the weak categorical minor theorem from undirected graphs to quivers. As case of study, we investigate the consequences on the homology of multipath complexes;
eg. on its torsion. Further, we prove a comparison result: we show that, when restricted to directed graphs without oriented cycles, multipath complexes and matching complexes yield functors which commute up to a blow-up operation on directed graphs. We use this fact to compute the homotopy type of matching complexes for a certain class of bipartite graphs also known as half-graphs or ladders. We complement the work with a study of the (representation) category of cones, and with analysing related consequences on magnitude cohomology of quivers.",[],[]
"Femtoscopy is a unique tool to investigate the space-time geometry of the matter created in ultra-relativistic collisions. If the probability density distribution of hadron emission is parametrized, then the dependence of its parameters on particle momentum, collision energy, and collision geometry can be given. In recent years, several measurements came to light that indicated the adequacy of assuming a Lévy-stable shape for the mentioned distribution. In parallel, several new phenomenological developments appeared, aiding the interpretation of the experimental results, or providing tools for the measurements. In this paper we review and discuss some of these advances, phenomenological and experimental.",[],[]
"Recently, anomalous Floquet topological phases without static counterparts have been observed in different systems, where periodically driven models are realized to support a winding number of 1 and a pair of edge modes in each quasienergy gap. Here, we focus on cold atomic gases in optical lattices and propose a novel driving scheme that breaks rotation symmetry but maintains inversion symmetry of the instantaneous Hamiltonian, and discover a novel type of anomalous Floquet topological phase with winding number larger than 1. By analyzing the condition of band touching under symmetry constraint, we map out the phase diagram exactly by varying the driving parameters and discuss the quasienergy spectra of typical topological phases, which can present multiple pairs of edge modes within a single gap. Finally, we suggest to characterize the topology of such phases by detecting the band inversion surfaces via quench dynamics.",[],['China']
"Density functional theory calculations are used to systematically investigate the structural and electronic properties of MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT transition metal dichalcogenide monolayers with M = Cr, Mo, W and X = S, Se, Te that are doped with single (V, Nb, Ta) and double (Ti, Zr, Hf) acceptor dopants on the M site with local D3⁢hsubscript𝐷3ℎD_{3h}italic_D start_POSTSUBSCRIPT 3 italic_h end_POSTSUBSCRIPT symmetry in the dilute limit. Three impurity levels that arise from intervalley scattering are found above the valence band maxima (VBM): an orbitally doubly degenerate e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT level bound to the K/K′𝐾superscript𝐾′K/K^{\prime}italic_K / italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT VBM and a singly degenerate a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level bound to the ΓΓ\Gammaroman_Γ-point VBM.
Replacing S with Se or Te lowers the ΓΓ\Gammaroman_Γ point VBM substantially with respect to the K/K′𝐾superscript𝐾′K/K^{\prime}italic_K / italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT VBM bringing the a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level down with it. The relative positions of the impurity levels that determine the different structural and electronic properties of the impurities in p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers can thus be tuned by replacing S with Se or Te.

Single acceptors introduce a magnetic moment of 1μBsubscript𝜇B\,\mu_{\rm B}italic_μ start_POSTSUBSCRIPT roman_B end_POSTSUBSCRIPT in all MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Out-of-plane magnetic anisotropy energies as large as 10 meV/dopant atom are found thereby satisfying an essential condition for long-range ferromagnetic ordering in two dimensions.
For double acceptors in MS22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers, both holes occupy the high-lying a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level with opposite spins so there is no magnetic moment;
in MSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers the holes occupy the e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT level, a Jahn-Teller (JT) distortion wins the competition with exchange splitting resulting in the quenching of the magnetic moments. Even when the JT distortion is disallowed, magnetic double acceptors have a large in-plane magnetic anisotropy energy that is incompatible with long-range magnetic ordering in two dimensions.
The magnetic moments of pairs of single acceptors exhibit long-range ferromagnetic coupling except for MS22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT where the coupling is quenched for impurity pairs below a critical separation. For Se and Te compounds, the holes are accommodated in high-lying degenerate e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT levels which form triplets for all separations. However, for X=Te, a JT distortion lifts the degeneracy of the e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT levels leading to a reduction of the exchange interaction between impurity pairs.
Deep, intrinsic, vacancy and antisite defects that localize the holes might stabilize the magnetization of p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Our systematic study of the p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers identifies 1H CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MoSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT as the most promising candidates for room temperature ferromagnetism.
We combine the exchange interaction estimated from the energy difference calculated for ferromagnetically and antiferromagnetically coupled pairs with Monte Carlo calculations to estimate the Curie temperatures TCsubscript𝑇CT_{\rm C}italic_T start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT for vanadium doped CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MoSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Room temperature values of TCsubscript𝑇CT_{\rm C}italic_T start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT are predicted for V dopant concentrations of 5% and 9%, respectively. In view of the instability of CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT in the 1H form, we suggest that the Crx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPTMo1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPT(Tey𝑦{}_{y}start_FLOATSUBSCRIPT italic_y end_FLOATSUBSCRIPTSe)1−y2{}_{1-y})_{2}start_FLOATSUBSCRIPT 1 - italic_y end_FLOATSUBSCRIPT ) start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT alloy system be studied.
A single d𝑑ditalic_d electron or hole is uncorrelated. However, in the single impurity limit, the residual self-interaction of this carrier in the local spin density approximation (LSDA) can be corrected by introducing a Hubbard U𝑈Uitalic_U. Doing so leads to a large increase of the ordering temperatures calculated in the LSDA (reducing the doping concentration needed to achieve room temperature ordering) but at the expense of introducing an indeterminate parameter U𝑈Uitalic_U.",[],"['China', 'Netherlands']"
"Fix a stable degree-n𝑛nitalic_n rank-k𝑘kitalic_k bundle ℱℱ\mathcal{F}caligraphic_F on a complex elliptic curve for (coprime) 1≤k<n≥31𝑘𝑛31\leq k<n\geq 31 ≤ italic_k < italic_n ≥ 3. We identify the symplectic leaves of the Poisson structure introduced independently by Polishchuk and Feigin-Odesskii on ℙn−1≅ℙ⁢Ext1⁢(ℱ,𝒪)superscriptℙ𝑛1ℙsuperscriptExt1ℱ𝒪\mathbb{P}^{n-1}\cong\mathbb{P}\mathrm{Ext}^{1}(\mathcal{F},\mathcal{O})blackboard_P start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ≅ blackboard_P roman_Ext start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( caligraphic_F , caligraphic_O ) as precisely the loci classifying extensions 0→𝒪→ℰ→ℱ→0→0𝒪→ℰ→ℱ→00\to\mathcal{O}\to\mathcal{E}\to\mathcal{F}\to 00 → caligraphic_O → caligraphic_E → caligraphic_F → 0 with ℰℰ\mathcal{E}caligraphic_E fitting into a fixed isomorphism class, verifying a claim of Feigin-Odesskii. We also classify the bundles ℰℰ\mathcal{E}caligraphic_E which do fit into such extensions in geometric / combinatorial terms, involving their Harder-Narasimhan polygons introduced by Shatz.",[],[]
"From politicians to podcast hosts, online platforms have systematically banned (“deplatformed”) influential users for breaking platform guidelines.
Previous inquiries on the effectiveness of this intervention are inconclusive because
1) they consider only few deplatforming events;
2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views);
3) they do not consider all the potential places users impacted by the deplatforming event might migrate to.
We address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers.
We collect deplatforming events from Reddit posts and then manually curate the data, ensuring the correctness of a large dataset of deplatforming events.
Then, we link these events to Google Trends and Wikipedia page views, platform-agnostic measures of online attention that capture the general public’s interest in specific influencers.
Through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers.
After 12 months, we estimate that online attention toward deplatformed influencers is reduced by
−--63% (95% CI [−--75%,−--46%]) on Google and by
−--43% (95% CI [−--57%,−--24%]) on Wikipedia.
Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention.
Notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers;
Overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation.",['online communities fringe online communities content moderation online radicalization deplatforming social networks'],['Switzerland']
,[],[]
"In this paper, we examine the parameter estimation performance of three well-known sinusoidal models for speech and audio. The first one is the standard Sinusoidal Model (SM), which is based on the Fast Fourier Transform (FFT). The second is the Exponentially Damped Sinusoidal Model (EDSM) which has been proposed in the last decade, and utilizes a subspace method for parameter estimation, and finally the extended adaptive Quasi-Harmonic Model (eaQHM), which has been recently proposed for AM-FM decomposition, and estimates the signal parameters using Least Squares on a set of basis function that are adaptive to the local characteristics of the signal. The parameter estimation of each model is briefly described and its performance is compared to the others in terms of signal reconstruction accuracy versus window size on a variety of synthetic signals and versus the number of sinusoids on real signals. The latter include highly non stationary signals, such as singing voices and guitar solos. The advantages and disadvantages of each model are presented via synthetic signals and then the application on real signals is discussed. Conclusively, eaQHM outperforms EDS in medium-to-large window size analysis, whereas EDSM yields higher reconstruction values for smaller analysis window sizes. Thus, a future research direction appears to be the merge of adaptivity of the eaQHM and parameter estimation robustness of the EDSM in a new paradigm for high-quality analysis and resynthesis of general audio signals.","['Sinusoidal', 'Model', 'adaptive', 'Quasi-Harmonic', 'Model', 'Exponentially', 'Damped', 'Sinusoids', 'Parameter', 'Estimation', 'Speech', 'Analysis', 'Audio', 'Analysis']",[]
"The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM to detail each entity. The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity. Finally, VideoDrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account. The diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos. Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference.",[],[]
"This paper documents a year-long experiment to “profile” the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process. We added interactive quizzes to The Rust Programming Language, the official textbook for learning Rust. Over 13 months, 62,526 readers answered questions 1,140,202 times. First, we analyze the trajectories of readers. We find that many readers drop-out of the book early when faced with difficult language concepts like Rust’s ownership types. Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions. We find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles. Third, we performed 12 interventions into the book to help readers with difficult questions. We find that on average, interventions improved quiz scores on the targeted questions by +20%. Fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small N𝑁Nitalic_N. These results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales.","['rust education', 'digital textbooks', 'item response theory']",[]
"Concept-based learning improves a deep learning model’s interpretability by explaining its predictions via human-understandable concepts.
Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts.
Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures.
In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts.
To understand locality, we analyse how changes to features outside of a concept’s spatial or semantic locality impact concept predictions.
Our results suggest that even in well-defined scenarios where the presence of a concept is localised to a fixed feature subspace, or whose semantics are correlated to a small subset of other concepts, CBMs fail to learn this locality.
These results cast doubt upon the quality of concept representations learnt by CBMs and strongly suggest that concept-based explanations may be fragile to changes outside their localities.",[],[]
"Magnonic frequency combs have recently attracted particular attention due to their potential impact on spin-wave science.
Here, we demonstrate theoretically the generation of ultra-wideband (UWB) magnonic frequency combs induced by dissipative coupling in an open cavity magnomechanical system.
A broadband comb with gigahertz repetition rates is obtained in the magnonic spectrum and a typical non-perturbation frequency-comb structure is also observed.
The total width of the magnonic comb in the robust plateau region can be up to ∼400similar-toabsent400\sim 400∼ 400 comb lines, which is much broader and flatter than the reported in the previous works.
Furthermore, when the dissipative coupling strength is further increased, the chaotic motion is predicted in the magnonic spectrum.
Our results provide an in-depth understanding of nonlinear magnomechanic dynamics in open quantum systems and fundamentally broadens the research range of magnon in wider spectral regimes.",[],['China']
"The strategies for and the performance of the CMS tracker alignment during the ongoing Run 3 data-taking period are described. The results of the very first tracker alignment for Run 3 data reprocessing performed with cosmic rays and collision tracks recorded at the unprecedented center of mass energy of 13.6 TeV are presented. Also, the performance after deployment of a more granular automated alignment associated with the improvement of the alignment calibration already during data taking is discussed. Finally, the prospects for the tracker alignment calibration during the Run 3 data-taking period, in light of the gained operational experience, are discussed.",[],[]
"Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.",[],[]
"When identifying electrical, mechanical, or biological systems, parametric continuous-time identification methods can lead to interpretable and parsimonious models when the model structure aligns with the physical properties of the system. Traditional linear system identification may not consider the most parsimonious model when relying solely on unfactored transfer functions, which typically result from standard direct approaches. This paper presents a novel identification method that delivers additive models for both open and closed-loop setups. The estimators that are derived are shown to be generically consistent, and can admit the identification of marginally stable additive systems. Numerical simulations show the efficacy of the proposed approach, and its performance in identifying a modal representation of a flexible beam is verified using experimental data.",[],[]
,[],[]
,[],[]
"High temperature REBCO superconducting tapes are very promising for high-field magnets. With high magnetic field application there are high electro-mechanical forces, and thus concern for mechanical damage. Due to the presence of large screening currents and composite structure of the tape, the mechanical design of these magnets are not straight forward. In addition, many contemporary designs use insulated winding. In this work we develop a novel two-dimensional axisymmetric finite element tool programmed in MATLAB that assumes the displacement field within linear elastic range. The stack of pancakes and a large number of REBCO tape turns are approximated as an an-isotropic bulk hollow cylinder. Our results agree with uni-axial stress experiments in literature, validating the bulk approximation. Here, we study the following configuration. The current is first ramp up to below the critical current and we calculate the screening currents and the forces that they cause using the MEMEP model. This electromagnetic model can now take insulated magnets into account. As a case study, 32 T REBCO superconductor magnet, is taken and simulated numerically. We have done complete mechanical analysis of the magnet by including the axial and shear mechanical quantities for each pancake unlike previous work where only radial and circumferential quantities are focused. Effect on mechanical quantities without screening current is also calculated and compared. It is shown that including screening current induced field strongly affect the mechanical quantities, specially the shear stress. The latter might be the critical quantity for certain magnet configurations. Additionally, in order to overcome high stresses, a stiff over banding of different material is considered and numerically modelled which significantly reduces the mechanical stresses. The FE based model developed is efficient to calculate the mechanical behaviour of any general superconductor magnet and its devices.",[],[]
"The deployment of several large scale arrays is envisioned to study astroparticles at ultra-high energies. In order to circumvent the heavy computational costs of exploring and optimizing their layouts, we have developed a pruning method. It consists in i) running a set of microscopic simulations and interpolate them over a dense, regularly spaced array of detection units, and ii) pruning the unnecessary units out of the layout, in order to obtain the shower footprint on a newly shaped layout. This method offers flexibility to test various layout parameters, instrumental constraints, and physical inputs, with a drastic reduction in the required CPU time. The method can be universally applied to optimize arrays of any size, and using any detection techniques.
For demonstration, we apply the pruning tool to radio antenna layouts, which allows us to discuss the interplay between the energy and inclination of air-showers on the size of the radio footprint and the intensity of the signal on the ground. Some rule-of-thumb conclusions that can be drawn for this specific case are: i) a hexagonal geometry is more efficient than a triangular geometry, ii) the detection efficiency of the array is stable to changes in the spacing between radio antennas around 1000mm\rm{m}roman_m step size, iii) for a given number of antennas, adding a granular infill on top of a coarse hexagonal array is more efficient than instrumenting the full array with a less dense spacing.",[],[]
"In deep learning, classification tasks are formalized as optimization problems solved via the minimization of the cross-entropy.
However, recent advancements in the design of objective functions allow the f𝑓fitalic_f-divergence measure to generalize the formulation of the optimization problem for classification.
With this goal in mind, we adopt a Bayesian perspective and formulate the classification task as a maximum a posteriori probability problem.
We propose a class of objective functions based on the variational representation of the f𝑓fitalic_f-divergence, from which we extract a list of five posterior probability estimators leveraging well-known f𝑓fitalic_f-divergences.
In addition, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of a new objective function (and posterior probability estimator) corresponding to a novel f𝑓fitalic_f-divergence referred to as shifted log (SL).
First, we theoretically prove the convergence property of the posterior probability estimators.
Then, we numerically test the set of proposed objective functions in three application scenarios: toy examples, image data sets, and signal detection/decoding problems. The analyzed tasks demonstrate the effectiveness of the proposed estimators and that the SL divergence achieves the highest classification accuracy in almost all the scenarios.","['Classification', 'decoding', 'estimation', 'KL divergence', 'f𝑓fitalic_f-divergence', 'MAP', 'neural networks', 'cross-entropy', 'deep learning', 'ML', 'discriminative', 'AI.']",[]
"Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs outperform our expectations in finding issues within applications correctly flagging insecure apps in 91.67% of cases in the Ghera benchmark. We use inferences from our experiments towards building a robust and actionable vulnerability detection system and demonstrate its effectiveness. Our experiments also shed light on how different various simple configurations can affect the True Positive (TP) and False Positive (FP) rates.",[],['Canada']
"Motivated by the studies of neural networks (e.g.,the neural tangent kernel theory), we perform a study on the large-dimensional behavior of kernel ridge regression (KRR) where the sample size n≍dγasymptotically-equals𝑛superscript𝑑𝛾n\asymp d^{\gamma}italic_n ≍ italic_d start_POSTSUPERSCRIPT italic_γ end_POSTSUPERSCRIPT for some γ>0𝛾0\gamma>0italic_γ > 0.
Given an RKHS ℋℋ\mathcal{H}caligraphic_H associated with an inner product kernel defined on the sphere 𝕊dsuperscript𝕊𝑑\mathbb{S}^{d}blackboard_S start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, we suppose that the true function fρ*∈[ℋ]ssuperscriptsubscript𝑓𝜌superscriptdelimited-[]ℋ𝑠f_{\rho}^{*}\in[\mathcal{H}]^{s}italic_f start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ∈ [ caligraphic_H ] start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT, the interpolation space of ℋℋ\mathcal{H}caligraphic_H with source condition s>0𝑠0s>0italic_s > 0. We first determined the exact order (both upper and lower bound) of the generalization error of kernel ridge regression for the optimally chosen regularization parameter λ𝜆\lambdaitalic_λ. We then further showed that when 0<s≤10𝑠10<s\leq 10 < italic_s ≤ 1, KRR is minimax optimal; and when s>1𝑠1s>1italic_s > 1, KRR is not
minimax optimal (a.k.a. the saturation effect).
Our results illustrate that the curves of rate varying along γ𝛾\gammaitalic_γ exhibit the periodic plateau behavior and the multiple descent behavior and show how the curves evolve with s>0𝑠0s>0italic_s > 0.
Interestingly, our work provides a unified viewpoint of several recent works on kernel regression in the large-dimensional setting, which correspond to s=0𝑠0s=0italic_s = 0 and s=1𝑠1s=1italic_s = 1 respectively.",[],[]
"Antifreeze proteins (AFPs) are remarkable biomolecules that suppress ice formation at trace concentrations.
To inhibit ice growth, AFPs must not only bind to ice crystals, but also resist engulfment by ice.
The highest supercooling, Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, for which AFPs are able to resist engulfment is widely believed to scale as the inverse of the separation, L𝐿Litalic_L, between bound AFPs, whereas its dependence on the molecular characteristics of the AFP remains poorly understood.
By using specialized molecular simulations and interfacial thermodynamics,
here we
show that in contrast with conventional wisdom, Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT scales as L−2superscript𝐿2L^{-2}italic_L start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT and not as L−1superscript𝐿1L^{-1}italic_L start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
We further show that Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is proportional to AFP size and that diverse naturally occurring AFPs are optimal at resisting engulfment by ice.
By facilitating the development of AFP structure-function relationships,
we hope that our findings will pave the way for the rational design of novel AFPs.",[],[]
"Vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation. Traditional codebooks need a wide index range, while modulation favors few discrete states. To address this, we propose a multilevel generative semantic communication system with a two-stage training framework. In the first stage, we train a high-quality codebook, using a multi-head octonary codebook (MOC) to compress the index range. We also integrate a residual vector quantization (RVQ) mechanism for effective multilevel communication. In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration. Experimental results highlight MOC-RVQ’s superior performance over methods like BPG or JPEG, even without channel error correction coding.","['Terms:  vector quantization', 'generative semantic communication', 'two-stage training', 'semantic knowledge base']",[]
"Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management. Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models. Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. Additionally, we explore the impact of climate variability, particularly during extreme weather events, on agricultural outcomes and management. Our findings demonstrate the adaptability of fertilization policies to varying climate conditions. Notably, a fixed policy exhibits resilience in the face of minor climate fluctuations, leading to commendable corn yields, cost-effectiveness, and environmental conservation. However, our study illuminates the need for agent retraining to acquire new optimal policies under extreme weather events. This research charts a promising course toward adaptable fertilization strategies that can seamlessly align with dynamic climate scenarios, ultimately contributing to the optimization of crop management practices.",[],[]
"The double star S⁢(m1,m2)𝑆subscript𝑚1subscript𝑚2S(m_{1},m_{2})italic_S ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) is obtained from joining the centres of a star with m1subscript𝑚1m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT leaves and a star with m2subscript𝑚2m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT leaves.
We give a short proof of a new upper bound on the two-colour Ramsey number of S⁢(m1,m2)𝑆subscript𝑚1subscript𝑚2S(m_{1},m_{2})italic_S ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) which holds for all m1,m2subscript𝑚1subscript𝑚2m_{1},m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with 5+12⁢m2<m1<3⁢m2512subscript𝑚2subscript𝑚13subscript𝑚2\frac{\sqrt{5}+1}{2}m_{2}<m_{1}<3m_{2}divide start_ARG square-root start_ARG 5 end_ARG + 1 end_ARG start_ARG 2 end_ARG italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 3 italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Our result implies that for all positive m𝑚mitalic_m, the Ramsey number of the double star S⁢(2⁢m,m)𝑆2𝑚𝑚S(2m,m)italic_S ( 2 italic_m , italic_m ) is at most 4.275⁢m4.275𝑚4.275m4.275 italic_m.",[],[]
"Recently, the advent of large language models (LLMs) has revolutionized generative agents.
Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users.
However, the absence of a comprehensive benchmark impedes progress in this field.
To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset.
The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts.
It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike.
CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions.
To facilitate the convenient evaluation for these subjective metrics in CharacterEval, we further developed CharacterRM, a role-playing reward model based on human annotations, which has a higher correlation with human judgment compared to GPT-4.
Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation.
Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval.",[],[]
,[],[]
"In this study, we investigate the conductivity of a two-dimensional (2D) system in HgTe quantum well comprising two types of carriers with linear and quadratic spectra, respectively. The interactions between the two-dimensional Dirac holes and the heavy holes lead to the breakdown of Galilean invariance, resulting in interaction-limited resistivity. Our exploration of the transport properties spans from low temperatures, where both subsystems are fully degenerate, to higher temperatures, where the Dirac holes remain degenerate while the heavy holes follow Boltzmann statistics, creating a partially degenerate regime. Through a developed theory, we successfully predict the behavior of resistivity as ρ∼T2similar-to𝜌superscript𝑇2\rho\sim T^{2}italic_ρ ∼ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and ρ∼T3similar-to𝜌superscript𝑇3\rho\sim T^{3}italic_ρ ∼ italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT for the fully degenerate and partially degenerate regimes, respectively, which is in reasonable agreement with experimental observations. Notably, at elevated temperatures, the interaction-limited resistivity surpasses the resistivity caused by impurity scattering by a factor of 5-6. These findings imply that the investigated system serves as a versatile experimental platform for exploring various interaction-limited transport regimes in two component plasma.",[],['Brazil']
"We identify an extended diffuse radio emission (J1507+3013) around an elliptical galaxy from the Very Large Array (VLA) Faint Images of Radio Sky at Twenty-cm (FIRST) survey. J1507+3013 possesses a morphology similar to the recently identified circular, low-surface-brightness, edge-brightened radio sources commonly known as odd radio circles (ORCs). Such diffuse emissions, as reported in the current paper, are also found in mini haloes and fossil radio galaxies, but the results presented in the current paper do not match the properties of mini haloes or fossil radio galaxies. The extended emission observed in J1507+3013 around an elliptical galaxy is a very rare class of diffuse emission which is unlike any previously known classes of diffuse emission. The extended diffuse emission of J1507+3013 is also detected in LOFAR at 144 MHz. J1507+3013 is hosted by an optical galaxy near the geometrical centre of the structure with a photometric redshift of z=0.079𝑧0.079z=0.079italic_z = 0.079. The physical extent of J1507+3013 is approximately 68 kpc, with a peak-to-peak angular size of 44 arcsec. J1507+3013 shows significantly higher flux densities compared to previously discovered ORCs. The spectral index of J1507+3013 varies between –0.90 and –1.4 in different regions of the diffused structure, which is comparable to previously discovered ORCs but less steep than mini halos and fossil radio galaxies. If we consider J1507+3013 as a candidate ORC, then this would be the closest and most luminous ORC discovered so far. This paper describes the radio, spectral, and optical/IR properties of J1507+3013 to study the nature of this source.",[],[]
"At time zero, there are N𝑁Nitalic_N identical point particles in the line (1D) which are characterized by their positions and velocities. Both values are given randomly and independently from each other, with arbitrary probability densities. Each particle evolves at constant velocity until eventually they meet. When this happens, a perfectly-plastic collision is produced, resulting in a new particle composed by the sum of their masses and the weighted average velocity.
The merged particles evolve indistinguishably from the non-merged ones, i.e. they move at constant velocity until a new plastic collision eventually happens.
As in any open system, the particles are not confined to any region or reservoir, so as time progresses, they go on to infinity.
From this non-equilibrium process, the number of (now, non-identical) final particles, X~Nsubscript~𝑋𝑁\tilde{X}_{N}over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, the distribution of masses of these final particles and the kinetic energy loss from all plastic collisions, is studied. Counterintuitively, the way to achieve the number of final particles and each of their masses does not need to rely on evolving the particle system; this result can be obtained by simply considering the initial conditions. Moreover, they can also be used to obtain an accurate approximation of the energy loss. Finally, I will also present strong evidence for the validity of the following conjecture: ⟨X~N⟩=∑k=1𝑁⁢1kdelimited-⟨⟩subscript~𝑋𝑁𝑁𝑘11𝑘\langle\tilde{X}_{N}\rangle=\overset{N}{\underset{k=1}{\sum}}\frac{1}{k}⟨ over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ⟩ = overitalic_N start_ARG start_UNDERACCENT italic_k = 1 end_UNDERACCENT start_ARG ∑ end_ARG end_ARG divide start_ARG 1 end_ARG start_ARG italic_k end_ARG (which behaves as l⁢o⁢g⁢(N)+γ𝑙𝑜𝑔𝑁𝛾log(N)+\gammaitalic_l italic_o italic_g ( italic_N ) + italic_γ for large N𝑁Nitalic_N), additionally an explicit expression for the variance will also be given.","['Many-body dynamics', 'out-of-equilibrium systems', '1D system']",['Argentina']
"Large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions. These engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs.
Reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time. Detecting common computation
is the first and key step for reducing this computational redundancy. However, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated. In addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries). Unfortunately, existing solutions fall short of satisfying these requirements.
In this paper, we take a major step towards filling this gap by proposing GEqO, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale. GEqO introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism. Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another. Our extensive empirical evaluation shows that, on TPC-DS-like queries, GEqO yields significant performance gains—up to 200×200\times200 × faster than automated verifiers—and finds up to 2×2\times2 × more equivalences than optimizer and signature-based equivalence approaches.",[],[]
,[],[]
"We study Hilbert Poincaré series associated to general seed functions and construct Cohen’s kernels and double Eisenstein series as series of Hilbert Poincaré series. Then we calculate the Rankin-Cohen brackets of Hilbert Poincaré series and Hilbert modular forms and extend Zagier’s kernel formula to totally real number fields. Finally, we show that the Rankin-Cohen brackets of two different types of Eisenstein series are special values of double Eisenstein series up to a constant.","['Hilbert modular form', 'Poincaré series', 'Rankin-Cohen bracket', 'Cohen’s kernel', 'double', 'Eisenstein series']",[]
"Automatic machine translation metrics often use human translations to determine the quality system translations.
Common wisdom in the field dictates that the human references should be of very high quality.
However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation.
We find that higher-quality references lead to better metric correlations with humans at the segment-level.
Having up to 7 references per segment and taking their average helps all metrics.
Interestingly, the references from vendors of different qualities can be mixed together and improve metric success.
Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success.
These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.",[],[]
,[],[]
"Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum.
Our students need to be able to examine the social complexities in which technology development and use are situated.
Also, aligning students’ personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging.
Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing.
Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules.
Rather than adding social on top of the technical content, our curricular approach seeks to weave them together.
The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change.
We share our approach to designing this new introductory socially responsible computing course and the students’ reflections.
We also highlight seven considerations for educators seeking to incorporate socially responsible computing.","['SRC', 'responsibility', 'social impact', 'ethics', 'power', 'critical pedagogy']",[]
"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs’ behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. Drawing inspiration from educational and cognitive research theories Bruner (1964, 1960); Jayashri and Kalaiselvi (2018), we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches. Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures inherent within LLMs. Initially conceived as a means to steer LLMs efficiently, we hope that insights gained from knowledge editing research could shed light on the underlying knowledge mechanisms of LLMs. To facilitate future research, we have released an open-source framework, EasyEdit111https://github.com/zjunlp/EasyEdit. 

      The contributions of the authors are detailed in §§\lx@sectionsign§Contributions., which will enable practitioners to efficiently and flexibly implement knowledge editing for LLMs. Finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications.",[],[]
,[],[]
"Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area. Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development. A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented.
The study concludes by addressing the challenges faced and suggesting potential research directions in this field.","['wireless channel modeling', 'physics-based modeling', 'deep learning', '3D segmentation', 'knowledge distillation.']",[]
,[],[]
"Computing reduced-order models using non-intrusive methods is particularly attractive for systems that are simulated using black-box solvers.
However, obtaining accurate data-driven models can be challenging, especially if the underlying systems exhibit large-amplitude transient growth.
Although these systems may evolve near a low-dimensional subspace that can be easily identified using standard techniques such as Proper Orthogonal Decomposition (POD), computing accurate models often requires projecting the state onto this subspace via a non-orthogonal projection.
While appropriate oblique projection operators can be computed using intrusive techniques that leverage the form of the underlying governing equations, purely data-driven methods currently tend to achieve dimensionality reduction via orthogonal projections, and this can lead to models with poor predictive accuracy.
In this paper, we address this issue by introducing a non-intrusive framework designed to simultaneously identify oblique projection operators and reduced-order dynamics.
In particular, given training trajectories and assuming reduced-order dynamics of polynomial form, we fit a reduced-order model by solving an optimization problem over the product manifold of a Grassmann manifold, a Stiefel manifold, and several linear spaces (as many as the tensors that define the low-order dynamics).
Furthermore, we show that the gradient of the cost function with respect to the optimization parameters can be conveniently written in closed-form, so that there is no need for automatic differentiation.
We compare our formulation with state-of-the-art methods on three examples: a three-dimensional system of ordinary differential equations, the complex Ginzburg-Landau (CGL) equation, and a two-dimensional lid-driven cavity flow at Reynolds number R⁢e=8300𝑅𝑒8300Re=8300italic_R italic_e = 8300.",[],[]
"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK’s public sector urgently needs to develop more systematic methods for taking advantage of the technology.
Keywords: Generative AI, public services, productivity",[],[]
"First we show that physics-informed neural networks are not suitable for a large class of parabolic partial differential equations including the Fokker-Planck equation. Then we devise an algorithm to compute solutions of the Fokker-Planck equation using the zeros of Fokker-Planck operator and the Feynman-Kac formula. The resulting algorithm is mesh-free, highly parallelizable and able to compute solutions pointwise, thus mitigating the curse of dimensionality in a practical sense. We analyze various nuances of this algorithm that are determined by the drift term in the Fokker-Planck equation. We work with problems ranging in dimensions from 2 to 10. We demonstrate that this algorithm requires orders of magnitude fewer trajectories for each point in space when compared to Monte-Carlo. We also prove that under suitable conditions the error that is caused by letting some trajectories (associated with the Feynman-Kac expectation) escape our domain of knowledge is proportional to the fraction of trajectories that escape.",[],[]
"We investigate the number of squares in a very broad family of binary recurrence
sequences with u0=1subscript𝑢01u_{0}=1italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1. We show that there are at most two distinct squares in
such sequences (the best possible result), except under such very special conditions
where we prove there are at most three such squares.","['binary recurrence sequences', 'Diophantine approximations.']",[]
"In recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. However, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and Lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile/least absolute loss). In this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. Our learning loss consists of a robust least absolute loss and an ℓ1subscriptℓ1\ell_{1}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT sparse penalty term. To fast solve the non-smooth loss under a given privacy budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE) algorithm for least absolute deviation regression. Our algorithm achieves a fast estimation by reformulating the sparse LAD problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the (ϵ,δ)italic-ϵ𝛿(\epsilon,\delta)( italic_ϵ , italic_δ )-differential privacy. We show that our algorithm can achieve better privacy and statistical accuracy trade-off compared with the state-of-the-art privacy-preserving regression algorithms. In the end, we conduct experiments to verify the efficiency of our proposed FRAPPE algorithm.",[],[]
"Reproducing kernel Hilbert spaces (RKHSs) are Hilbert spaces of functions where pointwise evaluation is continuous. There are known examples of RKHSs that are Banach algebras under pointwise multiplication. These examples are built from weights on the dual of a locally compact abelian group. In this paper we define an algebra structure on an RKHS that is equivalent to subconvolutivity of the weight for known examples (referred to as reproducing kernel Hilbert algebras, or RKHAs). We show that the class of RKHAs is closed under the Hilbert space tensor product and the pullback construction on the category of RKHSs. The subcategory of RKHAs becomes a monoidal category with the spectrum as a monoidal functor to the category of topological spaces. The image of this functor is shown to contain all compact subspaces of ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for n>0𝑛0n>0italic_n > 0.",[],[]
"The article by Anton E. M. van de Ven, Class. Quantum Grav. 15 (1998), is one of the fundamental references for higher-order heat kernel coefficients
in curved backgrounds and with non-abelian gauge connections.
In this manuscript, we point out two errors and ambiguities in the 𝖺5subscript𝖺5\mathsf{a}_{5}sansserif_a start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT coefficient, which may also affect the higher-order ones.",[],[]
"Critical slowing down and topological freezing severely hinder Monte Carlo sampling of lattice field theories as the continuum limit is approached. Recently, significant progress has been made in applying a class of generative machine learning models, known as “flow-based” samplers, to combat these issues. These generative samplers also enable promising practical improvements in Monte Carlo sampling, such as fully parallelized configuration generation. These proceedings review the progress towards this goal and future prospects of the method.",[],[]
"We study maximally supersymmetric irrelevant deformations of the D1-D5 CFT that correspond to following the attractor flow in reverse in the dual half-BPS black string solutions of type IIB supergravity on K3. When a single, quadratic condition is imposed on the parameters of the 22222222 such irrelevant deformations, the asymptotics of the solution degenerate to a linear dilaton-like spacetime. We identify each such degeneration limit with a known decoupling limit of string theory, which yields little string theory or deformations thereof (the so-called open brane LST, or ODp𝑝pitalic_p theories), compactified to two dimensions. This suggests that a 21212121-parameter family of the above deformations leads to UV-complete theories, which are string theories decoupled from gravity that are continuously connected to each other. All these theories have been argued to display Hagedorn behaviour; we show that including the F1 strings leads to an additional Cardy term. The resulting entropy formula closely resembles that of single-trace T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG-deformed CFTs, whose generalisations could provide possibly tractable effective two-dimensional descriptions of the above web of theories.
We also consider the asymptotically flat black strings. At fixed temperature, the partition function is dominated by thermodynamically stable, ‘small’ black string solutions, similar to the ones in the decoupled backgrounds. We show that certain asymptotic symmetries of these black strings bear a striking resemblance with the state-dependent symmetries of single-trace T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG, and break down precisely when the background solution reaches the ‘large’ black string threshold. This suggests that small, asymptotically flat black strings may also admit a T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG - like effective description.",[],[]
"Even-hole-free graphs pose a central challenge in identifying hereditary classes of bounded treewidth. We investigate this matter by presenting and studying the following conjecture: for an integer t≥4𝑡4t\geq 4italic_t ≥ 4 and a graph H𝐻Hitalic_H, every even-hole-free graph of large enough treewidth has an induced subgraph isomorphic to either Ktsubscript𝐾𝑡K_{t}italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT or H𝐻Hitalic_H, if (and only if) H𝐻Hitalic_H is a K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free chordal graph. The “only if” part follows from the properties of the so-called layered wheels, a construction by Sintiari and Trotignon consisting of (even-hole, K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT)-free graphs with arbitrarily large treewidth.
Alecu, Chudnovsky, Spirkl and the author proved recently that the conjecture holds in two special cases:
(a) when t=4𝑡4t=4italic_t = 4; and (b) when H=𝖼𝗈𝗇𝖾⁡(F)𝐻𝖼𝗈𝗇𝖾𝐹H=\operatorname{{\text{\sf{cone}}}}(F)italic_H = cone ( italic_F ) for some forest F𝐹Fitalic_F; that is, H𝐻Hitalic_H is obtained from a forest F𝐹Fitalic_F by adding a universal vertex. Our first result is a common strengthening of (a) and (b): for an integer t≥4𝑡4t\geq 4italic_t ≥ 4 and graphs F𝐹Fitalic_F and H𝐻Hitalic_H, (even-hole, 𝖼𝗈𝗇𝖾⁡(𝖼𝗈𝗇𝖾⁡(F))𝖼𝗈𝗇𝖾𝖼𝗈𝗇𝖾𝐹\operatorname{{\text{\sf{cone}}}}(\operatorname{{\text{\sf{cone}}}}(F))cone ( cone ( italic_F ) ), H𝐻Hitalic_H, Ktsubscript𝐾𝑡K_{t}italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT)-free graphs have bounded treewidth if and only if F𝐹Fitalic_F is a forest and H𝐻Hitalic_H is a K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free chordal graph.
Also, for general t≥4𝑡4t\geq 4italic_t ≥ 4, we push the current state of the art further than (b) by settling the conjecture for the smallest choices of H𝐻Hitalic_H that are not coned forests. The latter follows from our second result: we prove the conjecture when H𝐻Hitalic_H is a crystal; that is, a graph obtained from arbitrarily many coned double stars by gluing them together along the “middle” edges of the double stars.
Generally, even-hole-free graphs of large treewidth are rare; as far as we know, if the lower bound t𝑡titalic_t on the treewidth is large enough, then essentially there are only two examples: the layered wheels of treewidth at least t𝑡titalic_t, which happen to be K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free, and the complete graphs on more than t𝑡titalic_t vertices. In particular, an upsurge in the clique number seems to be inevitable. This extends beyond even-hole-free graphs: except for complete graphs and complete bipartite graphs, graphs from all other constructions of unbounded treewidth which have been discovered so far are 2222-degenerate.
The above discussion motivates our second conjecture: for every t≥1𝑡1t\geq 1italic_t ≥ 1, every graph of sufficiently large treewidth has an induced subgraph of treewidth t𝑡titalic_t which is either complete, complete bipartite, or 2222-degenerate. To the best of our knowledge, this is the first (and much anticipated) formulation of a possible “grid-type theorem” for induced subgraphs. Although concise, it also appears to be an informative one; for instance, if true, the latter conjecture would imply our former conjecture by reducing it to (a).",[],[]
"Strain engineering has quickly emerged as a viable option to modify the electronic, optical and magnetic properties of 2D materials. However, it remains challenging to arbitrarily control the strain. Here we show that by creating atomically-flat surface nanostructures in hexagonal boron nitride, we achieve an arbitrary on-chip control of both the strain distribution and magnitude on high-quality molybdenum disulfide. The phonon and exciton emissions are shown to vary in accordance with our strain field designs, enabling us to write and draw any photoluminescence color image in a single chip. Moreover, our strain engineering offers a powerful means to significantly and controllably alter the strengths and energies of interlayer excitons at room temperature. This method can be easily extended to other material systems and offers a promise for functional excitonic devices.",[],['Japan']
"Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations—responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs’ responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area.
(2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases.
(3) We illustrate that LLMs often fail to correct a user’s incorrect legal assumptions in a contra-factual question setup.
(4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations.
Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most—pro se litigants or those without access to traditional legal resources.111All our code, raw data, prompts, and results are available at: https://github.com/reglab/legal_hallucinations.",[],[]
"A tuple (Z1,…,Zp)subscript𝑍1…subscript𝑍𝑝(Z_{1},\ldots,Z_{p})( italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) of matrices of size r𝑟ritalic_r is said to be a commuting extension of a tuple (A1,…,Ap)subscript𝐴1…subscript𝐴𝑝(A_{1},\ldots,A_{p})( italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) of matrices of size n<r𝑛𝑟n<ritalic_n < italic_r if the Zisubscript𝑍𝑖Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT pairwise commute
and each Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT sits in the upper left corner of a block decomposition of Zisubscript𝑍𝑖Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.
This notion was discovered and rediscovered in several contexts including algebraic complexity theory (in Strassen’s work on tensor rank), in
numerical analysis for the construction of cubature formulas and in quantum mechanics for the study of computational methods and the study of the so-called ""quantum Zeno dynamics.""
Commuting extensions have also attracted the attention of the linear algebra community.
In this paper we present 3 types of results:



(i)

Theorems on the uniqueness of commuting extensions for three matrices or more.



(ii)

Algorithms for the computation of commuting extensions of minimal size. These algorithms work under the same assumptions
as our uniqueness theorems. They are applicable up to r=4⁢n/3𝑟4𝑛3r=4n/3italic_r = 4 italic_n / 3, and are apparently the first provably efficient algorithms for this problem applicable beyond r=n+1𝑟𝑛1r=n+1italic_r = italic_n + 1.



(iii)

A genericity theorem showing that our algorithms and uniqueness theorems can be applied to a wide range of
input matrices.",[],[]
"Manual delineation of tumor regions from magnetic resonance (MR) images is time-consuming, requires an expert, and is prone to human error. In recent years, deep learning models have been the go-to approach for the segmentation of brain tumors. U-Net and its’ variants for semantic segmentation of medical images have achieved good results in the literature. However, U-Net and its’ variants tend to over-segment tumor regions and may not accurately segment the tumor edges. The edges of the tumor are as important as the tumor regions for accurate diagnosis, surgical precision, and treatment planning. In the proposed work, the authors aim to extract edges from the ground truth using a derivative-like filter followed by edge reconstruction to obtain an edge ground truth in addition to the brain tumor ground truth. Utilizing both ground truths, the author studies several U-Net and its’ variant architectures with and without tumor edges ground truth as a target along with the tumor ground truth for brain tumor segmentation. The author used the BraTS2020 benchmark dataset to perform the study and the results are tabulated for the dice and Hausdorff95 metrics. The mean and median metrics are calculated for the whole tumor (WT), tumor core (TC), and enhancing tumor (ET) regions. Compared to the baseline U-Net and its variants, the models that learned edges along with the tumor regions performed well in the enhancing and core tumor regions in both training and validation datasets. The improved performance of edge-trained models trained on baseline models like U-Net and V-Net achieved performance similar to baseline state-of-the-art models like Swin U-Net and hybrid MR-U-Net. The edge-target trained models are capable of generating edge maps that can be useful for treatment planning. Additionally, for further explainability of the results, the activation map generated by the hybrid MR-U-Net has been studied.",[],[]
,[],[]
"The a𝑎aitalic_a-number is an invariant of the isomorphism class of the p𝑝pitalic_p-torsion group scheme. We use the Cartier operator on H0⁢(𝒜2,Ω1)superscript𝐻0subscript𝒜2superscriptΩ1H^{0}(\mathcal{A}_{2},\Omega^{1})italic_H start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_Ω start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ) to find a closed formula for the a𝑎aitalic_a-number of the form 𝒜2=v⁢(Yq+Y−xq+12)subscript𝒜2𝑣superscript𝑌𝑞𝑌superscript𝑥𝑞12\mathcal{A}_{2}=v(Y^{\sqrt{q}}+Y-x^{\frac{\sqrt{q}+1}{2}})caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_v ( italic_Y start_POSTSUPERSCRIPT square-root start_ARG italic_q end_ARG end_POSTSUPERSCRIPT + italic_Y - italic_x start_POSTSUPERSCRIPT divide start_ARG square-root start_ARG italic_q end_ARG + 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT ) where q=ps𝑞superscript𝑝𝑠q=p^{s}italic_q = italic_p start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT over the finite field 𝔽q2subscript𝔽superscript𝑞2\mathbb{F}_{q^{2}}blackboard_F start_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT. The application of the computed a𝑎aitalic_a-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it.","['\na𝑎aitalic_a-number', 'Cartier operator', 'Super-singular', 'Curves', 'Maximal', 'Curves.']",[]
"In this work we present deep learning implementations of two popular theoretical constrained optimization algorithms in infinite dimensional Hilbert spaces, namely, the penalty and the augmented Lagrangian methods. We test these algorithms on some toy problems originating in either calculus of variations or physics. We demonstrate that both methods are able to produce decent approximations for the test problems and are comparable in terms of different errors. Leveraging the common occurrence of the Lagrange multiplier update rule being computationally less expensive than solving subproblems in the penalty method, we achieve significant speedups in cases when the output of the constraint function is itself a function.",[],[]
"We introduce a novel time-energy uncertainty relationship
within the context of restarts in monitored quantum dynamics.
Initially, we investigate the concept of “first hitting time” in quantum systems
using an IBM quantum computer and a three-site ring graph as our starting point.
Previous studies have established that the mean recurrence time,
which represents the time taken to return to the initial state,
is quantized as an integer multiple of the sampling time,
displaying pointwise discontinuous transitions at resonances.
Our findings demonstrate that,
the natural utilization of the restart mechanism in laboratory experiments,
driven by finite data collection time spans,
leads to a broadening effect on the transitions of the mean recurrence time.
Our newly proposed uncertainty relation captures the underlying essence of these phenomena,
by connecting the broadening of the mean hitting time near resonances,
to the intrinsic energies of the quantum system
and to the fluctuations of recurrence time.
This work not only contributes to our understanding of fundamental aspects
related to quantum measurements and dynamics,
but also offers practical insights for the design
of efficient quantum algorithms with mid-circuit measurements.",[],"['Germany', 'Israel']"
"We discuss Hamiltonian learning in quantum field theories as a protocol for systematically extracting the operator content and coupling constants of effective field theory Hamiltonians from experimental data. Learning the Hamiltonian for varying spatial measurement resolutions gives access to field theories at different energy scales, and allows to learn a flow of Hamiltonians reminiscent of the renormalization group. Our method, which we demonstrate in both theoretical studies and available data from a quantum gas experiment, promises new ways of addressing the emergence of quantum field theories in quantum simulation experiments.",[],['Austria']
"Parity-time (PT) symmetric dimers were introduced to highlight the unusual properties of non-Hermitian systems that are invariant after a combined parity and time reversal operation. They are also the building blocks of a variety of symmetry and topologically protected structures, especially on integrated photonic platforms. As the name suggests, it consists of two coupled oscillators, which can be optical, mechanical, electronic, etc. in nature. In this article, we show that its effective size, defined by the number of lattice sites inversely proportional to the lattice momentum, is surprisingly three instead of two from the perspective of energy quantization. More specifically, we show analytically that the complex energy levels of a one-dimensional concatenated chain with N𝑁Nitalic_N PT-dimers are determined by a system size of 1+2⁢N12𝑁1+2N1 + 2 italic_N, which reduces to three in the case of a single PT-dimer. We note that while energy quantization conditions have been established in various non-Hermitian systems, exact and explicitly quantized complex energies as reported here are still scarce. In connection, we also discuss the other symmetries of a PT-dimer and concatenated PT-dimer chain, including non-Hermitian particle-hole symmetry and chiral symmetry.",[],[]
"We present the analytical and numerical results on the collective excitation spectrum of quasi-one-dimensional spin-orbit (SO) coupled spin-1 spinor ferromagnetic Bose-Einstein condensates. The collective excitation spectrum, using Bogoliubov-de-Gennes theory, reveals the existence of a diverse range of phases in the SO and Rabi (kL−Ωsubscript𝑘𝐿Ωk_{L}-\Omegaitalic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT - roman_Ω) coupling plane. Based on the nature of the eigenvalue of the excitation spectrum, we categorize the kL−Ωsubscript𝑘𝐿Ωk_{L}-\Omegaitalic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT - roman_Ω plane into three distinct regions, namely I, II, and III. In region I, a stable mode with phonon-like excitations is observed. In region IIa, single and multi-band instabilities are noted with a gapped mode, while multi-band instability accompanied by a gapless mode between low-lying and first excited states is realized in region IIb, which also provides evidence of unstable avoided crossing between low-lying and first excited modes, responsible for the Iosubscript𝐼𝑜I_{o}italic_I start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT type of oscillatory non-equilibrium dynamical pattern formation. The gap between low-lying and first-excited states increases upon increasing the Rabi coupling while decreases upon increase of SO coupling. Using eigenvector analysis, we confirm the presence of the spin-dipole mode in the spin-like modes in Region II. We corroborate the nature of the collective excitation through real-time dynamical evolution of the ground state perturbed with the quench of the trap using the mean-field Gross-Pitaevskii model. This analysis suggests the presence of dynamical instability leading to the disappearance of the 00-th component of the condensate. In Region III, mainly encompassing Ω∼0similar-toΩ0\Omega\sim 0roman_Ω ∼ 0 and finite kLsubscript𝑘𝐿k_{L}italic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT, we observe phonon-like excitations in both the first excited and the low-lying state. The eigenvectors in this region reveal alternative in- and out-of-phase behaviours of the spin components. Numerical analysis reveals the presence of a super stripe phase for small Rabi coupling in this region, wherein the eigenvector indicates the presence of more complicated spin-like-density mixed modes.",[],"['Brazil', 'China', 'India']"
"The success of a future quantum internet will rest in part on the ability of quantum and classical signals to coexist in the same optical fiber infrastructure, a challenging endeavor given the orders of magnitude differences in flux of single-photon-level quantum fields and bright classical traffic. We theoretically describe and experimentally implement Procrustean entanglement concentration for polarization-entangled states contaminated with classical light, showing significant mitigation of crosstalk noise in dense wavelength-division multiplexing. Our approach leverages a pair of polarization-dependent loss emulators to attenuate highly polarized crosstalk that results from imperfect isolation of conventional signals copropagating on shared fiber links. We demonstrate our technique both on the tabletop and over a deployed quantum local area network, finding a substantial improvement of two-qubit entangled state fidelity from approximately 75% to over 92%. This local filtering technique could be used as a preliminary step to reduce asymmetric errors, potentially improving the overall efficiency when combined with more complex error mitigation techniques in future quantum repeater networks.",[],[]
"Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs’ autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework’s superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.",[],[]
"As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to “hallucinate” – generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people’s lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, customer support conversations, financial analysis reports, and providing erroneous legal advice. Small errors could lead to harm, revealing the LLMs’ lack of actual comprehension despite advances in self-learning. This paper presents a comprehensive survey of over thirty-two techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval-Augmented Generation (RAG) Lewis et al. (2021), Knowledge Retrieval Varshney et al. (2023), CoNLI Lei et al. (2023), and CoVe Dhuliawala et al. (2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.",[],[]
"Grammatical inference consists in learning a language or a grammar from data. In this paper, we consider a number of models for inferring a non-deterministic finite automaton (NFA) with 3 sorts of states, that must accept some words, and reject some other words from a given sample. We then propose a transformation from this 3-sort NFA into weighted-frequency and probabilistic NFA, and we apply the latter to a classification task. The experimental evaluation of our approach shows that the probabilistic NFAs can be successfully applied for classification tasks on both real-life and superficial benchmark data sets.","['grammatical inference  and nondeterministic automata  and', 'SAT models']","['Poland', 'France']"
"In this article, we study how the absolute
coregularity
of a projective log pair
reflects on
its fundamental group.
More precisely, we conjecture
that for a projective klt log pair (X,D)𝑋𝐷(X,D)( italic_X , italic_D )
of absolute coregularity c𝑐citalic_c (and arbitrary dimension)
the fundamental group
π1reg⁢(X,D)superscriptsubscript𝜋1reg𝑋𝐷\pi_{1}^{\rm reg}(X,D)italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_reg end_POSTSUPERSCRIPT ( italic_X , italic_D )
admits a normal abelian subgroup
of finite index
and rank at most 2⁢c2𝑐2c2 italic_c.
We prove this conjecture
in the cases c∈{0,1,2}𝑐012c\in\{0,1,2\}italic_c ∈ { 0 , 1 , 2 }, building on the almost abelianity of the fundamental groups of klt Calabi-Yau pairs of dimension ≤2absent2\leq 2≤ 2. In the cases c∈{0,1,2}𝑐012c\in\{0,1,2\}italic_c ∈ { 0 , 1 , 2 } and fixed dimension, we can furthermore bound the index of a solvable normal subgroup.
In dimension three, we are able to prove almost abelianity for projective varieties with klt singularities and ℚℚ\mathbb{Q}blackboard_Q-trivial canonical divisor.",[],[]
"In this work, photon bunching from LED light was observed for the first time using SiPMs. The bunching signature was observed with a significance of 7.3⁢σ7.3𝜎7.3~{}\sigma7.3 italic_σ using 97 hs of data. The light was spectrally filtered using a 1 nm bandpass filter and an Etalon filter to ensure temporal coherence of the field and its coherence time was measured to be τC=(13.0±1.3)subscript𝜏𝐶plus-or-minus13.01.3\tau_{C}=(13.0\pm 1.3)italic_τ start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT = ( 13.0 ± 1.3 ) ps. The impact of SiPM non-idealities in these kinds of measurements is explored, and we describe the methodology to process SiPM analog waveforms and the event selection used to mitigate these non-idealities.",[],"['Germany', 'Argentina']"
"We propose a model of a twisted accretion disc around a Kerr black hole
interacting with a secondary black hole of a smaller mass on an inclined eccentric orbit.
We use parameters of the system, which may be appropriate for
the so-called ’precessing massive’ model of OJ 287.
We calculate expressions for torque exerted on the disc by the secondary and a contribution of the secondary
to the apsidal precession of disc elements by a double averaging procedure over the periods of
the secondary and the disc elements. These expressions are used at all
scales of interest, including the ones inside the binary orbit. We calculate numerically
the evolution of the disc tilt and twist assuming a flat initial configuration. We consider the disc
aspect ratio h/r=10−3ℎ𝑟superscript103h/r=10^{-3}italic_h / italic_r = 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, a rather large viscosity parameter α=0.1𝛼0.1\alpha=0.1italic_α = 0.1 and several values of the primary
rotational parameter, χ𝜒\chiitalic_χ. We find that, after a few periods of Lense-Thirring precession of the
orbit, the disc relaxes to a quasi-stationary configuration in the precessing frame with a non-trivial
distribution of the disc inclination angle, β𝛽\betaitalic_β, over the radial scale.
 We propose an analytic model for this configuration. We show that
the presence of the twisted disc leads to multiple crossings of the disc by the secondary per one orbital period, with time periods between the crossings being different from the flat disc model. Our results should be taken into account in the modelling of OJ 287. They can also be applied to similar sources.",[],[]
"We present time-series near-infrared (NIR) spectra for the classical Cepheid, CP Cephei, from the Astrophysical Research Consortium 3.5-m telescope and NIR spectrograph, TripleSpec, at Apache Point Observatory, NM, USA. Spectral observations were made at three points on the ascending portion of the visible phase diagram for the star. Carbon monoxide (CO) was detected in absorption in the 2.3-micron band head for each observation. We observed that the equivalent width of the 3-1 transition of the CO band head decreased by half from our first observation to the second, or slightly over one day out of the 17.867-day period. Our third observation occurred 54 days after the first (slightly over three periods for the star) and showed similar CO levels to the first observation, suggesting that the CO is in the stellar atmosphere and varies with pulsation.",[],[]
,[],[]
"We introduce the Whitehead complex, a one-complex associated to a finite regular cover of the rose and show that it is connected if and only if the fundamental group of the associated cover is generated by its intersection with the set of elements in proper free factors of 𝐅nsubscript𝐅𝑛\mathbf{F}_{n}bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. The Whitehead complex admits an action of Out⁢(𝐅n)Outsubscript𝐅𝑛\mathrm{Out}(\mathbf{F}_{n})roman_Out ( bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) by isometries if the associated cover corresponds to a characteristic subgroup of 𝐅nsubscript𝐅𝑛\mathbf{F}_{n}bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. We prove that the Whitehead complex of the rose has infinite diameter and is nonhyperbolic, implying it is not quasi-isometric to the free splitting complex or the free factor complex.",[],[]
"In this work, we report a study of the equilibrium configurations and the radial stability of spherically symmetric relativistic Neutron Stars(NS) with polytropic model in a modified f⁢(R,T)=R+2⁢λ⁢T+ξ⁢T2𝑓𝑅𝑇𝑅2𝜆𝑇𝜉superscript𝑇2f(R,T)=R+2\lambda T+\xi T^{2}italic_f ( italic_R , italic_T ) = italic_R + 2 italic_λ italic_T + italic_ξ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT gravity (where T𝑇Titalic_T is the trace of the conserved energy-momentum tensor Tμ⁢νsubscript𝑇𝜇𝜈T_{\mu\nu}italic_T start_POSTSUBSCRIPT italic_μ italic_ν end_POSTSUBSCRIPT of the matter-energy, λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ are the modified gravity parameters). We investigate the neutron stars properties such as mass(M𝑀Mitalic_M), radius(R𝑅Ritalic_R), pressure(P𝑃Pitalic_P) and energy density(ρ𝜌\rhoitalic_ρ) and their dependence on the modified gravity parameters λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ corresponding to different central density (ρcsubscript𝜌𝑐\rho_{c}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT) of the NS. For λ=0,−1,−3,−5𝜆0135\lambda=0,-1,-3,-5italic_λ = 0 , - 1 , - 3 , - 5 with ξ=0𝜉0\xi=0italic_ξ = 0 and central density ρc=1.5×1018⁢kg⁢m−3subscript𝜌𝑐1.5superscript1018kgsuperscriptm3\rho_{c}=1.5\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.5 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, we find the maximum mass of the NS as M=1.06⁢M⊙𝑀1.06subscript𝑀direct-productM=1.06M_{\odot}italic_M = 1.06 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT, 1.19⁢M⊙1.19subscript𝑀direct-product1.19M_{\odot}1.19 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT 1.61⁢M⊙1.61subscript𝑀direct-product1.61M_{\odot}1.61 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and 2.47⁢M⊙2.47subscript𝑀direct-product2.47~{}M_{\odot}2.47 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT corresponding to the radius(R𝑅Ritalic_R) 10.40910.40910.40910.409 km, 10.73710.73710.73710.737 km, 11.46111.46111.46111.461 km and 12.11912.11912.11912.119 km. respectively. This higher value of NS mass can be compared with observational constraints like gravitational wave data(GW170817) which is ≈\approx≈ 2.33 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. For a given λ=−6𝜆6\lambda=-6italic_λ = - 6 and ξ=0𝜉0\xi=0italic_ξ = 0, we find that as ρcsubscript𝜌𝑐\rho_{c}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT increases from ρc=1.1×1018⁢kg⁢m−3subscript𝜌𝑐1.1superscript1018kgsuperscriptm3\rho_{c}=1.1\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.1 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT to ρc=1.6×1018⁢kg⁢m−3subscript𝜌𝑐1.6superscript1018kgsuperscriptm3\rho_{c}=1.6\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.6 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, the maximum mass Mm⁢a⁢xsubscript𝑀𝑚𝑎𝑥M_{max}italic_M start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT of the NS decreases from 4.19⁢M⊙4.19subscript𝑀direct-product4.19M_{\odot}4.19 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT to 3.23⁢M⊙3.23subscript𝑀direct-product3.23M_{\odot}3.23 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT(giving mass of stellarmass Black Hole ⪆3⁢M⊙greater-than-or-approximately-equalsabsent3subscript𝑀direct-product\gtrapprox 3M_{\odot}⪆ 3 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT), while it’s radius R𝑅Ritalic_R decreases 13.86⁢km13.86km13.86\rm{km}13.86 roman_km to 11.54⁢km11.54km11.54\rm{km}11.54 roman_km. With the fixed value of ξ=10−27𝜉superscript1027\xi=10^{-27}italic_ξ = 10 start_POSTSUPERSCRIPT - 27 end_POSTSUPERSCRIPT and λ=0,−1,−3,−5𝜆0135\lambda=0,-1,-3,-5italic_λ = 0 , - 1 , - 3 , - 5, we find the maximum mass M=1.06⁢M⊙𝑀1.06subscript𝑀direct-productM=1.06M_{\odot}italic_M = 1.06 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT, 1.34⁢M⊙1.34subscript𝑀direct-product1.34M_{\odot}1.34 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT 1.89⁢M⊙1.89subscript𝑀direct-product1.89M_{\odot}1.89 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and 3.39⁢M⊙3.39subscript𝑀direct-product3.39~{}M_{\odot}3.39 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT corresponding to the radius R=10.409𝑅10.409R=10.409italic_R = 10.409 km, 10.84310.84310.84310.843 km, 11.54911.54911.54911.549 km and 11.68011.68011.68011.680 km. respectively.
Taking our observational constraints i.e. GW170817 (BNS Merger) mass - radius data, observed pulsars PSRJ1614-2230, PSRJ0348+0432 maximum mass - radius data; we found that posterior distribution plot of mass &\&& radius gives good result and the corner plot of modified gravity parameters λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ are giving very good posterior results. So, for a range of values of λ𝜆\lambdaitalic_λ with ξ=0(≠0)𝜉annotated0absent0\xi=0(\neq 0)italic_ξ = 0 ( ≠ 0 ), we found that the mass M𝑀Mitalic_M and the radius R𝑅Ritalic_R of the NS lie within the range given by the GW170817 gravitational wave data given by LIGO, Pulsars &\&& Millisecond Pulsars data and the NICER (Neutron star Interior Composition ExploreR) mass-radius data given by NASA.",[],['India']
,[],[]
,[],[]
"In this paper, we consider classes of decision tables closed under
removal of attributes (columns) and changing of decisions attached to rows.
For decision tables from closed classes, we study lower bounds on the minimum
cardinality of reducts, which are minimal sets of attributes that allow us
to recognize, for a given row, the decision attached to it. We assume that the
number of rows in decision tables from the closed class is not bounded from above by
a constant. We divide the set of such closed classes into two families. In
one family, only standard lower bounds Ω(log\Omega(\logroman_Ω ( roman_log cl(T)){\rm cl}(T))roman_cl ( italic_T ) ) on the
minimum cardinality of reducts for decision tables hold, where cl⁢(T)cl𝑇{\rm cl}(T)roman_cl ( italic_T )
is the number of decision classes in the table T𝑇Titalic_T. In another family, these
bounds can be essentially tightened up to Ω⁢(cl⁢(T)1/q)Ωclsuperscript𝑇1𝑞\Omega({\rm cl}(T)^{1/q})roman_Ω ( roman_cl ( italic_T ) start_POSTSUPERSCRIPT 1 / italic_q end_POSTSUPERSCRIPT ) for
some natural q𝑞qitalic_q.",[],[]
"This work elicits LLMs’ inherent ability to handle long contexts without fine-tuning.
The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs’ context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs’ long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model’s self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs’ context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs’ context window’s length.","['Machine', 'Learning', 'ICML']",[]
"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is span-based. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.",[],[]
"In this work, the description of the moduli space of principal G𝐺Gitalic_G-bundles as double quotient of loop groups is used to construct an étale local r𝑟ritalic_r-matrix for the Hitchin integrable system.",[],[]
"We prove a finiteness theorem for subgroups of bounded rank in hyperbolic 3333-manifold groups. As a consequence, we show that every bounded rank covering tower of closed hyperbolic 3333-manifolds is a tower of finite covers associated to a fibration over a 1111-orbifold.",[],[]
"The quasi-optical propagation of millimeter-wave (mmWave) signals enables high-accuracy localization algorithms that employ geometric approaches or machine learning models. However, most algorithms require information on the indoor environment, may entail the collection of large training datasets, or bear an infeasible computational burden for commercial off-the-shelf (COTS) devices. In this work, we propose to use tiny neural networks (NNs) to learn the relationship between angle difference-of-arrival (ADoA) measurements and locations of a receiver in an indoor environment. To relieve training data collection efforts, we resort to a self-supervised approach by bootstrapping the training of our neural network through location estimates obtained from a state-of-the-art localization algorithm. We evaluate our scheme via mmWave measurements from indoor 60-GHz double-directional channel sounding. We process the measurements to yield dominant multipath components, use the corresponding angles to compute ADoA values, and finally obtain location fixes. Results show that the tiny NN achieves sub-meter errors in 74% of the cases, thus performing as good as or even better than the state-of-the-art algorithm, with significantly lower computational complexity.",[],[]
,[],['Netherlands']
"In U⁢(1)𝑈1U(1)italic_U ( 1 ) lattice gauge theory with compact U⁢(1)𝑈1U(1)italic_U ( 1 ) variables, we construct the
symmetry operator, i.e., the topological defect, for the axial U⁢(1)𝑈1U(1)italic_U ( 1 )
non-invertible symmetry. This requires a lattice formulation of chiral gauge
theory with an anomalous matter content and we employ the lattice formulation
on the basis of the Ginsparg–Wilson relation. Then, the invariance of the
symmetry operator under the gauge transformation of the gauge field on the
defect is realized, imitating the prescription by Karasik in continuum theory,
by integrating the lattice Chern–Simons term on the defect over
smooth lattice gauge transformations. The projection operator for
allowed magnetic fluxes on the defect then automatically emerges with lattice
regularization. The resulting symmetry operator is manifestly gauge invariant
under lattice gauge transformations.",[],['Japan']
,[],[]
"Nuclear spins in solid-state platforms are promising for building rotation sensors due to their long coherence times. Among these platforms, nitrogen-vacancy centers have attracted considerable attention with ambient operating conditions. However, the current performance of NV gyroscopes remains limited by the degraded coherence when operating with large spin ensembles. Protecting the coherence of these systems requires a systematic study of the coherence decay mechanism. Here we present the use of nitrogen-15 nuclear spins of NV centers in building gyroscopes, benefiting from its simpler energy structure and vanishing nuclear quadrupole term compared with nitrogen-14 nuclear spins, though suffering from different challenges in coherence protection. We systematically reveal the coherence decay mechanism of the nuclear spin in different NV electronic spin manifolds and further develop a robust coherence protection protocol based on controlling the NV electronic spin only, achieving a 15-fold dephasing time improvement. With the developed coherence protection, we demonstrate an emulated gyroscope by measuring a designed rotation rate pattern, showing an order-of-magnitude sensitivity improvement.",[],[]
"Solid-state platforms based on electro-nuclear spin systems are attractive candidates for rotation sensing due to their excellent sensitivity, stability, and compact size, compatible with industrial applications. Conventional spin-based gyroscopes measure the accumulated phase of a nuclear spin superposition state to extract the rotation rate and thus suffer from spin dephasing. Here, we propose a gyroscope protocol based on a two-spin system that includes a spin intrinsically tied to the host material, while the other spin is isolated. The rotation rate is then extracted by measuring the relative rotation angle between the two spins starting from their population states, robust against spin dephasing. In particular, the relative rotation rate between the two spins can be enhanced by their hyperfine coupling by more than an order of magnitude, further boosting the achievable sensitivity. The ultimate sensitivity of the gyroscope is limited by the lifetime of the spin system and compatible with a broad dynamic range, even in the presence of magnetic noises or control errors due to initialization and qubit manipulations. Our result enables precise measurement of slow rotations and exploration of fundamental physics.",[],[]
"Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.
At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT.
Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM’s performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.",[],[]
"Motivated by explosive releases of energy in fusion, space and astrophysical plasmas, we consider the nonlinear convective stability of stratified magnetohydrodynamic (MHD) equilibria in 2D. We demonstrate that, unlike the Schwarzschild criterion in hydrodynamics (“entropy must increase upwards for convective stability”), the so-called modified Schwarzschild criterion for 2D MHD (or for any kind of fluid dynamics with more than one source of pressure) guarantees only linear stability. As a result, in 2D MHD (unlike in hydrodynamics) there exist metastable equilibria that are unstable to nonlinear perturbations despite being stable to linear ones. We show that the minimum-energy configurations attainable by these atmospheres via non-diffusive reorganization can be determined by solving a combinatorial optimization problem. We find inter alia that these minimum-energy states are usually 2D, even when the original metastable equilibrium was 1D. We demonstrate with direct numerical simulations that these 2D states are fairly accurate predictors of the final state reached by laminar relaxation of metastable equilibria at small Reynolds number. To describe relaxation at large Reynolds number, we construct a statistical mechanical theory based on the maximization of Boltzmann’s mixing entropy that is analogous to the Lynden-Bell statistical mechanics of self-gravitating systems and collisionless plasmas, and to the Robert-Sommeria-Miller (RSM) theory of 2D vortex turbulence. The minimum-energy states described above are, we show, the low-temperature limit of this theory. We demonstrate that the predictions of the statistical mechanics are in reasonable agreement with direct numerical simulations.",[],[]
"This paper studies how to recover parameters in diagonal Gaussian mixture models using tensors. High-order moments of the Gaussian mixture model are estimated from samples. They form incomplete symmetric tensors generated by hidden parameters in the model. We propose to use generating polynomials to compute incomplete symmetric tensor approximations. The obtained decomposition is utilized to recover parameters in the model. We prove that our recovered parameters are accurate when the estimated moments are accurate. Using high-order moments enables our algorithm to learn Gaussian mixtures with more components. For a given model dimension and order, we provide an upper bound of the number of components in the Gaussian mixture model that our algorithm can compute.","['Gaussian mixture', 'symmetric tensor decomposition', 'generating polynomial', 'moments']",[]
"Consider the transverse isometric action of a finite dimensional Lie algebra 𝔤𝔤\mathfrak{g}fraktur_g on a Riemannian foliation. This paper studies the equivariant Morse-Bott theory on the leaf space of the Riemannian foliations in this setting. Among other things, we establish a foliated version of the Morse-Bott lemma for a 𝔤𝔤\mathfrak{g}fraktur_g-invariant basic Morse-Bott function, and a foliated version of the usual handle presentation theorem. In the non-equivariant case, we apply these results to present a new proof of the Morse inequalities on Riemannian foliations. In the equivariant case, we apply these results to study Hamiltonian action of an abelian Lie algebra on a presymplectic manifold whose underlying foliation is also Riemannian, and extend the Kirwan surjectivity and injectivity theorem in equivariant symplectic geometry to this situation. Among other things, this implies the Kirwan surjectivity and injectivity hold for Hamiltonian torus actions on symplectic orbifolds.",[],[]
"This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos.
Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes.
However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses.
We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations.
Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background.
To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance.
The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066×\times×1600 resolution) within half an hour of training.
The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets.
Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets.
Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker.
The code is available at
https://zju3dv.github.io/street_gaussians/.",[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
"A Hardy-Littlewood triple is a 3-tuple of integers with the form (n,n+2,n+6)𝑛𝑛2𝑛6(n,n+2,n+6)( italic_n , italic_n + 2 , italic_n + 6 ). In this paper, we study Hardy-Littlewood triples of the form (p,Pa,Pb)𝑝subscript𝑃𝑎subscript𝑃𝑏(p,P_{a},P_{b})( italic_p , italic_P start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) and improve the upper and lower bound orders of it, where p𝑝pitalic_p is a prime and Prsubscript𝑃𝑟P_{r}italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT has at most r𝑟ritalic_r prime factors. Our new results generalize and improve the previous results.","['Prime', 'Goldbach-type problems', 'Sieve', 'Application of sieve method']",[]
,[],[]
"In this letter, the size (height and weight) of fictional characters in animations, superhero series, movies, and other media is studied.
We find that the distributions of character height and weight approximately follow lognormal distributions in common to five selected works.
We propose a mechanism governing this lognormal behavior based on the principle of maximum entropy and the Weber-Fechner law.
Moreover, we provide a comparison to the size distributions of real animals.
Although the size distributions of fictional characters and real animals are both lognormal, the distributions are essentially different, particularly in the scaling between height and weight.",[],['Japan']
"Let Prsubscript𝑃𝑟P_{r}italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT denote an integer with at most r𝑟ritalic_r prime factors counted with multiplicity. In this paper we prove that for any 0<λ<140𝜆140<\lambda<\frac{1}{4}0 < italic_λ < divide start_ARG 1 end_ARG start_ARG 4 end_ARG, the inequality {p}<p−λ𝑝superscript𝑝𝜆\{\sqrt{p}\}<p^{-\lambda}{ square-root start_ARG italic_p end_ARG } < italic_p start_POSTSUPERSCRIPT - italic_λ end_POSTSUPERSCRIPT has infinitely many solutions in primes p𝑝pitalic_p such that p+2=Pr𝑝2subscript𝑃𝑟p+2=P_{r}italic_p + 2 = italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, where r=⌊81−4⁢λ⌋𝑟814𝜆r=\lfloor\frac{8}{1-4\lambda}\rflooritalic_r = ⌊ divide start_ARG 8 end_ARG start_ARG 1 - 4 italic_λ end_ARG ⌋. This generalizes the previous result of Cai.","['Prime', 'Goldbach-type problems', 'Sieve', 'Application of sieve method']",[]
,[],[]
"In the era of data-driven economies, incentive systems and loyalty programs, have
become ubiquitous in various sectors, including advertising, retail, travel, and
financial services. While these systems offer advantages for both users and companies,
they necessitate the transfer and analysis of substantial amounts of sensitive data.
Privacy concerns have become increasingly pertinent, necessitating the development of
privacy-preserving incentive protocols. Despite the rising demand for secure and
decentralised systems, the existing landscape lacks a comprehensive solution.
In this work, we propose the Boomerang protocol, a novel decentralised
privacy-preserving incentive protocol that leverages cryptographic black box
accumulators to securely store user interactions within the incentive system.
Moreover, the protocol employs zero-knowledge proofs based on BulletProofs to
transparently compute rewards for users, ensuring verifiability while preserving their
privacy. To further enhance public verifiability and transparency, we utilise a smart contract on a Layer 1 blockchain to verify these
zero-knowledge proofs. The careful combination of black box accumulators with selected
elliptic curves in the zero-knowledge proofs makes the Boomerang protocol highly
efficient.
Our proof of concept implementation shows that we can handle up to 23.6 million users
per day, on a single-threaded backend server with financial costs of approximately 2
US$. Using the Solana blockchain we can handle 15.5 million users per
day with approximate costs of 0.00011 US$ per user.
The versatility of the the Boomerang protocol is demonstrated through its
applications in personalised privacy-preserving advertising, data collection, and
health and fitness tracking. Overall, the Boomerang protocol represents a
significant advancement in privacy-preserving incentive protocols, laying the
groundwork for a more secure and privacy-centric future.",[],[]
"In this paper, our focus is on investigating the impact of cosmological constant on relativistic quantum systems comprising spin-0 scalar particles. Our analysis centers around the Klein-Gordon equation, and we obtain both approximate and exact analytical solutions for spin-0 particles of the quantum system. Afterwards, we explore quantum oscillator fields by considering the Klein-Gordon oscillator within the same space-time characterized by a cosmological constant. We obtain an approximate expression for the energy eigenvalue of the oscillator fields. In fact, the energy spectrum in both scenarios are examined and show the influences of the cosmological constant and geometry’s topology. Our investigation is situated within the context of a magnetic universe-a four-dimensional cosmological space-time recognized as the Bonnor-Melvin universe.",[],[]
,[],[]
"Video lectures are becoming more popular and in demand as online classroom teaching is becoming more prevalent. Massive Open Online Courses (MOOCs), such as NPTEL, have been creating high-quality educational content that is freely accessible to students online. A large number of colleges across the country are now using NPTEL videos in their classrooms. So more video lectures are being recorded, maintained, and uploaded. These videos generally contain information about that video before the lecture begins. We generally observe that these educational videos have metadata containing five to six attributes: Institute Name, Publisher Name, Department Name, Professor Name, Subject Name, and Topic Name. It would be easy to maintain these videos if we could organize them according to their categories. The indexing of these videos based on this information is beneficial for students all around the world to efficiently utilise these videos. In this project, we are trying to get the metadata information mentioned above from the video lectures.",[],[]
"People living with Type 1 Diabetes (T1D) lose the ability to produce
insulin naturally. To compensate, they inject synthetic insulin. One
common way to inject insulin is through automated insulin delivery
systems, which use sensors to monitor their metabolic state and an
insulin pump device to adjust insulin to adapt.
In this paper, we present the Metabolic Operating System, a new
automated insulin delivery system that we designed from the ground up
using security first principles. From an architecture perspective, we
apply separation principles to simplify the core system and isolate
non-critical functionality from the core closed-loop algorithm. From
an algorithmic perspective, we evaluate trends in insulin technology
and formulate a simple, but effective, algorithm given the
state-of-the-art. From a safety perspective, we build in multiple
layers of redundancy to ensure that the person using our system
remains safe.
Fundamentally, this paper is a paper on real-world experiences
building and running an automated insulin delivery system. We report
on the design iterations we make based on experiences working with one
individual using our system. Our evaluation shows that an automated
insulin delivery system built from the ground up using security first
principles can still help manage T1D effectively.

Our source code is open source and available on GitHub (link omitted).",[],[]
"We investigate physical consequences of non-linear electrodynamic coupled to parameters that signal violation Lorentz-symmetry breaking (LSV). Our undertaking is done by considering a general non-linear photonic Lagrangian which coupled to the Carroll-Field-Jackiw’s model (CFJ). Our endeavor reveals how the (meta) material constitutive properties of the vacuum and wave propagation are affected by the interference of the LSV parameters LSV with the specific non-linear electrodynamic model under consideration. We also discuss the refractive indices for this new medium characterized by the coupling between non-linearities and the operators that carry the LSV message. Our results show that the QED-vacuum responds with birefringence and a dispersive propagation of waves. Subsequently, we consider the electromagnetic radiation produced by a moving charged particle interacting with this new medium. Our inspection illustrates that the emitted radiation reproduces the features of the Cherenkov effect for certain intensities of background magnetic fields . Finally, we compute the static potential profile within the framework of the gauge-invariant, but path-dependent, variables formalism. A logarithmic correction to the usual static Coulomb potential emerges driven by the LSV parameter and there also appear corrections due to the non-linearity; nevertheless, the logarithm behavior drops out whenever the LSV parameter is switched off.",[],['Chile']
"In this paper, we conduct a comprehensive exploration of the relativistic quantum dynamics of spin-0 scalar particles, as described by the Duffin-Kemmer-Petiau (DKP) equation, within the framework of a magnetic space-time. Our focus is on the Bonnor-Melvin-Lambda (BML) solution, a four-dimensional magnetic universe characterized by a magnetic field that varies with axial distance. To initiate this investigation, we derive the radial equation using a suitable wave function ansatz and subsequently employ special functions to solve it. Furthermore, we extend our analysis to include Duffin-Kemmer-Petiau oscillator fields within the same BML space-time background. We derive the corresponding radial equation and solve it using special functions. Significantly, our results show that the geometry’s topology and the cosmological constant (both are related with the magnetic field strength) influences the eigenvalue solution of spin-0 DKP fields and DKP-oscillator fields, leading to substantial modifications in the overall outcomes.",[],[]
"We study heavy-flavor hadron production in high-energy pp collisions, assuming the formation of a small, deconfined and expanding fireball where charm quarks can undergo rescattering and hadronization. We adopt the same in-medium hadronization mechanism developed for heavy-ion collisions, which involves Local Color-Neutralization (LCN) through recombination of charm quarks with nearby opposite color charges from the background fireball. Diquark excitations in the hot medium favor the formation of charmed baryons. The recombination process, involving closely aligned partons from the same fluid cell, effectively transfers the collective flow of the system to the final charmed hadrons. This framework can qualitatively reproduce the observed experimental findings in heavy-flavor particle-yield ratios, pTsubscript𝑝𝑇p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT-spectra and elliptic-flow coefficients. Our results provide new, complementary support to the idea that the collective phenomena observed in small systems have the same origin as those observed in heavy-ion collisions.",[],[]
"Convolutional Neural Networks (CNN) are widely used to face challenging tasks like speech recognition, natural language processing or computer vision. As CNN architectures get larger and more complex, their computational requirements increase, incurring significant energetic costs and challenging their deployment on resource-restricted devices. In this paper, we propose Optimizing Convolutional Neural Network Architecture (OCNNA), a novel CNN optimization and construction method based on pruning and knowledge distillation designed to establish the importance of convolutional layers. The proposal has been evaluated though a thorough empirical study including the best known datasets (CIFAR-10, CIFAR-100 and Imagenet) and CNN architectures (VGG-16, ResNet-50, DenseNet-40 and MobileNet), setting Accuracy Drop and Remaining Parameters Ratio as objective metrics to compare the performance of OCNNA against the other state-of-art approaches. Our method has been compared with more than 20 convolutional neural network simplification algorithms obtaining outstanding results. As a result, OCNNA is a competitive CNN constructing method which could ease the deployment of neural networks into IoT or resource-limited devices.",[],['Spain']
,[],[]
,[],[]
"Cognitive maps are a proposed concept on how the brain efficiently organizes memories and retrieves context out of them. The entorhinal-hippocampal complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place cell dynamics and cognitive map representations. Here, we use multi-modal inputs consisting of images and word embeddings. The network learns the similarities between novel inputs and the training database and therefore the representation of the cognitive map successfully. Subsequently, the prediction of the network can be used to infer from one modality to another with over 90%percent9090\%90 % accuracy. The proposed method could therefore be a building block to improve current AI systems for better understanding of the environment and the different modalities in which objects appear. The association of specific modalities with certain encounters can therefore lead to context awareness in novel situations when similar encounters with less information occur and additional information can be inferred from the learned cognitive map. Cognitive maps, as represented by the entorhinal-hippocampal complex in the brain, organize and retrieve context from memories, suggesting that large language models (LLMs) like ChatGPT could harness similar architectures to function as a high-level processing center, akin to how the hippocampus operates within the cortex hierarchy. Finally, by utilizing multi-modal inputs, LLMs can potentially bridge the gap between different forms of data (like images and words), paving the way for context-awareness and grounding of abstract concepts through learned associations, addressing the grounding problem in AI.",[],['Germany']
"Let ℓℓ\ellroman_ℓ be an odd prime and K𝐾Kitalic_K a field of characteristic different from ℓℓ\ellroman_ℓ. Let K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG be an algebraic closure of K𝐾Kitalic_K. Assume that K𝐾Kitalic_K contains a primitive ℓℓ\ellroman_ℓth root of unity.
Let n≠ℓ𝑛ℓn\neq\ellitalic_n ≠ roman_ℓ be another odd prime.
Let f⁢(x)𝑓𝑥f(x)italic_f ( italic_x ) and h⁢(x)ℎ𝑥h(x)italic_h ( italic_x ) be degree n𝑛nitalic_n polynomials with coefficients in K𝐾Kitalic_K and without repeated roots.
Let us consider superelliptic curves
Cf,ℓ:yℓ=f⁢(x):subscript𝐶𝑓ℓsuperscript𝑦ℓ𝑓𝑥C_{f,\ell}:y^{\ell}=f(x)italic_C start_POSTSUBSCRIPT italic_f , roman_ℓ end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT = italic_f ( italic_x ) and Ch,ℓ:yℓ=h⁢(x):subscript𝐶ℎℓsuperscript𝑦ℓℎ𝑥C_{h,\ell}:y^{\ell}=h(x)italic_C start_POSTSUBSCRIPT italic_h , roman_ℓ end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT = italic_h ( italic_x ) of genus (n−1)⁢(ℓ−1)/2𝑛1ℓ12(n-1)(\ell-1)/2( italic_n - 1 ) ( roman_ℓ - 1 ) / 2, and their jacobians J(f,ℓ)superscript𝐽𝑓ℓJ^{(f,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT and J(h,ℓ)superscript𝐽ℎℓJ^{(h,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT, which are
(n−1)⁢(ℓ−1)/2𝑛1ℓ12(n-1)(\ell-1)/2( italic_n - 1 ) ( roman_ℓ - 1 ) / 2-dimensional abelian varieties over K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG.
Suppose that one of the polynomials is irreducible and the other reducible over K𝐾Kitalic_K.
We prove that if J(f,ℓ)superscript𝐽𝑓ℓJ^{(f,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT and J(h,ℓ)superscript𝐽ℎℓJ^{(h,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT are isogenous over K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG then both endomorphism algebras End0⁢(J(f,ℓ))superscriptEnd0superscript𝐽𝑓ℓ\mathrm{End}^{0}(J^{(f,\ell)})roman_End start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT ) and End0⁢(J(h,ℓ))superscriptEnd0superscript𝐽ℎℓ\mathrm{End}^{0}(J^{(h,\ell)})roman_End start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT )
contain an invertible element of multiplicative order n𝑛nitalic_n.","['superelliptic curves', 'jacobians', 'isogenies of abelian varieties']",[]
"If the extraction of sensor fingerprints represents nowadays an important forensic tool for sensor attribution, it has been shown recently in [1, 2, 3] that images coming from several sensors were more prone to generate False Positives (FP) by presenting a common ”leak”. In this paper, we investigate the possible cause of this leak and after inspecting the EXIF metadata of the sources causing FP, we found out that they were related to the Adobe Lightroom or Photoshop softwares. The cross-correlation between residuals on images presenting FP reveals periodic peaks showing the presence of a periodic pattern. By developing our own images with Adobe Lightroom we are able to show that all developments from raw images (or 16 bits per channel coded) to 8 bits-coded images also embed a periodic 128×128128128128\times 128128 × 128 pattern very similar to a watermark. However, we also show that the watermark depends on both the content and the architecture used to develop the image. The rest of the paper presents two different ways of removing this watermark, one by removing it from the image noise component, and the other by removing it in the pixel domain. We show that for a camera presenting FP in [3], we were able to prevent the False Positives. A discussion with Adobe representatives informed us that the company decided to add this pattern in order to induce dithering.","['PRNU', 'False-Positive', 'Watermarking', 'Watermark', 'Removal']",[]
,[],[]
"In addition to the Standard Model, the introduction of a singlet complex scalar field that acquires vacuum expectation value may give rise to a cosmologically stable pseudo-Nambu-Goldstone boson (pNGB), a suitable dark matter (DM) candidate. This work extends this scenario
by including a second cosmologically stable particle: a fermion singlet. The pNGB and the new fermion can be regarded as DM candidates simultaneously, both interacting with the Standard Model through Higgs portals via two non-degenerate Higgs bosons. We explore the thermal freeze-out of this scenario, with particular emphasis on the increasing yield of the pNGB before it completely decouples (recently called Bouncing DM). We test the model under collider, relic abundance, and direct detection, and we explore the consequences of the yield bouncing on indirect detection observables today.",[],[]
"Recommender systems aim to recommend the most suitable items to users from a large number of candidates. Their computation cost grows as the number of user requests and the complexity of services (or models) increases.
Under the limitation of computation resources (CRs), how to make a trade-off between computation cost and business revenue becomes an essential question.
The existing studies focus on dynamically allocating CRs in queue truncation scenarios (i.e., allocating the size of candidates), and formulate the CR allocation problem as an optimization problem with constraints. Some of them focus on single-phase CR allocation, and others focus on multi-phase CR allocation but introduce some assumptions about queue truncation scenarios. However, these assumptions do not hold in other scenarios, such as retrieval channel selection and prediction model selection. Moreover, existing studies ignore the state transition process of requests between different phases, limiting the effectiveness of their approaches.
This paper proposes a Reinforcement Learning (RL) based Multi-Phase Computation Allocation approach (RL-MPCA), which aims to maximize the total business revenue under the limitation of CRs. RL-MPCA formulates the CR allocation problem as a Weakly Coupled MDP problem and solves it with an RL-based approach. Specifically, RL-MPCA designs a novel deep Q-network to adapt to various CR allocation scenarios, and calibrates the Q-value by introducing multiple adaptive Lagrange multipliers (adaptive-λ𝜆\lambdaitalic_λ) to avoid violating the global CR constraints.
Finally, experiments on the offline simulation environment and online real-world recommender system validate the effectiveness of our approach.","['Computation', 'Resource', 'Allocation', 'Deep', 'Reinforcement', 'Learning', 'Recommender', 'System', 'Weakly', 'Coupled', 'MDP']",['China']
"Spurred by consistent advances and innovation in deep learning, object detection applications have become prevalent, particularly in autonomous driving that leverages various visual data. As convolutional neural networks (CNNs) are being optimized, the performances and computation speeds of object detection in autonomous driving have been significantly improved. However, due to the exponentially rapid growth in the complexity and scale of data used in object detection, there are limitations in terms of computation speeds while conducting object detection solely with classical computing. Motivated by this, quantum convolution-based object detection (QCOD) is proposed to adopt quantum computing to perform object detection at high speed. The QCOD utilizes our proposed fast quantum convolution that uploads input channel information and re-constructs output channels for achieving reduced computational complexity and thus improving performances. Lastly, the extensive experiments with KITTI autonomous driving object detection dataset verify that the proposed fast quantum convolution and QCOD are successfully operated in real object detection applications.","['Quantum', 'Machine', 'Learning', 'Quantum', 'Convolutional', 'Neural', 'Network', 'Object', 'Detection', 'Autonomous', 'Driving']",[]
"We apply a computational modelling approach to investigate the relative effectiveness of general isolation practices for mitigation of COVID-19 outbreaks in residential care facilities. Our study focuses on policies intended to reduce contact between residents, without regard to confirmed infection status. Despite the ubiquity of such policies, and their controversial association with adverse physical and mental health outcomes, little evidence exists evaluating their effectiveness at mitigating outbreaks. Through detailed simulations of COVID-19 outbreaks in residential care facilities, our results demonstrate that general isolation of residents provides little additional impact beyond what is achievable through isolation of confirmed cases and deployment of personal protective equipment.",[],['Australia']
"The shuffle relation among multiple zeta values is algebraically expressed as the shuffle algebra. In this paper, the shuffle algebra structure for multiple zeta values is extended to a Hopf algebra structure, for which the key idea is the lifting of the shuffle multiplication to Chen fractions as the function multiplication. The linear span of Chen fractions can be equipped with a locality Hopf algebra structure, and the pushforward of the coproduct gives us the desired construction on the shuffle algebra.",[],[]
"Defect detection is one of the most important yet challenging tasks in the quality control stage in the manufacturing sector.
In this work, we introduce a Tensor Convolutional Neural Network (T-CNN) and examine its performance on a real defect detection application in one of the components of the ultrasonic sensors produced at Robert Bosch’s manufacturing plants. Our quantum-inspired T-CNN operates on a reduced model parameter space to substantially improve the training speed and performance of an equivalent CNN model without sacrificing accuracy. More specifically, we demonstrate how T-CNNs are able to reach the same performance as classical CNNs as measured by quality metrics, with up to fifteen times fewer parameters and 4%percent44\%4 % to 19%percent1919\%19 % faster training times. Our results demonstrate that the T-CNN greatly outperforms the results of traditional human visual inspection, providing value in a current real application in manufacturing.",[],"['Spain', 'Canada']"
,[],[]
"Effective monitoring of walnut water status and stress level across the whole orchard is an essential step towards precision irrigation management of walnuts, a significant crop in California. This study presents a machine learning approach using Random Forest (RF) models to map stem water potential (SWP) by integrating high-resolution multispectral remote sensing imagery from Unmanned Aerial Vehicle (UAV) flights with weather data. From 2017 to 2018, five flights of an UAV equipped with a seven-band multispectral camera were conducted over a commercial walnut orchard, paired with concurrent ground measurements of sampled walnut plants. The RF regression model, utilizing vegetation indices derived from orthomosaiced UAV imagery and weather data, effectively estimated ground-measured SWPs, achieving an R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.63 and a mean absolute error (MAE) of 0.80 bars. The integration of weather data was particularly crucial for consolidating data across various flight dates. Significant variables for SWP estimation included wind speed and vegetation indices such as NDVI, NDRE, and PSRI. A reduced RF model excluding red-edge indices of NDRE and PSRI, demonstrated slightly reduced accuracy (R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.54). Additionally, the RF classification model predicted water stress levels in walnut trees with 85% accuracy, surpassing the 80% accuracy of the reduced classification model. The results affirm the efficacy of UAV-based multispectral imaging combined with machine learning, incorporating thermal data, NDVI, red-edge indices, and weather data, in walnut water stress estimation and assessment. This methodology offers a scalable, cost-effective tool for data-driven precision irrigation management at an individual plant level in walnut orchards.",[],[]
,[],[]
"The field of few-shot learning (FSL) has shown promising results in scenarios where training data is limited, but its vulnerability to backdoor attacks remains largely unexplored. We first explore this topic by first evaluating the performance of the existing backdoor attack methods on few-shot learning scenarios. Unlike in standard supervised learning, existing backdoor attack methods failed to perform an effective attack in FSL due to two main issues. Firstly, the model tends to overfit to either benign features or trigger features, causing a tough trade-off between attack success rate and benign accuracy. Secondly, due to the small number of training samples, the dirty label or visible trigger in the support set can be easily detected by victims, which reduces the stealthiness of attacks. It seemed that FSL could survive from backdoor attacks. However, in this paper, we propose the Few-shot Learning Backdoor Attack (FLBA) to show that FSL can still be vulnerable to backdoor attacks. Specifically, we first generate a trigger to maximize the gap between poisoned and benign features. It enables the model to learn both benign and trigger features, which solves the problem of overfitting. To make it more stealthy, we hide the trigger by optimizing two types of imperceptible perturbation, namely attractive and repulsive perturbation, instead of attaching the trigger directly. Once we obtain the perturbations, we can poison all samples in the benign support set into a hidden poisoned support set and fine-tune the model on it. Our method demonstrates a high Attack Success Rate (ASR) in FSL tasks with different few-shot learning paradigms while preserving clean accuracy and maintaining stealthiness. This study reveals that few-shot learning still suffers from backdoor attacks, and its security should be given attention.",[],[]
,[],[]
"Currently cryptocurrencies and Decentralized Finance (DeFi), which enable financial services on public blockchains, represents a new growing trend in finance. In contrast to financial markets, ruled by traditional corporations, DeFi is completely transparent as it keeps records of all transactions that occur in the network and makes them publicly available.
The availability of the data represents an opportunity to analyze and understand the market from the complexity that emerges from the interactions of the actors (users, bots and companies) operating in the embedded market. In this paper we focus on the Ethereum network and our main goal is to show that the properties of the underlying transaction network provide further and useful information to forecast the evolution of the market. We aim to separate the non-redundant effects of the blockchain transaction network properties from classic technical indicators and social media trends in the future price of Ethereum. To this end, we build two machine learning models to predict the future trend of the market. The first one serves as a base model and considers a set of the most relevant features according to the current scientific literature—including technical indicators and social media trends. The second model considers the features of the base model, together with the network properties computed from the transaction networks. We found that the full model outperforms the base model and can anticipate 46% more rises in the price than the base model and 19% more falls. Thus, we conclude that indicators based on network properties provide valuable information to forecast the future direction of the market that can not be explained neither by traditional indicators, or social media trends. Hence, our results represent a first step towards a new family of DeFi market indicators based on the complexity of the underlying transaction network.",[],['Spain']
,[],[]
"In the light of S⁢U⁢(3)𝑆𝑈3SU(3)italic_S italic_U ( 3 ) flavor symmetry, the effective interaction Hamiltonian in tensor form is obtained by virtue of group representation theory. The strong and electromagnetic breaking effects are treated as a spurion octet so that the flavor singlet principle can be utilized as the criterion to determine the form of effective Hamiltonian for all charmonium two body decays. Moreover, a synthetical nonet is introduced to include both octet and singlet representations for meson description, and resorting to the mixing angle the pure octet and singlet states are combined into the observable pseudoscalar and vector particles, so that the empirically effective Hamiltonian can be obtained in a concise way. As an application, by virtue of this scenario the relative phase between the strong and electromagnetic amplitudes is studied for vector-pseudoscalar meson final state. In data analysis of samples taken in e+⁢e−superscript𝑒superscript𝑒e^{+}e^{-}italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT collider, the details of experimental effects, such as energy spread and initial state radiative correction are taken into consideration in order to make full use of experimental information and acquire the accurate and delicate results.",[],[]
"Existing music-driven 3D dance generation methods mainly concentrate on high-quality dance generation, but lack sufficient control during the generation process.
To address these issues, we propose a unified framework capable of generating high-quality dance movements and supporting multi-modal control, including genre control, semantic control, and spatial control. First, we decouple the dance generation network from the dance control network, thereby avoiding the degradation in dance quality when adding additional control information. Second, we design specific control strategies for different control information and integrate them into a unified framework.
Experimental results show that the proposed dance generation framework outperforms state-of-the-art methods in terms of motion quality and controllability.",[],[]
"The understanding of the convoluted evolution of infant brain networks during the first postnatal year is pivotal for identifying the dynamics of early brain connectivity development. Thanks to the valuable insights into the brain’s anatomy, existing deep learning frameworks focused on forecasting the brain evolution trajectory from a single baseline observation. While yielding remarkable results, they suffer from three major limitations. First, they lack the ability to generalize to multi-trajectory prediction tasks, where each graph trajectory corresponds to a particular imaging modality or connectivity type (e.g., T1-w MRI). Second, existing models require extensive training datasets to achieve satisfactory performance which are often challenging to obtain. Third, they do not efficiently utilize incomplete time series data. To address these limitations, we introduce FedGmTE-Net++, a federated graph-based multi-trajectory evolution network. Using the power of federation, we aggregate local learnings among diverse hospitals with limited datasets. As a result, we enhance the performance of each hospital’s local generative model, while preserving data privacy. The three key innovations of FedGmTE-Net++ are: (i) presenting the first federated learning framework specifically designed for brain multi-trajectory evolution prediction in a data-scarce environment, (ii) incorporating an auxiliary regularizer in the local objective function to exploit all the longitudinal brain connectivity within the evolution trajectory and maximize data utilization, (iii) introducing a two-step imputation process, comprising a preliminary KNN-based precompletion followed by an imputation refinement step that employs regressors to improve similarity scores and refine imputations. Our comprehensive experimental results showed the outperformance of FedGmTE-Net++ in brain multi-trajectory prediction from a single baseline graph in comparison with benchmark methods. Our source code is available at https://github.com/basiralab/FedGmTE-Net-plus.",[],[]
,[],[]
,[],[]
,[],[]
"The task of Visual Relationship Recognition (VRR) aims to identify relationships between two interacting objects in an image and is particularly challenging due to the widely-spread and highly imbalanced distribution of <<<subject, relation, object>>> triplets. To overcome the resultant performance bias in existing VRR approaches, we introduce DiffAugment – a method which first augments the tail classes in the linguistic space by making use of WordNet and then utilizes the generative prowess of Diffusion Models to expand the visual space for minority classes. We propose a novel hardness-aware component in diffusion which is based upon the hardness of each <<<S,R,O>>> triplet and demonstrate the effectiveness of hardness-aware diffusion in generating visual embeddings for the tail classes. We also propose a novel subject and object based seeding strategy for diffusion sampling which improves the discriminative capability of the generated visual embeddings. Extensive experimentation on the GQA-LT dataset shows favorable gains in the subject/object and relation average per-class accuracy using Diffusion augmented samples.",[],[]
"WiFi Channel State Information (CSI)-based human activity recognition (HAR) enables contactless, long-range sensing in spatially constrained environments while preserving visual privacy. However, despite the presence of numerous WiFi-enabled devices around us, few expose CSI to users, resulting in a lack of sensing hardware options. Variants of the Espressif ESP32 have emerged as potential low-cost and easy-to-deploy solutions for WiFi CSI-based HAR. In this work, four ESP32-S3-based 2.4GHz directional antenna systems are evaluated for their ability to facilitate long-range through-wall HAR. Two promising systems are proposed, one of which combines the ESP32-S3 with a directional biquad antenna. This combination represents, to the best of our knowledge, the first demonstration of such a system in WiFi-based HAR. The second system relies on the built-in printed inverted-F antenna (PIFA) of the ESP32-S3 and achieves directionality through a plane reflector. In a comprehensive evaluation of line-of-sight (LOS) and non-line-of-sight (NLOS) HAR performance, both systems are deployed in an office environment spanning a distance of 18 meters across five rooms. In this experimental setup, the Wallhack1.8k dataset, comprising 1806 CSI amplitude spectrograms of human activities, is collected and made publicly available. Based on Wallhack1.8k, we train activity recognition models using the EfficientNetV2 architecture to assess system performance in LOS and NLOS scenarios. For the core NLOS activity recognition problem, the biquad antenna and PIFA-based systems achieve accuracies of 92.0±plus-or-minus\pm±3.5 and 86.8±plus-or-minus\pm±4.7, respectively, demonstrating the feasibility of long-range through-wall HAR with the proposed systems.","['Human', 'Activity', 'Recognition', 'WiFi', 'Channel', 'State', 'Information', 'Through-Wall', 'Sensing', 'ESP32']",[]
"Nuclear magnetic resonance (NMR) and magnetic resonance imaging (MRI) are versatile tools with broad applications from physics and chemistry to geology and medical studies. In this mini-review, we consider the concepts of NMR and MRI technologies from their fundamental origins to applications in medical science. We start from a quantum mechanical basis and consider the significant importance of NMR and MRI in clinical research. Furthermore, we briefly introduce different types of NMR systems. We also investigate some of the most important applications of MRI techniques to provide valuable methods for visualizing the inside of the body and soft tissues.",[],[]
"While in [16] we studied classes of Fredholm-type operators defined by the homomorphism ΠΠ\Piroman_Π from L⁢(X)𝐿𝑋L(X)italic_L ( italic_X ) onto the Calkin algebra 𝒞⁢(X)𝒞𝑋\mathcal{C}(X)caligraphic_C ( italic_X ), X𝑋Xitalic_X being a Banach space, we study in this paper two classes of Fredholm-type operators defined by the homomorphism π𝜋\piitalic_π from L⁢(X)𝐿𝑋L(X)italic_L ( italic_X ) onto the algebra 𝒞0⁢(X)=L⁢(X)/F0⁢(X),subscript𝒞0𝑋𝐿𝑋subscript𝐹0𝑋\mathcal{C}_{0}(X)=L(X)/F_{0}(X),caligraphic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) = italic_L ( italic_X ) / italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) , where F0⁢(X)subscript𝐹0𝑋F_{0}(X)italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) is the ideal of finite rank operators in L⁢(X).𝐿𝑋L(X).italic_L ( italic_X ) . Then we define an index for Fredholm-type operators and we show that this new index satisfies similar properties as the usual Fredholm index.",[],[]
"Neural implicit fields, such as the neural signed distance field (SDF) of a shape, have emerged as a powerful representation for many applications, e.g., encoding a 3D shape and performing collision detection. Typically, implicit fields are encoded by Multi-layer Perceptrons (MLP) with positional encoding (PE) to capture high-frequency geometric details. However, a notable side effect of such PE-equipped MLPs is the noisy artifacts present in the learned implicit fields. While increasing the sampling rate could in general mitigate these artifacts, in this paper we aim to explain this adverse phenomenon through the lens of Fourier analysis. We devise a tool to determine the appropriate sampling rate for learning an accurate neural implicit field without undesirable side effects. Specifically, we propose a simple yet effective method to estimate the intrinsic frequency of a given network with randomized weights based on the Fourier analysis of the network’s responses. It is observed that a PE-equipped MLP has an intrinsic frequency much higher than the highest frequency component in the PE layer. Sampling against this intrinsic frequency following the Nyquist-Sannon sampling theorem allows us to determine an appropriate training sampling rate. We empirically show in the setting of SDF fitting that this recommended sampling rate is sufficient to secure accurate fitting results, while further increasing the sampling rate would not further noticeably reduce the fitting error. Training PE-equipped MLPs simply with our sampling strategy leads to performances superior to the existing methods.","['SDF', 'neural representation', 'positional encoding', 'Fourier analysis', 'spectrum analysis', 'neural network.']",[]
"Dempster-Shafer Theory (DST) as an effective and robust framework for handling uncertain information is applied in decision-making and pattern classification. Unfortunately, its real-time application is limited by the exponential computational complexity. People attempt to address the issue by taking advantage of its mathematical consistency with quantum computing to implement DST operations on quantum circuits and realize speedup. However, the progress so far is still impractical for supporting large-scale DST applications. In this paper, we find that Boolean algebra as an essential mathematical tool bridges the definition of DST and quantum computing. Based on the discovery, we establish a flexible framework mapping any set-theoretically defined DST operations to corresponding quantum circuits for implementation. More critically, this new framework is not only uniform but also enables exponential acceleration for computation and is capable of handling complex applications. Focusing on tasks of classification, we based on a classical attribute fusion algorithm putting forward a quantum evidential classifier, where quantum mass functions for attributes are generated with a simple method and the proposed framework is applied for fusing the attribute evidence. Compared to previous methods, the proposed quantum classifier exponentially reduces the computational complexity to linear. Tests on real datasets validate the feasibility.","['Dempster-Shafer', 'Theory', 'Quantum circuit', 'Classification', 'Information fusion', 'Quantum computing.']",[]
"A new variant of Newton’s method - named Backtracking New Q-Newton’s method (BNQN) - which has strong theoretical guarantee, is easy to implement, and has good experimental performance, was recently introduced by the third author.
Experiments performed previously showed some remarkable properties of the basins of attractions for finding roots of polynomials and meromorphic functions, with BNQN. In general, they look more smooth than that of Newton’s method.
In this paper, we continue to experimentally explore in depth this remarkable phenomenon, and connect BNQN to Newton’s flow and Voronoi’s diagram. This link poses a couple of challenging puzzles to be explained. Experiments also indicate that BNQN is more robust against random perturbations than Newton’s method and Random Relaxed Newton’s method.",[],[]
,[],[]
"Land use / land cover (LULC) modeling is a challenging task due to long-range dependencies between geographic features and distinct spatial patterns related to topography, ecology, and human development. We identify a strong connection between modeling spatial patterns of land use and the task of image inpainting from computer vision, and conduct a study of a modified PixelCNN architecture with approximately 19 million parameters for modeling LULC. Compared with a benchmark spatial statistical model, we find that the former is capable of capturing much richer spatial correlation patterns such as roads and water bodies but does not produce a calibrated predictive distribution, suggesting the need for further tuning. We find evidence of predictive underdispersion with regard to important ecologically-relevant land use statistics such as patch count and adjacency, which can be mitigated to some extent by manipulating sampling variability.",[],[]
"In this paper we present some extensions of recent noncentral moderate deviation results in the literature.
In the first part we generalize the results in [1] by considering a general Lévy process
{S⁢(t):t≥0}conditional-set𝑆𝑡𝑡0\{S(t):t\geq 0\}{ italic_S ( italic_t ) : italic_t ≥ 0 } instead of a compound Poisson process. In the second part we assume that {S⁢(t):t≥0}conditional-set𝑆𝑡𝑡0\{S(t):t\geq 0\}{ italic_S ( italic_t ) : italic_t ≥ 0 }
has bounded variation and it is not a subordinator; thus, in some sense, we have the difference of two independent
non-null subordinators. In this way we generalize the results in [7] for Skellam processes.
 
Keywords: large deviations, weak convergence, Mittag-Leffler function, tempered stable subordinators.
2000 Mathematical Subject Classification: 60F10, 60F05, 60G22, 33E12.",[],[]
,[],[]
"Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process – mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to “get stuck,” which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than >100absent100>100> 100k alternatives within 100 or fewer expensive queries.",[],[]
"We present 3D fully kinetic shearing-box (SB) simulations of pair-plasma magnetorotational turbulence with unprecedented macro-to-microscopic scale separation. We retrieve the expected fluid-model behavior of turbulent magnetic fields and angular-momentum transport, and observe fundamental differences in turbulent fluctuation spectra linked with plasma heating. For the first time, we provide a definitive demonstration of nonthermal particle acceleration in kinetic magnetorotational turbulence agnostically of SB initial conditions, by means of a novel strategy exploiting synchrotron cooling.",[],['Belgium']
,[],[]
"In this work, we use the term “quantum chaos” to refer to spectral correlations similar to those found in random matrix theory. Quantum chaos can be diagnosed through the analysis of level statistics using the spectral form factor, which detects both short- and long-range level correlations. The spectral form factor corresponds to the Fourier transform of the two-point spectral correlation function and exhibits a typical slope-dip-ramp-plateau structure (aka correlation hole) when the system is chaotic. We discuss how this structure could be detected through the dynamics of two physical quantities accessible to experimental many-body quantum systems: the survival probability and the spin autocorrelation function. When the system is small, the dip reaches values that are large enough at times which are short enough to be detected with current experimental platforms and commercially available quantum computers.",[],"['Spain', 'Mexico', 'India', 'Luxembourg']"
"We show here that numerous examples abound where changing topology does not necessarily close the bulk insulating charge gap as demanded in the standard non-interacting picture. From extensive determinantal and dynamical cluster quantum Monte Carlo simulations of the half-filled and quarter-filled Kane-Mele-Hubbard model, we show that for sufficiently strong interactions at either half- or quarter-filling, a transition between topological and trivial insulators occurs without the closing of a charge gap. To shed light on this behavior, we illustrate that an exactly solvable model reveals that while the single-particle gap remains, the many-body gap does in fact close. These two gaps are the same in the non-interacting system but depart from each other as the interaction turns on. We purport that for interacting systems, the proper probe of topological phase transitions is the closing of the many-body rather than the single-particle gap.",[],[]
"Most tidal disruption events (TDEs) are currently found in time-domain optical and soft X-ray surveys, both of which are prone to significant obscuration. The infrared (IR), however, is a powerful probe of dust-enshrouded environments, and hence, we recently performed a systematic search of NEOWISE mid-IR data for nearby, obscured TDEs within roughly 200 Mpc. We identified 18 TDE candidates in galactic nuclei, using difference imaging to uncover nuclear variability amongst significant host galaxy emission. These candidates were selected based on the following IR light curve properties: (1) LW2≳1042greater-than-or-equivalent-tosubscript𝐿W2superscript1042L_{\mathrm{W2}}\gtrsim 10^{42}italic_L start_POSTSUBSCRIPT W2 end_POSTSUBSCRIPT ≳ 10 start_POSTSUPERSCRIPT 42 end_POSTSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT at peak, (2) fast rise, followed by a slow, monotonic decline, (3) no significant prior variability, and (4) no evidence for AGN activity in WISE colors. The majority of these sources showed no variable optical counterpart, suggesting that optical surveys indeed miss numerous obscured TDEs. Using narrow line ionization levels and variability arguments, we identified 6 sources as possible underlying AGN, yielding a total of 12 TDEs in our gold sample. This gold sample yields a lower limit on the IR-selected TDE rate of 2.0±0.3×10−5plus-or-minus2.00.3superscript1052.0\pm 0.3\times 10^{-5}2.0 ± 0.3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT galaxy−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT year−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT (1.3±0.2×10−7plus-or-minus1.30.2superscript1071.3\pm 0.2\times 10^{-7}1.3 ± 0.2 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT Mpc−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT year−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT), which is comparable to optical and X-ray TDE rates. The IR-selected TDE host galaxies do not show a green valley overdensity nor a preference for quiescent, Balmer strong galaxies, which are both overrepresented in optical and X-ray TDE samples. This IR-selected sample represents a new population of dusty TDEs that have historically been missed by optical and X-ray surveys and helps alleviate tensions between observed and theoretical TDE rates and the so-called missing energy problem.","['Accretion (14)', 'Supermassive black holes (1663)', 'Tidal disruption (1696)', 'Transient sources (1851)', 'Time domain astronomy (2109)']","['Germany', 'Netherlands', 'Israel']"
"Network reconstruction consists in determining the unobserved pairwise
couplings between N𝑁Nitalic_N nodes given only observational data on the resulting
behavior that is conditioned on those couplings — typically a time-series or
independent samples from a graphical model. A major obstacle to the
scalability of algorithms proposed for this problem is a seemingly unavoidable
quadratic complexity of O⁢(N2)𝑂superscript𝑁2O(N^{2})italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), corresponding to the requirement of each
possible pairwise coupling being contemplated at least once, despite the fact
that most networks of interest are sparse, with a number of non-zero couplings
that is only O⁢(N)𝑂𝑁O(N)italic_O ( italic_N ). Here we present a general algorithm applicable to a broad
range of reconstruction problems that achieves its result in subquadratic
time, with a data-dependent complexity loosely upper bounded by
O⁢(N3/2⁢log⁡N)𝑂superscript𝑁32𝑁O(N^{3/2}\log N)italic_O ( italic_N start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT roman_log italic_N ), but with a more typical log-linear complexity of
O⁢(N⁢log2⁡N)𝑂𝑁superscript2𝑁O(N\log^{2}N)italic_O ( italic_N roman_log start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_N ). Our algorithm relies on a stochastic second neighbor search
that produces the best edge candidates with high probability, thus bypassing
an exhaustive quadratic search. In practice, our algorithm achieves a
performance that is many orders of magnitude faster than the quadratic
baseline, allows for easy parallelization, and thus enables the reconstruction
of networks with hundreds of thousands and even millions of nodes and edges.",[],['Austria']
"Does Donald Trump speak differently from other presidents? If so, in what ways? Are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Trump’s speech patterns diverge from those of all major party nominees for the presidency in recent history. Some notable findings include Trump’s employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. Furthermore, Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values are comparably closer to those of the Democrats. These differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular time trends.",[],[]
,[],[]
"It is common to observe a notable non-monotonic dependence of thermal conductivity on applied magnetic field in magnetic insulators. This prevalent behavior prompts the need for an explanation involving components present in a wide range of systems. We report the field-dependence of thermal conductivity in the well-characterized effective spin-1/2 paramagnetic insulator CsYbSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT. Along with the data, we propose that the observed non-monotonic field dependence results from the hybridization of acoustic phonons with spin-flip excitations across the Zeeman gap, where the magnetoelastic coupling arises via modulation of the magnetic g𝑔gitalic_g-tensor by local strain.
This hypothesis aligns with a simple theoretical model that qualitatively reproduces key features of the data on CsYbSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT. Our results provide a starting point to understand the magnetic field dependence of thermal conductivity in a broad spectrum of magnetic insulators.",[],[]
"Multi-cloud systems facilitate a cost-efficient and geographically-distributed deployment of microservice-based applications by temporary leasing virtual nodes with diverse pricing models. To preserve the cost-efficiency of multi-cloud deployments, it is essential to redeploy microservices onto the available nodes according to a dynamic resource configuration, which is often performed to better accommodate workload variations.
However, this approach leads to frequent service disruption since applications are continuously shutdown and redeployed in order to apply the new resource assignment. To overcome this issue, we propose a re-orchestration scheme that migrates microservice at runtime based on a rolling update scheduling logic. Specifically, we propose an integer linear optimization problem that minimizes the cost associated to multi-cloud virtual nodes and that ensures that delay-sensitive microservices are co-located on the same regional cluster. The resulting rescheduling order guarantees no service disruption by repacking microservices between the available nodes without the need to turn off the outdated microservice instance before redeploying the updated version. In addition, we propose a two-step heuristic scheme that effectively approximates the optimal solution at the expense of close-to-zero service disruption and QoS violation probability. Results show that proposed schemes achieve better performance in terms of cost mitigation, low service disruption and low QoS violation probability compared to baseline schemes replicating Kubernetes scheduler functionalities.","['Microservice re-orchestration', 'cost minimization', 'resource allocation', 'multi-cloud systems', 'optimization']",[]
,[],[]
"We study the inclusive production of hadrons with bottom flavor at the LHC and its luminosity upgrade.
We describe the collinear fragmentation of singly b𝑏bitalic_b-flavored hadrons, B𝐵Bitalic_B mesons and ΛbsubscriptΛ𝑏\Lambda_{b}roman_Λ start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT baryons, via the KKSS07 determination of fragmentation functions, while for charmed B𝐵Bitalic_B mesons, Bc(1S0)B_{c}(^{1}S_{0})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and Bc(3S1)B_{c}(^{3}S_{1})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) particles, we employ the novel ZCFW22 set, built on the basis of state-of-the-art nonrelativistic QCD inputs.
We use the Jethad multimodular working environment to analyze rapidity and transverse-momentum distributions for observables sensitive to the associated emission of two hadrons or a hadron-plus-jet system.
Our reference formalism is the NLL/NLO+NLLsuperscriptNLO{\rm NLL/NLO^{+}}roman_NLL / roman_NLO start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT hybrid collinear and high-energy factorization, where the standard collinear description is improved by the inclusions of energy logarithms resummed up to the next-to-leading approximation and beyond.
We provide a corroborating evidence that b𝑏bitalic_b-flavor emissions act as fair stabilizers of the high-energy resummation, thus serving as valuable tools for precision studies of high-energy QCD.
As a bonus, we highlight that the predicted production-rate hierarchy between noncharmed b𝑏bitalic_b-hadrons and charmed Bc(1S0)B_{c}(^{1}S_{0})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) mesons is in line with recent LHCb estimates.
This serves as simultaneous benchmark both for the hybrid factorization and the single-parton fragmentation mechanism from the nonrelativistic QCD effective theory.",[],[]
,[],[]
"The evolution of the temperature dependence of pseudogap
ΔΔ\Deltaroman_Δ*(T) in optimally doped (OD) YBa22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTO7−δ7𝛿{}_{7-\delta}start_FLOATSUBSCRIPT 7 - italic_δ end_FLOATSUBSCRIPT
(YBCO) films with Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 88.7 K under the influence of a magnetic
field B𝐵Bitalic_B up to 8 T has been studied in detail. It has been
established that the shape of ΔΔ\Deltaroman_Δ*(T) for various B𝐵Bitalic_B over the
entire range from the pseudogap opening temperature T𝑇Titalic_T* to
T01subscript𝑇01T_{01}italic_T start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT, below which superconducting fluctuations occur, has a wide
maximum at the BEC-BCS crossover temperature Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT, which is
typical for OD films and untwinned YBCO single crystals. T𝑇Titalic_T* was
shown to be independent on B𝐵Bitalic_B, whereas Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT shifts to the low
temperature region along with increase of B𝐵Bitalic_B, while the maximum
value of ΔΔ\Deltaroman_Δ*(Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT) remains practically constant
regardless of B𝐵Bitalic_B. It was revealed that as the field increases, the
low-temperature maximum near the 3D-2D transition temperature
T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is blurred and disappears at B𝐵Bitalic_B > 5 T. Moreover, above the
Ginzburg temperature TGsubscript𝑇𝐺T_{G}italic_T start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, which limits superconducting
fluctuations from below, at B𝐵Bitalic_B > 0.5 T, a minimum appears on
ΔΔ\Deltaroman_Δ*(T) at Tm⁢i⁢nsubscript𝑇𝑚𝑖𝑛T_{min}italic_T start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT, which becomes very pronounced with a
further increase in the field. As a result, the overall value of
ΔΔ\Deltaroman_Δ*(T) decreases noticeably most likely due to pair-breaking
affect of a magnetic field. A comparison of ΔΔ\Deltaroman_Δ*(T) near
Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT with the Peters-Bauer theory shows that the density of
fluctuating Cooper pairs actually decreases from <n↑↑{}_{\uparrow}start_FLOATSUBSCRIPT ↑ end_FLOATSUBSCRIPTn↓↓{}_{\downarrow}start_FLOATSUBSCRIPT ↓ end_FLOATSUBSCRIPT> ≈\approx≈
0.31 at B𝐵Bitalic_B = 0 to <n↑↑{}_{\uparrow}start_FLOATSUBSCRIPT ↑ end_FLOATSUBSCRIPTn↓↓{}_{\downarrow}start_FLOATSUBSCRIPT ↓ end_FLOATSUBSCRIPT> ≈\approx≈
0.28 in the field 8 T. The observed behavior of ΔΔ\Deltaroman_Δ*(T) around
Tm⁢i⁢nsubscript𝑇𝑚𝑖𝑛T_{min}italic_T start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT is assumed to be due to the influence of a two-dimensional
vortex lattice created by the magnetic field, which prevents the
formation of fluctuating Cooper pairs near Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT.
Keywords: high-temperature superconductors, YBCO films, excess
conductivity, fluctuation conductivity, pseudogap, magnetic field,
coherence length.",[],['Poland']
"Visual attribution in medical imaging seeks to make evident the diagnostically-relevant components of a medical image, in contrast to the more common detection of diseased tissue deployed in standard machine vision pipelines (which are less straightforwardly interpretable/explainable to clinicians).

We here present a novel generative visual attribution technique, one that leverages latent diffusion models in combination with domain-specific large language models, in order to generate normal counterparts of abnormal images. The discrepancy between the two hence gives rise to a mapping indicating the diagnostically-relevant image components.
To achieve this, we deploy image priors in conjunction with appropriate conditioning mechanisms in order to control the image generative process, including natural language text prompts acquired from medical science and applied radiology. We perform experiments and quantitatively evaluate our results on the COVID-19 Radiography Database containing labelled chest X-rays with differing pathologies via the Frechet Inception Distance (FID), Structural
Similarity (SSIM) and Multi Scale Structural Similarity Metric (MS-SSIM) metrics obtained between real and generated images.
The resulting system also exhibits a range of latent capabilities including zero-shot localized disease induction, which are evaluated with real examples from the cheXpert dataset.",[],['Pakistan']
"Context:Twenty-two extragalactic fast X-ray transients (FXTs) have now been discovered from two decades of Chandra data (analyzing ∼similar-to{\sim}∼259 Ms of data), with 17 associated with distant galaxies (≳greater-than-or-equivalent-to{\gtrsim}≳100 Mpc). Different mechanisms and progenitors have been proposed to explain their properties; nevertheless, after analyzing their timing, spectral parameters, host-galaxy properties, luminosity function, and volumetric rates, their nature remains uncertain.
Aims:We interpret a sub-sample of nine FXTs that show a plateau or a fast-rise light curve within the framework of a binary neutron star (BNS) merger magnetar model.
Methods:We fit their light curves and derive magnetar (magnetic field and initial rotational period) and ejecta (ejecta mass and opacity) parameters. This model predicts two zones: an orientation-dependent free zone (where the magnetar spin-down X-ray photons escape freely to the observer) and a trapped zone (where the X-ray photons are initially obscured and only escape freely once the ejecta material becomes optically thin). We argue that six FXTs show properties consistent with the free zone and three FXTs with the trapped zone.
Results:This sub-sample of FXTs has a similar distribution of magnetic fields and initial rotation periods to those inferred for short gamma-ray bursts (SGRBs), suggesting a possible association.
We compare the predicted ejecta emission fed by the magnetar emission (called merger-nova) to the optical and near-infrared upper limits of two FXTs, XRT 141001 and XRT 210423 where contemporaneous optical observations are available. The non-detections place lower limits on the redshifts of XRT 141001 and XRT 210423 of z≳1.5greater-than-or-equivalent-to𝑧1.5z{\gtrsim}1.5italic_z ≳ 1.5 and ≳0.1greater-than-or-equivalent-toabsent0.1{\gtrsim}0.1≳ 0.1, respectively.
Conclusions:If the magnetar remnants lose energy via gravitational waves (GWs), it should be possible to detect similar objects with the current advanced LIGO detectors out to a redshift z≲0.03less-than-or-similar-to𝑧0.03z{\lesssim}0.03italic_z ≲ 0.03, while future GW detectors will be able to detect them out to z≈0.5𝑧0.5z{\approx}0.5italic_z ≈ 0.5.","['X-ray: general –', 'X-ray: bursts –', 'X-ray: magnetars']",[]
,[],[]
"In this article, we demonstrate how black hole quasi-normal modes can emerge from a Dirichlet brickwall model normal modes. We consider a probe scalar field in a BTZ-geometry with a Dirichlet brickwall and demonstrate that as the wall approaches the event horizon, the corresponding poles in the retarded correlator become dense and yield an effective branch-cut. The associated discontinuity of the correlator carries the information of the black hole quasi-normal modes. We further demonstrate that a non-vanishing angular momentum non-perturbatively enhances the pole-condensing. We hypothesize that it is also related to quantum chaotic features of the corresponding spectral form factor, which has been observed earlier. Finally we discuss the underlying algebraic justification of this approximate thermalization in terms of the trace of the algebra.",[],"['Germany', 'India']"
,[],[]
"We conduct a large-scale fine-grained comparative analysis
of machine translations (MT) against human translations (HT) through
the lens of morphosyntactic divergence.
Across three language pairs and two types of divergence
defined as the structural difference between the source and the target,
MT is consistently more conservative than HT, with less morphosyntactic diversity, more convergent patterns, and more one-to-one alignments.
Through analysis on different decoding algorithms,
we attribute this discrepancy to the use of beam search
that biases MT towards more convergent patterns.
This bias is most amplified when the convergent pattern appears around 50% of the time in training data.
Lastly, we show that for a majority of morphosyntactic divergences,
their presence in HT is
correlated with decreased MT performance, presenting a greater challenge for MT systems.",[],[]
"For a group G𝐺Gitalic_G and a positive integer n𝑛nitalic_n write Bn⁢(G)={x∈G:|xG|≤n}subscript𝐵𝑛𝐺conditional-set𝑥𝐺superscript𝑥𝐺𝑛B_{n}(G)=\{x\in G:|x^{G}|\leq n\}italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_G ) = { italic_x ∈ italic_G : | italic_x start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT | ≤ italic_n }. If s≥1𝑠1s\geq 1italic_s ≥ 1 and w𝑤witalic_w is a group word, say that G𝐺Gitalic_G satisfies the
(n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word w𝑤witalic_w if there exists a subset S⊆G𝑆𝐺S\subseteq Gitalic_S ⊆ italic_G such that |S|≤s𝑆𝑠|S|\leq s| italic_S | ≤ italic_s and all w𝑤witalic_w-values of G𝐺Gitalic_G are contained in Bn⁢(G)⁢Ssubscript𝐵𝑛𝐺𝑆B_{n}(G)Sitalic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_G ) italic_S. In a natural way, this condition emerged in the study of probabilistically nilpotent groups of class two. In this paper we obtain the following results.


Let w𝑤witalic_w be a multilinear commutator word on k𝑘kitalic_k variables and let G𝐺Gitalic_G be a group satisfying the (n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word w𝑤witalic_w. Then G𝐺Gitalic_G has a soluble subgroup T𝑇Titalic_T such that [G:T]delimited-[]normal-:𝐺𝑇[G:T][ italic_G : italic_T ] and the derived length of T𝑇Titalic_T are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded. (Theorem 1.1.)


Let k≥1𝑘1k\geq 1italic_k ≥ 1 and G𝐺Gitalic_G be a group satisfying the (n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word γksubscript𝛾𝑘\gamma_{k}italic_γ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Then (1)
γ2⁢k−1⁢(G)subscript𝛾2𝑘1𝐺\gamma_{2k-1}(G)italic_γ start_POSTSUBSCRIPT 2 italic_k - 1 end_POSTSUBSCRIPT ( italic_G ) has a subgroup T𝑇Titalic_T such that [γ2⁢k−1⁢(G):T]delimited-[]normal-:subscript𝛾2𝑘1𝐺𝑇[\gamma_{2k-1}(G):T][ italic_γ start_POSTSUBSCRIPT 2 italic_k - 1 end_POSTSUBSCRIPT ( italic_G ) : italic_T ] and |T′|superscript𝑇normal-′|T^{\prime}|| italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded; and (2) G𝐺Gitalic_G has a nilpotent subgroup U𝑈Uitalic_U such that [G:U]delimited-[]normal-:𝐺𝑈[G:U][ italic_G : italic_U ] and the nilpotency class of U𝑈Uitalic_U are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded. (Theorem 1.2.)","['conjugacy classes', 'word values', 'nilpotent groups']",[]
"In this paper we continue investigating connections between Floer
theory and dynamics of Hamiltonian systems, focusing on the barcode
entropy of Reeb flows. Barcode entropy is the exponential growth
rate of the number of not-too-short bars in the Floer or symplectic
homology persistence module. The key novel result is that the
barcode entropy is bounded from below by the topological entropy of
any hyperbolic invariant set. This, combined with the fact that the
topological entropy bounds the barcode entropy from above,
established by Fender, Lee and Sohn, implies that in dimension three
the two types of entropy agree. The main new ingredient of the proof
is a variant of the Crossing Energy Theorem for Reeb flows.","['Periodic orbits', 'Reeb flows', 'Floer homology', 'topological\nentropy', 'barcode entropy', 'persistence modules']",[]
"Linear-Quadratic (LQ) problems that arise in systems and controls include the classical optimal control problems of the Linear Quadratic Regulator (LQR) in both its deterministic and stochastic forms, as well as 𝖧∞superscript𝖧{\sf H}^{\infty}sansserif_H start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT-analysis (the Bounded Real Lemma), the Positive Real Lemma, and general Integral Quadratic Constraints (IQCs) tests. We present a unified treatment of all of these problems using an approach which converts linear-quadratic problems to matrix-valued linear-linear problems with a positivity constraint. This is done through a system representation where the joint state/input covariance (the outer product in the deterministic case) matrix is the fundamental object. LQ problems then become infinite-dimensional semidefinite programs, and the key tool used is that of linear-conic duality. Linear Matrix Inequalities (LMIs) emerge naturally as conal constraints on dual problems. Riccati equations characterize extrema of these special LMIs, and therefore provide solutions to the dual problems. The state-feedback structure of all optimal signals in these problems emerge out of alignment (complementary slackness) conditions between primal and dual problems. Perhaps the new insight gained from this approach is that first LMIs, and then second, Riccati equations arise naturally in dual, rather than primal problems. Furthermore, while traditional LQ problems are set up in 𝖫2superscript𝖫2{\sf L}^{2}sansserif_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT spaces of signals, their equivalent covariance-representation problems are most naturally set up in 𝖫1superscript𝖫1{\sf L}^{1}sansserif_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT spaces of matrix-valued signals.",[],[]
"Starting from the Kirchhoff-Huygens representation and Duhamel’s principle of time-domain wave equations, we propose novel butterfly-compressed Hadamard integrators for self-adjoint wave equations in both time and frequency domain in an inhomogeneous medium. First, we incorporate the leading term of Hadamard’s ansatz into the Kirchhoff-Huygens representation to develop a short-time valid propagator. Second, using the Fourier transform in time, we derive the corresponding Eulerian short-time propagator in frequency domain; on top of this propagator, we further develop a time-frequency-time (TFT) method for the Cauchy problem of time-domain wave equations. Third, we further propose the time-frequency-time-frequency (TFTF) method for the corresponding point-source Helmholtz equation, which provides Green’s functions of the Helmholtz equation for all angular frequencies within a given frequency band. Fourth, to implement TFT and TFTF methods efficiently, we introduce butterfly algorithms to compress oscillatory integral kernels at different frequencies. As a result, the proposed methods can construct wave field beyond caustics implicitly and advance spatially overturning waves in time naturally with quasi-optimal computational complexity and memory usage. Furthermore, once constructed the Hadamard integrators can be employed to solve both time-domain wave equations with various initial conditions and frequency-domain wave equations with different point sources. Numerical examples for two-dimensional wave equations illustrate the accuracy and efficiency of the proposed methods.","['Time-dependent wave equation', 'Helmholtz equationHigh frequency wave', 'Hadamard’s ansatz', 'Butterfly algorithm', 'Caustics']",[]
"Information aging has gained prominence in characterizing communication protocols for timely remote estimation and control applications. This work proposes an Age of Information (AoI)-aware threshold-based dynamic frame slotted ALOHA (T-DFSA) for contention resolution in random access machine-type communication networks. Unlike conventional DFSA that maximizes the throughput in each frame, the frame length and age-gain threshold in T-DFSA are determined to minimize the normalized average AoI reduction of the network in each frame. At the start of each frame in the proposed protocol, the common Access Point (AP) stores an estimate of the age-gain distribution of a typical node. Depending on the observed status of the slots, age-gains of successful nodes, and maximum available AoI, the AP adjusts its estimation in each frame. The maximum available AoI is exploited to derive the maximum possible age-gain at each frame and thus, to avoid overestimating the age-gain threshold, which may render T-DFSA unstable. Numerical results validate our theoretical analysis and demonstrate the effectiveness of the proposed T-DFSA compared to the existing optimal frame slotted ALOHA, threshold-ALOHA, and age-based thinning protocols in a considerable range of update generation rates.","['Age of information', 'random access', 'dynamic frame slotted', 'ALOHA', 'Internet of', 'Things', 'stochastic arrivals.']",[]
"This paper investigates the high-level decision-making problem in highway scenarios regarding lane changing and over-taking other slower vehicles. In particular, this paper aims to improve the Travel Assist feature for automatic overtaking and lane changes on highways. About 9 million samples including lane images and other dynamic objects are collected in simulation. This data; Overtaking on Simulated HighwAys (OSHA) dataset is released to tackle this challenge. To solve this problem, an architecture called SwapTransformer is designed and implemented as an imitation learning approach on the OSHA dataset. Moreover, auxiliary tasks such as future points and car distance network predictions are proposed to aid the model in better understanding the surrounding environment. The performance of the proposed solution is compared with a multi-layer perceptron (MLP) and multi-head self-attention networks as baselines in a simulation environment. We also demonstrate the performance of the model with and without auxiliary tasks. All models are evaluated based on different metrics such as time to finish each lap, number of overtakes, and speed difference with speed limit. The evaluation shows that the SwapTransformer model outperforms other models in different traffic densities in the inference phase.",[],[]
"Pearl’s causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a deep causal generative model, which utilizes the pre-trained model and can provably sample from identifiable interventional and counterfactual distributions. Our algorithm, called Modular-DCM, uses adversarial training to learn the network weights, and to the best of our knowledge, is the first algorithm that can make use of pre-trained models and provably sample from any identifiable causal query in the presence of latent confounders with high-dimensional data. We demonstrate the utility of our algorithm using semi-synthetic and real-world datasets containing images as variables in the causal structure.",[],[]
"In this note, we use recent advances concerning the K-stability of ℚℚ\mathbb{Q}blackboard_Q-Fano varieties to provide settings for which Vojta’s conjecture holds.","['Vojta’s conjecture', 'K-stability', 'Fano varieties']",[]
"We prove that in a theory T𝑇Titalic_T stable over a predicate P𝑃Pitalic_P, for any λ>|T|𝜆𝑇\lambda>|T|italic_λ > | italic_T |, there is a λ𝜆\lambdaitalic_λ-prime model over any complete set A𝐴Aitalic_A with a λ𝜆\lambdaitalic_λ-saturated P𝑃Pitalic_P-part.",[],[]
,[],[]
,[],[]
,[],[]
"Multiple access (MA) is a crucial part of any wireless system and refers to techniques that make use of the resource dimensions (e.g., time, frequency, power, antenna, code, message, etc) to serve multiple users/devices/machines/services, ideally in the most efficient way. Given the increasing needs of multi-functional wireless networks for integrated communications, sensing, localization, computing, coupled with the surge of machine learning / artificial intelligence (AI) in wireless networks, MA techniques are expected to experience a paradigm shift in 6G and beyond. In this paper, we provide a tutorial, survey and outlook of past, emerging and future MA techniques and pay a particular attention to how wireless network intelligence and multi-functionality will lead to a re-thinking of those techniques. The paper starts with an overview of orthogonal, physical layer multicasting, space domain, power domain, rate-splitting, code domain MAs, and MAs in other domains, and highlight the importance of researching universal multiple access to shrink instead of grow the knowledge tree of MA schemes by providing a unified understanding of MA schemes across all resource dimensions. It then jumps into rethinking MA schemes in the era of wireless network intelligence, covering AI for MA such as AI-empowered resource allocation, optimization, channel estimation, receiver designs, user behavior predictions for different MA schemes, and MA for AI such as federated learning/edge intelligence and over the air computation. We then discuss MA for network multi-functionality and the interplay between MA and integrated
sensing, localization, and communications, covering MA for joint sensing and communications, multimodal sensing-aided communications, multimodal sensing and digital twin-assisted communications, and communication-aided sensing/localization systems. We finish with studying MA for emerging intelligent applications such as semantic communications, metaverse, virtual reality, smart radio and reconfigurable intelligent surfaces, and massive connectivity and random access in Internet-of-Things, before presenting a roadmap toward 6G standardization. Throughout the text, we also point out numerous directions that are promising for future research.","['Multiple', 'Access', 'Orthogonal', 'Multiple', 'Access', 'Non-Orthogonal', 'Multiple', 'Access', 'Space', 'Division', 'Multiple', 'Access', 'Code', 'Domain', 'Multiple', 'Access', 'Rate-Splitting', 'Multiple', 'Access', 'Universal', 'Multiple', 'Access', 'Artificial', 'Intelligence', 'Machine', 'Learning', 'Integrated', 'Sensing and', 'Communications', 'Semantic', 'Communications', 'Reconfigurable', 'Intelligent', 'Surfaces', 'Metaverse', 'Augmented', 'Reality', 'Internet-of-Things', '6G.']",[]
,[],[]
,[],[]
"Active fluid transport is a hallmark of many biological transport networks. While
animal circulatory systems generally rely on a single heart to drive flows,
other organisms employ decentralized local pumps to distribute fluids and nutrients.
Here, we study the decentralized pumping mechanism
in the slime mold Physarum polycephalum which is locally triggered by
active release, uptake, and transport of a chemical solute within the
organism’s vascular network to drive global oscillations.
Based on a conceptual network model combining active elasticity and
fluid transport we identify a set of contractile modes specific to each network and show that modes corresponding
to large-scale oscillations are preferentially and robustly excited both
in model simulations and
in experimental data obtained from living Physarum plasmodia. These dominant
modes are computed explicitly and shown to drive large-scale flows within the
organism.
Furthermore, Physarum must transport nutrients over long distances.
As each mode corresponds to pure shuttle flow, long-range, directed transport
must rely on a non-linear coupling beyond harmonic dynamics. Using simulations,
we demonstrate that the network’s transport capability is optimized when two
dominant modes are excited at a phase shift of π/2𝜋2\pi/2italic_π / 2, resulting in contractile
excitations similar to those observed in real Physarum.
Our results provide a conceptual framework for understanding active
decentralized transport in Physarum and other contractile
biological networks, such as brain vasculature, as well as decentralized transportation
networks more generally.",[],[]
,[],[]
,[],[]
"LiDAR is used in autonomous driving to provide 3D spatial information and enable accurate perception in off-road environments, aiding in obstacle detection, mapping, and path planning. Learning-based LiDAR semantic segmentation utilizes machine learning techniques to automatically classify objects and regions in LiDAR point clouds. Learning-based models struggle in off-road environments due to the presence of diverse objects with varying colors, textures, and undefined boundaries, which can lead to difficulties in accurately classifying and segmenting objects using traditional geometric-based features. In this paper, we address this problem by harnessing the LiDAR intensity parameter to enhance object segmentation in off-road environments. Our approach was evaluated in the RELLIS-3D data set and yielded promising results as a preliminary analysis with improved mIoU for classes ”puddle” and ”grass” compared to more complex deep learning-based benchmarks111https://github.com/MOONLABIISERB/lidar-intensity-predictor/tree/main. The methodology was evaluated for compatibility across both Velodyne and Ouster LiDAR systems, assuring its cross-platform applicability. This analysis advocates for the incorporation of calibrated intensity as a supplementary input, aiming to enhance the prediction accuracy of learning based semantic segmentation frameworks.

222The work is supported by TIH iHUB Drishti-IIT Jodhpur under project number 23 and accepted for publication at International Symposium on Experimental Robotics 2023.",[],[]
"Machine learning, particularly neural networks, has rapidly permeated most activities and work where data has a story to tell. Recently, deep learning has started to be used for solving differential equations with input from physics, also known as Physics-Informed Neural Networks (PINNs). We present a study showing the efficacy of PINNs for solving the Zerilli and the Regge-Wheeler equations in the time domain to calculate the quasi-normal oscillation modes of a Schwarzschild black hole. We compare the extracted modes with those obtained with finite difference methods.
Although the PINN results are competitive, with a few percent differences in the quasi-normal modes estimates relative to those computed with finite difference methods, the real power of PINNs will emerge when applied to large dimensionality problems.",[],[]
,[],[]
"When implementing hierarchical federated learning over wireless networks, scalability assurance and the ability to handle both interference and device data heterogeneity are crucial. This work introduces a learning method designed to address these challenges, along with
a scalable transmission scheme that efficiently uses a single wireless resource
through over-the-air computation. To provide resistance against data heterogeneity, we employ gradient aggregations. Meanwhile, the impact of interference is minimized through optimized receiver normalizing factors. For this, we model a multi-cluster wireless network using stochastic geometry, and characterize the mean squared error of the aggregation estimations as a function of the network parameters.
We show that despite the interference and the data heterogeneity, the proposed scheme achieves high learning accuracy and can significantly outperform the conventional hierarchical algorithm.","['Federated learning', 'hierarchical networks', 'over-the-air computation', 'interference', 'stochastic geometry.']",[]
"In ultraviolet (UV) astronomical observations, photons from the sources are very few compared to the visible or infrared (IR) wavelength ranges. Detectors operating in the UV usually employ a photon-counting mode of operation. These detectors usually have an image intensifier sensitive to UV photons and a readout mechanism that employs photon counting. The development of readouts for these detectors is resource-intensive and expensive. In this paper, we describe the development of a low-cost UV photon-counting detector processing unit that employs a Raspberry Pi with its in built readout to perform the photon-counting operation. Our system can operate in both 3×3333\times 33 × 3 and 5×5555\times 55 × 5 window modes at 30 frames per sec (fps), where 5×5555\times 55 × 5 window mode also enables the provision of detection of double events. The system can be built quickly from readily available custom-off-the-shelf (COTS) components and is thus used in inexpensive CubeSats or small satellite missions. This low-cost solution promises to broaden access to UV observations, advancing research possibilities in space-based astronomy.",[],['India']
"Flamelet-based methods are extensively used in modeling turbulent hydrocarbon flames. However, these models have yet to be established for (lean) premixed hydrogen flames.
While flamelet models exist for laminar thermo-diffusively unstable hydrogen flames, for which consideration of curvature effects has resulted in improved model predictions [1],
it is still unclear whether these models are directly applicable to turbulent hydrogen flames.
Therefore, a detailed assessment of stretch effects on thermochemical states in a turbulent lean premixed hydrogen-air slot flame through finite-rate chemistry simulations is conducted.
Strain and curvature are examined individually using a composition space model, revealing their distinct influences on thermochemical states.
An a-priori analysis confirms that the previously developed tabulated manifolds fall short of capturing all turbulent flame phenomena,
necessitating a novel manifold incorporating both strain and curvature variations.
These results underscore the significance of these variations in developing manifold-based combustion models for turbulent lean hydrogen flames.","['Turbulent premixed flames', 'Thermodiffusive instability', 'Hydrogen combustion', 'Preferential diffusion', 'Strain and curvature', 'Flamelet modeling']",[]
"Visual obstacle discovery is a key step towards autonomous navigation of indoor mobile robots.
Successful solutions have many applications in multiple scenes.
One of the exceptions is the reflective ground.
In this case,
the reflections on the floor resemble the true world,
which confuses the obstacle discovery and leaves navigation unsuccessful.
We argue that the key to this problem lies in obtaining discriminative features for reflections and obstacles.
Note that obstacle and reflection can be separated by the ground plane in 3D space.
With this observation,
we firstly introduce a pre-calibration based ground detection scheme that uses robot motion to predict the ground plane.
Due to the immunity of robot motion to reflection,
this scheme avoids failed ground detection caused by reflection.
Given the detected ground,
we design a ground-pixel parallax to describe the location of a pixel relative to the ground.
Based on this,
a unified appearance-geometry feature representation is proposed to describe objects inside rectangular boxes.
Eventually,
based on segmenting by detection framework,
an appearance-geometry fusion regressor is designed to utilize the proposed feature to discover the obstacles.
It also prevents our model from concentrating too much on parts of obstacles instead of whole obstacles.
For evaluation,
we introduce a new dataset for Obstacle on Reflective Ground (ORG),
which comprises 15 scenes with various ground reflections,
a total of more than 200 image sequences and 3400 RGB images.
The pixel-wise annotations of ground and obstacle provide a comparison to our method and other methods.
By reducing the misdetection of the reflection,
the proposed approach outperforms others.
The source code and the dataset will be available at https://github.com/XuefengBUPT/IndoorObstacleDiscovery-RG.","['Reflective', 'Ground', 'Obstacle', 'Discovery', 'Homography']",[]
,[],[]
,[],[]
"Multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. Recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. However, these methods often include complex modules that entail heavy computation and lack interpretability. In this paper, we propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel framework to address these challenges in multi-label image classification tasks. Our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. This structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. We enhance representation learning by incorporating a mixture density network into contrastive learning and generating Gaussian mixture distributions to explore the epistemic uncertainty of the feature encoder. We validate the effectiveness of our framework through experimentation with datasets from the computer vision and medical imaging domains. Our method outperforms the existing state-of-the-art methods while achieving a low computational footprint on both datasets. Visualization analyses also demonstrate that ProbMCL-learned classifiers maintain a meaningful semantic topology.",[],[]
"Let Md(k)⁢(n)subscriptsuperscript𝑀𝑘𝑑𝑛M^{({k})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( italic_k ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) be the manifold of n𝑛nitalic_n-tuples (x1,…,xn)∈(ℝd)nsubscript𝑥1…subscript𝑥𝑛superscriptsuperscriptℝ𝑑𝑛(x_{1},\ldots,x_{n})\in(\mathbb{R}^{d})^{n}( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ∈ ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT having non-k𝑘kitalic_k-equal coordinates. We show that, for d≥2𝑑2d\geq 2italic_d ≥ 2, Md(3)⁢(n)subscriptsuperscript𝑀3𝑑𝑛M^{({3})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) is rationally formal if and only if n≤6𝑛6n\leq 6italic_n ≤ 6. This stands in sharp contrast with the fact that all classical configuration spaces Md(2)⁢(n)=Conf ⁢(ℝd,n)subscriptsuperscript𝑀2𝑑𝑛Conf superscriptℝ𝑑𝑛M^{({2})}_{d}(n)=\text{Conf\hskip 1.13809pt}(\hskip 0.56905pt\mathbb{R}^{d},n)italic_M start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) = Conf ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , italic_n ) are rationally formal, just as are all complements of arrangements of arbitrary complex subspaces with geometric lattice of intersections. The rational non formality of Md(3)⁢(n)subscriptsuperscript𝑀3𝑑𝑛M^{({3})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) for n>6𝑛6n>6italic_n > 6 is established via detection of non-trivial triple Massey products assessed through Poincaré duality.",[],[]
"We present a comparative study of the molecular gas in two galaxies from the LEGUS sample: barred spiral NGC 1313 and flocculent spiral NGC 7793. These two galaxies have similar masses, metallicities, and star formation rates, but NGC 1313 is forming significantly more massive star clusters than NGC 7793, especially young massive clusters (<10absent10<10< 10 Myr, >104absentsuperscript104>10^{4}> 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT).
Using ALMA CO(2-1) observations of the two galaxies with the same sensitivities and resolutions of 13 pc, we directly compare the molecular gas in these two similar galaxies to determine the physical conditions responsible for their large disparity in cluster formation.
By fitting size-linewidth relations for the clouds in each galaxy, we find that NGC 1313 has a higher intercept than NGC 7793, implying that its clouds have higher kinetic energies at a given size scale. NGC 1313 also has more clouds near virial equilibrium than NGC 7793, which may be connected to its higher rate of massive cluster formation. However, these virially bound clouds do not show a stronger correlation with young clusters than that of the general cloud population. 
We find surprisingly small differences between the distributions of molecular cloud populations in the two galaxies, though the largest of those differences are that NGC 1313 has higher surface densities and lower free-fall times.","['star formation', 'ALMA spiral galaxies']","['Australia', 'Sweden', 'Switzerland', 'Germany', 'Italy']"
"We compare the molecular cloud properties in sub-galactic regions of two galaxies, barred spiral NGC 1313, which is forming many massive clusters, and flocculent spiral NGC 7793, which is forming significantly fewer massive clusters despite having a similar star formation rate to NGC 1313.
We find that there are larger variations in cloud properties between different regions within each galaxy than there are between the galaxies on a global scale, especially for NGC 1313.
There are higher masses, linewidths, pressures, and virial parameters in the arms of NGC 1313 and center of NGC 7793 than in the interarm and outer regions of the galaxies.
The massive cluster formation of NGC 1313 may be driven by its greater variation in environments, allowing more clouds with the necessary conditions to arise, although no one parameter seems primarily responsible for the difference in star formation.
Meanwhile NGC 7793 has clouds that are as massive and have as much kinetic energy as clouds in the arms of NGC 1313, but have densities and pressures more similar to the interarm regions and so are less inclined to collapse and form stars.
The cloud properties in NGC 1313 and NGC 7793 suggest that spiral arms, bars, interarm regions, and flocculent spirals each represent distinct environments with regard to molecular cloud populations.
We see surprisingly little difference in surface densities between the regions, suggesting that the differences in surface densities frequently seen between arm and interarm regions of lower-resolution studies are indicative of the sparsity of molecular clouds, rather than differences in their true surface density.","['star formation', 'ALMA spiral galaxies']","['Australia', 'Sweden', 'Switzerland', 'Germany', 'Italy']"
,[],[]
"We introduce the entangled quantum polynomial hierarchy 𝖰𝖤𝖯𝖧𝖰𝖤𝖯𝖧\mathsf{QEPH}sansserif_QEPH as the class of problems that are efficiently verifiable given alternating quantum proofs that may be entangled with each other.
We prove 𝖰𝖤𝖯𝖧𝖰𝖤𝖯𝖧\mathsf{QEPH}sansserif_QEPH collapses to its second level. In fact, we show that a polynomial number of alternations collapses to just two.
As a consequence, 𝖰𝖤𝖯𝖧=𝖰𝖱𝖦⁢(𝟣)𝖰𝖤𝖯𝖧𝖰𝖱𝖦1\mathsf{QEPH}=\mathsf{QRG(1)}sansserif_QEPH = sansserif_QRG ( sansserif_1 ), the class of problems having one-turn quantum refereed games, which is known to be contained in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE.
This is in contrast to the unentangled quantum polynomial hierarchy 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH, which contains 𝖰𝖬𝖠⁢(𝟤)𝖰𝖬𝖠2\mathsf{QMA(2)}sansserif_QMA ( sansserif_2 ).

We also introduce a generalization of the quantum-classical polynomial hierarchy 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH where the provers send probability distributions over strings (instead of strings) and denote it by 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧\mathsf{DistributionQCPH}sansserif_DistributionQCPH.
Conceptually, this class is intermediate between 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH and 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH.
We prove 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧=𝖰𝖢𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{DistributionQCPH}=\mathsf{QCPH}sansserif_DistributionQCPH = sansserif_QCPH, suggesting that only quantum superposition (not classical probability) increases the computational power of these hierarchies.
To prove this equality, we generalize a game-theoretic result of Lipton and Young (1994) which says that the provers can send distributions that are uniform over a polynomial-size support.
We also prove the analogous result for the polynomial hierarchy, i.e., 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖯𝖧=𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖯𝖧𝖯𝖧\mathsf{DistributionPH}=\mathsf{PH}sansserif_DistributionPH = sansserif_PH.
These results also rule out certain approaches for showing 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH collapses.
Finally, we show that 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH and 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH are contained in 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH, resolving an open question of Gharibian et al. (2022).",[],[]
"Autonomous driving has rapidly developed and shown promising performance with recent advances in hardware and deep learning methods. High-quality datasets are fundamental for developing reliable autonomous driving algorithms. Previous dataset surveys tried to review the datasets but either focused on a limited number or lacked detailed investigation of the characters of datasets. To this end, we present an exhaustive study of over 200 autonomous driving datasets from multiple perspectives, including sensor modalities, data size, tasks, and contextual conditions. We introduce a novel metric to evaluate the impact of each dataset, which can also be a guide for establishing new datasets. We further analyze the annotation process and quality of datasets. Additionally, we conduct an in-depth analysis of the data distribution of several vital datasets. Finally, we discuss the development trend of the future autonomous driving datasets.","['Dataset', 'influence', 'annotation', 'autonomous driving.']",[]
"The notions of Hausdorff and Fourier dimensions are ubiquitous in harmonic analysis and geometric measure theory. It is known that any hypersurface in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT has Hausdorff dimension d𝑑ditalic_d. However, the Fourier dimension depends on the finer geometric properties of the hypersurface. For instance, the Fourier dimension of a hyperplane is 0, and the Fourier dimension of a hypersurface with non-vanishing Gaussian curvature is d𝑑ditalic_d. Recently, Harris has shown that the Euclidean light cone in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT has Fourier dimension d−1𝑑1d-1italic_d - 1, which leads one to conjecture that the Fourier dimension of a hypersurface equals the number of non-vanishing principal curvatures. We prove this conjecture for all d𝑑ditalic_d-dimensional cones and cylinders in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT generated by hypersurfaces in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT with non-vanishing Gaussian curvature. In particular, cones and cylinders are not Salem. Our method involves substantial generalizations of Harris’s strategy.","['Fourier dimension', 'Hausdorff dimension', 'Salem set', 'Gaussian curvature', 'Principal curvature', 'Oscillatory integrals', 'Stationary phase', 'Conical and cylindrical hypersurfaces']",[]
"Recently, diffusion models have demonstrated their effectiveness in generating extremely high-quality images and have found wide-ranging applications, including automatic sketch colorization. However, most existing models use text to guide the conditional generation, with fewer attempts exploring the potential advantages of using image tokens as conditional inputs for networks. As such, this paper exhaustively investigates image-guided models, specifically targeting reference-based sketch colorization, which aims to colorize sketch images using reference color images. We investigate three critical aspects of reference-based diffusion models: the shortcomings compared to text-based counterparts, the training strategies, and the capability in zero-shot, sequential text-based manipulation. We introduce two variations of an image-guided latent diffusion model using different image tokens from the pre-trained CLIP image encoder, and we propose corresponding manipulation methods to adjust their results sequentially using weighted text inputs. We conduct comprehensive evaluations of our models through qualitative and quantitative experiments, as well as a user study. Code link: https://github.com/ydk-tellurion/colorizeDiffusion.",[],[]
,[],[]
"Neural networks (NNs) are increasingly used in always-on safety-critical applications deployed on hardware accelerators (NN-HAs) employing various memory technologies. Reliable continuous operation of NN is essential for safety-critical applications. During online operation, NNs are susceptible to single and multiple permanent and soft errors due to factors such as radiation, aging, and thermal effects. Explicit NN-HA testing methods cannot detect transient faults during inference, are unsuitable for always-on applications, and require extensive test vector generation and storage.
Therefore, in this paper, we propose the
uncertainty fingerprint approach representing the online fault status of NN. Furthermore, we propose a dual head NN topology specifically designed to produce uncertainty fingerprints and the primary prediction of the NN in a single shot. During the online operation, by matching the uncertainty fingerprint, we can concurrently self-test NNs with up to 100%percent100100\%100 % coverage with a low false positive rate while maintaining a similar performance of the primary task. Compared to existing works, memory overhead is reduced by up to 243.7243.7243.7243.7 MB, multiply and accumulate (MAC) operation is reduced by up to 10000×10000\times10000 ×, and false-positive rates are reduced by up to 89%percent8989\%89 %.","['Self-testing', 'concurrent testing', 'testing neural network', 'uncertainty estimation.']",[]
"Disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. However, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. To help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. Our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. Most importantly, experts have used our open-source Python implementation since April 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. Other organizations can readily adapt this implementation to create rankings from the outputs of their tailored univariate methods across large-scale streams.",[],[]
"We introduce Deep Set Linearized Optimal Transport, an algorithm designed for the efficient simultaneous embedding of point clouds into an L2−limit-fromsuperscript𝐿2L^{2}-italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT -space. This embedding preserves specific low-dimensional structures within the Wasserstein space while constructing a classifier to distinguish between various classes of point clouds. Our approach is motivated by the observation that L2−limit-fromsuperscript𝐿2L^{2}-italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT -distances between optimal transport maps for distinct point clouds, originating from a shared fixed reference distribution, provide an approximation of the Wasserstein-2 distance between these point clouds, under certain assumptions.
To learn approximations of these transport maps, we employ input convex neural networks (ICNNs) and establish that, under specific conditions, Euclidean distances between samples from these ICNNs closely mirror Wasserstein-2 distances between the true distributions. Additionally, we train a discriminator network that attaches weights these samples and creates a permutation invariant classifier
to differentiate between different classes of point clouds. We showcase the advantages of our algorithm over the standard deep set approach through experiments on a flow cytometry dataset with a limited number of labeled point clouds.",[],[]
"DSLR cameras can achieve multiple zoom levels via shifting lens distances or swapping lens types.
However, these techniques are not possible on smartphone devices due to space constraints.
Most smartphone manufacturers adopt a hybrid zoom system: commonly a Wide (W) camera at a low zoom level and a Telephoto (T) camera at a high zoom level.
To simulate zoom levels between W and T, these systems crop and digitally upsample images from W, leading to significant detail loss.
In this paper, we propose an efficient system for hybrid zoom super-resolution on mobile devices, which captures a synchronous pair of W and T shots and leverages machine learning models to align and transfer details from T to W.
We further develop an adaptive blending method that accounts for depth-of-field mismatches, scene occlusion, flow uncertainty, and alignment errors.
To minimize the domain gap, we design a dual-phone camera rig to capture real-world inputs and ground-truths for supervised training.
Our method generates a 12-megapixel image in 500ms on a mobile platform and compares favorably against state-of-the-art methods under extensive evaluation on real-world scenarios.","['hybrid zoom', 'dual camera fusion', 'deep neural networks']",[]
"We introduce the notion of quota trees in directed graphs. Given a
nonnegative integer “quota” for each vertex of a directed multigraph
G𝐺Gitalic_G, a quota tree is an immersed rooted tree which hits each vertex of
G𝐺Gitalic_G the prescribed number of times. When the quotas are all one, the
tree is actually embedded and we recover the usual notion of a
spanning arborescence (directed spanning tree). The usual algorithms
which produce spanning arborescences with various properties typically
have (sometimes more complicated) “quota” analogues.
Our original motivation for studying quota trees was the problem of
characterizing the sizes of the Myhill-Nerode equivalence classes in a
connected deterministic finite-state automaton recognizing a given
regular language. We show that the obstruction to realizing a given
set of M-N class sizes is precisely the existence of a suitable quota
tree.
In this paper we develop the basic theory of quota trees.
We give necessary and sufficient conditions for the
existence of a quota tree (or forest) over a given directed graph with
specified quotas, solving the M-N class size problem as a special
case. We discuss some potential applications of quota trees and
forests, and connect them to the k𝑘kitalic_k lightest paths problem. We give
two proofs of the main theorem: one based on an algorithmic loop
invariant, and one based on direct enumeration of quota trees. For the
latter, we use Lagrange inversion to derive a formula which vastly
generalizes both the matrix-tree theorem and Cayley’s formula for
counting labeled trees. We give an efficient algorithm to sample
uniformly from the set of forests with given quotas, as well as a
generalization of Edmonds’ algorithm for computing a minimum-weight
quota forest.","['graph traversal', 'graph search', 'automata', 'DFA', 'regular languages', 'Myhill-Nerode', 'private information retrieval', 'graph immersions', 'arborescences', 'spanning trees', 'Edmonds’ algorithm', 'lightest paths', 'matrix-tree', 'random trees', 'Cayley formula', 'Lagrange inversion', 'Narayana numbers', 'combinatorial reciprocity']",[]
,[],[]
"ABSTRACT: The Debye-Hückel (DH) formalism of bulk electrolytes equivalent to the gaussian-level closure of the electrostatic Schwinger-Dyson (SD) identities without the interionic hard-core (HC) coupling is extended via the cumulant treatment of these equations augmented by HC interactions. By confronting the monovalent ion activity and pressure predictions of our cumulant-corrected DH (CCDH) theory with hypernetted-chain (HNC) results and Monte-Carlo (MC) simulations from the literature, we show that this rectification extends the accuracy of the DH formalism from submolar into molar salt concentrations. In the case of internal energies or the general case of divalent electrolytes mainly governed by charge correlations, the improved accuracy of the CCDH theory is limited to submolar ion concentrations. Comparison with experimental data from the literature shows that via the adjustment of the hydrated ion radii, the CCDH formalism can equally reproduce the non-uniform effect of salt increment on the ionic activity coefficients up to molar concentrations. The inequality satisfied by these HC sizes coincides with the cationic branch of the Hofmeister series.",[],[]
"We present a comprehensive analysis of the Hubble Space Telescope
observations of the atmosphere of WASP-121 b, a ultra-hot Jupiter.
After reducing the transit, eclipse, and phase-curve observations
with a uniform methodology and addressing the biases from
instrument systematics, sophisticated atmospheric retrievals are
used to extract robust constraints on the thermal structure,
chemistry, and cloud properties of the atmosphere.
Our analysis shows that the observations are consistent with a
strong thermal inversion beginning at ∼similar-to\sim∼104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT Pa on the
dayside, solar to subsolar metallicity Z𝑍Zitalic_Z
(i.e., −0.77<log⁡(Z)<0.050.77𝑍0.05-0.77<\log(Z)<0.05- 0.77 < roman_log ( italic_Z ) < 0.05), and super-solar C/O ratio
(i.e., 0.59<C/O<0.870.59C/O0.870.59<\textrm{C/O}<0.870.59 < C/O < 0.87).
More importantly, utilizing the high signal-to-noise ratio and
repeated observations of the planet, we identify the following
unambiguous time-varying signals in the data: i) a shift of
the putative hotspot offset between the two phase-curves and
ii) varying spectral signatures in the transits and eclipses.
By simulating the global dynamics of WASP-121 b
atmosphere at high-resolution, we show that the identified signals
are consistent with quasi-periodic weather patterns, hence
atmospheric variability, with signatures at the level probed by
the observations (∼similar-to\sim∼5% to ∼similar-to\sim∼10%) that change on a
timescale of ∼similar-to\sim∼5 planet days; in the simulations, the
weather patterns arise from the formation and movement of storms
and fronts, causing hot (as well as cold) patches of atmosphere
to deform, separate, and mix in time.","['Exoplanet atmospheric variability (2020)', 'Exoplanet atmospheric composition (2021)', 'Bayesian statistics (1900)', 'Astrophysical fluid dynamics (101)', 'Astronomy data analysis (1858)']","['Sweden', 'France', 'Germany', 'Spain', 'Netherlands']"
"Achieving effective and seamless human-robot collaboration requires two key outcomes: enhanced team performance and fostering a positive human perception of both the robot and the collaboration. This paper investigates the capability of the proposed task planning framework to realize these objectives by integrating human leading/following preference and performance into its task allocation and scheduling processes. We designed a collaborative scenario wherein the robot autonomously collaborates with participants. The outcomes of the user study indicate that the proactive task planning framework successfully attains the aforementioned goals. We also explore the impact of participants’ leadership and followership styles on their collaboration. The results reveal intriguing relationships between these factors, which warrant further investigation in future studies.",[],[]
,[],[]
"In order to study exoplanets, a comprehensive characterization of the fundamental properties of the host stars, such as angular diameter, temperature, luminosity, and age, is essential, as the formation and evolution of exoplanets are directly influenced by the host stars at various points in time. In this paper, we present interferometric observations taken of directly imaged planet host 51 Eridani at the CHARA Array. We measure the limb-darkened angular diameter of 51 Eridani to be θLD=0.450±0.004subscript𝜃LDplus-or-minus0.4500.004\theta_{\rm LD}=0.450\pm 0.004italic_θ start_POSTSUBSCRIPT roman_LD end_POSTSUBSCRIPT = 0.450 ± 0.004 mas and combining with the Gaia zero-point corrected parallax, we get a stellar radius of 1.45±0.01plus-or-minus1.450.011.45\pm 0.011.45 ± 0.01 R⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. We use the PARSEC isochrones to estimate an age of 23.2−1.6+1.7subscriptsuperscript23.21.71.623.2^{+1.7}_{-1.6}23.2 start_POSTSUPERSCRIPT + 1.7 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 1.6 end_POSTSUBSCRIPT Myr and a mass of 1.550±0.005plus-or-minus1.5500.0051.550\pm 0.0051.550 ± 0.005 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. The age and mass agree well with values in the literature, determined through a variety of methods ranging from dynamical age trace-backs to lithium depletion boundary methods. We derive a mass of 4.1−0.4+0.5subscriptsuperscript4.10.50.44.1^{+0.5}_{-0.4}4.1 start_POSTSUPERSCRIPT + 0.5 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.4 end_POSTSUBSCRIPT MJupJup{}_{\rm Jup}start_FLOATSUBSCRIPT roman_Jup end_FLOATSUBSCRIPT for 51 Eri b using the Sonora Bobcat models, which further supports the possibility of 51 Eri b forming under either the hot-start formation model or the warm-start formation model.",[],[]
,[],[]
"Vision transformers (ViTs) have achieved promising results on a variety of computer vision tasks. However, their quadratic complexity in the number of input tokens limits their application, especially in resource-constrained settings. Previous approaches that address this challenge by employing gradual token reduction assume that token redundancy in one layer implies redundancy in all the following layers. We demonstrate empirically that this assumption is often incorrect, i.e., tokens that are redundant in one layer can be useful in later layers. Based on this key insight, we propose a novel token propagation controller (TPC) that incorporates two different token-distributions, namely pause probability and restart probability, to control the reduction and reuse of tokens respectively, resulting in more efficient token utilization. To improve the estimates of token-distributions, we propose a smoothing mechanism that acts as a regularizer and helps remove noisy outliers. Furthermore, to improve the training-stability of our proposed TPC, we introduce a model stabilizer that is able to implicitly encode local image structures and minimize accuracy fluctuations during model training. We conduct extensive experiments on the ImageNet-1K dataset using DeiT, LV-ViT, and Swin models to demonstrate the effectiveness of the proposed method.
For example, compared to baseline models, our proposed method improves the efficiency of the DeiT-S model by 21.7%percent21.721.7\%21.7 % (FLOPs) while increasing the classification accuracy by 0.4%percent0.40.4\%0.4 %.",[],[]
"A recently-established necessary condition for polynomials that preserve the class of entrywise nonnegative matrices of a fixed order is shown to be necessary and sufficient for the class of nonnegative monomial matrices. Along the way, we provide a formula for computing an arbitrary power of a monomial matrix and a formula for computing the polynomial of a nonnegative monomial matrix.",[],[]
"Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. 
Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. 
Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers. 
Results: Our models based on CNN architecture achieve precision ranging from 0.71 to 0.82. The trained model for automatic code content highlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming the trained models for other formatting styles. The BERT models have even lower recalls and F1 scores than the CNN models. Our analysis of failure cases indicates that the majority of the failure cases are missing identification (i.e., the model misses the content that is supposed to be highlighted) due to the models tend to learn the frequently highlighted words while struggling to learn less frequent words.
Conclusion: Our findings suggest that it is possible to develop recommendation models for highlighting information for answers with different formatting styles on Stack Overflow.",[],[]
"Speaker representation learning is critical for modern voice recognition systems. While supervised learning techniques require extensive labeled data, unsupervised methodologies can leverage vast unlabeled corpora, offering a scalable solution. This paper introduces self-supervised reflective learning (SSRL), a novel paradigm that streamlines existing iterative unsupervised frameworks. SSRL integrates self-supervised knowledge distillation with online clustering to refine pseudo labels and train the model without iterative bottlenecks.
Specifically, a teacher model continually refines pseudo labels through online clustering, providing dynamic supervision signals to train the student model. The student model undergoes noisy student training with input and model noise to boost its modeling capacity. The teacher model is updated via an exponential moving average of the student, acting as an ensemble of past iterations. Further, a pseudo label queue retains historical labels for consistency, and noisy label modeling directs learning towards clean samples.
Experiments on VoxCeleb show SSRL’s superiority over current iterative approaches, surpassing the performance of a 5-round method in just a single training round. Ablation studies validate the contributions of key components like noisy label modeling and pseudo label queues. Moreover, consistent improvements in pseudo labeling and the convergence of cluster counts demonstrate SSRL’s effectiveness in deciphering unlabeled data. This work marks an important advancement in efficient and accurate speaker representation learning through the novel reflective learning paradigm.","['Self-supervised learning', 'self-labeling', 'knowledge distillation', 'noisy label modeling', 'speaker recognition']",[]
"We present our general-purpose mobile manipulation system consisting of a custom robot platform and key algorithms spanning perception and planning.
To extensively test the system in the wild and benchmark its performance, we choose a grocery shopping scenario in an actual, unmodified grocery store.
We derive key performance metrics from detailed robot log data collected during six week-long field tests, spread across 18 months.
These objective metrics, gained from complex yet repeatable tests, drive the direction of our research efforts and let us continuously improve our system’s performance.
We find that thorough end-to-end system-level testing of a complex mobile manipulation system can serve as a reality-check for state-of-the-art methods in robotics.
This effectively grounds robotics research efforts in real world needs and challenges, which we deem highly useful for the advancement of the field.
To this end, we share our key insights and takeaways to inspire and accelerate similar system-level research projects.",[],[]
"We consider a Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT semiflow {φt}t≥0subscriptsubscript𝜑𝑡𝑡0\{\varphi_{t}\}_{t\geq 0}{ italic_φ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t ≥ 0 end_POSTSUBSCRIPT on a Banach space X𝑋Xitalic_X admitting a stable fixed point x𝑥xitalic_x.
We show, along the lines of the parameterization method [CFdlL03a], the existence of a Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT invariant foliation tangent to X1subscript𝑋1X_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at x𝑥xitalic_x, for an arbitrary D⁢φt⁢(x)𝐷subscript𝜑𝑡𝑥D\varphi_{t}(x)italic_D italic_φ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x )-invariant subspace X1⊂Xsubscript𝑋1𝑋X_{1}\subset Xitalic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊂ italic_X satisfying some additional spectral conditions.
Uniqueness ensues in a subclass of sufficiently smooth invariant foliations tangent to X1subscript𝑋1X_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at x𝑥xitalic_x.
We then draw relations to Koopman theory, and thereby establish the existence and uniqueness, in some appropriate sense, of Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT Koopman eigenfunctions.
We demonstrate that these results apply to the case of the Navier-Stokes system, the archetypal example considered by the modern upheaval of applied ’Koopmanism’.",[],[]
,[],[]
"We report the observations of two self-lensing pulses from KIC 12254688 in Transiting Exoplanet Survey Satellite (TESS) light curves. This system, containing a F2V star and white-dwarf companion, was amongst the first self-lensing binary systems discovered by the Kepler Space Telescope over the past decade. Each observed pulse occurs when the white dwarf transits in front of its companion star, gravitationally lensing the star’s surface, thus making it appear brighter to a distant observer. These two pulses are the very first self-lensing events discovered in TESS observations. We describe the methods by which the data were acquired and detrended, as well as the best-fit binary parameters deduced from our self-lensing+radial velocity model. We highlight the difficulties of finding new self-lensing systems with TESS, and we discuss the types of self-lensing systems that TESS may be more likely to discover in the future.","['Compact binary stars (283)', 'Gravitational microlensing (672)', 'White', 'Dwarf', 'Stars (1799)']",[]
"We address the choice of penalty parameter in the Smoothness-Penalized Deconvolution (SPeD) method of estimating a probability density under additive measurement error.
Cross-validation gives an unbiased estimate of the risk (for the present sample size n𝑛nitalic_n) with a given penalty parameter, and this function can be minimized as a function of the penalty parameter.
Least-squares cross-validation, which has been proposed for the similar Deconvoluting Kernel Density Estimator (DKDE), performs quite poorly for SPeD.
We instead estimate the risk function for a smaller sample size n1<nsubscript𝑛1𝑛n_{1}<nitalic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_n with a given penalty parameter, using this to choose the penalty parameter for sample size n1subscript𝑛1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and then use the asymptotics of the optimal penalty parameter to choose for sample size n𝑛nitalic_n.
In a simulation study, we find that this has dramatically better performance than cross-validation, is an improvement over a SURE-type method previously proposed for this estimator, and compares favorably to the classic DKDE with its recommended plug-in method.
We prove that the maximum error in estimating the risk function is of smaller order than its optimal rate of convergence.",[],[]
"Time series forecasting task predicts future trends based on historical information. Recent U-Net-based methods have demonstrated superior performance in predicting real-world datasets. However, the performance of these models is lower than patch-based models or linear models. In this work, we propose a symmetric and hierarchical framework, Kernel-U-Net, which cuts the input sequence into slices at each layer of the network and then computes them using kernels. Furthermore, it generalizes the concept of convolutional kernels in classic U-Net to accept custom kernels that follow the same design pattern. Compared to the existing linear or transformer-based solution, our model contains 3 advantages: 1) A small number of parameters: the parameters size is O⁢(l⁢o⁢g⁢(L)2)𝑂𝑙𝑜𝑔superscript𝐿2O(log(L)^{2})italic_O ( italic_l italic_o italic_g ( italic_L ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) where L𝐿Litalic_L is the look-back window size, 2) Flexibility: its kernels can be customized and fitted to the datasets, 3) Computation efficiency: the computation complexity of transformer modules is reduced to O⁢(l⁢o⁢g⁢(L)2)𝑂𝑙𝑜𝑔superscript𝐿2O(log(L)^{2})italic_O ( italic_l italic_o italic_g ( italic_L ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) if they are placed close to the latent vector. Kernel-U-Net accuracy was greater than or equal to the state-of-the-art model on six (out of seven) real-world datasets.",[],[]
,[],[]
"One of the most critical applications undertaken by coalitions of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) is reaching predefined targets by following the most time-efficient routes while avoiding collisions. Unfortunately, UAVs are hampered by limited battery life, and UGVs face challenges in reachability due to obstacles and elevation variations. Existing literature primarily focuses on one-to-one coalitions, which constrains the efficiency of reaching targets. In this work, we introduce a novel approach for a UAV-UGV coalition with a variable number of vehicles, employing a modified mean-shift clustering algorithm to segment targets into multiple zones. Each vehicle utilizes Multi-agent Deep Deterministic Policy Gradient (MADDPG) and Multi-agent Proximal Policy Optimization (MAPPO) — two advanced reinforcement learning algorithms — to form an effective coalition for navigating obstructed environments without collisions. This approach of assigning targets to various circular zones, based on density and range, significantly reduces the time required to reach these targets. Moreover, introducing variability in the number of UAVs and UGVs in a coalition enhances task efficiency by enabling simultaneous multi-target engagement. The results of our experimental evaluation demonstrate that our proposed method substantially surpasses current state-of-the-art techniques, nearly doubling efficiency in terms of target navigation time and task completion rate.",[],[]
"Existing object recognition models have been shown to lack robustness in diverse geographical scenarios due to significant domain shifts in design and context. Class representations need to be adapted to more accurately reflect an object concept under these shifts. In the absence of training data from target geographies, we hypothesize that geography-specific descriptive knowledge of object categories can be leveraged to enhance robustness. For this purpose, we explore the feasibility of probing a large-language model for geography-specific object knowledge, and we investigate integrating knowledge in zero-shot and learnable soft prompting with the CLIP vision-language model. In particular, we propose a geography knowledge regularization method to ensure that soft prompts trained on a source set of geographies generalize to an unseen target set of geographies. Our gains on DollarStreet when generalizing from a model trained only on data from Europe are as large as +2.8 on countries from Africa, and +4.6 on the hardest classes. We further show
competitive performance vs. few-shot target training, and provide insights into how descriptive knowledge captures geographical differences.",[],[]
,[],[]
"The Evidential Regression Network (ERN) represents a novel approach that integrates deep learning with Dempster-Shafer’s theory to predict a target and quantify the associated uncertainty. Guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. This paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. Initially, we define the region where the models can’t effectively learn from the samples. Following this, we thoroughly analyze the ERN and investigate this constraint. Leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ERN to learn from the whole training set. Our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.",[],[]
"First-order phase transitions produce abrupt changes to the character of both ground and excited electronic states. Here we conduct electronic compressibility measurements to map the spin phase diagram and Landau level (LL) energies of monolayer WSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT in a magnetic field. We resolve a sequence of first-order phase transitions between completely spin-polarized LLs and states with LLs of both spins. Unexpectedly, the LL gaps are roughly constant over a wide range of magnetic fields below the transitions, which we show reflects a preference for opposite spin excitations of the spin-polarized ground state. These transitions also extend into compressible regimes, with a sawtooth boundary between full and partial spin polarization. We link these observations to the important influence of LL filling on the exchange energy beyond a smooth density-dependent contribution. Our results show that WSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT realizes a unique hierarchy of energy scales where such effects induce re-entrant magnetic phase transitions tuned by density and magnetic field.",[],['Japan']
"In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data.",[],[]
"PSR J1012+5307 is a millisecond pulsar with an extremely low-mass (ELM) white dwarf (WD) companion in an orbit of 14.5 hours. Magnetic braking (MB) plays an important role in influencing the orbital evolution of binary systems with a low-mass (<1−2⁢M⊙absent12subscript𝑀direct-product<1-2~{}M_{\odot}< 1 - 2 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) donor star. At present, there exist several different MB descriptions. In this paper, we investigate the formation of PSR J1012+5307 as a probe to test the plausible MB model. Employing a detailed stellar evolution model by the MESA code, we find that the Convection And Rotation Boosted MB and the ’Intermediate’ MB models can reproduce the WD mass, WD radius, WD surface gravity, neutron-star mass, and orbital period observed in PSR J1012+5307. However, our simulated WD has higher effective temperature than the observation. Other three MB mechanisms including the standard MB model are too weak to account for the observed orbital period in a Hubble time. A long cooling timescale caused by H-shell flashes of the WD may alleviate the discrepancy between the simulated effective temperature and the observed value.","['Stars: evolution:', 'Magnetic braking –', 'Stars:', 'White dwarfs –Binaries: general –', 'Pulsars:', 'PSR', 'J1012+5307']",['China']
,[],[]
,[],[]
"We show that a complete, two-sided, stable minimal hypersurface in 𝐑5superscript𝐑5\mathbf{R}^{5}bold_R start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT is flat.",[],[]
"Remote Sensing Target Fine-grained Classification (TFGC) is of great significance in both military and civilian fields. Due to location differences, growth in data size, and centralized server storage constraints, these data are usually stored under different databases across regions/countries. However, privacy laws and national security concerns constrain researchers from accessing these sensitive remote sensing images for further analysis. Additionally, low-resource remote sensing devices encounter challenges in terms of communication overhead and efficiency when dealing with the ever-increasing data and model scales. To solve the above challenges, this paper proposes a novel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed PRFL. The proposed framework allows each client to learn global and local knowledge to enhance the local representation of private data in environments with extreme statistical heterogeneity (non. Independent and Identically Distributed, IID). Thus, it provides highly customized models to clients with differentiated data distributions. Moreover, the framework minimizes communication overhead and improves efficiency while ensuring satisfactory performance, thereby enhancing robustness and practical applicability under resource-scarce conditions. We demonstrate the effectiveness of the proposed PRFL on the classical TFGC task by leveraging four public datasets.",[],[]
"We show that small perturbations of the spatially homogeneous equilibrium of a thermally driven compressible viscous fluid are globally stable. Specifically, any weak solution of the evolutionary Navier–Stokes–Fourier system driven by thermal convection converges to an equilibrium as time goes to infinity. The main difficulty to overcome is the fact the problem does not admit any obvious Lyapunov function. The result applies, in particular, to the Rayleigh–Bénard convection problem.",[],[]
"In terms of human-computer interaction, it is becoming more and more important to correctly understand the user’s emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This staged classification method can help the model to better focus on different levels of emotional information, thereby improving the performance of the model. Extensive experiments show that TS-GCL has superior performance on IEMOCAP and MELD datasets compared with previous methods.","['graph contrastive learning', 'graph convolutional network', 'multimodal emotion recognition', 'two-stage classification']",[]
"Thyroid cancer is the most common endocrine malignancy, and accurately distinguishing between benign and malignant thyroid tumors is crucial for developing effective treatment plans in clinical practice. Pathologically, thyroid tumors pose diagnostic challenges due to improper specimen sampling. In this study, we have designed a three-stage model using representation learning to integrate pixel-level and slice-level annotations for distinguishing thyroid tumors. This structure includes a pathology structure recognition method to predict structures related to thyroid tumors, an encoder-decoder network to extract pixel-level annotation information by learning the feature representations of image blocks, and an attention-based learning mechanism for the final classification task. This mechanism learns the importance of different image blocks in a pathological region, globally considering the information from each block. In the third stage, all information from the image blocks in a region is aggregated using attention mechanisms, followed by classification to determine the category of the region. Experimental results demonstrate that our proposed method can predict microscopic structures more accurately. After color-coding, the method achieves results on unstained pathology slides that approximate the quality of Hematoxylin and eosin staining, reducing the need for stained pathology slides. Furthermore, by leveraging the concept of indirect measurement and extracting polarized features from structures correlated with lesions, the proposed method can also classify samples where membrane structures cannot be obtained through sampling, providing a potential objective and highly accurate indirect diagnostic technique for thyroid tumors.",[],[]
"Sequential recommenders are crucial to the success of online applications, e.g., e-commerce, video streaming, and social media. While model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. On the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. Inspired by the success of pre-trained models in peer AI fields, we propose a novel pre-trained sequential recommendation framework: PrepRec. We learn universal item representations by modeling item popularity dynamics. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. In addition, with a simple post-hoc interpolation, PrepRec can improve the performance of existing sequential recommenders on average by 13.8% in Recall@10 and 29.5% in NDCG@10. We provide an anonymized implementation of PrepRec at https://anonymous.4open.science/r/PrepRec--2F60/.","['Recommender', 'System', 'Neural', 'Collaborative', 'Filtering', 'Sequential', 'Recommendation', 'Zero-shot', 'Sequential', 'Recommendation']",[]
"We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. We also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in TTS frameworks.","['speech synthesis', 'neural transducer', 'zero-shot adaptive', 'TTS', 'speech representation.']",[]
"We consider MRL maps (Markov-Renyi-Lüroth), a class of interval maps with infinitely many branches that can have parabolic fixed points. We prove that for every MRL map T𝑇Titalic_T, the Lyapunov spectrum can be expressed in terms of the Legendre transform of the topological pressure of −t⁢log⁡|T′|𝑡superscript𝑇′-t\log|T^{\prime}|- italic_t roman_log | italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT |, generalizing previous results in the area. We also show that the Lyapunov spectrum coincides with a function directly related to the Newton-Raphson method applied to the topological pressure of −t⁢log⁡|T′|𝑡superscript𝑇′-t\log|T^{\prime}|- italic_t roman_log | italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT |.","['Lyapunov spectrum', 'thermodynamic formalism', 'Newton-Raphson method.']",[]
"We propose a method for estimating a log-concave density on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT from samples, under the assumption that there exists an orthogonal transformation that makes the components of the random vector independent. While log-concave density estimation is hard both computationally and statistically, the independent components assumption alleviates both issues, while still maintaining a large non-parametric class. We prove that under mild conditions, at most 𝒪~⁢(ϵ−4)~𝒪superscriptitalic-ϵ4\tilde{\mathcal{O}}(\epsilon^{-4})over~ start_ARG caligraphic_O end_ARG ( italic_ϵ start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT ) samples (suppressing constants and log factors) suffice for our proposed estimator to be within ϵitalic-ϵ\epsilonitalic_ϵ of the original density in squared Hellinger distance. On the computational front, while the usual log-concave maximum likelihood estimate can be obtained via a finite-dimensional convex program, it is slow to compute – especially in higher dimensions. We demonstrate through numerical experiments that our estimator can be computed efficiently, making it more practical to use.",[],[]
"Real-time safety metrics are important for the automated driving system (ADS) to assess the risk of driving situations and to assist the decision-making. Although a number of real-time safety metrics have been proposed in the literature, systematic performance evaluation of these safety metrics has been lacking. As different behavioral assumptions are adopted in different safety metrics, it is difficult to compare the safety metrics and evaluate their performance. To overcome this challenge, in this study, we propose an evaluation framework utilizing logged vehicle trajectory data, in that vehicle trajectories for both subject vehicle (SV) and background vehicles (BVs) are obtained and the prediction errors caused by behavioral assumptions can be eliminated. Specifically, we examine whether the SV is in a collision unavoidable situation at each moment, given all near-future trajectories of BVs. In this way, we level the ground for a fair comparison of different safety metrics, as a good safety metric should always alarm in advance to the collision unavoidable moment. When trajectory data from a large number of trips are available, we can systematically evaluate and compare different metrics’ statistical performance. In the case study, three representative real-time safety metrics, including the time-to-collision (TTC) [1], the PEGASUS Criticality Metric (PCM) [2] and the Model Predictive Instantaneous Safety Metric (MPrISM) [3], are evaluated using a large-scale simulated trajectory dataset. The results demonstrate that the MPrISM achieves the highest recall and the PCM has the best accuracy. The proposed evaluation framework is important for researchers, practitioners, and regulators to characterize different metrics, and to select appropriate metrics for different applications. Moreover, by conducting failure analysis on moments when a safety metric failed, we can identify its potential weaknesses which are valuable for its potential refinements and improvements.","['Safety metric', 'autonomous vehicle', 'logged trajectory data']",[]
"The values of two-player general-sum differential games are viscosity solutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy approximations for such games suffer from the curse of dimensionality (CoD). Alleviating CoD through physics-informed neural networks (PINN) encounters convergence issues when value discontinuity is present due to state constraints. On top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. To address these challenges, we propose in this paper a Pontryagin-mode neural operator that outperforms existing state-of-the-art (SOTA) on safety performance across games with parametric state constraints. Our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. We show that the discontinuity of costate dynamics (in the presence of state constraints) effectively enables the learning of discontinuous values, without requiring manually supervised data as suggested by the current SOTA. More importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance.",[],[]
"Specific emitter identification (SEI) technology is significant in device administration scenarios, such as self-organized networking and spectrum management, owing to its high security.
For nonlinear and non-stationary electromagnetic signals, SEI often employs variational modal decomposition (VMD) to decompose the signal in order to effectively characterize the distinct device fingerprint.
However, the trade-off of VMD between the robustness to noise and the ability to preserve signal information has not been investigated in the current literature.
Moreover, the existing VMD algorithm does not utilize the stability of the intrinsic distortion of emitters within a certain
temporal span, consequently constraining its practical applicability in SEI.
In this paper, we propose a joint variational modal decomposition (JVMD) algorithm, which is an improved version of VMD by simultaneously implementing modal decomposition on multi-frame signals.
The consistency of multi-frame signals in terms of the central frequencies and the inherent modal functions (IMFs) is exploited, which effectively highlights the distinctive characteristics among emitters and reduces noise.
Additionally, the complexity of JVMD is analyzed, which is proven to be more computational-friendly than VMD.
Simulations of both modal decomposition and SEI that involve real-world datasets are presented to illustrate that when compared with VMD, the JVMD algorithm improves the accuracy of device classification and the robustness towards noise.","['Intrinsic modal functions (IMFs)', 'radio frequency fingerprints (RFFs)', 'specific emitter identification (SEI)', 'variational mode decomposition (VMD)']",[]
"The use of sub-Terahertz (sub-THz) band is gaining considerable attention in 6G networks. In this study, we introduce hardware and propagation integrated 3D Propagation Model to describe sub-THz channels and discuss its advantages over both deterministic and stochastic 6G channel models. The undiscovered mutuality of localization and communication is presented and its potential in integrated sensing and communication (ISAC) applications is highlighted. Afterward, a real-time sub-THz localization experiment is conducted to show the impact of the mispositioned and misaligned narrow beams on service quality. In continuation, we highlight the most current challenges and developments in THz localization and explore the potential of sub-THz frequencies to efficiently utilize the ultra-wideband spectrum. In the end, the open issues that need to be overcome to provide high spatial resolution and millidegree-level angle of arrival estimation in ISAC applications have been explored.",[],[]
"Reasoning over sports videos for question answering is an important task with numerous applications, such as player training and information retrieval. However, this task has not been explored due to the lack of relevant datasets and the challenging nature it presents. Most datasets for video question answering (VideoQA) focus mainly on general and coarse-grained understanding of daily-life videos, which is not applicable to sports scenarios requiring professional action understanding and fine-grained motion analysis. In this paper, we introduce the first dataset, named Sports-QA, specifically designed for the sports VideoQA task. The Sports-QA dataset includes various types of questions, such as descriptions, chronologies, causalities, and counterfactual conditions, covering multiple sports. Furthermore, to address the characteristics of the sports VideoQA task, we propose a new Auto-Focus Transformer (AFT) capable of automatically focusing on particular scales of temporal information for question answering.
We conduct extensive experiments on Sports-QA, including baseline studies and the evaluation of different methods. The results demonstrate that our AFT achieves state-of-the-art performance111The data and codes will be released..",[],[]
,[],[]
,[],[]
"Natural Language Processing (NLP) is now a cornerstone of requirements automation. One compelling factor behind the growing adoption of NLP in Requirements Engineering (RE) is the prevalent use of natural language (NL) for specifying requirements in industry. NLP techniques are commonly used for automatically classifying requirements, extracting important information, e.g., domain models and glossary terms, and performing quality assurance tasks, such as ambiguity handling and completeness checking. With so many different NLP solution strategies available and the possibility of applying machine learning alongside, it can be challenging to choose the right strategy for a specific RE task and to evaluate the resulting solution in an empirically rigorous manner. This book chapter presents guidelines for the selection of NLP techniques as well as for their evaluation in the context of RE. In particular, we discuss how to choose among different strategies such as traditional NLP, feature-based machine learning, and language-model-based methods. Our ultimate hope for this chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in quickly initiating themselves into the NLP technologies most pertinent to the RE field.",[],[]
"This article is concerned with the rigorous connections between the inertial Qian–Sheng model and the Ericksen–Leslie model for the liquid crystal flow, under a more general condition of coefficients. More specifically, in the framework of Hilbert expansions, we show that: (i) when the elastic coefficients tend to zero (also called the uniaxial limit), the smooth solution to the inertial Qian–Sheng model converges to that to the full inertial Ericksen–Leslie model; (ii) when the elastic coefficients and the inertial coefficient tend to zero simultaneously, the smooth solution to the inertial Qian–Sheng model converges to that to the noninertial Ericksen–Leslie model.
Keywords. Liquid crystals, Ericksen–Leslie model, Qian–Sheng model, Q𝑄Qitalic_Q-tensor theory
AMS subject classifications. Primary, 35Q35; Secondary, 35Q30, 76D05",[],[]
"While significant advancements have been made in video question answering (VideoQA), the potential benefits of enhancing model generalization through tailored difficulty scheduling have been largely overlooked in existing research. This paper seeks to bridge that gap by incorporating VideoQA into a curriculum learning (CL) framework that progressively trains models from simpler to more complex data. Recognizing that conventional self-paced CL methods rely on training loss for difficulty measurement, which might not accurately reflect the intricacies of video-question pairs, we introduce the concept of uncertainty-aware CL. Here, uncertainty serves as the guiding principle for dynamically adjusting the difficulty. Furthermore, we address the challenge posed by uncertainty by presenting a probabilistic modeling approach for VideoQA. Specifically, we conceptualize VideoQA as a stochastic computation graph, where the hidden representations are treated as stochastic variables. This yields two distinct types of uncertainty: one related to the inherent uncertainty in the data and another pertaining to the model’s confidence. In practice, we seamlessly integrate the VideoQA model into our framework and conduct comprehensive experiments. The findings affirm that our approach not only achieves enhanced performance but also effectively quantifies uncertainty in the context of VideoQA.","['Video question answering', 'curriculum learning', 'uncertainty', 'stochastic computation graph.']",[]
"The advent of Large Language Models has revolutionized information retrieval, ushering in a new era of expansive knowledge accessibility. While these models excel in providing open-world knowledge, effectively extracting answers in diverse linguistic environments with varying levels of literacy remains a formidable challenge. Retrieval Augmented Generation (RAG) emerges as a promising solution, bridging the gap between information availability and multilingual comprehension. However, deploying RAG models in real-world scenarios demands careful consideration of various factors.
This paper addresses the critical challenges associated with implementing RAG models in multicultural environments. We delve into essential considerations, including data feeding strategies, timely updates, mitigation of hallucinations, prevention of erroneous responses, and optimization of delivery speed. Our work involves the integration of a diverse array of tools, meticulously combined to facilitate the seamless adoption of RAG models across languages and literacy levels within a multicultural organizational context. Through strategic tweaks in our approaches, we achieve not only effectiveness but also efficiency, ensuring the accelerated and accurate delivery of information in a manner that is tailored to the unique requirements of multilingual and multicultural settings",[],[]
"This paper discusses the limitations of evaluating Masked Language Models (MLMs) in code completion tasks. We highlight that relying on accuracy-based measurements may lead to an overestimation of models’ capabilities by neglecting the syntax rules of programming languages. To address these issues, we introduce a technique called SyntaxEval in which Syntactic Capabilities are used to enhance the evaluation of MLMs. SyntaxEval automates the process of masking elements in the model input based on their  Syntax Trees (ASTs). We conducted a case study on two popular MLMs using data from GitHub repositories. Our results showed negative causal effects between the node types and MLMs’ accuracy. We conclude that MLMs under study fail to predict some syntactic capabilities.","['deep learning', 'code generation', 'interpretability', 'transformers']",[]
"When ultrasonic wave is irradiated on materials, a small static stress is required to get materials yielding and flowing. This is called acoustic softening effect, also known as Blaha effect for a long time. In the past, this effect was explained by several continuum scale or meso-scale solid mechanics theories such as stress superposition or energy superposition theory, or crystal/dislocation plasticity. Due to a lot of microscopic complexities happening inside the materials during ultrasonic vibration, fully understanding of acoustic softening effect is not easy. In this paper, traditional solid mechanics theory is expanded by introducing several concepts in semi-conductor physics. Four new aspects were introduced to understand acoustic softening effect. Firstly, contrary to most existed work in acoustic softening research area which treats ultrasound as waves, it was treated as particles. Secondly, crystal/dislocation plastic theory was simplified to a single equation. Thirdly, concepts of photoelectric effect or photo-voltaic effect were introduced. Analogy of electron movement due to light wave and defect movement due to ultrasonic wave was illustrated. Particularly, as light wave is treated as photon, ultrasonic wave is treated as phonon in this paper. Fourthly, defects such as point defects or line defects are assumed to have certain bonding energy. Their bonding energies are assumed to be quantized or discontinuous. The band gap theory used in photo-voltaic theory is embraced to understand defects movements in solid mechanics due to ultrasonic phonon.
Keywords: Wave-Particle Duality; Ultrasonic Wave; Acoustic Softening, Photoelectric Effect; Photo-voltaic Effect",[],[]
The hot spots conjecture of J. Rauch states that the second Neumann eigenfunction of the Laplace operator on a bounded Lipschitz domain in ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT attains its extrema only on the boundary of the domain. We present an analogous problem for domains with mixed Dirichlet-Neumann boundary conditions. We then solve this problem for Euclidean triangles and a class of planar domains bounded by the graphs of certain piecewise smooth functions.,[],[]
"Linear RMS-flux relation has been well established in different spectral states of all accreting systems. In this work, we study the evolution of the frequency-dependent RMS-flux relation of MAXI J1820+070 during the initial decaying phase of the 2018 outburst with Insight-HXMT over a broad energy range 1–150 keV.
As the flux decreases, we first observe a linear RMS-flux relation at frequencies from 2 mHz to 10 Hz, while such a relation breaks at varying times for different energies, leading to a substantial reduction in the slope.
Moreover, we find that the low-frequency variability exhibits the highest sensitivity to the break, which occurs prior to the hard-to-hard state transition time determined through time-averaged spectroscopy, and the time deviation increases with energy. The overall evolution of the RMS-flux slope and intercept suggests the presence of a two-component Comptonization system. One component is radially extended, explaining the strong disk-corona coupling before the break, while the other component extends vertically, contributing to the reduction of the disk-corona coupling after the break. A further vertical expansion of the latter component is required to accommodate the dynamic evolution observed in the RMS-flux slope.
In conclusion, we suggest that the RMS-flux slope in 1–150 keV band can be employed as an indicator of the disk-corona coupling and the hard-to-hard state transition in MAXI J1820+070 could be partially driven by the changes in the corona geometry.","['accretion (14) – black holes (162) –', 'High energy astrophysics(739)']",['China']
"We study the efficiency of fair allocations using the well-studied price of fairness concept, which quantitatively measures the worst-case efficiency loss when imposing fairness constraints.
Previous works provided partial results on the price of fairness with well-known fairness notions such as envy-freeness up to one good (EF1) and envy-freeness up to any good (EFX).
In this paper, we give a complete characterization for the price of envy-freeness in various settings.
In particular, we first consider the two-agent case under the indivisible-goods setting and present tight ratios for the price of EF1 (for scaled utility) and EFX (for unscaled utility), which resolve questions left open in the literature.
Next, we consider the mixed goods setting which concerns a mixture of both divisible and indivisible goods.
We focus on envy-freeness for mixed goods (EFM), which generalizes both envy-freeness and EF1, as well as its strengthening called envy-freeness up to any good for mixed goods (EFXM), which generalizes envy-freeness and EFX.
To this end, we settle the price of EFM and EFXM by providing a complete picture of tight bounds for two agents and asymptotically tight bounds for n𝑛nitalic_n agents, for both scaled and unscaled utilities.",[],[]
"To gain a better understanding of the Andromeda galaxy M31 and its role in the Local Group, measuring its mass precisely is essential. In this work, we have constructed the rotation curve of M31 out to ∼similar-to\sim∼125 kpc using 13,679 M31 objects obtained from various sources, including the LAMOST data release 9 (LAMOST DR9), the DESI survey, and relevant literature. We divide all objects in our sample into bulge, disk and halo components. For the sources in the M31 disk, we have measured their circular velocities by a kinematic model with asymmetric drift corrections. For the bulge and halo objects, we calculate their velocity dispersions and use the spherical and projected Jeans equation to obtain the circular velocities. Our findings indicate a nearly isotropic nature for the M31 bulge, while the halo exhibits tangential anisotropy. The results show that the rotation curve remains constant at ∼similar-to\sim∼220 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT up to radius ∼similar-to\sim∼25 kpc and gradually decreases to ∼similar-to\sim∼170 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT further out. Based on the newly determined rotation curve, we have constructed a mass distribution model for M31. Our measurement of the M31 virial mass is Mvir=1.14−0.35+0.51×1012⁢M⊙subscript𝑀virsubscriptsuperscript1.140.510.35superscript1012subscript𝑀direct-productM_{\rm vir}=1.14^{+0.51}_{-0.35}\times 10^{12}M_{\odot}italic_M start_POSTSUBSCRIPT roman_vir end_POSTSUBSCRIPT = 1.14 start_POSTSUPERSCRIPT + 0.51 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.35 end_POSTSUBSCRIPT × 10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT within rvir=220±25subscript𝑟virplus-or-minus22025r_{\rm vir}=220\pm 25italic_r start_POSTSUBSCRIPT roman_vir end_POSTSUBSCRIPT = 220 ± 25 kpc.",[],[]
"Optical quantum routers which play a crucial role in quantum networks, have been extensively studied in both theory and experiment, resulting in significant advancements in their performance. However, these routers impose stringent requirements for achieving optimal routing performance, where the incident photon frequency must be in strict resonance with one or several specific frequencies. To address this challenge, we have designed an efficient quantum router capable of stable output with 100% transfer rate over the entire energy band of coupled-resonator waveguide (CRW) by coupling a giant atom to two or more semi-infinite CRWs. We also explain and prove the fundamental physical mechanism behind this distinctive phenomenon as the result of destructive interference between two waves composing the final reflected wave. We hope that quantum router with output results unaffected by the energy of the incoming information carriers present a more reliable solution for the implementation of quantum networks.
Keywords: Quantum Router, Single-Photon Router, Single-Photon Transport, Semi-Infinite Coupled-Resonator Waveguides, Giant Atom",[],['China']
,[],[]
"Diffusion models have emerged as powerful generative tools, rivaling GANs in sample quality and mirroring the likelihood scores of autoregressive models. A subset of these models, exemplified by DDIMs, exhibit an inherent asymmetry: they are trained over T𝑇Titalic_T steps but only sample from a subset of
T𝑇Titalic_T during generation. This selective sampling approach, though optimized for speed, inadvertently misses out on vital information from the unsampled steps, leading to potential compromises in sample quality. To address this issue, we present the S22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-DMs, which is a new training method by using an innovative Ls⁢k⁢i⁢psubscript𝐿𝑠𝑘𝑖𝑝L_{skip}italic_L start_POSTSUBSCRIPT italic_s italic_k italic_i italic_p end_POSTSUBSCRIPT, meticulously designed to reintegrate the information omitted during the selective sampling phase. The benefits of this approach are manifold: it notably enhances sample quality, is exceptionally simple to implement, requires minimal code modifications, and is flexible enough to be compatible with various sampling algorithms. On the CIFAR10 dataset, models trained using our algorithm showed an improvement of 3.27% to 14.06% over models trained with traditional methods across various sampling algorithms (DDIMs, PNDMs, DEIS) and different numbers of sampling steps (10, 20, …, 1000). On the CELEBA dataset, the improvement ranged from 8.97% to 27.08%. Access to the code and additional resources is provided in the github.","['Machine', 'Learning', 'ICML']",[]
"Quantum computing offers significant acceleration capabilities over its classical counterpart in various application domains. Consequently, there has been substantial focus on improving quantum computing capabilities. However, to date, the security implications of these quantum computing platforms have been largely overlooked. With the emergence of cloud-based quantum computing services, it is critical to investigate the extension of classical computer security threats to the realm of quantum computing.
In this study, we investigated timing-based side-channel vulnerabilities within IBM’s cloud-based quantum service.
The proposed attack effectively subverts the confidentiality of the executed quantum algorithm, using a more realistic threat model compared to existing approaches. Our experimental results, conducted using IBM’s quantum cloud service, demonstrate that with just 10 measurements, it is possible to identify the underlying quantum computer that executed the circuit. Moreover, when evaluated using the popular Grover circuit, we showcase the ability to leak the quantum oracle with a mere 500 measurements. These findings underline the pressing need to address timing-based vulnerabilities in quantum computing platforms and advocate for enhanced security measures to safeguard sensitive quantum algorithms and data.","['Quantum computing', 'side-channel', 'security', 'cloud computing', 'timing side-channel']",[]
"Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes or learning to directly generate the corresponding markup sequences from the table images. However, existing approaches either count on additional heuristic rules to recover the table structures, or face challenges in capturing long-range dependencies within tables, resulting in increased complexity. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time regresses logical location as well as spatial location of table cells in a unified network. Our proposed LORE is conceptually simpler, easier to train, and more accurate than other paradigms of TSR. Moreover, inspired by the persuasive success of pre-trained models on a number of computer vision and natural language processing tasks, we propose two pre-training tasks to enrich the spatial and logical representations at the feature level of LORE, resulting in an upgraded version called LORE++. The incorporation of pre-training in LORE++ has proven to enjoy significant advantages, leading to a substantial enhancement in terms of accuracy, generalization, and few-shot capability compared to its predecessor. Experiments on standard benchmarks against methods of previous paradigms demonstrate the superiority of LORE++, which highlights the potential and promising prospect of the logical location regression paradigm for TSR.","['Table structure recognition', 'pre-trained vision model', 'document understanding.']",[]
"The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at https://goatlmm.github.io/, contributing to ongoing research in this vital field.",[],[]
"Multimodal deep learning utilizing imaging and diagnostic reports has made impressive progress in the field of medical imaging diagnostics, demonstrating a particularly strong capability for auxiliary diagnosis in cases where sufficient annotation information is lacking. Nonetheless, localizing diseases accurately without detailed positional annotations remains a challenge. Although existing methods have attempted to utilize local information to achieve fine-grained semantic alignment, their capability in extracting the fine-grained semantics of the comprehensive contextual within reports is limited. To solve this problem, we introduce a new method that takes full sentences from textual reports as the basic units for local semantic alignment. Our approach combines chest X-ray images with their corresponding textual reports, performing contrastive learning at both global and local levels. The leading results obtained by our method on multiple datasets confirm its efficacy in the task of lesion localization.",[],[]
"FinTech platforms facilitated by digital payments are watching growth rapidly, which enable the distribution of mutual funds personalized to individual investors via mobile Apps. As the important intermediation of financial products investment, these platforms distribute thousands of mutual funds obtaining impressions under guaranteed delivery (GD) strategy required by fund companies. Driven by the profit from fund purchases of users, the platform aims to maximize each transaction amount of customers by promoting mutual funds to these investors who will be interested in. Different from the conversions in traditional advertising or e-commerce recommendations, the investment amount in each purchase varies greatly even for the same financial product, which provides a significant challenge for the promotion recommendation of mutual funds. In addition to predicting the click-through rate (CTR) or the conversion rate (CVR) as in traditional recommendations, it is essential for FinTech platforms to estimate the customers’ purchase amount for each delivered fund and achieve an effective allocation of impressions based on the predicted results to optimize the total expected transaction value (ETV). In this paper, we propose an ETV-optimized customer allocation framework (EOCA) that aims to maximize the total ETV of recommended funds, under the constraints of GD dealt with fund companies. EOCA consists of two phases: a prediction phase of the customer purchase amount followed by a constrained allocation phase. Specifically, we propose an entire space deep probabilistic model with a novel-designed loss function to predict the purchase amount when a promotional fund is exposed to a user, which involves not only the conversion rate prediction but also the post-conversion purchase amount estimation. Based on the predicted ETV, we design a heuristic algorithm to solve the large-scale constrained combinatorial optimization problem to suggest which fund each user should be exposed to in order to maximize the total purchase amount. To the best of our knowledge, it’s the first attempt to solve the GD problem for financial product promotions based on customer purchase amount prediction. We conduct extensive experiments on large-scale real-world datasets and online tests based on LiCaiTong, Tencent’s wealth management platform, to demonstrate the effectiveness of our proposed EOCA framework.","['FinTech platform', 'customer allocation', 'purchase amount prediction']",['China']
"We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",[],[]
"Modern recommender systems have seen substantial success, yet they remain vulnerable to malicious activities, notably poisoning attacks. These attacks involve injecting malicious data into the training datasets of RS, thereby compromising their integrity and manipulating recommendation outcomes for gaining illicit profits. This survey paper provides a systematic and up-to-date review of the research landscape on Poisoning Attacks against Recommendation (PAR). A novel and comprehensive taxonomy is proposed, categorizing existing PAR methodologies into three distinct categories: Component-Specific, Goal-Driven, and Capability Probing. For each category, we discuss its mechanism in detail, along with associated methods. Furthermore, this paper highlights potential future research avenues in this domain. Additionally, to facilitate and benchmark the empirical comparison of PAR, we introduce an open-source library, ARLib, which encompasses a comprehensive collection of PAR models and common datasets. The library is released at https://github.com/CoderWZW/ARLib.",[],[]
"Two-sided matching markets have been widely studied in the literature due to their rich applications. Since participants are usually uncertain about their preferences, online algorithms have recently been adopted to learn them through iterative interactions. Wang et al. (2022) initiate the study of this problem in a many-to-one setting with responsiveness. However, their results are far from optimal and lack guarantees of incentive compatibility. An extension of Kong and Li (2023) to this more general setting achieves a near-optimal bound for player-optimal regret. Nevertheless, due to the substantial requirement for collaboration, a single player’s deviation could lead to a huge increase in its own cumulative rewards and an O⁢(T)𝑂𝑇O(T)italic_O ( italic_T ) regret for others. In this paper, we aim to enhance the regret bound in many-to-one markets while ensuring incentive compatibility. We first propose the adaptively explore-then-deferred-acceptance (AETDA) algorithm for responsiveness setting and derive an O⁢(N⁢min⁡{N,K}⁢C⁢log⁡T/Δ2)𝑂𝑁𝑁𝐾𝐶𝑇superscriptΔ2O(N\min\left\{N,K\right\}C\log T/\Delta^{2})italic_O ( italic_N roman_min { italic_N , italic_K } italic_C roman_log italic_T / roman_Δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) upper bound for player-optimal stable regret while demonstrating its guarantee of incentive compatibility, where N𝑁Nitalic_N represents the number of players, K𝐾Kitalic_K is the number of arms, T𝑇Titalic_T denotes the time horizon, C𝐶Citalic_C is arms’ total capacities and ΔΔ\Deltaroman_Δ signifies the minimum preference gap among players. This result is a significant improvement over Wang et al. (2022). And to the best of our knowledge, it constitutes the first player-optimal guarantee in matching markets that offers such robust assurances. We also consider broader substitutable preferences, one of the most general conditions to ensure the existence of a stable matching and cover responsiveness. We devise an online DA (ODA) algorithm and establish an O⁢(N⁢K⁢log⁡T/Δ2)𝑂𝑁𝐾𝑇superscriptΔ2O(NK\log T/\Delta^{2})italic_O ( italic_N italic_K roman_log italic_T / roman_Δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) player-pessimal stable regret bound for this setting. Compared with Wang et al. (2022), this algorithm not only achieves a better result but also applies to more general markets.",[],[]
"Video Question Answering (VideoQA) has emerged as a vital tool to evaluate agents’ ability to understand human daily behaviors. Despite the recent success of large vision language models in many multi-modal tasks, complex situation reasoning over videos involving multiple human-object interaction events still remains challenging. In contrast, humans can easily tackle it by using a series of episode memories as anchors to quickly locate question-related key moments for reasoning. To mimic this effective reasoning strategy, we propose the Glance-Focus model. One simple way is to apply an action detection model to predict a set of actions as key memories. However, these actions within a closed set vocabulary are hard to generalize to various video domains. Instead of that, we train an Encoder-Decoder to generate a set of dynamic event memories at the glancing stage. Apart from using supervised bipartite matching to obtain the event memories, we further design an unsupervised memory generation method to get rid of dependence on event annotations. Next, at the focusing stage, these event memories act as a bridge to establish the correlation between the questions with high-level event concepts and low-level lengthy video content. Given the question, the model first focuses on the generated key event memory, then focuses on the most relevant moment for reasoning through our designed multi-level cross-attention mechanism. We conduct extensive experiments on four Multi-Event VideoQA benchmarks including STAR, EgoTaskQA, AGQA, and NExT-QA. Our proposed model achieves state-of-the-art results, surpassing current large models in various challenging reasoning tasks. The code and models are available at https://github.com/ByZ0e/Glance-Focus.",[],[]
"Thouless pumping, a dynamical version of the integer quantum Hall effect, represents the quantized charge pumped during an adiabatic cyclic evolution. Here we report experimental observations of nontrivial topological pumping that is induced by disorder even during a topologically trivial pumping trajectory. With a 41-qubit superconducting quantum processor, we develop a Floquet engineering technique to realize cycles of adiabatic pumping by simultaneously varying the on-site potentials and the hopping couplings. We demonstrate Thouless pumping in the presence of disorder and show its breakdown as the strength of disorder increases. Moreover, we observe two types of topological pumping that are induced by on-site potential disorder and hopping disorder, respectively. Especially, an intrinsic topological pump that is induced by quasi-periodic hopping disorder has never been experimentally realized before. Our highly controllable system provides a valuable quantum simulating platform for studying various aspects of topological physics in the presence of disorder.",[],"['Japan', 'China']"
"This paper explores opportunities and challenges of task (goal)-oriented and semantic communications for next-generation (NextG) communication networks through the integration of multi-task learning. This approach employs deep neural networks representing a dedicated encoder at the transmitter and multiple task-specific decoders at the receiver, collectively trained to handle diverse tasks including semantic information preservation, source input reconstruction, and integrated sensing and communications. To extend the applicability from point-to-point links to multi-receiver settings, we envision the deployment of decoders at various receivers, where decentralized learning addresses the challenges of communication load and privacy concerns, leveraging federated learning techniques that distribute model updates across decentralized nodes. However, the efficacy of this approach is contingent on the robustness of the employed deep learning models. We scrutinize potential vulnerabilities stemming from adversarial attacks during both training and testing phases. These attacks aim to manipulate both the inputs at the encoder at the transmitter and the signals received over the air on the receiver side, highlighting the importance of fortifying semantic communications against potential multi-domain exploits. Overall, the joint and robust design of task-oriented communications, semantic communications, and integrated sensing and communications in a multi-task learning framework emerges as the key enabler for context-aware, resource-efficient, and secure communications ultimately needed in NextG network systems.","['Task-oriented communications', 'semantic communications', 'integrated sensing and communications', 'deep learning', 'multi-task learning', 'distributed learning', 'security.']",[]
"Zermelo navigation is not only a fundamental tool in Finsler geometry but also a fundamental approach to the geometrization of dynamics in physics. In this paper, we consider the Zermelo navigation problem on optical Riemannian space and, via Zermelo/Randers/spacetime triangle, explore the generation of new spacetimes from pre-existing ones. Whether the Randers metric has reversible geodesics corresponds to the presence of time-reversal symmetry in the generated spacetime. In cases where the Randers metric has reversible geodesics, we utilize a radial vector field to generate new static spacetimes from existing ones. For example, we can generate Schwarzschild, Rindler, de Sitter, and Schwarzschild-de Sitter spacetimes from flat spacetime. In fact, the Zermelo navigation method allows for the derivation of a variety of static spacetimes from flat spacetime. For multi-parameter spacetimes, they can be generated through various navigation paths. However, for some spacetimes, not all navigation paths may exist. In the second scenario, when the Randers metric does not have reversible geodesics, we employ a rotational vector field to transform non-flat static metrics into slowly rotating spacetimes. Alternatively, using a mixed vector field, we generate slowly rotating spacetimes starting from flat spacetime. We provide examples of generating Kerr spacetimes and Kerr-de Sitter spacetimes.",[],['China']
"In this article, we introduce a notion of twisted set-theoretic Yang-Baxter solution, which is a triplet (X,f,R)𝑋𝑓𝑅(X,f,R)( italic_X , italic_f , italic_R ), where (X,R)𝑋𝑅(X,R)( italic_X , italic_R ) is a Yang-Baxter set and f:X→X:𝑓→𝑋𝑋f:X\to Xitalic_f : italic_X → italic_X is an automorphism of (X,R)𝑋𝑅(X,R)( italic_X , italic_R ). We present a cohomology theory for it, and use cocycles of twisted biquandles in amalgamation with Alexander numbering to construct state-sum invariant of knots and knotted surfaces. Additionally, we introduce a twisted version of cohomology theory for Yang-Baxter sets and give applications to knot theory.","['Twisted', 'Yang-Baxter sets', 'cohomology', 'twisted biquandles', 'cocycle knot invariants']",[]
"The goal of this Article is to perform a systematic study the global entanglement and coherence length dynamics in a natural light-harvesting system Fenna-–Matthews–-Olson (FMO) complex across various parameters of a dissipative environment from low to high temperatures, weak to strong system-environment coupling, and non-Markovian environments. The non-perturbative numerically exact hierarchical equations of motions method is employed to generate the dynamics of the system. We found that entanglement is driven primarily by the strength of interaction between the system and environment, and it is modulated by the interplay between temperature and non-Markovianity. In contrast, coherence length is found not to be sensitive to non-Markovianity. Our results do not show the direct correlation between global entanglement and the efficiency of the excitation energy transfer.",[],[]
"This is the first paper in a series that studies
smooth relative Lie algebra homologies and cohomologies
based on the theory of formal manifolds and formal Lie groups.
In this paper, we lay the foundations for this study by introducing the notion of formal manifolds in the context of differential geometry, inspired by the notion of formal schemes in algebraic geometry.
We develop the basic theory for formal manifolds, including a generalization of the theory of vector-valued distributions and generalized functions on smooth manifolds to the setting of formal manifolds. Additionally, we establish Poincaré’s lemma for de Rham complexes with coefficients in formal functions, formal generalized functions, compactly supported formal densities, or compactly supported formal distributions.","['manifold', 'generalized function', 'de', 'Rham complex', 'Poincaré’s lemma']",[]
"We establish a connection between the Alexander polynomial of a knot and its
twisted and L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-versions with the triangulations that appear in
3-dimensional hyperbolic geometry. Specifically, we introduce twisted
Neumann–Zagier matrices of ordered ideal triangulations and use them to provide
formulas for the Alexander polynomial and its variants, the twisted Alexander
polynomial and the L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-Alexander torsion.","['Alexander polynomial', 'twisted', 'Alexander polynomial', 'L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-Alexander torsion', 'Neumann–Zagier matrices', 'ordered ideal triangulation', 'Mahler measure', 'Fuglede-Kadison determinant']",[]
"The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while maintaining exceptional accuracy with non-poisoned datasets.",[],[]
"Coherent small-amplitude unsteadiness of the shock wave and the separation region over a canonical double cone flow, termed in literature as oscillation-type unsteadiness, is experimentally studied at Mach 6. The double cone model is defined by three non-dimensional geometric parameters: fore- and aft-cone angles (θ1subscript𝜃1\theta_{1}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and θ2subscript𝜃2\theta_{2}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), and ratio of the conical slant lengths (ΛΛ\Lambdaroman_Λ). Previous studies of oscillations have been qualitative in nature, and mostly restricted to a special case of the cone model with fixed θ1=0∘subscript𝜃1superscript0\theta_{1}=0^{\circ}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT and θ2=90∘subscript𝜃2superscript90\theta_{2}=90^{\circ}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT (referred to as the spike-cylinder model), where ΛΛ\Lambdaroman_Λ becomes the sole governing parameter. In the present effort we investigate the self-sustained flow oscillations in the θ1subscript𝜃1\theta_{1}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-ΛΛ\Lambdaroman_Λ parameter space for fixed θ2=90∘subscript𝜃2superscript90\theta_{2}=90^{\circ}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT using time-resolved schlieren visualization. The experiments reveal two distinct sub-types of oscillations, characterized by the motion (or lack thereof) of the separation point on the fore-cone surface. The global time scale associated with flow oscillation is extracted using spectral proper orthogonal decomposition. The non-dimensional frequency (Strouhal number) of oscillation is seen to exhibit distinct scaling for the two oscillation sub-types. The relationship observed between the local flow properties, instability of the shear layer, and geometric constraints on the flow suggests that an aeroacoustic feedback mechanism sustains the oscillations. Based on this insight, a simple model with no empiricism is developed for the Strouhal number. The model predictions are found to match well with experimental measurements. The model provides helpful physical insight into the nature of the self-sustained flow oscillations over a double cone at high-speeds.",[],[]
,[],[]
"We compare, with data from the quasars, the Hubble parameter measurements, and the Pantheon+ type Ia supernova, three different relations between X-ray luminosity (LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT) and ultraviolet luminosity (LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT) of quasars. These three relations consist of the standard and two redshift-evolutionary LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT-LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT relations which are constructed respectively by considering a redshift dependent correction to the luminosities of quasars and using the statistical tool called copula. By employing the PAge approximation for a cosmological-model-independent description of the cosmic background evolution and dividing the quasar data into the low-redshift and high-redshift parts, we find that the constraints on the PAge parameters from the low-redshift and high-redshift data, which are obtained with the redshift-evolutionary relations, are consistent with each other, while they are not when the standard relation is considered. If the data are used to constrain the coefficients of the relations and the PAge parameters simultaneously, then the observations support the redshift-evolutionary relations at more than 3⁢σ3𝜎3\sigma3 italic_σ. The Akaike and Bayes information criteria indicate that there is strong evidence against the standard relation and mild evidence against the redshift-evolutionary relation constructed by considering a redshift dependent correction to the luminosities of quasars. This suggests that the redshift-evolutionary LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT-LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT relation of quasars constructed from copula is favored by the observations.",[],['China']
"We study the issue of temperature in a steady system around a black hole event horizon, contrasting it with the appearance of divergence in a thermal equilibrium system.
We focus on a spherically symmetric system governed by general relativity, particularly examining the steady state with radial heat conduction.
Employing an appropriate approximation, we derive exact solutions that illuminate the behaviors of number density, local temperature, and heat in the proximity of a black hole.
We demonstrate that a carefully regulated heat inflow can maintain finite local temperatures at the black hole event horizon, even without considering the back-reaction of matter.
This discovery challenges conventional expectations that the local temperature near the event horizon diverges in scenarios of thermal equilibrium.
This implications shows that there’s an intricate connection between heat and gravity in the realm of black hole thermodynamics.",[],[]
,[],[]
"Quantization is of significance for compressing the over-parameterized deep neural models and deploying them on resource-limited devices.
Fixed-precision quantization suffers from
performance drop due to the limited numerical representation ability.
Conversely, mixed-precision quantization (MPQ) is advocated to compress the model effectively by allocating heterogeneous bit-width for layers. MPQ is typically organized into a searching-retraining two-stage process. Previous works only focus on determining the optimal bit-width configuration in the first stage efficiently, while ignoring the considerable time costs in the second stage.
However, retraining always consumes hundreds of GPU-hours on the cutting-edge GPUs, thus hindering deployment efficiency significantly.
In this paper, we devise a one-shot training-searching paradigm for mixed-precision model compression.
Specifically, in the first stage, all potential bit-width configurations are coupled and thus optimized simultaneously within a set of shared weights.
However, our observations reveal a previously unseen and severe bit-width interference phenomenon among highly coupled weights during optimization, leading to considerable performance degradation under a high compression ratio.
To tackle this problem, we first design a bit-width scheduler to dynamically freeze the most turbulent bit-width of layers during training, to ensure the rest bit-widths converged properly.
Then, taking inspiration from information theory, we present an information distortion mitigation technique to align the behaviour of the bad-performing bit-widths to the well-performing ones.
In the second stage, an inference-only greedy search scheme is devised to evaluate the goodness of configurations without introducing any additional training costs.
Extensive experiments on three representative models and three datasets demonstrate the effectiveness of the proposed method.",[],[]
"Autonomous driving has attracted significant attention from both academia and industries, which is expected to offer a safer and more efficient driving system.
However, current autonomous driving systems are mostly based on a single vehicle, which has significant limitations which still poses threats to driving safety. Collaborative perception with connected and autonomous vehicles (CAVs) shows a promising solution to overcoming these limitations. In this article, we first identify the challenges of collaborative perception, such as data sharing asynchrony, data volume, and pose errors. Then, we discuss the possible solutions to address these challenges with various technologies, where the research opportunities are also elaborated. Furthermore, we propose a scheme to deal with communication efficiency and latency problems, which is a channel-aware collaborative perception framework to dynamically adjust the communication graph and minimize latency, thereby improving perception performance while increasing communication efficiency.
Finally, we conduct experiments to demonstrate the effectiveness of our proposed scheme.","['Collaborative perception', 'autonomous driving', 'connected and autonomous vehicle', 'vehicle-to-everything (V2X) communication.']",[]
"We propose DDN-SLAM, a real-time dense neural implicit semantic SLAM system designed for dynamic scenes. While existing neural implicit SLAM systems perform well in static scenes, they often encounter challenges in real-world environments with dynamic interferences, leading to ineffective tracking and mapping. DDN-SLAM utilizes the priors provided by the deep semantic system, combined with conditional probability fields, for segmentation.By constructing depth-guided static masks and employing joint multi-resolution hashing encoding, we ensure fast hole filling and high-quality mapping while mitigating the effects of dynamic information interference. To enhance tracking robustness, we utilize sparse feature points validated with optical flow and keyframes, enabling loop closure detection and global bundle optimization. Furthermore, DDN-SLAM supports monocular, stereo, and RGB-D inputs, operating robustly at a frequency of 20-30Hz. Extensive experiments on 6 virtual/real datasets demonstrate that our method outperforms state-of-the-art approaches in both dynamic and static scenes.",[],[]
,[],[]
"Understanding if attractive fermions in an unbalanced occupation of its flavors can give rise to a superfluid state in two dimensions (2D), realizing the Fulde-Ferrel-Larkin-Ovchinnikov (FFLO) state, presents a long-standing question. A limitation on its solution by numerics is posed by the sign problem, which constrains the applicability of quantum Monte Carlo techniques at sufficiently low temperatures and large lattice sizes, where a potential signature of polarized superfluidity would be unambiguous. By using a recently explored argument that the sign problem may be used instead to infer quantum critical behavior, we explore the regime where partial polarization occurs in the phase diagram, further showing that the average sign ⟨𝒮⟩delimited-⟨⟩𝒮\langle{\cal S}\rangle⟨ caligraphic_S ⟩ of quantum Monte Carlo weights tracks the criticality between balanced (or fully polarized) and polarized phases. Using the attractive Hubbard model with an unbalanced population, our investigation expands the scope of problems in which ⟨𝒮⟩delimited-⟨⟩𝒮\langle{\cal S}\rangle⟨ caligraphic_S ⟩ can be used for monitoring critical behavior, providing compelling albeit indirect evidence for the robustness of an FFLO phase in 2D.",[],['China']
"Implicit Neural Representation (INR) has emerged as an effective method for unsupervised image denoising. However, INR models are typically overparameterized; consequently, these models are prone to overfitting during learning, resulting in suboptimal results, even noisy ones. To tackle this problem, we propose a general recipe for regularizing INR models in image denoising. In detail, we propose to iteratively substitute the supervision signal with the mean value derived from both the prediction and supervision signal during the learning process. We theoretically prove that such a simple iterative substitute can gradually enhance the signal-to-noise ratio of the supervision signal, thereby benefiting INR models during the learning process. Our experimental results demonstrate that INR models can be effectively regularized by the proposed approach, relieving overfitting and boosting image denoising performance.",[],[]
"Despite the recent progress in deep neural networks (DNNs), it remains challenging to explain the predictions made by DNNs. Existing explanation methods for DNNs mainly focus on post-hoc explanations where another explanatory model is employed to provide explanations. The fact that post-hoc methods can fail to reveal the actual original reasoning process of DNNs raises the need to build DNNs with built-in interpretability. Motivated by this, many self-explaining neural networks have been proposed to generate not only accurate predictions but also clear and intuitive insights into why a particular decision was made. However, existing self-explaining networks are limited in providing distribution-free uncertainty quantification for the two simultaneously generated prediction outcomes (i.e., a sample’s final prediction and its corresponding explanations for interpreting that prediction). Importantly, they also fail to establish a connection between the confidence values assigned to the generated explanations in the interpretation layer and those allocated to the final predictions in the ultimate prediction layer. To tackle the aforementioned challenges, in this paper, we design a novel uncertainty modeling framework for self-explaining networks, which not only demonstrates strong distribution-free uncertainty modeling performance for the generated explanations in the interpretation layer but also excels in producing efficient and effective prediction sets for the final predictions based on the informative high-level basis explanations. We perform the theoretical analysis for the proposed framework. Extensive experimental evaluation demonstrates the effectiveness of the proposed uncertainty framework.",[],[]
"The Atomic Cluster Expansion (ACE) (Drautz, Phys. Rev. B 99, 2019) has been widely applied in high energy physics, quantum mechanics and atomistic modeling to construct many-body interaction models respecting physical symmetries. Computational efficiency is achieved by allowing non-physical self-interaction terms in the model.
We propose and analyze an efficient method to evaluate and parameterize an orthogonal, or, non-self-interacting cluster expansion model. We present numerical experiments demonstrating improved conditioning and more robust approximation properties than the original expansion in regression tasks both in simplified toy problems and in applications in the machine learning of interatomic potentials.",[],[]
,[],[]
"Point cloud completion is an indispensable task for recovering complete point clouds due to incompleteness caused by occlusion, limited sensor resolution, etc.
The family of coarse-to-fine generation architectures has recently exhibited great success in point cloud completion and gradually became mainstream.
In this work, we unveil one of the key ingredients behind these methods: meticulously devised feature extraction operations with explicit cross-resolution aggregation.
We present Cross-Resolution Transformer that efficiently performs cross-resolution aggregation with local attention mechanisms.
With the help of our recursive designs, the proposed operation can capture more scales of features than common aggregation operations, which is beneficial for capturing fine geometric characteristics.
While prior methodologies have ventured into various manifestations of inter-level cross-resolution aggregation, the effectiveness of intra-level one and their combination has not been analyzed.
With unified designs, Cross-Resolution Transformer can perform intra- or inter-level cross-resolution aggregation by switching inputs.
We integrate two forms of Cross-Resolution Transformers into one up-sampling block for point generation, and following the coarse-to-fine manner, we construct CRA-PCN to incrementally predict complete shapes with stacked up-sampling blocks.
Extensive experiments demonstrate that our method outperforms state-of-the-art methods by a large margin on several widely used benchmarks.
Codes are available at https://github.com/EasyRy/CRA-PCN.",[],[]
"Multi-modal Learning has attracted widespread attention in medical image analysis. Using multi-modal data, whole slide images (WSIs) and clinical information, can improve the performance of deep learning models in the diagnosis of axillary lymph node metastasis. However, clinical information is not easy to collect in clinical practice due to privacy concerns, limited resources, lack of interoperability, etc.
Although patient selection can ensure the training set to have multi-modal data for model development, missing modality of clinical information can appear during test. This normally leads to performance degradation, which limits the use of multi-modal models in the clinic. To alleviate this problem, we propose a bidirectional distillation framework consisting of a multi-modal branch and a single-modal branch. The single-modal branch acquires the complete multi-modal knowledge from the multi-modal branch, while the multi-modal learns the robust features of WSI from the single-modal. We conduct experiments on a public dataset of Lymph Node Metastasis in Early Breast Cancer to validate the method. Our approach not only achieves state-of-the-art performance with an AUC of 0.861 on the test set without missing data, but also yields an AUC of 0.842 when the rate of missing modality is 80%. This shows the effectiveness of the approach in dealing with multi-modal data and missing modality. Such a model has the potential to improve treatment decision-making for early breast cancer patients who have axillary lymph node metastatic status.","['Missing modality', 'Whole slide image', 'Clinical data.']",[]
"The quantum SearchRank algorithm is a promising tool for a future quantum search engine based on PageRank quantization. However, this algorithm loses its functionality when the N/M𝑁𝑀N/Mitalic_N / italic_M ratio between the network size N𝑁Nitalic_N and the number of marked nodes M𝑀Mitalic_M is sufficiently large. We propose a modification of the algorithm, replacing the underlying Szegedy quantum walk with a semiclassical walk. To maintain the same time complexity as the quantum SearchRank algorithm we propose a simplification of the algorithm. This new algorithm is called Randomized SearchRank, since it corresponds to a quantum walk over a randomized mixed state. The performance of the SearchRank algorithms is first analyzed on an example network, and then statistically on a set of different networks of increasing size and different number of marked nodes. On the one hand, to test the search ability of the algorithms, it is computed how the probability of measuring the marked nodes decreases with N/M𝑁𝑀N/Mitalic_N / italic_M for the quantum SearchRank, but remarkably it remains at a high value around 0.90.90.90.9 for our semiclassical algorithms, solving the quantum SearchRank problem. The time complexity of the algorithms is also analyzed, obtaining a quadratic speedup with respect to the classical ones. On the other hand, the ranking functionality of the algorithms has been investigated, obtaining a good agreement with the classical PageRank distribution. Finally, the dependence of these algorithms on the intrinsic PageRank damping parameter has been clarified. Our results suggest that this parameter should be below a threshold so that the execution time does not increase drastically.",[],['Spain']
"We investigate the problem of holomorphic algebraizibility for real hypersurfaces in complex space. We introduce a new invariant of a (real-analytic) Levi-nondegenerate hypersurface called the jet transcendence degree. Using this invariant, we solve in the negative the Conjecture of Huang, Ji and Yau on the algabraizability of real hypersurfaces with algebraic syzygies.",[],[]
There has recently been some interest in optimizing the error term in the asymptotic for the fourth moment of Dirichlet L𝐿Litalic_L-functions and a closely related mixed moment of L𝐿Litalic_L-functions involving automorphic L𝐿Litalic_L-functions twisted by Dirichlet characters. We obtain an improvement for the error term of the latter.,"['Dirichlet', 'L𝐿Litalic_L-functions', 'modular forms', 'moments.']",[]
"The use of very high energy electrons (VHEE) for radiotherapy has been actively studied for over two decades due to its advantageous dose distribution, deep penetration depth and great potential of ultra-high dose-rate irradiation. However, the high entrance dose of VHEE beams can damage the surface skin of patients and hinder its widespread application. To address this challenge, a novel method utilizing only two dipole magnets is presented in this article. By adjusting the magnet strengths, the electron beams can be guided along different angular directions towards a specific position as deep as 20 cm inside a water phantom, creating a maximum dose over the target region and significantly reducing the entrance dose Supported by Monte Carlo simulations, such a beam delivery approach contains two major advantages over previous methods: first, it is insensitive to beam energy spread, releasing the constraints on accelerator performance, and second, the dose peak position can be accurately controlled in both lateral and longitudinal directions. In addition, we also show that a flattop dose peak can be generated by the weighted sum of VHEE beams focusing at different positions. These results demonstrate that VHEE beams can be compactly delivered into a deep-seated tumor region in a controllable manner, thus advancing the development of the VHEE radiotherapy towards the practical clinical applications in the near future.",[],['China']
"Late fusion multi-view clustering (LFMVC) has become a rapidly growing class of methods in the multi-view clustering (MVC) field, owing to its excellent computational speed and clustering performance. One bottleneck faced by existing late fusion methods is that they are usually aligned to the average kernel function, which makes the clustering performance highly dependent on the quality of datasets. Another problem is that they require subsequent k-means clustering after obtaining the consensus partition matrix to get the final discrete labels, and the resulting separation of the label learning and cluster structure optimization processes limits the integrity of these models. To address the above issues, we propose an integrated framework named One-Step Late Fusion Multi-view Clustering with Compressed Subspace (OS-LFMVC-CS). Specifically, we use the consensus subspace to align the partition matrix while optimizing the partition fusion, and utilize the fused partition matrix to guide the learning of discrete labels. A six-step iterative optimization approach with verified convergence is proposed. Sufficient experiments on multiple datasets validate the effectiveness and efficiency of our proposed method.",[],[]
"There is growing evidence that high-mass star formation (HMSF) is a multiscale, dynamical process in molecular clouds, where filaments transport gas material between larger and smaller scales. We analyze here multiscale gas dynamics in an HMSF filamentary cloud, G034.43+00.24 (G34), using APEX observations of C1818{}^{18}start_FLOATSUPERSCRIPT 18 end_FLOATSUPERSCRIPTO (2-1), HCO+{}^{+}start_FLOATSUPERSCRIPT + end_FLOATSUPERSCRIPT/H1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCO+{}^{+}start_FLOATSUPERSCRIPT + end_FLOATSUPERSCRIPT (3-2), and HCN/H1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCN (3-2) lines. We find large-scale, filament-aligned velocity gradients from C1818{}^{18}start_FLOATSUPERSCRIPT 18 end_FLOATSUPERSCRIPTO emission, which drive filamentary gas inflows onto dense clumps in the middle ridge of G34. The nature of these inflows is gravity-driven.
We also find clump-scale gas infall in the middle ridge of MM2, MM4, and MM5 clumps from other lines. Their gas infall rates could depend on large-scale filamentary gas inflows since the infall/inflow rates on these two scales are comparable.
We confirm that the multiscale, dynamical HMSF scenario is at work in G34.
It could be driven by gravity up to the filament scale, beyond which turbulence originating from several sources including gravity could be in effect in G34.","['Star forming regions (1565)', 'Molecular clouds (1072)', 'Infrared dark clouds (787)', 'High-mass stars (1834)', 'Molecular gas (1073)']",['China']
"Ultra-low-noise laser sources are crucial for a variety of applications, including microwave synthesizers, optical gyroscopes, and the manipulation of quantum systems. Silicon photonics has emerged as a promising solution for high-coherence applications due to its ability to reduce system size, weight, power consumption, and cost (SWaP-C). Semiconductor lasers based on self-injection locking (SIL) have reached fiber laser coherence, but typically require a high-Q external cavity to suppress coherence collapse through frequency-selective feedback. Lasers based on external-cavity locking (ECL) are a low-cost and turnkey operation option, but their coherence is generally inferior to SIL lasers. In this work, we demonstrate quantum-dot (QD) lasers grown directly on Si that achieve SIL laser coherence under turnkey ECL. The high-performance QD laser offers a scalable and low-cost heteroepitaxial integration platform. Moreover, the QD laser’s chaos-free nature enables a 16 Hz Lorentzian linewidth under ECL using a low-Q external cavity, and improves the frequency noise by an additional order of magnitude compared to conventional quantum-well lasers.",[],[]
"We present recent progress in calculating the semileptonic
form factors hA1⁢(w)subscriptℎsubscript𝐴1𝑤h_{A_{1}}(w)italic_h start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_w ) for the B¯→D∗⁢ℓ⁢ν¯→¯𝐵superscript𝐷∗ℓ¯𝜈\bar{B}\to D^{\ast}\ell\bar{\nu}over¯ start_ARG italic_B end_ARG → italic_D start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT roman_ℓ over¯ start_ARG italic_ν end_ARG decays.
We use the Oktay-Kronfeld (OK) action for the charm and bottom
valence quarks and the HISQ action for light quarks.
We adopt the Newton method combined with the scanning method to
find a good initial guess for the χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT minimizer in the fitting
of the 2pt correlation functions.
The main advantage is that the Newton method lets us to consume all
the time slices allowed by the physical positivity.
We report the first, reliable, but preliminary results for
hA1⁢(w)/ρA1subscriptℎsubscript𝐴1𝑤subscript𝜌subscript𝐴1h_{A_{1}}(w)/\rho_{A_{1}}italic_h start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_w ) / italic_ρ start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT at zero recoil (w=1𝑤1w=1italic_w = 1).
Here we use a MILC HISQ ensemble (a=0.12𝑎0.12a=0.12italic_a = 0.12 fm, Mπsubscript𝑀𝜋M_{\pi}italic_M start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT = 220
MeV, and Nf=2+1+1subscript𝑁𝑓211N_{f}=2+1+1italic_N start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = 2 + 1 + 1 flavors).",[],[]
"Identifying a reasonably small Hilbert space that completely describes an unknown quantum state is crucial for efficient quantum information processing. We introduce a general dimension-certification protocol for both discrete and continuous variables that is fully evidence-based, relying solely on the experimental data collected and no other assumptions whatsoever. Using the Bayesian concept of relative belief, we take the effective dimension of the state as the smallest one such that the posterior probability is larger than the prior, as dictated by the data. The posterior probabilities associated with the relative-belief ratios measure the strength of the evidence provide by these ratios so that we can assess whether there is weak or strong evidence in favor or against a particular dimension. Using experimental data from spectral-temporal and polarimetry measurements, we demonstrate how to correctly assign Bayesian plausible error bars for the obtained effective dimensions. This makes relative belief a conservative and easy-to-use model-selection method for any experiment.",[],"['Germany', 'Spain', 'Belarus', 'Canada']"
"Evolutionary Multitasking (EMT) paradigm, an emerging research topic in evolutionary computation, has been successfully applied in solving high-dimensional feature selection (FS) problems recently.
However, existing EMT-based FS methods suffer from several limitations, such as a single mode of multitask generation, conducting the same generic evolutionary search for all tasks, relying on implicit transfer mechanisms through sole solution encodings, and employing single-objective transformation, which result in inadequate knowledge acquisition, exploitation, and transfer.
To this end, this paper develops a novel EMT framework for multiobjective high-dimensional feature selection problems, namely MO-FSEMT. In particular, multiple auxiliary tasks are constructed by distinct formulation methods to provide diverse search spaces and information representations and then simultaneously addressed with the original task through a multi-slover-based multitask optimization scheme. Each task has an independent population with task-specific representations and is solved using separate evolutionary solvers with different biases and search preferences. A task-specific knowledge transfer mechanism is designed to leverage the advantage information of each task, enabling the discovery and effective transmission of high-quality solutions during the search process.
Comprehensive experimental results demonstrate that our MO-FSEMT framework can achieve overall superior performance compared to the state-of-the-art FS methods on 26 datasets. Moreover, the ablation studies verify the contributions of different components of the proposed MO-FSEMT.","['Feature selection', 'Evolutionary', 'Multitasking', 'High-dimensional classification', 'Multi-objective optimization']",[]
"We consider multi-user semantic communications over broadcast channels. While most existing works consider that each receiver requires either the same or independent semantic information, this paper explores the scenario where the semantic information desired by different receivers is different but correlated. In particular, we investigate semantic communications over Gaussian broadcast channels where the transmitter has a common observable source but the receivers wish to recover hierarchical semantic information in adaptation to their channel conditions. Inspired by the capacity achieving property of superposition codes, we propose a deep learning based superposition coded modulation (DeepSCM) scheme. Specifically, the hierarchical semantic information is first extracted and encoded into basic and enhanced feature vectors. A linear minimum mean square error (LMMSE) decorrelator is then developed to obtain a refinement from the enhanced features that is uncorrelated with the basic features. Finally, the basic features and their refinement are superposed for broadcasting after probabilistic modulation. Experiments are conducted for two-receiver image semantic broadcasting with coarse and fine classification as hierarchical semantic tasks. DeepSCM outperforms the benchmarking coded-modulation scheme without a superposition structure, especially with large channel disparity and high order modulation. It also approaches the performance upperbound as if there were only one receiver.","['Semantic communications', 'digital modulation', 'superposition coding', 'broadcast channel.']",[]
,[],[]
"We describe team ielab from CSIRO and The University of Queensland’s approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval.",[],[]
"Mergers of binary compact objects, accompanied with electromagnetic (EM) counterparts, offer excellent opportunities to explore varied cosmological models, since gravitational waves (GW) and EM counterparts always carry the information of luminosity distance and redshift, respectively.
f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity, which alters the background evolution and provides a friction term in the propagation of GW, can be tested by comparing the modified GW luminosity distance with the EM luminosity distance. Considering the third–generation gravitational–wave detectors, Einstein Telescope and two Cosmic Explorers, we simulate a series of GW events of binary neutron stars (BNS) and neutron-star-black-hole (NSBH) binary with EM counterparts. These simulations can be used to constrain f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity (specially the Power-law model f⁢(T)=T+α⁢(−T)β𝑓𝑇𝑇𝛼superscript𝑇𝛽f(T)=T+\alpha(-T)^{\beta}italic_f ( italic_T ) = italic_T + italic_α ( - italic_T ) start_POSTSUPERSCRIPT italic_β end_POSTSUPERSCRIPT in this work) and other cosmological parameters, such as β𝛽\betaitalic_β and Hubble constant. In addition, combining simulations with current observations of type Ia supernovae and baryon acoustic oscillations, we obtain tighter limitations for f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity. We find that the estimated precision significantly improved when all three data sets are combined (Δ⁢β∼0.03similar-toΔ𝛽0.03\Delta\beta\sim 0.03roman_Δ italic_β ∼ 0.03), compared to analyzing the current observations alone (Δ⁢β∼0.3similar-toΔ𝛽0.3\Delta\beta\sim 0.3roman_Δ italic_β ∼ 0.3). Simultaneously, the uncertainty of the Hubble constant can be reduced to approximately 1%percent11\%1 %.",[],['China']
"Communication protocols form the bedrock of our interconnected world, yet vulnerabilities within their implementations pose significant security threats.
Recent developments have seen a surge in fuzzing-based research dedicated to uncovering these vulnerabilities within protocol implementations.
However, there still lacks a systematic overview of protocol fuzzing for answering the essential questions such as what the unique challenges are, how existing works solve them, etc.
To bridge this gap, we conducted a comprehensive investigation of related works from both academia and industry.
Our study includes a detailed summary of the specific challenges in protocol fuzzing, and provides a systematic categorization and overview of existing research efforts. Furthermore, we explore and discuss potential future research directions in protocol fuzzing. This survey serves as a foundational guideline for researchers and practitioners in the field.","['Protocol', 'Fuzz', 'Testing', 'Security']","['Singapore', 'China']"
"The abstract should appear at the top of the left-hand column of text, about
0.5 inch (12 mm) below the title area and no more than 3.125 inches (80 mm) in
length. Leave a 0.5 inch (12 mm) space between the end of the abstract and the
beginning of the main text. The abstract should contain about 100 to 150
words, and should be identical to the abstract text submitted electronically
along with the paper cover sheet. All manuscripts must be in English, printed
in black ink.",[],[]
,[],[]
"In the domain of large-scale software development, the demands for dynamic and multifaceted static code analysis exceed the capabilities of traditional tools. To bridge this gap, we present CodeFuse-Query, a system that redefines static code analysis through the fusion of Domain Optimized System Design and Logic Oriented Computation Design.
CodeFuse-Query reimagines code analysis as a data computation task, support scanning over 10 billion lines of code daily and more than 300 different tasks. It optimizes resource utilization, prioritizes data reusability, applies incremental code extraction, and introduces tasks types specially for Code Change, underscoring its domain-optimized design.
The system’s logic-oriented facet employs Datalog, utilizing a unique two-tiered schema, COREF, to convert source code into data facts. Through Gödel, a distinctive language, CodeFuse-Query enables formulation of complex tasks as logical expressions, harnessing Datalog’s declarative prowess.
This paper provides empirical evidence of CodeFuse-Query’s transformative approach, demonstrating its robustness, scalability, and efficiency. We also highlight its real-world impact and diverse applications, emphasizing its potential to reshape the landscape of static code analysis in the context of large-scale software development.Furthermore, in the spirit of collaboration and advancing the field, our project is open-sourced and the repository is available for public access111https://github.com/codefuse-ai/CodeFuse-Query.",[],[]
"Hallucinations are a type of output error produced by deep neural networks. While this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. Here, we define hallucinations in ASR as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. The similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. We show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. To address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (ASR) model to hallucination at test time, which does not require access to the training dataset. We demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that have similar baseline word error rates. We further explore the relationship between the types of ASR errors and the types of dataset noise to determine what types of noise are most likely to create hallucinatory outputs. We devise a framework for identifying hallucinations by analysing their semantic connection with the ground truth and their fluency. Finally, we discover how to induce hallucinations with a random noise injection to the utterance.",[],[]
"Unmanned Aerial Vehicle (UAV) visual geo-localization aims to match images of the same geographic target captured from different views, i.e., the UAV view and the satellite view.
It is very challenging due to the large appearance differences in UAV-satellite image pairs.
Previous works map images captured by UAVs and satellites to a shared feature space and employ a classification framework to learn location-dependent features while neglecting the overall distribution shift between the UAV view and the satellite view.
In this paper, we address these limitations by introducing distribution alignment of the two views to shorten their distance in a common space.
Specifically, we propose an end-to-end network, called PVDA (Progressive View Distribution Alignment).
During training, feature encoder, location classifier, and view discriminator are jointly optimized by a novel progressive adversarial learning strategy.
Competition between feature encoder and view discriminator prompts both of them to be stronger.
It turns out that the adversarial learning is progressively emphasized until UAV-view images are indistinguishable from satellite-view images.
As a result, the proposed PVDA becomes powerful in learning location-dependent yet view-invariant features with good scalability towards unseen images of new locations.
Compared to the state-of-the-art methods, the proposed PVDA requires less inference time but has achieved superior performance on the University-1652 dataset.","['UAV visual geo-localization', 'UAV view satellite view distribution alignment adversarial learning.']",[]
"This paper addresses the task of Unmanned Aerial Vehicles (UAV) visual geo-localization, which aims to match images of the same geographic target taken by different platforms, i.e., UAVs and satellites.
In general, the key to achieving accurate UAV-satellite image matching lies in extracting visual features that are robust against viewpoint changes, scale variations, and rotations.
Current works have shown that part matching is crucial for UAV visual geo-localization since part-level representations can capture image details and help to understand the semantic information of scenes.
However, the importance of preserving semantic characteristics in part-level representations is not well discussed.
In this paper, we introduce a transformer-based adaptive semantic aggregation method that regards parts as the most representative semantics in an image.
Correlations of image patches to different parts are learned in terms of the transformer’s feature map.
Then our method decomposes part-level features into an adaptive sum of all patch features.
By doing this, the learned parts are encouraged to focus on patches with typical semantics.
Extensive experiments on the University-1652 dataset have shown the superiority of our method over the current works.",['UAV visual geo-localization transformer part matching.'],[]
"The blooming of social media and face recognition (FR) systems has increased people’s concern about privacy and security. A new type of adversarial privacy cloak (class-universal) can be applied to all the images of regular users, to prevent malicious FR systems from acquiring their identity information. In this work, we discover the optimization dilemma in the existing methods – the local optima problem in large-batch optimization and the gradient information elimination problem in small-batch optimization. To solve these problems, we propose Gradient Accumulation (GA) to aggregate multiple small-batch gradients into a one-step iterative gradient to enhance the gradient stability and reduce the usage of quantization operations. Experiments show that our proposed method achieves high performance on the Privacy-Commons dataset against black-box face recognition models.",[],[]
"Confined active particles constitute simple, yet realistic, examples
of systems that converge into a non-equilibrium steady state. We
investigate a run-and-tumble particle in one spatial dimension,
trapped by an external potential, with a given distribution g⁢(t)𝑔𝑡g(t)italic_g ( italic_t ) of
waiting times between tumbling events whose mean value is equal to
τ𝜏\tauitalic_τ. Unless g⁢(t)𝑔𝑡g(t)italic_g ( italic_t ) is an exponential distribution (corresponding to
a constant tumbling rate), the process is non-Markovian, which makes
the analysis of the model particularly challenging. We use an
analytical framework involving effective position-dependent tumbling
rates, to develop a numerical method that yields the full steady-state
distribution (SSD). The method is very efficient and requires modest
computing resources, including in the large-deviations and/or
small-τ𝜏\tauitalic_τ regime, where the SSD can be related to the the
large-deviation function, s⁢(x)𝑠𝑥s(x)italic_s ( italic_x ), via the scaling relation Pst⁢(x)∼e−s⁢(x)/τsimilar-tosubscript𝑃st𝑥superscript𝑒𝑠𝑥𝜏P_{{\rm st}}(x)\sim e^{-s\left(x\right)/\tau}italic_P start_POSTSUBSCRIPT roman_st end_POSTSUBSCRIPT ( italic_x ) ∼ italic_e start_POSTSUPERSCRIPT - italic_s ( italic_x ) / italic_τ end_POSTSUPERSCRIPT.",[],['Israel']
"Despite the recent remarkable achievement in gaze estimation, efficient and accurate personalization of gaze estimation without labels is a practical problem but rarely touched on in the literature.
To achieve efficient personalization, we take inspiration from the recent advances in Natural Language Processing (NLP) by updating a negligible number of parameters, “prompts”, at the test time.
Specifically, the prompt is additionally attached without perturbing original network and can contain less than 1% of a ResNet-18’s parameters. Our experiments show high efficiency of the prompt tuning approach. The proposed one can be 10 times faster in terms of adaptation speed than the methods compared.
However, it is non-trivial to update the prompt for personalized gaze estimation without labels. At the test time, it is essential to ensure that the minimizing of particular unsupervised loss leads to the goals of minimizing gaze estimation error. To address this difficulty, we propose to meta-learn the prompt to ensure that its updates align with the goal. Our experiments show that the meta-learned prompt can be effectively adapted even with a simple symmetry loss. In addition, we experiment on four cross-dataset validations to show the remarkable advantages of the proposed method.",[],[]
"Spatio-temporal video grounding (or STVG) task aims at locating a spatio-temporal tube for a specific instance given a text query. Despite advancements, current methods easily suffer the distractors or heavy object appearance variations in videos due to insufficient object information from the text, leading to degradation. Addressing this, we propose a novel framework, context-guided STVG (CG-STVG), which mines discriminative instance context for object in videos and applies it as a supplementary guidance for target localization. The key of CG-STVG lies in two specially designed modules, including instance context generation (ICG), which focuses on discovering visual context information (in both appearance and motion) of the instance, and instance context refinement (ICR), which aims to improve the instance context from ICG by eliminating irrelevant or even harmful information from the context. During grounding, ICG, together with ICR, are deployed at each decoding stage of a Transformer architecture for instance context learning. Particularly, instance context learned from one decoding stage is fed to the next stage, and leveraged as a guidance containing rich and discriminative object feature to enhance the target-awareness in decoding feature, which conversely benefits generating better new instance context for improving localization finally. Compared to existing methods, CG-STVG enjoys object information in text query and guidance from mined instance visual context for more accurate target localization. In our experiments on three benchmarks, including HCSTVG-v1/-v2 and VidSTG, CG-STVG sets new state-of-the-arts in m_tIoU and m_vIoU on all of them, showing its efficacy. The code will be released at https://github.com/HengLan/CGSTVG.",[],[]
,[],[]
"With the increase in the number of electric vehicles (EV), there is a need for the development of the EV charging infrastructure (EVCI) to facilitate fast charging, thereby mitigating the EV congestion at charging stations. The role of the public charging station depot is to charge the vehicle, prioritizing the achievement of the desired state of charge (SoC) value for the EV battery or charging till the departure of the EV, whichever occurs first. The integration of cyber and physical components within EVCI defines it as a cyber physical power system (CPPS), increasing its vulnerability to diverse cyber attacks. When an EV interfaces with the EVCI, mutual exchange of data takes place via various communication protocols like the Open Charge Point Protocol (OCPP), and IEC 61850. Unauthorized access to this data by intruders leads to cyber attacks, potentially resulting in consequences like energy theft, and revenue loss. These scenarios may cause the EVCI to incur higher charges than the actual energy consumed or the EV owners to remit payments that do not correspond adequately to the amount of energy they have consumed. This article proposes an EVCI architecture connected to the utility grid and uses the EVCI data to identify the anomalies or outliers present in the EV transmitted data, particularly focusing on SoC irregularities. The proposed methodology involves utilizing a ridge regression based machine learning (ML) model for predicting changes in the SoC. The adversaries have the capability of spoofing these change in SoC values, consequently making the EVCI incapable of achieving the desired task. Three distinct spoofing techniques namely, decimal shifting, incremental array spoofing, and random spoofing are implemented on the data and subsequently tested with the proposed methodology. The results show that the proposed methodology detects the anomaly accurately and also classifies the type of spoofing that causes the anomaly.","['EVCI', 'SoC', 'fast charging', 'spoofing', 'anomaly detection', 'Ridge regression']",[]
"For long wavelength gravitational wave (GW), it is easy to diffract when it is lensed by celestial objects. Traditional diffractive integral formula has ignored large angle diffraction, which is adopted in most of cases. However, in some special cases (e. g. a GW source lensed by its companion in a binary system, where the lens is very close to the source), large angle diffraction could be important. Our previous works have proposed a new general diffractive integral formula which has including large angle diffraction case. In this paper, we have investigated how much difference between this general diffractive formula and traditional diffractive integral formula could be under these special cases with different parameters. We find that the module of amplification factor for general diffractive formula could become smaller than that of traditional diffractive integral basically with a factor rF≃0.674similar-to-or-equalssubscript𝑟𝐹0.674r_{F}\simeq 0.674italic_r start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ≃ 0.674 when the distance between lens and sources is DLS=1subscript𝐷LS1D_{\rm LS}=1italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT = 1 AU and lens mass ML=1⁢M⊙subscript𝑀L1subscript𝑀direct-productM_{\rm L}=1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT = 1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. Their difference is so significant that it is detectable. Furthermore, we find that the proportionality factor rFsubscript𝑟𝐹r_{F}italic_r start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT is gradually increasing from 0.5 to 1 with increasing DLSsubscript𝐷LSD_{\rm LS}italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT and it is decreasing with increasing MLsubscript𝑀LM_{\rm L}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT. As long as DLS≲3less-than-or-similar-tosubscript𝐷LS3D_{\rm LS}\lesssim 3italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT ≲ 3 AU (with ML=1⁢M⊙subscript𝑀L1subscript𝑀direct-productM_{\rm L}=1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT = 1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) or ML≳0.1⁢M⊙greater-than-or-equivalent-tosubscript𝑀L0.1subscript𝑀direct-productM_{\rm L}\gtrsim 0.1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT ≳ 0.1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT (with DLS=1subscript𝐷LS1D_{\rm LS}=1italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT = 1 AU ), the difference between new and traditional formulas is enough significant to be detectable. It is promising to test this new general diffractive formula by next-generation GW detectors in the future GW detection.",[],[]
,[],[]
"The development of multi-modal medical foundation models has attracted significant attention in the field of medicine and healthcare due to their promising prospects in various clinical applications. One area of focus in this research direction is the extractions of features at different scales. While previous studies have explored feature learning at individual scales, investigation on integrating the diverse scales and modalities of information is lacking, which may hinder the potential for mutual reinforcement among these features. This paper aims to bridge this gap by proposing a method that effectively exploits multi-scale and cross-modality information to enhance the performance of medical foundation models. The proposed method simultaneously exploit features at the local, instance, modality and global aspects, facilitating comprehensive representation learning within the models. We evaluate the effectiveness of the proposed method on six open-source datasets across different clinical tasks, demonstrating its ability to enhance the performance of medical foundation models.",[],[]
"We report recent progress in data analysis on the two point
correlation functions which will be prerequisite to obtain
semileptonic form factors for the B(s)→D(s)⁢ℓ⁢ν→subscript𝐵𝑠subscript𝐷𝑠ℓ𝜈B_{(s)}\to D_{(s)}\ell\nuitalic_B start_POSTSUBSCRIPT ( italic_s ) end_POSTSUBSCRIPT → italic_D start_POSTSUBSCRIPT ( italic_s ) end_POSTSUBSCRIPT roman_ℓ italic_ν
decays. We use a MILC HISQ ensemble for the measurement. We use the
HISQ action for light quarks, and the Oktay-Kronfeld (OK) action for
the heavy quarks (b𝑏bitalic_b and c𝑐citalic_c). We used a sequential Bayesian method
for the data analysis. Here we test the new fitting methodology of
Benjamin J. Choi in a completely independent manner.",[],[]
"A network can contain numerous spanning trees. If two spanning trees Ti,Tjsubscript𝑇𝑖subscript𝑇𝑗T_{i},T_{j}italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT do not share any common edges, Tisubscript𝑇𝑖T_{i}italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Tjsubscript𝑇𝑗T_{j}italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are said to be pairwisely edge-disjoint. For spanning trees T1,T2,…,Tmsubscript𝑇1subscript𝑇2…subscript𝑇𝑚T_{1},T_{2},...,T_{m}italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, if any two of them are pairwisely edge-disjoint, they are called completely edge-independent spanning trees (CEISTs for short). CEISTs can facilitate many network functionalities, and constructing CEISTs as maximally allowed as possible in a given network is a worthy undertaking.
In this paper, we establish the maximal number of CEISTs in the locally twisted cube network, and propose an algorithm to construct ⌊n2⌋𝑛2\lfloor\frac{n}{2}\rfloor⌊ divide start_ARG italic_n end_ARG start_ARG 2 end_ARG ⌋ CEISTs in L⁢T⁢Qn𝐿𝑇subscript𝑄𝑛LTQ_{n}italic_L italic_T italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, the n𝑛nitalic_n-dimensional locally twisted cube. The proposed algorithm has been actually implemented, and we present the outputs. Network broadcasting in the L⁢T⁢Qn𝐿𝑇subscript𝑄𝑛LTQ_{n}italic_L italic_T italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT was simulated using ⌊n2⌋𝑛2\lfloor\frac{n}{2}\rfloor⌊ divide start_ARG italic_n end_ARG start_ARG 2 end_ARG ⌋ CEISTs, and the performance compared with broadcasting using a single tree.","['Broadcasting', 'Edge-disjoint', 'CEISTs', 'Locally twisted cubes', 'Spanning trees', 'Tree embedding.']",[]
"We consider a time-fractional subdiffusion equation with a Caputo derivative in time,
a general second-order elliptic spatial operator, and a right-hand side that is non-smooth in time.
The presence of the latter may lead to locking problems in our time stepping
procedure recently introduced in [4, 2]. Hence,
a generalized version of the residual barrier is proposed to rectify the issue.
We also consider related alternatives to this generalized algorithm, and, furthermore, show that this new residual barrier
may be useful in the case of a negative reaction coefficient.",[],[]
"The elderly population is increasing rapidly around the world. There are no enough caretakers for them. Use of AI-based in-home medical care systems is gaining momentum due to this. Human fall detection is one of the most important tasks of medical care system for the aged people. Human fall is a common problem among elderly people. Detection of a fall and providing medical help as early as possible is very important to reduce any further complexity. The chances of death and other medical complications can be reduced by detecting and providing medical help as early as possible after the fall. There are many state-of-the-art fall detection techniques available these days, but the majority of them need very high computing power. In this paper, we proposed a lightweight and fast human fall detection system using pose estimation. We used ‘Movenet’ for human joins key-points extraction. Our proposed method can work in real-time on any low-computing device with any basic camera. All computation can be processed locally, so there is no problem of privacy of the subject. We used two datasets ‘GMDCSA’ and ‘URFD’ for the experiment. We got the sensitivity value of 0.9375 and 0.9167 for the dataset ‘GMDCSA’ and ‘URFD’ respectively. The source code and the dataset GMDCSA of our work are available online to access.",[],[]
"Bayesian networks are powerful tools for probabilistic analysis and have been widely used in machine learning and data science. Unlike the parameters learning mode of neural networks, Bayes classifiers only use sample features to determine the classification results without a time-consuming training process. We study the construction of quantum Bayes classifiers (QBCs) and design a naïve QBC and three semi-naïve QBCs (SN-QBCs). These QBCs are applied to image classification.
A local features sampling method is employed to extract a limited number of features from images to reduce the computational complexity. These features are then used to construct Bayesian networks and generate QBCs. We simulate these QBCs on the MindQuantum quantum platform and test them on the MNIST and Fashion-MNIST datasets. Results show that these QBCs based on a limited number of features exhibit good classification accuracies. The classification accuracies of QBCs on the MNIST dataset surpass that of the classical Bayesian network and quantum neural networks that utilize all feature points.",[],['China']
"Mobile Edge Computing (MEC) is a new computing paradigm that enables cloud computing and information technology (IT) services to be delivered at the network’s edge. By shifting the load of cloud computing to individual local servers, MEC helps meet the requirements of ultralow latency, localized data processing, and extends the potential of Internet of Things (IoT) for end-users. However, the crosscutting nature of MEC and the multidisciplinary components necessary for its deployment have presented additional security and privacy concerns. Fortunately, Artificial Intelligence (AI) algorithms can cope with excessively unpredictable and complex data, which offers a distinct advantage in dealing with sophisticated and developing adversaries in the security industry. Hence, in this paper we comprehensively provide a survey of security and privacy in MEC from the perspective of AI.
On the one hand, we use European Telecommunications Standards Institute (ETSI) MEC reference architecture as our based framework while merging the Software Defined Network (SDN) and Network Function Virtualization (NFV) to better illustrate a serviceable platform of MEC. On the other hand, we focus on new security and privacy issues, as well as potential solutions from the viewpoints of AI. Finally, we
comprehensively discuss the opportunities and challenges associated with applying AI to MEC security and privacy
as possible future research directions.","['Mobile', 'Edge', 'Computing', '5G', 'Internet of', 'Things', 'Artificial', 'Intelligence', 'Machine', 'Learning', 'Security and', 'Privacy', 'Software', 'Defined', 'Network', 'Security', 'Virtual', 'Machine security.']",[]
"Optimized blockade is an efficient tool in generating a single-magnon state, that is fundamental to manipulate the magnonic systems at the quantum level. In this study, we consider a hybrid system in which a qubit is strongly coupled to N𝑁Nitalic_N magnons via the exchange interaction. The qubit and the magnon modes are subject to the probing field and driving fields, respectively. It is interesting to find the scalable conditions in minimizing the equal-time second-order correlation function g(2)⁢(0)superscript𝑔20g^{(2)}(0)italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) for each magnon with respect to N𝑁Nitalic_N. In particular, the simultaneous blockade is optimized when (i) the detuning between the qubit (magnon) and the probing (driving field) field is N𝑁\sqrt{N}square-root start_ARG italic_N end_ARG times the magnon-qubit coupling strength, (ii) the probing intensity is 3⁢N3𝑁3\sqrt{N}3 square-root start_ARG italic_N end_ARG times the driving intensity, and (iii) the relative phase between probing and driving fields is 2/(3N2/(3\sqrt{N}2 / ( 3 square-root start_ARG italic_N end_ARG) times the ratio of the system decay rate to the magnon-qubit coupling strength. More than a high-degree blockade, we can generate a significant population on the single-magnon state. With experimental-relevant driving intensity and decay rate, the correlation function can achieve about g(2)⁢(0)∼10−7similar-tosuperscript𝑔20superscript107g^{(2)}(0)\sim 10^{-7}italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) ∼ 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT in company with a large single-magnon population P1∼0.24similar-tosubscript𝑃10.24P_{1}\sim 0.24italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∼ 0.24 when N=1𝑁1N=1italic_N = 1 and g(2)⁢(0)∼10−7similar-tosuperscript𝑔20superscript107g^{(2)}(0)\sim 10^{-7}italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) ∼ 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT with P1∼0.12similar-tosubscript𝑃10.12P_{1}\sim 0.12italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∼ 0.12 when N=2𝑁2N=2italic_N = 2.",[],['China']
"Existing contrastive language-image pre-training aims to learn a joint representation by matching abundant image-text pairs. However, the number of image-text pairs in medical datasets is usually orders of magnitude smaller than that in natural datasets. Besides, medical image-text pairs often involve numerous complex fine-grained correspondences. This paper aims to enhance the data efficiency by introducing multiple-to-multiple local relationship modeling to capture denser supervisions. More specifically, we propose a Medical Language-Image Pre-training (MLIP) framework, which exploits the limited image-text medical data more efficiently through patch-sentence matching. Furthermore, we introduce a masked contrastive learning strategy with semantic integrity estimation to reduce redundancy in images while preserving the underlying semantics. Our evaluation results show that MLIP outperforms previous work in zero/few-shot classification and few-shot segmentation tasks by a large margin.",[],[]
"We study single-photon scattering spectra of a giant atom chirally
coupled to a one-dimensional waveguide at multiple connection points,
and examine chirality induced effects in the scattering spectra by
engineering the chirality of the coupling strengths. We show that
the transmission spectra typically possess an anti-Lorentzian lineshape
with a nonzero minimum, but when the chirality satisfies some specific
conditions independent of the number of coupling points, the transmission spectrum of an incident photon can undergo a transition from complete
transmission to total reflection at multiple frequency “windows”,
the width of which can be flexibly tuned in situ by engineering the
coupling strengths of a certain disordered coupling point. Moreover,
we show that a perfect nonreciprocal photon scattering can be achieved
due to the interplay between internal atomic spontaneous emission
and the chirally external decay to the waveguide, in contrast to that
induced by the non-Markovian retardation effect. We also consider the
non-Markovian retardation effect on the scattering spectra, which allows
for a photonic band gap even with only two chiral coupling points.
The giant-atom-waveguide system with chiral coupling is a promising
candidate for realizing single-photon routers with multiple channels.",[],['China']
"In the context of measurement-induced entanglement phase transitions, the influence of quantum noises, which are inherent in real physical systems, is of great importance and experimental relevance.
In this Letter, we present a comprehensive theoretical analysis of the effects of both temporally uncorrelated and correlated quantum noises on entanglement generation and information protection.
This investigation reveals that entanglement within the system follows q−1/3superscript𝑞13q^{-1/3}italic_q start_POSTSUPERSCRIPT - 1 / 3 end_POSTSUPERSCRIPT scaling for both types of quantum noises, where q𝑞qitalic_q represents the noise probability.
The scaling arises from the Kardar-Parisi-Zhang fluctuation with effective length scale Leff∼q−1similar-tosubscript𝐿effsuperscript𝑞1L_{\text{eff}}\sim q^{-1}italic_L start_POSTSUBSCRIPT eff end_POSTSUBSCRIPT ∼ italic_q start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
Moreover, the timescales of information protection are explored and shown to follow q−1/2superscript𝑞12q^{-1/2}italic_q start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT and q−2/3superscript𝑞23q^{-2/3}italic_q start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT scaling for temporally uncorrelated and correlated noises, respectively.
The former scaling can be interpreted as a Hayden-Preskill protocol, while the latter is a direct consequence of Kardar-Parisi-Zhang fluctuations.
We conduct extensive numerical simulations using stabilizer formalism to support the theoretical understanding.
This Letter not only contributes to a deeper understanding of the interplay between quantum noises and measurement-induced phase transition but also provides a new perspective to understand the effects of Markovian and non-Markovian noises on quantum computation.",[],['China']
,[],[]
,[],[]
"In the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. Although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. Also prior works in the area of medical question summarisation have been limited to the English language. This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. To address this gap, we introduce the Multimodal Medical Codemixed Question Summarization (MMCQS) dataset, which combines Hindi-English codemixed medical queries with visual aids. This integration enriches the representation of a patient’s medical condition, providing a more comprehensive perspective. We also propose a framework named MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing our MMCQS dataset, we demonstrate the value of integrating visual information from images to improve the creation of medically detailed summaries. This multimodal strategy not only improves healthcare decision-making but also promotes a deeper comprehension of patient queries, paving the way for future exploration in personalized and responsive medical care. Our dataset, code, and pre-trained models will be made publicly available.
https://github.com/ArkadeepAcharya/MedSumm-ECIR2024
Keywords: Mutimodal Summarization, LLM, VLM, Codemixing, Clinical Queries.",[],[]
"The rapid increase in \acEV adoption provides a promising solution for reducing carbon emissions and fossil fuel dependency in transportation systems. However, the increasing numbers of \acEVs pose significant challenges to the electrical grids. In addition, the number of \acDER and \acMGs is increasing on a global scale to meet the energy demand, consequently changing the energy infrastructure. Recently, energy-sharing methods have been proposed to share excess energy from \acDERs and \acEVs in \acEVCI and \acMGs. Accommodating this sharing mechanism with the existing electrical distribution systems is a critical issue concerning the economic, reliability, and resilience aspects. This study examines the ever-changing field of EVCI and the critical role of \acP2P energy trading in mitigating the problems with grid management that result from unorganized EV charging and intermittency in \acDER. Also, the possibilities of energy sharing in electrical distribution systems for microgrids and EVCI on various energy-sharing methods and algorithms are discussed in detail. Furthermore, the application of market clearing algorithms like game theory, double auction theory, blockchain technology, optimization techniques, machine learning algorithms, and other models from the existing literature are presented. This paper discusses the policies, economic benefits, environmental impacts, societal advantages, and challenges in distribution systems related to sharing in \acEVCI and \acMGs. A roadmap for future research and sharing strategies is provided to guide policymakers, researchers, and industry stakeholders toward a sustainable, resilient, and efficient energy market by integrating P2P technology into EVCIs and \acMGs.","['Blockchain technology', 'electric vehicle', 'electric vehicle charging infrastructure', 'electrical distribution systems', 'double auction theory', 'game theory', 'machine learning', 'peer-to-peer energy trading', 'sharing models', 'vehicle-to-grid.']",[]
"Few-shot Class-Incremental Learning (FSCIL) aims to continuously learn new classes based on very limited training data without forgetting the old ones encountered.
Existing studies solely relied on pure visual networks, while in this paper we solved FSCIL by leveraging the Vision-Language model (e.g., CLIP) and propose a simple yet effective framework, named Learning Prompt with Distribution-based Feature Replay (LP-DiF).
We observe that simply using CLIP for zero-shot evaluation can substantially outperform the most influential methods.
Then, prompt tuning technique is involved to further improve its adaptation ability, allowing the model to continually capture specific knowledge from each session.
To prevent the learnable prompt from forgetting old knowledge in the new session, we propose a pseudo-feature replay approach.
Specifically, we preserve the old knowledge of each class by maintaining a feature-level Gaussian distribution with a diagonal covariance matrix, which is estimated by the image features of training images and synthesized features generated from a VAE.
When progressing to a new session, pseudo-features are sampled from old-class distributions combined with training images of the current session to optimize the prompt, thus enabling the model to learn new knowledge while retaining old knowledge.
Experiments on three prevalent benchmarks, i.e., CIFAR100, mini-ImageNet, CUB-200, and two more challenging benchmarks, i.e. SUN-397 and CUB-200*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT proposed in this paper showcase the superiority of LP-DiF, achieving new state-of-the-art (SOTA) in FSCIL.
Code is publicly available at https://github.com/1170300714/LP-DiF.",[],[]
"The generalization error curve of certain kernel regression method aims at determining the exact order of generalization error with various source condition, noise level and choice of the regularization parameter rather than the minimax rate.
In this work, under mild assumptions, we rigorously provide a full characterization of the generalization error curves of the kernel gradient descent method (and a large class of analytic spectral algorithms) in kernel regression.
Consequently, we could sharpen the near inconsistency of kernel interpolation and clarify the saturation effects of kernel regression algorithms with higher qualification, etc.
Thanks to the neural tangent kernel theory, these results greatly improve our understanding of the generalization behavior of training the wide neural networks.
A novel technical contribution, the analytic functional argument, might be of independent interest.",[],[]
"Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It’s enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences.
Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accuracy of PLLaMa’s responses to various academic inquiries, ensuring its effective and reliable application in the field.
To support further research and development, we have made the model’s checkpoints and source codes accessible to the scientific community. These resources are available for download at https://github.com/Xianjun-Yang/PLLaMa.",[],[]
"Recent literature on Weil–Petersson random hyperbolic surfaces has met a
consistent obstacle: the necessity to condition the model, prohibiting certain rare geometric
patterns (which we call tangles), such as short closed geodesics or embedded surfaces of
short boundary length. The main result of this article is a Moebius inversion formula, allowing to
integrate the indicator function of the set of tangle-free surfaces in a systematic, tractable
way. It is inspired by a key step of Friedman’s celebrated proof of Alon’s conjecture. We further
prove that our tangle-free hypothesis significantly reduces the number of local topological types
of short geodesics, replacing the exponential proliferation observed on tangled surfaces by a
polynomial growth.","['Random hyperbolic surfaces', 'Weil–Petersson form', 'moduli space', 'spectral gap', 'closed geodesic', 'Selberg trace formula.']",[]
"We have conducted a theoretical investigation of the topological phenomena associated with chiral superconducting pairing states induced in a doped Kane-Mele model on a honeycomb lattice. Through numerical analysis, we have obtained exotic phase diagrams for both the d+i⁢d𝑑𝑖𝑑d+iditalic_d + italic_i italic_d and p+i⁢p𝑝𝑖𝑝p+ipitalic_p + italic_i italic_p superconducting states. In the case of the d+i⁢d𝑑𝑖𝑑d+iditalic_d + italic_i italic_d pairing state, higher Chern number states with |C|=±4𝐶plus-or-minus4\left|C\right|=\pm 4| italic_C | = ± 4 emerge. The Chern number decreases as the spin-orbit coupling is introduced. For the p+i⁢p𝑝𝑖𝑝p+ipitalic_p + italic_i italic_p pairing state, additional phase transition lines are present in the overdoped region near the Van Hove singularity point, leading to the emergence of higher Chern number phases with |C|=±6𝐶plus-or-minus6\left|C\right|=\pm 6| italic_C | = ± 6. These higher Chern number phases are further verified through the bulk-edge correspondence.
To understand the origin of the exotic topological phase diagrams in the chiral superconducting state, we have examined the electronic structure at the phase transition lines. This investigation provides insight into the complex interplay between chiral superconductivity and topological properties, potentially paving the way for the discovery of new materials with unique topological properties.",[],['China']
,[],['Japan']
"An important aspect of solar energetic particle (SEP) events is their source populations.
Elemental abundance enhancements of impulsive SEP events, originating in presumed coronal
reconnection episodes, can be fitted to steep power laws of A/Q,
where A and Q are the atomic mass and ionic charge.
Since thermal electron energies are enhanced and
nonthermal electron distributions arise in the reconnection process, we might expect that ionic
charge states Q would be increased through ionization interactions with those electron populations
during the acceleration process. The temperature estimated from the SEPs corresponds to the charge state during the acceleration process, while the actual charge state measured in situ may be modified as the SEPs pass through the corona.
We examine whether the temperature estimation from the A/Q would differ with various kappa values
in a kappa function representing high-energy tail deviating from a Maxwellian velocity distribution.
We find that the differences in the A/Q between a Maxwellian and an extreme kappa distribution are only about 10-30%. We fit power-law enhancement of element abundances as a function of their A/Q with various kappa values. Then, we find that the derived source region temperature is not significantly affected by whether or not the electron velocity distribution deviates from a Maxwellian, i.e., thermal, distribution. Assuming that electrons are heated in the acceleration region, the agreement of the SEP charge state during acceleration with typical active region temperatures suggests that SEPs are accelerated and leave the acceleration region in a shorter time than the ionization time scale.","['The', 'Sun (1693) —', 'Solar', 'Energetic', 'Particles (1491) —', 'Non-thermal radiation sources (1119)']",[]
"We study the quantum oscillations of inter-layer capacitance in an excitonic insulating electron-hole double layer with the Hartree Fock mean-field theory.
Such oscillations could be simply understood from the physical picture “exciton formed by electron/hole Landau levels”, where the direct gap between the electron-hole Landau levels will oscillate with exciton chemical potential and the inverse of the magnetic field.
We also find that the excitonic order parameters can be destroyed by a strong magnetic field.
At this time, the system becomes two independent quantum Hall liquids and the inter-layer capacitance oscillates to zero at zero temperature.",[],['China']
"In this paper we propose a minimal model for free reeds taking into account the significant phenomena. This free reed model may be used to build models of free reed instruments which permit numerical simulations. Several definitions for the section by which the airflow passes through the reed are reviewed and a new one is proposed which takes into account the entire escape area under the reed and the reed thickness. To derive this section, it is necessary to distinguish the neutral section (the only section of the reed which always keeps its length constant while moving) from the upstream or downstream sections. A minimal configuration is chosen to permit the instabilities of both (-,+) and (+,-) reeds on the basis of a linear analysis of instabilities conditions. This configuration is used to illustrate, with temporal simulations, the minimal model for both kinds of reeds and to discuss the model assumptions. Some clues are given about the influence, on the playing frequency and on the dynamic of the sound, of two main parameters of the geometrical model: the size of the volume and the level of the excitation. It is shown that the playing frequency of a (+,-) reed can vary in a large range according to the size of the volume upstream of the reed; that the playing frequency is nearly independent of the excitation but that the dynamic of the sound increases with the excitation level. Some clues are also proposed to determine the nature of the bifurcation for free reeds: it seems that free reeds may present inverse bifurcations. The influence of the reed thickness is also studied for configurations where the reed length or the reed width vary to keep the mass constant. This study shows that the reed thickness can have a great influence on the sound magnitude, the playing frequency and the magnitude of the reed displacement which justifies its introduction in the reed model.
This article has been published in Acta Acustica united with Acustica, Vol. 93 (2007), p. 122-144.",[],[]
"We present an alternative temporal approach for convolution, providing a new algorithm, called the taches-algorithm. Based on interferences between the successive delayed and amplified output signals associated respectively with the impulses constituting the input signal, the taches-algorithm can give access immediately to the new output sample and have a low latency response even without using vector-based optimisation of the calculation. With the taches-algorithm it seems easy to change (even in real-time) the impulse response while running the calculation, simply by updating the impulse response to use it for next samples, a task rather difficult to achieve using FFT convolution. Real-time audio demonstrations using notably Pure Data and simple explanations of the taches-algorithm will be given.
Paper 7412 presented at the 125th Convention of the Audio Engineering Society, Amsterdam, 2008",[],['France']
,[],[]
"Hierarchical beam search in mmWave communications incurs substantial training overhead, necessitating deep learning-enabled beam predictions to effectively leverage channel priors and mitigate this overhead. In this study, we introduce a comprehensive probabilistic model of power distribution in beamspace, and formulate the joint optimization problem of probing beam selection and probabilistic beam prediction as an entropy minimization problem. Then, we propose a greedy scheme to iteratively and alternately solve this problem, where a transformer-based beam predictor is trained to estimate the conditional power distribution based on the probing beams and user location within each iteration, and the trained predictor selects an unmeasured beam that minimizes the entropy of remaining beams. To further reduce the number of interactions and the computational complexity of the iterative scheme, we propose a two-stage probing beam selection scheme. Firstly, probing beams are selected from a location-specific codebook designed by an entropy-based criterion, and predictions are made with corresponding feedback. Secondly, the optimal beam is identified using additional probing beams with the highest predicted power values. Simulation results demonstrate the superiority of the proposed schemes compared to hierarchical beam search and beam prediction with uniform probing beams.","['mmWave communication', 'beam prediction', 'probing beam selection', 'deep learning', 'entropy minimization.']",[]
"We investigate self-gravitating solutions of the Einstein-Skyrme theory coupled to spin-isospin Dirac fermions and consider the dependence of the spectral flow on the effective gravitational coupling constant and on the Yukawa coupling.
It is shown that the effects of the backreaction of the fermionic mode may strongly deform the configuration.
In particular, the energy conditions may be violated, and regular anti-gravitating asymptotically flat solutions with negative ADM mass may emerge.",[],"['Kyrgyzstan', 'Germany', 'Kazakhstan']"
"We prove large and moderate deviations for the output of Gaussian fully connected neural networks. The main achievements concern deep neural networks (i.e., when the model has more than one hidden layer) and hold for bounded and continuous pre-activation functions. However, for deep neural networks fed by a single input, we have results even if the pre-activation is ReLU. When the network is shallow (i.e., there is exactly one hidden layer) the large and moderate principles hold for quite general pre-activations and in an infinite-dimensional setting.
 
Keywords: Asymptotic behavior, Contraction principle, Deep neural networks, ReLU pre-activation function.
Mathematics Subject Classification: 60F10, 60F05, 68T07",[],[]
"We define a leaf which is a domain in the closure ℌ¯=ℌ∪ℝ∪{∞}¯ℌℌℝ\overline{{\mathfrak{H}}}={\mathfrak{H}}\cup{\mathbb{R}}\cup\{\infty\}over¯ start_ARG fraktur_H end_ARG = fraktur_H ∪ blackboard_R ∪ { ∞ } of the complex upper half plane ℌ={z∈ℂ∣Im⁢z>0}ℌconditional-set𝑧ℂIm𝑧0{\mathfrak{H}}=\{z\in{\mathbb{C}}\mid{\mathrm{Im}\,}z>0\}fraktur_H = { italic_z ∈ blackboard_C ∣ roman_Im italic_z > 0 } for any linear transformation of an inner product space over the real number field ℝℝ{\mathbb{R}}blackboard_R.
If the dimension of the inner product space is at least 3,
the leaf is convex on the Poincaré metric, and then simply connected, and contains all eigenvalues with nonnegative imaginary part.
Moreover, if the linear transformation is normal, the leaf is the eigenvalue geodesic polygon, which is the minimum convex domain in ℌ¯¯ℌ\overline{{\mathfrak{H}}}over¯ start_ARG fraktur_H end_ARG containing all eigenvalues with nonnegative imaginary part.
We discuss the application of the geometric properties of a leaf to the operator norm.",[],[]
"Sensors play a crucial role in advanced apparatuses and it is persistently pursued to improve their sensitivities. Recently, the singularity of a non-Hermitian system, known as the exceptional point (EP), has drawn much attention for this goal. Response of the eigenfrequency shift to a perturbation ϵitalic-ϵ\epsilonitalic_ϵ follows the ϵ1/nsuperscriptitalic-ϵ1𝑛\epsilon^{1/n}italic_ϵ start_POSTSUPERSCRIPT 1 / italic_n end_POSTSUPERSCRIPT-dependence at an n𝑛nitalic_nth-order EP, leading to significantly enhanced sensitivity via a high-order EP. However, due to the requirement of increasingly complicated systems, great difficulties will occur along the path of increasing the EP order to enhance the sensitivity. Here we report that by utilizing the spectral anomaly of the coherent perfect absorption (CPA), the sensitivity at a third-order EP can be further enhanced owing to the cooperative effects of both CPA and EP. We realize this synthetically enhanced sensor using a pseudo-Hermitian cavity magnonic system composed of two yttrium iron garnet spheres and a microwave cavity. The detectable minimum change of the magnetic field reaches 4.2×10−214.2superscript10214.2\times 10^{-21}4.2 × 10 start_POSTSUPERSCRIPT - 21 end_POSTSUPERSCRIPT T. It opens a new avenue to design novel sensors using hybrid non-Hermitian quantum systems.",[],[]
"The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering.
In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website.
We propose SeeAct, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web.
We evaluate on the recent Mind2Web benchmark.
In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites.
We show that GPT-4V presents a great potential for web agents—it can successfully complete 50505050% of the tasks on live websites if we manually ground its textual plans into actions on the websites.
This substantially outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2) specifically fine-tuned for web agents.
However, grounding still remains a major challenge.
Existing LMM grounding strategies like set-of-mark prompting turns out not effective for web agents, and the best grounding strategy we develop in this paper leverages both the HTML text and visuals.
Yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement.111Code and evaluation tool will be released at https://github.com/OSU-NLP-Group/SeeAct.",[],[]
"A method is proposed to produce a classical optical state that is ‘intersystem nonseparable’ and a close analog of the ϕ+superscriptitalic-ϕ\phi^{+}italic_ϕ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT Bell state. A derivation of the CHSH-Bell inequality is sketched within the framework of classical polarization optics using noncontextuality for factorizable states as an axiom rather than any hidden variable theory, and it is shown that the classical state violates this inequality.",[],[]
"We consider how the theory of optimal quantum measurements determines the maximum information available to the receiving party of a quantum key distribution (QKD) system employing linearly independent but non-orthogonal quantum states. Such a setting is characteristic of several practical QKD protocols. Due to non-orthogonality, the receiver is not able to discriminate unambiguously between the signals.
To understand the fundamental limits that this imposes, the quantity of interest is the maximum mutual information between the transmitter (Alice) and the receiver, whether legitimate (Bob) or an eavesdropper (Eve).
To find the optimal measurement – taken individually or collectively – , we use a framework based on operator algebra and general results derived from singular value decomposition, achieving optimal solutions for von Neumann measurements and positive operator-valued measures (POVMs).
The formal proof and quantitative analysis elaborated for two signals allow one to conclude that optimal von Neumann measurements are uniquely defined and provide a higher information gain compared to POVMs. Interestingly, collective measurements not only do not provide additional information gain with respect to individual ones, but also suffer from a gain reduction in the case of POVMs.",[],['Italy']
"In this article we explore the holographic approach to neutron stars in the realm of Quantum Field Theory (QFT). We delve into the structures of neutron stars, emphasizing the application of the AdS/CFT duality in modeling them. We discuss both ”bottom-up” and ”top-down” holographic models, comparing their predictions with astrophysical observations. Finally, we demonstrate the potential broader applications of the holography method in areas like superconductivity, highlighting the methodological significance of string theory and QFT in astrophysics.

Key words


Holography, neutron stars, quantum chromodynamics",[],[]
"This article presents a priori error estimates of the miscible displacement of one incompressible fluid by another through a porous medium characterized by a coupled system of nonlinear elliptic and parabolic equations. The study utilizes the H⁢(div)𝐻divH(\mathrm{div})italic_H ( roman_div ) conforming virtual element method (VEM) for the approximation of the velocity, while a non-conforming virtual element approach is employed for the concentration. The pressure is discretised using the standard piecewise discontinuous polynomial functions. These spatial discretization techniques are combined with a backward Euler difference scheme for time discretization. The article also includes numerical results that validate the theoretical estimates presented.
Keywords: Miscible fluid flow, coupled elliptic-parabolic problem, convergence analysis, virtual element methods",[],[]
,[],[]
,[],[]
,[],[]
"The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.
In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum’s biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 132 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum’s total block value and outline possible mitigations.",[],[]
"Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI’s creative potential becomes imperative for its responsible development and application.
This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human.
This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity.
This methodological shift facilitates a statistically quantifiable evaluation of AI’s creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI’s creative abilities with those of specific human groups.
Building on this foundation, we discuss the application of statistical creativity in contemporary prompt-conditioned autoregressive models.
In addition to defining and analyzing a measure of creativity, we introduce an actionable training guideline, effectively bridging the gap between theoretical quantification of creativity and practical model training.
Through these multifaceted contributions, the paper establishes a cohesive, continuously evolving, and transformative framework for assessing and fostering statistical creativity in AI models.",[],[]
"RGB-T semantic segmentation is a key technique for autonomous driving scenes understanding.
For the existing RGB-T semantic segmentation methods, however, the effective exploration of the complementary relationship between different modalities is not implemented in the information interaction between multiple levels.
To address such an issue, the Context-Aware Interaction Network (CAINet) is proposed for RGB-T semantic segmentation, which constructs interaction space to exploit auxiliary tasks and global context for explicitly guided learning.
Specifically, we propose a Context-Aware Complementary Reasoning (CACR) module aimed at establishing the complementary relationship between multimodal features with the long-term context in both spatial and channel dimensions.
Further, considering the importance of global contextual and detailed information, we propose the Global Context Modeling (GCM) module and Detail Aggregation (DA) module, and we introduce specific auxiliary supervision to explicitly guide the context interaction and refine the segmentation map.
Extensive experiments on two benchmark datasets of MFNet and PST900 demonstrate that the proposed CAINet achieves state-of-the-art performance. The code is available at https://github.com/YingLv1106/CAINet.","['RGB-T semantic segmentation', 'context-aware complementation', 'global context', 'detail aggregation.']",[]
"Anomaly detection on attributed networks aims to find the nodes whose behaviors are significantly different from other majority nodes. Generally, network data contains information about relationships between entities, and the anomaly is usually embodied in these relationships. Therefore, how to comprehensively model complex interaction patterns in networks is still a major focus. It can be observed that anomalies in networks violate the homophily assumption. However, most existing studies only considered this phenomenon obliquely rather than explicitly. Besides, the node representation of normal entities can be perturbed easily by the noise relationships introduced by anomalous nodes. To address the above issues, we present a novel contrastive learning framework for anomaly detection on attributed networks, SCALA, aiming to improve the embedding quality of the network and provide a new measurement of qualifying the anomaly score for each node by introducing sparsification into the conventional method. Extensive experiments are conducted on five benchmark real-world datasets and the results show that SCALA consistently outperforms all baseline methods significantly.",[],[]
"The study of Graph Neural Networks (GNNs) has received considerable interest in the past few years. By extending deep learning to graph-structured data, GNNs can solve a diverse set of tasks in fields including social science, chemistry, and medicine. The development of GNN architectures has largely been focused on improving empirical performance on tasks like node or graph classification. However, a line of recent work has instead sought to find GNN architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness.
While there is no consensus on the best way to define the expressiveness of a GNN, it can be viewed from several well-motivated perspectives. Perhaps the most natural approach is to study the universal approximation properties of GNNs, much in the way that this has been studied extensively for MLPs. Another direction focuses on the extent to which GNNs can distinguish between different graph structures, relating this to the graph isomorphism test. Besides, a GNN’s ability to compute graph properties such as graph moments has been suggested as another form of expressiveness. All of these different definitions are complementary and have yielded different recommendations for GNN architecture choices. In this review paper, we would like to give an overview of the notion of ”expressive power” of GNNs and provide some valuable insights regarding the design choices of GNNs.",[],[]
"Bielliptic surfaces appear as quotient of a product of two elliptic curves and were classified by Bagnera-Franchis. We give a concrete way of computing their GW-invariants with point insertions using a floor diagram algorithm. Using the latter, we are able to prove the quasi-modularity of their generating series by relating them to generating series of graphs for which we also prove quasi-modularity results. We propose a refinement of these invariants by inserting a λ𝜆\lambdaitalic_λ-class in the considered GW-invariants.",[],[]
"Defining a successful notion of a multivariate quantile has been an open problem for more
than half a century, motivating a plethora of possible solutions. Of
these, the approach of [8] and
[25] leading to M-quantiles, is very appealing for
its mathematical elegance – combining elements of convex analysis and
probability theory. The key idea is the description of a convex
function (the K-function) whose gradient (the K-transform) is in
one-to-one correspondence between all of ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and the unit ball in
ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. By analogy with the d=1𝑑1d=1italic_d = 1 case where the K-transform
is a cumulative distribution function-like object (an M-distribution), the fact that its
inverse is guaranteed to exist lends itself
naturally to providing the basis for the definition of a quantile
function for all d≥1𝑑1d\geq 1italic_d ≥ 1. Over the past twenty years the resulting M-quantiles
have seen applications in a variety of fields, primarily for the
purpose of detecting outliers in multidimensional spaces.
In this article we prove that for odd d≥3𝑑3d\geq 3italic_d ≥ 3, it is not the gradient but a
poly-Laplacian of the K-function that is (almost
everywhere) proportional to the density
function. For d𝑑ditalic_d even one cannot establish a differential equation connecting
the K-function with the density.
These results show that usage of the K-transform for outlier
detection in higher odd-dimensions is in principle flawed,
as the K-transform does not originate from inversion of a true M-distribution.
We demonstrate these conclusions in two dimensions
through examples from non-standard asymmetric distributions. Our
examples illustrate a feature of the K-transform whereby regions in
the domain with higher density map to larger volumes in the co-domain,
thereby producing a magnification effect that moves inliers closer to
the boundary of the co-domain than outliers. This feature obviously
disrupts any outlier detection mechanism that relies on the inverse K-transform.","['multivariate distribution function', 'multivariate quantile', 'geometric quantile', 'outlier detection']",[]
,[],[]
"The introduction of the European Union Artificial Intelligence Act, the NIST Artificial Intelligence Risk Management Framework,
and related norms demands a better understanding and implementation
of novel risk analysis
approaches to evaluate systems with Artificial Intelligence components. This paper provides a
cybersecurity risk analysis framework that can help assessing such systems. We use an
illustrative
example concerning automated driving systems.",[],['Spain']
"The primary objective of this work is to construct spaces that are ""pseudocompact but not countably compact,"" abbreviated as P-NC,
while endowing them with additional properties.
First, motivated by an old problem of van Douwen concerning first
countable P-NC spaces,
we construct from CH a locally compact and locally countable first
countable P-NC space with countable spread.
A space is deemed densely countably compact, denoted as DCC for brevity,
if it possesses a dense, countable compact subspace. Moreover, a space qualifies as
densely relatively countably compact, abbreviated as DRC, if it contains a
dense subset D𝐷Ditalic_D
such that every infinite subset of D𝐷Ditalic_D has an accumulation point in X𝑋Xitalic_X.
A countably compact space is DCC,
a DCC space is DRC,
and a DRC space is evidently pseudocompact.
The Tychonoff plank is a DCC space but is not countably compact.
A ΨΨ\Psiroman_Ψ-space belongs to the class of DRC spaces but is not DCC.
Lastly, if p∈ω*𝑝superscript𝜔p\in{\omega}^{*}italic_p ∈ italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is not a P-point, then T⁢(p)𝑇𝑝T(p)italic_T ( italic_p ),
representing the type of p𝑝pitalic_p in ω*superscript𝜔{\omega}^{*}italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, constitutes a pseudocompact subspace of
ω*superscript𝜔{\omega}^{*}italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT that is not DRC.
Berner constructed a first countable example which separates DRC and pseudocompactness,
but his example is not “hereditary” and it has cardinality 𝔠+superscript𝔠\mathfrak{c}^{+}fraktur_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT.
When considering a topological property denoted as Q𝑄Qitalic_Q,
we define a space X𝑋Xitalic_X as ""hereditarily Q𝑄Qitalic_Q""
if every regular closed subspace of X𝑋Xitalic_X also possesses property Q𝑄Qitalic_Q.
The Tychonoff plank and the ΨΨ\Psiroman_Ψ-spaces are not hereditary examples.
However, the aforementioned space T⁢(p)𝑇𝑝T(p)italic_T ( italic_p ) is a hereditary example,
albeit not being first countable.
In this paper we want to find (first countable) examples
which separates these properties hereditarily.
We have obtained the following result.


(1)

There is aDCC  space X𝑋Xitalic_X such that no H∈R⁢C⁢(X)+𝐻𝑅𝐶superscript𝑋H\in RC(X)^{+}italic_H ∈ italic_R italic_C ( italic_X ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is countably compact.



(2)

If CH holds, then there is a DRC space Y𝑌Yitalic_Y such that no H∈R⁢C⁢(Y)+𝐻𝑅𝐶superscript𝑌H\in RC(Y)^{+}italic_H ∈ italic_R italic_C ( italic_Y ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is DCC.



(3)

If CH holds, then there is a first countable pseudocompact space Z𝑍Zitalic_Z
such that no H∈R⁢C⁢(Z)+𝐻𝑅𝐶superscript𝑍H\in RC(Z)^{+}italic_H ∈ italic_R italic_C ( italic_Z ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is DRC.","['conditionally compact', 'countably compact', 'relatively countably compact', 'pseudocompact']",[]
"Consumer-resource dynamics is central in determining biomass transport across ecosystems. The assumptions of mass action, chemostatic conditions and stationarity in stochastic feeding dynamics lead to Holling type II functional responses, whose use is widespread in macroscopic models of population dynamics. However, to be useful for parameter inference, stochastic population models need to be identifiable, this meaning that model parameters can be uniquely inferred from a large number of model observations. In this contribution we study parameter identifiability in a multi-resource consumer-resource model, for which we can obtain the steady-state and out-of-equilibrium probability distributions of predator’s abundances by analytically solving the master equation. Based on these analytical results, we can conduct in silico experiments by tracking the abundance of consumers that are either searching for or handling prey, data then used for maximum likelihood parameter estimation. We show that, when model observations are recorded out of equilibrium, feeding parameters are truly identifiable, whereas if sampling is done at stationarity, only ratios of rates can be inferred from data. We discuss the implications of our results when inferring parameters of general dynamical models.","['stochastic consumer-resource models', 'master equation', 'out-of-equilibrium distribution', 'parameter inference', 'multi-resource', 'Holling type', 'II feeding dynamics']",['Spain']
"The Polynomial-Time Hierarchy (𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH) is a staple of classical complexity theory, with applications spanning randomized computation to circuit lower bounds to “quantum advantage” analyses for near-term quantum computers.
Quantumly, however, despite the fact that at least four definitions of quantum 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH exist, it has been challenging to prove analogues for these of even basic facts from 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH.
This work studies three quantum-verifier based generalizations of PH, two of which are from [Gharibian, Santha, Sikora, Sundaram, Yirka, 2022] and use classical strings (𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH) and quantum mixed states (𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH) as proofs, and one of which is new to this work, utilizing quantum pure states (𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH) as proofs.
We first resolve several open problems from [GSSSY22], including a collapse theorem and a Karp-Lipton theorem for 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH. Then, for our new class 𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH, we show one-sided error reduction 𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH, as well as the first bounds relating these quantum variants of PH, namely 𝖰𝖢𝖯𝖧⊆𝗉𝗎𝗋𝖾𝖰𝖯𝖧⊆𝖤𝖷𝖯𝖯𝖯𝖰𝖢𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧superscript𝖤𝖷𝖯𝖯𝖯\mathsf{QCPH}\subseteq\mathsf{pureQPH}\subseteq\mathsf{EXP}^{\mathsf{PP}}sansserif_QCPH ⊆ sansserif_pureQPH ⊆ sansserif_EXP start_POSTSUPERSCRIPT sansserif_PP end_POSTSUPERSCRIPT.",[],[]
"We explicitly provide minimal Gröbner bases for simple, finite-dimensional modules of complex Lie algebras of types A and C, using a weighted ordering that is compatible with the PBW filtration on the universal enveloping algebras.",[],[]
"Let f:X⟶Y:𝑓⟶𝑋𝑌f\,:\,X\,\longrightarrow\,Yitalic_f : italic_X ⟶ italic_Y be a generically smooth nonconstant morphism between irreducible projective
curves, defined over an algebraically closed field, which is étale on an open subset of Y𝑌Yitalic_Y that contains both
the singular locus of Y𝑌Yitalic_Y and the image, in Y𝑌Yitalic_Y, of the singular locus of X𝑋Xitalic_X. We prove that the following
statements are equivalent:


(1)

The homomorphism of étale fundamental groups



f*:π1et⁢(X)⟶π1et⁢(Y):subscript𝑓⟶superscriptsubscript𝜋1et𝑋superscriptsubscript𝜋1et𝑌f_{*}\,:\,\pi_{1}^{\rm et}(X)\,\longrightarrow\,\pi_{1}^{\rm et}(Y)italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT : italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_et end_POSTSUPERSCRIPT ( italic_X ) ⟶ italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_et end_POSTSUPERSCRIPT ( italic_Y )



induced by f𝑓fitalic_f is surjective.



(2)

There is no nontrivial étale covering ϕ:Y′⟶Y:italic-ϕ⟶superscript𝑌′𝑌\phi\,:\,Y^{\prime}\,\longrightarrow\,Yitalic_ϕ : italic_Y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⟶ italic_Y admitting
a morphism q:X⟶Y′:𝑞⟶𝑋superscript𝑌′q\,:\,X\,\longrightarrow\,Y^{\prime}italic_q : italic_X ⟶ italic_Y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT such that ϕ∘q=fitalic-ϕ𝑞𝑓\phi\circ q\,=\,fitalic_ϕ ∘ italic_q = italic_f.



(3)

The fiber product X×YXsubscript𝑌𝑋𝑋X\times_{Y}Xitalic_X × start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT italic_X is connected.




(4)

dimH0⁢(X,f*⁢f*⁢𝒪X)= 1dimensionsuperscript𝐻0𝑋superscript𝑓subscript𝑓subscript𝒪𝑋1\dim H^{0}(X,\,f^{*}f_{*}{\mathcal{O}}_{X})\,=\,1roman_dim italic_H start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_X , italic_f start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT caligraphic_O start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ) = 1.



(5)

𝒪Y⊂f*⁢𝒪Xsubscript𝒪𝑌subscript𝑓subscript𝒪𝑋{\mathcal{O}}_{Y}\,\subset\,f_{*}{\mathcal{O}}_{X}caligraphic_O start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ⊂ italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT caligraphic_O start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT is the maximal semistable subsheaf.



(6)

The pullback f*⁢Esuperscript𝑓𝐸f^{*}Eitalic_f start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_E of every stable sheaf E𝐸Eitalic_E on Y𝑌Yitalic_Y is also stable.","['Étale over singular locus', 'stable bundle', 'genuinely ramified map']",[]
"Wireless communication highly depends on the cellular ground base station (GBS). A failure of the cellular GBS, fully or partially, during natural or man-made disasters creates a communication gap in the disaster-affected areas. In such situations, public safety communication (PSC) can significantly save the national infrastructure, property, and lives. Throughout emergencies, the PSC can provide mission-critical communication and video transmission services in the affected area. Unmanned aerial vehicles (UAVs) as flying base stations (UAV-BSs) are particularly suitable for PSC services as they are flexible, mobile, and easily deployable. This manuscript considers a multi-UAV-assisted PSC network with an observational UAV receiving videos from the affected area’s ground users (AGUs) and transmitting them to the nearby GBS via a relay UAV. The objective of the proposed study is to maximize the average utility of the video streams generated by the AGUs upon reaching the GBS. This is achieved by optimizing the positions of the observational and relay UAVs, as well as the distribution of communication resources, such as bandwidth, and transmit power, while satisfying the system-designed constraints, such as transmission rate, rate outage probability, transmit power budget, and available bandwidth. To this end, a joint UAVs placement and resource allocation problem is mathematically formulated. The proposed problem poses a significant challenge for a solution. Considering the block coordinate descent and successive convex approximation techniques, an efficient iterative algorithm is proposed. Finally, simulation results are provided which show that our proposed approach outperforms the existing methods.","['Public safety communication networks (PSCNs)', 'UAVs', 'video transmission', 'resource allocation.']",[]
"Social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos.
While previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. Brand personalities are shown to be affecting consumers’ behaviours and social interactions and thus are proven to be a key aspect of marketing strategies.
Current open-source multimodal LLMs are not directly suited for this task. Hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities.
Our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain English caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned social media caption. Along with brand personality, our system also gives users the flexibility to provide hashtags, Instagram handles, URLs, and named entities they want the caption to contain, making the captions more semantically related to the social media handles. Comparative evaluations against various baselines demonstrate the effectiveness of our approach, both qualitatively and quantitatively.",[],[]
"The PandaX-4T distillation system, designed for the removal of krypton and radon from xenon, was evaluated for its radon removal efficiency using a 222222{}^{222}start_FLOATSUPERSCRIPT 222 end_FLOATSUPERSCRIPTRn source during the online distillation process. The PandaX-4T dark matter detector was employed to monitor the temporal evolution of radon activity.
To determine the radon reduction factor, the experimental data of radon atoms introduced into and bypassed the distillation system was compared. The results indicate that, the PandaX-4T distillation system achieved a radon reduction factor exceeding 190 at a flow rate of 10 slpm and a reflux ratio of 1.44. Gas-only online distillation process of a flow rate of 20 slpm was also conducted, without observing significant reduction of radon levels in the detector. This observation suggests that the migration flow of radon atoms from the liquid phase to the gas phase is limited, and the flow rate and duration of the process may be insignificant compared to the total xenon mass of 6 tons.
This study provides the evidence supporting the efficient removal of radon using cryogenic distillation systems. Furthermore, it demonstrates that the distillation method could control radon background levels effectively in liquid xenon-based experiments.",[],[]
We study the possibility of FDM.,[],['India']
"Self-supervised learning (SSL) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels.
Hypothesizing that SSL models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns).
Motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing SSL models to their supervised counterparts. Our findings demonstrate that SSL has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness—exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. Ultimately, this work underscores SSL’s potential in human-centric computing, particularly high-stakes, data-scarce application domains like healthcare.",[],[]
"Machine learning models underpin many modern financial systems for use cases such as fraud detection and churn prediction. Most are based on supervised learning with hand-engineered features, which relies heavily on the availability of labelled data. Large self-supervised generative models have shown tremendous success in natural language processing and computer vision, yet so far they haven’t been adapted to multivariate time series of financial transactions. In this paper, we present a generative pretraining method that can be used to obtain contextualised embeddings of financial transactions. Benchmarks on public datasets demonstrate that it outperforms state-of-the-art self-supervised methods on a range of downstream tasks. We additionally perform large-scale pretraining of an embedding model using a corpus of data from 180 issuing banks containing 5.1 billion transactions and apply it to the card fraud detection problem on hold-out datasets. The embedding model significantly improves value detection rate at high precision thresholds and transfers well to out-of-domain distributions.","['transaction embeddings', 'self-supervised learning', 'generative modelling', 'multivariate time series', 'fraud detection']",[]
"Perceiving the complete shape of occluded objects is essential for human and machine intelligence. While the amodal segmentation task is to predict the complete mask of partially occluded objects, it is time-consuming and labor-intensive to annotate the pixel-level ground truth amodal masks. Box-level supervised amodal segmentation addresses this challenge by relying solely on ground truth bounding boxes and instance classes as supervision, thereby alleviating the need for exhaustive pixel-level annotations. Nevertheless, current box-level methodologies encounter limitations in generating low-resolution masks and imprecise boundaries, failing to meet the demands of practical real-world applications. We present a novel solution to tackle this problem by introducing a directed expansion approach from visible masks to corresponding amodal masks. Our approach involves a hybrid end-to-end network based on the overlapping region - the area where different instances intersect. Diverse segmentation strategies are applied for overlapping regions and non-overlapping regions according to distinct characteristics. To guide the expansion of visible masks, we introduce an elaborately-designed connectivity loss for overlapping regions, which leverages correlations with visible masks and facilitates accurate amodal segmentation. Experiments are conducted on several challenging datasets and the results show that our proposed method can outperform existing state-of-the-art methods with large margins.",[],[]
"Stereo matching and semantic segmentation are significant tasks in binocular satellite 3D reconstruction. However, previous studies primarily view these as independent parallel tasks, lacking an integrated multitask learning framework. This work introduces a solution, the Single-branch Semantic Stereo Network (S33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTNet), which innovatively combines semantic segmentation and stereo matching using Self-Fuse and Mutual-Fuse modules. Unlike preceding methods that utilize semantic or disparity information independently, our method identifies and leverages the intrinsic link between these two tasks, leading to a more accurate understanding of semantic information and disparity estimation. Comparative testing on the US3D dataset proves the effectiveness of our S33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTNet. Our model improves the mIoU in semantic segmentation from 61.38 to 67.39, and reduces the D1-Error and average endpoint error (EPE) in disparity estimation from 10.051 to 9.579 and 1.439 to 1.403 respectively, surpassing existing competitive methods. Our codes are available at: https://github.com/CVEO/S3Net.",[],[]
,[],[]
"This paper discusses pairing double/debiased machine learning (DDML) with stacking, a model averaging method for combining multiple candidate learners, to estimate structural parameters. We introduce two new stacking approaches for DDML: short-stacking exploits the cross-fitting step of DDML to substantially reduce the computational burden and pooled stacking enforces common stacking weights over cross-fitting folds. Using calibrated simulation studies and two applications estimating gender gaps in citations and wages, we show that DDML with stacking is more robust to partially unknown functional forms than common alternative approaches based on single pre-selected learners. We provide Stata and R software implementing our proposals.
Keywords: causal inference, partially linear model, high-dimensional models, super learners, nonparametric estimation 
JEL: C21, C26, C52, C55, J01, J08",[],[]
"Multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an “intra-modal redundancy” issue. (2) Duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an “inter-modal redundancy” issue. To address these, we propose a new framework, Prototypical Information Bottlenecking and Disentangling (PIBD), consisting of Prototypical Information Bottleneck (PIB) module for intra-modal redundancy and Prototypical Information Disentanglement (PID) module for inter-modal redundancy. Specifically, a variant of information bottleneck, PIB, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. PID module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. Extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods. The code is released 111https://github.com/zylbuaa/PIBD.git.",[],[]
"Advances in image diffusion models have recently led to notable improvements in the generation of high-quality images.
In combination with Neural Radiance Fields (NeRFs), they enabled new opportunities in 3D generation.
However, most generative 3D approaches are object-centric and applying them to editing existing photorealistic scenes is not trivial.
We propose SIGNeRF, a novel approach for fast and controllable NeRF scene editing and scene-integrated object generation.
A new generative update strategy ensures 3D consistency across the edited images, without requiring iterative optimization.
We find that depth-conditioned diffusion models inherently possess the capability to generate 3D consistent views by requesting a grid of images instead of single views.
Based on these insights, we introduce a multi-view reference sheet of modified images.
Our method updates an image collection consistently based on the reference sheet and refines the original NeRF with the newly generated image set in one go.
By exploiting the depth conditioning mechanism of the image diffusion model, we gain fine control over the spatial location of the edit and enforce shape guidance by a selected region or an external mesh.",[],[]
"A topological space is said to be DRC (\DRS) iff it possesses a dense,
relatively countably compact (or relatively sequentially compact, respectively) subspace.
The concept of
selectively pseudocompact game Sp(X) and the
selectively sequentially pseudocompact game Ssp(X) were
introduced by Dorantes-Aldama and Shakhmatov.
They explored the relationship between the existence of a winning strategy
and a stationary winning strategy for player P in these games.
In particular, they observed that there exists a stationary winning strategy
in the game Sp(X) (Ssp(X)) for Player P iff X𝑋Xitalic_X is DRC (or \DRS, respectively).
In this paper we introduce natural weakening of the properties
DRC and \DRS:
a space X𝑋Xitalic_X is DRCω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT (DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT)  iff there is a
sequence ⟨Dn:n∈ω⟩delimited-⟨⟩:subscript𝐷𝑛𝑛𝜔\left\langle D_{n}:n\in{\omega}\right\rangle⟨ italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ italic_ω ⟩ of dense subsets of X𝑋Xitalic_X such that every sequence
⟨dn:n∈ω⟩delimited-⟨⟩:subscript𝑑𝑛𝑛𝜔\left\langle d_{n}:n\in{\omega}\right\rangle⟨ italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ italic_ω ⟩ with
dn∈Dnsubscript𝑑𝑛subscript𝐷𝑛d_{n}\in D_{n}italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT has an accumulation point (or contains a convergent subsequence, respectively).
These properties are also equivalent
to the existence of some limited knowledge winning strategy on the
corresponding games S⁢p⁢(X)𝑆𝑝𝑋Sp(X)italic_S italic_p ( italic_X ) and S⁢s⁢p⁢(X)𝑆𝑠𝑝𝑋Ssp(X)italic_S italic_s italic_p ( italic_X ).
Clearly, \DRS implies DRC and DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT, DRC or DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT imply DRCω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT.
The main part of this paper is devoted to prove that apart from these trivial implications, consistently there are no
other implications between these properties.","['countably compact', 'relatively countably compact', 'relatively sequentially compact', 'pseudocompact']",[]
"The structure of the irreducible collective spaces of the group
S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ), which many-particle nuclear states are classified
according to the chain S⁢p⁢(12,R)⊃U⁢(6)⊃S⁢O⁢(6)⊃S⁢Up⁢n⁢(3)⊗S⁢O⁢(2)⊃S⁢O⁢(3)superset-of𝑆𝑝12𝑅𝑈6superset-of𝑆𝑂6superset-oftensor-product𝑆subscript𝑈𝑝𝑛3𝑆𝑂2superset-of𝑆𝑂3Sp(12,R)\supset U(6)\supset SO(6)\supset SU_{pn}(3)\otimes SO(2)\supset SO(3)italic_S italic_p ( 12 , italic_R ) ⊃ italic_U ( 6 ) ⊃ italic_S italic_O ( 6 ) ⊃ italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) ⊗ italic_S italic_O ( 2 ) ⊃ italic_S italic_O ( 3 ) of the proton-neutron
symplectic model (PNSM), is considered in detail. This chain of the
PNSM was shown to correspond to a microscopic shell-model version of
the Bohr-Mottelson collective model. The construction of the
relevant shell-model representations of the S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ) group along
this chain is considered for three nuclei with varying collective
properties and from different mass regions. It is shown that the
S⁢Up⁢n⁢(3)𝑆subscript𝑈𝑝𝑛3SU_{pn}(3)italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) basis states of the S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ) representations are
always Pauli allowed for υ≥υ0𝜐subscript𝜐0\upsilon\geq\upsilon_{0}italic_υ ≥ italic_υ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, but organized
in a different way into different S⁢O⁢(6)𝑆𝑂6SO(6)italic_S italic_O ( 6 ) shells. This is in
contrast to the case of filling the levels of the standard
three-dimensional harmonic oscillator and using the plethysm
operation. Although the S⁢Up⁢n⁢(3)𝑆subscript𝑈𝑝𝑛3SU_{pn}(3)italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) multiplets with υ<υ0𝜐subscript𝜐0\upsilon<\upsilon_{0}italic_υ < italic_υ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT are not all Pauli forbidden, it is safe to discard
them, as it was actually done in the practical applications.",[],['Bulgaria']
"Source-free domain adaptation (SFDA) aims to transfer knowledge learned from a source domain to an unlabeled target domain, where the source data is unavailable during adaptation. Existing approaches for SFDA focus on self-training usually including well-established entropy minimization and pseudo-labeling techniques.
Recent work suggested a co-learning strategy to improve the quality of the generated target pseudo-labels using robust pre-trained networks such as Swin-B. However, since the generated pseudo-labels depend on the source model, they may be noisy due to domain shift.
In this paper, we view SFDA from the perspective of label noise learning and learn to de-confuse the pseudo-labels.
More specifically, we learn a noise transition matrix of the pseudo-labels to capture the label corruption of each class and learn the underlying true label distribution.
Estimating the noise transition matrix enables a better true class-posterior estimation results with better prediction accuracy.
We demonstrate the effectiveness of our approach applied with several SFDA methods: SHOT, SHOT++, and AaD.
We obtain state-of-the-art results on three domain adaptation datasets: VisDA, DomainNet, and OfficeHome.",[],[]
"The burgeoning field of Artificial Intelligence Generated Content (AIGC) is witnessing rapid advancements, particularly in video generation. This paper introduces AIGCBench, a pioneering comprehensive and scalable benchmark designed to evaluate a variety of video generation tasks, with a primary focus on Image-to-Video (I2V) generation. AIGCBench tackles the limitations of existing benchmarks, which suffer from a lack of diverse datasets, by including a varied and open-domain image-text dataset that evaluates different state-of-the-art algorithms under equivalent conditions. We employ a novel text combiner and GPT-4 to create rich text prompts, which are then used to generate images via advanced Text-to-Image models. To establish a unified evaluation framework for video generation tasks, our benchmark includes 11 metrics spanning four dimensions to assess algorithm performance. These dimensions are control-video alignment, motion effects, temporal consistency, and video quality. These metrics are both reference video-dependent and video-free, ensuring a comprehensive evaluation strategy. The evaluation standard proposed correlates well with human judgment, providing insights into the strengths and weaknesses of current I2V algorithms. The findings from our extensive experiments aim to stimulate further research and development in the I2V field. AIGCBench represents a significant step toward creating standardized benchmarks for the broader AIGC landscape, proposing an adaptable and equitable framework for future assessments of video generation tasks.",[],[]
,[],[]
"A large part of the discussion on entanglement islands has explored the specific setup of 2⁢d2𝑑2d2 italic_d JT gravity with a flat heatbath coupled to a 2⁢d2𝑑2d2 italic_d CFT.
In this paper, we consider a more general setup and treatment of islands in a d−limit-from𝑑d-italic_d -dimensional AdS black hole background. The quantum fields modeling the Hawking radiation have a scale and are consistently inherited from a conformal parent theory; their symmetries are thus compatible with those of curved backgrounds. We demonstrate explicitly that the existence of islands is sensitive to the choice of CFT used to model the Hawking radiation.
We compute the renormalised entanglement entropy of conformal fields on a negatively curved background in d𝑑ditalic_d dimensions at zero temperature as well as the thermal regulated entropy of an entangling region near the UV boundary. Using the latter quantity as the entropy of the Hawking radiation, we find that islands never emerge for d>2𝑑2d>2italic_d > 2.",[],[]
"Recent research has shown the potential of deep learning in multi-parametric MRI-based visual pathway (VP) segmentation. However, obtaining labeled data for training is laborious and time-consuming. Therefore, it is crucial to develop effective algorithms in situations with limited labeled samples. In this work, we propose a label-efficient deep learning method with self-ensembling (LESEN). LESEN incorporates supervised and unsupervised losses, enabling the student and teacher models to mutually learn from each other, forming a self-ensembling mean teacher framework. Additionally, we introduce a reliable unlabeled sample selection (RUSS) mechanism to further enhance LESEN’s effectiveness. Our experiments on the human connectome project (HCP) dataset demonstrate the superior performance of our method when compared to state-of-the-art techniques, advancing multimodal VP segmentation for comprehensive analysis in clinical and research settings. The implementation code will be available at: https://github.com/aldiak/Semi-Supervised-Multimodal-Visual-Pathway- Delineation.",[],['China']
"Microwave electric field sensing is of importance for a wide range of applications in areas of remote sensing, radar astronomy and communications. Over the past decade, Rydberg atoms, owing to their exaggerated response to microwave electric fields, plentiful optional energy levels and integratable preparation methods, have been used in ultra-sensitive, wide broadband, traceable, stealthy microwave electric field sensing. This review first introduces the basic concept of quantum sensing, properties of Rydberg atoms and principles of quantum sensing of microwave electric fields with Rydberg atoms. Then an overview of this very active research direction is gradually expanded, covering progresses of sensitivity and bandwidth in Rydberg atoms based microwave sensing, superheterodyne quantum sensing with microwave-dressed Rydberg atoms, quantum-enhanced sensing of microwave electric field, recent advanced quantum measurement systems and approaches to further improve the performance of microwave electric field sensing. Finally, a brief outlook on future development directions is discussed.",[],[]
"E-commerce platforms usually present an ordered list, mixed with several organic items and an advertisement, in response to each user’s page view request. This list, the outcome of ad auction and allocation processes, directly impacts the platform’s ad revenue and gross merchandise volume (GMV). Specifically, the ad auction determines which ad is displayed and the corresponding payment, while the ad allocation decides the display positions of the advertisement and organic items. The prevalent methods of segregating the ad auction and allocation into two distinct stages face two problems: 1) Ad auction does not consider externalities, such as the influence of actual display position and context on ad Click-Through Rate (CTR); 2) The ad allocation, which utilizes the auction-winning ad’s payment to determine the display position dynamically, fails to maintain incentive compatibility (IC) for the advertisement. For instance, in the auction stage employing the traditional Generalized Second Price (GSP) , even if the winning ad increases its bid, its payment remains unchanged. This implies that the advertisement cannot secure a better position and thus loses the opportunity to achieve higher utility in the subsequent ad allocation stage. Previous research often focused on one of the two stages, neglecting the two-stage problem, which may result in suboptimal outcomes.

Therefore, this paper proposes a deep automated mechanism that integrates ad auction and allocation, ensuring both IC and Individual Rationality (IR) in the presence of externalities while maximizing revenue and GMV. The mechanism takes candidate ads and the ordered list of organic items as input. For each candidate ad, several candidate allocations are generated by inserting the ad in different positions of the ordered list of organic items. For each candidate allocation, a list-wise model takes the entire allocation as input and outputs the predicted result for each ad and organic item to model the global externalities. Finally, an automated auction mechanism, modeled by deep neural networks, is executed to select the optimal allocation. Consequently, this mechanism simultaneously decides the ranking, payment, and display position of the ad. Furthermore, the proposed mechanism results in higher revenue and GMV than state-of-the-art baselines in offline experiments and online A/B tests.","['Automated', 'Mechanism', 'Design', 'Ad', 'Auction', 'Externalities', 'Ad', 'Allocation']",['China']
"The back-end module of Distributed Collaborative Simultaneous Localization and Mapping (DCSLAM) requires solving a nonlinear Pose Graph Optimization (PGO) under a distributed setting, also known as S⁢E⁢(d)𝑆𝐸𝑑SE(d)italic_S italic_E ( italic_d )-synchronization.
Most existing distributed graph optimization algorithms employ a simple sequential partitioning scheme, which may result in unbalanced subgraph dimensions due to the different geographic locations of each robot, and hence imposes extra communication load.
Moreover, the performance of current Riemannian optimization algorithms can be further accelerated.
In this letter, we propose a novel distributed pose graph optimization algorithm combining multi-level partitioning with an accelerated Riemannian optimization method.
Firstly, we employ the multi-level graph partitioning algorithm to preprocess the naive pose graph to formulate a balanced optimization problem.
In addition, inspired by the accelerated coordinate descent method, we devise an Improved Riemannian Block Coordinate Descent (IRBCD) algorithm and the critical point obtained is globally optimal.
Finally, we evaluate the effects of four common graph partitioning approaches on the correlation of the inter-subgraphs, and discover that the Highest scheme has the best partitioning performance.
Also, we implement simulations to quantitatively demonstrate that our proposed algorithm outperforms the state-of-the-art distributed pose graph optimization protocols111We make the code available at https://github.com/tjcunhao/distributed-pose-graph..","['Distributed', 'Pose', 'Graph', 'Optimization', 'Graph', 'Partitioning', 'CSLAM', 'Accelerated', 'Riemannian', 'Optimization']",[]
"We describe how the spin Hall effect (SHE) can be studied from ab-initio by combining
density functional theory with the non-equilibrium Green’s functions technique for quantum
transport into the so-called DFT+NEGF method. After laying down our theoretical approach,
in particular discussing how to compute charge and spin bond currents, DFT+NEGF calculations
are carried out for ideal clean systems. In these the transport is ballistic and the linear
response limit is met. The SHE emerges in a central region attached to two leads when we apply
a bias voltage so that electrons are accelerated by a uniform electric field. As a result, we
obtain a finite spin-Hall current and, by performing a scaling analysis with respect to the
system size, we estimate the “ballistic” spin Hall conductivity (SHC). We consider 5⁢d5𝑑5d5 italic_d
metals with fcc and bcc crystal structures, finding that the SHC exhibits a rough qualitative
dependence on the d𝑑ditalic_d-band filling, and comment on these results in relation to existing
literature. Finally, within the same DFT+NEGF approach, we also predict the appearance of
a current-induced spin dipole moment inside the materials’ unit cell and estimate its magnitude.",[],"['Spain', 'Ireland']"
"Object detection models represented by YOLO series have been widely used and have achieved great results on the high quality datasets, but not all the working conditions are ideal. To settle down the problem of locating targets on low quality datasets, the existing methods either train a new object detection network, or need a large collection of low-quality datasets to train. However, we propose a framework in this paper and apply it on the YOLO models called DiffYOLO. Specifically, we extract feature maps from the denoising diffusion probabilistic models to enhance the well-trained models, which allows us fine-tune YOLO on high-quality datasets and test on low-quality datasets. The results proved this framework can not only prove the performance on noisy datasets, but also prove the detection results on high-quality test datasets. We will supplement more experiments later (with various datasets and network architectures).",[],[]
"Recently, Maurice Chayet and Skip Garibaldi introduced a class of commutative non-associative algebras.
In previous work, we gave an explicit description of these algebras for groups of type G2,F4subscript𝐺2subscript𝐹4G_{2},F_{4}italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT and certain forms of E6subscript𝐸6E_{6}italic_E start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT in terms of octonion and Albert algebras. In this paper, we extend this further by dealing with E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT in terms of generalised Freudenthal triple systems.","['non-associative algebras', 'exceptional groups', 'Lie algebras', 'Frobenius algebras', 'E7']",[]
,[],[]
"Diffusion Magnetic Resonance Imaging (dMRI) plays a crucial role in the noninvasive investigation of tissue microstructural properties and structural connectivity in the in vivo human brain. However, to effectively capture the intricate characteristics of water diffusion at various directions and scales, it is important to employ comprehensive q-space sampling. Unfortunately, this requirement leads to long scan times, limiting the clinical applicability of dMRI. To address this challenge, we propose SSOR, a Simultaneous q-Space sampling Optimization and Reconstruction framework.
We jointly optimize a subset of q-space samples using a continuous representation of spherical harmonic functions and a reconstruction network. Additionally, we integrate the unique properties of diffusion magnetic resonance imaging (dMRI) in both the q-space and image domains by applying l⁢1𝑙1l1italic_l 1-norm and total-variation regularization.The experiments conducted on HCP data demonstrate that SSOR has promising strengths both quantitatively and qualitatively and exhibits robustness to noise.",[],[]
"We present enhanced sensing of radio frequency (RF) electric fields (E-fields) by the combined polarizability of Rydberg atoms and the optimized local oscillator (LO) fields of supergheterodyne receiving. Our modified theoretical model reveals the dependencies of sensitivity of E-field amplitude measurement on the polarizability of Rydberg states and the strength of the LO RF field. The enhanced sensitivity of megahertz(MHz) E-field are demonstrated at an optimal LO field for three different Rydberg states 43⁢D5/243subscriptD52\rm 43D_{5/2}43 roman_D start_POSTSUBSCRIPT 5 / 2 end_POSTSUBSCRIPT, 60⁢S1/260subscriptS12\rm 60S_{1/2}60 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT, and 90⁢S1/290subscriptS12\rm 90S_{1/2}90 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT. The sensitivity of 63 MHz for the 90⁢S1/290subscriptS12\rm 90S_{1/2}90 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT state reaches 0.96 μ⁢V/cm/Hz𝜇VcmHz\mu\rm V/cm/\sqrt{Hz}italic_μ roman_V / roman_cm / square-root start_ARG roman_Hz end_ARG that is about an order of magnitude higher than those already published. This result closely approaches the theoretical sensitivity limit of RF dipole antennas, and indicates the potential for breaking the limit in measuring sub-MHz E-fields. This atomic sensor based on Rydberg Stark effect with heterodyne technique is expected to boost an alternative solution to electric dipole antennas.",[],['China']
"We show that any pair of Hadamard subfactors arising from complex Hadamard matrices of order 3333 are either equal or inner conjugate. If the pair of Hadamard subfactors are distinct, their intersection is shown to be a subfactor of the hyperfinite type I⁢I1𝐼subscript𝐼1II_{1}italic_I italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT factor R𝑅Ritalic_R. We compute its first relative commutant and characterize this subfactor by identifying it with a vertex model subfactor of the Krishnan-Sunder type. A few key invariants, including the Pimsner-Popa probabilistic number, the angle, and the Connes-Størmer relative entropy for the pair of Hadamard subfactors are computed to understand their relative position.",[],[]
"The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. Authors are advised to check the author instructions for the journal they are submitting to for word limits and if structural elements like subheadings, citations, or equations are permitted.",[],[]
"Generative artificial intelligence (GenAI) offers various services to users through content creation, which is believed to be one of the most important components in future networks.
However, training and deploying big artificial intelligence models (BAIMs) introduces substantial computational and communication overhead.
This poses a critical challenge to centralized approaches, due to the need of high-performance computing infrastructure and the reliability, secrecy and timeliness issues in long-distance access of cloud services.
Therefore, there is an urging need to decentralize the services, partly moving them from the cloud to the edge and establishing native GenAI services to enable private, timely, and personalized experiences.
In this paper, we propose a brand-new bottom-up BAIM architecture with synergetic big cloud model and small edge models, and design a distributed training framework and a task-oriented deployment scheme for efficient provision of native GenAI services. The proposed framework can facilitate collaborative intelligence, enhance adaptability, gather edge knowledge and alleviate edge-cloud burden.
The effectiveness of the proposed framework is demonstrated through an image generation use case. Finally, we outline fundamental research directions to fully exploit the collaborative potential of edge and cloud for native GenAI and BAIM applications.","['Generative', 'AI', 'big', 'AI model', 'cloud-edge collaboration.']",[]
"While Transformer-based pre-trained language models and their variants exhibit strong semantic representation capabilities, the question of comprehending the information gain derived from the additional components of PLMs remains an open question in this field.
Motivated by recent efforts that prove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture capabilities, even outperforming Graph Neural Networks (GNNs),
this paper aims to quantify whether simple MLPs can further enhance the already potent ability of PLMs to capture linguistic information.
Specifically, we design a simple yet effective probing framework containing MLPs components based on BERT structure and conduct extensive experiments encompassing 10 probing tasks spanning three distinct linguistic levels.
The experimental results demonstrate that MLPs can indeed enhance the comprehension of linguistic structure by PLMs.
Our research provides interpretable and valuable insights into crafting variations of PLMs utilizing MLPs for tasks that emphasize diverse linguistic structures.",[],[]
"UDIL (unified descriptive intensional logic) aims to be an alternative and improved version of Bealer’s logic111for an introduction see [25, 9] (but see the present work for a correction regarding the generalization rule for T2). fulfilling the goal of unifying Bealer’s systems T1 and T2 together with adding features to deal with definite descriptions and singular terms and their related philosophical problems (there are interesting connections to Zalta’s more restricted parallel second-order version in his book Axiomatic Metaphysics). UDIL also allows a much shorter and transparent proof of soundness, in particular with regards to a notoriously difficult preliminary lemma. UDIL stands out as being both formally and philosophically distinct from mainstream approaches to intensionality. One motivation for UDIL is to contribute to the Leibnizean goal of a formal philosophy, that is, a philosophy in which arguments and proofs are carried out entirely within a formal system. 03B65(Primary) 03B45, 03B42, 03A05 (Secondary).",[],[]
,[],[]
,[],[]
"A family of two-unitary complex Hadamard matrices (CHM) stemming from a particular matrix,
of size 36363636 is constructed.
Every matrix in this orbit remains unitary after operations of
partial transpose and reshuffling which makes it
a distinguished subset of CHM.
It provides a novel solution to the quantum version of the Euler
problem, in which each field of the Graeco-Latin square of size six contains a symmetric
superposition of all 36363636 officers with phases being multiples of
sixth root of unity. This simplifies previously known solutions
as all amplitudes of the superposition are equal and the set of phases
consists of 6666 elements only. Multidimensional parameterization
allows for more flexibility in a potential experimental treatment.",[],[]
"This work is concerned with numerical simulation of water freezing
and thawing at pore scale, resolving the complex three-dimensional
geometry of the porous medium. The used model of a porous structure
represents a container partially filled with spherical glass beads.
It has been created artificially by simulation of spheres gradually
falling into the container and organizing themselves due to gravity
and mutual collisions. For this purpose, an original model has been
developed, based on particle interaction forces exponentially decreasing
with distance . This model allows for accurate simulation of collisions
with the coefficient of restitution anywhere between zero and one.
The implementation is notably simple as it employs readily available
high order ODE solvers with time step adaptivity, resolving the moments
of collision in a natural way. For the modeling of the freezing and
thawing processes, two approaches have been utilized: The phase field
approach has been compared to the more simple solution of the heat
equation in a heterogeneous medium, with phase transitions focusing
based on temperature. The phase field approach considers the effects
of surface tension leading to premelting, whereas the simplified model
assumes that surface tension is neglected. The formulation of both
models contains novel components tailored for the given situation.
Their numerical solution has been implemented using an efficient hybrid
parallel algorithm based on the finite volume method and the Runge-Kutta-Merson
solver with adaptive time stepping. Qualitative comparison of the
results of both phase transition modeling approaches is performed
and the influence of surface tension is analyzed. Numerical stability,
accuracy, and computational costs are also discussed.",[],[]
"In extremely large-scale multiple input multiple output (XL-MIMO) systems for future sixth-generation (6G) communications, codebook-based beam training stands out as a promising technology to acquire channel state information (CSI). Despite their effectiveness, when the pilot overhead is limited, existing beam training methods suffer from significant achievable rate degradation for remote users with low signal-to-noise ratio (SNR). To tackle this challenge, leverging the error-correcting capability of channel codes, we introduce channel coding theory into hierarchical beam training to extend the coverage area. Specifically, we establish the duality between hierarchical beam training and channel coding, and the proposed coded beam training scheme serves as a general framework. Then, we present two specific implementations exemplified by coded beam training methods based on Hamming codes and convolutional codes, during which the beam encoding and decoding processes are refined respectively to better accommodate to the beam training problem. Simulation results have demonstrated that, the proposed coded beam training method can enable reliable beam training performance for remote users with low SNR, while keeping training overhead low.","['Beam training', 'channel codes', 'hierarchical codebook', 'convolutional codes', 'Hamming codes.']",[]
"Many RGBT tracking researches primarily focus on modal fusion design, while overlooking the effective handling of target appearance changes. While some approaches have introduced historical frames or fuse and replace initial templates to incorporate temporal information, they have the risk of disrupting the original target appearance and accumulating errors over time. To alleviate these limitations, we propose a novel Transformer RGBT tracking approach, which mixes spatio-temporal multimodal tokens from the static multimodal templates and multimodal search regions in Transformer to handle target appearance changes, for robust RGBT tracking. We introduce independent dynamic template tokens to interact with the search region, embedding temporal information to address appearance changes, while also retaining the involvement of the initial static template tokens in the joint feature extraction process to ensure the preservation of the original reliable target appearance information that prevent deviations from the target appearance caused by traditional temporal updates. We also use attention mechanisms to enhance the target features of multimodal template tokens by incorporating supplementary modal cues, and make the multimodal search region tokens interact with multimodal dynamic template tokens via attention mechanisms, which facilitates the conveyance of multimodal-enhanced target change information. Our module is inserted into the transformer backbone network and inherits joint feature extraction, search-template matching, and cross-modal interaction. Extensive experiments on three RGBT benchmark datasets show that the proposed approach maintains competitive performance compared to other state-of-the-art tracking algorithms while running at 39.1 FPS.","['RGBT tracking', 'Transformer', 'Cross-modal interaction', 'Spatio-Temporal', 'Multimodal', 'Tokens.']",[]
,[],"['Austria', 'Netherlands']"
"The availability of the Global Positioning System (GPS) trajectory data is increasing along with the availability of different GPS receivers and with the increasing use of various mobility services. GPS trajectory is an important data source which is used in traffic density detection, transport mode detection, mapping data inferences with the use of different methods such as image processing and machine learning methods. While the data size increases, efficient representation of this type of data is becoming difficult to be used in these methods. A common approach is the representation of GPS trajectory information such as average speed, bearing, etc. in raster image form and applying analysis methods. In this study, we evaluate GPS trajectory data rasterization using the spatial join functions of QGIS, PostGIS+QGIS, and our iterative spatial structured grid aggregation implementation coded in the Python programming language. Our implementation is also parallelizable, and this parallelization is also included as the fourth method. According to the results of experiment carried out with an example GPS trajectory dataset, QGIS method and PostGIS+QGIS method showed relatively low performance with respect to our method using the metric of total processing time. PostGIS+QGIS method achieved the best results for spatial join though its total performance decreased quickly while test area size increases. On the other hand, both of our methods’ performances decrease directly proportional to GPS point. And our methods’ performance can be increased proportional to the increase with the number of processor cores and/or with multiple computing clusters.","['Rasterization', 'GPS trajectory', 'Data aggregation', 'Spatial join', 'Parallelization']",[]
We investigate the Hardy and Rellich inequalities for classes of antisymmetric and odd functions and general exponent p𝑝pitalic_p. The obtained constants are better than the classical ones.,"['Hardy inequality', 'Rellich inequality', 'antisymmetric function', 'odd function', 'weight']",[]
"Classical spin systems with non-coplanar ground states typically exhibit nonlinear magnetization curves characterized by kinks and jumps. Our article briefly summarizes the most important related analytical results. In a comprehensive case study, we then address AF-square kagomé and AF/FM-square kagomé spin lattices equipped with additional cross-plaquette interactions. It is known that these systems have non-coplanar ground states that assume a cuboctahedral structure in the absence of a magnetic field. When a magnetic field H𝐻Hitalic_H is switched on, a rich variety of different phases develops from the cuboctahedral ground state, which are studied in their dependence on H𝐻Hitalic_H and a cross-plaquette coupling constant J3>0subscript𝐽30J_{3}>0italic_J start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0.
For the AF square-kagomé spin lattice, we carefully identify and describe seven phases that appear in a phase diagram with five triple points. The transitions between these phases are predominantly discontinuous, although two cases exhibit continuous transitions. In contrast, the phase diagram of the AF/FM square-kagomé
model shows only four phases with a single triple point,
but these also lead to exotic magnetization curves.
Here, too, there are two types of phase boundaries belonging to continuous and discontinuous transitions.",[],['Germany']
,[],[]
"In
this paper we would like to introduce some new methods for studying magic type-colorings of graphs or domination of graphs, based on combinatorial
spectrum on polynomial rings. We hope that this concept will be potentially
useful for the graph theorists.",[],[]
"For integers k≥1𝑘1k\geq 1italic_k ≥ 1 and n≥2⁢k+1𝑛2𝑘1n\geq 2k+1italic_n ≥ 2 italic_k + 1, the Schrijver graph S⁢(n,k)𝑆𝑛𝑘S(n,k)italic_S ( italic_n , italic_k ) has as vertices all k𝑘kitalic_k-element subsets of [n]:={1,2,…,n}assigndelimited-[]𝑛12…𝑛[n]:=\{1,2,\ldots,n\}[ italic_n ] := { 1 , 2 , … , italic_n } that contain no two cyclically adjacent elements, and an edge between any two disjoint sets.
More generally, for integers k≥1𝑘1k\geq 1italic_k ≥ 1, s≥2𝑠2s\geq 2italic_s ≥ 2, and n≥s⁢k+1𝑛𝑠𝑘1n\geq sk+1italic_n ≥ italic_s italic_k + 1, the s𝑠sitalic_s-stable Kneser graph S⁢(n,k,s)𝑆𝑛𝑘𝑠S(n,k,s)italic_S ( italic_n , italic_k , italic_s ) has as vertices all k𝑘kitalic_k-element subsets of [n]delimited-[]𝑛[n][ italic_n ] in which any two elements are in cyclical distance at least s𝑠sitalic_s.
We prove that all the graphs S⁢(n,k,s)𝑆𝑛𝑘𝑠S(n,k,s)italic_S ( italic_n , italic_k , italic_s ), in particular Schrijver graphs S⁢(n,k)=S⁢(n,k,2)𝑆𝑛𝑘𝑆𝑛𝑘2S(n,k)=S(n,k,2)italic_S ( italic_n , italic_k ) = italic_S ( italic_n , italic_k , 2 ), admit a Hamilton cycle that can be computed in time 𝒪⁢(n)𝒪𝑛{\mathcal{O}}(n)caligraphic_O ( italic_n ) per generated vertex.",[],[]
"The diagrammatic theory of strongly correlated systems includes two types of
selfconsistent perturbative analysis: ΦΦ\Phiroman_Φ derivability, or conserving
approximations, and iterative parquet theory. Becker and Grosser
[W. Becker and D. Grosser, Nuov. Cim. A 10, 343 (1972)]
first showed that crossing symmetry and elastic unitarity (conservation)
could not both be satisfied in any approximation to the two-particle
Bethe-Salpeter equation for the transition matrix. Jackson and Smith
[A. D. Jackson and R. A. Smith, Phys. Rev. A 36, 2517 (1987)],
later proved in particular that, despite their close affinity,
ΦΦ\Phiroman_Φ derivability and parquet are fundamentally irreconcilable.
Parquet theory computes the two-body scattering amplitude,
respecting its crossing symmetry. ΦΦ\Phiroman_Φ derivability computes the
nonequilibrium one-body dynamics, respecting conservation in the two-body
response. Parquet cannot safeguard conservation and ΦΦ\Phiroman_Φ derivability
cannot guarantee crossing symmetry, yet both are physical requirements. We
investigate these “failure modes” within a generalized Hamiltonian
approach. The two methods’ respective relation to the exact ground state
sheds light on their complementary shortcomings.",[],['Australia']
,[],[]
"In the last years, social media has gained an unprecedented amount of attention, playing a pivotal role in shaping the contemporary landscape of communication and connection. However, Coordinated Inhautentic Behaviour (CIB), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, has emerged as a tactic to exploit the online discourse.
In this study, we quantify the efficacy of CIB tactics by defining a general framework for evaluating the influence of a subset of nodes in a directed tree.
We design two algorithms that provide optimal and greedy post-hoc placement strategies that lead to maximising the configuration influence.
We then consider cascades from information spreading on Twitter to compare the observed behaviour with our algorithms.
The results show that, according to our model, coordinated accounts are quite inefficient in terms of their network influence, thus suggesting that they may play a less pivotal role than expected.
Moreover, the causes of these poor results may be found in two separate aspects: a bad placement strategy and a scarcity of resources.","['Trees', 'Influence', 'Coordinated', 'Inhautentic', 'Behaviour']",['Italy']
,[],[]
"Online contextual reasoning and association across consecutive video frames are critical to perceive instances in visual tracking. However, most current top-performing trackers persistently lean on sparse temporal relationships between reference and search frames via an offline mode. Consequently, they can only interact independently within each image-pair and establish limited temporal correlations. To alleviate the above problem, we propose a simple, flexible and effective video-level tracking pipeline, named ODTrack, which densely associates the contextual relationships of video frames in an online token propagation manner. ODTrack receives video frames of arbitrary length to capture the spatio-temporal trajectory relationships of an instance, and compresses the discrimination features (localization information) of a target into a token sequence to achieve frame-to-frame association. This new solution brings the following benefits: 1) the purified token sequences can serve as prompts for the inference in the next video frame, whereby past information is leveraged to guide future inference; 2) the complex online update strategies are effectively avoided by the iterative propagation of token sequences, and thus we can achieve more efficient model representation and computation. ODTrack achieves a new SOTA performance on seven benchmarks, while running at real-time speed.
Code and models are available at https://github.com/GXNU-ZhongLab/ODTrack.",[],[]
"The aim of this paper is to derive explicit formulas
for two distinct values. The first is the total number of symmetric peaks in a set partition of [n]delimited-[]𝑛[n][ italic_n ]
with exactly k𝑘kitalic_k blocks, and the second one is the total number of non-symmetric peaks in a set partition of [n]delimited-[]𝑛[n][ italic_n ]
with exactly k𝑘kitalic_k blocks. We represent these results in two ways. First by using the theory of generating functions,
and the second by using combinatorial tools.
Keywords: Symmetric peaks, Non-symmetric peaks, Set partitions and Generating functions.",[],[]
"Let (X,ω)𝑋𝜔(X,\omega)( italic_X , italic_ω ) be a compact Kähler manifold and θ𝜃\thetaitalic_θ be a smooth closed real (1,1)11(1,1)( 1 , 1 )-form that represents a big cohomology class. In this paper, we show that for p≥1𝑝1p\geq 1italic_p ≥ 1, the high energy space ℰp⁢(X,θ)superscriptℰ𝑝𝑋𝜃\mathcal{E}^{p}(X,\theta)caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) can be endowed with a metric dpsubscript𝑑𝑝d_{p}italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT that makes (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) a complete geodesic metric space. The weak geodesics in ℰp⁢(X,θ)superscriptℰ𝑝𝑋𝜃\mathcal{E}^{p}(X,\theta)caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) are the metric geodesic for (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ). Moreover, for p>1𝑝1p>1italic_p > 1, the geodesic metric space (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) is uniformly convex.","['Kähler', 'Manifolds', 'Pluripotential', 'Theory', 'Monge-Ampère', 'Measures', 'Finite', 'Energy', 'Classes']",[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
"Possible forms of black hole images, viewed by a distant observer, are calculated basing on general relativity and equations of motion in the Kerr-Newman metric. Black hole image is a gravitationally lensed image of the black hole event horizon. It may be viewed as a black spot on the celestial sphere, projected inside the position of classical black hole shadow. In the nearest future it would be possible to verify modified gravity theories by observations of astrophysical black hole with Space Observatory Millimetron.",[],[]
"For a
modulus of continuity ω𝜔\omegaitalic_ω
and Banach spaces X,Y𝑋𝑌X,Yitalic_X , italic_Y we introduce and study the subspaces VC˙Υ0,ω⁢(X,Y)subscriptsuperscript˙VC0𝜔Υ𝑋𝑌\dot{\operatorname{VC}}^{0,\omega}_{\Upsilon}(X,Y)over˙ start_ARG roman_VC end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( italic_X , italic_Y ) of vanishing scales Υ∈{small,large,far}Υsmalllargefar\Upsilon\in\{\operatorname{small},\operatorname{large},\operatorname{far}\}roman_Υ ∈ { roman_small , roman_large , roman_far } of the homogeneous Hölder space C˙0,ω⁢(X,Y).superscript˙𝐶0𝜔𝑋𝑌\dot{C}^{0,\omega}(X,Y).over˙ start_ARG italic_C end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT ( italic_X , italic_Y ) .
For a wide class of couples X𝑋Xitalic_X and Y𝑌Yitalic_Y, we characterize the subspaces of functions approximable by smooth and Lipschitz and boundedly supported functions in terms of these three vanishing scales.
In the particular case X=ℝn,𝑋superscriptℝ𝑛X=\mathbb{R}^{n},italic_X = blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , we identify the spaces VC˙Υ0,ω⁢(ℝn,Y)subscriptsuperscript˙VC0𝜔Υsuperscriptℝ𝑛𝑌\dot{\operatorname{VC}}^{0,\omega}_{\Upsilon}(\mathbb{R}^{n},Y)over˙ start_ARG roman_VC end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_Y ) with the corresponding vanishing mean oscillation spaces VMOΥω⁢(ℝn,Y)subscriptsuperscriptVMO𝜔Υsuperscriptℝ𝑛𝑌\mathrm{VMO}^{\omega}_{\Upsilon}(\mathbb{R}^{n},Y)roman_VMO start_POSTSUPERSCRIPT italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_Y ), thus providing a proof for the density of test functions also on these spaces.","['smooth approximation', 'vanishing mean oscillation', 'Hölder spaces', 'Banach spaces']",[]
,[],[]
,[],[]
"Language similarities can be caused by genetic relatedness, areal contact, universality, or chance.
Colexification, i.e. a type of similarity where a single lexical form is used to convey multiple meanings, is underexplored. In our work, we shed light on the linguistic causes of cross-lingual similarity in colexification and phonology, by exploring genealogical stability (persistence) and contact-induced change (diffusibility). We construct large-scale graphs incorporating semantic, genealogical, phonological and geographical data for 1,966 languages.
We then show the potential of this resource, by investigating several established hypotheses from previous work in linguistics, while proposing new ones.
Our results strongly support a previously established hypothesis in the linguistic literature, while offering contradicting evidence to another.
Our large scale resource opens for further research across disciplines, e.g. in multilingual NLP and comparative linguistics.",[],[]
,[],[]
"The Tulczyjew triple on a principal bundle with connection is constructed in a convenient trivialisation. A reduction by the structure group is performed leading to the triple on the trivialised Atiyah algebroid and a presentation of this algebroid via a double vector bundle morphism. The dynamics of physical systems with configuration manifolds having the structure of a principal bundle with connection or the Atiyah algebroid is discussed and applied to the example of an axially symmetric body confined to a sphere.
Keywords: Hamiltonian mechanics, Lagrangian mechanics, Tulczyjew triple, Ehresmann connection Lie Algebroid
MSC: 22E70, 53D05, 53Z05, 70E17, 70H33.",[],[]
"Large languages models (LLMs) trained on datasets of publicly available source code have established a new state-of-the-art in code completion.
However, these models are mostly unaware of the code that already exists within a specific project, preventing the models from making good use of existing APIs.
Instead, LLMs often invent, or “hallucinate”, non-existent APIs or produce variants of already existing code.
Although the API information is available to IDEs, the input size limit of LLMs prevents code completion techniques from including all relevant context into the prompt.
This paper presents De-Hallucinator, an LLM-based code completion technique that grounds the predictions of a model through a novel combination of retrieving suitable API references and iteratively querying the model with increasingly suitable context information in the prompt.
The approach exploits the observation that LLMs often predict code that resembles the desired completion, but that fails to correctly refer to already existing APIs.
De-Hallucinator automatically identifies project-specific API references related to the code prefix and to the model’s initial predictions and adds these references into the prompt.
Our evaluation applies the approach to the task of predicting API usages in open-source Python projects.
We show that De-Hallucinator consistently improves the predicted code across four state-of-the-art LLMs compared to querying the model only with the code before the cursor.
In particular, the approach improves the edit distance of the predicted code by 23–51% and the recall of correctly predicted API usages by 24–61% relative to the baseline.",[],['Germany']
"We present Image Sculpting, a new framework for editing 2D images by incorporating tools from 3D geometry and graphics. This approach differs markedly from existing methods, which are confined to 2D spaces and typically rely on textual instructions, leading to ambiguity and limited control. Image Sculpting converts 2D objects into 3D, enabling direct interaction with their 3D geometry. Post-editing, these objects are re-rendered into 2D, merging into the original image to produce high-fidelity results through a coarse-to-fine enhancement process. The framework supports precise, quantifiable, and physically-plausible editing options such as pose editing, rotation, translation, 3D composition, carving, and serial addition. It marks an initial step towards combining the creative freedom of generative models with the precision of graphics pipelines.††   Code and project page available here.",[],[]
"The braiding operations of quantum states have attracted substantial attention due to their great potential for realizing topological quantum computations. In this paper, we show that a three-fold degenerate eigen subspace can be obtained in a four-level Hamiltonian which is the minimal physical system. Braiding operations are proposed to apply to dressed states in the subspace. The topology of the braiding diagram can be characterized through physical methods once that the sequential braiding pulses are adopted. We establish an equivalent relationship function between the permutation group and the output states where different output states correspond to different values of the function. The topological transition of the braiding happens when two operations overlap, which is detectable through the measurement of the function. Combined with the phase variation method, we can analyze the wringing pattern of the braiding. Therefore, the experimentally-feasible system provides a platform to investigate braiding dynamics, the SU(3) physics and the qutrit gates.",[],['China']
"This paper focuses
on the initial boundary value problem of two-dimensional non-resistive MHD equations in a half space. We prove that the MHD equations have a unique global strong solution around the equilibrium state (0,𝐞𝟏)0subscript𝐞1(0,\bf{e_{1}})( 0 , bold_e start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPT ) for Dirichlet boundary condition of velocity and modified Neumann boundary condition of magnetic.

MSC: 35A01; 35Q30; 76D05

Key words: Non-resistive MHD,
  Global regularity,  Asymptotic estimates,  Half space",[],[]
"The present work shows the correspondence between f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity and a dual scalar-tensor theory (with an antisymmetric tensor field) when the affine connection is considered to have an antisymmetric part. It turns out that the f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) action in presence of spacetime torsion can be recast to a n⁢o⁢n−m⁢i⁢n⁢i⁢m⁢a⁢l⁢l⁢y𝑛𝑜𝑛𝑚𝑖𝑛𝑖𝑚𝑎𝑙𝑙𝑦non-minimallyitalic_n italic_o italic_n - italic_m italic_i italic_n italic_i italic_m italic_a italic_l italic_l italic_y coupled scalar-tensor theory with a 2-rank massless antisymmetric tensor field in the Einstein frame, where the scalar field gets coupled with the antisymmetric field through derivative coupling(s).",[],[]
"We present a theoretical study of the medium modifications on the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT balance (xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT) of dijets in Xe+Xe collisions at sNN=5.44subscript𝑠NN5.44\sqrt{s_{\rm NN}}=5.44square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 5.44 TeV.
The initial production of dijets is carried out by the POWHEG+PYTHIA8 prescription, which matches the next-to-leading order (NLO) QCD matrix elements with the parton shower (PS) effect. The in-medium evolution in nucleus-nucleus collisions is described by the SHELL model with a transport approach. The theoretical results of the dijet xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT in Xe+Xe collisions exhibit more imbalanced distributions than that in p+p, consistent with the recently reported ATLAS data. By utilizing the Interleaved Flavor Neutralisation, an infrared-and-collinear-safe jet flavor algorithm, to identify the flavor of the reconstructed jets, we classify dijets processes into three categories: gluon-gluon (g⁢g𝑔𝑔ggitalic_g italic_g), quark-gluon (q⁢g𝑞𝑔qgitalic_q italic_g) and quark-quark (q⁢q𝑞𝑞qqitalic_q italic_q), and investigate the respective medium modification patterns and fraction changes of the g⁢g𝑔𝑔ggitalic_g italic_g, q⁢g𝑞𝑔qgitalic_q italic_g, and q⁢q𝑞𝑞qqitalic_q italic_q components of the dijet sample in Xe+Xe collisions. It is shown that the q⁢g𝑞𝑔qgitalic_q italic_g component plays a key role in the increased imbalance of the dijet xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT, and especially the q1⁢g2subscript𝑞1subscript𝑔2q_{1}g_{2}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (quark-jet-leading) dijets experience more significant asymmetric energy loss than the g1⁢q2subscript𝑔1subscript𝑞2g_{1}q_{2}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (gluon-jet-leading) dijets as traversing the QGP. By comparing the Δ⁢⟨xJ⟩Δdelimited-⟨⟩subscript𝑥J\Delta\langle x_{\rm J}\rangleroman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ of inclusive, c⁢c¯𝑐¯𝑐c\bar{c}italic_c over¯ start_ARG italic_c end_ARG and b⁢b¯𝑏¯𝑏b\bar{b}italic_b over¯ start_ARG italic_b end_ARG dijets in Xe+Xe collisions, we observe Δ⁢⟨xJ⟩incl.>Δ⁢⟨xJ⟩c⁢c¯>Δ⁢⟨xJ⟩b⁢b¯Δsubscriptdelimited-⟨⟩subscript𝑥JinclΔsubscriptdelimited-⟨⟩subscript𝑥Jc¯cΔsubscriptdelimited-⟨⟩subscript𝑥Jb¯b\Delta\langle x_{\rm J}\rangle_{\rm incl.}>\Delta\langle x_{\rm J}\rangle_{\rm
c%
\bar{c}}>\Delta\langle x_{\rm J}\rangle_{\rm b\bar{b}}roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_incl . end_POSTSUBSCRIPT > roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_c over¯ start_ARG roman_c end_ARG end_POSTSUBSCRIPT > roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_b over¯ start_ARG roman_b end_ARG end_POSTSUBSCRIPT. Moreover, ρXe,Pbsubscript𝜌XePb\rho_{\rm Xe,Pb}italic_ρ start_POSTSUBSCRIPT roman_Xe , roman_Pb end_POSTSUBSCRIPT, the ratios of nuclear modification factors of dijets in Xe+Xe to that in Pb+Pb, are calcualted, which indicates that the yield suppression of dijets in Pb+Pb is more pronounced than that in Xe+Xe due to the larger radius of the lead nucleus.",[],['China']
"I identify a point-symmetric morphology of the supernova remnant (SNR) G352.7-0.1 and propose that the outer axially-symmetric structure is the remnant of a common envelope evolution (CEE) of the progenitor system, while the inner structure is the ejecta of a thermonuclear explosion triggered by the merger of a white dwarf (WD) and the core of an asymptotic giant branch (AGB) star. The main radio structure of SNR G352.7-0.1 forms an outer (large) ellipse. The bright X-ray emitting gas forms a smaller ellipse with a symmetry axis inclined to the symmetry axis of the large radio ellipse. The high abundance of iron and the energy of its X-ray lines suggest a type Ia supernova (SN Ia). The massive swept-up gas suggests a relatively massive progenitor system. I propose a scenario with progenitors of initial masses of MZAMS,1≃5−7⁢M⊙similar-to-or-equalssubscript𝑀ZAMS157subscript𝑀direct-productM_{\rm ZAMS,1}\simeq 5-7M_{\odot}italic_M start_POSTSUBSCRIPT roman_ZAMS , 1 end_POSTSUBSCRIPT ≃ 5 - 7 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and MZAMS,2≃4−5⁢M⊙similar-to-or-equalssubscript𝑀ZAMS245subscript𝑀direct-productM_{\rm ZAMS,2}\simeq 4-5M_{\odot}italic_M start_POSTSUBSCRIPT roman_ZAMS , 2 end_POSTSUBSCRIPT ≃ 4 - 5 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. At a later phase, the WD remnant of the primary star and the AGB secondary star experience a CEE that ejects the circumstellar material that swept up more ISM to form the large elliptical radio structure. An explosion during the merger of the WD with the core of the AGB star triggered a super-Chandrasekhar thermonuclear explosion that formed the inner structure that is bright in X-ray. A tertiary star in the system caused the misalignment of the two symmetry axes. This study adds to the rich variety of evolutionary routes within the different scenarios of normal and peculiar SNe Ia.","['Type', 'Ia supernovae –', 'Supernova remnants –', 'Common envelope binary stars –', 'Planetary nebulae –', 'Stellar jets']",[]
"We report on a search for a new Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT (Lμ−Lτsubscript𝐿𝜇subscript𝐿𝜏L_{\mu}-L_{\tau}italic_L start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT - italic_L start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT) vector boson performed at the NA64 experiment employing a high energy muon beam and a missing energy-momentum technique.
Muons from the M2 beamline at the CERN Super Proton Synchrotron with a momentum of 160 GeV/c are directed to an active target. A signal event is a single scattered muon with momentum <<< 80 GeV/c in the final state, accompanied by missing energy, i.e. no detectable activity in the downstream calorimeters.
For a total statistic of (1.98±0.02)×1010plus-or-minus1.980.02superscript1010(1.98\pm 0.02)\times 10^{10}( 1.98 ± 0.02 ) × 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT muons on target, no event is observed in the expected signal region. This allows us to set new limits on part of the remaining (mZ′,gZ′)subscript𝑚superscript𝑍′subscript𝑔superscript𝑍′(m_{Z^{\prime}},\ g_{Z^{\prime}})( italic_m start_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) parameter space which could provide an explanation for the muon (g−2)μsubscript𝑔2𝜇(g-2)_{\mu}( italic_g - 2 ) start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT anomaly. Additionally, our study excludes part of the parameter space suggested by the thermal Dark Matter relic abundance.
Our results pave the way to explore Dark Sectors and light Dark Matter with muon beams in a unique and complementary way to other experiments.",[],"['Greece', 'Canada', 'Switzerland', 'Chile', 'Germany', 'Spain']"
,[],[]
"Out-of-distribution (OOD) detection plays a crucial role in ensuring the security of neural networks. Existing works have leveraged the fact that In-distribution (ID) samples form a subspace in the feature space, achieving state-of-the-art (SOTA) performance. However, the comprehensive characteristics of the ID subspace still leave under-explored. Recently, the discovery of Neural Collapse (𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C) sheds light on novel properties of the ID subspace. Leveraging insight from 𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C, we observe that the Principal Angle between the features and the ID feature subspace forms a superior representation for measuring the likelihood of OOD. Building upon this observation, we propose a novel 𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C-inspired OOD scoring function, named Entropy-enhanced Principal Angle (EPA), which integrates both the global characteristic of the ID subspace and its inner property. We experimentally compare EPA with various SOTA approaches, validating its superior performance and robustness across different network architectures and OOD datasets.",[],[]
"Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance.",[],[]
"In this work, we provide a detailed analysis of the issue of encoding of quantum information which is invariant with respect to arbitrary Lorentz transformations. We significantly extend already known results and provide compliments where necessary.
In particular, we introduce novel schemes for invariant encoding which utilize so-called pair-wise helicity – a physical parameter characterizing pairs of electric-magnetic charges. We also introduce new schemes for ordinary massive and massless particles based on states with fixed total momentum, in contrast to all protocols already proposed, which assumed equal momenta of all the particles involved in the encoding scheme.
Moreover, we provide a systematic discussion of already existing protocols and show directly that they are invariant with respect to Lorentz transformations drawn according to any distribution, a fact which was not manifestly shown in previous works.",[],['Poland']
"One class of statistical hypothesis testing procedures is the indisputable equivalence tests, whose main objective is to establish practical equivalence rather than the usual statistical significant difference. These hypothesis tests are prone in “bioequivalence studies,” where one would wish to show that, for example, an existing drug and a new one under development have the same therapeutic effect. In this article, we consider a two-stage randomized (RAND2) p𝑝pitalic_p-value utilizing the uniformly most powerful (UMP) p𝑝pitalic_p-value in the first stage when multiple two-one-sided hypotheses are of interest. We investigate the behavior of the distribution functions of the two p𝑝pitalic_p-values when there are changes in the boundaries of the null or alternative hypothesis or when the chosen parameters are too close to these boundaries. We also consider the behavior of the power functions to an increase in sample size. Specifically, we investigate the level of conservativity to the sample sizes to see if we control the α𝛼\alphaitalic_α level when using either of the two p𝑝pitalic_p-values for any sample size. In multiple tests, we evaluate the performance of the two p𝑝pitalic_p-values in estimating the proportion of true null hypotheses. We conduct a family-wise error rate control using an adaptive Bonferroni procedure with a plug-in estimator to account for the multiplicity that arises from the multiple hypotheses under consideration. We verify the various claims in this research using simulation study and real-world data analysis.",[],[]
"In this paper, the sharp quantitative weighted bounds for the iterated commutators of a class of multilinear operators were systematically studied. This class of operators contains multilinear Calderón-Zygmund operators, multilinear Fourier integral operators, and multilinear Littlewood-Paley square operators as its typical examples. These were done only under two pretty much general assumptions of pointwise sparse domination estimates. We first established local decay estimates and quantitative weak A∞subscript𝐴A_{\infty}italic_A start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT decay estimates for iterated commutators of this class of operators. Then, we considered the corresponding Coifman-Fefferman inequalities and the mixed weak type estimates associated with Sawyer’s conjecture. Beyond that, the Fefferman-Stein inequalities with respect to arbitrary weights and weighted modular inequalities were also given. As applications, it was shown that all the conclusions aforementioned can be applied to multilinear ω𝜔\omegaitalic_ω-Calderón-Zygmund operators, multilinear maximal singular integral operators, multilinear pseudo-differential operators, Stein’s square functions, and higher order Calderón commutators.","['multilinear operators', 'iterated commutators', 'sparse operators', 'modular inequalities \n2020', 'Mathematics', 'Subject', 'Classification.', 'Primary 42B20', 'Secondary 42B25.']",[]
"Many-body open quantum systems (OQS) have a profound impact on various subdisciplines of physics, chemistry, and biology. Thus, the development of a computer program capable of accurately, efficiently, and versatilely simulating many-body OQS is highly desirable. In recent years, we have focused on the advancement of numerical algorithms based on the fermionic hierarchical equations of motion (HEOM) theory. Being in-principle exact, this approach allows for the precise characterization of many-body correlations, non-Markovian memory, and non-equilibrium thermodynamic conditions. These efforts now lead to the establishment of a new computer program, HEOM for QUantum Impurity with a Correlated Kernel, version 2 (HEOM-QUICK2), which, to the best of our knowledge, is currently the only general-purpose simulator for fermionic many-body OQS. Compared with version 1, the HEOM-QUICK2 program features more efficient solvers for stationary states, more accurate treatment of non-Markovian memory, and improved numerical stability for long-time dissipative dynamics. Integrated with quantum chemistry software, HEOM-QUICK2 has become a valuable theoretical tool for the precise simulation of realistic many-body OQS, particularly the single atomic or molecular junctions. Furthermore, the unprecedented precision achieved by HEOM-QUICK2 enables accurate simulation of low-energy spin excitations and coherent spin relaxation. The unique usefulness of HEOM-QUICK2 is demonstrated through several examples of strongly correlated quantum impurity systems under non-equilibrium conditions. Thus, the new HEOM-QUICK2 program offers a powerful and comprehensive tool for studying many-body OQS with exotic quantum phenomena and exploring applications in various disciplines.


Key words: open quantum systems; hierarchical equations of motion; non-Markovian dynamics; spin excitation and relaxation; strong electron correlation.",[],['China']
"Let k𝑘kitalic_k be a positive integer and let G𝐺Gitalic_G be a graph with n𝑛nitalic_n vertices.
A connected k𝑘kitalic_k-subpartition of G𝐺Gitalic_G is a collection of k𝑘kitalic_k pairwise disjoint sets (a.k.a. classes) of vertices in G𝐺Gitalic_G such that each set induces a connected subgraph.
The connected k𝑘kitalic_k-partition polytope of G𝐺Gitalic_G, denoted by 𝒫⁢(G,k)𝒫𝐺𝑘\mathcal{P}(G,k)caligraphic_P ( italic_G , italic_k ), is defined as the convex hull of the incidence vectors of all connected k𝑘kitalic_k-subpartitions of G𝐺Gitalic_G.
Many applications arising in off-shore oil-drilling, forest planning, image processing, cluster analysis, political districting, police patrolling, and biology are modeled in terms of finding connected (sub)partitions of a graph.
This study focus on the facial structure of 𝒫⁢(G,k)𝒫𝐺𝑘\mathcal{P}(G,k)caligraphic_P ( italic_G , italic_k ) and the computational complexity of the corresponding separation problems.
We first propose a set of valid inequalities having non-null coefficients associated with a single class that extends and generalizes the ones in the literature of related problems, show sufficient conditions for these inequalities to be facet-defining, and design a polynomial-time separation algorithm for them.
We also devise two sets of inequalities that consider multiple classes, prove when they define facets, and study the computational complexity of associated separation problems.",[],[]
,[],[]
,[],[]
"We study the spontaneous configuration transitions of an active semi-flexible polymer
between spiral and non-spiral states, and show that
the configuration dynamics is fully described by a subcritical pitchfork bifurcation.
Exploiting the fact that active polymer barely moves in spiral states and exhibits net displacements in non-spiral states, we prove that the motion of the active polymer is consistent with a run-and-tumble-like dynamics.
Moreover, we find that there exists an optimal self-propelling force, at which the probabilities of finding the polymer in the spiral and non-spiral state become equal, that maximizes the diffusion coefficient.",[],['France']
"Monitoring cameras are extensively utilized in industrial production to monitor equipment running. With advancements in computer vision, device recognition using image features is viable. This paper presents a vision-assisted identification system that implements real-time automatic equipment labeling through image matching in surveillance videos. The system deploys the ORB algorithm to extract image features and the GMS algorithm to remove incorrect matching points. According to the principles of clustering and template locality, a method known as Local Adaptive Clustering (LAC) has been established to enhance label positioning. This method segments matching templates using the cluster center, which improves the efficiency and stability of labels. The experimental results demonstrate that LAC effectively curtails the label drift.","['Image', 'Matching', 'Local', 'Clustering', 'Automatic', 'Identification']",[]
,[],[]
,[],[]
"We prove a new determinantal formula for the characters of irreducible representations of orthosymplectic Lie superalgebras analogous to the formula developed by Moens and Jeugt (J. Algebraic Combin., 2003) for general linear Lie superalgebras.
Our proof uses the Jacobi–Trudi type formulas for orthosymplectic characters. As a consequence, we show that
the odd symplectic characters
introduced by Proctor (Invent. Math., 1988)
are the same as the
orthosymplectic characters with some specialized indeterminates.
We also give a generalization of an odd symplectic character identity due to Brent, Krattenthaler and Warnaar (J. Combin. Theory Ser. A, 2016).","['orthosymplectic', 'Schur functions', 'hook', 'Schur polynomials', 'determinantal formula']",[]
"JPEG is a widely used compression scheme to efficiently reduce the volume of the transmitted images at the expense of visual perception drop. The artifacts appear among blocks due to the information loss in the compression process, which not only affects the quality of images but also harms the subsequent high-level tasks in terms of feature drifting. High-level vision models trained on high-quality images will suffer performance degradation when dealing with compressed images, especially on mobile devices. In recent years, numerous learning-based JPEG artifacts removal methods have been proposed to handle visual artifacts. However, it is not an ideal choice to use these JPEG artifacts removal methods as a pre-processing for compressed image classification for the following reasons: 1) These methods are designed for human vision rather than high-level vision models. 2) These methods are not efficient enough to serve as a pre-processing on resource-constrained devices. To address these issues, this paper proposes a novel lightweight adaptive feature de-drifting module (AFD-Module) to boost the performance of pre-trained image classification models when facing compressed images. First, a Feature Drifting Estimation Network (FDE-Net) is devised to generate the spatial-wise Feature Drifting Map (FDM) in the DCT domain. Next, the estimated FDM is transmitted to the Feature Enhancement Network (FE-Net) to generate the mapping relationship between degraded features and corresponding high-quality features. Specially, a simple but effective RepConv block equipped with structural re-parameterization is utilized in FE-Net, which enriches feature representation in the training phase while keeping efficiency in the deployment phase. After training on limited compressed images, the AFD-Module can serve as a “plug-and-play” module for pre-trained classification models to improve their performance on compressed images. Experiments on images compressed once (i.e. ImageNet-C) and multiple times demonstrate that our proposed AFD-Module can comprehensively improve the accuracy of the pre-trained classification models and significantly outperform the existing methods.","['JPEG compression', 'Feature', 'Drifting', 'Image', 'Classification', 'Feature', 'Enhancement']",[]
"We prove that the Cuntz–Pimsner algebra of every Temperley–Lieb subproduct system is K⁢K𝐾𝐾KKitalic_K italic_K-self-dual. We show also that every such Cuntz–Pimsner algebra has a canonical KMS-state, which we use to construct a Fredholm module representative for the fundamental class of the duality. This allows us to describe the K𝐾Kitalic_K-homology of the Cuntz–Pimsner algebras by explicit Fredholm modules.
Both the construction of the dual class and the proof of duality rely in a crucial way on quantum symmetries of Temperley–Lieb subproduct systems.
In the simplest case of Arveson’s 2222-shift our work establishes U⁢(2)𝑈2U(2)italic_U ( 2 )-equivariant K⁢K𝐾𝐾KKitalic_K italic_K-self-duality of S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT.","['Subproduct systems', 'quantum groups', 'K\u2062K𝐾𝐾KKitalic_K italic_K-theory', 'Spanier–Whitehead duality', 'Poincaré duality', 'KMS-states']",[]
"We resolve a long standing question regarding the suitable effective diffusion coefficient of the spherically-symmetric transport equation, which is valid at long times. To that end, we generalize a transport solution in three dimensions for homogeneous media, to include general collisional properties, including birth-death events and linearly anisotropic scattering. This is done by introducing an exact scaling law relating the Green function of the pure-scattering case with the general collision case, which is verified using deterministic and Monte-Carlo simulations. Importantly, the effective diffusion coefficient is identified by inspecting the transport solution at long times.",[],['Israel']
"Mode-pairing quantum key distribution (MP-QKD) can surpass the repeaterless rate-transmittance bound (Pirandola-Laurenza-Ottaviani-Banchi bound) without requiring global phase locking, exhibiting remarkable flexibility.
However, MP-QKD necessitates equal communication distances in two channels, which is a challenging requirement in practical applications.
To address this limitation, we extend the original MP-QKD to asymmetric cases.
Our decoy-state estimation confirms that asymmetric channel transmittances and asymmetric intensities do not compromise the security of the protocol.
We focus on the pulse-intensity relationship, a key factor for optimizing the performance of asymmetric MP-QKD.
Unlike previous asymmetric protocols, the intensities of different bases in asymmetric MP-QKD cannot be decoupled.
We introduce an optimal-pulse-intensity method, adaptable to various scenarios, to enhance key rates by calculating ideal pulse intensities.
Simulation results in various representative scenarios indicate that our method effectively reduces the impact of asymmetric channel distances on MP-QKD performance, enhancing its practical applicability.",[],['China']
"Modern deep learning models, growing larger and more complex, have demonstrated exceptional generalization and accuracy due to training on huge datasets. This trend is expected to continue. However, the increasing size of these models poses challenges in training, as traditional centralized methods are limited by memory constraints at such scales. This paper proposes an asynchronous decentralized training paradigm for large modern deep learning models that harnesses the compute power of regular heterogeneous PCs with limited resources connected across the internet to achieve favourable performance metrics. Ravnest facilitates decentralized training by efficiently organizing compute nodes into clusters with similar data transfer rates and compute capabilities, without necessitating that each node hosts the entire model. These clusters engage in Zero-Bubble Asynchronous Model Parallel training, and a Parallel Multi-Ring All-Reduce method is employed to effectively execute global parameter averaging across all clusters. We have framed our asynchronous SGD loss function as a block structured optimization problem with delayed updates and derived an optimal convergence rate of O⁢(1K)𝑂1𝐾O\left(\frac{1}{\sqrt{K}}\right)italic_O ( divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_K end_ARG end_ARG ). We further discuss linear speedup with respect to the number of participating clusters and the bound on the staleness parameter.",[],[]
,[],[]
"The recovery of 3D human mesh from monocular images has significantly been developed in recent years. However, existing models usually ignore spatial and temporal information, which might lead to mesh and image misalignment and temporal discontinuity. For this reason, we propose a novel Spatio-Temporal Alignment Fusion (STAF) model. As a video-based model, it leverages coherence clues from human motion by an attention-based Temporal Coherence Fusion Module (TCFM). As for spatial mesh-alignment evidence, we extract fine-grained local information through predicted mesh projection on the feature maps. Based on the spatial features, we further introduce a multi-stage adjacent Spatial Alignment Fusion Module (SAFM) to enhance the feature representation of the target frame. In addition to the above, we propose an Average Pooling Module (APM) to allow the model to focus on the entire input sequence rather than just the target frame. This method can remarkably improve the smoothness of recovery results from video. Extensive experiments on 3DPW, MPII3D, and H36M demonstrate the superiority of STAF. We achieve a state-of-the-art trade-off between precision and smoothness. Our code and more video results are on the project page https://yw0208.github.io/staf/.",[],[]
"Optical two-dimensional (2D) spectroscopy under pump-probe geometry
has achieved significant successes in one-quantum research. However,
due to the typical phase matching condition, its implementation on
the measurement of double-quantum (2Q) coherence have been limited
for long, until recently Farrell and Zanni realized detecting 2Q signal
with a permuted–pump–probe pulse sequence in 2D infrared spectroscopy.
Here, we promote this technique to 2D electronic spectroscopy. Using
this pulse sequence, both the 2Q and zero-quantum (0Q) signal will
be detected. We present that with the propagation phase of the probe
pulse and by applying a rotating frame, the 2Q and 0Q coherence exhibit
distinct effective oscillation frequencies during the scanned interval.
These frequencies may share the same sign. We propose that 2Q and
0Q coherence could be separated onto different spectra using phase
cycling techniques and causality enforcement. Our experimental demonstration
on measuring the electronic 2Q coherence of rubidium atoms yields
broadband spectra. Notably, we simultaneously observe not only the
doubly excited state of an individual rubidium atom but also the collective
resonances of dipole-dipole interactions of both D1subscript𝐷1D_{1}italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and D2subscript𝐷2D_{2}italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT
lines.",[],['China']
"Explainability in deep networks has gained increased importance in recent years. We argue herein that an AI must be tasked not just with a task but also with an explanation of why said task was accomplished as such. We present a basic framework—Task and Explanation Network (TENet)—which fully integrates task completion and its explanation.
We believe that the field of AI as a whole should insist—quite emphatically—on explainability.",[],[]
"Leakages are a major risk in water distribution networks as they cause water loss and increase contamination risks. Leakage detection is a difficult task due to the complex dynamics of water distribution networks. In particular, small leakages are hard to detect. From a machine-learning perspective, leakages can be modeled as concept drift. Thus, a wide variety of drift detection schemes seems to be a suitable choice for detecting leakages. In this work, we explore the potential of model-loss-based and distribution-based drift detection methods to tackle leakage detection. We additionally discuss the issue of temporal dependencies in the data and propose a way to cope with it when applying distribution-based detection. We evaluate different methods systematically for leakages of different sizes and detection times. Additionally, we propose a first drift-detection-based technique for localizing leakages.",[],[]
"Assistive robots should be able to wash, fold or iron clothes.
However, due to the variety, deformability and self-occlusions of clothes, creating general-purpose robot systems for cloth manipulation is challenging. Synthetic data is a promising direction to improve generalization, though its usability is often limited by the sim-to-real gap.
To advance the use of synthetic data for cloth manipulation and to enable tasks such as robotic folding, we present a synthetic data pipeline to train keypoint detectors for almost flattened cloth items. To test its performance, we have also collected a real-world dataset.
We train detectors for both T-shirts, towels and shorts and obtain an average precision of 64.3%. Fine-tuning on real-world data improves performance to 74.2%. Additional insight is provided by discussing various failure modes of the keypoint detectors and by comparing different approaches to obtain cloth meshes and materials.
We also quantify the remaining sim-to-real gap and argue that further improvements to the fidelity of cloth assets will be required to further reduce this gap. The code, dataset and trained models are available at https://github.com/tlpss/synthetic-cloth-data.","['Deep', 'Learning for', 'Visual', 'Perception', 'Simulation and', 'Animation', 'Data', 'Sets for', 'Robotic', 'Vision']",[]
"Large language models (LLMs) have been extensively used as the backbones for general-purpose agents, and some economics literature suggest that LLMs are capable of playing various types of economics games.
Following these works, to overcome the limitation of evaluating LLMs using static benchmarks, we propose to explore competitive games as an evaluation for LLMs to incorporate multi-players and dynamicise the environment.
By varying the game history revealed to LLMs-based players, we find that most of LLMs are rational in that they play strategies that can increase their payoffs, but not as rational as indicated by Nash Equilibria (NEs).
Moreover, when game history are available, certain types of LLMs, such as  GPT4, can converge faster to the NE strategies, which suggests higher rationality level in comparison to other models.
In the meantime, certain types of LLMs can win more often when game history are available, and we argue that the winning rate reflects the reasoning ability with respect to the strategies of other players.
Throughout all our experiments, we observe that the ability to strictly follow the game rules described by natural languages also vary among the LLMs we tested.
In this work, we provide an economics arena for the LLMs research community as a dynamic simulation to test the above-mentioned abilities of LLMs, i.e. rationality, strategic reasoning ability, and instruction-following capability.",[],[]
"Star formation takes place in filamentary molecular clouds which arise by physical processes that take place in the cold, neutral medium (CNM). We address the necessary conditions for this diffuse (n≈30𝑛30n\approx 30italic_n ≈ 30 cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT), cold (T ≈\approx≈ 60 K), magnetized gas undergoing shock waves and supersonic turbulence, to produce filamentary structures capable of fragmenting into cluster forming regions. Using RAMSES and a magnetized CNM environment as our initial conditions, we simulate a 0.5 kpc turbulent box to model a uniform gas with magnetic field strength of 7 μ⁢G𝜇𝐺\mu Gitalic_μ italic_G, varying the 3D velocity dispersion via decaying turbulence. We use a surface density of 320⁢M⊙⁢p⁢c−2320subscript𝑀direct-product𝑝superscript𝑐2320M_{\odot}pc^{-2}320 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT italic_p italic_c start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT, representative of the inner 4.0 kpc CMZ of the Milky Way and typical luminous galaxies. Filamentary molecular clouds are formed dynamically via shocks within a narrow range of velocity dispersions in the CNM of 5 - 10 km/s with a preferred value at 8 km/s. Cluster sink particles appear in filaments which exceed their critical line mass, occurring optimally for velocity dispersions of 8 km/s. Tracking the evolution of magnetic fields, we find that they lead to double the dense star forming gas than in purely hydro runs. Perpendicular orientations between magnetic field and filaments can increase the accretion rates onto filaments and hence their line masses. Because magnetic fields help support gas, MHD runs result in average temperatures an order of magnitude higher than unmagnetized counterparts. Finally, we find magnetic fields delay the onset of cluster formation by ∝0.4proportional-toabsent0.4\propto 0.4∝ 0.4 Myr.",[],[]
"Benefitting from the vast spatial degrees of freedom, the amalgamation of integrated sensing and communication (ISAC) and massive multiple-input multiple-output (MIMO) is expected to simultaneously improve spectral and energy efficiencies as well as the sensing capability.
However, a large number of antennas deployed in massive MIMO-ISAC raises critical challenges in acquiring both accurate channel state information and target parameter information.
To overcome these two challenges with a unified framework, we first analyze their underlying system models and then propose a novel tensor-based approach that addresses both the channel estimation and target sensing problems.
Specifically, by parameterizing the high-dimensional communication channel exploiting a small number of physical parameters, we associate the channel state information with the sensing parameters of targets in terms of angular, delay, and Doppler dimensions.
Then, we propose a shared training pattern adopting the same time-frequency resources such that both the channel estimation and target parameter estimation can be formulated as a canonical polyadic decomposition problem with a similar mathematical expression.
On this basis, we first investigate the uniqueness condition of the tensor factorization and the maximum number of resolvable targets by utilizing the specific Vandermonde structure.
Then, we develop a unified tensor-based algorithm to estimate the parameters including angles, time delays, Doppler shifts, and reflection/path coefficients of the targets/channels.
In addition, we propose a segment-based shared training pattern to facilitate the channel and target parameter estimation for the case with significant beam squint effects.
Simulation results verify our theoretical analysis and the superiority of the proposed unified algorithms in terms of estimation accuracy, sensing resolution, and training overhead reduction.","['Integrated sensing and communication', 'massive', 'MIMO', 'channel estimation', 'target parameter estimation', 'tensor decomposition.']",[]
"This paper introduces a new type of soft continuum robot, called SCoReS, which is capable of self-controlling continuously its curvature at the segment level; in contrast to previous designs which either require external forces or machine elements, or whose variable curvature capabilities are discrete—depending on the number of locking mechanisms and segments. The ability to have a variable curvature, whose control is continuous and independent from external factors, makes a soft continuum robot more adaptive in constrained environments, similar to what is observed in nature in the elephant’s trunk or ostrich’s neck for instance which exhibit multiple curvatures. To this end, our soft continuum robot enables reconfigurable variable curvatures utilizing a variable stiffness growing spine based on micro-particle granular jamming for the first time. We detail the design of the proposed robot, presenting its modeling through beam theory and FEA simulation—which is validated through experiments. The robot’s versatile bending profiles are then explored in experiments and an application to grasp fruits at different configurations is demonstrated. A narrated video detailing the work can be seen at https://youtu.be/H6SCK0NjGpE.","['Continuous stiffness regulation', 'variable curvature', 'soft robot applications', 'soft robot materials and design.']",[]
"We consider the 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT problem, the problem of minimizing the weighted number of tardy jobs on a single machine. This problem is one of the most basic and fundamental problems in scheduling theory, with several different applications both in theory and practice. We prove that 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is W[1]-hard with respect to the number p#subscript𝑝#p_{\#}italic_p start_POSTSUBSCRIPT # end_POSTSUBSCRIPT of different processing times in the input, as well as with respect to the number w#subscript𝑤#w_{\#}italic_w start_POSTSUBSCRIPT # end_POSTSUBSCRIPT of different weights in the input. This, along with previous work, provides a complete picture for 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT from the perspective of parameterized complexity, as well as almost tight complexity bounds for the problem under the Exponential Time Hypothesis (ETH).",[],[]
,[],[]
"Micro-environmental acidity is a common feature of the tumor. One of the causes behind tumor acidity is lactate production by hypoxic cells of the tumor. Hypoxia is a direct result of the establishment of oxygen gradients. It is commonly observed in the tumor in an in-vitro experimental setup and also in-vivo situation. Here, we propose a mathematical model to analyses the production of lactate by hypoxic cells, and it is used as an alternative fuel by normoxic cells in tumor tissue in-vitro and in-vivo conditions.
In this article, we study the effects of unequal oxygen concentration at the tumor boundaries on lactate status in the tumor. The effects of presence of the necrotic core in the tumor on the lactate concentration profile is examined. The results have good agreement with experimental data and align with the theoretical findings of previous studies. The analytical results show that lactate levels are elevated in an in-vivo tumor compared to that in an in-vitro tumor. Also, during the onset of necrotic core formation, the effects of necrotic core on lactate levels are noticed.
Knowledge of the lactate status in a patient’s tumor may be helpful in choosing the rightful and precious medicines for cancer treatment.",[],[]
"The astrophysical origin of binary black hole (BBH) mergers remains uncertain[1] though many events have been observed by the LIGO-Virgo-KAGRA network. Such mergers are predicted to originate in the vicinity of massive black holes (MBHs)[2, 3, 4, 5]. Especially, GW190814, due to its secondary mass and mass ratio being beyond the expectations of isolated stellar evolution theories, is a promising event that has happened in an active galactic nucleus(AGN) disk[6]. In this model, a compact object resides in the vicinity of a merging BBH. Here we report multiple pieces of evidence pointing to the fact that GW190814 is a BBH merging near a compact object. The orbital motion of BBHs around the third body produces a line-of-sight acceleration (LSA) and induces a varying Doppler shift[7, 8]. Using a waveform template that considers LSA, we perform Bayesian inference on a few BBH events with a high signal-to-noise ratio in the gravitational-wave transient catalog (GWTC). Compared to the model for isolated BBH mergers, we obtain significantly higher network signal-to-noise ratios for GW190814 by that with the LSA and constrain the LSA to a=0.0014−0.0022+0.0014⁢c⁢s−1𝑎subscriptsuperscript0.00140.00140.0022𝑐superscripts1a=0.0014^{+0.0014}_{-0.0022}~{}c~{}\mathrm{s}^{-1}italic_a = 0.0014 start_POSTSUPERSCRIPT + 0.0014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.0022 end_POSTSUBSCRIPT italic_c roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. In addition, the logarithmic Bayes factor for the LSA case over the isolated case is 16.616.616.616.6, which means the LSA model is significantly preferred by the GW data. We conclude that this is the first indication showing merging BBHs are located near a compact object.",[],[]
This paper introduces for the first time the concepts of non-coherent interfaces and microstructure-driven interface forces in the framework of micromorphic elasticity. It is shown that such concepts are of paramount importance when studying the response of finite-size mechanical metamaterials at the homogenized macro-scale. The need of introducing interface forces is elucidated through numerical examples comparing reduced relaxed micromorphic simulations to their full-microstructured counterparts. These results provide a milestone for the understanding of metamaterials’ modeling at the homogenized scale and for the use of micromorphic-type models to achieve an accurate upscaling towards larger-scale metamaterials’ structures.,[],[]
,"['multirate explicit stabilized methods', 'Rush–Larsen', 'electrophysiology', 'monodomain model', 'ionic model', 'local time-stepping']",[]
"We present two infinite families of coherent quantum speed limits (QSLs) for general unitary dynamics by employing the Hölder’s inequality for matrix norms.
Our approach clearly highlights the contribution of the coherence of the evolved states, and provides novel QSL bounds characterized by coherence measures based on Schatten p𝑝pitalic_p-norm or Hellinger distance.
We illustrate our findings with relevant models, demonstrating our bounds are much tighter than the established ones and asymptotically saturable in the adiabatic limit.
Our results show that rapid quantum dynamics requires coherent superpositions of energy eigenstates, singling out coherence as a key resource for the evolution of quantum systems.",[],['China']
"The RADiCAL Collaboration is conducting R&D on high performance electromagnetic (EM) calorimetry to address the challenges expected in future collider experiments under conditions of high luminosity and/or high irradiation (FCC-ee, FCC-hh and fixed target and forward physics environments). Under development is a sampling calorimeter approach, known as RADiCAL modules, based on scintillation and wavelength-shifting (WLS) technologies and photosensor, including SiPM and SiPM-like technology. The modules discussed herein consist of alternating layers of very dense (W) absorber and scintillating crystal (LYSO:Ce) plates, assembled to a depth of 25 X0subscript𝑋0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. The scintillation signals produced by the EM showers in the region of EM shower maximum (shower max) are transmitted to SiPM located at the upstream and downstream ends of the modules via quartz capillaries which penetrate the full length of the module. The capillaries contain DSB1 organic plastic WLS filaments positioned within the region of shower max, where the shower energy deposition is greatest, and fused with quartz rod elsewhere. The wavelength shifted light from this spatially-localized shower max region is then propagated to the photosensors. This paper presents the results of an initial measurement of the time resolution of a RADiCAL module over the energy range 25 GeV ≤\leq≤ E ≤\leq≤ 150 GeV using the H2 electron beam at CERN. The data indicate an energy dependence of the time resolution that follows the functional form: σt=a/E⊕bsubscript𝜎𝑡direct-sum𝑎𝐸𝑏\sigma_{t}=a/\sqrt{E}\oplus bitalic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a / square-root start_ARG italic_E end_ARG ⊕ italic_b, where a = 256 G⁢e⁢V𝐺𝑒𝑉\sqrt{GeV}square-root start_ARG italic_G italic_e italic_V end_ARG ps and b = 17.5 ps. The time resolution measured at the highest electron beam energy for which data was currently recorded (150 GeV) was found to be σtsubscript𝜎𝑡\sigma_{t}italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 27 ps.",[],[]
,[],[]
"Images generated by most of generative models trained with limited data often exhibit deficiencies in either fidelity, diversity, or both. One effective solution to address the limitation is few-shot generative model adaption. However, the type of approaches typically rely on a large-scale pre-trained model, serving as a source domain, to facilitate information transfer to the target domain. In this paper, we propose a method called Information Transfer from the Built Geodesic Surface (ITBGS), which contains two module: Feature Augmentation on Geodesic Surface (FAGS); Interpolation and Regularization (I&R). With the FAGS module, a pseudo-source domain is created by projecting image features from the training dataset into the Pre-Shape Space, subsequently generating new features on the Geodesic surface. Thus, no pre-trained models is needed for the adaption process during the training of generative models with FAGS. I&R module are introduced for supervising the interpolated images and regularizing their relative distances, respectively, to further enhance the quality of generated images. Through qualitative and quantitative experiments, we demonstrate that the proposed method consistently achieves optimal or comparable results across a diverse range of semantically distinct datasets, even in extremely few-shot scenarios.",[],[]
"The attention mechanism has been proven effective on various visual tasks in recent years. In the semantic segmentation task, the attention mechanism is applied in various methods, including the case of both Convolution Neural Networks (CNN) and Vision Transformer (ViT) as backbones.
However, we observe that the attention mechanism is vulnerable to patch-based adversarial attacks.
Through the analysis of the effective receptive field, we attribute it to the fact that the wide receptive field brought by global attention may lead to the spread of the adversarial patch.
To address this issue, in this paper, we propose a Robust Attention Mechanism (RAM) to improve the robustness of the semantic segmentation model, which can notably relieve the vulnerability against patch-based attacks. Compared to the vallina attention mechanism, RAM introduces two novel modules called Max Attention Suppression and Random Attention Dropout, both of which aim to refine the attention matrix and limit the influence of a single adversarial patch on the semantic segmentation results of other positions.
Extensive experiments demonstrate the effectiveness of our RAM to improve the robustness of semantic segmentation models against various patch-based attack methods under different attack settings.",[],[]
,[],[]
"In recent years, the Vision Transformer (ViT) model has gradually become mainstream in various computer vision tasks, and the robustness of the model has received increasing attention. However, existing large models tend to prioritize performance during training, potentially neglecting the robustness, which may lead to serious security concerns. In this paper, we establish a new challenge: exploring how to use a small number of additional parameters for adversarial finetuning to quickly and effectively enhance the adversarial robustness of a standardly trained model. To address this challenge, we develop the novel LNLoRA module, incorporating a learnable layer normalization before the conventional LoRA module, which helps mitigate magnitude differences in parameters between the adversarial and standard training paradigms.
Furthermore, we propose the FullLoRA-AT framework by integrating the learnable LNLoRA modules into all key components of ViT-based models while keeping the pretrained model frozen, which can significantly improve the model robustness via adversarial finetuning in a parameter-efficient manner.
Extensive experiments on CIFAR-10, CIFAR-100, and Imagenette demonstrate the superiority of our proposed FullLoRA-AT framework. It achieves comparable robustness with full finetuning while only requiring about 5% of the learnable parameters. This also effectively addresses concerns regarding extra model storage space and enormous training time caused by adversarial finetuning.",[],[]
,[],[]
"We introduce a new challenge to the software development community: 1) leveraging AI to accurately detect and flag up secrets in code and on popular document sharing platforms that frequently used by developers, such as Confluence and 2) automatically remediating the detections (e.g. by suggesting password vault functionality). This is a challenging, and mostly unaddressed task. Existing methods leverage heuristics and regular expressions, that can be very noisy, and therefore increase toil on developers. The next step - modifying code itself - to automatically remediate a detection, is a complex task. We introduce two baseline AI models that have good detection performance and propose an automatic mechanism for remediating secrets found in code, opening up the study of this task to the wider community.","['artificial intelligence', 'software engineering', 'cybersecurity']",[]
"Parallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis process compared with conventional auto-regressive models. Although parallel models have benefits in many aspects, they become naturally unfit for incremental synthesis due to their fully parallel architecture such as transformer. In this work, we propose Incremental FastPitch, a novel FastPitch variant capable of incrementally producing high-quality Mel chunks by improving the architecture with chunk-based FFT blocks, training with receptive-field constrained chunk attention masks, and inference with fixed size past model states. Experimental results show that our proposal can produce speech quality comparable to the parallel FastPitch, with a significant lower latency that allows even lower response time for real-time speech applications.",[],[]
"Many researchers around the world are researching to get control solutions that enhance robots’ ability to navigate in dynamic environments autonomously. However, until these days robots have limited capability and many navigation tasks on Earth and other planets have been difficult so far.
This paperwork presents the development of a control system for a differential drive-wheeled mobile robot that autonomously controls its position, heading, and speed based on destination information given and surrounding data gathered through mounted proximity and GPS sensors. The intelligence of this control system is implemented by using a fuzzy logic algorithm which is a very powerful tool to handle un-modeled systems like the dynamically changing environment dealt with in this research. The fuzzy controller is used to address the problems associated with navigation in an obstacle-strewn environment. Such issues include position estimation, path planning, and obstacle avoidance. 
In this study modeling, design, and simulation of the system have been done. The simulation result shows that the developed mobile robot travels successfully from any location to the destination location without colliding with obstacles. 
Keywords:- Mobile Robot; Fuzzy Logic; Navigation; Obstacle avoidance",[],[]
"The model of directed polymer in a random environment is a fundamental model of
interaction between a simple random walk and ambient disorder. This interaction
gives rise to complex phenomena and transitions from a central limit theory
to novel statistical behaviours. Despite its intense study, there are still many aspects and phases
which have not yet been identified. In this review we focus on the current status
of our understanding of the transition between weak and strong disorder phases,
give an account of some of the methods that the study of the model has motivated
and highlight some open questions.","['random polymers', 'disordered systems', 'phase transitions', 'weak and strong disorder', 'martingales', 'fractional moment method', 'coarse graining', 'pinning models', 'heavy tail disorder', 'hierarchical lattices', 'intermediate disorder regime']",[]
"This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",[],[]
"With the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. Beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. The majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. These comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. Therefore, in this study, we propose a novel Vision and Graph Fused Attention Network (VGA) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and further explore visual tampering features, as well as the textual information hidden in images. We conduct extensive experiments on three datasets, demonstrating that VGA can effectively detect multimodal rumors and outperform state-of-the-art methods significantly.","['rumor detection', 'multimodal fusion', 'propagation structure', 'social media']",['China']
"The motivation of this paper is to investigate the joint distribution of succession and Eulerian statistics.
We first investigate the enumerators for the joint distribution of descents, big ascents and successions over all permutations in the symmetric group.
As an generalization a result of Diaconis-Evans-Graham (Adv. in Appl. Math., 61 (2014), 102–124),
we show that two triple set-valued statistics of permutations are equidistributed on symmetric groups.
We then introduce the definition of proper left-to-right minimum.
We discover that the joint distribution of the succession and proper left-to-right minimum statistics over permutations is a symmetric distribution.
In the final part, we discuss the relationship between the fixfix{\rm fix\,}roman_fix and cyccyc{\rm cyc\,}roman_cyc (p,q)𝑝𝑞(p,q)( italic_p , italic_q )-Eulerian polynomials and
the joint distribution of succession and several Eulerian-type statistics.


Keywords: Eulerian polynomials; Fixed points; Successions; Proper left-to-right minima",[],[]
"Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target.
One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets.
However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge.
In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge.
First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM).
Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor.
Extensive experiments results demonstrate the superiority of MPPT against the state-of-the-art baseline methods.",[],[]
"Multichannel convolutive blind speech source separation refers to the problem of separating different speech sources from the observed multichannel mixtures without much a priori information about the mixing system. Multichannel nonnegative matrix factorization (MNMF) has been proven to be one of the most powerful separation frameworks and the representative algorithms such as MNMF and the independent low-rank matrix analysis (ILRMA) have demonstrated great performance. However, the sparseness properties of speech source signals are not fully taken into account in such a framework. It is well known that speech signals are sparse in nature, which is considered in this work to improve the separation performance. Specifically, we utilize the Bingham and Laplace distributions to formulate a disjoint constraint regularizer, which is subsequently incorporated into both MNMF and ILRMA. We then derive majorization-minimization rules for updating parameters related to the source model, resulting in the development of two enhanced algorithms: s-MNMF and s-ILRMA. Comprehensive simulations are conducted, and the results unequivocally demonstrate the efficacy of our proposed methodologies.",[],[]
"Data augmentation (DA) encodes invariance and provides implicit regularization critical to a model’s performance in image classification tasks.
However, while DA improves average accuracy, recent studies have shown that its impact can be highly class dependent: achieving optimal average accuracy comes at the cost of significantly hurting individual class accuracy by as much as 20%percent2020\%20 % on ImageNet. There has been little progress in resolving class-level accuracy drops due to a limited understanding of these effects. In this work, we present a framework for understanding how DA interacts with class-level learning dynamics. Using higher-quality multi-label annotations on ImageNet, we systematically categorize the affected classes and find that the majority are inherently ambiguous, co-occur, or involve fine-grained distinctions, while DA controls the model’s bias towards one of the closely related classes.
While many of the previously reported performance drops are explained by multi-label annotations, our analysis of class confusions reveals other sources of accuracy degradation.
We show that simple class-conditional augmentation strategies informed by our framework improve performance on the negatively affected classes.",[],[]
,[],[]
"A subgraph of an edge-colored graph is rainbow if all of its edges have different colors. Let G𝐺Gitalic_G and H𝐻Hitalic_H be two graphs. The anti-Ramsey number ar⁢(G,H)ar𝐺𝐻{\rm ar}(G,H)roman_ar ( italic_G , italic_H ) is the maximum number of colors of an edge-coloring of G𝐺Gitalic_G that does not contain a rainbow copy of H𝐻Hitalic_H. In this paper, we study the anti-Ramsey numbers of Kksubscript𝐾𝑘K_{k}italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in complete multi-partite graphs. We determine the values of the anti-Ramsey numbers of Kksubscript𝐾𝑘K_{k}italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in complete k𝑘kitalic_k-partite graphs and in balanced complete r𝑟ritalic_r-partite graphs for r≥k𝑟𝑘r\geq kitalic_r ≥ italic_k.
Keywords: anti-Ramsey number; multi-partite graph; extremal coloring",[],[]
"Regular black holes (RBHs) – geometries free from curvature singularities – arise naturally in theories of non linear electrodynamics. Here we study the absorption, and superradiant amplification, of a monochromatic planar wave in a charged, massive scalar field impinging on the electrically-charged Ayón-Beato-García (ABG) RBH. Comparisons are drawn with absorption and superradiance for the Reissner-Nordström (RN) black hole in linear electrodynamics. We find that, in a certain parameter regime, the ABG absorption cross section is negative, due to superradiance, and moreover it is unbounded from below as the momentum of the wave approaches zero; this phenomenon of “unbounded superradiance” is absent in the RN case. We show how the parameter space can be divided into regions, using the bounded/unbounded and absorption/amplification boundaries. After introducing a high-frequency approximation based on particle trajectories, we calculate the absorption cross section numerically, via the partial-wave expansion, as function of wave frequency, and we present a gallery of results. The cross section of the ABG RBH is found to be larger (smaller) than in the RN case when the field charge has the same (opposite) sign as the black hole charge. We show that it is possible to find “mimics”: situations in which the cross sections of both black holes are very similar. We conclude with a discussion of unbounded superradiance, and superradiant instabilities.",[],"['Portugal', 'Brazil']"
,[],[]
"The d𝑑ditalic_d-dimensional hypercube graph Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT has as vertices all subsets of {1,…,d}1…𝑑\{1,\ldots,d\}{ 1 , … , italic_d }, and an edge between any two sets that differ in a single element.
The Ruskey-Savage conjecture asserts that every matching of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, d≥2𝑑2d\geq 2italic_d ≥ 2, can be extended to a Hamilton cycle, i.e., to a cycle that visits every vertex exactly once.
We prove that every matching of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, d≥2𝑑2d\geq 2italic_d ≥ 2, can be extended to a cycle that visits at least a 2/3232/32 / 3-fraction of all vertices.",[],[]
,[],[]
"Different index concepts for linear differential-algebraic equations are defined in the general Banach space setting, and compared. For regular finite-dimensional linear differential-algebraic equations, all these indices exist and are equivalent. For infinite-dimensional systems, the situation is more complex. It is proven that although some indices imply others, in general they are not equivalent. The situation is illustrated with a number of examples.",[],[]
"Artificial neural networks (ANNs) have permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. However, the inherent limitations of traditional neural networks arise due to their relatively fixed network structures and activation functions. 1, The type of activation function is single and relatively fixed, which leads to poor ”unit representation ability” of the network, and it is often used to solve simple problems with very complex networks; 2, the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. To address the aforementioned issues, this study proposes a novel neural network called X-Net. By utilizing our designed Alternating Backpropagation mechanism, X-Net dynamically selects appropriate activation functions based on derivative information during training to enhance the network’s representation capability for specific tasks. Simultaneously, it accurately adjusts the network structure at the neuron level to accommodate tasks of varying complexities and reduce computational costs. Through a series of experiments, we demonstrate the dual advantages of X-Net in terms of reducing model size and improving representation power. Specifically, in terms of the number of parameters, X-Net is only 3%percent\%% of baselines on average, and only 1.4%percent\%% under some tasks. In terms of representation ability, X-Net can achieve an average R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT=0.985 on the fitting task by only optimizing the activation function without introducing any parameters. Finally, we also tested the ability of X-Net to help scientific discovery on data from multiple disciplines such as society, energy, environment, and aerospace, and achieved concise and good results.",[],[]
,[],[]
,[],[]
"We discuss representations of product systems (of W*superscript𝑊W^{*}italic_W start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-correspondences) over the semigroup ℤ+nsubscriptsuperscriptℤ𝑛\mathbb{Z}^{n}_{+}blackboard_Z start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and show that, under certain pureness and Szego positivity conditions, a completely contractive representation can be dilated to an isometric representation. For n=1,2𝑛12n=1,2italic_n = 1 , 2 this is known to hold in general (without assuming the conditions) but, for n≥3𝑛3n\geq 3italic_n ≥ 3, it does not hold in general (as is known for the special case of isometric dilations of a tuple of commuting contractions). Restricting to the case of tuples of commuting contractions, our result reduces to a result of Barik, Das, Haria and Sarkar.
Our dilation is explicitly constructed and we present some applications.","['Completely contractive representation', 'W*superscript𝑊W^{*}italic_W start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-correspondence', 'product system', 'isometric dilation', 'Szegö positivity']",[]
"We devise an autonomous quantum thermal machine consisting of three pairwise-interacting qubits, two of which are locally coupled to separate classical reservoirs. The machine operates autonomously, as it requires no time-coherent control, external driving or quantum bath engineering, and is instead propelled by a chemical potential bias between the reservoirs. Under ideal conditions, we show that this out-of-equilibrium system can deterministically generate a maximally entangled steady-state between two of the qubits, or in fact, any desired pure two-qubit entangled state, emerging as a dark state of the system. The entanglement production is also robust, such that nearly-maximally-entangled states can be generated well-away from the ideal regime of operation. Furthermore, we show that our machine architecture can be generalised to a configuration with 2⁢n−12𝑛12n-12 italic_n - 1 qubits, in which only a potential bias and two-body interactions are sufficient to generate genuine multipartite maximally entangled steady states in the form of a W state of n𝑛nitalic_n qubits.",[],['Sweden']
"In this paper we study a class of variable coefficient third order partial differential operators on ℝn+1superscriptℝ𝑛1\mathbb{R}^{n+1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT, containing, as a subclass, some variable coefficient operators of KdV-type in any space dimension. For such a class, as well as for the adjoint class, we obtain a Carleman estimate and the local solvability at any point of ℝn+1superscriptℝ𝑛1\mathbb{R}^{n+1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT. A discussion of possible applications in the context of dispersive equations is provided.","['Third order equations with variable coefficients', 'variable coefficient', 'KdV-type equations', 'Carleman estimates', 'local solvability']",[]
"This paper presents the effects of non-minimal Lorentz-violation operators in superconductivity. By constructing a Lorentz-Violating Ginzburg-Landau theory of superconductivity with a five-dimensional operator, we discuss the influence of higher dimensional Lorentz-Violating operators in the London’s depth penetration, in the coherence length and critical magnetic field.",[],['Brazil']
"We extend Ziv and Lempel’s model of finite-state encoders to the
realm of lossy compression of individual sequences. In particular, the model
of the encoder includes a finite-state reconstruction codebook followed by
an information lossless finite-state encoder that compresses the
reconstruction codeword with no additional distortion. We first derive two
different lower
bounds to the compression ratio that depend on the number of states of the
lossless encoder.
Both bounds are asymptotically achievable by
conceptually simple coding schemes. We then show that when the number of
states of the lossless encoder is large enough in terms of the reconstruction
block-length, the performance can be improved, sometimes significantly so.
In particular, the improved performance is achievable using a random-coding
ensemble that is universal, not only in terms of the source sequence, but also in terms
of the distortion measure.",[],[]
"While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data. Our model directly provides answers for 78.2%percent78.278.2\%78.2 % of the known queries and opts to search for 77.2%percent77.277.2\%77.2 % of the unknown ones. This results in the API being utilized only 62%percent6262\%62 % of the time.",[],[]
"The proliferation of low-quality online information in today’s era has underscored the need for robust and automatic mechanisms to evaluate the trustworthiness of online news publishers. In this paper, we analyse the trustworthiness of online news media outlets by leveraging a dataset of 4033 news stories from 40 different sources. We aim to infer the trustworthiness level of the source based on the classification of individual articles’ content. The trust labels are obtained from NewsGuard, a journalistic organization that evaluates news sources using well-established editorial and publishing criteria. The results indicate that the classification model is highly effective in classifying the trustworthiness levels of the news articles. This research has practical applications in alerting readers to potentially untrustworthy news sources, assisting journalistic organizations in evaluating new or unfamiliar media outlets and supporting the selection of articles for their trustworthiness assessment.","['Online', 'News', 'Transparency and', 'Reputability of', 'Online', 'News', 'Sources', 'Multiclass', 'Classification', 'Data', 'Science for', 'Social', 'Good']",['Italy']
"Much debate nowadays is devoted to the impacts of modern information and communication technology on global carbon emissions. Green information and communication technology is a paradigm creating a sustainable and environmentally friendly computing field that tries to minimize the adverse effects on the environment. Green information and communication technology are under constant development nowadays. Thus, in this paper, we undertake the problem of performance bugs that, until recently, have never been studied so profoundly. We assume that inappropriate software implementations can have a crucial influence on global carbon emissions. Here, we classify those performance bugs and develop inappropriate implementations of four programs written in C++. To mitigate these simulated performance bugs, measuring software and hardware methods that can estimate the increased carbon footprint properly were proposed.","['carbon footprint', 'green computing', 'performance bugs', 'software engineering']",[]
"Classical numerical schemes exist for solving PDEs numerically, and recently, neural network-based methods have been developed. However, methodologies using neural networks, such as PINN and neural operators, lack robustness and generalization power. To compensate for such drawbacks, there are many types of research combining classical numerical schemes and machine learning methods by replacing a small portion of the numerical schemes with neural networks. In this work, we focus on hyperbolic conservation laws and replace numerical fluxes in the numerical schemes by neural operator. For this, we construct losses that are motivated by numerical schemes for conservation laws and approximate numerical flux by FNO. Through experiments, we show that our methodology has advantages of both numerical schemes and FNO by comparing with original methods. For instance, we demonstrate our method gains robustness, resolution invariance property, and feasibility of a data-driven method. Our method especially has the ability to predict continuously in time and generalization power on the out-of-distribution samples, which are challenges to be tackled for existing neural operator methods.",[],[]
"We describe computer calculations which show that if L𝐿Litalic_L is a 5-Engel Lie
algebra over a field of characteristic zero, or over a field of prime
characteristic p>7𝑝7p>7italic_p > 7,  then L𝐿Litalic_L is nilpotent of class at most 11. We use
the representation theory of the symmetric group to show that the problem can
be reduced to showing that certain four generator Lie superalgebras satisfying
relations derived from the 5-Engel identity are nilpotent of class at most 11.
We also describe computer calculations which show that if G𝐺Gitalic_G is a finite
5-Engel p𝑝pitalic_p-group for a prime p>7𝑝7p>7italic_p > 7 then G𝐺Gitalic_G is nilpotent of class at most 10.",[],[]
"Minimizing data storage poses a significant challenge in large-scale metagenomic projects. In this paper, we present a new method for improving the encoding of FASTQ files generated by metagenomic sequencing. This method incorporates metagenomic classification followed by a recursive filter for clustering reads by DNA sequence similarity to improve the overall reference-free compression. In the results, we show an overall improvement in the compression of several datasets. As hypothesized, we show a progressive compression gain for higher coverage depth and number of identified species. Additionally, we provide an implementation that is freely available at https://github.com/cobilab/mizar and can be customized to work with other FASTQ compression tools.",[],[]
"According to the World Health Organization (WHO), air pollution kills seven million people every year. Outdoor air pollution is a major environmental health problem affecting low, middle, and high-income countries. In the past few years, the research community has explored IoT-enabled machine learning applications for outdoor air pollution prediction. The general objective of this paper is to systematically review applications of machine learning and Internet of Things (IoT) for outdoor air pollution prediction and the combination of monitoring sensors and input features used. Two research questions were formulated for this review. 1086 publications were collected in the initial PRISMA stage. After the screening and eligibility phases, 37 papers were selected for inclusion. A cost-based analysis was conducted on the findings to highlight high-cost monitoring, low-cost IoT and hybrid enabled prediction. Three methods of prediction were identified: time series, feature-based and spatio-temporal. This review’s findings identify major limitations in applications found in the literature, namely lack of coverage, lack of diversity of data and lack of inclusion of context-specific features. This review proposes directions for future research and underlines practical implications in healthcare, urban planning, global synergy and smart cities.",[],[]
"This research explores the reliability of deep learning, specifically Long Short-Term Memory (LSTM) networks, for estimating the Hurst parameter in fractional stochastic processes. The study focuses on three types of processes: fractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process, and linear fractional stable motions (lfsm). The work involves a fast generation of extensive datasets for fBm and fOU to train the LSTM network on a large volume of data in a feasible time. The study analyses the accuracy of the LSTM network’s Hurst parameter estimation regarding various performance measures like RMSE, MAE, MRE, and quantiles of the absolute and relative errors. It finds that LSTM outperforms the traditional statistical methods in the case of fBm and fOU processes; however, it has limited accuracy on lfsm processes. The research also delves into the implications of training length and valuation sequence length on the LSTM’s performance. The methodology is applied by estimating the Hurst parameter in Li-ion battery degradation data and obtaining confidence bounds for the estimation. The study concludes that while deep learning methods show promise in parameter estimation of fractional processes, their effectiveness is contingent on the process type and the quality of training data.",[],[]
,[],['France']
"Existing chain-based rotating leader BFT SMR protocols for the partially synchronous network model that commit blocks with O⁢(1)𝑂1O(1)italic_O ( 1 ) minimum latency have block periods of at least 2⁢δ2𝛿2\delta2 italic_δ (where δ𝛿\deltaitalic_δ is the message transmission latency). While a protocol with a block period of δ𝛿\deltaitalic_δ exists under the synchronous model, its minimum commit latency is linear in the size of the system.
To close this gap, we present the first chain-based BFT SMR protocols with best-case delays of δ𝛿\deltaitalic_δ between the proposals of distinct honest leaders, and minimum commit latencies of 3⁢δ3𝛿3\delta3 italic_δ. We present three protocols for the partially synchronous network model under different notions of optimistic responsiveness, two of which implement pipelining and one of which does not. All of our protocols achieve reorg resilience and two have short view lengths; properties that many existing chain-based BFT SMR protocols lack. We experimentally evaluate our protocols and show that they achieve significant increases in throughput and reductions in latency compared to the state-of-the-art, Jolteon. Our results also demonstrate that techniques commonly employed to reduce communication complexity—such as vote-pipelining and the use of designated vote-aggregators—actually reduce practical performance in many settings.",[],[]
"The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling. A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling. Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. Audio samples and codes are available at https://comosvc.github.io/.",[],[]
"It was proposed that the tensor product structure of the Hilbert space is uniquely determined by the Hamiltonian’s spectrum, for most finite-dimensional cases satisfying certain conditions.
I show that, for more than three qudits, any such method can only lead to infinitely many tensor product structures. The number of additional continuous parameters needed to find a unique solution is exponential in the number of qudits. In addition, even if the result were unique, such a Hamiltonian would not entangle subsystems.
These results affect some proposals to recover the 3d space from the Hamiltonian.","['tensor product structure entanglement emergent spacetime', 'Hilbert space fundamentalism.']",[]
"Channel state information (CSI) is important to reap the full benefits of millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems. The traditional channel estimation methods using pilot frames (PF) lead to excessive overhead. To reduce the demand for PF, data frames (DF) can be adopted for joint channel estimation and data recovery. However, the computational complexity of the DF-based methods is prohibitively high. To reduce the computational complexity, we propose a joint channel estimation and data recovery (JCD) method assisted by a small number of PF for mmWave massive MIMO systems. The proposed method has two stages. In Stage 1, differing from the traditional PF-based methods, the proposed PF-assisted method is utilized to capture the angle of arrival (AoA) of principal components (PC) of channels. In Stage 2, JCD is designed for parallel implementation based on the multi-user decoupling strategy. The theoretical analysis demonstrates that the PF-assisted JCD method can achieve equivalent performance to the Bayesian-optimal DF-based method, while greatly reducing the computational complexity. Simulation results are also presented to validate the analytical results.","['MmWave massive', 'MIMO', 'joint channel estimation and data recovery', 'PF-assisted', 'principal components.']",[]
"Magnetic reconnection is an important process in astrophysical environments, as it re-configures magnetic field topology and converts magnetic energy into thermal and kinetic energy.
In extreme astrophysical systems, such as black hole coronae and pulsar magnetospheres, radiative cooling modifies the energy partition by radiating away internal energy, which can lead to the radiative collapse of the reconnection layer. In this paper, we perform two- and three-dimensional simulations to model the MARZ (Magnetic Reconnection on Z) experiments, which are designed to access cooling rates in the laboratory necessary to investigate reconnection in a previously unexplored radiatively-cooled regime. These simulations are performed in GORGON, an Eulerian two-temperature resistive magnetohydrodynamic code, which models the experimental geometry comprising two exploding wire arrays driven by 20 MA of current on the Z machine (Sandia National Laboratories). Radiative losses are implemented using non-local thermodynamic equilibrium tables computed using the atomic code Spk, and we probe the effects of radiation transport by implementing both a local radiation loss model and P1/313{}_{1/3}start_FLOATSUBSCRIPT 1 / 3 end_FLOATSUBSCRIPT multi-group radiation transport. The load produces highly collisional, super-Alfvénic (MA≈1.5subscript𝑀𝐴1.5M_{A}\approx 1.5italic_M start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ≈ 1.5), supersonic (MS≈4−5)subscript𝑀𝑆45(M_{S}\approx 4-5)( italic_M start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ≈ 4 - 5 ) strongly driven plasma flows which generate an elongated reconnection layer (L/δ≈100,SL≈400formulae-sequence𝐿𝛿100subscript𝑆𝐿400L/\delta\approx 100,\,S_{L}\approx 400italic_L / italic_δ ≈ 100 , italic_S start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ≈ 400). The reconnection layer undergoes radiative collapse when the radiative losses exceed the rates of Ohmic and compressional heating (τcool−1/τH−1≈100superscriptsubscript𝜏cool1superscriptsubscript𝜏𝐻1100\tau_{\text{cool}}^{-1}/\tau_{H}^{-1}\approx 100italic_τ start_POSTSUBSCRIPT cool end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT / italic_τ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≈ 100); this generates a cold strongly compressed current sheet, leading to an accelerated reconnection rate, consistent with theoretical predictions. Finally, the current sheet is also unstable to the plasmoid instability, but the magnetic islands are extinguished by strong radiative cooling before ejection from the layer.",[],[]
"User facing ‘platform safety technology’ encompasses an array of tools offered by platforms to help people protect themselves from harm, for example allowing people to report content and unfollow or block other users. These tools are an increasingly important part of online safety: in the UK, legislation has made it a requirement for large platforms to offer them. However, little is known about user engagement with such tools. We present findings from a nationally representative survey of UK adults covering their awareness of and experiences with seven common safety technologies. We show that experience of online harms is widespread, with 67% of people having seen what they perceived as harmful content online; 26% of people have also had at least one piece of content removed by content moderation. Use of safety technologies is also high, with more than 80% of people having used at least one. Awareness of specific tools is varied, with people more likely to be aware of ‘post-hoc’ safety tools, such as reporting, than preventative measures. However, satisfaction with safety technologies is generally low. People who have previously seen online harms are more likely to use safety tools, implying a ‘learning the hard way’ route to engagement. Those higher in digital literacy are also more likely to use some of these tools, raising concerns about the accessibility of these technologies to all users. Additionally, women are more likely to engage in particular types of online ‘safety work’. We discuss the implications of our results for those seeking a safer online environment.


Keywords: Safety technology, User controls, User empowerment tools, Online Safety, Online harms, Survey research, Public attitudes",[],[]
"A metric measure space equipped with a Dirichlet form is called recurrent if its Hausdorff dimension is less than its walk dimension. In bounded domains of such spaces we study the parabolic Anderson models



∂tu⁢(t,x)=Δ⁢u⁢(t,x)+β⁢u⁢(t,x)⁢W˙α⁢(t,x)subscript𝑡𝑢𝑡𝑥Δ𝑢𝑡𝑥𝛽𝑢𝑡𝑥subscript˙𝑊𝛼𝑡𝑥\partial_{t}u(t,x)=\Delta u(t,x)+\beta u(t,x)\,\dot{W}_{\alpha}(t,x)∂ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_u ( italic_t , italic_x ) = roman_Δ italic_u ( italic_t , italic_x ) + italic_β italic_u ( italic_t , italic_x ) over˙ start_ARG italic_W end_ARG start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT ( italic_t , italic_x )



where the noise Wαsubscript𝑊𝛼W_{\alpha}italic_W start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT is white in time and colored in space when α>0𝛼0\alpha>0italic_α > 0 while for α=0𝛼0\alpha=0italic_α = 0 it is also white in space. Both Dirichlet and Neumann boundary conditions are considered. Besides proving existence and uniqueness in the Itô sense we also get precise Lpsuperscript𝐿𝑝L^{p}italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT estimates for the moments and intermittency properties of the solution as a consequence. Our study reveals new exponents which are intrinsically associated to the geometry of the underlying space and the results for instance apply in metric graphs or fractals like the Sierpiński gasket for which we prove scaling invariance properties of the models.",[],[]
"In this paper, we are concerned with the micro-macro Parareal algorithm for the simulation of initial-value problems.
In this algorithm, a coarse (fast) solver is applied sequentially over the time domain, and a fine (time-consuming) solver is applied as a corrector in parallel over smaller chunks of the time interval.
Moreover, the coarse solver acts on a reduced state variable, which is coupled to the fine state variable through appropriate coupling operators.
We first provide a contribution to the convergence analysis of the micro-macro Parareal method for multiscale linear ordinary differential equations (ODEs).
Then, we extend a variant of the micro-macro Parareal algorithm for scalar stochastic differential equations (SDEs) to higher-dimensional SDEs.
2020 MSC codes: 65L11, 34E13, 65C30, 68Q10, 65C35, 60H35;
Keywords: Parallel-in-time; Parareal; multiscale; McKean-Vlasov SDE; micro-macro; moment model; reduced model.",[],[]
,[],[]
"We survey the current state of affairs in the study of thresholds and sharp thresholds in random structures on the occasion of the recent proof of the Kahn–Kalai Conjecture by Park and Pham and the fairly recent proof of the satisfiability conjecture for large k𝑘kitalic_k by Ding, Sly, and Sun. Random discrete structures appear as fundamental objects of study in many scientific and mathematical fields including statistical physics, combinatorics, algorithms and complexity, social choice theory, coding theory, and statistics. While the models and properties of interest in these fields vary widely, much progress has been made through the development of general tools applicable to large families of models and properties all at once. Historically these tools originated to solve or make progress on specific, difficult conjectures in the areas mentioned above. We will survey recent progress on some of these hard problems and describe some challenges for the future.
This survey was prepared in conjunction with a talk for the Current Events Bulletin at the 2024 Joint Mathematics Meetings in San Francisco.",[],[]
"By conceiving physical systems as 3D many-body point clouds, geometric graph neural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased promising performance. In particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. However, current geometric GNNs only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. To address this limitation, tensor networks, widely employed by computational physics to handle many-body systems using high-order tensors, have been introduced. Nevertheless, integrating these tensorized networks into the message-passing framework of GNNs faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. In response, we introduce an innovative equivariant Matrix Product State (MPS)-based message-passing strategy, through achieving an efficient implementation of the tensor contraction operation. Our method effectively models complex many-body relationships, suppressing mean-field approximations, and captures symmetries within geometric graphs. Importantly, it seamlessly replaces the standard message-passing and layer-aggregation modules intrinsic to geometric GNNs. We empirically validate the superior accuracy of our approach on benchmark tasks, including predicting classical Newton systems and quantum tensor Hamiltonian matrices. To our knowledge, our approach represents the inaugural utilization of parameterized geometric tensor networks.",[],[]
Insert your english abstract here.,[],[]
"Cut and project sets
are obtained by taking an irrational slice of a lattice and projecting it to
a lower dimensional subspace, and are fully characterised by the shape of
the slice (window) and the choice of the lattice. In this context we seek to quantify
fluctuations from the asymptotics for point counts. We obtain uniform upper
bounds on the discrepancy depending on the diophantine properties of the
lattice as well as universal lower bounds on the average of the discrepancy.
In an appendix, Michael Björklund and Tobias Hartnick obtain lower bounds on
the L2superscriptL2\mathrm{L}^{2}roman_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-norm of the discrepancy also depending on the diophantine class; these lower bounds match our uniform upper
bounds and both are therefore sharp.
Using the sufficient criteria of Burago–Kleiner and
Aliste-Prieto–Coronel–Gambaudo we find an explicit full-measure class of
cut and project sets that are biLipschitz equivalent to
lattices; the lower bounds on the variance indicate that this is the largest
class of cut-and-project sets for which those sufficient criteria can apply.",[],[]
"Economic models produce moment inequalities, which can be used to form tests of the true parameters. Confidence sets (CS) of the true parameters are derived by inverting these tests. However, they often lack analytical expressions, necessitating a grid search to obtain the CS numerically by retaining the grid points that pass the test. When the statistic is not asymptotically pivotal, constructing the critical value for each grid point in the parameter space adds to the computational burden. In this paper, we convert the computational issue into a classification problem by using a support vector machine (SVM) classifier. Its decision function provides a faster and more systematic way of dividing the parameter space into two regions: inside vs. outside of the confidence set. We label those points in the CS as 1 and those outside as -1. Researchers can train the SVM classifier on a grid of manageable size and use it to determine whether points on denser grids are in the CS or not. We establish certain conditions for the grid so that there is a tuning that allows us to asymptotically reproduce the test in the CS. This means that in the limit, a point is classified as belonging to the confidence set if and only if it is labeled as 1 by the SVM.",[],[]
"In physics and engineering literature, the distribution of the excursion-above-zero time distribution (exceedance distribution) for a stationary Gaussian process has been approximated by a stationary switching process with independently distributed switching times.
The approach matched the covariance of the clipped Gaussian process with the one for the stationary switching process and the distribution of the latter was used as the so-called independent interval approximation (IIA).
The approach successfully assessed the persistency exponent for many physically important processes but left an unanswered question when such an approach leads to a mathematically meaningful and proper exceedance distribution.
Here we address this question by proposing an alternative matching of the expected values of the clipped Slepian process and the corresponding switched process initiated at the origin.
The method has allowed resolving the mathematical correctness of the matching method for a large subclass of the Gaussian processes with monotonic covariance, for which we provide a sufficient condition for the validity of the IIA.
Within this class, the IIA produces a valid distribution for the excursion time and is represented in an explicit stochastic form that connects directly to the covariance of the underlying Gaussian process.
We compare the excursion level distributions as well as the corresponding persistency exponents obtained through the IIA method with numerically computed exact distributions, and the simulated distribution for several important Gaussian models.
We also argue that for stationary Gaussian processes with a non-monotonic covariance, the IIA fails and should not be used.","['Slepian model', 'Gaussian process', 'level crossing distributions', 'switching process', 'clipped process', 'renewal process']",[]
"Network meta-analysis (NMA) combines evidence from multiple trials to compare the effectiveness of a set of interventions. In public health research, interventions are often complex, made up of multiple components or features. This makes it difficult to define a common set of interventions on which to perform the analysis. One approach to this problem is component network meta-analysis (CNMA) which uses a meta-regression framework to define each intervention as a subset of components whose individual effects combine additively. In this paper, we are motivated by a systematic review of complex interventions to prevent obesity in children. Due to considerable heterogeneity across the trials, these interventions cannot be expressed as a subset of components but instead are coded against a framework of characteristic features. To analyse these data, we develop a bespoke CNMA-inspired model that allows us to identify the most important features of interventions. We define a meta-regression model with covariates on three levels: intervention, study, and follow-up time, as well as flexible interaction terms. By specifying different regression structures for trials with and without a control arm, we relax the assumption from previous CNMA models that a control arm is the absence of intervention components. Furthermore, we derive a correlation structure that accounts for trials with multiple intervention arms and multiple follow-up times. Although our model was developed for the specifics of the obesity data set, it has wider applicability to any set of complex interventions that can be coded according to a set of shared features.",[],[]
"While it is commonly accepted that the disorder induced by magnetic ion doping in quantum magnets usually generates a rugged free-energy landscape resulting in slow or glassy spin dynamics, the disorder/distortion effects associated with non-magnetic ion sites doping are still illusive. Here, using AC susceptibility measurements, we show that the mixture of Sn/Ti on the non-magnetic ion sites of pyrochlore Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT(Ti1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPTSnx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPT)22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT induces an antiferromagnetic ground state despite both parent compounds, Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTTi22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT, and Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTSn22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT, order ferromagnetically. Local structure studies through neutron total scattering reveals the local distortion in the non-magnetic ion sites and its strong correlation with the magnetic phase switching. Our study, for the first time, demonstrates the local distortion as induced by the non-magnetic ion site mixture could be a new path to achieve magnetic phase switching, which has been traditionally obtained by external stimuli such as temperature, magnetic field, pressure, strain, light etc.",[],['Croatia']
"We present aMUSEd, an open-source, lightweight masked image model (MIM) for text-to-image generation based on MUSE (Chang et al. (2023)). With 10% of MUSE's parameters, aMUSEd is focused on fast image generation. We believe MIM is underexplored compared to latent diffusion (Rombach et al. (2022)), the prevailing approach for text-to-image generation. Compared to latent diffusion, MIM requires fewer inference steps (Chang et al. (2023)) and is more interpretable. Additionally, MIM can be fine-tuned to learn additional styles with only a single image (Sohn et al. (2023)). We hope to encourage further exploration of MIM by demonstrating its effectiveness on large-scale text-to-image generation and releasing reproducible training code. We also release checkpoints for two models which directly produce images at 256x256 and 512x512 resolutions.",[],[]
,[],[]
,[],['China']
"Design of new drugs is a challenging process: a candidate molecule should satisfy multiple conditions to act properly and make the least side-effect – perfect candidates selectively attach to and influence only targets, leaving off-targets intact.
The amount of experimental data about various properties of molecules constantly grows, promoting data-driven approaches.
However, the applicability of typical predictive machine learning techniques can be substantially limited by a lack of experimental data about a particular target.
For example, there are many known Thrombin inhibitors (acting as anticoagulants), but a very limited number of known Protein C inhibitors (coagulants).
In this study, we present our approach to suggest new inhibitor candidates by building an effective representation of chemical space.
For this aim, we developed a deep learning model – autoencoder, trained on a large set of molecules in the SMILES format to map the chemical space.
Further, we applied different sampling strategies to generate novel coagulant candidates.
Symmetrically, we tested our approach on anticoagulant candidates, where we were able to predict their inhibition towards Thrombin.
We also compare our approach with MegaMolBART – another deep learning generative model, but exploiting similar principles of navigation in a chemical space.",[],[]
,[],[]
"It is a popular hypothesis in neuroscience that ganglion cells in the retina are activated by selectively detecting visual features in an observed scene.
While ganglion cell firings can be predicted via data-trained deep neural nets, the networks remain indecipherable, thus providing little understanding of the cells’ underlying operations.
To extract knowledge from the cell firings, in this paper we learn an interpretable graph-based classifier from data to predict the firings of ganglion cells in response to visual stimuli.
Specifically, we learn a positive semi-definite (PSD) metric matrix 𝐌⪰0succeeds-or-equals𝐌0{\mathbf{M}}\succeq 0bold_M ⪰ 0 that defines Mahalanobis distances between graph nodes (visual events) endowed with pre-computed feature vectors; the computed inter-node distances lead to edge weights and a combinatorial graph that is amenable to binary classification.
Mathematically, we define the objective of metric matrix 𝐌𝐌{\mathbf{M}}bold_M optimization using a graph adaptation of large margin nearest neighbor (LMNN), which is rewritten as a semi-definite programming (SDP) problem.
We solve it efficiently via a fast approximation called Gershgorin disc perfect alignment (GDPA) linearization.
The learned metric matrix 𝐌𝐌{\mathbf{M}}bold_M provides interpretability: important features are identified along 𝐌𝐌{\mathbf{M}}bold_M’s diagonal, and their mutual relationships are inferred from off-diagonal terms.
Our fast metric learning framework can be applied to other biological systems with pre-chosen features that require interpretation.",[],['Canada']
"Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by tracking concept saliency and similarity in pruned neurons during retraining. Our findings reveal that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. This demonstrates that models exhibit polysemantic capacities and can blend old and new concepts in individual neurons. While neuron pruning provides interpretability into model concepts, our results highlight the challenges of permanent concept removal for improved model safety. Monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts will be important directions for more robust model editing. Overall, our work strongly demonstrates the resilience and fluidity of concept representations in LLMs post concept removal.",[],[]
A model of space-time foam in the form of an arbitrary distribution of spherical Euclidean wormholes is considered. A method for constructing the exact solution of Einstein’s Euclidean equations for the metric corresponding to this model is proposed. In the framework of our model we obtain the expression for the Euclidean action and its dependence on the parameters of wormholes in the explicit form. It is shown how the solutions obtained make it possible to determine all possible correlation functions associated with the parameters of virtual wormholes in the vacuum state.,[],[]
"A general modulus of continuity is quantified for locally bounded, local, weak solutions to nonlocal parabolic equations,
under a minimal tail condition. Hölder modulus of continuity is then deduced under a slightly stronger tail condition.
These regularity estimates are demonstrated under the framework of nonlocal p𝑝pitalic_p-Laplacian with measurable kernels.
Mathematics Subject Classification (2020): 35R11, 35K65, 35B65, 47G20

Key Words: Hölder regularity, parabolic p𝑝pitalic_p-Laplacian, nonlocal operators, intrinsic scaling",[],[]
"This study tasckles the problem of many-objective sequence optimization for semi-automated robotic disassembly operations. To this end, we employ a many-objective genetic algorithm (MaOGA) algorithm inspired by the Non-dominated Sorting Genetic Algorithm (NSGA)-III, along with robotic-disassembly-oriented constraints and objective functions derived from geometrical and robot simulations using 3-dimensional (3D) geometrical information stored in a 3D Computer-Aided Design (CAD) model of the target product. The MaOGA begins by generating a set of initial chromosomes based on a contact and connection graph (CCG), rather than random chromosomes, to avoid falling into a local minimum and yield repeatable convergence. The optimization imposes constraints on feasibility and stability as well as objective functions regarding difficulty, efficiency, prioritization, and allocability to generate a sequence that satisfies many preferred conditions under mandatory requirements for semi-automated robotic disassembly.
The NSGA-III-inspired MaOGA also utilizes non-dominated sorting and niching with reference lines to further encourage steady and stable exploration and uniformly lower the overall evaluation values. Our sequence generation experiments for a complex product (36 parts) demonstrated that the proposed method can consistently produce feasible and stable sequences with a 100% success rate, bringing the multiple preferred conditions closer to the optimal solution required for semi-automated robotic disassembly operations.","['Robotic disassembly', 'Disassembly sequence', 'Many-objective optimization', 'NSGA-III']",[]
"The growing demand for natural interactions with technology underscores the importance of achieving realistic touch sensations in digital environments. Realizing this goal highly depends on comprehensive databases of finger-surface interactions, which need further development. Here, we present SENS3, an extensive open-access repository of multisensory data acquired from fifty surfaces when two participants explored them with their fingertips through static contact, pressing, tapping, and sliding. SENS3 encompasses high-fidelity visual, audio, and haptic information recorded during these interactions, including videos, sounds, contact forces, torques, positions, accelerations, skin temperature, heat flux, and surface photographs. Additionally, it incorporates thirteen participants’ psychophysical sensation ratings while exploring these surfaces freely. We anticipate that SENS3 will be valuable for advancing multisensory texture rendering, user experience development, and touch sensing in robotics.","['Texture', 'Dataset', 'Haptic', 'Multisensory', 'Sensation']",[]
"Given a prime power q𝑞qitalic_q and a positive integer n𝑛nitalic_n, let 𝔽qnsubscript𝔽superscript𝑞𝑛\mathbb{F}_{q^{n}}blackboard_F start_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT represents a finite extension of degree n𝑛nitalic_n of the finite field 𝔽qsubscript𝔽𝑞{\mathbb{F}_{q}}blackboard_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT. In this article, we investigate the existence of m𝑚mitalic_m elements in arithmetic progression, where every element is primitive and at least one is normal with prescribed norms. Moreover, for n≥6,q=3k,m=2formulae-sequence𝑛6formulae-sequence𝑞superscript3𝑘𝑚2n\geq 6,q=3^{k},m=2italic_n ≥ 6 , italic_q = 3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , italic_m = 2 we establish that there are only 10101010 possible exceptions.",[],[]
"Predictions for processes involving soft photons,
up to next-to-leading power (NLP) in the photon energy,
can be obtained using the Low-Burnett-Kroll (LBK) theorem.
The consistency of the theorem has been a recent topic of investigation
since it is traditionally formulated in terms of a non-radiative
amplitude, which is evaluated with unphysical momenta.
We address such questions and propose a formulation of the
LBK theorem which relies on the evaluation of the non-radiative
amplitude with on-shell, physical momenta.
We use this form to numerically study the impact
of NLP contributions to cross-sections for p⁢p𝑝𝑝ppitalic_p italic_p and
e−⁢e+superscript𝑒superscript𝑒e^{-}e^{+}italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT processes involving soft-photon emission.",[],[]
"The geodesic method has played a crucial role in understanding the circular orbits generated by compact objects, culminating in the definition of the photon sphere, which was later generalized to a photon surface in arbitrary spacetimes. This new formulation extends the concept of the photon sphere in a broader sense, including dynamical spacetimes, as shown by the Vaidya solution. The photon surface essentially defines the null geodesics, which are originally tangent to the temporal surface, and keeps them confined to this surface. However, this formalism does not cover all classes of particles, and to overcome this limitation, a more comprehensive approach, denoted as the “massive particle surface”, has been proposed that also accounts for charged massive particles. Indeed, the photon surface concept is recovered when the charge and mass of the particles are zero. In this work, we use these three formalisms to check the consistency of the results for the values of the radius of the photon sphere (rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT) and the radius of the “innermost stable circular orbit” (ISCO) (rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT) for some gravitational models. In our results, the first model is described by conformal gravity, with the peculiarity that g00≠−g11−1subscript𝑔00superscriptsubscript𝑔111g_{00}\neq-g_{11}^{-1}italic_g start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT ≠ - italic_g start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. The second model, i.e. Culetu model, is developed by coupling General Relativity (GR) with nonlinear electrodynamics (NLED), which requires the consideration of the effective metric (geffμ⁢νsuperscriptsubscript𝑔eff𝜇𝜈g_{\rm eff}^{\mu\nu}italic_g start_POSTSUBSCRIPT roman_eff end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_μ italic_ν end_POSTSUPERSCRIPT) for geodesic approaches, for example.
Under these circumstances, we have found that the value for the radius of the photon sphere (rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT) obtained by the massive particle surface formalism in the conformal gravity case does not agree with the values obtained by the geodesic and photon surface formalisms. Similarly, the values for rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT differ between the geodesic and the massive particle surface formalisms. In Culetu’s model, we found the same values for the radius of the photon sphere rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT when we consider the effective metric in the geodesic and photon surface formalisms. However, when we apply the massive particle surface formalism, we find an inconsistency with the values of the other two formalisms. Finally, we have examined the expressions for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT and rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT for a spherically symmetric and generally static metric arising from the massive particle surface method. We find that the expression for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT, for example, differs from the photon surface method, as does the expression for rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT, which differs from the geodesic formalism. Moreover, we highlight a significant difference in the two expressions obtained for a static and spherically symmetric metric in general, as they exhibit a dependence on the metric function −g11=B⁢(r)subscript𝑔11𝐵𝑟-g_{11}=B(r)- italic_g start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = italic_B ( italic_r ), unlike the other expressions for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT and rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT in the other two formalisms.",[],"['Portugal', 'Brazil']"
"Connected and automated vehicles (CAVs) have become a transformative technology that can change our daily life.
Currently, millimeter-wave (mmWave) bands are identified as the promising CAV connectivity solution. While it can provide high data rate, their realization faces many challenges such as high attenuation during mmWave signal propagation and mobility management. Existing solution has to initiate pilot signal to measure channel information, then apply signal processing to calculate the best narrow beam towards the receiver end to guarantee sufficient signal power. This process takes significant overhead and time, hence not suitable for vehicles. In this study, we propose an autonomous and low-cost testbed to collect extensive co-located mmWave signal and other sensors data such as LiDAR (Light Detection and Ranging), cameras, ultrasonic, etc, traditionally for “automated”, to facilitate mmWave vehicular communications. Intuitively, these sensors can build a 3D map around the vehicle and signal propagation path can be estimated, eliminating iterative the process via pilot signals. This multimodal data fusion, together with AI, is expected to bring significant advances in “connected” research.","['Vehicular communication', 'mmWave communication', 'sensor fusion', 'machine learning.']",[]
"We introduce the video detours problem for navigating instructional videos. Given a source video and a natural language query asking to alter the how-to video’s current path of execution in a certain way, the goal is to find a related “detour video” that satisfies the requested alteration. To address this challenge, we propose VidDetours, a novel video-language approach that learns to retrieve the targeted temporal segments from a large repository of how-to’s using video-and-text conditioned queries. Furthermore, we devise a language-based pipeline that exploits how-to video narration text to create weakly supervised training data.
We demonstrate our idea applied to the domain of how-to cooking videos, where a user can detour from their current recipe to find steps with alternate ingredients, tools, and techniques. Validating on a ground truth annotated dataset of 16K samples, we show our model’s significant improvements over best available methods for video retrieval and question answering, with recall rates exceeding the state of the art by 35%.",[],[]
"The investigation of many-body interactions holds significant importance in both quantum foundations and information. Hamiltonians coupling multiple particles at once, beyond others, can lead to a faster entanglement generation, multiqubit gate implementation and improved error correction. As an increasing number of quantum platforms enable the realization of such physical settings, it becomes interesting to study the verification of many-body interaction resources. In this work, we explore the possibility of higher-order couplings detection through the quantum Fisher information. For a family of symmetric and translationally invariant k𝑘kitalic_k-body Ising-like Hamiltonians, we derive the bounds on the quantum Fisher information in product states. Due to its ordering with respect to the order of interaction, we demonstrate the possibility of detecting many-body couplings for a given Hamiltonian from the discussed family by observing violations of an appropriate bound.",[],['Poland']
"The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://physio.inesctec.pt.","['Retrieval-augmented generation', 'Information extraction', 'Conversational health agents']",[]
,[],[]
"Most existing video diffusion models (VDMs) are limited to mere text conditions. Thereby, they are usually lacking in control over visual appearance and geometry structure of the generated videos. This work presents MoonShot, a new video generation model that conditions simultaneously on multimodal inputs of image and text. The model builts upon a core module, called multimodal video block (MVB), which consists of conventional spatialtemporal layers for representing video features, and a decoupled cross-attention layer to address image and text inputs for appearance conditioning. In addition, we carefully design the model architecture such that it can optionally integrate with pre-trained image ControlNet modules for geometry visual conditions, without needing of extra training overhead as opposed to prior methods. Experiments show that with versatile multimodal conditioning mechanisms, MoonShot demonstrates significant improvement on visual quality and temporal consistency compared to existing models. In addition, the model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing, unveiling its potential to serve as a fundamental architecture for controllable video generation. Models will be made public on https://github.com/salesforce/LAVIS.",[],[]
"Energy disaggregation is a promising solution to access detailed information on energy consumption in a household, by itemizing its total energy consumption. However, in real-world applications, overfitting remains a challenging problem for data-driven disaggregation methods. First, the available real-world datasets are biased towards the most frequently used appliances. Second, both real and synthetic publicly-available datasets are limited in number of appliances, which may not be sufficient for a disaggregation algorithm to learn complex relations among different types of appliances and their states. To address the lack of appliance data, we propose two physics-informed data generators: one for high sampling rate signals (kHz) and another for low sampling rate signals (Hz). These generators rely on prior knowledge of the physics of appliance energy consumption, and are capable of simulating a virtually unlimited number of different appliances and their corresponding signatures for any time period. Both methods involve defining a mathematical model, selecting centroids corresponding to individual appliances, sampling model parameters around each centroid, and finally substituting the obtained parameters into the mathematical model. Additionally, by using Principal Component Analysis and Kullback-Leibler divergence, we demonstrate that our methods significantly outperform the previous approaches.","['energy disaggregation', 'non-intrusive load monitoring', 'synthetic data', 'physics-informed methods']",[]
"High-energy photons may oscillate with axion-like particles (ALPs) when they propagate through the Milky Way’s magnetic field, resulting in an alteration in the observed photon energy spectrum. The ultra-high energy gamma-ray spectra, measured by the Large High Altitude Air Shower Observatory (LHAASO) up to 𝒪⁢(1)⁢PeV𝒪1PeV\mathcal{O}(1)~{}\mathrm{PeV}caligraphic_O ( 1 ) roman_PeV, provide a promising opportunity to investigate the ALP-photon oscillation effect. In this study, we utilize the gamma-ray spectra of four Galactic sources measured by LHAASO, including the Crab Nebula, LHAASO J2226+6057, LHAASO J1908+0621, and LHAASO J1825-1326, to explore this effect. We employ the CLssubscriptCLs\rm CL_{s}roman_CL start_POSTSUBSCRIPT roman_s end_POSTSUBSCRIPT method to set constraints on the ALP parameters.
Combing the observations of the four sources, our analysis reveals that the ALP-photon coupling ga⁢γsubscript𝑔𝑎𝛾g_{a\gamma}italic_g start_POSTSUBSCRIPT italic_a italic_γ end_POSTSUBSCRIPT is constrained to be smaller than
1.4×10−101.4superscript10101.4\times 10^{-10}1.4 × 10 start_POSTSUPERSCRIPT - 10 end_POSTSUPERSCRIPT GeV−1superscriptGeV1{\rm GeV}^{-1}roman_GeV start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT for the ALP mass of ∼4×10−7⁢eVsimilar-toabsent4superscript107eV\sim 4\times 10^{-7}~{}\mathrm{eV}∼ 4 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT roman_eV at the 95% C.L.
By combing the observations of the Crab Nebula from LHAASO and other experiments, we find that the ALP-photon coupling could be set to be about 7.2×10−117.2superscript10117.2\times 10^{-11}7.2 × 10 start_POSTSUPERSCRIPT - 11 end_POSTSUPERSCRIPT GeV−1superscriptGeV1{\rm GeV}^{-1}roman_GeV start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT
for the ALP mass ∼4×10−7⁢eVsimilar-toabsent4superscript107eV\sim 4\times 10^{-7}~{}\mathrm{eV}∼ 4 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT roman_eV , which is in close proximity to the CAST constraint.",[],['China']
"Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets.",['text augmentation data augmentation mask filling language modeling'],[]
,[],[]
,[],[]
"Inference on overall ranking of a set of entities, such as chess players, subpopulations or hospitals, is an important problem. Estimation of ranks based on point estimates of means does not account for the uncertainty in those estimates. Treating estimated ranks without regard for uncertainty is problematic. We propose a Bayesian solution. It is competitive with recent frequentist methods, and more effective and informative, and is as easy to implement as it is to compute the posterior means and variances of the entity means. Using credible sets, we created novel credible distributions for the rank vector of the entities. We evaluate the Bayesian procedure in terms of accuracy and stability in two applications and a simulation study. Frequentist approaches cannot take account of covariates, but the Bayesian method handles them easily.",[],[]
"Let T𝑇Titalic_T be a satellite knot, link, or spatial graph in a 3-manifold M𝑀Mitalic_M that is either S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT or a lens space. Let 𝔟0subscript𝔟0\mathfrak{b}_{0}fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and 𝔟1subscript𝔟1\mathfrak{b}_{1}fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT denote genus 0 and genus 1 bridge number, respectively. Suppose that T𝑇Titalic_T has a companion knot K𝐾Kitalic_K and wrapping number ω𝜔\omegaitalic_ω with respect to K𝐾Kitalic_K. When K𝐾Kitalic_K is not a torus knot, we show that 𝔟1⁢(T)≥ω⁢𝔟1⁢(K)subscript𝔟1𝑇𝜔subscript𝔟1𝐾\mathfrak{b}_{1}(T)\geq\omega\mathfrak{b}_{1}(K)fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_T ) ≥ italic_ω fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_K ). There are previously known counter-examples if K𝐾Kitalic_K is a torus knot. Along the way, we generalize and give a new proof of Schubert’s result that 𝔟0⁢(T)≥ω⁢𝔟0⁢(K)subscript𝔟0𝑇𝜔subscript𝔟0𝐾\mathfrak{b}_{0}(T)\geq\omega\mathfrak{b}_{0}(K)fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_T ) ≥ italic_ω fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_K ). We also prove versions of the theorem applicable to when T𝑇Titalic_T is a “lensed satellite” or when there is a torus separating components of T𝑇Titalic_T.",[],[]
"Controlling complex dynamical systems is generally associated with minimizing certain control objectives with known dynamics under the variational calculus framework. For systems with unknown dynamics, an additional step of dynamics modeling is required. However, any inaccuracy in dynamics modeling will lead to sub-optimality in the resulting control function. Another set of approaches for controlling unknown dynamical systems - reinforcement learning, folds the dynamics modeling into controller training via value function approximation or policy gradient through extensively interacting with the environment, but it suffers from low data efficiency. To address these, we introduce NODEC, a novel framework for controlling unknown dynamical systems, which combines dynamics modelling and controller training using a coupled neural ODE model. Through an intriguing interplay between the two coupled neural networks, NODEC learns system dynamics as well as optimal controls that guides the unknown dynamical system towards target states. Our experiments demonstrate the effectiveness and data efficiency of NODEC for learning optimal control of unknown dynamical systems.",[],[]
"Photodissociated gas bears the signature of the dynamical evolution of the
ambient interstellar medium impacted by the mechanical and radiative feedback
from an expanding H ii region. Here we present an analysis of the kinematics of
the young Trifid nebula, based on velocity-resolved observations of the far-infrared fine-structure lines of [C ii] at 158 µm and [O i] at 63 µm. The distribution of the photodissociated regions (PDRs) surrounding the nebula is consistent with a shell-like structure created by the H ii region expanding with a velocity of 5 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. Comparison of ratios of [C ii] and [O i]63 µm intensities for identical velocity components with PDR models indicate a density of 1044{}^{4}start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT. The red- and blue-shifted PDR shells with a combined mass of 516 M⊙subscriptMdirect-product\mathrm{M}_{\odot}roman_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT have a kinetic energy of ∼1047similar-toabsentsuperscript1047\sim 10^{47}∼ 10 start_POSTSUPERSCRIPT 47 end_POSTSUPERSCRIPT erg. This is consistent with the thermal energy of the H ii region as well as with the energy deposited by the stellar wind luminosity from HD 169442A, an O7 V star, over the 0.5 Myr lifetime of the star. The observed momentum of the PDR shell is lower than what theoretical calculations predict for the radial momentum due to the shell being swept up by an expanding H ii region, which suggests that significant mass loss has occurred in M20 due to the dispersal of the surrounding gas by the advancing ionization front.","['ISM: clouds –', 'ISM: kinematics and dynamics – submillimetre:', 'ISM –', 'ISM: structure\n– stars: formation –', 'ISM:individual (M20)']",['India']
"Over the past century, an intense debate in statistical mechanics has been about the correctness of Boltzmann’s surface entropy versus Gibbs’ volume entropy, for isolated systems. Both entropies make significantly different predictions for systems with few degrees of freedom. Even in the thermodynamic limit, they can disagree—while Boltzmann entropy allows negative absolute temperatures to exist, Gibbs entropy precludes such a possibility. Here, we show that modifying Boltzmann’s entropy via a relative energy tolerance eliminates thermodynamic inconsistencies in several model systems with unbounded energy spectra by ensuring positive, finite temperatures. Concomitantly, the proposed entropy allows for negative temperatures in systems with bounded spectra and closely matches canonical ensemble predictions. This work conclusively remedies the prevalent deficiencies of the Gibbs and Boltzmann entropy formulations and paves the way for the use of the modified Boltzmann entropy in the microcanonical ensemble, allowing negative temperatures to exist.",[],['India']
"Visible-infrared person re-identification (VI-ReID) is challenging due to the significant cross-modality discrepancies between visible and infrared images.
While existing methods have focused on designing complex network architectures or using metric learning constraints to learn modality-invariant features, they often overlook which specific component of the image causes the modality discrepancy problem.
In this paper, we first reveal that the difference in the amplitude component of visible and infrared images is the primary factor that causes the modality discrepancy and further propose a novel Frequency Domain modality-invariant feature learning framework (FDMNet) to reduce modality discrepancy from the frequency domain perspective.
Our framework introduces two novel modules, namely the Instance-Adaptive Amplitude Filter (IAF) module and the Phrase-Preserving Normalization (PPNorm) module, to enhance the modality-invariant amplitude component and suppress the modality-specific component at both the image- and feature-levels.
Extensive experimental results on two standard benchmarks, SYSU-MM01 and RegDB, demonstrate the superior performance of our FDMNet against state-of-the-art methods.",[],[]
"This paper reviews (and expands) some recent results on the modeling of aggregation-diffusion phenomena at various scales, focusing on the emergence of collective dynamics as a result of the competition between attractive and repulsive phenomena - especially (but not exclusively) in the context of attractive chemotaxis phenomena.
At microscopic scales, particles (or other agents) are represented by spheres of radius δ>0𝛿0\delta>0italic_δ > 0 and we discuss both soft-sphere models (with a pressure term penalizing the overlap of the particles) and hard-sphere models (in which overlap is prohibited). The first case leads to so-called “blob models” which have received some attention recently as a tool to approximate non-linear diffusion by particle systems. The hard-sphere model
is similar to a classical model for congested crowd motion.
We will review well-posedness results for these models and discuss their relationship to classical continuum description of aggregation-diffusion phenomena in the limit δ→0→𝛿0\delta\to 0italic_δ → 0: the classical nonlinear drift diffusion equation and its incompressible counterpart.
In the second part of the paper, we discuss recent results on the emergence and evolution of sharp interfaces when a large population of particles is considered at appropriate space and time scales:
At some intermediate time scale, phase separation occurs and a sharp interface appears which evolves according to a Stefan free boundary problem (and the density function eventually relaxes to a characteristic function - metastable steady state for the original problem). At a larger time scale the attractive forces lead to surface tension phenomena and the evolution of the sharp interface can be described by a Hele-Shaw free boundary problem with surface tension. At that same time scale, we will also discuss the emergence of contact angle conditions for problems set in bounded domains.",[],[]
"A fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. Such problems are traditionally modeled as non-stationary Markov decision processes (NSMDP). However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts “safely” to account for the non-stationary evolution of the environment. We argue that both these assumptions are invalid in practice—updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. We present a heuristic search algorithm called Adaptive Monte Carlo Tree Search (ADA-MCTS) that addresses these challenges. We show that the agent can learn the updated dynamics of the environment over time and then act as it learns, i.e., if the agent is in a region of the state space about which it has updated knowledge, it can avoid being pessimistic. To quantify “updated knowledge,” we disintegrate the aleatoric and epistemic uncertainty in the agent’s updated belief and show how the agent can use these estimates for decision-making. We compare the proposed approach with the multiple state-of-the-art approaches in decision-making across multiple well-established open-source problems and empirically show that our approach is faster and highly adaptive without sacrificing safety.",[],[]
"Nonnegative tensor factorization (NTF) has become an important tool for feature extraction and part-based representation with preserved intrinsic structure information from nonnegative high-order data.
However, the original NTF methods utilize Euclidean or Kullback-Leibler divergence as the loss function which treats each feature equally leading to the neglect of the side-information of features.
To utilize correlation information of features and manifold information of samples, we introduce Wasserstein manifold nonnegative tensor factorization (WMNTF), which minimizes the Wasserstein distance between the distribution of input tensorial data and the distribution of reconstruction.
Although some researches about Wasserstein distance have been proposed in nonnegative matrix factorization (NMF), they ignore the spatial structure information of higher-order data.
We use Wasserstein distance (a.k.a. Earth Mover’s distance or Optimal Transport distance) as a metric and add a graph regularizer to a latent factor.
Experimental results demonstrate the effectiveness of the proposed method compared with other NMF and NTF methods.",[],[]
"Using large training datasets enhances the generalization capabilities of neural networks.
Semi-supervised learning (SSL) is useful when there are few labeled data and a lot of unlabeled data.
SSL methods that use data augmentation are most successful for image datasets.
In contrast, texts do not have consistent augmentation methods as images.
Consequently, methods that use augmentation are not as effective in text data as they are in image data.
In this study, we compared SSL algorithms that do not require augmentation; these are self-training, co-training, tri-training, and tri-training with disagreement.
In the experiments, we used 4 different text datasets for different tasks.
We examined the algorithms from a variety of perspectives by asking experiment questions and suggested several improvements.
Among the algorithms, tri-training with disagreement showed the closest performance to the Oracle; however, performance gap shows that new semi-supervised algorithms or improvements in existing methods are needed.","['semi supervised learning', 'self-training', 'co-training', 'tri-training', 'tri-training with disagreement']",[]
"The crystallographic restriction theorem constrains two-dimensional
nematicity to display either Ising (Z2subscript𝑍2Z_{2}italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) or three-state-Potts
(Z3subscript𝑍3Z_{3}italic_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) critical behaviors, both of which are dominated by amplitude
fluctuations. Here, we use group theory and microscopic modeling to
show that this constraint is circumvented in a 30∘superscript3030^{\circ}30 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT-twisted
hexagonal bilayer due to its emergent quasicrystalline symmetries.
We find a critical phase dominated by phase fluctuations of a Z6subscript𝑍6Z_{6}italic_Z start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT
nematic order parameter and bounded by two Berezinskii-Kosterlitz-Thouless
(BKT) transitions, which displays only quasi-long-range nematic order.
The electronic spectrum in the critical phase displays a thermal pseudogap-like
behavior, whose properties depend on the anomalous critical exponent.
We also show that an out-of-plane magnetic field induces nematic phase
fluctuations that suppress the two BKT transitions via a mechanism
analogous to the Hall viscoelastic response of the lattice, giving
rise to a putative nematic quantum critical point with emergent continuous
symmetry. Finally, we demonstrate that even in the case of an untwisted
bilayer, a critical phase emerges when the nematic order parameter
changes sign between the two layers, establishing an odd-parity nematic
state.",[],[]
"Hille’s theorem is a powerful classical result in vector measure theory.
It asserts that the application of a closed, unbounded linear operator commutes with strong/Bochner integration of functions taking values in a Banach space.
This note shows that Hille’s theorem also holds in the setting of complete locally convex spaces.
Keywords. Bochner integral ∙∙\bullet∙ closed operator ∙∙\bullet∙ Hille’s theorem ∙∙\bullet∙ locally convex space ∙∙\bullet∙ strong integral ∙∙\bullet∙ unbounded operator
2020 Mathematics Subject Classification. 28B05 ∙∙\bullet∙ 28C20 ∙∙\bullet∙ 46G10",[],[]
"Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.",[],[]
"We provide an exposition of a ‘horizontal’ generalization of Goodman’s surgery operation on (pseudo-)Anosov flows.
This operation is performed by cutting along a specific kind of annulus that is transverse to the flow and regluing with a Dehn twist of the appropriate sign.
We then show that performing horizontal Goodman surgery on a transitive pseudo-Anosov flow yields an almost equivalent flow, i.e. the original flow and the surgered flow are orbit equivalent after drilling out a finite collection of closed orbits.
We obtain some almost equivalence results by applying this theorem on examples of the surgery operation.
Along the way, we also show a structural stability result for pseudo-Anosov flows.",[],[]
"The Global Ecosystem Dynamics Investigation (GEDI) is a spaceborne lidar instrument that collects near-global measurements of forest structure. While expansive in scope, GEDI samples are spatially sparse and cover a small fraction of the land surface. Converting the sparse samples into spatially complete predictive maps is of practical importance for a number of ecological studies. A complicating factor is that GEDI collects measurements over forested and non-forested land alike, with no automatic labeling of the land type. Such classification is important, as it categorically influences the probability distribution of the spatial process and the ecological interpretation of the observations/predictions. We propose and implement a spatial mixture model, separating the observations and the greater spatial domain into two latent classes. The latent classes are governed by a Bernoulli spatial process, with spatial effects driven by a Gaussian process. Within each class, the process is governed by a separate spatial model, describing the unique probabilistic attributes. Model predictions take the form of scalar predictions of the GEDI observables as well as discrete labeling of the class membership. Inference is conducted through a Bayesian paradigm, yielding rich quantification of prediction and uncertainty through posterior predictive distributions. We demonstrate the method using GEDI data over Wollemi National Park, Australia, using optical data from Landsat 8 as model covariates. When compared to a single spatial model, the mixture model achieves much higher posterior predictive densities on the true value. When compared to a random forest model, a common algorithmic approach in the remote sensing community, the random forest achieves better absolute prediction accuracy for prediction locations far from observed training data locations, but at the expense of location-specific assessments of uncertainty. The unsupervised binary classifications of the mixture model appear broadly ecologically interpretable as forest and non-forest when compared to optical imagery, but further comparison to ground-truth data is required.",[],[]
"In designing external validation studies of clinical prediction models,
contemporary sample size calculation methods are based on the
frequentist inferential paradigm. One of the widely reported metrics of
model performance is net benefit (NB), and the relevance of conventional
inference around NB as a measure of clinical utility is doubtful. Value
of Information methodology quantifies the consequences of uncertainty in
terms of its impact on clinical utility of decisions. We introduce the
expected value of sample information (EVSI) for validation as the
expected gain in NB from conducting an external validation study of a
given size. We propose algorithms for EVSI computation, and in a case
study demonstrate how EVSI changes as a function of the amount of
current information and future study’s sample size. Value of Information
methodology provides a decision-theoretic lens to the process of
planning a validation study of a risk prediction model and can
complement conventional methods when designing such studies.",[],[]
"We investigate the impact of confinement density (i.e the number of individuals in a group per unit area of available space) on transitions from polarized to milling state, using groups of rummy-nose tetrafish (Hemigrammus rhodostomus) under controlled experimental conditions. We demonstrate for the first time a continuous state transition controlled by confinement density in a group of live animals. During this transition, the school exhibits a bistable state, wherein both polarization and milling states coexist, with the group randomly alternating between them. A simple two-state Markov process describes the observed transition remarkably
well. Importantly, the confinement density influences the statistics of this bistability, shaping the distribution of transition times between states. Our findings suggest that confinement plays a crucial role in state transitions for moving animal groups, and, more generally, they constitute a solid experimental benchmark for active matter models of macroscopic, self-propelled, confined agents.",[],['France']
"This work examines the effects of variations in machine learning training regimes and learning paradigms on the corresponding energy consumption.
While increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also supports the fading perception of energy consumption and carbon emission.
Therefore, the goal of this work is to create awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. Multiple setups with different hyperparameter initializations are evaluated on two different hardware configurations to obtain meaningful results.
Experiments on pretraining and multitask training are conducted on top of the baseline results to determine their potential towards sustainable machine learning.",[],[]
,[],[]
"We use the VERITAS imaging air Cherenkov Telescope (IACT) array to obtain the first measured angular diameter of β𝛽\betaitalic_β UMa at visual wavelengths using stellar intensity interferometry (SII) and independently constrain the limb-darkened angular diameter.
The age of the Ursa Major moving group has been assessed from the ages of its members, including nuclear member Merak (β𝛽\betaitalic_β UMa), an A1-type subgiant, by comparing effective temperature and luminosity constraints to model stellar evolution tracks.
Previous interferometric limb-darkened angular-diameter measurements of β𝛽\betaitalic_β UMa in the near-infrared (CHARA Array, 1.149 ±plus-or-minus\pm± 0.014 mas) and mid-infrared (Keck Nuller, 1.08 ±plus-or-minus\pm± 0.07 mas), together with the measured parallax and bolometric flux, have constrained the effective temperature.
This paper presents current VERITAS-SII observation and analysis procedures to derive squared visibilities from correlation functions.
We fit the resulting squared visibilities to find a limb-darkened angular diameter of 1.07±0.04⁢(stat)±0.05plus-or-minus1.070.04stat0.051.07\pm 0.04{\rm~{}(stat)}\pm 0.051.07 ± 0.04 ( roman_stat ) ± 0.05 (sys) mas, using synthetic visibilities from a stellar atmosphere model that provides a good match to the spectrum of β𝛽\betaitalic_β UMa in the optical wave band. The VERITAS-SII limb-darkened angular diameter yields an effective temperature of 9700±200±200plus-or-minus97002002009700\pm 200\pm 2009700 ± 200 ± 200 K,
consistent with ultraviolet spectrophotometry, and an age of 390±29±32plus-or-minus3902932390\pm 29\pm 32390 ± 29 ± 32 Myr, using MESA Isochrones and Stellar Tracks (MIST). This age is consistent with 408 ±plus-or-minus\pm± 6 Myr from the CHARA Array angular diameter.","['Long baseline interferometry (932)', 'Fundamental parameters of stars (555)', 'Astronomy data modeling (1859)']","['Germany', 'France', 'Canada', 'Ireland']"
"As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those languages.
Finally, we find that increasing the number of languages in the instruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual generalization. Our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses.",[],[]
"Density estimation, a central problem in machine learning, can be performed using Normalizing Flows (NFs). NFs comprise a sequence of invertible transformations, that turn a complex target distribution into a simple one, by exploiting the change of variables theorem.
Neural Autoregressive Flows (NAFs) and Block Neural Autoregressive Flows (B-NAFs) are arguably the most perfomant members of the NF family. However, they suffer scalability issues and training instability due to the constraints imposed on the network structure.
In this paper, we propose a novel solution to these challenges by exploiting transformers to define a new class of neural flows called Transformer Neural Autoregressive Flows (T-NAFs). T-NAFs treat each dimension of a random variable as a separate input token, using attention masking to enforce an autoregressive constraint. We take an amortization-inspired approach where the transformer outputs the parameters of an invertible transformation. The experimental results demonstrate that T-NAFs consistently match or outperform NAFs and B-NAFs across multiple datasets from the UCI benchmark. Remarkably, T-NAFs achieve these results using an order of magnitude fewer parameters than previous approaches, without composing multiple flows.",[],[]
"We numerically address the issue of which monopole operators are
relevant under renormalization group flow in three-dimensional
parity-invariant noncompact QED with 4444 flavors of massless
two-component Dirac fermion. Using lattice simulation and finite-size
scaling analysis of the free energy to introduce monopole-antimonopole
pairs in N=4𝑁4N=4italic_N = 4 and N=12𝑁12N=12italic_N = 12 flavor noncompact QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, we estimate
the infrared scaling dimensions of monopole operators that introduce
2⁢π2𝜋2\pi2 italic_π and 4⁢π4𝜋4\pi4 italic_π fluxes around them. We first show that the
estimates for the monopole scaling dimensions are consistent with
the large-N𝑁Nitalic_N expectations for N=12𝑁12N=12italic_N = 12 QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. Applying the same
procedure in N=4𝑁4N=4italic_N = 4 QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, we estimate the scaling dimension of
4⁢π4𝜋4\pi4 italic_π flux monopole operator to be 3.7⁢(3)3.733.7(3)3.7 ( 3 ), which allows the
possibility of the operator being irrelevant. This finding offers
support to the scenario in which higher-flux monopoles are irrelevant
deformations to the Dirac spin liquid phase that could be realized
on certain non-bipartite lattices by forbidding 2⁢π2𝜋2\pi2 italic_π-flux monopoles.",[],[]
"We consider the problem of designing contextual bandit algorithms in the “cross-learning” setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of O~⁢(T⁢K)~𝑂𝑇𝐾\widetilde{O}(\sqrt{TK})over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_T italic_K end_ARG ), independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.
At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between estimation of the unknown distribution and the actions played by the algorithm. This technique may be of independent interest for other learning problems involving estimation of an unknown context distribution.",[],[]
"This paper presents a new synthetic dataset of ID and travel documents, called SIDTD.
The SIDTD dataset is created to help training and evaluating forged ID documents detection systems.
Such a dataset has become a necessity as ID documents contain personal information and a public dataset of real documents can not be released.
Moreover, forged documents are scarce, compared to legit ones, and the way they are generated varies from one fraudster to another resulting in a class of high intra-variability.
In this paper we trained state-of-the-art models on this dataset and we compare them to the performance achieved in larger, but private, datasets.
The creation of this dataset will help to document image analysis community to progress in the task of ID document verification.",[],[]
,[],[]
"We study orbits of semigroups of SL⁢(2,ℤ)SL2ℤ\text{SL}(2,\mathbb{Z})SL ( 2 , blackboard_Z ), and demonstrate reciprocity obstructions: we show that certain such orbits avoid squares, but not as a consequence of such obstructions on the Zariski closure, and not as a consequence of congruence obstructions. This is in analogy to the reciprocity obstructions recently used to disprove the Apollonian local-global conjecture. We give an example of such an orbit which is known exactly, and misses all squares together with an explicit finite list of sporadic values: the corresponding semigroup is not thin, but its Zariski closure does not miss squares. We also demonstrate thin semigroups with reciprocity obstructions, including semigroups associated to continued fractions formed from finite alphabets. Zaremba’s conjecture states that for continued fractions with coefficients chosen from {1,…,5}1…5\{1,\ldots,5\}{ 1 , … , 5 }, every positive integer appears as a denominator. Bourgain and Kontorovich proposed a generalization of Zaremba’s conjecture in the context of semigroups associated to finite alphabets. We disprove their conjecture. In particular, we demonstrate classes of finite continued fraction expansions which never represent rationals with square denominator, but not as a consequence of congruence obstructions, and for which the limit set has Hausdorff dimension exceeding 1/2121/21 / 2. An example of such a class is continued fractions of the form [0;a1,a2,…,an,1,1,2]0subscript𝑎1subscript𝑎2…subscript𝑎𝑛112[0;a_{1},a_{2},\ldots,a_{n},1,1,2][ 0 ; italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , 1 , 1 , 2 ], where the aisubscript𝑎𝑖a_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are chosen from the set {4,8,12,…,128}4812…128\{4,8,12,\ldots,128\}{ 4 , 8 , 12 , … , 128 }. The object at the heart of these results is a semigroup Ψ⊆Γ1⁢(4)ΨsubscriptΓ14\Psi\subseteq\Gamma_{1}(4)roman_Ψ ⊆ roman_Γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 4 ) which preserves Kronecker symbols.","['Thin semigroup', 'thin group', 'reciprocity obstruction', 'continued fraction', 'Zaremba’s conjecture', 'local-global conjecture', 'Hausdorff dimension']",[]
"A nonlocal model of peridynamic type for dynamic brittle damage is introduced consisting of two phases, one elastic and the other inelastic. Evolution from the elastic to the inelastic phase depends on material strength.
Existence and uniqueness of the displacement-failure set pair
follow from the initial value problem. The displacement-failure pair satisfies energy balance. The length scale of nonlocality ϵitalic-ϵ\epsilonitalic_ϵ is taken to be small relative to the domain in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, d=2,3𝑑23d=2,3italic_d = 2 , 3. The new nonlocal model delivers a two point strain dynamics on a subset of ℝd×ℝdsuperscriptℝ𝑑superscriptℝ𝑑\mathbb{R}^{d}\times\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. This dynamics provides an energy that interpolates between volume energy corresponding to elastic behavior and surface energy corresponding to failure.
The deformation energy resulting in material failure over a region R𝑅Ritalic_R is given by a d−1𝑑1d-1italic_d - 1 dimensional integral that is uniformly bounded as ϵ→0→italic-ϵ0\epsilon\rightarrow 0italic_ϵ → 0. For fixed ϵitalic-ϵ\epsilonitalic_ϵ, this energy is nonzero for d−1𝑑1d-1italic_d - 1 dimensional regions R𝑅Ritalic_R associated with flat crack surfaces. The failure energy is the Griffith fracture energy for a given crack R𝑅Ritalic_R in terms of its area for d=3𝑑3d=3italic_d = 3 (or length for d=2𝑑2d=2italic_d = 2). This energy follows directly from the nonlocal model without sending ϵitalic-ϵ\epsilonitalic_ϵ to zero.
Simulations illustrate fracture evolution through generation of an internal traction free boundary as a wake left behind a moving strain concentration. Crack paths are seen to follow a maximal strain energy density criterion.",[],[]
"What does learning to model relationships between strings teach Large Language Models about the visual world?
We systematically evaluate LLMs’ abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text. As language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study. Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world. Furthermore, experiments on self-supervised visual representation learning, utilizing images generated with text models, highlight the potential to train vision models capable of making semantic assessments of natural images using just LLMs.
††footnotetext: Project page: https://vision-checkup.github.io/",[],[]
"It is a well-known fact that the category 𝖢𝖺𝗍⁢(𝐂)𝖢𝖺𝗍𝐂\mathsf{Cat}(\bf{C})sansserif_Cat ( bold_C ) of internal categories
in a category 𝐂𝐂\bf{C}bold_C has a description in terms of crossed modules, when
𝐂=𝐆𝐫𝐂𝐆𝐫\bf{C}=\bf{Gr}bold_C = bold_Gr is the category of groups. The proof of this result heavily uses
the fact that any split epimorphism decomposes as a semi-direct product. An
equivalent statement does not hold in the category 𝐌𝐨𝐧𝐌𝐨𝐧\bf{Mon}bold_Mon of monoids. In a
previous work on quadratic algebras, [3] I constructed an internal
category in the category of monoids, see Section 6. Based on this
construction, this paper will introduce the notion of a crossed semi-bimodule
and show that it gives rise to an object in 𝖢𝖺𝗍⁢(𝐌𝐨𝐧)𝖢𝖺𝗍𝐌𝐨𝐧\mathsf{Cat}(\bf{Mon})sansserif_Cat ( bold_Mon ). I will also relate
this new notion to the crossed semi-modules introduced earlier by A.
Patchkoria [2].",[],[]
"Utilizing the bounds on primordial magnetic fields (PMFs), their contributions
to secondary gravitational waves (GWs) and the results from the pulsar timing
arrays (PTAs), we arrive at constraints on the epoch of reheating.
We find that the combined spectral density of primary and secondary GWs
(generated by the PMFs) can, in general, be described as a broken power
law with five different indices.
We show that the PMFs that have a blue tilt and satisfy the other observational
constraints can generate secondary GWs of strengths suggested by the PTA data.",[],['India']
"Context: Cybercrime groups, driven by financial and geopolitical motives, launch advanced persistent threat (APT) attacks. The attacks consist of adversarial techniques, which adversaries perform step-by-step by during cyberattacks. Cybersecurity vendors often publish cyber threat intelligence (CTI) reports, referring to the written artifacts on technical and forensic analysis of the techniques used by the malware in APT attacks. To defend organizations, prevalent techniques used by malware in APT attacks and the association among the techniques need to be identified. Objective: The goal of this research is to inform cybersecurity practitioners about how adversaries form cyberattacks through an analysis of adversarial techniques documented in cyberthreat intelligence reports. Dataset: We use 594 adversarial techniques cataloged in MITRE ATT&CK. We systematically construct a set of 667 CTI reports that MITRE ATT&CK used as citations in the descriptions of the cataloged adversarial techniques. Methodology: We analyze the frequency and trend of adversarial techniques, followed by a qualitative analysis of the implementation of techniques. Next, we perform association rule mining to identify pairs of techniques recurring in APT attacks. We then perform qualitative analysis to identify the underlying relations among the techniques in the recurring pairs. Findings: The set of 667 CTI reports documents 10,370 techniques in total, and we identify 19 prevalent techniques accounting for 37.3% of documented techniques. We also identify 425 statistically significant recurring pairs and seven types of relations among the techniques in these pairs. The top three among the seven relationships suggest that techniques used by the malware inter-relate with one another in terms of (a) abusing or affecting the same system assets, (b) executing in sequences, and (c) overlapping in their implementations. We identify that obtaining information on the operating and network system of the victim environment is the most prevalent technique and appears in the highest number of recurring pairs. We identify that spear-phishing is the most prevalent way of initial infection. We also identify three prevalent misuses of system functionalities: macro in office documents, registry in Windows, and task scheduler. We also identify that mimicking legitimate users through compromised credentials is the most prevalent persistence-related technique used by malware. Overall, the study quantifies how adversaries leverage techniques through malware in APT attacks based on publicly reported documents. We advocate organizations prioritize their defense against the identified prevalent techniques and actively hunt for potential malicious intrusion based on the identified pairs of techniques.","['Tactics', 'techniques', 'and procedures', 'ATT&CK', 'APT attacks', 'Multi-stage attacks', 'malware', 'cyber-criminal groups', 'cyber-threat actors', 'TTPs', 'Advanced persistent threats', 'Threat hunting', 'Cyberattack']",[]
,[],[]
"Motivated by the goals of dataset pruning and defect identification, a growing body of methods have been developed to score individual examples within a dataset.
These methods, which we call “example difficulty scores”, are typically used to rank or categorize examples, but the consistency of rankings between different training runs, scoring methods, and model architectures is generally unknown.
To determine how example rankings vary due to these random and controlled effects, we systematically compare different formulations of scores over a range of runs and model architectures.
We find that scores largely share the following traits: they are noisy over individual runs of a model, strongly correlated with a single notion of difficulty, and reveal examples that range from being highly sensitive to insensitive to the inductive biases of certain model architectures. Drawing from statistical genetics, we develop a simple method for fingerprinting model architectures using a few sensitive examples.
These findings guide practitioners in maximizing the consistency of their scores (e.g. by choosing appropriate scoring methods, number of runs, and subsets of examples), and establishes comprehensive baselines for evaluating scores in the future.",[],[]
,[],[]
"We study the problem of learning equivariant neural networks via gradient descent. The incorporation of known symmetries (“equivariance”) into neural nets has empirically improved the performance of learning pipelines, in domains ranging from biology to computer vision. However, a rich yet separate line of learning theoretic research has demonstrated that actually learning shallow, fully-connected (i.e. non-symmetric) networks has exponential complexity in the correlational statistical query (CSQ) model, a framework encompassing gradient descent. In this work, we ask: are known problem symmetries sufficient to alleviate the fundamental hardness of learning neural nets with gradient descent? We answer this question in the negative. In particular, we give lower bounds for shallow graph neural networks, convolutional networks, invariant polynomials, and frame-averaged networks for permutation subgroups, which all scale either superpolynomially or exponentially in the relevant input dimension. Therefore, in spite of the significant inductive bias imparted via symmetry, actually learning the complete classes of functions represented by equivariant neural networks via gradient descent remains hard.",[],[]
,[],[]
"WISE J224607.6–052634.9 (W2246–0526) is a hot dust-obscured galaxy at z𝑧zitalic_z = 4.601, and the most luminous obscured quasar known to date. W2246–0526 harbors a heavily obscured supermassive black hole that is most likely accreting above the Eddington limit. We present observations with the Atacama Large Millimeter/submillimeter Array (ALMA) in seven bands, including band 10, of the brightest far-infrared (FIR) fine-structure emission lines of this galaxy: [OI]63⁢μ⁢m63μm{}_{63\upmu\mathrm{m}}start_FLOATSUBSCRIPT 63 roman_μ roman_m end_FLOATSUBSCRIPT, [OIII]88⁢μ⁢m88μm{}_{88\upmu\mathrm{m}}start_FLOATSUBSCRIPT 88 roman_μ roman_m end_FLOATSUBSCRIPT, [NII]122⁢μ⁢m122μm{}_{122\upmu\mathrm{m}}start_FLOATSUBSCRIPT 122 roman_μ roman_m end_FLOATSUBSCRIPT, [OI]145⁢μ⁢m145μm{}_{145\upmu\mathrm{m}}start_FLOATSUBSCRIPT 145 roman_μ roman_m end_FLOATSUBSCRIPT, [CII]158⁢μ⁢m158μm{}_{158\upmu\mathrm{m}}start_FLOATSUBSCRIPT 158 roman_μ roman_m end_FLOATSUBSCRIPT, [NII]205⁢μ⁢m205μm{}_{205\upmu\mathrm{m}}start_FLOATSUBSCRIPT 205 roman_μ roman_m end_FLOATSUBSCRIPT, [CI]370⁢μ⁢m370μm{}_{370\upmu\mathrm{m}}start_FLOATSUBSCRIPT 370 roman_μ roman_m end_FLOATSUBSCRIPT, and [CI]609⁢μ⁢m609μm{}_{609\upmu\mathrm{m}}start_FLOATSUBSCRIPT 609 roman_μ roman_m end_FLOATSUBSCRIPT. A comparison of the data to a large grid of Cloudy radiative transfer models reveals that a high hydrogen density (nH∼3×103similar-tosubscript𝑛H3superscript103n_{\mathrm{H}}\sim 3\times 10^{3}italic_n start_POSTSUBSCRIPT roman_H end_POSTSUBSCRIPT ∼ 3 × 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT) and extinction (AV∼300similar-tosubscript𝐴V300A_{\mathrm{V}}\sim 300italic_A start_POSTSUBSCRIPT roman_V end_POSTSUBSCRIPT ∼ 300 mag), together with extreme ionization (l⁢o⁢g⁢(U)=−0.5𝑙𝑜𝑔𝑈0.5log(U)=-0.5italic_l italic_o italic_g ( italic_U ) = - 0.5) and a high X-ray to UV ratio (αox≥−0.8subscript𝛼ox0.8\alpha_{\mathrm{ox}}\geq-0.8italic_α start_POSTSUBSCRIPT roman_ox end_POSTSUBSCRIPT ≥ - 0.8) are required to reproduce the observed nuclear line ratios. The values of αoxsubscript𝛼ox\alpha_{\mathrm{ox}}italic_α start_POSTSUBSCRIPT roman_ox end_POSTSUBSCRIPT and U𝑈Uitalic_U are among the largest found in the literature and imply the existence of an X-ray-dominated region (XDR). In fact, this component explains the a priori very surprising non-detection of the [OIII]88⁢μ⁢m88μm{}_{88\upmu\mathrm{m}}start_FLOATSUBSCRIPT 88 roman_μ roman_m end_FLOATSUBSCRIPT emission line, which is actually suppressed, instead of boosted, in XDR environments. Interestingly, the best-fitted model implies higher X-ray emission and lower CO content than what is detected observationally, suggesting the presence of a molecular gas component that should be further obscuring the X-ray emission over larger spatial scales than the central region that is being modeled. These results highlight the need for multiline infrared observations to characterize the multiphase gas in high redshift quasars and, in particular, W2246–0526 serves as an extreme benchmark for comparisons of interstellar medium conditions with other quasar populations at cosmic noon and beyond.","['galaxies:', 'ISM – galaxies: nuclei – galaxies: active galaxies: individual (WISE', 'J2246-0526) – quasars: emission lines']",[]
"International comparisons of hierarchical time series data sets based on survey data, such as annual country-level estimates of school enrollment rates, can suffer from large amounts of missing data due to differing coverage of surveys across countries and across times.
A popular approach to handling missing data in these settings is through multiple imputation, which can be especially effective when there is an auxiliary variable that is strongly predictive of and has a smaller amount of missing data than the variable of interest.
However, standard methods for multiple imputation of hierarchical time series data can perform poorly when the auxiliary variable and the variable of interest are have a nonlinear relationship.
Performance of standard multiple imputation methods can also suffer if the substantive analysis model of interest is uncongenial to the imputation model, which can be a common occurrence for social science data if the imputation phase is conducted independently of the analysis phase.
We propose a Bayesian method for multiple imputation of hierarchical nonlinear time series data that uses a sequential decomposition of the joint distribution and incorporates smoothing splines to account for nonlinear relationships between variables.
We compare the proposed method with existing multiple imputation methods through a simulation study and an application to secondary school enrollment data.
We find that the proposed method can lead to substantial performance increases for estimation of parameters in uncongenial analysis models and for prediction of individual missing values.",[],[]
,[],[]
,[],[]
"On 2022 February 15, an impressive filament eruption was observed off the solar eastern limb from three remote-sensing viewpoints, namely Earth, STEREO-A, and Solar Orbiter. In addition to representing the most-distant observed filament at extreme ultraviolet wavelengths—captured by Solar Orbiter’s field of view extending to above 6 R⊙subscript𝑅direct-productR_{\odot}italic_R start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT—this event was also associated with the release of a fast (∼similar-to\sim∼2200 km⋅⋅\cdot⋅s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT) coronal mass ejection (CME) that was directed towards BepiColombo and Parker Solar Probe. These two probes were separated by 2∘{}^{\circ}start_FLOATSUPERSCRIPT ∘ end_FLOATSUPERSCRIPT in latitude, 4∘{}^{\circ}start_FLOATSUPERSCRIPT ∘ end_FLOATSUPERSCRIPT in longitude, and 0.03 au in radial distance around the time of the CME-driven shock arrival in situ. The relative proximity of the two probes to each other and to the Sun (∼similar-to\sim∼0.35 au) allows us to study the mesoscale structure of CMEs at Mercury’s orbit for the first time. We analyse similarities and differences in the main CME-related structures measured at the two locations, namely the interplanetary shock, the sheath region, and the magnetic ejecta. We find that, despite the separation between the two spacecraft being well within the typical uncertainties associated with determination of CME geometric parameters from remote-sensing observations, the two sets of in-situ measurements display some profound differences that make understanding of the overall 3D CME structure particularly challenging. Finally, we discuss our findings within the context of space weather at Mercury’s distances and in terms of the need to investigate solar transients via spacecraft constellations with small separations, which has been gaining significant attention during recent years.","['Solar filament eruptions (1981)', 'Solar coronal mass ejections (310)', 'Interplanetary magnetic fields (824)', 'Interplanetary shocks (829)']","['Finland', 'Germany', 'Spain', 'Belgium', 'Austria', 'Romania']"
,[],[]
"We present a comprehensive study of hydrodynamic theories for superfluids with dipole symmetry. Taking diffusion as an example, we systematically construct a hydrodynamic framework that incorporates an intrinsic dipole degree of freedom in analogy to spin density in micropolar (spinful) fluids. Subsequently, we study a dipole condensed phase and propose a model that captures the spontaneous breaking of the U⁢(1)𝑈1U(1)italic_U ( 1 ) charge. The theory explains the role of the inverse Higgs constraint for this class of theories, and naturally generates the gapless field.
Next, we introduce finite temperature theory using the Hamiltonian formalism and study the hydrodynamics of ideal fracton superfluids. Finally, we postulate a derivative counting scheme and incorporate dissipative effects using the method of irreversible thermodynamics. We verify the consistency of the dispersion relations and argue that our counting is systematic.",[],[]
,[],[]
"A simple and effective method for the alignment of generative models is the best-of-n𝑛nitalic_n policy, where n𝑛nitalic_n samples are drawn from a base policy, and ranked based on a reward function, and the highest ranking one is selected. A commonly used analytical expression in the literature claims that the KL divergence between the best-of-n𝑛nitalic_n policy and the base policy is equal to log⁡(n)−(n−1)/n.𝑛𝑛1𝑛\log(n)-(n-1)/n.roman_log ( italic_n ) - ( italic_n - 1 ) / italic_n . We disprove the validity of this claim, and show that it is an upper bound on the actual KL divergence. We also explore the tightness of this upper bound in different regimes. Finally, we propose a new estimator for the KL divergence and empirically show that it provides a tight approximation through a few examples.",[],[]
"This work concerns maps of commutative noetherian local rings containing a field of positive characteristic. Given such a map φ𝜑\varphiitalic_φ of finite flat dimension, the results relate homological properties of the relative Frobenius of φ𝜑\varphiitalic_φ to those of the fibers of φ𝜑\varphiitalic_φ. The focus is on the complete intersection property and the Gorenstein property.",[],[]
"Model uncertainty poses a significant challenge to the implementation of safety-critical control systems. With this as motivation, this paper proposes a safe control design approach that guarantees the robustness of nonlinear feedback systems in the presence of matched or unmatched unmodelled system dynamics and external disturbances. Our approach couples control barrier functions (CBFs) with a new uncertainty/disturbance estimator to ensure robust safety against input and state-dependent model uncertainties. We prove upper bounds on the estimator’s error and estimated outputs. We use an uncertainty estimator-based composite feedback control law to adaptively improve robust control performance under hard safety constraints by compensating for the matched uncertainty. Then, we robustify existing CBF constraints with this uncertainty estimate and the estimation error bounds to ensure robust safety via a quadratic program (CBF-QP). We also extend our method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which causes relative degree differences with respect to control input and disturbance.
We assume the relative degree difference is at most one, resulting in a second-order cone (SOC) condition.
The proposed robust HOCBFs method is demonstrated in a simulation of an uncertain elastic actuator control problem.
Finally, the efficacy of our method is experimentally demonstrated on a tracked robot with slope-induced matched and unmatched perturbations.",[],[]
"Let V𝑉Vitalic_V be a set of n𝑛nitalic_n points in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, and suppose that the distance between each pair of points is revealed independently with probability p𝑝pitalic_p. We study when this information is sufficient to reconstruct large subsets of V𝑉Vitalic_V, up to isometry.
Strong results for d=1𝑑1d=1italic_d = 1 have been obtained by Girão, Illingworth, Michel, Powierski, and Scott. In this paper, we investigate higher dimensions, and show that if p>n−2/(d+4)𝑝superscript𝑛2𝑑4p>n^{-2/(d+4)}italic_p > italic_n start_POSTSUPERSCRIPT - 2 / ( italic_d + 4 ) end_POSTSUPERSCRIPT, then we can reconstruct almost all of V𝑉Vitalic_V up to isometry, with high probability. We do this by relating it to a polluted graph bootstrap percolation result, for which we adapt the methods of Balogh, Bollobás, and Morris.",[],[]
"Defending from cyberattacks requires practitioners to operate on high-level adversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattack incidents describe the chain of malicious actions with respect to time. To avoid repeating cyberattack incidents, practitioners must proactively identify and defend against recurring chain of actions - which we refer to as temporal attack patterns. Automatically mining the patterns among actions provides structured and actionable information on the adversary behavior of past cyberattacks. The goal of this paper is to aid security practitioners in prioritizing and proactive defense against cyberattacks by mining temporal attack patterns from cyberthreat intelligence reports. To this end, we propose ChronoCTI, an automated pipeline for mining temporal attack patterns from cyberthreat intelligence (CTI) reports of past cyberattacks. To construct ChronoCTI, we build the ground truth dataset of temporal attack patterns and apply state-of-the-art large language models, natural language processing, and machine learning techniques. We apply ChronoCTI on a set of 713 CTI reports, where we identify 124 temporal attack patterns - which we categorize into nine pattern categories. We identify that the most prevalent pattern category is to trick victim users into executing malicious code to initiate the attack, followed by bypassing the anti-malware system in the victim network. Based on the observed patterns, we advocate organizations to train users about cybersecurity best practices, introduce immutable operating systems with limited functionalities, and enforce multi-user authentications. Moreover, we advocate practitioners to leverage the automated mining capability of ChronoCTI and design countermeasures against the recurring attack patterns.","['Advanced persistent threat', 'Tactics', 'Techniques', 'and', 'Procedures', 'ATT&CK', 'Temporal pattern', 'Cyberthreat intelligence', 'CTI reports', 'Knowledge graph', 'attack graph']",[]
"This paper presents
a concrete and a symbolic rewriting
logic semantics for
parametric time Petri nets with inhibitor arcs (PITPNs), a
flexible model
of timed systems
where
parameters are allowed in firing bounds.
We prove that our semantics is bisimilar to the “standard” semantics
of PITPNs.
This allows us to use
the rewriting logic tool Maude,
combined with SMT solving, to
provide sound and complete formal analyses for PITPNs.
We develop and implement a new general folding
approach for symbolic reachability, so that Maude-with-SMT
reachability analysis
terminates whenever the parametric state-class graph of the PITPN is
finite.
Our work opens up
the possibility of using the many formal analysis capabilities of
Maude—including full LTL model checking, analysis with
user-defined analysis strategies, and even statistical model
checking—for such nets.
We illustrate this by explaining how almost all formal analysis and
parameter synthesis methods
supported by the state-of-the-art PITPN tool
Roméo can be performed using Maude with SMT. In addition, we also support
analysis and parameter
synthesis from parametric initial markings, as well as full
LTL model
checking and analysis with
user-defined execution strategies.
Experiments show that our methods outperform
Roméo in many cases.",[],[]
"We present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction.
Given speech audio, we output multiple possibilities of gestural motion for an individual, including face, body, and hands.
The key behind our method is in combining the benefits of sample diversity from vector quantization with the high-frequency details obtained through diffusion to generate more dynamic, expressive motion.
We visualize the generated motion using highly photorealistic avatars that can express crucial nuances in gestures (e.g. sneers and smirks).
To facilitate this line of research, we introduce a first-of-its-kind multi-view conversational dataset that allows for photorealistic reconstruction.
Experiments show our model generates appropriate and diverse gestures, outperforming both diffusion- and VQ-only methods. Furthermore, our perceptual evaluation highlights the importance of photorealism (vs. meshes) in accurately assessing subtle motion details in conversational gestures.
Code and dataset available on project page.",[],[]
"We extend the Calderón-Zygmund theory for nonlocal equations to
strongly coupled system of linear nonlocal equations ℒAs⁢u=fsubscriptsuperscriptℒ𝑠𝐴𝑢𝑓\mathcal{L}^{s}_{A}u=fcaligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_u = italic_f, where the operator ℒAssubscriptsuperscriptℒ𝑠𝐴\mathcal{L}^{s}_{A}caligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT is formally given by



ℒAs⁢u=∫ℝnA⁢(x,y)|x−y|n+2⁢s⁢(x−y)⊗(x−y)|x−y|2⁢(u⁢(x)−u⁢(y))⁢𝑑y.subscriptsuperscriptℒ𝑠𝐴𝑢subscriptsuperscriptℝ𝑛𝐴𝑥𝑦superscript𝑥𝑦𝑛2𝑠tensor-product𝑥𝑦𝑥𝑦superscript𝑥𝑦2𝑢𝑥𝑢𝑦differential-d𝑦\mathcal{L}^{s}_{A}u=\int_{\mathbb{R}^{n}}\frac{A(x,y)}{|x-y|^{n+2s}}\frac{(x-%
y)\otimes(x-y)}{|x-y|^{2}}(u(x)-u(y))dy.caligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_u = ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT divide start_ARG italic_A ( italic_x , italic_y ) end_ARG start_ARG | italic_x - italic_y | start_POSTSUPERSCRIPT italic_n + 2 italic_s end_POSTSUPERSCRIPT end_ARG divide start_ARG ( italic_x - italic_y ) ⊗ ( italic_x - italic_y ) end_ARG start_ARG | italic_x - italic_y | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ( italic_u ( italic_x ) - italic_u ( italic_y ) ) italic_d italic_y .



For 0<s<10𝑠10<s<10 < italic_s < 1 and A:ℝn×ℝn→ℝ:𝐴→superscriptℝ𝑛superscriptℝ𝑛ℝA:\mathbb{R}^{n}\times\mathbb{R}^{n}\to\mathbb{R}italic_A : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → blackboard_R taken to be symmetric and serving as
a variable coefficient for the operator, the system under consideration is the fractional version of the classical Navier-Lamé linearized elasticity system. The study of the coupled system of nonlocal equations is motivated by its appearance in nonlocal mechanics, primarily in peridynamics. Our regularity result states that if A⁢(⋅,y)𝐴⋅𝑦A(\cdot,y)italic_A ( ⋅ , italic_y ) is uniformly Holder continuous and infx∈ℝnA⁢(x,x)>0subscriptinfimum𝑥superscriptℝ𝑛𝐴𝑥𝑥0\inf_{x\in\mathbb{R}^{n}}A(x,x)>0roman_inf start_POSTSUBSCRIPT italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_A ( italic_x , italic_x ) > 0, then for f∈Ll⁢o⁢cp,𝑓subscriptsuperscript𝐿𝑝𝑙𝑜𝑐f\in L^{p}_{loc},italic_f ∈ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l italic_o italic_c end_POSTSUBSCRIPT , for p≥2𝑝2p\geq 2italic_p ≥ 2, the solution vector u∈Hl⁢o⁢c2⁢s−δ,p𝑢subscriptsuperscript𝐻2𝑠𝛿𝑝𝑙𝑜𝑐u\in H^{2s-\delta,p}_{loc}italic_u ∈ italic_H start_POSTSUPERSCRIPT 2 italic_s - italic_δ , italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l italic_o italic_c end_POSTSUBSCRIPT for some δ∈(0,s)𝛿0𝑠\delta\in(0,s)italic_δ ∈ ( 0 , italic_s ).",[],[]
"Visual odometry estimates the motion of a moving camera based on visual input. Existing methods, mostly focusing on two-view point tracking, often ignore the rich temporal context in the image sequence, thereby overlooking the global motion patterns and providing no assessment of the full trajectory reliability. These shortcomings hinder performance in scenarios with occlusion, dynamic objects, and low-texture areas. To address these challenges, we present the Long-term Effective Any Point Tracking (LEAP) module. LEAP innovatively combines visual, inter-track, and temporal cues with mindfully selected anchors for dynamic track estimation. Moreover, LEAP’s temporal probabilistic formulation integrates distribution updates into a learnable iterative refinement module to reason about point-wise uncertainty. Based on these traits, we develop LEAP-VO, a robust visual odometry system adept at handling occlusions and dynamic scenes. Our mindful integration showcases a novel practice by employing long-term point tracking as the front-end. Extensive experiments demonstrate that the proposed pipeline significantly outperforms existing baselines across various visual odometry benchmarks.",[],[]
"Hot dust in the proximity of AGNs strongly emits in the Near Infrared producing a red excess that, in type 2 sources, can be modeled to measure its temperature. In the era of high spatial-resolution multi-wavelength data, mapping the hot dust around Supermassive Black Holes is important for the efforts to achieve a complete picture of the dust role and distribution around these compact objects.
In this work we propose a methodology to detect the hot dust emission in the proximity of Type 2 AGNs and measure its temperature using K-band spectra (λcsubscript𝜆𝑐\lambda_{c}italic_λ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 2.2 μ𝜇\muitalic_μm).
To achieve this, we have developed NIRDust, a Python package for modeling K-band spectra, estimate the dust temperature and characterize the involved uncertainties. We tested synthetic and real spectra in order to check the performance and suitability of the physical model over different types of data.
Our tests on synthetic spectra demonstrated that the obtained results are influenced by the signal-to-noise ratio (S/N) of the input spectra. However, we accurately characterized the uncertainties, which remained below ∼similar-to\sim∼150 K for an average S/N per pixel exceeding 20. Applying NIRDust to NGC 5128 (Centaurus A), observed with the Gemini South Telescope, we estimated a dust temperature of 662 and 667 K from Flamingos-2 spectra and 697 and 607  K from GNIRS spectra using two different approaches.",[],[]
"Relativistic jets accompany the collapse of massive stars, the merger of compact objects, or the accretion of gas in active galactic nuclei. They carry information about the central engine and generate electromagnetic radiation. No self-consistent simulations have been able to follow these jets from their birth at the black hole scale to the Newtonian dissipation phase, making the inference of central engine property through astronomical observations undetermined. We present the general relativistic moving-mesh framework to achieve the continuity of jet simulations throughout space-time. We implement the general relativistic extension for the moving-mesh relativistic hydrodynamic code-JET, and develop a tetrad formulation to utilize the HLLC Riemann solver in the general relativistic moving mesh code. The new framework is able to trace the radial movement of the relativistic jets from the central region where strong gravity holds all the way to distances of jet dissipation.","['General', 'Relativistic', 'Relativistic jet', 'HLLC']",['Germany']
"For any set S𝑆Sitalic_S, the free magmatic algebra spanned by card⁢(S)card𝑆{\mbox{card}(S)}card ( italic_S ) binary products is the vector space spanned by the set of all planar rooted binary trees with the internal nodes colored by the elements of S𝑆Sitalic_S, graded by the number of leaves of a tree. We show that it has a unique structure of coassociative coalgebra such that the coproduct
satisfies the unital infinitesimal condition with each magmatic product, and prove an analog of Aguiar-Sottile’s formula in this context, describing the coproduct in terms of the Moebius basis for the Tamari order. The last result allows us to compute the subspace of primitive elements of any unital infinitesimal S𝑆Sitalic_S-magmatic bialgebra. As an example, we construct a set of generators of the dual of Pilaud and Pons bialgebra of integer relations and compute an explicit basis of its subspace of primitive elements.","['Magmatic algebras', 'bialgebras', 'Tamari order', 'binary rooted trees']",[]
"As time progresses, the need for more secure applications grows exponentially. The different types of sensitive information that is being transferred virtually has sparked a rise in systems that leverage blockchain. Different sectors are beginning to use this disruptive technology to evaluate the risks and benefits. Sectors like finance, medicine, higher education, and wireless communication have research regarding blockchain. Futhermore, the need for security standards in this area of research is pivotal. In recent past, several attacks on blockchain infrastructures have resulted in hundreds of millions dollars lost and sensitive information compromised. Some of these attacks include DAO attacks, bZx attacks, and Parity Multisignature Wallet Double Attacks which targeted vulnerabilities within smart contracts on the Ethereum network. These attacks exposed the weaknesses of current smart contract development practices which has led to the increase in distrust and adoption of systems that leverage blockchain for its functionality. In this paper, I identify common software vulnerabilities and attacks on blockchain infrastructures, thoroughly detail the smart contract development process and propose a model for ensuring a stronger security standard for future systems leveraging smart contracts. The purpose for proposing a model is to promote trust among end users in the system which is a foundational element for blockchain adoption in the future.","['Smart', 'Contract', 'Blockchain', 'Software', 'Development', 'Cybersecurity']",[]
"We obtain asymptotic formulae for the second discrete moments of the Riemann zeta function over arithmetic progressions 12+i⁢(a⁢n+b)12𝑖𝑎𝑛𝑏\frac{1}{2}+i(an+b)divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_i ( italic_a italic_n + italic_b ).
It reveals noticeable relation between the discrete moments and the continuous moment of the Riemann zeta function.
Especially, when a𝑎aitalic_a is a positive integer, main terms of the formula are equal to those for the continuous mean value.
The proof requires the rational approximation of eπ⁢k/asuperscript𝑒𝜋𝑘𝑎e^{\pi k/a}italic_e start_POSTSUPERSCRIPT italic_π italic_k / italic_a end_POSTSUPERSCRIPT for positive integers k𝑘kitalic_k.","['the', 'Riemann ζ𝜁\\zetaitalic_ζ-function']",[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
"We present the results of an optical link to a corner cube on board a tethered balloon at 300 m altitude including a Tip/Tilt compensation for the balloon tracking. Our experiment measures the carrier phase of a 1542 nm laser, which is the useful signal for frequency comparison of distant clocks. An active phase noise compensation of the carrier is implemented, demonstrating a fractional frequency stability of 8×10−198superscript10198\times 10^{-19}8 × 10 start_POSTSUPERSCRIPT - 19 end_POSTSUPERSCRIPT after 16 s averaging, which slightly (factor ∼similar-to\sim∼ 3) improves on best previous links via an airborne platform. This state-of-the-art result is obtained with a transportable set-up that enables a fast field deployment.",[],['France']
,[],[]
"Interferometers play a crucial role in high-precision displacement measurement such as gravitational-wave detection.
Conventional interferometer designs require accurate laser alignment, including the laser pointing and the waist position, to maintain high interference contrast during motion. Although the corner reflector returns the reflected beam in parallel, there is still a problem of lateral beam shift which reduces the interference contrast. This paper presents a new compact interferometric sensor head design for measuring translations with auto-alignment. It works without laser beam alignment adjustment and maintains high interferometric contrast during arbitrary motion (tilts as well as lateral translation). Automatic alignment of the measuring beam with the reference beam is possible by means of a secondary reflection design with a corner reflector. A 20×10×10⁢mm3201010superscriptmm320\times 10\times 10\,\mathrm{mm}^{3}20 × 10 × 10 roman_mm start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT all-glass quasi-monolithic sensor head is built based on UV adhesive bonding and tested by a piezoelectric (PZT) positioning stage. Our sensor head achieved a displacement sensitivity of 1⁢pm/Hz1/21pmsuperscriptHz121\,\mathrm{pm}/\mathrm{Hz}^{1/2}1 roman_pm / roman_Hz start_POSTSUPERSCRIPT 1 / 2 end_POSTSUPERSCRIPT at 1⁢Hz1Hz{\rm 1\,Hz}1 roman_Hz with a tilt dynamic range over ±200⁢mradplus-or-minus200mrad\pm 200\,\mathrm{mrad}± 200 roman_mrad. This optical design can be widely used for high-precision displacement measurement over a large tilt dynamic range, such as torsion balances and seismometers.",[],['China']
,[],[]
,[],[]
"Background: The established GAseous Detector with GErmanium Tagging (GADGET) detection system is used to measure weak, low-energy β𝛽\betaitalic_β-delayed proton decays. It consists of the gaseous Proton Detector equipped with a MICROMEGAS (MM) readout to detect protons and other charged particles calorimetrically, surrounded by the Segmented Germanium Array (SeGA) for high-resolution detection of prompt γ𝛾\gammaitalic_γ-rays.

Purpose: To upgrade GADGET’s Proton Detector to operate as a compact Time Projection Chamber (TPC) for the detection, 3D imaging and identification of low-energy β𝛽\betaitalic_β-delayed single- and multi-particle emissions mainly of interest to astrophysical studies.

Method: A new high granularity MM board with 1024 pads has been designed, fabricated, installed and tested. A high-density data acquisition system based on Generic Electronics for TPCs (GET) has been installed and optimized to record and process the gas avalanche signals collected on the readout pads. The TPC’s performance has been tested using a 220220{}^{220}start_FLOATSUPERSCRIPT 220 end_FLOATSUPERSCRIPTRn α𝛼\alphaitalic_α-particle source and cosmic-ray muons. In addition, decay events in the TPC have been simulated by adapting the ATTPCROOT data analysis framework. Further, a novel application of 2D convolutional neural networks for GADGET II event classification is introduced. The optimization of data throughput is also addressed.
Results: The GADGET II TPC is capable of detecting and identifying α𝛼\alphaitalic_α-particles, as well as measuring their track direction, range, and energy. The extracted energy resolution of the GADGET II TPC using P10 gas is about 5.4% at 6.288 MeV (220220{}^{220}start_FLOATSUPERSCRIPT 220 end_FLOATSUPERSCRIPTRn α𝛼\alphaitalic_α-events), computed using charge integration. Based on a systematic simulation study, we estimated the detection efficiency of the GADGET II TPC for protons and α𝛼\alphaitalic_α-particles, respectively. It has also been demonstrated that the GADGET II TPC is capable of tracking minimum ionizing particles (i.e. cosmic-ray muons). From these measurements, the electron drift velocity was measured under typical operating conditions. In addition to being one of the first generation of micro pattern gaseous detectors (MPGDs) to utilize a resistive anode applied to low-energy nuclear physics, the GADGET II TPC will also be the first TPC surrounded by a high-efficiency array of high-purity germanium γ𝛾\gammaitalic_γ-ray detectors. 
Conclusions: The TPC of GADGET II has been designed, fabricated and tested, and is ready for operation at the Facility for Rare Isotope Beams (FRIB) for radioactive beam-line experiments.",[],"['Canada', 'Switzerland', 'France', 'Spain', 'Israel']"
,[],[]
,[],[]
"In 1902, Paul Stäckel constructed an analytic function f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) in a neighborhood of the origin, which was transcendental, and with the property that both f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) and its inverse, as well as its derivatives, assumed algebraic values at all algebraic points in this neighborhood. Inspired by this result, Mahler in 1976 questioned the existence of an transcendental entire function f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) such that f⁢(ℚ¯)𝑓¯ℚf(\overline{\mathbb{Q}})italic_f ( over¯ start_ARG blackboard_Q end_ARG ) and f−1⁢(ℚ¯)superscript𝑓1¯ℚf^{-1}(\overline{\mathbb{Q}})italic_f start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( over¯ start_ARG blackboard_Q end_ARG ) are subsets of ℚ¯.¯ℚ\overline{\mathbb{Q}}.over¯ start_ARG blackboard_Q end_ARG . This problem was solved by Marques and Moreira in 2017. As Stäcklel’s result involved derivatives, it is natural to question whether we have an analogous result for transcendental entire functions involving derivatives. In this article, we show that there are an uncountable amount of such functions.","['Mahler', 'Problem', 'transcendental functions', 'arithmetic behavior.']",[]
"Next-generation data networks need to support Tb/s rates. In-phase and quadrature (IQ) modulation combine phase and intensity information to increase the density of encoded data, reduce overall power consumption by minimising the number of channels, and increase noise tolerance. To reduce errors when decoding the received signal, intersymbol interference must be minimised. This is achieved with pure phase modulation, where the phase of the optical signal is controlled without changing its intensity. Phase modulators are characterised by the voltage required to achieve a π𝜋\piitalic_π phase shift Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPT, the device length L, and their product Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL. To reduce power consumption, IQ modulators are needed with<<<1V drive voltages and compact (sub-cm) dimensions, which translate in Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL<<<1Vcm. Si and LiNbO33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT (LN) IQ modulators do not currently meet these requirements, because Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL>>>1Vcm. Here, we report a double single-layer graphene (SLG) Mach-Zehnder modulator (MZM) with pure phase modulation in the transparent regime, where optical losses are minimised and remain constant with increasing voltage. Our device has Vπ⁢L∼similar-tosubscript𝑉𝜋𝐿absentV_{\pi}L\simitalic_V start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT italic_L ∼0.3Vcm, matching state-of-the-art SLG-based MZMs and plasmonic LN MZMs, but with pure phase modulation and low insertion loss (∼similar-to\sim∼5dB), essential for IQ modulation. Our Vπ⁢Lsubscript𝑉𝜋𝐿V_{\pi}Litalic_V start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT italic_L is∼similar-to\sim∼5 times lower than the lowest thin-film LN MZMs, and∼similar-to\sim∼3 times lower than the lowest Si MZMs. This enables devices with complementary metal-oxide semiconductor compatible Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL (<<<1Vcm) and smaller footprint than LN or Si MZMs, improving circuit density and reducing power consumption by one order of magnitude.",[],"['Belgium', 'Italy']"
,[],[]
"In this work we first give a upper bound for the modulus of q𝑞qitalic_q-transcendental
entire functions, then prove certain sums associated with their zeros
are convergent, and derive the asymptotic behaviors of their associated
heat kernels.",['\nq-Transcendental functions heat kernels q𝑞qitalic_q-Bessel functions.'],[]
"In recent years, foundation models (FMs) have solidified their role as cornerstone advancements in the deep learning domain. By extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources [1].
Notably, MedCLIP [2], a vision-language contrastive learning-based medical FM, has been designed using unpaired image-text training. While the medical domain has often adopted unpaired training to amplify data [3], the exploration of potential security concerns linked to this approach hasn’t kept pace with its practical usage. Notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. In this study, we frame this label discrepancy as a backdoor attack problem. We further analyze its impact on medical FMs throughout the FM supply chain. Our evaluation primarily revolves around MedCLIP, emblematic of medical FM employing the unpaired strategy. We begin with an exploration of vulnerabilities in MedCLIP stemming from unpaired image-text matching, termed BadMatch. BadMatch is achieved using a modest set of wrongly labeled data. Subsequently, we disrupt MedCLIP’s contrastive learning through BadDist-assisted BadMatch by introducing a Bad-Distance between the embeddings of clean and poisoned data. Intriguingly, when BadMatch and BadDist are combined, a slight 0.05 percent of misaligned image-text data can yield a staggering 99 percent attack success rate, all the while maintaining MedCLIP’s efficacy on untainted data. Additionally, combined with BadMatch and BadDist, the attacking pipeline consistently fends off backdoor assaults across diverse model designs, datasets, and triggers. Also, our findings reveal that current defense strategies are insufficient in detecting these latent threats in medical FMs’ supply chains. Code and pre-trained models can be found at https://github.com/ubc-tea/Backdoor_Multimodal_Foundation_Model.","['Backdoor', 'Attack', 'Foundation', 'Models', 'Vision-Text', 'Models.', 'Contrastive', 'Learning']",[]
,[],[]
,[],[]
"We consider wave scattering from a system of highly contrasting resonators with time-modulated material parameters. In this setting, the wave equation reduces to a system of coupled Helmholtz equations that models the scattering problem. We consider the one-dimensional setting. In order to understand the energy of the system, we prove a novel higher-order discrete, capacitance matrix approximation of the subwavelength resonant quasifrequencies. Further, we perform numerical experiments to support and illustrate our analytical results and show how periodically time-dependent material parameters affect the scattered wave field.",[],[]
"This study seeks to understand the origins of intermittency in quantities of interest in pool boiling, such as bubble departure diameter and departure time. The intermittency of nucleation site activity due to nonuniform and unsteady near-wall temperatures is well-established; however few mechanistic models have been developed that predict such intermittency. Here we assume a fluctuating pressure field at a nucleation site due to adjacent bubble activity, which acts in combination with convective effects to alter bubble growth depending on the phase of the pressure oscillation with respect to the instant of bubble nucleation. The results suggest that even when a single departure frequency is assumed for nearby bubbles, its effect on the nucleation site being considered is to cause aperiodicity and intermittency in bubble departure quantities. The effects of pressure field phase angle, degree of superheat, and choice of force balance model on the bubble departure quantities are examined. The phase angle of the pressure fluctuation at the instant of bubble nucleation is shown to play a major role in determining bubble departure diameter and growth time. Departure diameter is observed to have a broad distribution over long times of observation, belying the assumption of a unique value. Period doubling of the ebullition cycle is observed for some conditions, a phenomenon documented by other investigators. The effects of dynamic contact angle",[],[]
"We explore the potential of enhancing LLM performance in astronomy-focused question-answering through targeted, continual pre-training. By employing a compact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of astronomy corpus—comprising abstracts, introductions, and conclusions—we achieve notable improvements in specialized topic comprehension. While general LLMs like GPT-4 outperform in broader question-answering scenarios due to superior reasoning capabilities, our findings suggest that continual pre-training with limited resources can still enhance model performance on specialized topics. Additionally, we present an extension of AstroLLaMA: the fine-tuning of the 7B LLaMA model on a domain-specific conversational dataset, culminating in the release of the chat-enabled AstroLLaMA for community use. Comprehensive quantitative benchmarking is currently in progress and will be detailed in an upcoming full paper. The model, AstroLLaMA-Chat, is now available at https://huggingface.co/universeTBD, providing the first open-source conversational AI tool tailored for the astronomy community.",[],"['Spain', 'Australia', 'Switzerland']"
,[],[]
"Striking a balance between precision and efficiency presents a prominent challenge in the bird’s-eye-view (BEV) 3D object detection. Although previous camera-based BEV methods achieved remarkable performance by incorporating long-term temporal information, most of them still face the problem of low efficiency. One potential solution is knowledge distillation. Existing distillation methods only focus on reconstructing spatial features, while overlooking temporal knowledge. To this end, we propose TempDistiller, a Temporal knowledge Distiller, to acquire long-term memory from a teacher detector when provided with a limited number of frames. Specifically, a reconstruction target is formulated by integrating long-term temporal knowledge through self-attention operation applied to the feature of teachers. Subsequently, novel features are generated for masked student features via a generator. Ultimately, we utilize this reconstruction target to reconstruct the student features. In addition, we also explore temporal relational knowledge when inputting full frames for the student model. We verify the effectiveness of the proposed method on the nuScenes benchmark. The experimental results show our method obtain an enhancement of +1.6 mAP and +1.1 NDS compared to the baseline, a speed improvement of approximately 6 FPS after compressing temporal knowledge, and the most accurate velocity estimation.",[],[]
,[],[]
,[],[]
,[],[]
"Visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called “object constancy” across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have a similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. During the inference, latent representations are randomly initialized and iteratively updated by integrating the information in different viewpoints with neural networks. Experiments on several specifically designed synthetic datasets have shown that the proposed method can effectively learn from multiple unspecified viewpoints.","['compositional scene representations', 'object-centric learning', 'unsupervised learning', 'deep generative models', 'variational inference', 'object constancy.']",[]
"Equipped with sensing, networking, and computing capabilities, Internet of Things (IoT) such as smartphones, wearables, smart speakers, and household robots have been seamlessly weaved into our daily lives.
Recent advancements in Generative AI exemplified by GPT, LLaMA, DALL-E, and Stable Difussion hold immense promise to push IoT to the next level. In this article, we share our vision and views on the benefits that Generative AI brings to IoT, and discuss some of the most important applications of Generative AI in IoT-related domains. Fully harnessing Generative AI in IoT is a complex challenge. We identify some of the most critical challenges including high resource demands of the Generative AI models, prompt engineering, on-device inference, offloading, on-device fine-tuning, federated learning, security, as well as development tools and benchmarks, and discuss current gaps as well as promising opportunities on enabling Generative AI for IoT. We hope this article can inspire new research on IoT in the era of Generative AI.","['Internet of', 'Things', 'IoT', 'AIoT', 'Generative', 'AI', 'Large', 'Language', 'Models', 'LLMs', 'Diffusion', 'Models', 'Edge', 'AI']",[]
"We revisit the construction of the Hilbert space of non-relativistic particles moving in three spatial dimensions. This is given by the space of sections of a line bundle that can in general be topologically non-trivial. Such bundles are classified by a set of integers—one for each pair of particles—and arise physically when we describe the interactions of dyons, particles which carry both electric and magnetic charges. The choice of bundle fixes the representation of the Euclidean group carried by the Hilbert space. These representations are shown to recover the ‘pairwise helicity’ formalism recently discussed in the literature.",[],[]
,[],[]
"The second law lies at the heart of thermodynamics, characterizing the convertibility of thermodynamic states by a single quantity, the entropy. A fundamental question in quantum information theory is whether one can formulate an analogous second law characterizing the convertibility of resources for quantum information processing. In 2008, a promising formulation was proposed, where quantum-resource convertibility is characterized by the optimal performance of a variant of another fundamental task in quantum information processing, quantum hypothesis testing. The core of this formulation was to prove a lemma that identifies a quantity indicating the optimal performance of this task—the generalized quantum Stein’s lemma—to seek out a counterpart of the thermodynamic entropy in quantum information processing. However, in 2023, a logical gap was found in the existing proof of the generalized quantum Stein’s lemma, throwing into question once again whether such a formulation is possible at all. In this work, we construct a proof of the generalized quantum Stein’s lemma by developing alternative techniques to circumvent the logical gap of the existing analysis. With our proof, we redeem the formulation of quantum resource theories equipped with the second law as desired. These results affirmatively settle the fundamental question about the possibility of bridging the analogy between thermodynamics and quantum information theory.",[],['Japan']
"We propose a formalism which defines chaos in both quantum and classical systems in an equivalent manner by means of adiabatic transformations. The complexity of adiabatic transformations which preserve classical time-averaged trajectories (quantum eigenstates) in response to Hamiltonian deformations serves as a measure of chaos. This complexity is quantified by the (properly regularized) fidelity susceptibility. Our exposition clearly showcases the common structures underlying quantum and classical chaos and allows us to distinguish integrable, chaotic but non-thermalizing, and ergodic regimes. We apply the fidelity susceptibility to a model of two coupled spins and demonstrate that it successfully predicts the universal onset of chaos, both for finite spin S𝑆Sitalic_S and in the classical limit S→∞→𝑆S\to\inftyitalic_S → ∞. Interestingly, we find that finite S𝑆Sitalic_S effects are anomalously large close to integrability.",[],[]
"In systems with a real Bloch Hamiltonian band nodes can be characterised by a non-Abelian frame-rotation charge. The ability of these band nodes to annihilate pairwise is path dependent, since by braiding nodes in adjacent gaps the sign of their charges can be changed.
Here, we theoretically construct and numerically confirm two concrete methods to experimentally probe these non-Abelian braiding processes and charges in ultracold atomic systems.
We consider a coherent superposition of two bands that can be created by moving atoms through the band singularities at some angle in momentum space. Analyzing the dependency on the frame charges, we demonstrate an interferometry scheme passing through two band nodes, which reveals the relative frame charges and allows for measuring the multi-gap topological invariant. The second method relies on a single wavepacket probing two nodes sequentially, where the frame charges can be determined from the band populations. Our results present a feasible avenue for measuring non-Abelian charges of band nodes and the experimental verification of braiding procedures directly, which can be applied in a variety of settings including the recently discovered anomalous non-Abelian phases arising under periodic driving.",[],[]
"We study the effect of ferromagnetic metals (FM) on the circularly polarized modes of an electromagnetic cavity and show that broken time-reversal symmetry leads to a dichroic response of the cavity modes. With one spin-split band, the Zeeman coupling between the FM electrons and cavity modes leads to an anticrossing for mode frequencies comparable to the spin splitting. However, this is only the case for one of the circularly polarized modes, while the other is unaffected by the FM, allowing for the determination of the spin-splitting of the FM using polarization-dependent transmission experiments. Moreover, we show that for two spin-split bands, also the lifetimes of the cavity modes display a polarization-dependent response. The reduced lifetime of modes of only one polarization could potentially be used to engineer and control circularly polarized cavities.",[],['Norway']
We develop a transfer operator approach for the calculation of Rényi entanglement entropies in arbitrary (i.e. Abelian and non-Abelian) pure lattice gauge theory projected entangled pair states in 2+1 dimensions. It is explicitly shown how the long-range behavior of these quantities gives rise to an entanglement area law in both the thermodynamic limit and in the continuum. We numerically demonstrate the applicability of our method to the ℤ2subscriptℤ2\mathds{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT lattice gauge theory and relate some entanglement properties to the confinement-deconfinement transition therein. It is argued on general grounds that Rényi entanglement entropies do not qualify as a complete probe of confinement or deconfinement properties in comparison to other genuine (nonlocal) observables.,[],[]
"We present new follow-up observations of two ultra-diffuse galaxies (UDGs), part of a total sample of five chosen for their distorted morphologies, suggestive of tidal influence. Using Hubble Space Telescope Advanced Camera for Surveys F555W and F814W imaging, we identify 8±2plus-or-minus828\pm 28 ± 2 globular clusters (GCs) in KUG 0203-Dw1 and 6±2plus-or-minus626\pm 26 ± 2 in KDG 013, abundances that are fairly typical for normal dwarf galaxies of similar stellar mass. Jansky Very Large Array data reveal a clear H i detection of KUG 0203-Dw1 with a gas mass estimate of log⁡MH⁢i/M⊙≲7.4less-than-or-similar-tosubscript𝑀Hisubscript𝑀direct-product7.4\log{M_{\rm{H}\,\rm{\textsc{i}}\ }/M_{\odot}}\lesssim 7.4roman_log italic_M start_POSTSUBSCRIPT roman_H i end_POSTSUBSCRIPT / italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT ≲ 7.4 and evidence of active stripping by the host. H i gas is found near the location of KDG 013 but is likely unrelated to the UDG itself due to the morphology and the numerous gas tails within the host group. Given that these UDGs have GC abundances typical for galaxies at their luminosity, these findings suggest that they likely originated as normal dwarf galaxies that have been subjected to significant stripping and tidal heating, causing them to become more diffuse. These two UDGs complete a sample of five exhibiting tidal features in the Canada-France-Hawaii Telescope Legacy Survey area (CFHTLS; ∼1502similar-toabsentsuperscript1502\sim 150^{2}∼ 150 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT deg), including UDGs with and without UV emission, indicative of recent star formation. Four UDGs in this sample, consistent with dwarfs ‘puffed-up’ by tidal interactions, contrast with an outlier, suggesting a dwarf merger origin. These findings indicate that tidal heating of dwarfs is a viable formation pathway for UDGs.",[],['Canada']
"We developed a tool that measures equivalent widths of various lines in low resolution optical spectra, and it was applied to stellar spectra obtained as part of SDSS-V and LAMOST programs.
These lines, such as Li I which directly indicates stellar youth, or optical H I and Ca II which in emission indicate activity associated with stellar youth, are commonly seen in YSOs.
We observe several notable differences in the properties of these lines between YSOs and the field stars. Using these data, we devise a set of criteria through which it is possible to confirm the youth of stars that have been observed by the ABYSS program, as well as to identify likely young stars that have serendipitously been observed by other programs. We examine the decrement of H lines seen in emission in CTTSs, and estimate the properties of the accretion stream that is responsible for the production of these lines. Finally, we examine the evolution of Li I as a function of age, and characterize the scatter in its abundance that appears to be intrinsic in young M dwarfs.",[],['Chile']
"“Changing-look” Active Galactic Nuclei (CL-AGNs) are challenging our basic ideas about the physics of accretion flows and of circumnuclear gas around supermassive black holes (SMBHs).
Using first-year Sloan Digital Sky Survey V (SDSS-V) repeated spectroscopy of nearly 29,000 previously-known AGNs, combined with dedicated follow-up spectroscopic observations, and publicly available optical light curves, we have identified 116 CL-AGNs where (at least) one broad emission line has essentially (dis-)appeared, as well as 88 other extremely variable systems.
Our CL-AGN sample, with 107 newly identified cases, is among the largest reported to date, and includes ∼0.4%similar-toabsentpercent0.4\sim 0.4\%∼ 0.4 % of the AGNs re-observed in the first year of SDSS-V operations.
Among our CL-AGNs, 67% exhibit dimming while 33% exhibit brightening.
Our data and sample probe extreme AGN spectral variability on timescales of months to decades, including some cases of recurring transitions on surprisingly short timescales (≲2less-than-or-similar-toabsent2\lesssim 2≲ 2 months in the rest frame).
We find that CL events are preferentially found in lower Eddington ratio (fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT) systems: Our CL-AGNs have a fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT distribution that significantly differs from that of a redshift- and a carefully constructed, luminosity-matched control sample (pKS≲2×10−4less-than-or-similar-tosubscript𝑝KS2superscript104p_{\rm KS}\lesssim 2\times 10^{-4}italic_p start_POSTSUBSCRIPT roman_KS end_POSTSUBSCRIPT ≲ 2 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT; median fEdd≈0.025subscript𝑓Edd0.025f_{\mathrm{Edd}}\approx 0.025italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT ≈ 0.025 vs. 0.0430.0430.0430.043).
This preference for low fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT strengthens previous findings of higher CL-AGN incidence at lower Eddington ratios, found in much smaller samples of spectroscopically confirmed CL-AGNs.
Finally, we show that the broad Mg ii emission line in our CL-AGN sample tends to vary significantly less than the broad Hβ𝛽\betaitalic_β emission line.
Our large CL-AGN sample demonstrates the advantages and challenges in using multi-epoch spectroscopy from large surveys to study extreme AGN variability, SMBH fueling, and AGN physics.","['Supermassive black holes (1663)', 'Quasars (1319)', 'Active galactic nuclei (16)']","['Canada', 'Chile', 'Germany', 'China', 'Israel']"
,[],[]
"Detection of redshifted \ionHi 21cm emission is a potential probe for investigating the Universe’s first billion years. However, given the significantly brighter foreground, detecting 21cm is observationally difficult. The Earth’s ionosphere considerably distorts the signal at low frequencies by introducing directional-dependent effects. Here, for the first time, we report the use of Artificial Neural Networks (ANNs) to extract the global 21cm signal characteristics from the composite all-sky averaged signal, including foreground and ionospheric effects such as refraction, absorption, and thermal emission from the ionosphere’s F and D-layers. We assume a ’perfect’ instrument and neglect instrumental calibration and beam effects. To model the ionospheric effect, we considered the static and time-varying ionospheric conditions for the mid-latitude region where LOFAR is situated. In this work, we trained the Artificial Neural Network (ANN) model for various situations using a synthetic set of the global 21cm signals created by altering its parameter space based on the ""tanh\rm\tanhroman_tanh"" parameterized model and the Accelerated Reionization Era Simulations (ARES) algorithm. The obtained result shows that the ANN model can extract the global signal parameters with an accuracy of ≥96%absentpercent96\geq 96\%≥ 96 % in the final study when we include foreground and ionospheric effects. On the other hand, a similar ANN model can extract the signal parameters from the final prediction dataset with an accuracy ranging from 97%percent9797\%97 % to 98%percent9898\%98 % when considering more realistic sets of the global 21cm signals based on physical models.",[],[]
"In dense neutrino gases, the neutrino-neutrino coherent forward scattering gives rise to a complex flavor oscillation phenomenon not fully incorporated in simulations of neutron star mergers (NSM) and core collapse supernovae (CCSNe). Moreover, it has been proposed to be chaotic, potentially limiting our ability to predict neutrino flavor transformations in simulations. To address this issue, we explore how small flavor perturbations evolve within a narrow centimeter-scale region inside a NSM and a toy neutrino distribution. Our findings reveal that paths in the flavor state space of solutions with similar initial conditions diverge exponentially, exhibiting chaos. This inherent chaos makes the microscopic scales of neutrino flavor transformations unpredictable. However, the domain-averaged neutrino density matrix remains relatively stable, with chaos minimally affecting it. This particular property suggests that domain-averaged quantities remain reliable despite the exponential amplification of errors.",[],[]
"The growth of active galactic nuclei (AGN) occurs under some form of obscuration in a large fraction of the population. The difficulty in constraining this population leads to high uncertainties in cosmic X-ray background and galaxy evolution models. Using an SDSS-WISE cross-match, we target infrared luminous AGN (W⁢1−W⁢2𝑊1𝑊2W1-W2italic_W 1 - italic_W 2 > 0.8, and monochromatic rest-frame luminosity above λ⁢Lλ𝜆subscript𝐿𝜆\lambda L_{\lambda}italic_λ italic_L start_POSTSUBSCRIPT italic_λ end_POSTSUBSCRIPT(12 µ⁢mtimes12micrometer12\text{\,}\mathrm{\SIUnitSymbolMicro m}start_ARG 12 end_ARG start_ARG times end_ARG start_ARG roman_µ roman_m end_ARG) ≈\approx≈ 3 ×\times× 104444{}^{44}start_FLOATSUPERSCRIPT 44 end_FLOATSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT), but with passive galaxy-like optical spectra (Optically Quiescent Quasars; OQQs). We find 47 objects that show no significant [O iii]λ𝜆\lambdaitalic_λ5007 emission, a typically strong AGN optical emission line. As a comparison sample, we examine SDSS-selected Type 2 quasars (QSO2s), which show a significant [O iii]λ𝜆\lambdaitalic_λ5007 line by definition. We find a 1:16 ratio of OQQs compared to QSO2s, suggesting that the OQQ duty cycle is likely much shorter than that of QSO2s (though selection biases are not fully quantified). We consider observed properties in comparison with other galaxy types, and examine them for consistency with theories on their intrinsic nature: chiefly (a) a high covering factor for surrounding obscuring matter, preventing the detection of high-ionisation emission lines – ‘cocooned AGN’; or (b) ionised gas being absent on the kpc scales of the Narrow Line Region (NLR), perhaps due to a ‘switching on’ or ‘young’ AGN. OQQs do not obviously fit the standard paradigm for merger-driven AGN and host galaxy evolution, implying we may be missing part of the flow of AGN evolution.",[],[]
"Molecular anisotropy plays an important role in the glass transition of a liquid. Recently, a novel glass state has been discovered by optical microscopy experiments on suspensions of ellipsoidal colloids. ’Liquid glass’ is a disordered analog of a nematic liquid crystal, where rotation motion is hindered but particles diffuse freely. Global nematic order is suppressed as clusters of aligned particles intertwine. We perform Brownian dynamics simulations to test the structure and dynamics of a dense system of soft ellipsoidal particles.
As seen in experiments and in accordance with predictions from mode coupling theory, on the time scale of our simulations rotation motion is frozen but translation motion persists in liquid glass. Analyses of the dynamic structure functions for translation and rotation corroborates the presence of two separate glass transitions for rotation and translation, respectively. Even though the equilibrium state should be a nematic, aligned structures remain small and orientational order rapidly decays with increasing size. Long-wavelength fluctuations are remnants of the isotropic-nematic transition.",[],['Germany']
"Amidst all candidates of physics beyond the Standard Model, string theory provides a unique proposal
for incorporating gauge and gravitational interactions.
In string theory, a four-dimensional theory that unifies quantum mechanics and gravity is obtained automatically if one posits that the additional dimensions predicted by the theory are small and curled up, a concept known as compactification. The gauge sector of the theory is specified by the topology and geometry of the extra dimensions, and the challenge is to reproduce all the features of the Standard Model of Particle Physics from them. We review the state-of-the-art in reproducing the Standard Model from string compactifications, together with the lessons drawn from this fascinating quest. We describe novel scenarios and mechanisms that string theory provides to address some of the Standard Model puzzles, as well as the most frequent signatures of new physics that could be detected in future experiments. We finally comment on recent developments that connect, in a rather unexpected way, the Standard Model with Quantum Gravity, and that may change our field theory notion of naturalness.",[],[]
,[],[]
"We present results for the τ1subscript𝜏1\tau_{1}italic_τ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and τ1⁢asubscript𝜏1𝑎\tau_{1a}italic_τ start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT 1-Jettiness global event shape distributions, for Deep Inelastic Scattering (DIS), at the N33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTLL + 𝒪⁢(αs2)𝒪superscriptsubscript𝛼𝑠2{\cal O}(\alpha_{s}^{2})caligraphic_O ( italic_α start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )
level of accuracy. These event-shape distributions quantify and characterize the pattern of final state radiation in electron-nucleus collisions. They can be used as a probe of nuclear structure functions, nuclear medium effects in jet production, and for a precision extraction of the QCD strong coupling. The results presented here, along with the corresponding numerical codes, can be used for analyses with HERA data, in EIC simulation studies, and for eventual comparison with real EIC data.",[],['China']
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
,[],[]
