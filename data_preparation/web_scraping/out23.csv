abstract,keyword,country
,[''],[]
"Personalized PageRank (PPR) is an extensively studied and applied node proximity measure in graphs.
For a pair of nodes s𝑠sitalic_s and t𝑡titalic_t on a graph G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ), the PPR value π⁢(s,t)𝜋𝑠𝑡\pi(s,t)italic_π ( italic_s , italic_t ) is defined as the probability that an α𝛼\alphaitalic_α-discounted random walk from s𝑠sitalic_s terminates at t𝑡titalic_t, where the walk terminates with probability α𝛼\alphaitalic_α at each step.
We study the classic Single-Source PPR query, which asks for PPR approximations from a given source node s𝑠sitalic_s to all nodes in the graph.
Specifically, we aim to provide approximations with absolute error guarantees, ensuring that the resultant PPR estimates π^⁢(s,t)^𝜋𝑠𝑡\hat{\pi}(s,t)over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) satisfy maxt∈V⁡|π^⁢(s,t)−π⁢(s,t)|≤εsubscript𝑡𝑉^𝜋𝑠𝑡𝜋𝑠𝑡𝜀\max_{t\in V}\big{|}\hat{\pi}(s,t)-\pi(s,t)\big{|}\leq\varepsilonroman_max start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT | over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) - italic_π ( italic_s , italic_t ) | ≤ italic_ε for a given error bound ε𝜀\varepsilonitalic_ε.
We propose an algorithm that achieves this with high probability, with an expected running time of


•

O~⁢(m/ε)~𝑂𝑚𝜀\widetilde{O}\big{(}\sqrt{m}/\varepsilon\big{)}over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_m end_ARG / italic_ε ) for directed graphs333O~⁢(⋅)~𝑂⋅\widetilde{O}(\cdot)over~ start_ARG italic_O end_ARG ( ⋅ ) suppresses polylog⁡(n)polylog𝑛\operatorname{polylog}(n)roman_polylog ( italic_n ) factors., where m=|E|𝑚𝐸m=|E|italic_m = | italic_E |;



•

O~⁢(dmax/ε)~𝑂subscript𝑑𝜀\widetilde{O}\big{(}\sqrt{d_{\max}}/\varepsilon\big{)}over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_d start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT end_ARG / italic_ε ) for undirected graphs, where dmaxsubscript𝑑d_{\max}italic_d start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum node degree in the graph;



•

O~⁢(nγ−1/2/ε)~𝑂superscript𝑛𝛾12𝜀\widetilde{O}\left(n^{\gamma-1/2}/\varepsilon\right)over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT italic_γ - 1 / 2 end_POSTSUPERSCRIPT / italic_ε ) for power-law graphs, where n=|V|𝑛𝑉n=|V|italic_n = | italic_V | and γ∈(12,1)𝛾121\gamma\in\left(\frac{1}{2},1\right)italic_γ ∈ ( divide start_ARG 1 end_ARG start_ARG 2 end_ARG , 1 ) is the extent of the power law.



These sublinear bounds improve upon existing results.
We also study the case when degree-normalized absolute error guarantees are desired, requiring maxt∈V⁡|π^⁢(s,t)/d⁢(t)−π⁢(s,t)/d⁢(t)|≤εdsubscript𝑡𝑉^𝜋𝑠𝑡𝑑𝑡𝜋𝑠𝑡𝑑𝑡subscript𝜀𝑑\max_{t\in V}\big{|}\hat{\pi}(s,t)/d(t)-\pi(s,t)/d(t)\big{|}\leq\varepsilon_{d}roman_max start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT | over^ start_ARG italic_π end_ARG ( italic_s , italic_t ) / italic_d ( italic_t ) - italic_π ( italic_s , italic_t ) / italic_d ( italic_t ) | ≤ italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT for a given error bound εdsubscript𝜀𝑑\varepsilon_{d}italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, where the graph is undirected and d⁢(t)𝑑𝑡d(t)italic_d ( italic_t ) is the degree of node t𝑡titalic_t.
We give an algorithm that provides this error guarantee with high probability, achieving an expected complexity of O~⁢(∑t∈Vπ⁢(s,t)/d⁢(t)/εd)~𝑂subscript𝑡𝑉𝜋𝑠𝑡𝑑𝑡subscript𝜀𝑑\widetilde{O}\left(\sqrt{\sum_{t\in V}\pi(s,t)/d(t)}\big{/}\varepsilon_{d}\right)over~ start_ARG italic_O end_ARG ( square-root start_ARG ∑ start_POSTSUBSCRIPT italic_t ∈ italic_V end_POSTSUBSCRIPT italic_π ( italic_s , italic_t ) / italic_d ( italic_t ) end_ARG / italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ).
This improves over the previously known O⁢(1/εd)𝑂1subscript𝜀𝑑O(1/\varepsilon_{d})italic_O ( 1 / italic_ε start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) complexity.",[''],[]
,[''],[]
,[''],[]
,[''],[]
"Suicide is recognized as one of the most serious concerns in the modern society. Suicide causes tragedy that affects countries, communities, and families. There are many factors that lead to suicidal ideations. Early detection of suicidal ideations can help to prevent suicide occurrence by providing the victim with the required professional support, especially when the victim does not recognize the danger of having suicidal ideations. As technology usage has increased, people share and express their ideations digitally via social media, chatbots, and other digital platforms. In this paper, we proposed a novel, simple deep learning-based model to detect suicidal ideations in digital content, mainly focusing on chatbots as the primary data source. In addition, we provide a framework that employs the proposed suicide detection integration with a chatbot-based support system.","['Index', 'Terms: ', 'Suicide, deep learning, chatbot, natural language processing, detection']","['elsayeny@ucmail.uc.edu', 'elsayezs@ucmail.uc.edu', 'ozermm@ucmail.uc.edu']"
,[''],[]
,[''],[]
,[''],[]
"This work is inspired by Shareshian and Wachs’s exquisite formula for the chromatic symmetric function of paths. We develop a composition method to unearth neat noncommutative analogs of chromatic symmetric functions. A symmetric function is e𝑒eitalic_e-positive if and only if it has a ΛΛ\Lambdaroman_Λ-positive noncommutative analog. We bring to light short and sweet ΛΛ\Lambdaroman_Λ-positive noncommutative analogs for the chromatic symmetric functions of tadpoles and barbells, with cycles and lollipops as specifications. Using these elegant formulas and the composition method, we discover a new family of e𝑒eitalic_e-positive graphs and call them hats, which are the unicyclic graphs obtained by adding an edge to a path. A compact ribbon Schur analog for cycles is also obtained as a by-product.","['Key words and phrases: chromatic symmetric functions,\ne𝑒eitalic_e-positivity,\nnoncommutative symmetric functions,', 'Stanley–Stembridge conjecture,', 'Schur positivity']",[]
"We present the mean star formation histories (SFHs) of 148 dwarf lenticular galaxies (dS0s) derived from SDSS spectra. The SFHs of dS0s are characterized by multiple bursts of star formation, including an initial burst at a lookback time of ∼14similar-toabsent14\sim 14∼ 14 Gyr for most galaxies. Stars formed during the first star-forming phase which ends at a lookback time of 6.3 Gyr primarily consist of old, metal-poor (Z=0.0004) stars , contributing to ∼60%similar-toabsentpercent60\sim 60\%∼ 60 % of the stellar mass and ∼30%similar-toabsentpercent30\sim 30\%∼ 30 % of the luminosity. The almost absence of extremely metal poor (Z=0.0001) stars seems to be due to pre-enrichment during the re-ionization era. Star formation gradually decreases during this initial period. In contrast, during the second period of star formation, there is an increase in star formation activity, peaking at a lookback time of 2.5 Gyr before declining again. Most moderately old stellar populations with intermediate metallicity were formed during this phase. We observe a strong dependence of SFHs on the mass and u-r color of dS0 galaxies but no significant dependence on morphological properties such as the presence or absence of outer spiral arms and nucleation. The star formation history of dS0 galaxies shares many similarities with that of dE galaxies, and many of them are believed to have originated from late-type galaxies.
galaxies.",[''],[]
,[''],[]
"A graph G𝐺Gitalic_G is k𝑘kitalic_k-factor-critical if G−S𝐺𝑆G-Sitalic_G - italic_S has a perfect matching for any
k𝑘kitalic_k-subset S𝑆Sitalic_S of the vertex set of G𝐺Gitalic_G. In this paper, we investigate the factor-criticality of graphs with fixed minimum degree and provide sufficient conditions for such graphs
to be k𝑘kitalic_k-factor-critical in terms of spectral radius and signless Laplacian spectral radius. 

Keywords: factor-critical graph, minimum degree, spectral radius, signless Laplacian spectral radius",[''],[]
"We investigate the quantum phase transition in the alternating XY chain with the XZY+YZX type of three-spin interactions. We present the exact solution derived by means of the Jordan-Wigner transformation and study the average magnetization, spin correlations, and von Neumann entropy to establish the phase diagram. By examining the nearest-neighbor transverse spin correlation, we probe that in the phase with zero magnetization (ZM), the spins within a supercell tend to point to opposite directions of the external field, but between the nearest-neighbor supercells are distributed randomly. This is the reason for the magnetization vanishing in the ZM phase under the alternating hopping interaction. In addition, we also investigate the influence of the three-site interaction, and find that the ZM phase is absent as the strength of the three-site interaction increases. Our findings shed light on the complex behavior of the alternating XY chain and provide valuable insights for future studies.",[''],"['China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
"A new position is introduced and studied for the convolution of log-concave functions, which may be regarded as a functional analogue of the maximum intersection position of convex bodies introduced and studied by Artstein-Avidan and Katzin (2018) and Artstein-Avidan and Putterman (2022). Our main result is a John-type theorem for the maximal intersection position of a pair of log-concave functions, including the corresponding decomposition of the identity. The main result holds under very weak assumptions on the functions; in particular, the functions considered may both have unbounded supports.","['Key words and phrases: \nconvex body, convolution, isotropic,', 'John position, log-concave, maximal intersection position']",[]
"Semantic segmentation models trained on annotated data fail to generalize well when the input data distribution changes over extended time period, leading to requiring re-training to maintain performance. Classic Unsupervised domain adaptation (UDA) attempts to address a similar problem when there is target domain with no annotated data points through transferring knowledge from a source domain with annotated data. We develop an online UDA algorithm for semantic segmentation of images that improves model generalization on unannotated domains in scenarios where source data access is restricted during adaptation. We perform model adaptation is by minimizing the distributional distance between the source latent features and the target features in a shared embedding space. Our solution promotes a shared domain-agnostic latent feature space between the two domains, which allows for classifier generalization on the target dataset. To alleviate the need of access to source samples during adaptation, we approximate the source latent feature distribution via an appropriate surrogate distribution, in this case a Gassian mixture model (GMM). We evaluate our approach on well established semantic segmentation datasets and demonstrate it compares favorably against state-of-the-art (SOTA) UDA semantic segmentation methods.111Partial results of this work were presented in the AAAI Conference Stan and Rostami (2021b).",[''],[]
"The correctness of a compiler affects the correctness of every program written in the language, and thus must be thoroughly evaluated. Existing automatic compiler testing methods however either rely on weak oracles (e.g., a program behaves the same if only dead code is modified), or require substantial initial effort (e.g., having a complete operational language semantics).
While the former prevents a comprehensive correctness evaluation, the latter makes those methods irrelevant in practice.
In this work, we propose an axiomatic semantics based approach for testing compilers, called PTE. The idea is to incrementally develop a set of “axioms” capturing anecdotes of the language semantics in the form of (precondition, transformation, expectation) triples, which allows us to test the compiler automatically. Such axioms are written in the same language whose compiler is under test, and can be developed either based on the language specification, or by generalizing the bug reports. PTE has been applied to a newly developed compiler (i.e., Cangjie) and a mature compiler (i.e., Java), and successfully identified 42 implementation bugs and 9 potential language design issues.","['Compiler testing, language semantics, automated testing']","['UniversitySingaporeSingapore', 'UniversitySingaporeSingapore', 'UniversitySingaporeSingapore', 'UniversityBeijingChina', 'UniversityShanghaiChina']"
"Let BunBun{\operatorname{Bun}}roman_Bun be the moduli stack of rank 2222 bundles with fixed determinant on a smooth proper curve C𝐶Citalic_C over a local field F𝐹Fitalic_F.
We show how to associate with a Schwartz κ𝜅\kappaitalic_κ-density,
for Re⁡(κ)≥1/2Re𝜅12{\operatorname{Re}}(\kappa)\geq 1/2roman_Re ( italic_κ ) ≥ 1 / 2,
a smooth function on the corresponding coarse moduli space of very stable bundles.
In the non-archimedean case we also prove that the stack BunBun{\operatorname{Bun}}roman_Bun is κ𝜅\kappaitalic_κ-bounded in the sense of [4, Def. 2.10] for any κ∈ℂ𝜅ℂ\kappa\in\operatorname{\mathbb{C}}italic_κ ∈ blackboard_C.",[''],[]
"The full array of the Large High Altitude Air Shower Observatory (LHAASO) has been in operation since July 2021. For its kilometer-square array (KM2A), we have optimized the selection criteria for very high and ultra-high energy γ𝛾\gammaitalic_γ-rays, using the data collected from August 2021 to August 2022, resulting in an improvement on significance of about 15%percent\%% compared with previous cuts. With the implementation of these new selection criteria, the angular resolution is also significantly improved by approximately 10%percent\%% at tens of TeV. Other aspects of the full KM2A array performance, such as the pointing error are also calibrated using the Crab Nebula. The resulting energy spectrum of the Crab Nebula in the energy range of 10-1000 TeV can be well fitted by a log-parabola model, which is consistent with the previous results from LHAASO and other experiments.","['γ𝛾\\gammaitalic_γ-ray;', 'Crab', 'Nebula; significance.']","['China', 'China', 'China', 'Ireland', 'Germany', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Switzerland', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'France', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Switzerland', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Russia', 'Russia', 'Russia', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Thailand', 'China', 'China', 'China', 'France', 'China', 'China', 'Thailand', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Thailand', 'Thailand', 'France', 'China', 'China', 'Russia', 'Russia', 'China', 'China', 'China', 'China', 'Russia', 'Russia', 'Russia', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
"The remarkable advancements in artificial intelligence (AI), primarily driven by deep neural networks, have significantly impacted various aspects of our lives. However, the current challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability call for the development of next-generation AI systems. Neuro-symbolic AI (NSAI) emerges as a promising paradigm, fusing neural, symbolic, and probabilistic approaches to enhance interpretability, robustness, and trustworthiness while facilitating learning from much less data. Recent NSAI systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we provide a systematic review of recent progress in NSAI and analyze the performance characteristics and computational operators of NSAI models. Furthermore, we discuss the challenges and potential future directions of NSAI from both system and architectural perspectives.",[''],[]
,[''],[]
"Event-based cameras provide accurate and high temporal resolution measurements for performing computer vision tasks in challenging scenarios, such as high-dynamic range environments and fast-motion maneuvers. Despite their advantages, utilizing deep learning for event-based vision encounters a significant obstacle due to the scarcity of annotated data caused by the relatively recent emergence of event-based cameras. To overcome this limitation, leveraging the knowledge available from annotated data obtained with conventional frame-based cameras presents an effective solution based on unsupervised domain adaptation. We propose a new algorithm tailored for adapting a deep neural network trained on annotated frame-based data to generalize well on event-based unannotated data. Our approach incorporates uncorrelated conditioning and self-supervised learning in an adversarial learning scheme to close the gap between the two source and target domains. By applying self-supervised learning, the algorithm learns to align the representations of event-based data with those from frame-based camera data, thereby facilitating knowledge transfer.
Furthermore, the inclusion of uncorrelated conditioning ensures that the adapted model effectively distinguishes between event-based and conventional data, enhancing its ability to classify event-based images accurately.
Through empirical experimentation and evaluation, we demonstrate that our algorithm surpasses existing approaches designed for the same purpose using two benchmarks. The superior performance of our solution is attributed to its ability to effectively utilize annotated data from frame-based cameras and transfer the acquired knowledge to the event-based vision domain.
111This paper is based on results partially presented at the 2023 International Conference on Computer Vision jian2023unsupervised .",[''],[]
"It has been an unanswered question how many dusty galaxies have been undetected from the state-of-the-art observational surveys. JWST enables us to detect faint IR galaxies that have prominent polycyclic aromatic hydrocarbon (PAH) features in the mid-IR wavelengths. PAH is a valuable tracer of star formation and dust properties in the mid-infrared wavelength. The JWST Cosmic Evolution Early Release Science (CEERS) fields provide us with wavelength coverage from 7.7 to 21 μ𝜇\muitalic_μm using six photometric bands of the mid-infrared instrument (MIRI). We have identified galaxies dominated by mid-IR emission from PAHs, termed PAH galaxies. From our multi-band photometry catalogue, we selected ten PAH galaxies displaying high flux ratios of log⁡(S15/S10)>0.8subscript𝑆15subscript𝑆100.8\log(S_{15}/S_{10})>0.8roman_log ( italic_S start_POSTSUBSCRIPT 15 end_POSTSUBSCRIPT / italic_S start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) > 0.8. The SED fitting analysis indicates that these galaxies are star-forming galaxies with total IR luminosities of 1010superscript101010^{10}10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT ∼similar-to\sim∼ 1011.5superscript1011.510^{11.5}10 start_POSTSUPERSCRIPT 11.5 end_POSTSUPERSCRIPT L⊙subscript𝐿direct-productL_{\odot}italic_L start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT at z ∼1similar-toabsent1\sim 1∼ 1. The morphology of PAH galaxies does not show any clear signatures of major merging or interaction within the MIRI resolution. The majority of them are on the star-formation main sequence at z∼1similar-to𝑧1z\sim 1italic_z ∼ 1. Our result demonstrates that JWST can detect PAH emissions from normal star-forming galaxies at z∼1similar-to𝑧1z\sim 1italic_z ∼ 1, in addition to ultra-luminous infrared galaxies (ULIRGs) or luminous infrared galaxies (LIRGs).",[''],[]
"Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments of text-audio alignment in TTA. Our findings reveal Auffusion’s superior capability in generating audios that accurately match textual descriptions, which further demonstrated in several related tasks, such as audio style transfer, inpainting and other manipulations. Project page is available at https://auffusion.github.io.",[''],[]
"In the stratified or partially premixed piloted jet flames, previous experimental and p⁢r⁢i⁢o⁢r⁢i𝑝𝑟𝑖𝑜𝑟𝑖prioriitalic_p italic_r italic_i italic_o italic_r italic_i studies have identified a strong correlation between mixture fraction and progress variable. In the framework of large-eddy simulation (LES) and flamelet-generated manifolds (FGM) approach, a joint probability density function (PDF) method is constructed to characterize subgrid correlations. To pave the way for high dimensional tabulation modeling, a deep residual network (ResNet) is trained, dramatically reducing the memory footprint of tabulation. The Message Passing Interface (MPI) shared memory technique is applied to load the original chemical table during parallel computations. Application of LES to a partially pre-vaporized ethanol spray flame demonstrates good agreement with experimental results. Consideration of the subgrid correlation results in a noticeable improvement in temperature prediction. Calculations using ResNet show a notable consistency with those using chemical tables. Visualization of enthalpy highlights the significance of non-adiabatic tabulation in modeling liquid fuel combustion. The unscaled progress variable is selected to better describe the chemical reaction rate in the blending zone of an air stream and a pilot stream with the product of a fully burnt lean fuel mixture. The impact of the source term due to evaporation in the transport equation of the progress variable is validated. The correlation coefficient is found to significantly influence the chemical reaction rate. The subgrid-scale interaction between liquid fuel evaporation and subgrid correlation is elucidated.",[''],[]
"As a higher analogue of the edge ideal of a graph, we study the t𝑡titalic_t-connected ideal JtsubscriptJ𝑡\operatorname{J}_{t}roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This is the monomial ideal generated by the connected subsets of size t𝑡titalic_t. For trees, we show that JtsubscriptJ𝑡\operatorname{J}_{t}roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT has a linear resolution iff the tree is t𝑡titalic_t-gap-free, and that this is equivalent to having linear quotients. We then show that if G𝐺Gitalic_G is any gap-free and t𝑡titalic_t-claw-free graph, then Jt⁡(G)subscriptJ𝑡𝐺\operatorname{J}_{t}(G)roman_J start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_G ) has linear quotients and hence, linear resolution.","['Key words and phrases:', 'Independence complex,', 'Stanley-Reisner ideal, edge ideal, linear resolution, shellable, linear quotients']",[]
"We investigate the power iteration algorithm for the tensor PCA model introduced in [RM14]. Previous work studying the properties of tensor power iteration is either limited to a constant number of iterations, or requires a non-trivial data-independent initialization. In this paper, we move beyond these limitations and analyze the dynamics of randomly initialized tensor power iteration up to polynomially many steps. Our contributions are threefold: First, we establish sharp bounds on the number of iterations required for power method to converge to the planted signal, for a broad range of the signal-to-noise ratios. Second, our analysis reveals that the actual algorithmic threshold for power iteration is smaller than the one conjectured in literature by a polylog⁢(n)polylog𝑛\mathrm{polylog}(n)roman_polylog ( italic_n ) factor, where n𝑛nitalic_n is the ambient dimension. Finally, we propose a simple and effective stopping criterion for power iteration, which provably outputs a solution that is highly correlated with the true signal. Extensive numerical experiments verify our theoretical results.",[''],[]
"This paper presents a series of new results for domain adaptation in the multi-view learning
setting. The incorporation of multiple views in the domain adaptation was paid little attention in the previous studies. In this way, we propose an analysis of generalization bounds with Pac-Bayesian theory to consolidate the two paradigms, which are currently treated separately. Firstly, building on previous work by Germain et al. [7, 8], we adapt the distance between distribution proposed by Germain et al. for domain adaptation with the concept of multi-view learning. Thus, we introduce a novel distance that is tailored for the multi-view domain adaptation setting. Then, we give Pac-Bayesian bounds for estimating the introduced divergence. Finally, we compare the different new bounds with the previous studies.","['PAC-Bayesian', 'Domain', 'Adaptation', 'Multi-view', 'Learning.']",[]
"The homogenization of eigenvalues of non-Hermitian Maxwell operators is studied by the H-convergence method. It is assumed that the Maxwell systems are equipped with suitable m-dissipative boundary conditions, namely, with Leontovich or generalized impedance boundary conditions of the form 𝐧×𝐄=Z⁢[(𝐧×𝐇)×𝐧]𝐧𝐄𝑍delimited-[]𝐧𝐇𝐧\mathbf{n}\times\mathbf{E}=Z[(\mathbf{n}\times\mathbf{H})\times\mathbf{n}]bold_n × bold_E = italic_Z [ ( bold_n × bold_H ) × bold_n ]. We show that, for a wide class of impedance operators Z𝑍Zitalic_Z, the nonzero spectrum of the corresponding Maxwell operator is discrete. To this end, a new continuous embedding theorem for domains of Maxwell operators is obtained. We prove the convergence of eigenvalues to an eigenvalue of a homogenized Maxwell operator under the assumption of the H-convergence of the material tensor-fields. This result is applied then to the existence of optimizers for eigenvalue optimization problems and to the existence of an eigenvalue-free region around zero. Connections with unique (and nonunique) continuation results are discussed.",[''],[]
,[''],[]
"We investigate the minimal Kitaev spin liquid on a single hexagon with three
Ising-type exchange interactions proportional to Kxsubscript𝐾𝑥K_{x}italic_K start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT, Kysubscript𝐾𝑦K_{y}italic_K start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT and Kzsubscript𝐾𝑧K_{z}italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT. In the limit Kz=0subscript𝐾𝑧0K_{z}=0italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT = 0, we find 32-fold zero-energy states, leading to 10
free Majorana fermions, and hence, 5 qubits are constructed. These qubits
are protected by particle-hole symmetry even for Kz≠0subscript𝐾𝑧0K_{z}\neq 0italic_K start_POSTSUBSCRIPT italic_z end_POSTSUBSCRIPT ≠ 0. Braiding of
these Majorana fermions is possible by temporally controlling a
spin-correlation Hamiltonian. In addition, the fusion is possible by
measuring the spin correlation. By switching on the Heisenberg interaction
together with magnetic field, only one zero-energy state persists, which can
be used as an initialization of qubits. Furthermore, it is shown that 3⁢L+23𝐿23L+23 italic_L + 2
qubits are constructed on the Kitaev spin liquid model on connected L𝐿Litalic_L
hexagons. All the processes of initialization, operation and readout of
qubits are executable in terms of spin operators.",[''],['Japan']
"In this paper we construct new indecomposable motivic cycles in the group Hℳ3⁢(X,ℚ⁢(2))subscriptsuperscript𝐻3ℳ𝑋ℚ2H^{3}_{{\mathcal{M}}}(X,{\mathds{Q}}(2))italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT caligraphic_M end_POSTSUBSCRIPT ( italic_X , blackboard_Q ( 2 ) ) where X𝑋Xitalic_X is a degree 2222 K⁢3𝐾3K3italic_K 3 surface. This generalizes our construction in [Sre22] for Kummer surfaces of Abelian surfaces as well as the recent work of Ma and Sato [MS23] on degree 2222 K⁢3𝐾3K3italic_K 3 surfaces.",[''],[]
"Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517517517517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specific languages, our approach facilitates the development of practical NLG applications for African communities. The findings of this study contribute to advancing NLP research in low-resource settings, enabling greater accessibility and inclusion for African languages in a rapidly expanding digital landscape. We will publicly release our models for research. 111https://github.com/UBC-NLP/Cheetah†† ⋆⋆{}^{\star}start_FLOATSUPERSCRIPT ⋆ end_FLOATSUPERSCRIPT Authors contributed equally.",[''],[]
"The goal of Continual Learning (CL) is to continuously learn from new data streams and accomplish the corresponding tasks.
Previously studied CL assumes that data are given in sequence nose-to-tail for different tasks, thus indeed belonging to Serial Continual Learning (SCL).
This paper studies the novel paradigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios, where a diverse set of tasks is encountered at different time points.
PCL presents challenges due to the training of an unspecified number of tasks with varying learning progress, leading to the difficulty of guaranteeing effective model updates for all encountered tasks.
In our previous conference work, we focused on measuring and reducing the discrepancy among gradients in a multi-objective optimization problem, which, however, may still contain negative transfers in every model update.
To address this issue, in the dynamic multi-objective optimization problem, we introduce task-specific elastic factors to adjust the descent direction towards the Pareto front.
The proposed method, called Elastic Multi-Gradient Descent (EMGD), ensures that each update follows an appropriate Pareto descent direction, minimizing any negative impact on previously learned tasks.
To balance the training between old and new tasks, we also propose a memory editing mechanism guided by the gradient computed using EMGD. This editing process updates the stored data points, reducing interference in the Pareto descent direction from previous tasks.
Experiments on public datasets validate the effectiveness of our EMGD in the PCL setting.","['Index', 'Terms: \nparallel continual learning, catastrophic forgetting, training conflict, multi-objective optimization,', 'Pareto optimum.']",[]
"In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language.
To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model’s level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model’s response quality is conducted, considering aspects such as accuracy, fluency, informativeness, logical coherence, and harmlessness, based on LLM-Eval, a benchmarks consisting instruction tasks from 17 diverse categories.
Our evaluation results demonstrate that comparable performance to state-of-the-art transfer models can be achieved with less than 1%percent11\%1 % of the pretraining data, both in terms of knowledge alignment and response quality. Furthermore, the experimental outcomes across the thirteen low-resource languages also exhibit similar trends. We anticipate that the conclusions revealed by the experiments will aid the community in developing non-English LLMs.",[''],[]
"Automatic Modulation Recognition (AMR) plays a crucial role in wireless communication systems.
Deep learning AMR strategies have achieved tremendous success in recent years.
Modulated signals exhibit long temporal dependencies, and extracting global features is crucial in identifying modulation schemes.
Traditionally, human experts analyze patterns in constellation diagrams to classify modulation schemes.
Classical convolutional-based networks, due to their limited receptive fields, excel at extracting local features but struggle to capture global relationships.
To address this limitation, we introduce a novel hybrid deep framework named TLDNN, which incorporates the architectures of the transformer and long short-term memory (LSTM).
We utilize the self-attention mechanism of the transformer to model the global correlations in signal sequences while employing LSTM to enhance the capture of temporal dependencies.
To mitigate the impact like RF fingerprint features and channel characteristics on model generalization, we propose data augmentation strategies known as segment substitution (SS) to enhance the model’s robustness to modulation-related features.
Experimental results on widely-used datasets demonstrate that our method achieves state-of-the-art performance and exhibits significant advantages in terms of complexity. Our proposed framework serves as a foundational backbone that can be extended to different datasets.
We have verified the effectiveness of our augmentation approach in enhancing the generalization of the models, particularly in few-shot scenarios.
Code is available at https://github.com/AMR-Master/TLDNN.","['Index', 'Terms: ', 'Automatic modulation recognition, transformer,', 'LSTM, deep learning, data augmentation']",[]
We prove a reciprocity relation for the twisted second moment of the Riemann Zeta function. This provides an analogue to a formula of Conrey for Dirichlet L𝐿Litalic_L-functions.,"['Key words and phrases:', 'Riemann', 'Zeta function,', 'Dirichlet', 'L𝐿Litalic_L-functions, twisted second moment, reciprocity relation']",[]
"We study the Boltzmann equation in a smooth bounded domain featuring a mixed boundary condition. Specifically, gas particles experience specular reflection in two parallel plates, while diffusive reflection occurs in the remaining portion between these two specular regions. The boundary is assumed to be motionless and isothermal. Our main focus is on constructing global-in-time small-amplitude solutions around global Maxwellians for the corresponding initial-boundary value problem. The proof relies on the L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT hypocoercivity at the linear level, utilizing the weak formulation and various functional inequalities on the test functions, such as Poincaré and Korn inequalities. It also extends to the linear problem involving Maxwell boundary conditions, where the accommodation coefficient can be a piecewise constant function on the boundary, allowing for more general bounded domains. Moreover, we develop a delicate application of the L2−L∞superscript𝐿2superscript𝐿L^{2}-L^{\infty}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_L start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT bootstrap argument, which relies on the specific geometry of our domains, to effectively handle this mixed-type boundary condition.","['Key words and phrases:', 'Boltzmann equation, global existence, long time asymptotics, mixed boundary conditions']",[]
,[''],[]
"Given an idempotent p𝑝pitalic_p in a Banach algebra and following the study in [6] of p-invertibility, we
consider here left p-invertibility, right p-invertibility and p-invertibility in the Calkin Algebra 𝒞⁢(X),𝒞𝑋\mathcal{C}(X),caligraphic_C ( italic_X ) ,
where X𝑋Xitalic_X is a Banach space. Then we define and study left and right generalized Drazin invertibility
and we characterize left and right Drazin invertible elements in the Calkin algebra. Globally, this leads to define and characterize the classes of P-Fredholm, pseudo B-Fredholm and weak B-Fredholm operators.",[''],[]
"The recent development on large language models makes automatically constructing small programs possible. It thus has the potential to free software engineers from low-level coding and allow us to focus on the perhaps more interesting parts of software development, such as requirement engineering and system testing. In this project, we develop a prototype named AISD (AI-aided Software Development), which is capable of taking high-level (potentially vague) user requirements as inputs, generates detailed use cases, prototype system designs, and subsequently system implementation. Different from existing attempts, AISD is designed to keep the user in the loop, i.e., by repeatedly taking user feedback on use cases, high-level system designs, and prototype implementations through system testing. AISD has been evaluated with a novel benchmark of non-trivial software projects. The experimental results suggest that it might be possible to imagine a future where software engineering is reduced to requirement engineering and system testing only.","['Requirement engineering, system testing, large language model, code generation']","['UniversityShanghaiChina', 'UniversityShanghaiChina', 'UniversitySingaporeSingapore', 'UniversitySingaporeSingapore', 'UniversityShanghaiChina', 'UniversityShanghaiChina']"
"Studying the relations between entanglement and coherence is essential in many quantum information applications. For this, we consider the concurrence, intrinsic concurrence and first-order coherence, and evaluate the proposed trade-off relations between them. In particular, we study the temporal evolution of a general two-qubit XYZ Heisenberg model with asymmetric spin-orbit interaction under decoherence and analyze the trade-off relations of quantum resource theory.
For XYZ Heisenberg model, we confirm that the trade-off relation between intrinsic concurrence and first-order coherence holds. Furthermore, we show that the lower bound of intrinsic concurrence is universally valid, but the upper bound is generally not.
These relations in Heisenberg models can provide a way to explore how quantum resources are distributed in spins, which may inspire future applications in quantum information processing.","['Trade-off relations,', 'First-order coherence,', 'Intrinsic concurrence,', 'Heisenberg models']","['Qatar', 'Qatar', 'Iran']"
"We propose a robust hypothesis testing procedure for the predictability of multiple predictors that could be highly persistent. Our method improves the popular extended instrumental variable (IVX) testing (Phillips and Lee,, 2013; Kostakis et al.,, 2015) in that, besides addressing the two bias effects found in Hosseinkouchack and Demetrescu, (2021), we find and deal with the variance-enlargement effect. We show that two types of higher-order terms induce these distortion effects in the test statistic, leading to significant over-rejection for one-sided tests and tests in multiple predictive regressions. Our improved IVX-based test includes three steps to tackle all the issues above regarding finite sample bias and variance terms. Thus, the test statistics perform well in size control, while its power performance is comparable with the original IVX. Monte Carlo simulations and an empirical study on the predictability of bond risk premia are provided to demonstrate the effectiveness of the newly proposed approach.",[''],[]
"The demand for the retrieval of complex scene data in autonomous driving is increasing, especially as passenger vehicles have been equipped with the ability to navigate urban settings, with the imperative to address long-tail scenarios. Meanwhile, under the pre-existing two dimensional image retrieval method, some problems may arise with scene retrieval, such as lack of global feature representation and subpar text retrieval ability. To address these issues, we have proposed BEV-CLIP, the first multimodal Bird’s-Eye View(BEV) retrieval methodology that utilizes descriptive text as an input to retrieve corresponding scenes. This methodology applies the semantic feature extraction abilities of a large language model (LLM) to facilitate zero-shot retrieval of extensive text descriptions, and incorporates semi-structured information from a knowledge graph to improve the semantic richness and variety of the language embedding. Our experiments result in 87.66% accuracy on NuScenes dataset in text-to-BEV feature retrieval. The demonstrated cases in our paper support that our retrieval method is also indicated to be effective in identifying certain long-tail corner scenes.",[''],[]
"Due to the poor illumination and the difficulty in annotating, nighttime conditions pose a significant challenge for autonomous vehicle perception systems. Unsupervised domain adaptation (UDA) has been widely applied to semantic segmentation on such images to adapt models from normal conditions to target nighttime-condition domains. Self-training (ST) is a paradigm in UDA, where a momentum teacher is utilized for pseudo-label prediction, but a confirmation bias issue exists. Because the one-directional knowledge transfer from a single teacher is insufficient to adapt to a large domain shift. To mitigate this issue, we propose to alleviate domain gap by incrementally considering style influence and illumination change. Therefore, we introduce a one-stage Dual-Teacher Bi-directional Self-training (DTBS) framework for smooth knowledge transfer and feedback. Based on two teacher models, we present a novel pipeline to respectively decouple style and illumination shift. In addition, we propose a new Re-weight exponential moving average (EMA) to merge the knowledge of style and illumination factors, and provide feedback to the student model. In this way, our method can be embedded in other UDA methods to enhance their performance. For example, the Cityscapes to ACDC night task yielded 53.8 mIoU (%), which corresponds to an improvement of +5% over the previous state-of-the-art. The code is available at https://github.com/hf618/DTBS.",[''],[]
"The safe operation of most tokamaks, especially the largen sized ones, rely on the feedback control of the vertical displacement events (VDEs). However, most these feedback control systems are based on the axisymmetric VDE models. In this work, we use NIMROD simulations to study the roles of non-axisymmetric perturbations in free drift vertical displacement events on EAST. The high-n𝑛nitalic_n modes in non-axisymmetric VDE grow first, which drive the formation of high-n𝑛nitalic_n magnetic island chains. Subsequently, the magnetic island chains grow and overlap with each other, leading to the destruction of the magnetic flux surface, which induces a minor disruption and accelerates the start of the following major disruption. The magnetic island and the stochastic magnetic field allow the toroidally asymmetric poloidal plasma current to jet towards the hoop force direction, forming the finger and filamentary structures. Such a plasma current asymmetry strongly depends on the anisotropy in thermal transport coefficients.",[''],[]
"We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.
Keywords: Legal Language Processing, Topic Models, Text-as-Data, Domain Name Disputes, European Court of Human Rights",[''],[]
"In this paper, we propose an iterative convolution-thresholding method (ICTM) based on prediction-correction for solving the topology optimization problem in steady-state heat transfer equations. The problem is formulated as a constrained minimization problem of the complementary energy, incorporating a perimeter/surface-area regularization term, while satisfying a steady-state heat transfer equation. The decision variables of the optimization problem represent the domains of different materials and are represented by indicator functions. The perimeter/surface-area term of the domain is approximated using Gaussian kernel convolution with indicator functions. In each iteration, the indicator function is updated using a prediction-correction approach. The prediction step is based on the variation of the objective functional by imposing the constraints, while the correction step ensures the monotonically decreasing behavior of the objective functional. Numerical results demonstrate the efficiency and robustness of our proposed method, particularly when compared to classical approaches based on the ICTM.",[''],[]
"In robust optimization problems, the magnitude of perturbations is relatively small.
Consequently, solutions within certain regions are less likely to represent the robust optima when perturbations are introduced.
Hence, a more efficient search process would benefit from increased opportunities to explore promising regions where global optima or good local optima are situated.
In this paper, we introduce a novel robust evolutionary algorithm named the dual-stage robust evolutionary algorithm (DREA) aimed at discovering robust solutions.
DREA operates in two stages: the peak-detection stage and the robust solution-searching stage.
The primary objective of the peak-detection stage is to identify peaks in the fitness landscape of the original optimization problem.
Conversely, the robust solution-searching stage focuses on swiftly identifying the robust optimal solution using information obtained from the peaks discovered in the initial stage.
These two stages collectively enable the proposed DREA to efficiently obtain the robust optimal solution for the optimization problem.
This approach achieves a balance between solution optimality and robustness by separating the search processes for optimal and robust optimal solutions.
Experimental results demonstrate that DREA significantly outperforms five state-of-the-art algorithms across 18 test problems characterized by diverse complexities.
Moreover, when evaluated on higher-dimensional robust optimization problems (100-D𝐷Ditalic_D and 200-D𝐷Ditalic_D), DREA also demonstrates superior performance compared to all five counterpart algorithms.","['Index', 'Terms: ', 'Evolutionary robust optimization, evolutionary algorithm, dual-stage strategy, peak detection']",[]
It is shown that the category of fuzzy ordered sets and order-preserving maps valued in the quantale based on a continuous triangular norm on the unit interval contains a largest Cartesian closed and stable subconstruct which contains all crisp ordered sets.,[''],[]
"In this paper, we present Coyote C++, a fully automated white-box unit testing tool for C and C++. Whereas existing tools have struggled to realize unit test generation for C++, Coyote C++ is able to produce high coverage results from unit test generation at a testing speed of over 10,000 statements per hour. This impressive feat is made possible by the combination of a powerful concolic execution engine with sophisticated automated test harness generation. Additionally, the GUI of Coyote C++ displays detailed code coverage visualizations and provides various configuration features for users seeking to manually optimize their coverage results. Combining potent one-click automated testing with rich support for manual tweaking, Coyote C++ is the first automated testing tool that is practical enough to make automated testing of C++ code truly viable in industrial applications.","['Index', 'Terms: ', 'Software', 'Testing,', 'Test case generation,', 'Automated unit test generation,', 'Symbolic execution,', 'C++']","['rho@codemind.co.kr', 'yeoneo@codemind.co.kr', 'philipp.m@codemind.co.kr', 'shin@codemind.co.kr']"
"Medical data collected for making a diagnostic decision are typically multi-modal and provide complementary perspectives of a subject. A computer-aided diagnosis system welcomes multi-modal inputs; however, how to effectively fuse such multi-modal data is a challenging task and attracts a lot of attention in the medical research field. In this paper, we propose a transformer-based framework, called Alifuse, for aligning and fusing multi-modal medical data. Specifically, we convert images and unstructured and structured texts into vision and language tokens, and use intramodal and intermodal attention mechanisms to learn holistic representations of all imaging and non-imaging data for classification. We apply Alifuse to classify Alzheimer’s disease and obtain state-of-the-art performance on five public datasets, by outperforming eight baselines. The source code will be available online later.",[''],[]
"Monocular 3D object detection poses a significant challenge due to the lack of depth information in RGB images.
Many existing methods strive to enhance the object depth estimation performance by allocating additional parameters for object depth estimation, utilizing extra modules or data.
In contrast, we introduce a novel metric learning scheme that encourages the model to extract depth-discriminative features regardless of the visual attributes without increasing inference time and model size.
Our method employs the distance-preserving function to organize the feature space manifold in relation to ground-truth object depth.
The proposed (K,B,ϵ)𝐾𝐵italic-ϵ(K,B,\epsilon)( italic_K , italic_B , italic_ϵ )-quasi-isometric loss leverages predetermined pairwise distance restriction as guidance for adjusting the distance among object descriptors without disrupting the non-linearity of the natural feature manifold.
Moreover, we introduce an auxiliary head for object-wise depth estimation, which enhances depth quality while maintaining the inference time.
The broad applicability of our method is demonstrated through experiments that show improvements in overall performance when integrated into various baselines.
The results show that our method consistently improves the performance of various baselines by 25.27% and 4.54% on average across KITTI and Waymo, respectively.",[''],[]
"Recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. These models have demonstrated significant improvements by fine-tuning on downstream tasks. However, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. In this paper, we propose a parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog retrieval. Specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model CLIP.
Besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data.
To facilitate various types of retrieval, we also design multiple experts to learn mappings from CLIP outputs to multi-modal representation space, with each expert being responsible to one specific retrieval type. Extensive experiments show that DialCLIP achieves state-of-the-art performance on two widely recognized benchmark datasets (i.e., PhotoChat and MMDialog) by tuning a mere 0.04% of the total parameters. These results highlight the efficacy and efficiency of our proposed approach, underscoring its potential to advance the field of multi-modal dialog retrieval.",[''],[]
,[''],[]
"Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the ”luc bat” genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the ”luc bat” genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.","['GPT-3, poem generation,', 'BLOOM,', 'Vietnamese, quantization,', 'LoRa']","['CityVietnam', 'CityVietnam']"
,[''],[]
,[''],[]
"Visual-inertial SLAM is essential in various fields, such as AR/VR, uncrewed aerial vehicles, industrial robots, and autonomous driving. The fusion of a camera and inertial measurement unit (IMU) can make up for the shortcomings of a signal sensor, which significantly improves the accuracy and robustness of localization in challenging environments. Robust tracking and accurate inertial parameter estimation are the basis for the stable operation of the system. This article presents PLE-SLAM, an entirely precise and real-time visual-inertial SLAM algorithm based on point-line features and efficient IMU initialization. First, we introduce line features in a point-based visual-inertial SLAM system. We use parallel computing methods to extract features and compute descriptors to ensure real-time performance. Second, the proposed system estimates gyroscope bias with rotation pre-integration and point and line observations. Accelerometer bias and gravity direction are solved by an analytical method. After initialization, all inertial parameters are refined through maximum a posteriori (MAP) estimation. Moreover, we open a dynamic feature elimination thread to improve the adaptability to dynamic environments and use CNN, bag-of-words and GNN to detect loops and match features. Excellent wide baseline matching capability of DNN-based matching method and illumination robustness significantly improve loop detection recall and loop inter-frame pose estimation. The front-end and back-end are designed for hardware acceleration. The experiments are performed on public datasets, and the results show that the proposed system is one of the state-of-the-art methods in complex scenarios.","['Index', 'Terms: ', 'Visual-inertial', 'SLAM, point-line features,', 'IMU initializaton, challenging environments.']",[]
"In this paper, we are concerned with n𝑛nitalic_n-component Ginzburg-Landau equations on ℝ2superscriptℝ2{\mathbb{R}^{2}}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT.
By introducing a diffusion constant for each component, we discuss that the n𝑛nitalic_n-component equations are different from n𝑛nitalic_n-copies of the single Ginzburg-Landau equations.
Then, the results of Brezis-Merle-Riviere for the single Ginzburg-Landau equation can be nontrivially extended to the multi-component case.
First, we show that if the solutions have their gradients in L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT space, they are trivial solutions.
Second, we prove that if the potential is square summable, then it has quantized integrals, i.e., there exists one-to-one correspondence between the possible values of the potential energy and ℕnsuperscriptℕ𝑛\mathbb{N}^{n}blackboard_N start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT.
Third, we show that different diffusion coefficients in the system are important to obtain nontrivial solutions of n𝑛nitalic_n-component equations.",[''],[]
"Aircraft landing time (ALT) prediction is crucial for air traffic management, especially for arrival aircraft sequencing on the runway. In this study, a trajectory image-based deep learning method is proposed to predict ALTs for the aircraft entering the research airspace that covers the Terminal Maneuvering Area (TMA). Specifically, the trajectories of all airborne arrival aircraft within the temporal capture window are used to generate an image with the target aircraft trajectory labeled as red and all background aircraft trajectory labeled as blue. The trajectory images contain various information, including the aircraft position, speed, heading, relative distances, and arrival traffic flows. It enables us to use state-of-the-art deep convolution neural networks for ALT modeling. We also use real-time runway usage obtained from the trajectory data and the external information such as aircraft types and weather conditions as additional inputs. Moreover, a convolution neural network (CNN) based module is designed for automatic holding-related featurizing, which takes the trajectory images, the leading aircraft holding status, and their time and speed gap at the research airspace boundary as its inputs. Its output is further fed into the final end-to-end ALT prediction. The proposed ALT prediction approach is applied to Singapore Changi Airport (ICAO Code: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from November 1 to November 30, 2022. Experimental results show that by integrating the holding featurization, we can reduce the mean absolute error (MAE) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of 96.1%, with 79.4% of the predictions errors being less than 60 seconds.","['Air', 'Traffic', 'Management,', 'Aircraft', 'Landing', 'Time,', 'Trajectory', 'Image,', 'Convolution', 'Neural', 'Networks.']",['Singapore']
"Natural policy gradient (NPG) and its variants are widely-used policy search methods in reinforcement learning. Inspired by prior work, a new NPG variant coined NPG-HM is developed in this paper, which utilizes the Hessian-aided momentum technique for variance reduction, while the sub-problem is solved via the stochastic gradient descent method.
It is shown that NPG-HM can achieve the global last iterate ϵitalic-ϵ\epsilonitalic_ϵ-optimality with a sample complexity of 𝒪⁢(ϵ−2)𝒪superscriptitalic-ϵ2{\cal O}(\epsilon^{-2})caligraphic_O ( italic_ϵ start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT ), which is the best known result for natural policy gradient type methods under the generic Fisher non-degenerate policy parameterizations. The convergence analysis is built upon a relaxed weak gradient dominance property tailored for NPG under the compatible function approximation framework, as well as a neat way to decompose the error when handling the sub-problem. Moreover, numerical experiments on Mujoco-based environments demonstrate the superior performance of NPG-HM over other state-of-the-art policy gradient methods.",[''],"['China.', 'China.', 'China.']"
"Revolutionized by the transformer architecture, natural language processing (NLP) has received unprecedented attention. While advancements in NLP models have led to extensive research into their backdoor vulnerabilities, the potential for these advancements to introduce new backdoor threats remains unexplored. This paper proposes Imperio111“Imperio” is a spell from the Harry Potter series that allows the caster to control another’s actions., which harnesses the language understanding capabilities of NLP models to enrich backdoor attacks. Imperio provides a new model control experience. It empowers the adversary to control the victim model with arbitrary output through language-guided instructions. This is achieved using a language model to fuel a conditional trigger generator, with optimizations designed to extend its language understanding capabilities to backdoor instruction interpretation and execution. Our experiments across three datasets, five attacks, and nine defenses confirm Imperio’s effectiveness. It can produce contextually adaptive triggers from text descriptions and control the victim model with desired outputs, even in scenarios not encountered during training. The attack maintains a high success rate across complex datasets without compromising the accuracy of clean inputs and also exhibits resilience against representative defenses. The source code is available at https://khchow.com/Imperio.","['Large', 'Language', 'Models,', 'Backdoor', 'Attacks,', 'Poisoning', 'Attacks,', 'AI', 'Security']",[]
"Given two measures μ,ν𝜇𝜈\mu,\nuitalic_μ , italic_ν on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT that satisfy Carleman’s condition, we provide a numerical
scheme to approximate as closely as desired the total variation distance between μ𝜇\muitalic_μ and ν𝜈\nuitalic_ν.
It consists of solving a sequence (hierarchy) of convex relaxations whose associated sequence of optimal values
converges to the total variation distance, an additional illustration
of the versatility of the Moment-SOS hierarchy.
Indeed each relaxation in the hierarchy
is a semidefinite program whose size increases
with the number of involved moments. It has an optimal solution which
is a couple of degree-2⁢n2𝑛2n2 italic_n pseudo-moments which converge, as n𝑛nitalic_n grows, to
moments of the Hahn-Jordan decomposition of μ−ν𝜇𝜈\mu-\nuitalic_μ - italic_ν.",[''],[]
,[''],[]
"We study the quantitative stability of the mapping that to a measure associates its
pushforward measure by a fixed (non-smooth) optimal transport map. We exhibit a tight
Hölder-behavior for
this operation under minimal assumptions.
Our proof essentially relies on a new bound that quantifies the size of
the singular sets of a convex and Lipschitz continuous function on a bounded domain.",[''],[]
"This paper presents the development of a specialized chatbot for materials science, leveraging the Llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the S2ORC dataset.
The methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot’s capabilities.
The chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science.
We make the four trained checkpoints (7B, 13B, with or without chat ability) freely available to the research community at https://github.com/Xianjun-Yang/Quokka.",[''],[]
,[''],[]
"The Gaia DR3 parallax approach was used to estimate the absolute parameters of 2375 δ𝛿\deltaitalic_δ Scuti stars from the ASAS catalog. The selected stars have a variety of observational characteristics, with a higher than 80% probability of being δ𝛿\deltaitalic_δ Scuti stars. We have displayed all the stars in the Hertzsprung-Russell (H-R) diagram along with the δ𝛿\deltaitalic_δ Scuti instability strip, the Zero Age Main Sequence (ZAMS), and the Terminal-Age Main Sequence (TAMS). Then, we determined which fundamental and overtone modes each star belongs to using pulsation constant (Q𝑄Qitalic_Q) calculations. In addition, we evaluated the parameters in the Q𝑄Qitalic_Q calculation equation using three machine learning methods, which showed that surface gravity and temperature have the greatest effect on its calculation. The Period-Luminosity (P−L𝑃𝐿P-Litalic_P - italic_L) relationship of the δ𝛿\deltaitalic_δ Scuti stars was also revisited. Eventually, using least squares linear regression, we made four linear fits for fundamental and overtone modes and updated their relationships.","['δ𝛿\\deltaitalic_δ', 'Scuti variable stars -', 'Fundamental parameters -', 'Data analysis']","['poroatila@gmail.com', 'Canada', 'USA', 'Iran', 'Iran', 'Italy', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran']"
"This paper investigates intelligent reflecting surface (IRS)-aided multi-antenna wireless powered communications in a multi-link interference channel, where multiple IRSs are deployed to enhance the downlink/uplink communications between each pair of hybrid access point (HAP) and wireless device. Our objective is to maximize the system sum throughput by optimizing the allocation of communication resources. To attain this objective and meanwhile balance the performance-cost tradeoff, we propose three transmission schemes: the IRS-aided asynchronous (Asy) scheme, the IRS-aided time-division multiple access (TDMA) scheme, and the IRS-aided synchronous (Syn) scheme. For the resulting three non-convex design problems, we propose a general algorithmic framework capable of addressing all of them.
Numerical results show that our proposed IRS-aided schemes noticeably surpass their counterparts without IRSs in both system sum throughput and total transmission energy consumption at the HAPs. Moreover, although the IRS-aided Asy scheme consistently achieves the highest sum throughput, the IRS-aided TDMA scheme is more appealing in scenarios with substantial cross-link interference and limited IRS elements, while the IRS-aided Syn scheme is preferable in low cross-link interference scenarios.","['Index', 'Terms: ', 'IRS, wireless powered communications, interference channel, resource allocation.']",[]
"Hyperspectral anomaly detection (HAD) aims to localize pixel points whose spectral features differ from the background. HAD is essential in scenarios of unknown or camouflaged target features, such as water quality monitoring, crop growth monitoring and camouflaged target detection, where prior information of targets is difficult to obtain. Existing HAD methods aim to objectively detect and distinguish background and anomalous spectra, which can be achieved almost effortlessly by human perception. However, the underlying processes of human visual perception are thought to be quite complex. In this paper, we analyze hyperspectral image (HSI) features under human visual perception, and transfer the solution process of HAD to the more robust feature space for the first time. Specifically, we propose a small target aware detector (STAD), which introduces saliency maps to capture HSI features closer to human visual perception. STAD not only extracts more anomalous representations, but also reduces the impact of low-confidence regions through a proposed small target filter (STF). Furthermore, considering the possibility of HAD algorithms being applied to edge devices, we propose a full connected network to convolutional network knowledge distillation strategy. It can learn the spectral and spatial features of the HSI while lightening the network. We train the network on the HAD100 training set and validate the proposed method on the HAD100 test set. Our method provides a new solution space for HAD that is closer to human visual perception with high confidence. Sufficient experiments on real HSI with multiple method comparisons demonstrate the excellent performance and unique potential of the proposed method. The code is available at https://github.com/majitao-xd/STAD-HAD.","['Index', 'Terms: ', 'Anomaly detection, visual perception, saliency map, hyperspectral images.']",[]
"In this paper, we introduce an algorithm designed to solve a Multilevel MOnoObjective Linear Programming Problem (ML(MO)OLPP). Our approach is a refined adaptation of Sinha and Sinha’s linear programming method, incorporating the development of an ""interval reduction map"" that precisely refines decision variable intervals based on the influence of the preceding level’s decision maker. Each construction stage is meticulously examined. The effectiveness of the algorithm is validated through a detailed numerical example, illustrating its practical applicability in resource management challenges. With a specific focus on vaccination planning within long-term care facilities and its relevance to the COVID-19 pandemic, our study addresses the optimization of resource allocation, placing a strong emphasis on the equitable distribution of COVID-19 vaccines.",[''],[]
"Context:
Aims:We studied the manifestation of decayless oscillations in 3D simulations of coronal loops, driven by random motions.
Methods:Using the PLUTO code, we ran magnetohydrodynamic (MHD) simulations of a straight gravitationally stratified flux tube, with its footpoints embedded in chromospheric plasma. We consider transverse waves drivers with a horizontally polarised red noise power-law spectrum.
Results:Our broadband drivers lead to the excitation of standing waves with frequencies equal to the fundamental standing kink mode and its harmonics. These standing kink oscillations have non-decaying amplitudes, and spectra that depend on the characteristics of the loops, with the latter amplifying the resonant frequencies from the drivers. We thus report for the first time in 3D simulations the manifestation of decayless oscillations from broadband drivers. The spatial and temporal evolution of our oscillation spectra reveals the manifestation of a half harmonic, which exhibits half the frequency of the identified fundamental mode with a similar spatial profile. Our results suggest that this mode is related to the presence of the transition region in our model and could be interpreted as being the equivalent to the fundamental mode of standing sound waves driven on pipes closed at one end.
Conclusions:The potential existence of this half harmonic has important implications for coronal seismology, since misinterpreting it for the fundamental mode of the system can lead to false estimations of the average kink speed profile along oscillating loops. Finally, its detection could potentially give us a tool for distinguishing between different excitation and driving mechanisms of decayless oscillations in observations.","['Key', 'Words.: \nmagnetohydrodynamics (MHD) - waves -', 'Sun: atmosphere -', 'Sun: magnetic fields - methods: numerical']",[]
,[''],[]
"Cryo-electron microscopy (cryo-EM) has achieved near-atomic level resolution of biomolecules by reconstructing 2D micrographs. However, the resolution and accuracy of the reconstructed particles are significantly reduced due to the extremely low signal-to-noise ratio (SNR) and complex noise structure of cryo-EM images. In this paper, we introduce a diffusion model with post-processing framework to effectively denoise and restore single particle cryo-EM images. Our method outperforms the state-of-the-art (SOTA) denoising methods by effectively removing structural noise that has not been addressed before. Additionally, more accurate and high-resolution three-dimensional reconstruction structures can be obtained from denoised cryo-EM images.",[''],[]
,[''],[]
"We present a fast and high-quality codec language model for parallel audio generation. While SoundStorm, a state-of-the-art parallel audio generation model, accelerates inference speed compared to autoregressive models, it still suffers from slow inference due to iterative sampling. To resolve this problem, we propose Group-Masked Language Modeling (G-MLM) and Group Iterative Parallel Decoding (G-IPD) for efficient parallel audio generation. Both the training and sampling schemes enable the model to synthesize high-quality audio with a small number of iterations by effectively modeling the group-wise conditional dependencies. In addition, our model employs a cross-attention-based architecture to capture the speaker style of the prompt voice and improves computational efficiency. Experimental results demonstrate that our proposed model outperforms the baselines in prompt-based audio generation.","['Index', 'Terms: ', 'Parallel audio generation, neural audio codec']",[]
,[''],[]
"Joint Communication and Sensing (JCAS) is taking its first shape in WLAN sensing under IEEE 802.11bf, where standardized WLAN signals and protocols are exploited to enable radar-like sensing. However, an overlooked problem in JCAS, and specifically in WLAN Sensing, is the sensitivity of the system to a deceptive jammer, which introduces phantom targets to mislead the victim radar receiver. Standardized waveforms and sensing parameters make the system vulnerable to physical layer attacks. Moreover, orthogonal frequency-division multiplexing (OFDM) makes deceptive jamming even easier as it allows digitally generated artificial range/Doppler maps. This paper studies deceptive jamming in JCAS, with a special focus on WLAN Sensing. The provided mathematical models give insights into how to design jamming signals and their impact on the sensing system. Numerical analyses illustrate various distortions caused by deceptive jamming, while the experimental results validate the need for meticulous JCAS design to protect the system against physical layer attacks in the form of deceptive jamming.","['Index', 'Terms: ', 'Joint', 'Communication and', 'Sensing,', 'WLAN', 'Sensing, deceptive jamming, physical layer security,', 'OFDM radars.']","['Belgium', 'Sweden']"
"Face recognition systems have raised concerns due to their vulnerability to different presentation attacks, and system security has become an increasingly critical concern.
Although many face anti-spoofing (FAS) methods perform well in intra-dataset scenarios, their generalization remains a challenge. To address this issue, some methods adopt domain adversarial training (DAT) to extract domain-invariant features. However, the competition between the encoder and the domain discriminator can cause the network to be difficult to train and converge. In this paper, we propose a domain adversarial attack (DAA) method to mitigate the training instability problem by adding perturbations to the input images, which makes them indistinguishable across domains and enables domain alignment.
Moreover, since models trained on limited data and types of attacks cannot generalize well to unknown attacks, we propose a dual perceptual and generative knowledge distillation framework for face anti-spoofing that utilizes pre-trained face-related models containing rich face priors.
Specifically, we adopt two different face-related models as teachers to transfer knowledge to the target student model. The pre-trained teacher models are not from the task of face anti-spoofing but from perceptual and generative tasks, respectively, which implicitly augment the data.
By combining both DAA and dual-teacher knowledge distillation, we develop a dual teacher knowledge distillation with domain alignment framework (DTDA) for face anti-spoofing.
The advantage of our proposed method has been verified through extensive ablation studies and comparison with state-of-the-art methods on public datasets across multiple protocols.","['Index', 'Terms: ', 'Face', 'Anti-Spoofing,', 'Knowledge', 'Distillation,', 'Domain', 'Generalization,', 'Adversarial', 'Attack']",[]
"For an input graph G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ) and a source vertex s∈V𝑠𝑉s\in Vitalic_s ∈ italic_V, the α𝛼\alphaitalic_α-approximate vertex fault-tolerant distance sensitivity oracle (α𝛼\alphaitalic_α-VSDO) answers an α𝛼\alphaitalic_α-approximate distance from s𝑠sitalic_s to t𝑡titalic_t in G−x𝐺𝑥G-xitalic_G - italic_x for any query (x,t)𝑥𝑡(x,t)( italic_x , italic_t ). It is a data structure version of the so-called single-source replacement path problem (SSRP). In this paper, we present a new nearly linear time algorithm of constructing the (1+ϵ)1italic-ϵ(1+\epsilon)( 1 + italic_ϵ )-VSDO for any weighted directed graph of n𝑛nitalic_n vertices and m𝑚mitalic_m edges with integer weights in range [1,W]1𝑊[1,W][ 1 , italic_W ], and any positive constant ϵ∈(0,1]italic-ϵ01\epsilon\in(0,1]italic_ϵ ∈ ( 0 , 1 ]. More precisely, the presented oracle attains O~⁢(m/ϵ+n/ϵ2)~𝑂𝑚italic-ϵ𝑛superscriptitalic-ϵ2\tilde{O}(m/\epsilon+n/\epsilon^{2})over~ start_ARG italic_O end_ARG ( italic_m / italic_ϵ + italic_n / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) construction time,
O~⁢(n/ϵ)~𝑂𝑛italic-ϵ\tilde{O}(n/\epsilon)over~ start_ARG italic_O end_ARG ( italic_n / italic_ϵ ) size, and O~⁢(1/ϵ)~𝑂1italic-ϵ\tilde{O}(1/\epsilon)over~ start_ARG italic_O end_ARG ( 1 / italic_ϵ ) query time for any polynomially-bounded W𝑊Witalic_W. To the best of our knowledge, this is the first non-trivial result for SSRP/VSDO beating the trivial O~⁢(m⁢n)~𝑂𝑚𝑛\tilde{O}(mn)over~ start_ARG italic_O end_ARG ( italic_m italic_n ) computation time for directed graphs with polynomially-bounded edge weights. Such a result has been unknown so far even for the setting of (1+ϵ)1italic-ϵ(1+\epsilon)( 1 + italic_ϵ )-approximation. It also implies that the known barrier of Ω⁢(m⁢n)Ω𝑚𝑛\Omega(m\sqrt{n})roman_Ω ( italic_m square-root start_ARG italic_n end_ARG ) time for the exact SSRP by Chechik and Magen [ICALP2020] does not apply to the case of approximation.",[''],[]
,[''],[]
"One of the major challenges in particle physics and cosmology is understanding why there is an asymmetry between matter and antimatter in the Universe. One possible explanation for this phenomenon is thermal leptogenesis, which involves the addition of at least two right-handed neutrinos (RHNs) to the standard model. Another possible explanation is baryogenesis through the hypermagnetic fields which involves the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly and helical hypermagnetic fields in the early Universe.
In this paper, after reviewing the thermal leptogenesis and baryogenesis through the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly, we investigate the simplest model that combines these two scenarios and explore the parameter space for optimal results.
Our results show that the combined scenario permits a specific region of parameter space that is not covered by either one separately. In fact, the minimum required mass scale of the RHN and strength of initial hypermagnetic helicity are reduced by one order of magnitude in our model.
Moreover, we find that in the combined scenario, leptogenesis and baryogenesis through the UY⁢(1)subscriptU𝑌1{\rm U}_{Y}(1)roman_U start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 1 ) anomaly can either amplify or reduce the effect of each other, i.e., the generated asymmetry, depending on the sign of the helical hypermagnetic fields.
Finally, we show the surprising result that a drastic amplification can occur even when the initial abundance of RHN is its equilibrium value for leptogenesis.",[''],"['Iran', 'Iran', 'Iran', 'Iran', 'Iran']"
,[''],[]
"Urban transformations have profound societal impact on both individuals and communities at large. Accurately assessing these shifts is essential for understanding their underlying causes and ensuring sustainable urban planning. Traditional measurements often encounter constraints in spatial and temporal granularity, failing to capture real-time physical changes. While street view imagery, capturing the heartbeat of urban spaces from a pedestrian point of view, can add as a high-definition, up-to-date, and on-the-ground visual proxy of urban change. We curate the largest street view time series dataset to date, and propose an end-to-end change detection model to effectively capture physical alterations in the built environment at scale. We demonstrate the effectiveness of our proposed method by benchmark comparisons with previous literature and implementing it at the city-wide level. Our approach has the potential to supplement existing dataset and serve as a fine-grained and accurate assessment of urban change.",[''],[]
"Comparative opinion mining is a specialized field of sentiment analysis that aims to identify and extract sentiments expressed comparatively. To address this task, we propose an approach that consists of solving three sequential sub-tasks: (i) identifying comparative sentence, i.e., if a sentence has a comparative meaning, (ii) extracting comparative elements, i.e., what are comparison subjects, objects, aspects, predicates, and (iii) classifying comparison types which contribute to a deeper comprehension of user sentiments in Vietnamese product reviews. Our method is ranked fifth at the Vietnamese Language and Speech Processing (VLSP) 2023 challenge on Comparative Opinion Mining (ComOM) from Vietnamese Product Reviews (Le et al., 2023). For reproducing the result, the code can be found at https://github.com/hallie304/VLSP23-Comparative-Opinion-Mining",[''],[]
"The limit q𝑞qitalic_q-Durrmeyer operator, D∞,q,subscript𝐷𝑞D_{\infty,q},italic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT , was introduced and its approximation properties were investigated by V. Gupta in 2008 during a study of q𝑞qitalic_q-analogues for the Bernstein-Durrmeyer operator. In the present work, this operator is investigated from a different perspective. More precisely, the growth estimates are derived for the entire functions comprising the range of D∞,qsubscript𝐷𝑞D_{\infty,q}italic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT. The interrelation between the analytic properties of a function f𝑓fitalic_f and the rate of growth for D∞,q⁢fsubscript𝐷𝑞𝑓D_{\infty,q}fitalic_D start_POSTSUBSCRIPT ∞ , italic_q end_POSTSUBSCRIPT italic_f are established, and the sharpness of the obtained results are demonstrated.",[''],[]
"Following [It12] and [It15], we construct two super-extensions of the usual tensor algebra through the super-actions of symmetric groups and Hecke algebras respectively. For each extension, we consider a special type of derivations coming from covectors, and study the the space generated, in some special manner, by these derivations and operators from left multiplication by vectors and permutations. Duality theorems of these spaces and the super-actions are proved. As an application, we provide a new proof of the Schur-Sergeev duality theorem, as well as its quantum version.",[''],[]
"Recently, the Floquet Na3⁢BisubscriptNa3Bi{\rm Na_{3}Bi}roman_Na start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT roman_Bi-type material has been proposed as an ideal platform for realizing various phases, i.e., the spin-degenerate Dirac semimetal (DSM) can be turned into the Weyl semimetal (WSM), and even to the Weyl half-metal (WHM)xiaoshi . Instead of the conventional electrical methods, we use the RKKY interaction to characterize the topological phase transitions in this paper. It is found that detecting the Ising term JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT is feasible for distinguishing the phase transition of DSM/WSM, since the emergence of JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT is induced by the broken spin degeneracy. For the case with impurities deposited on z𝑧zitalic_z axis (the line connecting the Weyl points), the Heisenberg term JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT coexists with JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT in the WSM, while JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is filtered out and only JIsubscript𝐽𝐼J_{I}italic_J start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT survives in the WHM. This magnetic filtering effect is a reflection of the fully spin-polarized property (one spin band is in the WSM phase while the other is gapped) of the WHM, and it can act a signal to capture the phase transition of WSM/WHM. This signal can not be disturbed unless the direction of the impurities greatly deviates from z𝑧zitalic_z axis. Interestingly, as the impurities are moved into the x𝑥xitalic_x-y𝑦yitalic_y plane, there arises another signal (a dip structure for JHsubscript𝐽𝐻J_{H}italic_J start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT at the phase boundary), which can also identify the phase transition of WSM/WHM. Furthermore, we have verified that all magnetic signals are robust to the term that breaks the electron-hole symmetry. Besides characterizing the phase transitions, our results also suggest that the Floquet DSMs are power platforms for controlling the magnetic interaction.",[''],"['China', 'China']"
"We establish the unique ergodicity of the Markov chain generated by the stochastic theta method (STM) with θ∈[1/2,1]𝜃121\theta\in[1/2,1]italic_θ ∈ [ 1 / 2 , 1 ] for monotone SODEs, without growth restriction on the coefficients, driven by nondegenerate multiplicative noise.
The main ingredient of the arguments lies in the construction of new Lyapunov functions, involving the coefficients, the stepsize, and θ𝜃\thetaitalic_θ, and the irreducibility and the strong Feller property for the STM.
We also generalize the arguments to the STM and its Galerkin-based full discretizations for a class of monotone SPDEs driven by infinite-dimensional nondegenerate multiplicative trace-class noise.
Applying these results to the stochastic Allen–Cahn equation indicates that its drift-implicit Euler scheme is uniquely ergodic for any interface thickness, which gives an affirmative answer to a question proposed in (J. Cui, J. Hong, and L. Sun, Stochastic Process. Appl. (2021): 55–93).
Numerical experiments verify our theoretical results.","['Key words and phrases: monotone stochastic differential equation,\nnumerical invariant measure,\nnumerical ergodicity,\nstochastic', 'Allen–Cahn equation,', 'Lyapunov structure']",[]
"In this paper, reconfigurable intelligent surface (RIS) is employed in a millimeter wave (mmWave) integrated sensing and communications (ISAC) system. To alleviate the multi-hop attenuation, the semi-self sensing RIS approach is adopted, wherein sensors are configured at the RIS to receive the radar echo signal. Focusing on the estimation accuracy, the Crame´´e\acute{\text{e}}over´ start_ARG e end_ARGr-Rao bound (CRB) for estimating the direction-of-the-angles is derived as the metric for sensing performance. A joint optimization problem on hybrid beamforming and RIS phase shifts is proposed to minimize the CRB, while maintaining satisfactory communication performance evaluated by the achievable data rate. The CRB minimization problem is first transformed as a more tractable form based on Fisher information matrix (FIM). To solve the complex non-convex problem, a double layer loop algorithm is proposed based on penalty concave-convex procedure (penalty-CCCP) and block coordinate descent (BCD) method with two sub-problems. Successive convex approximation (SCA) algorithm and second order cone (SOC) constraints are employed to tackle the non-convexity in the hybrid beamforming optimization. To optimize the unit modulus constrained analog beamforming and phase shifts, manifold optimization (MO) is adopted. Finally, the numerical results verify the effectiveness of the proposed CRB minimization algorithm, and show the performance improvement compared with other baselines. Additionally, the proposed hybrid beamforming algorithm can achieve approximately 96% of the sensing performance exhibited by the full digital approach within only a limited number of radio frequency (RF) chains.","['Index', 'Terms: ', 'Integrated sensing and communications, reconfigurable intelligent surface, millimeter wave,', 'Crame´´e\\acute{\\text{e}}over´ start_ARG e end_ARGr-Rao bound, beamforming.']",[]
"Rust relies on its unique ownership mechanism to ensure thread and memory safety. However, numerous potential security vulnerabilities persist in practical applications. New language features in Rust pose new challenges for vulnerability detection. This paper proposes a static deadlock detection method tailored for Rust programs, aiming to identify various deadlock types, including double lock, conflict lock, and deadlock associated with conditional variables. With due consideration for Rust’s ownership and lifetimes, we first complete the pointer analysis. Then, based on the obtained points-to information, we analyze dependencies among variables to identify potential deadlocks. We develop a tool and conduct experiments based on the proposed method. The experimental results demonstrate that our method outperforms existing deadlock detection methods in precision.","['Rust', 'Programs,', 'Static', 'Analysis,', 'Deadlock', 'Detection']","['UniversityShanghaiChina', 'UniversityShanghaiChina', 'UniversityShanghaiChina']"
,[''],[]
"Extinction is the elephant in the room that almost everyone tries to avoid when analyzing optical/IR data: astronomers
tend to find a quick fix for it that the referee will accept, but that does not mean such a solution is correct or even
optimal. In this contribution I address three important issues related to extinction that are commonly ignored and
present current and future solutions for them: [1] Extinction produces non-linear photometric effects, [2] the extinction
law changes between sightlines, and [3] not all families of extinction laws have the same accuracy.",[''],[]
"With the rapid evolution of the Text-to-Image (T2I) model in recent years, their unsatisfactory generation result has become a challenge. However, uniformly refining AI-Generated Images (AIGIs) of different qualities not only limited optimization capabilities for low-quality AIGIs but also brought negative optimization to high-quality AIGIs. To address this issue, a quality-award refiner named Q-Refine111The code will be released on https://github.com/Q-Future/Q-Refine is proposed. Based on the preference of the Human Visual System (HVS), Q-Refine uses the Image Quality Assessment (IQA) metric to guide the refining process for the first time, and modify images of different qualities through three adaptive pipelines. Experimental shows that for mainstream T2I models, Q-Refine can perform effective optimization to AIGIs of different qualities. It can be a general refiner to optimize AIGIs from both fidelity and aesthetic quality levels, thus expanding the application of the T2I generation models.",[''],[]
,[''],[]
"The prediction of rolling bearing lifespan is of significant importance in industrial production. However, the scarcity of high-quality, full lifecycle data has been a major constraint in achieving precise predictions. To address this challenge, this paper introduces the CVGAN model, a novel framework capable of generating one-dimensional vibration signals in both horizontal and vertical directions, conditioned on historical vibration data and remaining useful life. In addition, we propose an autoregressive generation method that can iteratively utilize previously generated vibration information to guide the generation of current signals. The effectiveness of the CVGAN model is validated through experiments conducted on the PHM 2012 dataset. Our findings demonstrate that the CVGAN model, in terms of both MMD and FID metrics, outperforms many advanced methods in both autoregressive and non-autoregressive generation modes. Notably, training using the full lifecycle data generated by the CVGAN model significantly improves the performance of the predictive model. This result highlights the effectiveness of the data generated by CVGans in enhancing the predictive power of these models.",[''],[]
"We prove a van der Corput lemma for non-atomic self-similar measures μ𝜇\muitalic_μ. As an application, we show that the correlations of all finite orders of (xnmod1)n≥1subscriptmodulosuperscript𝑥𝑛1𝑛1(x^{n}\mod 1)_{n\geq 1}( italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_mod 1 ) start_POSTSUBSCRIPT italic_n ≥ 1 end_POSTSUBSCRIPT converge to the Poissonian model for μ𝜇\muitalic_μ-a.e. x𝑥xitalic_x, assuming x>1𝑥1x>1italic_x > 1. We also complete a recent result of Algom, Rodriguez Hertz, and Wang (obtained simultaneously by Baker and Banaji), showing that any self-conformal measure with respect to a non-affine real analytic IFS has polynomial Fourier decay.",[''],[]
,[''],[]
"Shocks are often invoked as heating mechanisms in astrophysical systems, with both adiabatic compression and dissipative heating that leading to temperature increases.
Whilst shocks are reasonably well understood for ideal magnetohydrodynamic (MHD) systems, in many astrophysical plasmas, radiation is an important phenomena, which can allow energy to leave the system. As such, energy becomes non-conservative which can fundamentally change the behaviour of shocks. The energy emitted through optically-thin radiation post-shock can exceed the thermal energy increase, resulting in shocks that reduce the temperature of the medium, i.e., cooling shocks that have a net decrease in temperature across the interface.
In this paper, semi-analytical solutions for radiative shocks are derived to demonstrate that both cooling (temperature decreasing) and heating (temperature increasing) shock solutions are possible in radiative MHD. Numerical simulations of magnetic reconnection with optically-thin radiative losses also yield both heating and cooling shocks in roughly equal abundances. The detected cooling shocks feature a significantly lower pressure jump across the shock than their heating counterparts. The compression at the shock front leads to locally-enhanced radiative losses, resulting in significant cooling within a few grid cells in the upstream and downstream directions.
The presence of temperature-reducing (cooling) shocks is critical in determining the thermal evolution, and heating or cooling, across a wealth of radiative astrophysical plasmas.",[''],['Exeter']
"Discovering the symbols and rules that can be used in long-horizon planning from a robot’s unsupervised exploration of its environment and continuous sensorimotor experience is a challenging task. The previous studies proposed learning symbols from single or paired object interactions and planning with these symbols. In this work, we propose a system that learns rules with discovered object and relational symbols that encode an arbitrary number of objects and the relations between them, converts those rules to Planning Domain Description Language (PDDL), and generates plans that involve affordances of the arbitrary number of objects to achieve tasks. We validated our system with box-shaped objects in different sizes and showed that the system can develop a symbolic knowledge of pick-up, carry, and place operations, taking into account object compounds in different configurations, such as boxes would be carried together with a larger box that they are placed on. We also compared our method with the state-of-the-art methods and showed that planning with the operators defined over relational symbols gives better planning performance compared to the baselines.",[''],[]
"Tree-based models have been successfully applied to a wide variety of tasks, including time series forecasting.
They are increasingly in demand and widely accepted because of their comparatively high level of interpretability. However, many of them suffer from the overfitting problem, which limits their application in real-world decision-making. This problem becomes even more severe in online-forecasting settings where time series observations are incrementally acquired, and the
distributions from which they are drawn may keep changing over time. In this context, we propose a novel method for the online selection of tree-based models using the TreeSHAP explainability method in the task of time series forecasting. We start with an arbitrary set of different tree-based models. Then, we outline a performance-based ranking with a coherent design to make TreeSHAP able to specialize the tree-based forecasters across different regions in the input time series. In this framework, adequate model selection is performed online, adaptively following drift detection in the time series. In addition, explainability is supported on three levels, namely online input importance, model selection, and model output explanation. An extensive empirical study on various real-world datasets demonstrates that our method achieves excellent or on-par results in comparison to the state-of-the-art approaches as well as several baselines.","['Index', 'Terms: ', 'Online', 'Model', 'Selection,', 'Tree-based', 'Models,', 'Time', 'Series', 'Forecasting,', 'TreeSHAP,', 'Explainability']","['matthias.jakobs@tu-dortmund.de', 'amal.saadallah@cs.tu-dortmund.de']"
"We study the effect of a resetting point randomly distributed around the origin on the mean first passage time of a Brownian searcher moving in one dimension. We compare the search efficiency with that corresponding to reset to the origin and find that the mean first passage time of the latter can be larger or smaller than the distributed case, depending on whether the resetting points are symmetrically or asymmetrically distributed. In particular, we prove the existence of an optimal reset rate that minimizes the mean first-passage time for distributed resetting to a finite interval if the target is located outside this interval. When the target position belongs to the resetting interval or it is infinite then no optimal reset rate exists, but there is an optimal resetting interval width or resetting characteristic scale which minimizes the mean first-passage time. We also show that the first-passage density averaged over the resetting points depends on its first moment only. As a consequence, there is an equivalent point such that the first-passage problem with resetting to that point is statistically equivalent to the case of distributed resetting. We end our study by analyzing the fluctuations of the first-passage times for these cases. All our analytical results are verified through numerical simulations.",[''],['Spain.']
"We present a general construction of pseudo-hermitian matrices
in an arbitrary large, but finite dimensional vector space. The positive-definite
metric which ensures reality of the entire spectra of a pseudo-hermitian operator,
and is used for defining a modified inner-product in the associated vector space
is also presented. The construction for an N𝑁Nitalic_N dimensional vector space is based on the generators of S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) in the
fundamental representation and the identity operator. We apply the results to
construct a generic pseudo-hermitian lattice model of size N𝑁Nitalic_N with balanced loss-gain.
The system is amenable to periodic as well as open boundary conditions and by construction,
admits entirely real spectra along with unitary time-evolution. The tight binding and
Su-Schrieffer-Heeger(SSH) models with nearest neighbour(NN) and next-nearest
neighbour(NNN) interaction with balanced loss-gain appear as limiting cases.",[''],['India.']
"Compared to the generations up to 4G, whose main focus was on broadband and
coverage aspects, 5G has expanded the scope of wireless cellular systems towards
embracing two new types of connectivity: massive machine-type communication
(mMTC) and ultra-reliable low-latency communications (URLLC).
This paper will
discuss the possible evolution of these two types of connectivity within the
umbrella of 6G wireless systems. The paper consists of three parts. The first
part deals with the connectivity for a massive number of devices.
While mMTC research in 5G was predominantly focused on the problem of uncoordinated access in the uplink for a
large number of devices,
the traffic patterns in 6G may become more symmetric,
leading to closed-loop massive connectivity.
One of the drivers for this type of
traffic patterns is distributed/decentralized learning and inference.
The second part of the paper will discuss the evolution of wireless connectivity
for critical services. While latency and reliability are tightly coupled in 5G,
6G will support a variety of safety critical control applications with different types of
timing requirements, as evidenced by the emergence of metrics related to
information freshness and information value. Additionally, ensuring ultra-high reliability for safety critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel AI-based techniques, incorporating optimization theory, explainable AI, generative AI and digital twins.
The third part will analyze the coexistence of massive connectivity and critical services.
Specifically, we will consider scenarios in which a massive number of devices need to support
traffic patterns of mixed criticality. This will be followed by a discussion
about the management of wireless resources shared by services with different
criticality.",[''],[]
"Recently, text-to-image (T2I) synthesis has undergone significant advancements, particularly with the emergence of Large Language Models (LLM) and their enhancement in Large Vision Models (LVM), greatly enhancing the instruction-following capabilities of traditional T2I models.
Nevertheless, previous methods focus on improving generation quality but introduce unsafe factors into prompts. We explore that appending specific camera descriptions to prompts can enhance safety performance.
Consequently, we propose a simple and safe prompt engineering method (SSP) to improve image generation quality by providing optimal camera descriptions.
Specifically, we create a dataset from multi-datasets as original prompts. To select the optimal camera, we design an optimal camera matching approach and implement a classifier for original prompts capable of automatically matching. Appending camera descriptions to original prompts generates optimized prompts for further LVM image generation.
Experiments demonstrate that SSP improves semantic consistency by an average of 16% compared to others and safety metrics by 48.9%.",[''],[]
"This paper studies the reduction by symmetry of variational problems on Lie groups and Riemannian homogeneous spaces. We derive the reduced equations of motion in the case of Lie groups endowed with a left-invariant metric, and on Lie groups that admits a bi-invariant metric. We repeated this analysis for Riemannian homogeneous spaces, where we derive the reduced equations by considering an alternative variational problem written in terms of a connection on the horizontal bundle of the underlying Lie group. We study also the case that the underlying Lie group admits a bi-invariant metric, and consider the special case that the homogeneous space is in fact a Riemannian symmetric space. These ideas are applied to geodesics for a rigid body on S⁢O⁢(3)𝑆𝑂3SO(3)italic_S italic_O ( 3 ) to derive geodesic equations on the dual of its Lie algebra (a vector space), the heavy-top in S⁢E⁢(3)𝑆𝐸3SE(3)italic_S italic_E ( 3 ) to derive reduced equations of motion on the unit sphere S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, geodesics on S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT as a Riemannian symmetric space endowed with a bi-invariant metric and optimal control problems for applications to robotic manipulators.",[''],[]
"In this paper, we present a novel generative task: joint scene graph - image generation.
While previous works have explored image generation conditioned on scene graphs or layouts, our task is distinctive and important as it involves generating scene graphs themselves unconditionally from noise, enabling efficient and interpretable control for image generation.
Our task is challenging, requiring the generation of plausible scene graphs with heterogeneous attributes for nodes (objects) and edges (relations among objects), including continuous object bounding boxes and discrete object and relation categories.
We introduce a novel diffusion model, DiffuseSG, that jointly models the adjacency matrix along with heterogeneous node and edge attributes.
We explore various types of encodings for the categorical data, relaxing it into a continuous space.
With a graph transformer being the denoiser, DiffuseSG successively denoises the scene graph representation in a continuous space and discretizes the final representation to generate the clean scene graph.
Additionally, we introduce an IoU regularization to enhance the empirical performance.
Our model significantly outperforms existing methods in scene graph generation on the Visual Genome and COCO-Stuff datasets,
both on standard and newly introduced metrics that better capture the problem complexity.
Moreover, we demonstrate the additional benefits of our model in two downstream applications:
1) excelling in a series of scene graph completion tasks, and
2) improving scene graph detection models by using extra training samples generated from DiffuseSG.",[''],[]
"Given a dynamical system (X,T)𝑋𝑇(X,T)( italic_X , italic_T ) and a family 𝖨⊆𝒫⁢(ω)𝖨𝒫𝜔\mathsf{I}\subseteq\mathcal{P}(\omega)sansserif_I ⊆ caligraphic_P ( italic_ω ) of  “small”  sets of nonnegative integers, a point x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X is said to be 𝖨𝖨\mathsf{I}sansserif_I-strong universal if for each y∈X𝑦𝑋y\in Xitalic_y ∈ italic_X there exists a subsequence (Tn⁢x:n∈A):superscript𝑇𝑛𝑥𝑛𝐴(T^{n}x:n\in A)( italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x : italic_n ∈ italic_A ) of its orbit which is convergent to y𝑦yitalic_y and, in addition, the set of indexes A𝐴Aitalic_A is “not small,” 
that is, A∉𝖨𝐴𝖨A\notin\mathsf{I}italic_A ∉ sansserif_I.
An analoguous definition is given for 𝖨𝖨\mathsf{I}sansserif_I-strong recurrence. In this work, we provide several
structural properties and
relationships between 𝖨𝖨\mathsf{I}sansserif_I-strong universality, 𝖨𝖨\mathsf{I}sansserif_I-strong recurrence, and the corresponding ordinary notions of 𝖨𝖨\mathsf{I}sansserif_I-universality and 𝖨𝖨\mathsf{I}sansserif_I-recurrence.
As applications,
we provide sufficient conditions which ensure the equivalence between the above notions and the property that each nonempty open set contains some cluster point of some orbit. In addition, we show that if T𝑇Titalic_T is a homomorphism on a Fréchet space X𝑋Xitalic_X and there exists a dense set of vectors with null orbit, then for each y∈X𝑦𝑋y\in Xitalic_y ∈ italic_X the set of all vectors x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X such that limn∈ATn⁢x=ysubscript𝑛𝐴superscript𝑇𝑛𝑥𝑦\lim_{n\in A}T^{n}x=yroman_lim start_POSTSUBSCRIPT italic_n ∈ italic_A end_POSTSUBSCRIPT italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x = italic_y for some A⊆ω𝐴𝜔A\subseteq\omegaitalic_A ⊆ italic_ω with nonzero upper asymptotic density is either empty or comeager. 
In the special case of linear dynamical systems on Banach spaces with a dense set of uniformly recurrent vectors, we obtain that T𝑇Titalic_T is upper frequently hypercyclic if and only if there exists a hypercyclic vector x∈X𝑥𝑋x\in Xitalic_x ∈ italic_X for which limn∈ATn⁢x=0subscript𝑛𝐴superscript𝑇𝑛𝑥0\lim_{n\in A}T^{n}x=0roman_lim start_POSTSUBSCRIPT italic_n ∈ italic_A end_POSTSUBSCRIPT italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x = 0 for some A⊆ω𝐴𝜔A\subseteq\omegaitalic_A ⊆ italic_ω with nonzero upper asymptotic density.","['Key words and phrases:', 'Analytic', 'P-ideal; nonlinear dynamical system;', 'Furstenberg families; universality and recurrence; dense orbit.']",[]
"Suppose that {λn}n=1∞superscriptsubscriptsubscript𝜆𝑛𝑛1\{\lambda_{n}\}_{n=1}^{\infty}{ italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is a sequence of distinct positive real numbers
satisfying the conditions inf{λn+1−λn}>0,subscript𝜆𝑛1subscript𝜆𝑛0\{\lambda_{n+1}-\lambda_{n}\}>0,{ italic_λ start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT - italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } > 0 , and
∑n=1∞λn−1<∞.superscriptsubscript𝑛1superscriptsubscript𝜆𝑛1\sum_{n=1}^{\infty}\lambda_{n}^{-1}<\infty.∑ start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT < ∞ .
We prove that the exponential system {eλn⁢t}n=1∞superscriptsubscriptsuperscript𝑒subscript𝜆𝑛𝑡𝑛1\{e^{\lambda_{n}t}\}_{n=1}^{\infty}{ italic_e start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_t end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is hereditarily complete in
the closure of the subspace spanned by {eλn⁢t}n=1∞superscriptsubscriptsuperscript𝑒subscript𝜆𝑛𝑡𝑛1\{e^{\lambda_{n}t}\}_{n=1}^{\infty}{ italic_e start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_t end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT in the space L2⁢(a,b)superscript𝐿2𝑎𝑏L^{2}(a,b)italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_a , italic_b ).
We also give an example of a class of compact non-normal operators defined on this closure which admit spectral synthesis.",[''],[]
,[''],[]
"In recent years, two-stage multimodal object detection methods based on deep learning have garnered significant attention.
However, these existing deep learning methods exhibit a notable decrease in detection accuracy when faced with occluded 3D objects. Additionally, the current two-stage methods struggle to converge quickly during model training.
This paper introduces HPC-Net, a high-precision and rapidly convergent object detection network.
HPC-Net comprises three key components: (1) RP (Replaceable Pooling), which enhances the network’s detection accuracy, speed, robustness, and generalizability by incorporating pooling methods that can be flexibly replaced on 3D voxels and 2D BEV images.
(2) DACConv (Depth Accelerated Convergence Convolution), which integrates two convolution strategies—one for each input feature map and one for each input channel—to maintain the network’s feature extraction ability (i.e., high accuracy) while significantly accelerating convergence speed.
(3) MEFEM (Multi-Scale Extended Receptive Field Feature Extraction Module), which addresses the challenge of low detection accuracy for 3D objects with high occlusion and truncation by employing a multi-scale feature fusion strategy and expanding the receptive field of the feature extraction module.
Our HPC-Net currently holds the top position111As of the paper’s completion date, October 10, 2023 in the KITTI Car 2D Object Detection Ranking. In the KITTI Car 3D Object Detection Ranking, our HPC-Net currently ranks fourth overall and first in hard mode.",[''],[]
"Linear codes are widely studied in coding theory as they have nice applications in distributed storage, combinatorics, lattices, cryptography and so on.
Constructing linear codes with desirable properties is an interesting research topic. In this paper, based on the augmentation technique, we present two families of linear codes from some functions over finite fields. The first family of linear codes is constructed from monomial functions over finite fields. The locality of them is determined and the weight distributions of two subfamilies of the codes are also given. An infinite family of almost optimal recoverable codes and some optimal recoverable codes are obtained from the linear codes. In particular, the two subfamilies of the codes are proved to be both optimally or almost optimally extendable and self-orthogonal.
The second family of linear codes is constructed from weakly regular bent functions over finite fields and their weight distribution is determined. This family of codes is proved to have locality 3 for some cases and is conjectured to have locality 2 for other cases. Particularly, two families of optimal locally recoverable codes are derived from the linear codes. Besides, this family of codes is also proved to be both optimally or almost optimally extendable and self-orthogonal.",[''],[]
"Given an ideal ℐℐ\mathcal{I}caligraphic_I on ω𝜔\omegaitalic_ω and a bounded real sequence 𝒙𝒙\bm{x}bold_italic_x, we denote by core𝒙⁢(ℐ)subscriptcore𝒙ℐ\mathrm{core}_{\bm{x}}(\mathcal{I})roman_core start_POSTSUBSCRIPT bold_italic_x end_POSTSUBSCRIPT ( caligraphic_I ) the smallest interval [a,b]𝑎𝑏[a,b][ italic_a , italic_b ] such that {n∈ω:xn∉[a−ε,b+ε]}∈ℐconditional-set𝑛𝜔subscript𝑥𝑛𝑎𝜀𝑏𝜀ℐ\{n\in\omega:x_{n}\notin[a-\varepsilon,b+\varepsilon]\}\in\mathcal{I}{ italic_n ∈ italic_ω : italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∉ [ italic_a - italic_ε , italic_b + italic_ε ] } ∈ caligraphic_I for all ε>0𝜀0\varepsilon>0italic_ε > 0 (which corresponds to the interval [lim inf𝒙,lim sup𝒙]limit-infimum𝒙limit-supremum𝒙[\,\liminf\bm{x},\limsup\bm{x}\,][ lim inf bold_italic_x , lim sup bold_italic_x ] if ℐℐ\mathcal{I}caligraphic_I is the ideal FinFin\mathrm{Fin}roman_Fin of finite subsets of ω𝜔\omegaitalic_ω).
First, we characterize all the infinite real matrices A𝐴Aitalic_A such that



coreA⁢𝒙⁢(𝒥)=core𝒙⁢(ℐ)subscriptcore𝐴𝒙𝒥subscriptcore𝒙ℐ\mathrm{core}_{A\bm{x}}(\mathcal{J})=\mathrm{core}_{\bm{x}}(\mathcal{I})roman_core start_POSTSUBSCRIPT italic_A bold_italic_x end_POSTSUBSCRIPT ( caligraphic_J ) = roman_core start_POSTSUBSCRIPT bold_italic_x end_POSTSUBSCRIPT ( caligraphic_I )



for all bounded sequences 𝒙𝒙\bm{x}bold_italic_x, provided that 𝒥𝒥\mathcal{J}caligraphic_J is a countably generated ideal on ω𝜔\omegaitalic_ω and A𝐴Aitalic_A maps bounded sequences into bounded sequences.
Such characterization fails if both ℐℐ\mathcal{I}caligraphic_I and 𝒥𝒥\mathcal{J}caligraphic_J are the ideal of asymptotic density zero sets.
Next, we show that such equality is possible for distinct ideals ℐ,𝒥ℐ𝒥\mathcal{I},\mathcal{J}caligraphic_I , caligraphic_J, answering an open question in [J. Math. Anal. Appl. 321 (2006), 515–523]. Lastly, we prove that, if 𝒥=Fin𝒥Fin\mathcal{J}=\mathrm{Fin}caligraphic_J = roman_Fin, the above equality holds for some matrix A𝐴Aitalic_A if and only if ℐ=FinℐFin\mathcal{I}=\mathrm{Fin}caligraphic_I = roman_Fin or ℐ=Fin⊕𝒫⁢(ω)ℐdirect-sumFin𝒫𝜔\mathcal{I}=\mathrm{Fin}\oplus\mathcal{P}(\omega)caligraphic_I = roman_Fin ⊕ caligraphic_P ( italic_ω ).","['Key words and phrases:', 'Ideal convergence; summability; regular matrices;', 'Rudin–Keisler order; ideal core.']",[]
"Let F⁢(t),G⁢(t)∈ℚ⁢(t)𝐹𝑡𝐺𝑡ℚ𝑡F(t),G(t)\in\mathbb{Q}(t)italic_F ( italic_t ) , italic_G ( italic_t ) ∈ blackboard_Q ( italic_t ) be rational functions such that F⁢(t),G⁢(t)𝐹𝑡𝐺𝑡F(t),G(t)italic_F ( italic_t ) , italic_G ( italic_t ) and the constant function 1111 are linearly independent over ℚℚ\mathbb{Q}blackboard_Q, we prove an asymptotic formula for the number of the three term rational function progressions of the form x,x+F⁢(y),x+G⁢(y)𝑥𝑥𝐹𝑦𝑥𝐺𝑦x,x+F(y),x+G(y)italic_x , italic_x + italic_F ( italic_y ) , italic_x + italic_G ( italic_y ) in subsets of 𝔽psubscript𝔽𝑝\mathbb{F}_{p}blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT. The main new ingredient is an algebraic geometry version of PET induction that bypasses Weyl’s differencing. This answers a question of Bourgain and Chang.",[''],[]
"Controlling molecular reactivity by shaped laser pulses is a long-standing goal in chemistry. Here we suggest a direct optimal control approach which combines external pulse optimization with other control parameters arising in the upcoming field of vibro-polaritonic chemistry, for enhanced controllability
The direct optimal control approach is characterized by a simultaneous simulation and optimization paradigm, meaning that the equations of motion are discretized and converted into a set of holonomic constraints for a nonlinear optimization problem given by the control functional. Compared with indirect optimal control this procedure offers great flexibility such as final time or Hamiltonian parameter optimization. Simultaneous direct optimal control (SimDOC) theory will be applied to a model system describing H-atom transfer in a lossy Fabry-Pérot cavity under vibrational strong coupling conditions. Specifically, optimization of the cavity coupling strength and thus of the control landscape will be demonstrated.",[''],"['Germany', 'Germany', 'Germany', 'Germany', 'Germany']"
"In this paper we consider a fourth order nonlinear parabolic delayed problem
modelling a quasi-instantaneous turn-over of linkages in the context
of cell-motility.
The model depends on a small
parameter ε𝜀\varepsilonitalic_ε which represents a typical time scale of the memory effect.
We first prove global existence and uniqueness of solutions for ε𝜀\varepsilonitalic_ε fixed.
This is achieved by combining suitable fixed-point and energy arguments and by uncovering a nonlocal in time, integral conserved quantity.
After giving a complete classification of steady states in terms of elliptic functions,
we next show that every solution converges to a steady state as t→∞→𝑡t\to\inftyitalic_t → ∞.
When ε→0→𝜀0\varepsilon\to 0italic_ε → 0,
we then establish convergence results on finite time intervals, showing
that the solution tends in a suitable sense
towards the solution of a parabolic problem without delay.
Moreover, we establish the convergence of energies as ε→0→𝜀0\varepsilon\to 0italic_ε → 0,
which enables us to show
that, for ε𝜀\varepsilonitalic_ε small enough,
the ε𝜀\varepsilonitalic_ε-dependent
problem inherits part of the large time asymptotics of the limiting parabolic problem.",[''],[]
"In recent years, the amalgamation of satellite communications and aerial platforms into space-air-ground integrated network (SAGINs) has emerged as an indispensable area of research for future communications due to the global coverage capacity of low Earth orbit (LEO) satellites and the flexible Deployment of aerial platforms. This paper presents a deep reinforcement learning (DRL)-based approach for the joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within SAGINs. The proposed system considers the presence of multiple satellites, clouds and unmanned aerial vehicles (UAVs). The multiple tasks from ground users are modeled as directed acyclic graphs (DAGs). With the goal of reducing energy consumption and latency in MEC, we propose a novel multi-agent algorithm based on DRL that optimizes both the offloading strategy and the allocation of resources in the MEC infrastructure within SAGIN. A hybrid action algorithm is utilized to address the challenge of hybrid continuous and discrete action space in the proposed problems, and a decision-assisted DRL method is adopted to reduce the impact of unavailable actions in the training process of DRL. Through extensive simulations, the results demonstrate the efficacy of the proposed learning-based scheme, the proposed approach consistently outperforms benchmark schemes, highlighting its superior performance and potential for practical applications.","['Index', 'Terms: ', 'Space-air-ground integrated networks, edge computing, resource allocation, unmanned aerial vehicle, deep reinforcement learning.']",[]
"Including Artificial Neural Networks (ANNs) in embedded systems at the edge allows applications to exploit Artificial Intelligence (AI) capabilities directly within devices operating at the network periphery, facilitating real-time decision-making. Especially critical in domains such as autonomous vehicles, industrial automation, and healthcare, the use of ANNs can enable these systems to process substantial data volumes locally, thereby reducing latency and power consumption. Moreover, it enhances privacy and security by containing sensitive data within the confines of the edge device.
The adoption of Spiking Neural Networks (SNNs) in these environments offers a promising computing paradigm, mimicking the behavior of biological neurons and efficiently handling dynamic, time-sensitive data. However, deploying efficient SNNs in resource-constrained edge environments requires hardware accelerators, such as solutions based on Field Programmable Gate Arrays (FPGAs), that provide high parallelism and reconfigurability.
This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized SNNs accelerators on FPGAs for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNNs, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Dataset (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGAs, and power consumption, draining only 180mW for a complete inference on an input image. The latency is comparable to the ones observed in the state-of-the-art, with 780μ𝜇\muitalic_μs/img. To the authors’ knowledge, Spiker+ is the first SNNs accelerator tested on the SHD. In this case, the accelerator requires 18,268 logic cells and 51 BRAMs, with an overall power consumption of 430mW and a latency of 54 μ𝜇\muitalic_μs for a complete inference on input data. This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications.","['Index', 'Terms: ', 'Spiking', 'Neural', 'Networks,', 'LIF,', 'FPGA,', 'Neuromorphic accelerator,', 'Edge computing,', 'Artificial', 'Intelligence,', 'Frugal', 'AI.']",[]
"Plane-based Geometric Algebra (PGA) has revealed points in a d𝑑ditalic_d-dimensional pseudo-Euclidean space ℝp,q,1subscriptℝ𝑝𝑞1\mathbb{R}_{p,q,1}blackboard_R start_POSTSUBSCRIPT italic_p , italic_q , 1 end_POSTSUBSCRIPT to be represented by d𝑑ditalic_d-blades rather than vectors.
This discovery allows points to be factored into d𝑑ditalic_d orthogonal hyperplanes, establishing points as pseudoscalars of a local geometric algebra ℝp⁢qsubscriptℝ𝑝𝑞\mathbb{R}_{pq}blackboard_R start_POSTSUBSCRIPT italic_p italic_q end_POSTSUBSCRIPT.
Astonishingly, the non-uniqueness of this factorization reveals the existence of a local Spin⁢(p,q)Spin𝑝𝑞\textup{Spin}({p,q})Spin ( italic_p , italic_q ) geometric gauge group at each point.
Moreover, a point can alternatively be factored into a product of the elements of the Cartan subalgebra of 𝔰⁢𝔭⁢𝔦⁢𝔫⁢(p,q)𝔰𝔭𝔦𝔫𝑝𝑞\mathfrak{spin}({p,q})fraktur_s fraktur_p fraktur_i fraktur_n ( italic_p , italic_q ), which are traditionally used to label spinor representations.
Therefore, points reveal previously hidden geometric foundations for some of quantum field theory’s mysteries.
This work outlines the impact of PGA on the study of spinor representations in any number of dimensions, and is the first in a research programme exploring the consequences of this insight.",[''],[]
"This work presents a novel semantic transmission framework in wireless networks, leveraging the joint processing technique. Our framework enables multiple cooperating base stations to efficiently transmit semantic information to multiple users simultaneously. To enhance the semantic communication efficiency of the transmission framework, we formulate an optimization problem with the objective of maximizing the semantic spectral efficiency of the framework and propose a low-complexity dynamic semantic mapping and resource allocation algorithm. This algorithm, based on deep reinforcement learning and alternative optimization, achieves near-optimal performance while reducing computational complexity. Simulation results validate the effectiveness of the proposed algorithm, bridging the research gap and facilitating the practical implementation of semantic communication systems.","['Index', 'Terms: ', 'Semantic communication, spectral efficiency, joint processing, resource allocation, deep reinforcement learning.']",[]
,[''],[]
"This paper introduces HAAQI-Net, a non-intrusive deep learning model for music quality assessment tailored to hearing aid users. In contrast to traditional methods like the Hearing Aid Audio Quality Index (HAAQI), HAAQI-Net utilizes a Bidirectional Long Short-Term Memory (BLSTM) with attention. It takes an assessed music sample and a hearing loss pattern as input, generating a predicted HAAQI score. The model employs the pre-trained Bidirectional Encoder representation from Audio Transformers (BEATs) for acoustic feature extraction. Comparing predicted scores with ground truth, HAAQI-Net achieves a Longitudinal Concordance Correlation (LCC) of 0.92570.92570.92570.9257, Spearman’s Rank Correlation Coefficient (SRCC) of 0.93940.93940.93940.9394, and Mean Squared Error (MSE) of 0.00800.00800.00800.0080. Notably, this high performance comes with a substantial reduction in inference time: from 62.5262.5262.5262.52 seconds (by HAAQI) to 2.712.712.712.71 seconds (by HAAQI-Net), serving as an efficient music quality assessment model for hearing aid users.",[''],[]
,[''],[]
,[''],[]
"We present a new high-probability PAC-Bayes oracle bound for unbounded losses. This result can be understood as a PAC-Bayes version of the Chernoff bound. The proof technique relies on uniformly bounding the tail of certain random variable based on the Cramér transform of the loss. We highlight two applications of our main result. First, we show that our bound solves the open problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we show that our approach allows working with flexible assumptions on the loss function, resulting in novel bounds that generalize previous ones and can be minimized to obtain Gibbs-like posteriors.","['Machine', 'Learning,', 'ICML']",[]
"We study search games between a mobile Searcher and an immobile Hider in which the Searcher aims to minimize some payoff, which is either the time to find the Hider (the search time), or a normalized search time. We consider a new setting in which the Searcher has some potentially erroneous information, or prediction on the Hider’s position. Specifically, we study tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and the robustness (i.e., the worst case expected payoff assuming that the prediction is adversarially generated). We show how to apply this framework in search games over both discrete and continuous, as well as bounded and unbounded spaces. Specifically, we prove optimal consistency/robustness tradeoffs for three fundamental search games, namely searching in a number of discrete locations, expanding search in a tree network, and searching in the infinite line. Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations.",[''],"['University', 'School', 'Munich']"
"The growing trend towards specialization has led to a proliferation of accelerators and alternative processing devices. When embedded in conventional computer architectures, the PCIe link connecting the CPU to these devices becomes a bottleneck. Several proposals for alternative designs have been put forward, with these efforts having now converged into the Compute Express Link (CXL) specification. CXL is an interconnect protocol on top of PCIe with a more modern and powerful interface. While still on version 1.0 in terms of commercial availability, the potential of CXL to radically change the underlying architecture has already attracted considerable attention. This attention has been focused mainly on the possibility of using CXL to build a shared memory system among the machines in a rack. We argue, however, that such benefits are just the beginning of more significant changes that will have a major impact on database engines and data processing systems. In a nutshell, while the cloud favored scale-out approaches, CXL brings back scale-up architectures. In the paper we describe how CXL enables such architectures, and the research challenges associated with the emerging scale-up, heterogeneous hardware platforms.",[''],"['Switzerland', 'Switzerland']"
"One unique feature of nonlinear dynamical systems is the existence of superharmonic and subharmonic resonances in addition to primary resonances. In this study, an effective vibration testing methodology is introduced for the experimental identification of these secondary resonances. The proposed method relies on phase-locked loop control combined with adaptive filters for online Fourier decomposition. To this end, the concept of a resonant phase lag is exploited to define the target phase lag to be followed during the experimental continuation process. The method is demonstrated using two systems featuring cubic nonlinearities, namely a numerical Duffing oscillator and a physical experiment comprising a clamped-clamped thin beam. The obtained results highlight that the control scheme can accurately characterize secondary resonances as well as track their backbone curves.
A particularly salient feature of the developed algorithm is that, starting from the rest position, it facilitates an automatic and smooth dynamic state transfer toward one point of a subharmonic isolated branch, hence, inducing branch switching.",[''],[]
"In this paper, we propose a model enabling the creation of a social graph corresponding to real society. The procedure uses data describing the real social relations in the community, like marital status or number of kids. Results show the power-law behavior of the distribution of links and, typical for small worlds, the independence of the clustering coefficient on the size of the graph.",[''],"['Poland', 'Poland']"
"For a Fano manifold,
We consider the geometric quantization of the Kähler-Ricci flow
and the associated entropy functional.
Convergence to the original flow and entropy is established.
It is also possible to
formulate the finite-dimensional analogue of the optimal degeneration for the anti-canonical polarization.",[''],[]
"Context
It is commonly accepted that the quality of requirements specifications impacts subsequent software engineering activities.
However, we still lack empirical evidence to support organizations in deciding whether their requirements are good enough or impede subsequent activities.
Objective
We aim to contribute empirical evidence to the effect that requirements quality defects have on a software engineering activity that depends on this requirement.
Method
We replicate a controlled experiment in which 25 participants from industry and university generate domain models from four natural language requirements containing different quality defects.
We evaluate the resulting models using both frequentist and Bayesian data analysis.
Results
Contrary to our expectations, our results show that the use of passive voice only has a minor impact on the resulting domain models.
The use of ambiguous pronouns, however, shows a strong effect on various properties of the resulting domain models.
Most notably, ambiguous pronouns lead to incorrect associations in domain models.
Conclusion
Despite being equally advised against by literature and frequentist methods, the Bayesian data analysis shows that the two investigated quality defects have vastly different impacts on software engineering activities and, hence, deserve different levels of attention.
Our employed method can be further utilized by researchers to improve reliable, detailed empirical evidence on requirements quality.","['Requirements', 'Engineering', 'Requirements', 'Quality', 'Experiment', 'Replication', 'Bayesian', 'Data', 'Analysis']",[]
"Marker code is an effective coding scheme to protect data from insertions and deletions. It has potential applications in future storage systems, such as DNA storage and racetrack memory. When decoding marker codes, perfect channel state information (CSI), i.e., insertion and deletion probabilities, are required to detect insertion and deletion errors. Sometimes, the perfect CSI is not easy to obtain or the accurate channel model is unknown. Therefore, it is deserved to develop detecting algorithms for marker code without the knowledge of perfect CSI. In this paper, we propose two CSI-agnostic detecting algorithms for marker code based on deep learning. The first one is a model-driven deep learning method, which deep unfolds the original iterative detecting algorithm of marker code. In this method, CSI become weights in neural networks and these weights can be learned from training data. The second one is a data-driven method which is an end-to-end system based on the deep bidirectional gated recurrent unit network. Simulation results show that error performances of the proposed methods are significantly better than that of the original detection algorithm with CSI uncertainty. Furthermore, the proposed data-driven method exhibits better error performances than other methods for unknown channel models.","['Index', 'Terms: ', 'Bidirectional gated recurrent unit (bi-GRU), deep unfolding, insertions and deletions, marker codes, model-driven deep learning.']",[]
"TOPCAT is a desktop GUI tool for working with tabular data
such as source catalogues. Among other capabilities it provides
a rich set of visualisation options suitable for interactive
exploration of large datasets.
The latest release introduces a Corner Plot window which displays
a grid of linked scatter-plot-like and histogram-like plots for
all pair and single combinations from a supplied list of coordinates.",[''],[]
"In the present study, we perform direct numerical simulations of compressible turbulent boundary
layers at the free stream Mach number of 2∼6similar-to262\sim 62 ∼ 6 laden with dilute phase of spherical particles
to investigate the Mach number effects on particle transport and dynamics.
Most of the phenomena observed and well-recognized for inertia particles in incompressible
wall-bounded turbulent flows, such as the near-wall preferential accumulation and clustering
beneath the low-speed streaks, the flatter mean velocity profiles and the trend variation of the
particle velocity fluctuations, are identified in the compressible turbulent boundary layer as well.
However, we find that the compressibility effects are significant for large inertia particles.
As the Mach number increases, the near-wall accumulation and the small-scale clustering
are alleviated, which is probably caused by the variation of the fluid density and viscosity
that are crucial to particle dynamics.
This can be affected by the fact that the forces acting on the particles with
the viscous Stokes number greater than 500 are modulated by the comparatively
high particle Mach numbers in the near-wall region.
This is also the reason for the abatement of the streamwise particle velocity fluctuation
intensities with the Mach numbers.",[''],['China']
"The Job shop scheduling problem (JSSP) plays a pivotal role in industrial applications,
such as signal processing (SP) and steel manufacturing,
involving sequencing machines and jobs to maximize scheduling
efficiency. Before, JSSP was solved using manually defined circuits by variational quantum algorithm (VQA).
Finding a good circuit architecture is task-specific and time-consuming.
Differentiable quantum architecture search (DQAS) is a gradient-based framework
that can automatically design circuits.
However, DQAS is only tested on quantum approximate optimization algorithm (QAOA)
and error mitigation tasks.
Whether DQAS applies to JSSP based on a more flexible algorithm, such as
variational quantum eigensolver (VQE), is still open for optimization problems.
In this work, we redefine the operation pool and extend DQAS to a framework JSSP-DQAS
by evaluating circuits to
generate circuits for JSSP automatically.
The experiments conclude that JSSP-DQAS can automatically find
noise-resilient circuit architectures that perform much better than manually designed
circuits. It helps to improve the efficiency of solving JSSP.",[''],[]
"Utilizing the recently established connection between Palatini-like gravity and linear Generalized Uncertainty Principle (GUP) models, we have formulated an approach that facilitates the examination of Bose gases. Our primary focus is on the ideal Bose-Einstein condensate and liquid helium, chosen as illustrative examples to underscore the feasibility of tabletop experiments in assessing gravity models. The non-interacting Bose-Einstein condensate imposes constraints on linear GUP and Palatini f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity (Eddington-inspired Born-Infeld gravity) within the ranges of −1012≲σ≲3×1024⁢ s/kg mless-than-or-similar-tosuperscript1012𝜎less-than-or-similar-to3superscript1024 skg m-10^{12}\lesssim\sigma\lesssim 3\times 10^{24}{\text{ s}}/{\text{kg m}}- 10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT ≲ italic_σ ≲ 3 × 10 start_POSTSUPERSCRIPT 24 end_POSTSUPERSCRIPT s / kg m and −10−1≲β¯≲1011⁢ m2less-than-or-similar-tosuperscript101¯𝛽less-than-or-similar-tosuperscript1011superscript m2-10^{-1}\lesssim\bar{\beta}\lesssim 10^{11}\text{ m}^{2}- 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≲ over¯ start_ARG italic_β end_ARG ≲ 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (−4×10−1≲ϵ≲4×1011⁢ m2less-than-or-similar-to4superscript101italic-ϵless-than-or-similar-to4superscript1011superscript m2-4\times 10^{-1}\lesssim\epsilon\lesssim 4\times 10^{11}\text{ m}^{2}- 4 × 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≲ italic_ϵ ≲ 4 × 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT), respectively.
In contrast, the properties of liquid helium suggest more realistic bounds, specifically −1023≲σ≲1023⁢ s/kg mless-than-or-similar-tosuperscript1023𝜎less-than-or-similar-tosuperscript1023 skg m-10^{23}\lesssim\sigma\lesssim 10^{23}{\text{ s}}/{\text{kg m}}- 10 start_POSTSUPERSCRIPT 23 end_POSTSUPERSCRIPT ≲ italic_σ ≲ 10 start_POSTSUPERSCRIPT 23 end_POSTSUPERSCRIPT s / kg m and −109≲β¯≲109⁢ m2less-than-or-similar-tosuperscript109¯𝛽less-than-or-similar-tosuperscript109superscript m2-10^{9}\lesssim\bar{\beta}\lesssim 10^{9}\text{ m}^{2}- 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT ≲ over¯ start_ARG italic_β end_ARG ≲ 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. Additionally, we argue that the newly developed method employing Earth seismic waves provides improved constraints for quantum and modified gravity by approximately one order of magnitude.",[''],['Spain']
,[''],[]
"We study the problem of estimating the frequencies of several complex sinusoids with constant amplitude (CA) (also called constant modulus) from multichannel signals of their superposition. To exploit the CA property for frequency estimation in the framework of atomic norm minimization (ANM), we introduce multiple positive-semidefinite block matrices composed of Hankel and Toeplitz submatrices and formulate the ANM problem as a convex structured low-rank approximation (SLRA) problem. The proposed SLRA is a semidefinite programming and has substantial differences from existing such formulations without using the CA property. The proposed approach is termed as SLRA-based ANM for CA frequency estimation (SACA). We provide theoretical guarantees and extensive simulations that validate the advantages of SACA.",[''],[]
"In current studies for testing Bell inequalities at colliders, the reconstruction of spin correlations from scattering cross-sections relies on the bilinear form of the spin correlations, and not all local hidden variable models (LHVMs) have such a property. To demonstrate that a general LHVM cannot be rule out via scattering cross-section data, we propose a specific LHVM, which can exactly duplicate the same scattering cross-section for particle production and decay as the standard quantum theory, making it indistinguishable at colliders in principle. Despite of this, we find that reconstructing spin correlations through scattering cross-sections can still rule out a broad class of LHVMs, e.g., those models employing classical spin correlations as a surrogate for quantum spin correlations.",[''],"['China', 'China', 'China', 'China']"
"Multi-class colorectal tissue classification is a challenging problem that is typically addressed in a setting, where it is assumed that ample amounts of training data is available. However, manual annotation of fine-grained colorectal tissue samples of multiple classes, especially the rare ones like stromal tumor and anal cancer is laborious and expensive. To address this, we propose a knowledge distillation-based approach, named KD-CTCNet, that effectively captures local texture information from few tissue samples, through a distillation loss, to improve the standard CNN features. The resulting enriched feature representation achieves improved classification performance specifically in low data regimes. Extensive experiments on two public datasets of colorectal tissues reveal the merits of the proposed contributions, with a consistent gain achieved over different approaches across low data settings.
The code and models are publicly available on GitHub.","['Colorectal', 'Tissue', 'Classification', 'Low', 'Data', 'Regimes']",[]
"The electromagnetic inverse problem has long been a research hotspot. This study aims to reverse radar view angles in synthetic aperture radar (SAR) images given a target model. Nonetheless, the scarcity of SAR data, combined with the intricate background interference and imaging mechanisms, limit the applications of existing learning-based approaches. To address these challenges, we propose an interactive deep reinforcement learning (DRL) framework, where an electromagnetic simulator named differentiable SAR render (DSR) is embedded to facilitate the interaction between the agent and the environment, simulating a human-like process of angle prediction. Specifically, DSR generates SAR images at arbitrary view angles in real time. And the differences in sequential and semantic aspects between the view angle-corresponding images are leveraged to construct the state space in DRL, which effectively suppress the complex background interference, enhance the sensitivity to temporal variations, and improve the capability to capture fine-grained information. Additionally, in order to maintain the stability and convergence of our method, a series of reward mechanisms, such as memory difference, smoothing and boundary penalty, are utilized to form the final reward function. Extensive experiments performed on both simulated and real datasets demonstrate the effectiveness and robustness of our proposed method. When utilized in the cross-domain area, the proposed method greatly mitigates inconsistency between simulated and real domains, outperforming reference methods significantly.","['Index', 'Terms: ', 'Deep reinforcement learning (DRL), differentiable', 'SAR render (DSR), synthetic aperture radar (SAR), radar view angles']",[]
"In this article, we construct a 16161616-dimensional sedenion-like associative algebra, which is an even subalgebra of 25superscript252^{5}2 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT-dimensional Clifford algebra C⁢l5,0𝐶subscript𝑙50Cl_{5,0}italic_C italic_l start_POSTSUBSCRIPT 5 , 0 end_POSTSUBSCRIPT. We define the norm on sedenion-like algebra and show that its sixteen-dimensional elements preserves the norm relation ∥S⁢T∥=∥S∥⁢∥T∥delimited-∥∥𝑆𝑇delimited-∥∥𝑆delimited-∥∥𝑇\lVert ST\rVert=\lVert S\rVert\lVert T\rVert∥ italic_S italic_T ∥ = ∥ italic_S ∥ ∥ italic_T ∥ under the condition Sr⁢Sd†+Sr†⁢Sd=0subscript𝑆𝑟superscriptsubscript𝑆𝑑†superscriptsubscript𝑆𝑟†subscript𝑆𝑑0S_{r}S_{d}^{\dagger}+S_{r}^{\dagger}S_{d}=0italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT + italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = 0, where Sr,Sdsubscript𝑆𝑟subscript𝑆𝑑S_{r},~{}S_{d}italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT denote the real and dual part of an octonion-like number S𝑆Sitalic_S respectively and S†superscript𝑆†S^{\dagger}italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT is the transpose of S𝑆Sitalic_S. The elements of this sedenion-like algebra can be written as dual octonion like numbers called split bioctonion-like algebra and S⁢S†𝑆superscript𝑆†SS^{\dagger}italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT is commutative [i.e. S⁢S†=S†⁢S𝑆superscript𝑆†superscript𝑆†𝑆SS^{\dagger}=S^{\dagger}Sitalic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT = italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_S and (S⁢S†)⁢T=T⁢(S⁢S†)𝑆superscript𝑆†𝑇𝑇𝑆superscript𝑆†(SS^{\dagger})T=T(SS^{\dagger})( italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ) italic_T = italic_T ( italic_S italic_S start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT )], for any two octonion-like/sedenion-like numbers S𝑆Sitalic_S and T𝑇Titalic_T. We define the operations coproduct △△\bigtriangleup△, counit ϵitalic-ϵ\epsilonitalic_ϵ and antipode S𝑆Sitalic_S on octonion-like/sedenion-like algebra to construct the Hopf algebra structure on it. We also show that 8888-dimensional octonion-like associative seminormed division algebra is a ℤ24/2superscriptsubscriptℤ242\mathbb{Z}_{2}^{4}/2blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT / 2-graded quasialgebra and 16161616 dimensional sedenion-like algebra is a ℤ25/2superscriptsubscriptℤ252\mathbb{Z}_{2}^{5}/2blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT / 2-graded quasialgebra.",[''],[]
,[''],[]
"Federated Learning (FL) permits different parties to collaboratively train a global model without disclosing their respective local labels. A crucial step of FL, that of aggregating local models to produce the global one, shares many similarities with public decision-making, and elections in particular. In that context, a major weakness of FL, namely its vulnerability to poisoning attacks, can be interpreted as a consequence of the one person one vote (henceforth 1p1v) principle underpinning most contemporary aggregation rules.
In this paper, we propose FedQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. Our theoretical analysis establishes that FedQV is a truthful mechanism in which bidding according to one’s true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FedQV against poisoning attacks. It also shows that combining FedQV with unequal voting “budgets” according to a reputation score increases its performance benefits even further. Finally, we show that FedQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.",[''],[]
The effect of a finite volume presents itself both in heavy ion experiments as well as in recent model calculations. The magnitude is sensitive to the proximity of a nearby critical point. We calculate the finite volume effects at finite temperature in continuum QCD using lattice simulations. We focus on the vicinity of the chiral crossover. We investigate the impact of finite volumes at zero and small chemical potentials on the QCD transition through the chiral observables.,[''],[]
"In this paper, we provide some characterizations of strong pseudoconvexity by the boundary behavior of intrinsic invariants for smoothly bounded pseudoconvex domains of finite type in ℂ2superscriptℂ2\mathbb{C}^{2}blackboard_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. As a consequence, if such domain is biholomorphically equivalent to a quotient of the unit ball, then it is strongly pseudoconvex.","['Key words and phrases:', 'Strong pseudoconvexity,', 'Holomorphic sectional curvature,', 'Pseudoconvex domains,', 'Finite type']",[]
,[''],[]
"Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration’s non-stationary nature.
This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing’s inherent and operational parameters. We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. Based on this, we design a time-frequency convolutional neural network (TF-CNN) to diagnose various faults in rolling-element bearings.
Our experimental findings undeniably demonstrate the superior performance of TF-CNN in comparison to recently developed techniques. They also assert its versatility in capturing fault-relevant non-stationary features that couple with speed changes and show its exceptional resilience to noise, consistently surpassing competing methods across various signal-to-noise ratios and performance metrics. Altogether, the TF-CNN achieves substantial accuracy improvements up to 15%, in severe noise conditions.","['Index', 'Terms: ', 'Bearing fault, damage detection, deep learning, time-frequency analysis, variable speed.']",[]
"We present En3D, an enhanced generative scheme for sculpting high-quality 3D human avatars. Unlike previous works that rely on scarce 3D datasets or limited 2D collections with imbalanced viewing angles and imprecise pose priors, our approach aims to develop a zero-shot 3D generative scheme capable of producing visually realistic, geometrically accurate and content-wise diverse 3D humans without relying on pre-existing 3D or 2D assets. To address this challenge, we introduce a meticulously crafted workflow that implements accurate physical modeling to learn the enhanced 3D generative model from synthetic 2D data. During inference, we integrate optimization modules to bridge the gap between realistic appearances and coarse 3D shapes. Specifically, En3D comprises three modules: a 3D generator that accurately models generalizable 3D humans with realistic appearance from synthesized balanced, diverse, and structured human images; a geometry sculptor that enhances shape quality using multi-view normal constraints for intricate human anatomy; and a texturing module that disentangles explicit texture maps with fidelity and editability, leveraging semantical UV partitioning and a differentiable rasterizer. Experimental results show that our approach significantly outperforms prior works in terms of image quality, geometry accuracy and content diversity. We also showcase the applicability of our generated avatars for animation and editing, as well as the scalability of our approach for content-style free adaptation.",[''],[]
"We describe a basis for free Lie superalgebras which uses the theory of basic
commutators. The only description of bases for free Lie superalgbras that I
have found in the literature is in the book Infinite Dimensional Lie
Superalgebras by Bahturin et al. [1]. Their bases make use of the theory of
Shirshov bases in free Lie algebras, and I believe that there is a case for
writing up an alternative approach using basic commutators. An additional reason
for publishing this note is that I use the basis described here in a
forthcoming paper where I prove that 5-Engel Lie algebras of characteristic
p𝑝pitalic_p for p>7𝑝7p>7italic_p > 7 are nilpotent of class at most 11.",[''],[]
"Simulating high-resolution Synthetic Aperture Radar (SAR) images in complex scenes has consistently presented a significant research challenge. The development of a microwave-domain surface scattering model and its reversibility are poised to play a pivotal role in enhancing the authenticity of SAR image simulations and facilitating the reconstruction of target parameters. Drawing inspiration from the field of computer graphics, this paper proposes a surface microwave rendering model that comprehensively considers both Specular and Diffuse contributions. The model is analytically represented by the coherent spatially varying bidirectional scattering distribution function (CSVBSDF) based on the Kirchhoff approximation (KA) and the perturbation method (SPM). And SAR imaging is achieved through the synergistic combination of ray tracing and fast mapping projection techniques. Furthermore, a differentiable ray tracing (DRT) engine based on SAR images was constructed for CSVBSDF surface scattering parameter learning. Within this SAR image simulation engine, the use of differentiable reverse ray tracing enables the rapid estimation of parameter gradients from SAR images. The effectiveness of this approach has been validated through simulations and comparisons with real SAR images. By learning the surface scattering parameters, substantial enhancements in SAR image simulation performance under various observation conditions have been demonstrated.","['Index', 'Terms: \nbidirectional scattering distribution function, differentiable ray tracing, surface microwave rendering model, synthetic aperture radar (SAR).']",[]
"This paper studies the fundamental limit of semantic communications over the discrete memoryless channel. We consider the scenario to send a semantic source consisting of an observation state and its corresponding semantic state, both of which are recovered at the receiver. To derive the performance limitation, we adopt the semantic rate-distortion function (SRDF) to study the relationship among the minimum compression rate, observation distortion, semantic distortion, and channel capacity. For the case with unknown semantic source distribution, while only a set of the source samples is available, we propose a neural-network-based method by leveraging the generative networks to learn the semantic source distribution. Furthermore, for a special case where the semantic state is a deterministic function of the observation, we design a cascade neural network to estimate the SRDF. For the case with perfectly known semantic source distribution, we propose a general Blahut-Arimoto algorithm to effectively compute the SRDF. Finally, experimental results validate our proposed algorithms for the scenarios with ideal Gaussian semantic source and some practical datasets.","['Index', 'Terms: ', 'Semantic communications, semantic rate-distortion, generative network,', 'Blahut-Arimoto algorithm.']",[]
"Context:Plasmoid-mediated reconnection plays a fundamental role in different solar atmospheric phenomena.
Numerical reproduction of this process is therefore essential for developing robust solar models.
Aims:Our goal is to assess plasmoid-mediated reconnection across various numerical resistivity models in order to investigate how plasmoid numbers and reconnection rates depend on the Lundquist number.
Methods:We used the Bifrost code to drive magnetic reconnection in a 2D coronal fan-spine topology, carrying out a parametric study of several experiments with different numerical resolution and resistivity models. We employed three anomalous resistivity models: (1) the original hyper-diffusion from Bifrost, (2) a resistivity proportional to current density, and (3) a resistivity quadratically proportional to electron drift velocity. For comparisons, experiments with uniform resistivity were also run.
Results:Plasmoid-mediated reconnection is obtained in most of the experiments. With uniform resistivity, increasing the resolution reveals higher plasmoid frequency with weaker scaling to the Lundquist number, obtaining 7.9-12 plasmoids per minute for SL∈[1.8×104,2.6×105]subscript𝑆L1.8superscript1042.6superscript105S_{\mathrm{L}}\in[1.8\times 10^{4},2.6\times 10^{5}]italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT ∈ [ 1.8 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT , 2.6 × 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT ] with a scaling of SL0.210superscriptsubscript𝑆L0.210S_{\mathrm{L}}^{0.210}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.210 end_POSTSUPERSCRIPT in the highest-resolution resistivity cases, transcending into Petschek reconnection in the high-SLsubscript𝑆LS_{\mathrm{L}}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT limit (where the diffusive effects of the resistivity become small compared to the non-uniform viscosity)
and Sweet-Parker reconnection in the low-SLsubscript𝑆LS_{\mathrm{L}}italic_S start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT limit. Anomalous resistivity leads to similar results even with lower resolution. The drift-velocity-dependent resistivity excellently reproduces Petschek reconnection for any Lundquist number, and similar results are seen with resistivity
proportional to current-density though with slightly lower reconnection rates and plasmoid numbers.
Among the different resistivity models applied on the given numerical resolution, the hyper-diffusion model reproduced plasmoid characteristics in closest resemblance to those obtained with uniform resistivity at a significantly higher resolution.
Conclusions:","['Key', 'Words.: \n\nmagnetohydrodynamics (MHD) –\nmagnetic reconnection –\nmethods: numerical –', 'Sun: atmosphere –', 'Sun: corona –', 'Sun: magnetic fields']",[]
,[''],[]
"Modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of Vision-Language Self-Supervised Learning (VL-SSL) with large pre-trained models to learn versatile medical vision representations. However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders. To address both issues, we introduce the backbone-agnostic Adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight Adaptor module for cross-modal learning. Experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90%percent9090\%90 % compared to current pre-training approaches. Notably, when fine-tuned with just 1%percent11\%1 % of data, Adaptor outperforms several Transformer-based methods trained on full datasets in medical image segmentation.",[''],[]
"Deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides. Conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment. To overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory. Our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (DBH). Compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas. We evaluated our method on a comprehensive dataset of 400 trees and achieved a DBH estimation accuracy with an error rate of less than 2.5%. Our method holds significant potential for substantially improving forest management practices. By enhancing the accuracy and efficiency of tree inventory, our model empowers urban management to mitigate the adverse effects of deforestation and climate change.","['Index', 'Terms: ', 'Urban deforestation, street trees inventory, deep learning, mobile phones,', 'DBH,', 'ABG,', 'CNN']","['asim.khan@ku.ac.ae', '1601005@namal.edu.pk', 'aulhaq@csu.edu.au', 'iqbal.gondal@rmit.edu.au', 'sajid.javed@ku.ac.ae']"
"Identifying labels that did not appear during training, known as multi-label zero-shot learning, is a non-trivial task in computer vision. To this end, recent studies have attempted to explore the multi-modal knowledge of vision-language pre-training (VLP) models by knowledge distillation, allowing to recognize unseen labels in an open-vocabulary manner. However, experimental evidence shows that knowledge distillation is suboptimal and provides limited performance gain in unseen label prediction. In this paper, a novel query-based knowledge sharing paradigm is proposed to explore the multi-modal knowledge from the pretrained VLP model for open-vocabulary multi-label classification. Specifically, a set of learnable label-agnostic query tokens is trained to extract critical vision knowledge from the input image, and further shared across all labels, allowing them to select tokens of interest as visual clues for recognition. Besides, we propose an effective prompt pool for robust label embedding, and reformulate the standard ranking learning into a form of classification to allow the magnitude of feature vectors for matching, which both significantly benefit label recognition. Experimental results show that our framework significantly outperforms state-of-the-art methods on zero-shot task by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively.",[''],[]
"In this work, we study the renormalization of nonlocal quark bilinear operators containing an asymmetric staple-shaped Wilson line at the one-loop level in both lattice and continuum perturbation theory. These operators enter the first-principle calculation of transverse momentum-dependent parton distribution functions (TMDPDFs) in lattice QCD using the formulation of Large Momentum Effective Theory. We provide appropriate RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT-type conditions that address the power and logarithmic divergences, as well as the mixing among staple operators of different Dirac structures, using a number of different possible projectors. A variant of RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT, including calculations of rectangular Wilson loops, which cancel the pinch-pole singularities of the staple operators at infinite length and reduce residual power divergences, is also employed. We calculate at one-loop order the conversion matrix, which relates the quasi-TMDPDFs in the RI′′{}^{\prime}start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT-type schemes to the reference scheme MS¯¯MS{\overline{\rm MS}}over¯ start_ARG roman_MS end_ARG for arbitrary values of the renormalization momentum scale and of the dimensions of the staple.",[''],"['Cyprus', 'USA', 'Cyprus']"
"Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we
propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account. Extensive experiments on six benchmark datasets show the effectiveness of our model. Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.",[''],[]
,[''],[]
"In first-price and all-pay auctions under the standard symmetric independent private-values model, we show that the unique Bayesian Coarse Correlated Equilibrium with symmetric, differentiable and strictly increasing bidding strategies is the unique strict Bayesian Nash Equilibrium. Interestingly, this result does not require assumptions on the prior distribution. The proof is based on a dual bound of the infinite-dimensional linear program. Numerical experiments without restrictions on bidding strategies show that for first-price auctions and discretisations up to 21 of the type and bid space, increasing discretisation sizes actually increase the concentration of Bayesian Coarse Correlated Equilibrium over the Bayesian Nash Equilibrium, so long as the prior c.d.f. is concave. Such a concentration is also observed for all-pay auctions, independent of the prior distribution. Overall, our results imply that the equilibria of these important class of auctions are indeed learnable.",[''],[]
"This talk is on a refined investigation on light flavor meson-baryon scatterings, using a dynamical coupled-channel approach, i.e. the JÃlich-Bonn model. The previous channel space of π⁢N𝜋𝑁\pi Nitalic_π italic_N, π⁢Δ𝜋Δ\pi\Deltaitalic_π roman_Δ, σ⁢N𝜎𝑁\sigma Nitalic_σ italic_N, ρ⁢N𝜌𝑁\rho Nitalic_ρ italic_N, η⁢N𝜂𝑁\eta Nitalic_η italic_N, K⁢Λ𝐾ΛK\Lambdaitalic_K roman_Λ and K⁢Σ𝐾ΣK\Sigmaitalic_K roman_Σ is extended by adding the ω⁢N𝜔𝑁\omega Nitalic_ω italic_N final state. The spectra of N*superscript𝑁N^{*}italic_N start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and ΔΔ\Deltaroman_Δ resonances are extracted, based on the result of a global fit to a worldwide collection of data, in the energy region from the π⁢N𝜋𝑁\pi Nitalic_π italic_N threshold to center-of-mass energy z=2.3𝑧2.3z=2.3italic_z = 2.3 GeV (approximately 300300300300 parameters against 9000900090009000 data points). A negative value of the ω⁢N𝜔𝑁\omega Nitalic_ω italic_N elastic spin-averaged scattering length has been extracted.",[''],[]
"Quantum emitters such as atoms or quantum dots are excellent sources of indistinguishable single photons for quantum technologies. However, upon coherent excitation, the emitted photonic state can include a vacuum component in a superposition with the one-photon component. Here, we study how the presence of such coherence with vacuum impacts photonic quantum information processing, starting with Hong-Ou-Mandel (HOM) interference that is central to quantum photonic technology. We first demonstrate that when coherence with vacuum is present, it causes a systematic error in the measurement of photon indistinguishability, an effect that has previously been overlooked and impacts some results in the literature. Using a proper normalisation method we show how this can be corrected. Our complete analysis of HOM interference also reveals a coherent phenomenon that results in path entanglement between photons in presence of coherence with vacuum. This type of phenomenon appears when multiple interfering wavepackets are only partially measured, a scenario that is key for heralded quantum gates implementation. To illustrate its impact on information processing, we simulate a heralded controlled-NOT gate and show that the presence of coherence with vacuum can actually improve the fidelity compared to incoherent photon losses. Our work reveals that the lack of a photon cannot always be accounted for by a simple loss mechanism, and that coherence with vacuum must be considered to properly explain error processes in photon-based quantum information processing.",[''],"['France.', 'UK.', 'France.', 'France.', 'UK.', 'Spain.', 'France.', 'France.', 'France.', 'France.']"
"We use the entropy method to analyze the nonlinear dynamics and stability of a continuum kinetic model of an active nematic suspension. From the time evolution of the relative entropy – an energy-like quantity in the kinetic model – we derive a variational bound on relative entropy fluctuations that can be expressed in terms of orientational order parameters. From this bound we show isotropic suspensions are nonlinearly stable for sufficiently low activity, and derive upper bounds on spatiotemporal averages in the unstable regime that are consistent with fully nonlinear simulations. This work highlights the self-organizing role of activity in particle suspensions, and places limits on how organized such systems can be.",[''],['USA']
"Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map. Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments. We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynamic environments.",[''],[]
,[''],[]
"This talk focuses on a recent work aiming at determining the composition of certain N*superscript𝑁N^{*}italic_N start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and ΔΔ\Deltaroman_Δ resonances, i.e. whether they are compact states formed directly by quarks and gluons, or composite generated from the meson-baryon interaction. The information of the resonance poles is provided by a comprehensive coupled-channel approach, the Jülich-Bonn model. Thirteen states that are significant in this approach are studied. Two criteria for each state are adopted in this paper, the comparison thereof roughly indicates the model uncertainties. It is found that the conclusions for eight resonances are relatively certain: N⁢(1535)⁢12−𝑁1535superscript12N(1535)\frac{1}{2}^{-}italic_N ( 1535 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT, N⁢(1440)⁢12+𝑁1440superscript12N(1440)\frac{1}{2}^{+}italic_N ( 1440 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, N⁢(1710)⁢12+𝑁1710superscript12N(1710)\frac{1}{2}^{+}italic_N ( 1710 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, and N⁢(1520)⁢32−𝑁1520superscript32N(1520)\frac{3}{2}^{-}italic_N ( 1520 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT tend
to be composite; whereas N⁢(1650)⁢12−𝑁1650superscript12N(1650)\frac{1}{2}^{-}italic_N ( 1650 ) divide start_ARG 1 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT, N⁢(1900)⁢32+𝑁1900superscript32N(1900)\frac{3}{2}^{+}italic_N ( 1900 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, N⁢(1680)⁢52+𝑁1680superscript52N(1680)\frac{5}{2}^{+}italic_N ( 1680 ) divide start_ARG 5 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, and
Δ⁢(1600)⁢32+Δ1600superscript32\Delta(1600)\frac{3}{2}^{+}roman_Δ ( 1600 ) divide start_ARG 3 end_ARG start_ARG 2 end_ARG start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT tend to be compact.",[''],[]
"In many recent works, the potential of Exploratory Landscape Analysis (ELA) features to numerically characterize, in particular, single-objective continuous optimization problems has been demonstrated. These numerical features provide the input for all kinds of machine learning tasks on continuous optimization problems, ranging, i.a., from High-level Property Prediction to Automated Algorithm Selection and Automated Algorithm Configuration. Without ELA features, analyzing and understanding the characteristics of single-objective continuous optimization problems would be impossible.
Yet, despite their undisputed usefulness, ELA features suffer from several drawbacks. These include, in particular, (1.) a strong correlation between multiple features, as well as (2.) its very limited applicability to multi-objective continuous optimization problems. As a remedy, recent works proposed deep learning-based approaches as alternatives to ELA. In these works, e.g., point-cloud transformers were used to characterize an optimization problem’s fitness landscape. However, these approaches require a large amount of labeled training data.

Within this work, we propose a hybrid approach, Deep-ELA, which combines (the benefits of) deep learning and ELA features. Specifically, we pre-trained four transformers on millions of randomly generated optimization problems to learn deep representations of the landscapes of continuous single- and multi-objective optimization problems. Our proposed framework can either be used out-of-the-box for analyzing single- and multi-objective continuous optimization problems, or subsequently fine-tuned to various tasks focussing on algorithm behavior and problem understanding.",[''],[]
"Recently,  Xu and Zhou (2023) introduced a constructive approach for exploring computational hardness, proving that SAT requires exhaustive search.
In light of certain misinterpretations concerning the contributions and proofs in that paper, we focus on providing detailed explanations in this work.
We begin by delineating the core innovation of the constructive approach, shedding light on the pivotal concept of algorithm designability.
We address the overlooked white-box diagonalization method and highlight the concept of an almost independent solution space.
In response to specific misunderstandings, such as the concerns surrounding the assumptions of Lemma 3.1, we offer comprehensive clarifications aimed at improving the comprehension of the proof.
We are grateful for the feedback received on our prior paper and hope this work can foster a more well-informed discussion.",[''],[]
"We establish that the charmed hadrons start dissociating at the chiral crossover temperature, Tp⁢csubscript𝑇𝑝𝑐{T_{pc}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT, leading to the appearance of charm degrees freedom carrying fractional baryon number. Our method is based on analyzing the second and fourth-order cumulants of charm (C𝐶{C}italic_C) fluctuations, and their correlations with baryon number (B𝐵{B}italic_B), electric charge (Q𝑄{Q}italic_Q) and strangeness (S𝑆{S}italic_S) fluctuations. The first-time calculation of the Q⁢C𝑄𝐶{QC}italic_Q italic_C correlations on the high statistics datasets of the HotQCD Collaboration enables us to disentangle the contributions from different electrically-charged charm subsectors in the hadronic phase. In particular, we see an enhancement over the PDG expectation in the fractional contribution of the |Q|=2𝑄2{|Q|}=2| italic_Q | = 2 charm subsector to the total charm partial pressure for T<Tp⁢c𝑇subscript𝑇𝑝𝑐{T<T_{pc}}italic_T < italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT; this enhancement is in agreement with the Quark Model extended Hadron Resonance Gas (QM-HRG) model calculations. Furthermore, the agreement of QM-HRG calculations with the projections onto charmed baryonic and mesonic correlations in different charm subsectors indicates the existence of not-yet-discovered charmed hadrons in all charm subsectors below Tp⁢csubscript𝑇𝑝𝑐{T_{pc}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT. We aim at determining the relevant degrees of freedom in temperature range Tp⁢c<T<340⁢ MeVsubscript𝑇𝑝𝑐𝑇340 MeV{T_{pc}<T<340\text{ MeV}}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT < italic_T < 340 MeV by assuming the existence of a non-interacting gas of charmed quasi-particles composed of meson, baryon and quark-like excitations above Tp⁢csubscript𝑇𝑝𝑐T_{pc}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT. Our data suggest that the particles with quantum numbers consistent with quarks start appearing at Tp⁢csubscript𝑇𝑝𝑐T_{pc}italic_T start_POSTSUBSCRIPT italic_p italic_c end_POSTSUBSCRIPT.",[''],[]
"Buffer-aided cooperative networks (BACNs) have garnered significant attention due to their potential applications in beyond fifth generation (B5G) or sixth generation (6G) critical scenarios. This article explores various typical application scenarios of buffer-aided relaying in B5G/6G networks to emphasize the importance of incorporating BACN. Additionally, we delve into the crucial technical challenges in BACN, including stringent delay constraints, high reliability, imperfect channel state information (CSI), transmission security, and integrated network architecture. To address the challenges, we propose leveraging deep learning-based methods for the design and operation of B5G/6G networks with BACN, deviating from conventional buffer-aided relay selection approaches. In particular, we present two case studies to demonstrate the efficacy of centralized deep reinforcement learning (DRL) and decentralized DRL in buffer-aided non-terrestrial networks.
Finally, we outline future research directions in B5G/6G that pertain to the utilization of BACN.",[''],[]
,[''],[]
"Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pipelines.",[''],[]
"This paper studies the convergence of the mirror descent algorithm for finite horizon stochastic control problems with measure-valued control processes.
The control objective involves a convex regularisation function, denoted as hℎhitalic_h, with regularisation strength determined by the weight τ≥0𝜏0\tau\geq 0italic_τ ≥ 0.
The setting covers regularised relaxed control problems.
Under suitable conditions, we establish the relative smoothness and convexity of the control objective with respect to the Bregman divergence of hℎhitalic_h, and prove linear convergence of the algorithm for τ=0𝜏0\tau=0italic_τ = 0 and exponential convergence for τ>0𝜏0\tau>0italic_τ > 0.
The results apply to common regularisers including relative entropy, χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-divergence, and entropic Wasserstein costs.
This validates recent reinforcement learning heuristics that adding regularisation accelerates the convergence of gradient methods.
The proof exploits careful regularity estimates of backward stochastic differential equations in the bounded mean oscillation norm.","['Key words and phrases:', 'Mirror descent, stochastic control, convergence rate analysis,', 'Bregman divergence,', 'Pontryagin’s optimality principle']",[]
"Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. [1]. The experiments we carried out confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes. Noticeably, the JMA attack is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in a complex multilabel classification scenario with 20 labels, a capability that is out of reach of all the attacks proposed so far. As a further advantage, the JMA attack usually requires very few iterations, thus resulting more efficient than existing methods.","['Index', 'Terms: ', 'Adversarial', 'Examples,', 'Deep', 'Learning', 'Security,', 'Adversarial', 'Machine', 'Learning,', 'Multi-Label', 'Classification,', 'Mahalanobis', 'Distance,', 'Non-Negative', 'Least', 'Square', 'Problems']",[]
"Skin lesions are classified in benign or malignant. Among the malignant, melanoma is a very aggressive cancer and the major cause of deaths. So, early diagnosis of skin cancer is very desired. In the last few years, there is a growing interest in computer aided diagnostic (CAD) using most image and clinical data of the lesion. Although we have seen an increasing progress in CAD of skin lesions, these sources of information present limitations due to their inability to provide information of the molecular structure of the lesion. NIR spectroscopy may provide an alternative source of information to automated CAD of skin lesions. The most commonly used techniques and classification algorithms used in spectroscopy are Principal Component Analysis (PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support Vector Machines (SVM). Nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (MDL) to spectroscopy. One of the main limitations to apply MDL to spectroscopy is the lack of public datasets. Since there is no public dataset of NIR spectral data to skin lesions, as far as we know, an effort has been made and a new dataset named NIR-SC-UFES, has been collected, annotated and analyzed generating the gold-standard for classification of NIR spectral data to skin cancer. Next, the machine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutional neural network (1D-CNN) and standard algorithms as SVM and PLS-DA were investigated to classify cancer and non-cancer skin lesions. Experimental results indicate the best performance obtained by LightGBM with pre-processing using standard normal variate (SNV), feature extraction and data augmentation with Generative Adversarial Networks (GAN) providing values of 0.839 for balanced accuracy, 0.851 for recall, 0.852 for precision, and 0.850 for F-score. The obtained results indicate the first steps in CAD of skin lesions aiming the automated triage of patients with skin lesions in vivo using NIR spectral data.",[''],[]
"The current approach to fetal anomaly screening is based on biometric
measurements derived from individually selected ultrasound images.
In this paper, we introduce a paradigm shift that attains human-level
performance in biometric measurement by aggregating automatically
extracted biometrics from every frame across an entire scan, with
no need for operator intervention. We use a convolutional neural network
to classify each frame of an ultrasound video recording. We then measure
fetal biometrics in every frame where appropriate anatomy is visible.
We use a Bayesian method to estimate the true value of each biometric
from a large number of measurements and probabilistically reject outliers.
We performed a retrospective experiment on 1457 recordings (comprising
48 million frames) of 20-week ultrasound scans, estimated fetal biometrics
in those scans and compared our estimates to the measurements sonographers
took during the scan. Our method achieves human-level performance
in estimating fetal biometrics and estimates well-calibrated credible
intervals in which the true biometric value is expected to lie.","['Index', 'Terms: \n', 'Ultrasound;', 'Fetal imaging;', 'Machine learning;', 'Bayesian estimation;', 'Biometric measurement']","['London', 'London', 'London']"
"We present a new procedure to identify observations of known
objects in large data sets of unlinked detections. It begins with
a Keplerian integrals method that allows us to link two tracklets,
computing preliminary orbits, even when the tracklets are
separated in time by a few years. In the second step, we
represent the results in a ‘graph’ where the tracklets are the
nodes and the preliminary orbits are the edges. Then, acceptable
‘3-cycles’ are identified and a least squares orbit is computed
for each of them. Finally, we construct sequences of n≥4𝑛4n\geq 4italic_n ≥ 4
tracklets by searching through the orbits of nearby 3-cycles and
attempting to attribute the remaining tracklets. We calculate the
technique’s efficiency at identifying unknown objects using real
detections that attempt to mimic key parameters of the Minor
Planet Center’s Isolated Tracklet File (ITF) and then apply the
procedure to the ITF to identify tens of thousands of new
objects.

Keywords: Orbit determination, Keplerian
integrals methods, Linkage problem, Asteroid surveys.",[''],"['Spain', 'Spain', 'Italy', 'Italy', 'USA']"
"Recently, two monolayer magnetic materials, i.e., FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT and NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, have been successfully fabricated. Despite that they have the same atomic structure, the two monolayers exhibit distinct magnetic properties. FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT holds an out-of-plane zigzag antiferromagnetic (AFM-ZZ) structure, while NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT exhibits an in-plane AFM-ZZ structure. However, there is no theoretical model which can properly describe its magnetic ground state due to the lack of a full understanding of its magnetic interactions. Here, by combining the first-principles calculations and the newly developed machine learning method, we construct an exact spin Hamiltonian of the two magnetic materials. Different from the previous studies which failed to fully consider the spin-orbit coupling effect, we find that the AFM-ZZ ground state in FePS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT is stabilized by competing ferromagnetic nearest-neighbor and antiferromagnetic third nearest-neighbor exchange interactions, and combining single-ion anisotropy. Whereas, the often ignored nearest-neighbor biquadratic exchange is responsible for the in-plane AFM-ZZ ground state in NiPS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. We additionally calculate spin-wave spectrum of AFM-ZZ structure in the two monolayers based on the exact spin Hamiltonian, which can be directly verified by the experimental investigation. Our work provides a theoretical framework for the origin of AFM-ZZ ground state in two-dimensional materials.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus. However, challenges such as attacks on model parameters and the lack of incentive mechanisms hinder the effectiveness of federated learning. Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training. Blockchain ensures that model parameters stored in the InterPlanetary File System (IPFS) remain unaltered. A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning. Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training clients. Security analysis and experimental results demonstrate that PPBFL outperforms baseline methods in both model performance and security.","['Index', 'Terms: ', 'Federated', 'Learning,', 'Blockchain,', 'Differential', 'Privacy,', 'InterPlanetary', 'File', 'System']",[]
"Rattling phonon modes are known to be origin of various anomalous physical properties such as superconductivity, suppression of thermal conductivity, enhancement of specific heat etc. By means of DFT+U𝑈Uitalic_U calculations we directly show presence of the
rattling mode in the quadruple perovskites CuCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV44{}_{4}start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPTO1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT and CuCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTFe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTRe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT and argue that this can develop in others as well. It is demonstrated that Cu ions at A𝐴Aitalic_A sites vibrate in the center of the icosahedral oxygen O1212{}_{12}start_FLOATSUBSCRIPT 12 end_FLOATSUBSCRIPT cages and the corresponding potential has a complicated form with many local minima.",[''],[]
"A method is presented for estimating and reconstructing the sound field within a room using physics-informed neural networks. By incorporating a limited set of experimental room impulse responses as training data, this approach combines neural network processing capabilities with the underlying physics of sound propagation, as articulated by the wave equation. The network’s ability to estimate particle velocity and intensity, in addition to sound pressure, demonstrates its capacity to represent the flow of acoustic energy and completely characterise the sound field with only a few measurements. Additionally, an investigation into the potential of this network as a tool for improving acoustic simulations is conducted. This is due to its profficiency in offering grid-free sound field mappings with minimal inference time. Furthermore, a study is carried out which encompasses comparative analyses against current approaches for sound field reconstruction. Specifically, the proposed approach is evaluated against both data-driven techniques and elementary wave-based regression methods. The results demonstrate that the physics-informed neural network stands out when reconstructing the early part of the room impulse response, while simultaneously allowing for complete sound field characterisation in the time domain.",[''],"['Denmark', 'Jabra', 'A/S', 'Denmark']"
,[''],[]
"Crowd counting has gained significant popularity due to its practical applications. However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps. Additionally, they also struggle with high-density images.
To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet).
Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals.
This study designs a fusion module, named Fine-Grained Feature Pyramid (FGFP), that is used to fuse feature maps extracted by the backbone of FGENet.
The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual.
At the end, FGENet establishes correspondences between prediction points and ground truth points by employing the Hungarian algorithm.
For training FGENet, we design a robust loss function, named Three-Task Combination (TTC), to mitigate the impact of annotation noise. Extensive experiments are conducted on four widely used crowd counting datasets.
Experimental results demonstrate the effectiveness of FGENet. Notably, our method achieves a remarkable improvement of 3.14 points in Mean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing its superiority over the existing state-of-the-art methods. Even more impressively, FGENet surpasses previous benchmarks on the UCF_CC_50 dataset with an astounding enhancement of 30.16 points in MAE.","['Crowd counting', 'Computer vision', 'Convolutional neural network.']",[]
"Let U𝑈Uitalic_U be a smooth connected complex algebraic variety, and let f:U→ℂ*:𝑓→𝑈superscriptℂf\colon U\to{\mathbb{C}}^{*}italic_f : italic_U → blackboard_C start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT be an algebraic map. To the pair (U,f)𝑈𝑓(U,f)( italic_U , italic_f ) one can associate an infinite cyclic cover Ufsuperscript𝑈𝑓U^{f}italic_U start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT, and (homology) Alexander modules are defined as the homology groups of this cover. In two recent works, the first of which is joint with Geske, Maxim and Wang, we developed two different ways to put a mixed Hodge structure on Alexander modules. Since they are not finite dimensional in general, each approach replaces the Alexander module by a different finite dimensional module: one of them takes the torsion submodule, the other takes finite dimensional quotients, and the constructions are not directly comparable. In this note, we show that both constructions are compatible, in the sense that the map from the torsion to the quotients is a mixed Hodge structure morphism.","['Key words and phrases: infinite cyclic cover,', 'Alexander module, mixed', 'Hodge structure, thickened complex']",[]
"We investigate the behaviour of two recent methods for the computation
of preliminary orbits. These methods are based on the conservation
laws of Kepler’s problem, and enable the linkage of very short arcs of
optical observations even when they are separated in time by a few
years. Our analysis is performed using both synthetic and real data
of 822 main belt asteroids. The differences between computed and true
orbital elements have been analysed for the true linkages, as well as
the occurrence of alternative solutions. Some metrics have been
introduced to quantify the results, with the aim of discarding as many
of the false linkages as possible and keeping the vast majority of
true ones. These numerical experiments provide thresholds for the
metrics which take advantage of the knowledge of the ground
truth: the values of these thresholds can be used in normal
operation mode, when we do not know the correct values of the orbital
elements and whether the linkages are true or false.",[''],"['Italy', 'Italy', 'Italy', 'USA']"
"We derive a formula to calculate the local change to the log of any density of states for smooth real observables. Using this in Monte-Carlo simulations, we are able to calculate the expectation value of the observable with a precision often better than standard sampling. The method can be applied to previously generated configurations, as long as the analysis uses the same action used to generate the configurations. We show that for observables such as Wilson line correlators, errors are reduced by up to 4 times.",[''],[]
"This paper studies the algebraic structure of a new class of hyperplane arrangement 𝒜𝒜\mathscr{A}script_A obtained by deleting two hyperplanes from a free arrangement.
We provide information on the minimal free resolutions of
the logarithmic derivation module of 𝒜𝒜\mathscr{A}script_A,
which can be used to compute a lower bound for the graded Betti numbers of the resolution.
Specifically, for the three-dimensional case,
we determine
the minimal free resolution of
the logarithmic derivation module of 𝒜𝒜\mathscr{A}script_A.
We present illustrative examples of our main theorems to provide insights into the relationship between algebraic and combinatorial properties for close-to-free arrangements.",[''],[]
"We consider the following convective Neumann systems:



(S){−Δp1⁢u1+|∇u1|p1u1+δ1=f1⁢(x,u1,u2,∇u1,∇u2)in⁢Ω,−Δp2⁢u2+|∇u2|p2u2+δ2=f2⁢(x,u1,u2,∇u1,∇u2)in⁢Ω,|∇u1|p1−2⁢∂u1∂η=0=|∇u2|p2−2⁢∂u2∂ηon⁢∂Ω,ScasessubscriptΔsubscript𝑝1subscript𝑢1superscript∇subscript𝑢1subscript𝑝1subscript𝑢1subscript𝛿1subscript𝑓1𝑥subscript𝑢1subscript𝑢2∇subscript𝑢1∇subscript𝑢2inΩsubscriptΔsubscript𝑝2subscript𝑢2superscript∇subscript𝑢2subscript𝑝2subscript𝑢2subscript𝛿2subscript𝑓2𝑥subscript𝑢1subscript𝑢2∇subscript𝑢1∇subscript𝑢2inΩsuperscript∇subscript𝑢1subscript𝑝12subscript𝑢1𝜂0superscript∇subscript𝑢2subscript𝑝22subscript𝑢2𝜂onΩ\left(\mathrm{S}\right)\qquad\left\{\begin{array}[]{ll}-\Delta_{p_{1}}u_{1}+%
\frac{|\nabla u_{1}|^{p_{1}}}{u_{1}+\delta_{1}}=f_{1}(x,u_{1},u_{2},\nabla u_{%
1},\nabla u_{2})&\text{in}\;\Omega,\\
-\Delta_{p_{2}}u_{2}+\frac{|\nabla u_{2}|^{p_{2}}}{u_{2}+\delta_{2}}=f_{2}(x,u%
_{1},u_{2},\nabla u_{1},\nabla u_{2})&\text{in}\;\Omega,\\
|\nabla u_{1}|^{p_{1}-2}\frac{\partial u_{1}}{\partial\eta}=0=|\nabla u_{2}|^{%
p_{2}-2}\frac{\partial u_{2}}{\partial\eta}&\text{on}\;\partial\Omega,\end{%
array}\right.( roman_S ) { start_ARRAY start_ROW start_CELL - roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + divide start_ARG | ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_ARG start_ARG italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG = italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x , italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_CELL start_CELL in roman_Ω , end_CELL end_ROW start_ROW start_CELL - roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + divide start_ARG | ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_ARG start_ARG italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG = italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x , italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_CELL start_CELL in roman_Ω , end_CELL end_ROW start_ROW start_CELL | ∇ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT divide start_ARG ∂ italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG ∂ italic_η end_ARG = 0 = | ∇ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT divide start_ARG ∂ italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG ∂ italic_η end_ARG end_CELL start_CELL on ∂ roman_Ω , end_CELL end_ROW end_ARRAY



where ΩΩ\Omegaroman_Ω is a bounded domain in ℝNsuperscriptℝ𝑁\mathbb{R}^{N}blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT (N≥2𝑁2N\geq 2italic_N ≥ 2) with a
smooth boundary ∂ΩΩ\partial\Omega∂ roman_Ω, δ1,δ2>0subscript𝛿1subscript𝛿20\delta_{1},\,\delta_{2}>0italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0 are small parameters, η𝜂\etaitalic_η
is the outward unit vector normal to ∂Ω,Ω\partial\Omega,∂ roman_Ω ,
f1,f2:Ω×ℝ2×ℝ2⁢N→ℝ:subscript𝑓1subscript𝑓2→Ωsuperscriptℝ2superscriptℝ2𝑁ℝf_{1},\,f_{2}:\Omega\times\mathbb{R}^{2}\times\mathbb{R}^{2N}\rightarrow%
\mathbb{R}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : roman_Ω × blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT 2 italic_N end_POSTSUPERSCRIPT → blackboard_R are
Carathéodory
functions that satisfy certain growth conditions,
and
ΔpisubscriptΔsubscript𝑝𝑖\Delta_{p_{i}}roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT (1<pi<N,1subscript𝑝𝑖𝑁1<p_{i}<N,1 < italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_N , for i=1,2𝑖12i=1,2italic_i = 1 , 2)
are the p𝑝pitalic_p-Laplace operators
Δpi⁢ui=div⁢(|∇ui|pi−2⁢∇ui)subscriptΔsubscript𝑝𝑖subscript𝑢𝑖divsuperscript∇subscript𝑢𝑖subscript𝑝𝑖2∇subscript𝑢𝑖\Delta_{p_{i}}u_{i}=\mathrm{div}(|\nabla u_{i}|^{p_{i}-2}\nabla u_{i})roman_Δ start_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_div ( | ∇ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - 2 end_POSTSUPERSCRIPT ∇ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), for every⁢ui∈W1,pi⁢(Ω).for everysubscript𝑢𝑖superscript𝑊1subscript𝑝𝑖Ω\hbox{for every}\,u_{i}\in W^{1,p_{i}}(\Omega).for every italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_W start_POSTSUPERSCRIPT 1 , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) .
In order to prove the existence of solutions to such systems, we use a sub-supersolution method. We also obtain nodal solutions
by constructing appropriate sub-solution and super-solution pairs. To the best of our knowledge, such systems have not been studied yet.
Keywords and phrases:
Neumann elliptic system; gradient dependence; sub-solution and super-solution method; nodal solution.
Math. Subj. Classif. (2020):  35J62, 35J92.",[''],[]
"Traditional manual detection for solder joint defect is no longer applied during industrial production due to low efficiency, inconsistent evaluation, high cost and lack of real-time data. A new approach has been proposed to address the issues of low accuracy, high false detection rates and computational cost of solder joint defect detection in surface mount technology of industrial scenarios. The proposed solution is a hybrid attention mechanism designed specifically for the solder joint defect detection algorithm to improve quality control in the manufacturing process by increasing the accuracy while reducing the computational cost. The hybrid attention mechanism comprises a proposed enhanced multi-head self-attention and coordinate attention mechanisms increase the ability of attention networks to perceive contextual information and enhances the utilization range of network features. The coordinate attention mechanism enhances the connection between different channels and reduces location information loss. The hybrid attention mechanism enhances the capability of the network to perceive long-distance position information and learn local features. The improved algorithm model has good detection ability for solder joint defect detection, with mAP reaching 91.5%, 4.3% higher than the You Only Look Once version 5 algorithm and better than other comparative algorithms. Compared to other versions, mean Average Precision, Precision, Recall, and Frame per Seconds indicators have also improved. The improvement of detection accuracy can be achieved while meeting real-time detection requirements.","['Key words and phrases:', 'Solder joint defect, feature fusion, self-attention mechanism, feature pyramid network']",[]
In this paper we analyze a space-time unfitted finite element method for the discretization of scalar surface partial differential equations on evolving surfaces. For higher order approximations of the evolving surface we use the technique of (iso)parametric mappings for which a level set representation of the evolving surface is essential. We derive basic results in which certain geometric characteristics of the exact space-time surface are related to corresponding ones of the numerical surface approximation. These results are used in a complete error analysis of a higher order space-time TraceFEM.,[''],[]
"Neural radiance fields (NeRF) have been proposed as an innovative 3D representation method. While attracting lots of attention, NeRF faces critical issues such as information confidentiality and security. Steganography is a technique used to embed information in another object as a means of protecting information security. Currently, there are few related studies on NeRF steganography, facing challenges in low steganography quality, model weight damage, and a limited amount of steganographic information. This paper proposes a novel NeRF steganography method based on trainable noise: Noise-NeRF. Furthermore, we propose the Adaptive Pixel Selection strategy and Pixel Perturbation strategy to improve the steganography quality and efficiency. The extensive experiments on open-source datasets show that Noise-NeRF provides state-of-the-art performances in both steganography quality and rendering quality, as well as effectiveness in super-resolution image steganography.","['Index', 'Terms: \nneural radiation fields, steganography, implicit neural representation']",[]
"As more IoT applications gradually move towards the cloud-edge collaborative mode, the containerized scheduling of workflows extends from the cloud to the edge. However, given the high delay of the communication network, loose coupling of structure, and resource heterogeneity between cloud and edge, workflow containerization scheduling in the cloud-edge scenarios faces the difficulty of resource coordination and application collaboration management.
To address these two issues, we propose a KubeEdge-Cloud-Edge-Scheduling scheme named KCES, a workflow containerization scheduling scheme for the KubeEdge cloud-edge framework. The KCES includes a cloud-edge workflow scheduling engine for KubeEdge and workflow scheduling strategies for task horizontal roaming and vertical offloading. Considering the scheduling optimization of cloud-edge workflows, this paper proposes a cloud-edge workflow scheduling model and cloud-edge node model and designs a cloud-edge workflow scheduling engine to maximize cloud-edge resource utilization under the constraint of workflow task delay.
A cloud-edge resource hybrid management technology is used to design the cloud-edge resource evaluation and resource allocation algorithms to achieve cloud-edge resource collaboration. Based on the ideas of distributed functional roles and the hierarchical division of computing power, the horizontal roaming among the edges and vertical offloading strategies between the cloud and edges for workflow tasks are designed to realize the cloud-edge application collaboration.
Through a customized IoT application workflow instance, experimental results show that KCES is superior to the baseline in total workflow duration, average workflow duration, and resource usage and has the capabilities of horizontal roaming and vertical offloading for workflow tasks.","['Index', 'Terms: ', 'Workflow scheduling, cloud-edge collaboration, resource collaboration, application collaboration, horizontal roaming, vertical offloading.']",[]
"Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models.
However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance.
Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input.
Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality.
In this work, we propose a  zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs.
\AcZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets.
To improve the quality of unsupervised responses, we propose a  master-slave alignment (MSA) module to prune these responses.
Experiments on eight datasets and five tasks show that ZOE consistently outperforms existing methods in mitigating four types of position biases.
Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective.",[''],[]
"Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer.
To provide sufficient learning support, modern MTL uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks.
However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks.
In this work, we challenge this setup and show that MTL can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task.
We explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching.
To demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets.
Our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases.
In all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when MT model’s performance is worse than that of at least one single-task model).",[''],[]
"Context:Interstellar dust particles, in particular carbonaceous nano-grains (like polycyclic aromatic hydrocarbons, fullerenes, and amorphous hydrogenated carbon), are critical players for the composition, energy budget, and dynamics of the interstellar medium (ISM). The dust properties, specifically the composition and size of dust grains are not static; instead, they exhibit considerable evolution triggered by variations in local physical conditions such as the density and gas temperature within the ISM, as is the case in photon-dominated regions (PDRs). The evolution of dust and its impact on the local physical and chemical conditions is thus a key question for understanding the first stages of star formation.
Aims:From the extensive spectral and imaging data of the JWST PDRs4All program, we study the emission of dust grains within the Orion Bar — a well-known, highly far-UV (FUV)-irradiated PDR situated at the intersection between cold, dense molecular clouds, and warm ionized regions. The Orion Bar because of its edge-on geometry provides an exceptional benchmark for characterizing dust evolution and the associated driving processes under varying physical conditions. Our goal is to constrain the local properties of dust by comparing its emission to models. Taking advantage of the recent JWST data, in particular the spectroscopy of dust emission, we identify new constraints on dust and further previous works of dust modelling.
Methods:To characterize interstellar dust across the Orion Bar, we follow its emission as traced by JWST NIRCam (at 3.35 and 4.8 μ𝜇\muitalic_μm) and MIRI (at 7.7, 11.3, 15.0, and 25.5 μ𝜇\muitalic_μm) broad band images, along with NIRSpec and MRS spectroscopic observations. First, we constrain the minimum size and hydrogen content of carbon nano-grains from a comparison between the observed dust emission spectra and the predictions of the Heterogeneous dust Evolution Model for Interstellar Solids (THEMIS) coupled to the numerical code DustEM.
Using this dust model, we then perform 3D radiative transfer simulations of dust emission with the SOC code (Scattering with OpenCL) and compare to data obtained along well chosen profiles across the Orion Bar.
Results:The JWST data allows us, for the first time, to spatially resolve the steep variation of dust emission at the illuminated edge of the Orion Bar PDR. By considering a dust model with carbonaceous nano-grains and submicronic coated silicate grains, we derive unprecedented constraints on the properties of across the Orion Bar. To explain the observed emission profiles with our simulations, we find that the nano-grains must be strongly depleted with an abundance (relative to the gas) 15 times less than in the diffuse ISM. The NIRSpec and MRS spectroscopic observations reveal variations in the hydrogenation of the carbon nano-grains. The lowest hydrogenation levels are found in the vicinity of the illuminating stars suggesting photo-processing while more hydrogenated nano-grains are found in the cold and dense molecular region, potentially indicative of larger grains.
Conclusions:","['Key', 'Words.: \n infrared:', 'ISM / dust, extinction / photon-dominated region (PDR) /', 'ISM: individual objects:', 'Orion', 'Bar / radiative transfer']",[]
"By systematic theoretical calculations, we have revealed an excitonic insulator (EI) in a van der Waals layered compound Ta2⁢Pd3⁢Te5subscriptTa2subscriptPd3subscriptTe5\rm{Ta_{2}Pd_{3}Te_{5}}roman_Ta start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_Pd start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT roman_Te start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT. First-principles calculations show that the monolayer is a nearly zero-gap semiconductor. Due to the like symmetry of the band-edge states, the 2D polarization α2⁢Dsubscript𝛼2𝐷\alpha_{2D}italic_α start_POSTSUBSCRIPT 2 italic_D end_POSTSUBSCRIPT would be finite as the band gap goes to zero, allowing for the EI state in the compound. Using the first-principles many-body perturbation theory, the G⁢W𝐺𝑊GWitalic_G italic_W-BSE calculation shows that the exciton binding energy Ebsubscript𝐸𝑏E_{b}italic_E start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT is larger than the single-particle band gap Egsubscript𝐸𝑔E_{g}italic_E start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT, indicating the excitonic instability.
Additionally, no structure instability is found in the phonon spectrum of this material.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
"Recently, intelligent reflecting surface (IRS)-aided millimeter-wave (mmWave) and terahertz (THz) communications are considered in the wireless community. This paper aims to design a beam-based multiple-access strategy for this new paradigm. Its key idea is to make use of multiple sub-arrays over a hybrid digital-analog array to form independent beams, each of which is steered towards the desired direction to mitigate inter-user interference and suppress unwanted signal reflection. The proposed scheme combines the advantages of both orthogonal multiple access (i.e., no inter-user interference) and non-orthogonal multiple access (i.e., full time-frequency resource use). Consequently, it can substantially boost the system capacity, as verified by Monte-Carlo simulations.",[''],"['Germany', 'Schotten']"
"The Riviera model is a combinatorial model for a settlement along a coastline, introduced recently by the authors. Of most interest are the so-called jammed states, where no more houses can be built without violating the condition that every house needs to have free space to at least one of its sides. In this paper, we introduce new agents (predators and altruists) that want to build houses once the settlement is already in the jammed state. Their behavior is governed by a different set of rules, and this allows them to build new houses even though the settlement is jammed. Our main focus is to detect jammed configurations that are resistant to predators, to altruists, and to both predators and altruists. We provide bivariate generating functions, and complexity functions (configurational entropies) for such jammed configurations. We also discuss this problem in the two-dimensional setting of a combinatorial settlement planning model that was also recently introduced by the authors, and of which the Riviera model is just a special case.","['Key words and phrases: generating functions, complexity function, configurational entropy, jammed configuration, maximal packing, settlement model, equilibrium lattice systems']",[]
"Accretion-powered X-ray pulsars offer a unique opportunity to study physics under extreme conditions. To fully exploit this potential, the interrelated problems of modelling radiative transport and the dynamical structure of the accretion flow must, however, be solved. This task is challenging both from a theoretical and observational point of view and is further complicated by a lack of direct correspondence between the properties of emission emerging from the neutron star and observed far away from it. In general, a mixture of emission from both poles of the neutron star viewed from different angles is indeed observed at some or even all phases of the pulse cycle. It is essential, therefore, to reconstruct the contributions of each pole to the observed flux in order to test and refine models describing the formation of the spectra and pulse profiles of X-ray pulsars. In this paper we propose a novel data-driven approach to address this problem using the pulse-to-pulse variability in the observed flux, and demonstrate its application to RXTE observations of the bright persistent X-ray pulsar Cen~X$-$3. We then discuss the comparison of our results with previous work attempting to solve the same problem and how they can be qualitatively interpreted in the framework of a toy model describing emission from the poles of a neutron star.","['Key', 'Words.: \n', 'Methods: data analysis –', 'X-rays: binaries –\npulsars: individual:', 'Cen~X$-$3–', 'Stars: neutron']",[]
,[''],[]
"Homodyne measurement is a crucial tool widely used to address continuous variables for bosonic quantum systems. While an ideal homodyne detection provides a powerful analysis, e.g. to effectively measure quadrature amplitudes of light in quantum optics, it relies on the use of a strong reference field, the so-called local oscillator typically in a coherent state. Such a strong coherent local oscillator may not be readily available particularly for a massive quantum system like Bose-Einstein condensate (BEC), posing a substantial challenge in dealing with continuous variables appropriately. It is necessary to establish a practical framework that includes the effects of non-ideal local oscillators for a rigorous assessment of various quantum tests and applications. We here develop entanglement criteria beyond Gaussian regime applicable for this realistic homodyne measurement that do not require assumptions on the state of local oscillators. We discuss the working conditions of homodyne detection to effectively detect non-Gaussian quantum entanglement under various states of local oscillators.",[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Kingdom', 'Qatar']"
"The time resolution of the second monolithic silicon pixel prototype produced for the MONOLITH H2020 ERC Advanced project was studied using a femtosecond laser.
The ASIC contains a matrix of hexagonal pixels with 100 μ𝜇\muitalic_μm pitch, readout by low-noise and very fast SiGe HBT frontend electronics.
Silicon wafers with 50 μ𝜇\muitalic_μm thick epilayer with a resistivity of 350 ΩΩ\Omegaroman_Ωcm were used to produce a fully depleted sensor.
At the highest frontend power density tested of 2.7 W/cm22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT, the time resolution with the femtosecond laser pulses was found to be 45 ps for signals generated by 1200 electrons, and 3 ps in the case of 11k electrons, which corresponds approximately to 0.4 and 3.5 times the most probable value of the charge generated by a minimum-ionizing particle.
The results were compared with testbeam data taken with the same prototype to evaluate the time jitter produced by the fluctuations of the charge collection.",[''],[]
"The NASA New Horizons Venetia Burney Student Dust Counter (SDC) measures dust particle impacts along the spacecraft’s flight path for grains with mass ≥\geq≥ 10−12superscript101210^{-12}10 start_POSTSUPERSCRIPT - 12 end_POSTSUPERSCRIPT g, mapping out their spatial density distribution. We present the latest SDC dust density, size distribution, and flux measurements through 55 au and compare them to numerical model predictions. Kuiper Belt Objects (KBOs) are thought to be the dominant source of interplanetary dust particles (IDP) in the outer solar system due to both collisions between KBOs, and their continual bombardment by interstellar dust particles (ISD).
Continued measurements through 55 au show higher than model-predicted dust fluxes as New Horizons approaches the putative outer edge of the Kuiper Belt (KB). We discuss potential explanations for the growing deviation: radiation pressure stretches the dust distribution to further heliocentric distances than its parent body distribution; icy dust grains undergo photo-sputtering that rapidly increases their response to radiation pressure forces and pushes them further away from the sun; and the distribution of KBOs may extend much further than existing observations suggest. Ongoing SDC measurements at even larger heliocentric distances will continue to constrain the contributions of dust production in the KB. Continued SDC measurements remain crucial for understanding the Kuiper Belt and the interpretation of observations of dust disks around other stars.","['Kuiper', 'Belt,', 'Interplanetary', 'Dust,', 'PVDF,', 'New', 'Horizons']","['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"We develop a Bayesian modeling framework to address a pressing real-life problem faced by the police in tackling insurgent gangs. Unlike criminals associated with common crimes such as robbery, theft or street crime, insurgent gangs are trained in sophisticated arms and strategise against the government to weaken its resolve. They are constantly on the move, operating over large areas causing damage to national properties and terrorizing ordinary citizens. Different from the more commonly addressed problem of modeling crime-events, our context requires that an approach be formulated to model the movement of insurgent gangs, which is more valuable to the police forces in preempting their activities and nabbing them. This paper evolved as a collaborative work with the Indian police to help augment their tactics with a systematic method, by integrating past data on observed gang-locations with the expert knowledge of the police officers. A methodological challenge in modeling the movement of insurgent gangs is that the data on their locations is incomplete, since they are observable only at some irregularly separated time-points. Based on a weighted kernel density formulation for temporal data, we analytically derive the closed form of the likelihood, conditional on incomplete past observed data. Building on the current tactics used by the police, we device an approach for constructing an expert-prior on gang-locations, along with a sequential Bayesian procedure for estimation and prediction. We also propose a new metric for predictive assessment that complements another known metric used in similar problems.",[''],[]
"Graphs are typical non-Euclidean data of complex structures.
In recent years, Riemannian graph representation learning has
emerged as an exciting alternative to Euclidean ones.
However, Riemannian methods are still in an early stage:
most of them
present a single curvature (radius) regardless of structural complexity,
suffer from numerical instability due to the exponential/logarithmic map,
and lack the ability to capture motif regularity.
In light of the issues above, we propose the problem of Motif-aware Riemannian Graph Representation Learning,
seeking a numerically stable encoder to capture motif regularity in a diverse-curvature manifold without labels.
To this end, we present a novel Motif-aware Riemannian model with Generative-Contrastive learning (MotifRGC),
which conducts a minmax game in Riemannian manifold in a self-supervised manner.
First, we propose a new type of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold by a product layer with the diversified factor,
and replace the exponential/logarithmic map by a stable kernel layer.
Second,
we introduce a motif-aware Riemannian generative-contrastive learning
to capture motif regularity in the constructed manifold and learn motif-aware node representation without external labels.
Empirical results show the superiority of MofitRGC.",[''],[]
"Graph Neural Networks (GNNs) are widely applied across various domains, yet they perform poorly in deep layers. Existing research typically attributes this problem to node over-smoothing, where node representations become indistinguishable after multiple rounds of propagation. In this paper, we delve into the neighborhood propagation mechanism of GNNs and discover that the real root cause of GNNs’ performance degradation in deep layers lies in ineffective neighborhood feature propagation. This propagation leads to an exponential growth of a node’s current representation at every propagation step, making it extremely challenging to capture valuable dependencies between long-distance nodes. To address this issue, we introduce Graph Elimination Networks (GENs), which employ a specific algorithm to eliminate redundancies during neighborhood propagation. We demonstrate that GENs can enhance nodes’ perception of distant neighborhoods and extend the depth of network propagation. Extensive experiments show that GENs outperform the state-of-the-art methods on various graph-level and node-level datasets.","['Graph', 'Neural', 'Network,', 'Deep', 'Graph', 'Neural', 'Network,', 'Graph', 'Self-Attention,', 'Subgraph', 'Self-Attention,', 'Algorithm', 'Framework']","['UniversityXiangtanChina411105', 'UniversityXiangtanChina411105', 'UniversityHunanChina410082']"
"Survival analysis can sometimes involve individuals who will not experience the event of interest, forming what is known as the “cured group”. Identifying such individuals is not always possible beforehand, as they provide only right-censored data. Ignoring the presence of the cured group can introduce bias in the final model. This paper presents a method for estimating a semiparametric additive hazards model that accounts for the cured fraction. Unlike regression coefficients in a hazard ratio model, those in an additive hazard model measure hazard differences. The proposed method uses a primal-dual interior point algorithm to obtain constrained maximum penalized likelihood estimates of the model parameters, including the regression coefficients and the baseline hazard, subject to certain non-negativity constraints.


Keywords: Additive hazards model; Mixture cure model; Interval censoring; Maximum penalized likelihood estimation;
Automatic smoothing.",[''],"['China', 'Australia']"
"The notions of predictability and visibility are essential in the mathematical formulation of wave particle duality. The work of Jakob and Bergou [Phys. Rev. A 76, 052107] generalises these notions for higher-dimensional quantum systems, which were initially defined for qubits, and subsequently proves a complementarity relation between predictability and visibility. By defining the single-party information content of a quantum system as the addition of predictability and visibility, and assuming that entanglement in a bipartite system in the form of concurrence mutually excludes the single-party information, the authors have proposed a complementarity relation between the concurrence and the single-party information content. We show that the information content of a quantum system defined by Jakob and Bergou is nothing but the Hilbert-Schmidt distance between the state of the quantum system of our consideration and the maximally mixed state. Motivated by the fact that the trace distance is a good measure of distance as compared to the Hilbert-Schmidt distance from the information theoretic point of view, we, in this work, define the information content of a quantum system as the trace distance between the quantum state and the maximally mixed state. We then employ the quantum Pinsker’s inequality and the reverse Pinsker’s inequality to derive a new complementarity and a reverse complementarity relation between the single-party information content and the entanglement present in a bipartite quantum system in a pure state. As a consequence of our findings, we show that for a bipartite system in a pure state, its entanglement and the predictabilities and visibilities associated with the subsystems cannot be arbitrarily small as well as arbitrarily large.",[''],"['India', 'India', 'India', 'India.']"
"Measurement incompatibility has proved to be an important resource for information processing tasks. In this work, we analyze various levels of incompatibility of measurement sets. We provide operational classification of measurement incompatibility with respect to two elementary classical operations, viz., coarse-graining of measurement outcomes and convex mixing of different measurements. We derive analytical criteria for determining when a set of projective measurements is fully incompatible with respect to coarse-graining or convex mixing. Robustness against white noise is investigated for mutually unbiased bases that can sustain full incompatibility. Furthermore, we propose operational witnesses for different levels of incompatibility subject to classical operations, using the input-output statistics of Bell-type experiments as well as experiments in the prepare-and-measure scenario.",[''],"['India', 'India', 'India', 'Kingdom', 'India']"
,[''],[]
"The size of the smallest k𝑘kitalic_k-regular graph of girth g𝑔gitalic_g is denoted by the well studied function n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ).
We suggest generalizing this function to n⁢(H,g)𝑛𝐻𝑔n(H,g)italic_n ( italic_H , italic_g ), defined as the smallest size girth g𝑔gitalic_g graph covering the, possibly non-regular, graph H𝐻Hitalic_H.
We prove that the two main combinatorial bounds on n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ), the Moore lower bound and the Erdös Sachs upper bound,
carry over to the new setting of lifts, even in their non-asymptotic form.
We also consider two other generalizations of n⁢(k,g)𝑛𝑘𝑔n(k,g)italic_n ( italic_k , italic_g ):
i) The smallest size girth g𝑔gitalic_g graph sharing a universal cover with H𝐻Hitalic_H. We prove that it is the same as n⁢(H,g)𝑛𝐻𝑔n(H,g)italic_n ( italic_H , italic_g ) up to a multiplicative constant.
ii) The smallest size girth g𝑔gitalic_g graph with a prescribed degree distribution. We discuss this known generalization and argue that the new suggested definitions are superior.

We conclude with experimental results for a specific base graph and with some conjectures and open problems.",[''],['hooryshl@telhai.ac.il']
"As written by statistician George Box ”All models are wrong, but some are useful”, standard diffusion derivation or Feynman path ensembles use nonphysical nowhere differentiable trajectories of infinite kinetic energy - what seems wrong, bringing question of differences if doing it more right this article is focused on. To consider ensembles of more physical trajectories, we can work in (x,v)𝑥𝑣(x,v)( italic_x , italic_v ) phase space like in Langevin equation with velocity controlling spatial steps, here also controlled with spatial potential V⁢(x)𝑉𝑥V(x)italic_V ( italic_x ). There will be discussed and compared 4 approaches to predict stationary probability distributions: using Boltzmann ensemble of points in space (GRW - generic random walk) or in phase space (psGRW), and analogously Boltzmann ensemble of paths in space (MERW - maximal entropy random walk) and in phase space (psMERW). They have qualitatively different predictions, hopefully allowing to decide the most appropriate for various settings by distinguishing them experimentally. Path ensembles have much stronger Anderson-like localization exactly as in quantum ground state, proposed novel in phase space has additionally increased density of velocity as in potential gradient, decreased toward barrier. While MERW is thermodynamically in agreement with quantum mechanics, psMERW suggests slight corrections from consideration of more physical trajectories, which seem natural - reduced velocities toward close barriers, increased down potential gradients.",[''],['dudajar@gmail.com']
"Accurate determination of mass-loss rates from massive stars is important to understanding stellar and galactic
evolution and enrichment of the interstellar medium. Large-scale structure and variability in stellar winds have significant effects on mass-loss rates. Time-series observations provide direct quantification of such variability. Observations of this nature are available for some Galactic early supergiant stars but not yet for stars in lower metallicity environments such as the Magellanic Clouds. We utilise ultraviolet spectra from the Hubble Space Telescope ULLYSES program to demonstrate that the presence of structure in stellar winds of supergiant stars at low metallicities may be discerned from single-epoch spectra. We find evidence that, for given stellar luminosities and mean stellar wind optical depths, structure is more prevalent at higher metallicities. We confirm, at Large Magellanic Cloud (0.5 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT), Small Magellanic Cloud (0.2 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) and lower (0.14 – 0.1 Z⊙subscript𝑍direct-productZ_{\odot}italic_Z start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) metallicities, earlier Galactic results that there does not appear to be correlation between the degree of structure in stellar winds of massive stars and stellar effective temperature. Similar lack of correlation is found with regard to terminal velocity of stellar winds. Additional and revised values for radial velocities of stars and terminal velocities of stellar winds are presented. Direct evidence of temporal variability, on timescales of several days, in stellar wind at low metallicity is found. We illustrate that narrow absorption components in wind-formed profiles of Galactic OB stellar spectra remain common in early B supergiant spectra at low metallicities, providing means for better constraining hot, massive star mass-loss rates.",[''],[]
"We prove that the pushforwards of a very general class of fractal measures μ𝜇\muitalic_μ on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT under a large family of non-linear maps F:ℝd→ℝ:𝐹→superscriptℝ𝑑ℝF\colon\mathbb{R}^{d}\to\mathbb{R}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R exhibit polynomial Fourier decay: there exist C,η>0𝐶𝜂0C,\eta>0italic_C , italic_η > 0 such that |F⁢μ^⁢(ξ)|≤C⁢|ξ|−η^𝐹𝜇𝜉𝐶superscript𝜉𝜂|\widehat{F\mu}(\xi)|\leq C|\xi|^{-\eta}| over^ start_ARG italic_F italic_μ end_ARG ( italic_ξ ) | ≤ italic_C | italic_ξ | start_POSTSUPERSCRIPT - italic_η end_POSTSUPERSCRIPT for all ξ≠0𝜉0\xi\neq 0italic_ξ ≠ 0.
Using this, we prove that if Φ={φa:[0,1]→[0,1]}a∈𝒜Φsubscriptconditional-setsubscript𝜑𝑎→0101𝑎𝒜\Phi=\{\varphi_{a}\colon[0,1]\to[0,1]\}_{a\in\mathcal{A}}roman_Φ = { italic_φ start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT : [ 0 , 1 ] → [ 0 , 1 ] } start_POSTSUBSCRIPT italic_a ∈ caligraphic_A end_POSTSUBSCRIPT is an iterated function system consisting of analytic contractions, and there exists a∈𝒜𝑎𝒜a\in\mathcal{A}italic_a ∈ caligraphic_A such that φasubscript𝜑𝑎\varphi_{a}italic_φ start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT is not an affine map, then every non-atomic self-conformal measure for ΦΦ\Phiroman_Φ has polynomial Fourier decay; this result was obtained simultaneously by Algom, Rodriguez Hertz, and Wang.
We prove applications related to the Fourier uniqueness problem, Fractal Uncertainty Principles, and normal numbers in fractal sets.",[''],[]
"Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees. A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers). In this study we propose a contrastive approach for learning a binary event encoder from continuous time series data. As a preliminary result, we show that our approach has some potential in learning a valuable encoder.",[''],"['Denmark', 'Denmark']"
"The sequential interaction network usually find itself in a variety of applications, e.g., recommender system. Herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature Euclidean space.
Despite the promising results achieved by previous methods, a range of significant issues still largely remains open:
On the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference?
On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously?
On the learning paradigm, can we get rid of the label information costly to acquire?
To address the aforementioned issues, we propose a novel Contrastive model for Sequential Interaction Network learning on Co-Evolving RiEmannian spaces, CSincere.
To the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network.
In CSincere, we formulate a Cross-Space Aggregation for message-passing across representation spaces of different Riemannian geometries,
and design a Neural Curvature Estimator based on Ricci curvatures for modeling the space evolvement over time.
Thereafter, we present a Reweighed Co-Contrast between the temporal views of the sequential network,
so that the couple of Riemannian spaces interact with each other for the interaction prediction without labels.
Empirical results on 5 public datasets show the superiority of CSincere over the state-of-the-art methods.",[''],"['*', '[', '[', '[', '[', '[']"
"RGBT tracking has been widely used in various fields such as robotics, surveillance processing, and autonomous driving. Existing RGBT trackers fully explore the spatial information between the template and the search region and locate the target based on the appearance matching results. However, these RGBT trackers have very limited exploitation of temporal information, either ignoring temporal information or exploiting it through online sampling and training. The former struggles to cope with the object state changes, while the latter neglects the correlation between spatial and temporal information. To alleviate these limitations, we propose a novel Temporal Adaptive RGBT Tracking framework, named as TATrack. TATrack has a spatio-temporal two-stream structure and captures temporal information by an online updated template, where the two-stream structure refers to the multi-modal feature extraction and cross-modal interaction for the initial template and the online update template respectively. TATrack contributes to comprehensively exploit spatio-temporal information and multi-modal information for target localization. In addition, we design a spatio-temporal interaction (STI) mechanism that bridges two branches and enables cross-modal interaction to span longer time scales. Extensive experiments on three popular RGBT tracking benchmarks show that our method achieves state-of-the-art performance, while running at real-time speed.",[''],[]
"Solving the holography equation has long been a numerical task. While effective, the numeric approach has its own set of limitations. Relying solely on numerical approaches often obscures the intricate interplay and influence of the individual terms within the equation. This not only hampers a deeper understanding of the underlying physics but also makes it challenging to predict or control specific outcomes.
In this study, we address these challenges by leveraging our recently published Glückstad and Madsen (2023) updated Fraunhofer diffraction expression. This approach allows us to derive an analytic solution for complex-valued phase disks in on-axis holography. This solution facilitates the direct computation of each term’s influence within the holographic equation, paving the way for a more profound comprehension and application of the holographic process. When compared to experimental results and the numeric Fresnel diffraction solution, our analytic approach shows impressive accuracy, considering the inherent approximations. Notably, it remains precise for Fresnel numbers that extend well beyond the traditionally accepted boundaries of the Fraunhofer regime.",[''],[]
"This work provides an error analysis of quantum Krylov algorithms based on real-time evolutions, subject to generic errors in the outputs of the quantum circuits.
We establish a collective noise rate to summarize those errors, and prove that the resulting errors in the ground state energy estimates are leading-order linear in that noise rate.
This resolves a misalignment between known numerics, which exhibit this linear scaling, and prior theoretical analysis, which only provably obtained square-root scaling.
Our main technique is expressing generic errors in terms of an effective target Hamiltonian studied in an effective Krylov space.
These results provide a theoretical framework for understanding the main features of quantum Krylov errors.",[''],['USA']
"The early identification of diseases in cocoa pods is an important task to guarantee the production of high-quality cocoa. The use of artificial intelligence techniques such as machine learning, computer vision and deep learning are promising solutions to help identify and classify diseases in cocoa pods. In this paper we introduce the development and evaluation of a deep learning computational model applied to the identification of diseases in cocoa pods, focusing on “monilia” and “black pod” diseases. An exhaustive review of state-of-the-art of computational models was carried out, based on scientific articles related to the identification of plant diseases using computer vision and deep learning techniques. As a result of the search, EfficientDet-Lite4, an efficient and lightweight model for object detection, was selected. A dataset, including images of both healthy and diseased cocoa pods, has been utilized to train the model to detect and pinpoint disease manifestations with considerable accuracy. Significant enhancements in the model training and evaluation demonstrate the capability of recognizing and classifying diseases through image analysis. Furthermore, the functionalities of the model were integrated into an Android native mobile with an user-friendly interface, allowing to younger or inexperienced farmers a fast and accuracy identification of health status of cocoa pods.",[''],[]
"Building upon previous works of Proudfoot and Ramos, and using the categorical framework of Sam and Snowden, we extend the weak categorical minor theorem from undirected graphs to quivers. As case of study, we investigate the consequences on the homology of multipath complexes;
eg. on its torsion. Further, we prove a comparison result: we show that, when restricted to directed graphs without oriented cycles, multipath complexes and matching complexes yield functors which commute up to a blow-up operation on directed graphs. We use this fact to compute the homotopy type of matching complexes for a certain class of bipartite graphs also known as half-graphs or ladders. We complement the work with a study of the (representation) category of cones, and with analysing related consequences on magnitude cohomology of quivers.",[''],[]
"Femtoscopy is a unique tool to investigate the space-time geometry of the matter created in ultra-relativistic collisions. If the probability density distribution of hadron emission is parametrized, then the dependence of its parameters on particle momentum, collision energy, and collision geometry can be given. In recent years, several measurements came to light that indicated the adequacy of assuming a Lévy-stable shape for the mentioned distribution. In parallel, several new phenomenological developments appeared, aiding the interpretation of the experimental results, or providing tools for the measurements. In this paper we review and discuss some of these advances, phenomenological and experimental.",[''],[]
"Recently, anomalous Floquet topological phases without static counterparts have been observed in different systems, where periodically driven models are realized to support a winding number of 1 and a pair of edge modes in each quasienergy gap. Here, we focus on cold atomic gases in optical lattices and propose a novel driving scheme that breaks rotation symmetry but maintains inversion symmetry of the instantaneous Hamiltonian, and discover a novel type of anomalous Floquet topological phase with winding number larger than 1. By analyzing the condition of band touching under symmetry constraint, we map out the phase diagram exactly by varying the driving parameters and discuss the quasienergy spectra of typical topological phases, which can present multiple pairs of edge modes within a single gap. Finally, we suggest to characterize the topology of such phases by detecting the band inversion surfaces via quench dynamics.",[''],"['China', '100872,China', 'China', '100872,China', 'China', 'China', '100872,China', 'China']"
"Density functional theory calculations are used to systematically investigate the structural and electronic properties of MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT transition metal dichalcogenide monolayers with M = Cr, Mo, W and X = S, Se, Te that are doped with single (V, Nb, Ta) and double (Ti, Zr, Hf) acceptor dopants on the M site with local D3⁢hsubscript𝐷3ℎD_{3h}italic_D start_POSTSUBSCRIPT 3 italic_h end_POSTSUBSCRIPT symmetry in the dilute limit. Three impurity levels that arise from intervalley scattering are found above the valence band maxima (VBM): an orbitally doubly degenerate e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT level bound to the K/K′𝐾superscript𝐾′K/K^{\prime}italic_K / italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT VBM and a singly degenerate a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level bound to the ΓΓ\Gammaroman_Γ-point VBM.
Replacing S with Se or Te lowers the ΓΓ\Gammaroman_Γ point VBM substantially with respect to the K/K′𝐾superscript𝐾′K/K^{\prime}italic_K / italic_K start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT VBM bringing the a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level down with it. The relative positions of the impurity levels that determine the different structural and electronic properties of the impurities in p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers can thus be tuned by replacing S with Se or Te.

Single acceptors introduce a magnetic moment of 1μBsubscript𝜇B\,\mu_{\rm B}italic_μ start_POSTSUBSCRIPT roman_B end_POSTSUBSCRIPT in all MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Out-of-plane magnetic anisotropy energies as large as 10 meV/dopant atom are found thereby satisfying an essential condition for long-range ferromagnetic ordering in two dimensions.
For double acceptors in MS22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers, both holes occupy the high-lying a1′subscriptsuperscript𝑎′1a^{\prime}_{1}italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT level with opposite spins so there is no magnetic moment;
in MSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers the holes occupy the e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT level, a Jahn-Teller (JT) distortion wins the competition with exchange splitting resulting in the quenching of the magnetic moments. Even when the JT distortion is disallowed, magnetic double acceptors have a large in-plane magnetic anisotropy energy that is incompatible with long-range magnetic ordering in two dimensions.
The magnetic moments of pairs of single acceptors exhibit long-range ferromagnetic coupling except for MS22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT where the coupling is quenched for impurity pairs below a critical separation. For Se and Te compounds, the holes are accommodated in high-lying degenerate e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT levels which form triplets for all separations. However, for X=Te, a JT distortion lifts the degeneracy of the e′superscript𝑒′e^{\prime}italic_e start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT levels leading to a reduction of the exchange interaction between impurity pairs.
Deep, intrinsic, vacancy and antisite defects that localize the holes might stabilize the magnetization of p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Our systematic study of the p𝑝pitalic_p-doped MX22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers identifies 1H CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MoSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT as the most promising candidates for room temperature ferromagnetism.
We combine the exchange interaction estimated from the energy difference calculated for ferromagnetically and antiferromagnetically coupled pairs with Monte Carlo calculations to estimate the Curie temperatures TCsubscript𝑇CT_{\rm C}italic_T start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT for vanadium doped CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT and MoSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT monolayers. Room temperature values of TCsubscript𝑇CT_{\rm C}italic_T start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT are predicted for V dopant concentrations of 5% and 9%, respectively. In view of the instability of CrTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT in the 1H form, we suggest that the Crx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPTMo1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPT(Tey𝑦{}_{y}start_FLOATSUBSCRIPT italic_y end_FLOATSUBSCRIPTSe)1−y2{}_{1-y})_{2}start_FLOATSUBSCRIPT 1 - italic_y end_FLOATSUBSCRIPT ) start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT alloy system be studied.
A single d𝑑ditalic_d electron or hole is uncorrelated. However, in the single impurity limit, the residual self-interaction of this carrier in the local spin density approximation (LSDA) can be corrected by introducing a Hubbard U𝑈Uitalic_U. Doing so leads to a large increase of the ordering temperatures calculated in the LSDA (reducing the doping concentration needed to achieve room temperature ordering) but at the expense of introducing an indeterminate parameter U𝑈Uitalic_U.",[''],"['China', 'Netherlands', 'Netherlands']"
"Fix a stable degree-n𝑛nitalic_n rank-k𝑘kitalic_k bundle ℱℱ\mathcal{F}caligraphic_F on a complex elliptic curve for (coprime) 1≤k<n≥31𝑘𝑛31\leq k<n\geq 31 ≤ italic_k < italic_n ≥ 3. We identify the symplectic leaves of the Poisson structure introduced independently by Polishchuk and Feigin-Odesskii on ℙn−1≅ℙ⁢Ext1⁢(ℱ,𝒪)superscriptℙ𝑛1ℙsuperscriptExt1ℱ𝒪\mathbb{P}^{n-1}\cong\mathbb{P}\mathrm{Ext}^{1}(\mathcal{F},\mathcal{O})blackboard_P start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ≅ blackboard_P roman_Ext start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( caligraphic_F , caligraphic_O ) as precisely the loci classifying extensions 0→𝒪→ℰ→ℱ→0→0𝒪→ℰ→ℱ→00\to\mathcal{O}\to\mathcal{E}\to\mathcal{F}\to 00 → caligraphic_O → caligraphic_E → caligraphic_F → 0 with ℰℰ\mathcal{E}caligraphic_E fitting into a fixed isomorphism class, verifying a claim of Feigin-Odesskii. We also classify the bundles ℰℰ\mathcal{E}caligraphic_E which do fit into such extensions in geometric / combinatorial terms, involving their Harder-Narasimhan polygons introduced by Shatz.",[''],[]
"From politicians to podcast hosts, online platforms have systematically banned (“deplatformed”) influential users for breaking platform guidelines.
Previous inquiries on the effectiveness of this intervention are inconclusive because
1) they consider only few deplatforming events;
2) they consider only overt engagement traces (e.g., likes and posts) but not passive engagement (e.g., views);
3) they do not consider all the potential places users impacted by the deplatforming event might migrate to.
We address these limitations in a longitudinal, quasi-experimental study of 165 deplatforming events targeted at 101 influencers.
We collect deplatforming events from Reddit posts and then manually curate the data, ensuring the correctness of a large dataset of deplatforming events.
Then, we link these events to Google Trends and Wikipedia page views, platform-agnostic measures of online attention that capture the general public’s interest in specific influencers.
Through a difference-in-differences approach, we find that deplatforming reduces online attention toward influencers.
After 12 months, we estimate that online attention toward deplatformed influencers is reduced by
−--63% (95% CI [−--75%,−--46%]) on Google and by
−--43% (95% CI [−--57%,−--24%]) on Wikipedia.
Further, as we study over a hundred deplatforming events, we can analyze in which cases deplatforming is more or less impactful, revealing nuances about the intervention.
Notably, we find that both permanent and temporary deplatforming reduce online attention toward influencers;
Overall, this work contributes to the ongoing effort to map the effectiveness of content moderation interventions, driving platform governance away from speculation.",['online communities; fringe online communities; content moderation; online radicalization; deplatforming; social networks'],"['EPFLSwitzerland', 'UniversityUSA', 'EPFLSwitzerland', 'EPFLSwitzerland', 'EPFLSwitzerland']"
,[''],[]
"In this paper, we examine the parameter estimation performance of three well-known sinusoidal models for speech and audio. The first one is the standard Sinusoidal Model (SM), which is based on the Fast Fourier Transform (FFT). The second is the Exponentially Damped Sinusoidal Model (EDSM) which has been proposed in the last decade, and utilizes a subspace method for parameter estimation, and finally the extended adaptive Quasi-Harmonic Model (eaQHM), which has been recently proposed for AM-FM decomposition, and estimates the signal parameters using Least Squares on a set of basis function that are adaptive to the local characteristics of the signal. The parameter estimation of each model is briefly described and its performance is compared to the others in terms of signal reconstruction accuracy versus window size on a variety of synthetic signals and versus the number of sinusoids on real signals. The latter include highly non stationary signals, such as singing voices and guitar solos. The advantages and disadvantages of each model are presented via synthetic signals and then the application on real signals is discussed. Conclusively, eaQHM outperforms EDS in medium-to-large window size analysis, whereas EDSM yields higher reconstruction values for smaller analysis window sizes. Thus, a future research direction appears to be the merge of adaptivity of the eaQHM and parameter estimation robustness of the EDSM in a new paradigm for high-quality analysis and resynthesis of general audio signals.","['Index', 'Terms: ', 'Sinusoidal', 'Model, adaptive', 'Quasi-Harmonic', 'Model,', 'Exponentially', 'Damped', 'Sinusoids,', 'Parameter', 'Estimation,', 'Speech', 'Analysis,', 'Audio', 'Analysis']",[]
"The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM to detail each entity. The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity. Finally, VideoDrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account. The diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos. Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference.",[''],[]
"This paper documents a year-long experiment to “profile” the process of learning a programming language: gathering data to understand what makes a language hard to learn, and using that data to improve the learning process. We added interactive quizzes to The Rust Programming Language, the official textbook for learning Rust. Over 13 months, 62,526 readers answered questions 1,140,202 times. First, we analyze the trajectories of readers. We find that many readers drop-out of the book early when faced with difficult language concepts like Rust’s ownership types. Second, we use classical test theory and item response theory to analyze the characteristics of quiz questions. We find that better questions are more conceptual in nature, such as asking why a program does not compile vs. whether a program compiles. Third, we performed 12 interventions into the book to help readers with difficult questions. We find that on average, interventions improved quiz scores on the targeted questions by +20%. Fourth, we show that our technique can likely generalize to languages with smaller user bases by simulating our statistical inferences on small N𝑁Nitalic_N. These results demonstrate that quizzes are a simple and useful technique for understanding language learning at all scales.","['rust education, digital textbooks, item response theory']",['Island02912USA']
"Concept-based learning improves a deep learning model’s interpretability by explaining its predictions via human-understandable concepts.
Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts.
Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures.
In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts.
To understand locality, we analyse how changes to features outside of a concept’s spatial or semantic locality impact concept predictions.
Our results suggest that even in well-defined scenarios where the presence of a concept is localised to a fixed feature subspace, or whose semantics are correlated to a small subset of other concepts, CBMs fail to learn this locality.
These results cast doubt upon the quality of concept representations learnt by CBMs and strongly suggest that concept-based explanations may be fragile to changes outside their localities.",[''],[]
"Magnonic frequency combs have recently attracted particular attention due to their potential impact on spin-wave science.
Here, we demonstrate theoretically the generation of ultra-wideband (UWB) magnonic frequency combs induced by dissipative coupling in an open cavity magnomechanical system.
A broadband comb with gigahertz repetition rates is obtained in the magnonic spectrum and a typical non-perturbation frequency-comb structure is also observed.
The total width of the magnonic comb in the robust plateau region can be up to ∼400similar-toabsent400\sim 400∼ 400 comb lines, which is much broader and flatter than the reported in the previous works.
Furthermore, when the dissipative coupling strength is further increased, the chaotic motion is predicted in the magnonic spectrum.
Our results provide an in-depth understanding of nonlinear magnomechanic dynamics in open quantum systems and fundamentally broadens the research range of magnon in wider spectral regimes.",[''],['China']
"The strategies for and the performance of the CMS tracker alignment during the ongoing Run 3 data-taking period are described. The results of the very first tracker alignment for Run 3 data reprocessing performed with cosmic rays and collision tracks recorded at the unprecedented center of mass energy of 13.6 TeV are presented. Also, the performance after deployment of a more granular automated alignment associated with the improvement of the alignment calibration already during data taking is discussed. Finally, the prospects for the tracker alignment calibration during the Run 3 data-taking period, in light of the gained operational experience, are discussed.",[''],[]
"Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization.",[''],[]
"When identifying electrical, mechanical, or biological systems, parametric continuous-time identification methods can lead to interpretable and parsimonious models when the model structure aligns with the physical properties of the system. Traditional linear system identification may not consider the most parsimonious model when relying solely on unfactored transfer functions, which typically result from standard direct approaches. This paper presents a novel identification method that delivers additive models for both open and closed-loop setups. The estimators that are derived are shown to be generically consistent, and can admit the identification of marginally stable additive systems. Numerical simulations show the efficacy of the proposed approach, and its performance in identifying a modal representation of a flexible beam is verified using experimental data.",[''],[]
,[''],[]
,[''],[]
"High temperature REBCO superconducting tapes are very promising for high-field magnets. With high magnetic field application there are high electro-mechanical forces, and thus concern for mechanical damage. Due to the presence of large screening currents and composite structure of the tape, the mechanical design of these magnets are not straight forward. In addition, many contemporary designs use insulated winding. In this work we develop a novel two-dimensional axisymmetric finite element tool programmed in MATLAB that assumes the displacement field within linear elastic range. The stack of pancakes and a large number of REBCO tape turns are approximated as an an-isotropic bulk hollow cylinder. Our results agree with uni-axial stress experiments in literature, validating the bulk approximation. Here, we study the following configuration. The current is first ramp up to below the critical current and we calculate the screening currents and the forces that they cause using the MEMEP model. This electromagnetic model can now take insulated magnets into account. As a case study, 32 T REBCO superconductor magnet, is taken and simulated numerically. We have done complete mechanical analysis of the magnet by including the axial and shear mechanical quantities for each pancake unlike previous work where only radial and circumferential quantities are focused. Effect on mechanical quantities without screening current is also calculated and compared. It is shown that including screening current induced field strongly affect the mechanical quantities, specially the shear stress. The latter might be the critical quantity for certain magnet configurations. Additionally, in order to overcome high stresses, a stiff over banding of different material is considered and numerically modelled which significantly reduces the mechanical stresses. The FE based model developed is efficient to calculate the mechanical behaviour of any general superconductor magnet and its devices.",[''],[]
"The deployment of several large scale arrays is envisioned to study astroparticles at ultra-high energies. In order to circumvent the heavy computational costs of exploring and optimizing their layouts, we have developed a pruning method. It consists in i) running a set of microscopic simulations and interpolate them over a dense, regularly spaced array of detection units, and ii) pruning the unnecessary units out of the layout, in order to obtain the shower footprint on a newly shaped layout. This method offers flexibility to test various layout parameters, instrumental constraints, and physical inputs, with a drastic reduction in the required CPU time. The method can be universally applied to optimize arrays of any size, and using any detection techniques.
For demonstration, we apply the pruning tool to radio antenna layouts, which allows us to discuss the interplay between the energy and inclination of air-showers on the size of the radio footprint and the intensity of the signal on the ground. Some rule-of-thumb conclusions that can be drawn for this specific case are: i) a hexagonal geometry is more efficient than a triangular geometry, ii) the detection efficiency of the array is stable to changes in the spacing between radio antennas around 1000mm\rm{m}roman_m step size, iii) for a given number of antennas, adding a granular infill on top of a coarse hexagonal array is more efficient than instrumenting the full array with a less dense spacing.",[''],[]
"In deep learning, classification tasks are formalized as optimization problems solved via the minimization of the cross-entropy.
However, recent advancements in the design of objective functions allow the f𝑓fitalic_f-divergence measure to generalize the formulation of the optimization problem for classification.
With this goal in mind, we adopt a Bayesian perspective and formulate the classification task as a maximum a posteriori probability problem.
We propose a class of objective functions based on the variational representation of the f𝑓fitalic_f-divergence, from which we extract a list of five posterior probability estimators leveraging well-known f𝑓fitalic_f-divergences.
In addition, driven by the challenge of improving the state-of-the-art approach, we propose a bottom-up method that leads us to the formulation of a new objective function (and posterior probability estimator) corresponding to a novel f𝑓fitalic_f-divergence referred to as shifted log (SL).
First, we theoretically prove the convergence property of the posterior probability estimators.
Then, we numerically test the set of proposed objective functions in three application scenarios: toy examples, image data sets, and signal detection/decoding problems. The analyzed tasks demonstrate the effectiveness of the proposed estimators and that the SL divergence achieves the highest classification accuracy in almost all the scenarios.","['Index', 'Terms: ', 'Classification, decoding, estimation,', 'KL divergence, f𝑓fitalic_f-divergence,', 'MAP, neural networks, cross-entropy, deep learning,', 'ML, discriminative', 'AI.']",[]
"Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs outperform our expectations in finding issues within applications correctly flagging insecure apps in 91.67% of cases in the Ghera benchmark. We use inferences from our experiments towards building a robust and actionable vulnerability detection system and demonstrate its effectiveness. Our experiments also shed light on how different various simple configurations can affect the True Positive (TP) and False Positive (FP) rates.",[''],"['Canada', 'Canada', 'Canada', 'Canada', 'Canada']"
"Motivated by the studies of neural networks (e.g.,the neural tangent kernel theory), we perform a study on the large-dimensional behavior of kernel ridge regression (KRR) where the sample size n≍dγasymptotically-equals𝑛superscript𝑑𝛾n\asymp d^{\gamma}italic_n ≍ italic_d start_POSTSUPERSCRIPT italic_γ end_POSTSUPERSCRIPT for some γ>0𝛾0\gamma>0italic_γ > 0.
Given an RKHS ℋℋ\mathcal{H}caligraphic_H associated with an inner product kernel defined on the sphere 𝕊dsuperscript𝕊𝑑\mathbb{S}^{d}blackboard_S start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, we suppose that the true function fρ*∈[ℋ]ssuperscriptsubscript𝑓𝜌superscriptdelimited-[]ℋ𝑠f_{\rho}^{*}\in[\mathcal{H}]^{s}italic_f start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ∈ [ caligraphic_H ] start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT, the interpolation space of ℋℋ\mathcal{H}caligraphic_H with source condition s>0𝑠0s>0italic_s > 0. We first determined the exact order (both upper and lower bound) of the generalization error of kernel ridge regression for the optimally chosen regularization parameter λ𝜆\lambdaitalic_λ. We then further showed that when 0<s≤10𝑠10<s\leq 10 < italic_s ≤ 1, KRR is minimax optimal; and when s>1𝑠1s>1italic_s > 1, KRR is not
minimax optimal (a.k.a. the saturation effect).
Our results illustrate that the curves of rate varying along γ𝛾\gammaitalic_γ exhibit the periodic plateau behavior and the multiple descent behavior and show how the curves evolve with s>0𝑠0s>0italic_s > 0.
Interestingly, our work provides a unified viewpoint of several recent works on kernel regression in the large-dimensional setting, which correspond to s=0𝑠0s=0italic_s = 0 and s=1𝑠1s=1italic_s = 1 respectively.",[''],[]
"Antifreeze proteins (AFPs) are remarkable biomolecules that suppress ice formation at trace concentrations.
To inhibit ice growth, AFPs must not only bind to ice crystals, but also resist engulfment by ice.
The highest supercooling, Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, for which AFPs are able to resist engulfment is widely believed to scale as the inverse of the separation, L𝐿Litalic_L, between bound AFPs, whereas its dependence on the molecular characteristics of the AFP remains poorly understood.
By using specialized molecular simulations and interfacial thermodynamics,
here we
show that in contrast with conventional wisdom, Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT scales as L−2superscript𝐿2L^{-2}italic_L start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT and not as L−1superscript𝐿1L^{-1}italic_L start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
We further show that Δ⁢T*Δsuperscript𝑇\Delta T^{*}roman_Δ italic_T start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is proportional to AFP size and that diverse naturally occurring AFPs are optimal at resisting engulfment by ice.
By facilitating the development of AFP structure-function relationships,
we hope that our findings will pave the way for the rational design of novel AFPs.",[''],['Pennsylvania']
"Vector quantization-based image semantic communication systems have successfully boosted transmission efficiency, but face a challenge with conflicting requirements between codebook design and digital constellation modulation. Traditional codebooks need a wide index range, while modulation favors few discrete states. To address this, we propose a multilevel generative semantic communication system with a two-stage training framework. In the first stage, we train a high-quality codebook, using a multi-head octonary codebook (MOC) to compress the index range. We also integrate a residual vector quantization (RVQ) mechanism for effective multilevel communication. In the second stage, a noise reduction block (NRB) based on Swin Transformer is introduced, coupled with the multilevel codebook from the first stage, serving as a high-quality semantic knowledge base (SKB) for generative feature restoration. Experimental results highlight MOC-RVQ’s superior performance over methods like BPG or JPEG, even without channel error correction coding.","['Index', 'Terms:  vector quantization, generative semantic communication, two-stage training, semantic knowledge base']",[]
"Agricultural management, with a particular focus on fertilization strategies, holds a central role in shaping crop yield, economic profitability, and environmental sustainability. While conventional guidelines offer valuable insights, their efficacy diminishes when confronted with extreme weather conditions, such as heatwaves and droughts. In this study, we introduce an innovative framework that integrates Deep Reinforcement Learning (DRL) with Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train an intelligent agent to master optimal nitrogen fertilization management. Through a series of simulation experiments conducted on corn crops in Iowa, we compare Partially Observable Markov Decision Process (POMDP) models with Markov Decision Process (MDP) models. Our research underscores the advantages of utilizing sequential observations in developing more efficient nitrogen input policies. Additionally, we explore the impact of climate variability, particularly during extreme weather events, on agricultural outcomes and management. Our findings demonstrate the adaptability of fertilization policies to varying climate conditions. Notably, a fixed policy exhibits resilience in the face of minor climate fluctuations, leading to commendable corn yields, cost-effectiveness, and environmental conservation. However, our study illuminates the need for agent retraining to acquire new optimal policies under extreme weather events. This research charts a promising course toward adaptable fertilization strategies that can seamlessly align with dynamic climate scenarios, ultimately contributing to the optimization of crop management practices.",[''],[]
"The double star S⁢(m1,m2)𝑆subscript𝑚1subscript𝑚2S(m_{1},m_{2})italic_S ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) is obtained from joining the centres of a star with m1subscript𝑚1m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT leaves and a star with m2subscript𝑚2m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT leaves.
We give a short proof of a new upper bound on the two-colour Ramsey number of S⁢(m1,m2)𝑆subscript𝑚1subscript𝑚2S(m_{1},m_{2})italic_S ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) which holds for all m1,m2subscript𝑚1subscript𝑚2m_{1},m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with 5+12⁢m2<m1<3⁢m2512subscript𝑚2subscript𝑚13subscript𝑚2\frac{\sqrt{5}+1}{2}m_{2}<m_{1}<3m_{2}divide start_ARG square-root start_ARG 5 end_ARG + 1 end_ARG start_ARG 2 end_ARG italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 3 italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Our result implies that for all positive m𝑚mitalic_m, the Ramsey number of the double star S⁢(2⁢m,m)𝑆2𝑚𝑚S(2m,m)italic_S ( 2 italic_m , italic_m ) is at most 4.275⁢m4.275𝑚4.275m4.275 italic_m.",[''],[]
"Recently, the advent of large language models (LLMs) has revolutionized generative agents.
Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users.
However, the absence of a comprehensive benchmark impedes progress in this field.
To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset.
The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts.
It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike.
CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions.
To facilitate the convenient evaluation for these subjective metrics in CharacterEval, we further developed CharacterRM, a role-playing reward model based on human annotations, which has a higher correlation with human judgment compared to GPT-4.
Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation.
Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval.",[''],[]
,[''],[]
"In this study, we investigate the conductivity of a two-dimensional (2D) system in HgTe quantum well comprising two types of carriers with linear and quadratic spectra, respectively. The interactions between the two-dimensional Dirac holes and the heavy holes lead to the breakdown of Galilean invariance, resulting in interaction-limited resistivity. Our exploration of the transport properties spans from low temperatures, where both subsystems are fully degenerate, to higher temperatures, where the Dirac holes remain degenerate while the heavy holes follow Boltzmann statistics, creating a partially degenerate regime. Through a developed theory, we successfully predict the behavior of resistivity as ρ∼T2similar-to𝜌superscript𝑇2\rho\sim T^{2}italic_ρ ∼ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and ρ∼T3similar-to𝜌superscript𝑇3\rho\sim T^{3}italic_ρ ∼ italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT for the fully degenerate and partially degenerate regimes, respectively, which is in reasonable agreement with experimental observations. Notably, at elevated temperatures, the interaction-limited resistivity surpasses the resistivity caused by impurity scattering by a factor of 5-6. These findings imply that the investigated system serves as a versatile experimental platform for exploring various interaction-limited transport regimes in two component plasma.",[''],"['Brazil', 'Russia', 'Russia', 'Russia', 'Russia']"
"We identify an extended diffuse radio emission (J1507+3013) around an elliptical galaxy from the Very Large Array (VLA) Faint Images of Radio Sky at Twenty-cm (FIRST) survey. J1507+3013 possesses a morphology similar to the recently identified circular, low-surface-brightness, edge-brightened radio sources commonly known as odd radio circles (ORCs). Such diffuse emissions, as reported in the current paper, are also found in mini haloes and fossil radio galaxies, but the results presented in the current paper do not match the properties of mini haloes or fossil radio galaxies. The extended emission observed in J1507+3013 around an elliptical galaxy is a very rare class of diffuse emission which is unlike any previously known classes of diffuse emission. The extended diffuse emission of J1507+3013 is also detected in LOFAR at 144 MHz. J1507+3013 is hosted by an optical galaxy near the geometrical centre of the structure with a photometric redshift of z=0.079𝑧0.079z=0.079italic_z = 0.079. The physical extent of J1507+3013 is approximately 68 kpc, with a peak-to-peak angular size of 44 arcsec. J1507+3013 shows significantly higher flux densities compared to previously discovered ORCs. The spectral index of J1507+3013 varies between –0.90 and –1.4 in different regions of the diffused structure, which is comparable to previously discovered ORCs but less steep than mini halos and fossil radio galaxies. If we consider J1507+3013 as a candidate ORC, then this would be the closest and most luminous ORC discovered so far. This paper describes the radio, spectral, and optical/IR properties of J1507+3013 to study the nature of this source.",[''],[]
"At time zero, there are N𝑁Nitalic_N identical point particles in the line (1D) which are characterized by their positions and velocities. Both values are given randomly and independently from each other, with arbitrary probability densities. Each particle evolves at constant velocity until eventually they meet. When this happens, a perfectly-plastic collision is produced, resulting in a new particle composed by the sum of their masses and the weighted average velocity.
The merged particles evolve indistinguishably from the non-merged ones, i.e. they move at constant velocity until a new plastic collision eventually happens.
As in any open system, the particles are not confined to any region or reservoir, so as time progresses, they go on to infinity.
From this non-equilibrium process, the number of (now, non-identical) final particles, X~Nsubscript~𝑋𝑁\tilde{X}_{N}over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, the distribution of masses of these final particles and the kinetic energy loss from all plastic collisions, is studied. Counterintuitively, the way to achieve the number of final particles and each of their masses does not need to rely on evolving the particle system; this result can be obtained by simply considering the initial conditions. Moreover, they can also be used to obtain an accurate approximation of the energy loss. Finally, I will also present strong evidence for the validity of the following conjecture: ⟨X~N⟩=∑k=1𝑁⁢1kdelimited-⟨⟩subscript~𝑋𝑁𝑁𝑘11𝑘\langle\tilde{X}_{N}\rangle=\overset{N}{\underset{k=1}{\sum}}\frac{1}{k}⟨ over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ⟩ = overitalic_N start_ARG start_UNDERACCENT italic_k = 1 end_UNDERACCENT start_ARG ∑ end_ARG end_ARG divide start_ARG 1 end_ARG start_ARG italic_k end_ARG (which behaves as l⁢o⁢g⁢(N)+γ𝑙𝑜𝑔𝑁𝛾log(N)+\gammaitalic_l italic_o italic_g ( italic_N ) + italic_γ for large N𝑁Nitalic_N), additionally an explicit expression for the variance will also be given.","['Many-body dynamics, out-of-equilibrium systems, 1D system']","['Argentina,', 'Argentina.']"
"Large scale analytics engines have become a core dependency for modern data-driven enterprises to derive business insights and drive actions. These engines support a large number of analytic jobs processing huge volumes of data on a daily basis, and workloads are often inundated with overlapping computations across multiple jobs.
Reusing common computation is crucial for efficient cluster resource utilization and reducing job execution time. Detecting common computation
is the first and key step for reducing this computational redundancy. However, detecting equivalence on large-scale analytics engines requires efficient and scalable solutions that are fully automated. In addition, to maximize computation reuse, equivalence needs to be detected at the semantic level instead of just the syntactic level (i.e., the ability to detect semantic equivalence of seemingly different-looking queries). Unfortunately, existing solutions fall short of satisfying these requirements.
In this paper, we take a major step towards filling this gap by proposing GEqO, a portable and lightweight machine-learning-based framework for efficiently identifying semantically equivalent computations at scale. GEqO introduces two machine-learning-based filters that quickly prune out nonequivalent subexpressions and employs a semi-supervised learning feedback loop to iteratively improve its model with an intelligent sampling mechanism. Further, with its novel database-agnostic featurization method, GEqO can transfer the learning from one workload and database to another. Our extensive empirical evaluation shows that, on TPC-DS-like queries, GEqO yields significant performance gains—up to 200×200\times200 × faster than automated verifiers—and finds up to 2×2\times2 × more equivalences than optimizer and signature-based equivalence approaches.",[''],"['LabUSA', 'LabUSA', 'LabUSA', 'MicrosoftUSA', 'SmartAppsUSA', 'LabUSA']"
,[''],[]
"We study Hilbert Poincaré series associated to general seed functions and construct Cohen’s kernels and double Eisenstein series as series of Hilbert Poincaré series. Then we calculate the Rankin-Cohen brackets of Hilbert Poincaré series and Hilbert modular forms and extend Zagier’s kernel formula to totally real number fields. Finally, we show that the Rankin-Cohen brackets of two different types of Eisenstein series are special values of double Eisenstein series up to a constant.","['Key words and phrases:', 'Hilbert modular form,', 'Poincaré series,', 'Rankin-Cohen bracket,', 'Cohen’s kernel, double', 'Eisenstein series']",[]
"Automatic machine translation metrics often use human translations to determine the quality system translations.
Common wisdom in the field dictates that the human references should be of very high quality.
However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation.
We find that higher-quality references lead to better metric correlations with humans at the segment-level.
Having up to 7 references per segment and taking their average helps all metrics.
Interestingly, the references from vendors of different qualities can be mixed together and improve metric success.
Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success.
These findings can be used by evaluators of shared tasks when references need to be created under a certain budget.",[''],[]
,[''],[]
"Given the potential for technology to inflict harm and injustice on society, it is imperative that we cultivate a sense of social responsibility among our students as they progress through the Computer Science (CS) curriculum.
Our students need to be able to examine the social complexities in which technology development and use are situated.
Also, aligning students’ personal goals and their ability to achieve them in their field of study is important for promoting motivation and a sense of belonging.
Promoting communal goals while learning computing can help broaden participation, particularly among groups who have been historically marginalized in computing.
Keeping these considerations in mind, we piloted an introductory Java programming course in which activities engaging students in ethical and socially responsible considerations were integrated across modules.
Rather than adding social on top of the technical content, our curricular approach seeks to weave them together.
The data from the class suggests that the students found the inclusion of the social context in the technical assignments to be more motivating and expressed greater agency in realizing social change.
We share our approach to designing this new introductory socially responsible computing course and the students’ reflections.
We also highlight seven considerations for educators seeking to incorporate socially responsible computing.","['SRC, responsibility, social impact, ethics, power, critical pedagogy']","['USA', 'USA', 'USA', 'USA', 'USA']"
"Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs’ behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. Drawing inspiration from educational and cognitive research theories Bruner (1964, 1960); Jayashri and Kalaiselvi (2018), we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches. Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures inherent within LLMs. Initially conceived as a means to steer LLMs efficiently, we hope that insights gained from knowledge editing research could shed light on the underlying knowledge mechanisms of LLMs. To facilitate future research, we have released an open-source framework, EasyEdit111https://github.com/zjunlp/EasyEdit. 

      The contributions of the authors are detailed in §§\lx@sectionsign§Contributions., which will enable practitioners to efficiently and flexibly implement knowledge editing for LLMs. Finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications.",[''],[]
,[''],[]
"Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area. Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development. A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented.
The study concludes by addressing the challenges faced and suggesting potential research directions in this field.","['Index', 'Terms: \nwireless channel modeling, physics-based modeling, deep learning, 3D segmentation, knowledge distillation.']",['3mingyue.ji@utah.edu']
,[''],[]
"Computing reduced-order models using non-intrusive methods is particularly attractive for systems that are simulated using black-box solvers.
However, obtaining accurate data-driven models can be challenging, especially if the underlying systems exhibit large-amplitude transient growth.
Although these systems may evolve near a low-dimensional subspace that can be easily identified using standard techniques such as Proper Orthogonal Decomposition (POD), computing accurate models often requires projecting the state onto this subspace via a non-orthogonal projection.
While appropriate oblique projection operators can be computed using intrusive techniques that leverage the form of the underlying governing equations, purely data-driven methods currently tend to achieve dimensionality reduction via orthogonal projections, and this can lead to models with poor predictive accuracy.
In this paper, we address this issue by introducing a non-intrusive framework designed to simultaneously identify oblique projection operators and reduced-order dynamics.
In particular, given training trajectories and assuming reduced-order dynamics of polynomial form, we fit a reduced-order model by solving an optimization problem over the product manifold of a Grassmann manifold, a Stiefel manifold, and several linear spaces (as many as the tensors that define the low-order dynamics).
Furthermore, we show that the gradient of the cost function with respect to the optimization parameters can be conveniently written in closed-form, so that there is no need for automatic differentiation.
We compare our formulation with state-of-the-art methods on three examples: a three-dimensional system of ordinary differential equations, the complex Ginzburg-Landau (CGL) equation, and a two-dimensional lid-driven cavity flow at Reynolds number R⁢e=8300𝑅𝑒8300Re=8300italic_R italic_e = 8300.",[''],[]
"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK’s public sector urgently needs to develop more systematic methods for taking advantage of the technology.
Keywords: Generative AI, public services, productivity",[''],[]
"First we show that physics-informed neural networks are not suitable for a large class of parabolic partial differential equations including the Fokker-Planck equation. Then we devise an algorithm to compute solutions of the Fokker-Planck equation using the zeros of Fokker-Planck operator and the Feynman-Kac formula. The resulting algorithm is mesh-free, highly parallelizable and able to compute solutions pointwise, thus mitigating the curse of dimensionality in a practical sense. We analyze various nuances of this algorithm that are determined by the drift term in the Fokker-Planck equation. We work with problems ranging in dimensions from 2 to 10. We demonstrate that this algorithm requires orders of magnitude fewer trajectories for each point in space when compared to Monte-Carlo. We also prove that under suitable conditions the error that is caused by letting some trajectories (associated with the Feynman-Kac expectation) escape our domain of knowledge is proportional to the fraction of trajectories that escape.",[''],[]
"We investigate the number of squares in a very broad family of binary recurrence
sequences with u0=1subscript𝑢01u_{0}=1italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1. We show that there are at most two distinct squares in
such sequences (the best possible result), except under such very special conditions
where we prove there are at most three such squares.","['Key words and phrases: binary recurrence sequences;', 'Diophantine approximations.']",[]
"In recent years, privacy-preserving machine learning algorithms have attracted increasing attention because of their important applications in many scientific fields. However, in the literature, most privacy-preserving algorithms demand learning objectives to be strongly convex and Lipschitz smooth, which thus cannot cover a wide class of robust loss functions (e.g., quantile/least absolute loss). In this work, we aim to develop a fast privacy-preserving learning solution for a sparse robust regression problem. Our learning loss consists of a robust least absolute loss and an ℓ1subscriptℓ1\ell_{1}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT sparse penalty term. To fast solve the non-smooth loss under a given privacy budget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE) algorithm for least absolute deviation regression. Our algorithm achieves a fast estimation by reformulating the sparse LAD problem as a penalized least square estimation problem and adopts a three-stage noise injection to guarantee the (ϵ,δ)italic-ϵ𝛿(\epsilon,\delta)( italic_ϵ , italic_δ )-differential privacy. We show that our algorithm can achieve better privacy and statistical accuracy trade-off compared with the state-of-the-art privacy-preserving regression algorithms. In the end, we conduct experiments to verify the efficiency of our proposed FRAPPE algorithm.",[''],[]
"Reproducing kernel Hilbert spaces (RKHSs) are Hilbert spaces of functions where pointwise evaluation is continuous. There are known examples of RKHSs that are Banach algebras under pointwise multiplication. These examples are built from weights on the dual of a locally compact abelian group. In this paper we define an algebra structure on an RKHS that is equivalent to subconvolutivity of the weight for known examples (referred to as reproducing kernel Hilbert algebras, or RKHAs). We show that the class of RKHAs is closed under the Hilbert space tensor product and the pullback construction on the category of RKHSs. The subcategory of RKHAs becomes a monoidal category with the spectrum as a monoidal functor to the category of topological spaces. The image of this functor is shown to contain all compact subspaces of ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for n>0𝑛0n>0italic_n > 0.",[''],"['USA', 'USA']"
"The article by Anton E. M. van de Ven, Class. Quantum Grav. 15 (1998), is one of the fundamental references for higher-order heat kernel coefficients
in curved backgrounds and with non-abelian gauge connections.
In this manuscript, we point out two errors and ambiguities in the 𝖺5subscript𝖺5\mathsf{a}_{5}sansserif_a start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT coefficient, which may also affect the higher-order ones.",[''],[]
"Critical slowing down and topological freezing severely hinder Monte Carlo sampling of lattice field theories as the continuum limit is approached. Recently, significant progress has been made in applying a class of generative machine learning models, known as “flow-based” samplers, to combat these issues. These generative samplers also enable promising practical improvements in Monte Carlo sampling, such as fully parallelized configuration generation. These proceedings review the progress towards this goal and future prospects of the method.",[''],[]
"We study maximally supersymmetric irrelevant deformations of the D1-D5 CFT that correspond to following the attractor flow in reverse in the dual half-BPS black string solutions of type IIB supergravity on K3. When a single, quadratic condition is imposed on the parameters of the 22222222 such irrelevant deformations, the asymptotics of the solution degenerate to a linear dilaton-like spacetime. We identify each such degeneration limit with a known decoupling limit of string theory, which yields little string theory or deformations thereof (the so-called open brane LST, or ODp𝑝pitalic_p theories), compactified to two dimensions. This suggests that a 21212121-parameter family of the above deformations leads to UV-complete theories, which are string theories decoupled from gravity that are continuously connected to each other. All these theories have been argued to display Hagedorn behaviour; we show that including the F1 strings leads to an additional Cardy term. The resulting entropy formula closely resembles that of single-trace T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG-deformed CFTs, whose generalisations could provide possibly tractable effective two-dimensional descriptions of the above web of theories.
We also consider the asymptotically flat black strings. At fixed temperature, the partition function is dominated by thermodynamically stable, ‘small’ black string solutions, similar to the ones in the decoupled backgrounds. We show that certain asymptotic symmetries of these black strings bear a striking resemblance with the state-dependent symmetries of single-trace T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG, and break down precisely when the background solution reaches the ‘large’ black string threshold. This suggests that small, asymptotically flat black strings may also admit a T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG - like effective description.",[''],[]
"Even-hole-free graphs pose a central challenge in identifying hereditary classes of bounded treewidth. We investigate this matter by presenting and studying the following conjecture: for an integer t≥4𝑡4t\geq 4italic_t ≥ 4 and a graph H𝐻Hitalic_H, every even-hole-free graph of large enough treewidth has an induced subgraph isomorphic to either Ktsubscript𝐾𝑡K_{t}italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT or H𝐻Hitalic_H, if (and only if) H𝐻Hitalic_H is a K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free chordal graph. The “only if” part follows from the properties of the so-called layered wheels, a construction by Sintiari and Trotignon consisting of (even-hole, K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT)-free graphs with arbitrarily large treewidth.
Alecu, Chudnovsky, Spirkl and the author proved recently that the conjecture holds in two special cases:
(a) when t=4𝑡4t=4italic_t = 4; and (b) when H=𝖼𝗈𝗇𝖾⁡(F)𝐻𝖼𝗈𝗇𝖾𝐹H=\operatorname{{\text{\sf{cone}}}}(F)italic_H = cone ( italic_F ) for some forest F𝐹Fitalic_F; that is, H𝐻Hitalic_H is obtained from a forest F𝐹Fitalic_F by adding a universal vertex. Our first result is a common strengthening of (a) and (b): for an integer t≥4𝑡4t\geq 4italic_t ≥ 4 and graphs F𝐹Fitalic_F and H𝐻Hitalic_H, (even-hole, 𝖼𝗈𝗇𝖾⁡(𝖼𝗈𝗇𝖾⁡(F))𝖼𝗈𝗇𝖾𝖼𝗈𝗇𝖾𝐹\operatorname{{\text{\sf{cone}}}}(\operatorname{{\text{\sf{cone}}}}(F))cone ( cone ( italic_F ) ), H𝐻Hitalic_H, Ktsubscript𝐾𝑡K_{t}italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT)-free graphs have bounded treewidth if and only if F𝐹Fitalic_F is a forest and H𝐻Hitalic_H is a K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free chordal graph.
Also, for general t≥4𝑡4t\geq 4italic_t ≥ 4, we push the current state of the art further than (b) by settling the conjecture for the smallest choices of H𝐻Hitalic_H that are not coned forests. The latter follows from our second result: we prove the conjecture when H𝐻Hitalic_H is a crystal; that is, a graph obtained from arbitrarily many coned double stars by gluing them together along the “middle” edges of the double stars.
Generally, even-hole-free graphs of large treewidth are rare; as far as we know, if the lower bound t𝑡titalic_t on the treewidth is large enough, then essentially there are only two examples: the layered wheels of treewidth at least t𝑡titalic_t, which happen to be K4subscript𝐾4K_{4}italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT-free, and the complete graphs on more than t𝑡titalic_t vertices. In particular, an upsurge in the clique number seems to be inevitable. This extends beyond even-hole-free graphs: except for complete graphs and complete bipartite graphs, graphs from all other constructions of unbounded treewidth which have been discovered so far are 2222-degenerate.
The above discussion motivates our second conjecture: for every t≥1𝑡1t\geq 1italic_t ≥ 1, every graph of sufficiently large treewidth has an induced subgraph of treewidth t𝑡titalic_t which is either complete, complete bipartite, or 2222-degenerate. To the best of our knowledge, this is the first (and much anticipated) formulation of a possible “grid-type theorem” for induced subgraphs. Although concise, it also appears to be an informative one; for instance, if true, the latter conjecture would imply our former conjecture by reducing it to (a).",[''],[]
"Strain engineering has quickly emerged as a viable option to modify the electronic, optical and magnetic properties of 2D materials. However, it remains challenging to arbitrarily control the strain. Here we show that by creating atomically-flat surface nanostructures in hexagonal boron nitride, we achieve an arbitrary on-chip control of both the strain distribution and magnitude on high-quality molybdenum disulfide. The phonon and exciton emissions are shown to vary in accordance with our strain field designs, enabling us to write and draw any photoluminescence color image in a single chip. Moreover, our strain engineering offers a powerful means to significantly and controllably alter the strengths and energies of interlayer excitons at room temperature. This method can be easily extended to other material systems and offers a promise for functional excitonic devices.",[''],"['Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Japan', 'Japan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan', 'Taiwan']"
"Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations—responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs’ responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area.
(2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases.
(3) We illustrate that LLMs often fail to correct a user’s incorrect legal assumptions in a contra-factual question setup.
(4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations.
Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most—pro se litigants or those without access to traditional legal resources.111All our code, raw data, prompts, and results are available at: https://github.com/reglab/legal_hallucinations.",[''],[]
"A tuple (Z1,…,Zp)subscript𝑍1…subscript𝑍𝑝(Z_{1},\ldots,Z_{p})( italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) of matrices of size r𝑟ritalic_r is said to be a commuting extension of a tuple (A1,…,Ap)subscript𝐴1…subscript𝐴𝑝(A_{1},\ldots,A_{p})( italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) of matrices of size n<r𝑛𝑟n<ritalic_n < italic_r if the Zisubscript𝑍𝑖Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT pairwise commute
and each Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT sits in the upper left corner of a block decomposition of Zisubscript𝑍𝑖Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.
This notion was discovered and rediscovered in several contexts including algebraic complexity theory (in Strassen’s work on tensor rank), in
numerical analysis for the construction of cubature formulas and in quantum mechanics for the study of computational methods and the study of the so-called ""quantum Zeno dynamics.""
Commuting extensions have also attracted the attention of the linear algebra community.
In this paper we present 3 types of results:



(i)

Theorems on the uniqueness of commuting extensions for three matrices or more.



(ii)

Algorithms for the computation of commuting extensions of minimal size. These algorithms work under the same assumptions
as our uniqueness theorems. They are applicable up to r=4⁢n/3𝑟4𝑛3r=4n/3italic_r = 4 italic_n / 3, and are apparently the first provably efficient algorithms for this problem applicable beyond r=n+1𝑟𝑛1r=n+1italic_r = italic_n + 1.



(iii)

A genericity theorem showing that our algorithms and uniqueness theorems can be applied to a wide range of
input matrices.",[''],[]
"Manual delineation of tumor regions from magnetic resonance (MR) images is time-consuming, requires an expert, and is prone to human error. In recent years, deep learning models have been the go-to approach for the segmentation of brain tumors. U-Net and its’ variants for semantic segmentation of medical images have achieved good results in the literature. However, U-Net and its’ variants tend to over-segment tumor regions and may not accurately segment the tumor edges. The edges of the tumor are as important as the tumor regions for accurate diagnosis, surgical precision, and treatment planning. In the proposed work, the authors aim to extract edges from the ground truth using a derivative-like filter followed by edge reconstruction to obtain an edge ground truth in addition to the brain tumor ground truth. Utilizing both ground truths, the author studies several U-Net and its’ variant architectures with and without tumor edges ground truth as a target along with the tumor ground truth for brain tumor segmentation. The author used the BraTS2020 benchmark dataset to perform the study and the results are tabulated for the dice and Hausdorff95 metrics. The mean and median metrics are calculated for the whole tumor (WT), tumor core (TC), and enhancing tumor (ET) regions. Compared to the baseline U-Net and its variants, the models that learned edges along with the tumor regions performed well in the enhancing and core tumor regions in both training and validation datasets. The improved performance of edge-trained models trained on baseline models like U-Net and V-Net achieved performance similar to baseline state-of-the-art models like Swin U-Net and hybrid MR-U-Net. The edge-target trained models are capable of generating edge maps that can be useful for treatment planning. Additionally, for further explainability of the results, the activation map generated by the hybrid MR-U-Net has been studied.",[''],[]
,[''],[]
"The a𝑎aitalic_a-number is an invariant of the isomorphism class of the p𝑝pitalic_p-torsion group scheme. We use the Cartier operator on H0⁢(𝒜2,Ω1)superscript𝐻0subscript𝒜2superscriptΩ1H^{0}(\mathcal{A}_{2},\Omega^{1})italic_H start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_Ω start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ) to find a closed formula for the a𝑎aitalic_a-number of the form 𝒜2=v⁢(Yq+Y−xq+12)subscript𝒜2𝑣superscript𝑌𝑞𝑌superscript𝑥𝑞12\mathcal{A}_{2}=v(Y^{\sqrt{q}}+Y-x^{\frac{\sqrt{q}+1}{2}})caligraphic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_v ( italic_Y start_POSTSUPERSCRIPT square-root start_ARG italic_q end_ARG end_POSTSUPERSCRIPT + italic_Y - italic_x start_POSTSUPERSCRIPT divide start_ARG square-root start_ARG italic_q end_ARG + 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT ) where q=ps𝑞superscript𝑝𝑠q=p^{s}italic_q = italic_p start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT over the finite field 𝔽q2subscript𝔽superscript𝑞2\mathbb{F}_{q^{2}}blackboard_F start_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT. The application of the computed a𝑎aitalic_a-number in coding theory is illustrated by the relationship between the algebraic properties of the curve and the parameters of codes that are supported by it.","['Key words and phrases: \na𝑎aitalic_a-number;', 'Cartier operator;', 'Super-singular', 'Curves;', 'Maximal', 'Curves.']",[]
"In this work we present deep learning implementations of two popular theoretical constrained optimization algorithms in infinite dimensional Hilbert spaces, namely, the penalty and the augmented Lagrangian methods. We test these algorithms on some toy problems originating in either calculus of variations or physics. We demonstrate that both methods are able to produce decent approximations for the test problems and are comparable in terms of different errors. Leveraging the common occurrence of the Lagrange multiplier update rule being computationally less expensive than solving subproblems in the penalty method, we achieve significant speedups in cases when the output of the constraint function is itself a function.",[''],[]
"We introduce a novel time-energy uncertainty relationship
within the context of restarts in monitored quantum dynamics.
Initially, we investigate the concept of “first hitting time” in quantum systems
using an IBM quantum computer and a three-site ring graph as our starting point.
Previous studies have established that the mean recurrence time,
which represents the time taken to return to the initial state,
is quantized as an integer multiple of the sampling time,
displaying pointwise discontinuous transitions at resonances.
Our findings demonstrate that,
the natural utilization of the restart mechanism in laboratory experiments,
driven by finite data collection time spans,
leads to a broadening effect on the transitions of the mean recurrence time.
Our newly proposed uncertainty relation captures the underlying essence of these phenomena,
by connecting the broadening of the mean hitting time near resonances,
to the intrinsic energies of the quantum system
and to the fluctuations of recurrence time.
This work not only contributes to our understanding of fundamental aspects
related to quantum measurements and dynamics,
but also offers practical insights for the design
of efficient quantum algorithms with mid-circuit measurements.",[''],"['Israel', 'Israel', 'Germany', 'Israel']"
"We discuss Hamiltonian learning in quantum field theories as a protocol for systematically extracting the operator content and coupling constants of effective field theory Hamiltonians from experimental data. Learning the Hamiltonian for varying spatial measurement resolutions gives access to field theories at different energy scales, and allows to learn a flow of Hamiltonians reminiscent of the renormalization group. Our method, which we demonstrate in both theoretical studies and available data from a quantum gas experiment, promises new ways of addressing the emergence of quantum field theories in quantum simulation experiments.",[''],"['Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria', 'Austria']"
"Parity-time (PT) symmetric dimers were introduced to highlight the unusual properties of non-Hermitian systems that are invariant after a combined parity and time reversal operation. They are also the building blocks of a variety of symmetry and topologically protected structures, especially on integrated photonic platforms. As the name suggests, it consists of two coupled oscillators, which can be optical, mechanical, electronic, etc. in nature. In this article, we show that its effective size, defined by the number of lattice sites inversely proportional to the lattice momentum, is surprisingly three instead of two from the perspective of energy quantization. More specifically, we show analytically that the complex energy levels of a one-dimensional concatenated chain with N𝑁Nitalic_N PT-dimers are determined by a system size of 1+2⁢N12𝑁1+2N1 + 2 italic_N, which reduces to three in the case of a single PT-dimer. We note that while energy quantization conditions have been established in various non-Hermitian systems, exact and explicitly quantized complex energies as reported here are still scarce. In connection, we also discuss the other symmetries of a PT-dimer and concatenated PT-dimer chain, including non-Hermitian particle-hole symmetry and chiral symmetry.",[''],"['USA', 'USA']"
"We present the analytical and numerical results on the collective excitation spectrum of quasi-one-dimensional spin-orbit (SO) coupled spin-1 spinor ferromagnetic Bose-Einstein condensates. The collective excitation spectrum, using Bogoliubov-de-Gennes theory, reveals the existence of a diverse range of phases in the SO and Rabi (kL−Ωsubscript𝑘𝐿Ωk_{L}-\Omegaitalic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT - roman_Ω) coupling plane. Based on the nature of the eigenvalue of the excitation spectrum, we categorize the kL−Ωsubscript𝑘𝐿Ωk_{L}-\Omegaitalic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT - roman_Ω plane into three distinct regions, namely I, II, and III. In region I, a stable mode with phonon-like excitations is observed. In region IIa, single and multi-band instabilities are noted with a gapped mode, while multi-band instability accompanied by a gapless mode between low-lying and first excited states is realized in region IIb, which also provides evidence of unstable avoided crossing between low-lying and first excited modes, responsible for the Iosubscript𝐼𝑜I_{o}italic_I start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT type of oscillatory non-equilibrium dynamical pattern formation. The gap between low-lying and first-excited states increases upon increasing the Rabi coupling while decreases upon increase of SO coupling. Using eigenvector analysis, we confirm the presence of the spin-dipole mode in the spin-like modes in Region II. We corroborate the nature of the collective excitation through real-time dynamical evolution of the ground state perturbed with the quench of the trap using the mean-field Gross-Pitaevskii model. This analysis suggests the presence of dynamical instability leading to the disappearance of the 00-th component of the condensate. In Region III, mainly encompassing Ω∼0similar-toΩ0\Omega\sim 0roman_Ω ∼ 0 and finite kLsubscript𝑘𝐿k_{L}italic_k start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT, we observe phonon-like excitations in both the first excited and the low-lying state. The eigenvectors in this region reveal alternative in- and out-of-phase behaviours of the spin components. Numerical analysis reveals the presence of a super stripe phase for small Rabi coupling in this region, wherein the eigenvector indicates the presence of more complicated spin-like-density mixed modes.",[''],"['India', 'China', 'China', 'Brazil', 'India', 'India']"
"The success of a future quantum internet will rest in part on the ability of quantum and classical signals to coexist in the same optical fiber infrastructure, a challenging endeavor given the orders of magnitude differences in flux of single-photon-level quantum fields and bright classical traffic. We theoretically describe and experimentally implement Procrustean entanglement concentration for polarization-entangled states contaminated with classical light, showing significant mitigation of crosstalk noise in dense wavelength-division multiplexing. Our approach leverages a pair of polarization-dependent loss emulators to attenuate highly polarized crosstalk that results from imperfect isolation of conventional signals copropagating on shared fiber links. We demonstrate our technique both on the tabletop and over a deployed quantum local area network, finding a substantial improvement of two-qubit entangled state fidelity from approximately 75% to over 92%. This local filtering technique could be used as a preliminary step to reduce asymmetric errors, potentially improving the overall efficiency when combined with more complex error mitigation techniques in future quantum repeater networks.",[''],"['USA', 'USA', 'USA', 'USA', 'USA']"
"Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs’ autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework’s superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.",[''],[]
"As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to “hallucinate” – generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people’s lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, customer support conversations, financial analysis reports, and providing erroneous legal advice. Small errors could lead to harm, revealing the LLMs’ lack of actual comprehension despite advances in self-learning. This paper presents a comprehensive survey of over thirty-two techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval-Augmented Generation (RAG) Lewis et al. (2021), Knowledge Retrieval Varshney et al. (2023), CoNLI Lei et al. (2023), and CoVe Dhuliawala et al. (2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.",[''],[]
"Grammatical inference consists in learning a language or a grammar from data. In this paper, we consider a number of models for inferring a non-deterministic finite automaton (NFA) with 3 sorts of states, that must accept some words, and reject some other words from a given sample. We then propose a transformation from this 3-sort NFA into weighted-frequency and probabilistic NFA, and we apply the latter to a classification task. The experimental evaluation of our approach shows that the probabilistic NFAs can be successfully applied for classification tasks on both real-life and superficial benchmark data sets.","['grammatical inference  and nondeterministic automata  and', 'SAT models']","['TechnologyGliwicePoland', 'AngersAngersFrance', 'AngersAngersFrance']"
"In this article, we study how the absolute
coregularity
of a projective log pair
reflects on
its fundamental group.
More precisely, we conjecture
that for a projective klt log pair (X,D)𝑋𝐷(X,D)( italic_X , italic_D )
of absolute coregularity c𝑐citalic_c (and arbitrary dimension)
the fundamental group
π1reg⁢(X,D)superscriptsubscript𝜋1reg𝑋𝐷\pi_{1}^{\rm reg}(X,D)italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_reg end_POSTSUPERSCRIPT ( italic_X , italic_D )
admits a normal abelian subgroup
of finite index
and rank at most 2⁢c2𝑐2c2 italic_c.
We prove this conjecture
in the cases c∈{0,1,2}𝑐012c\in\{0,1,2\}italic_c ∈ { 0 , 1 , 2 }, building on the almost abelianity of the fundamental groups of klt Calabi-Yau pairs of dimension ≤2absent2\leq 2≤ 2. In the cases c∈{0,1,2}𝑐012c\in\{0,1,2\}italic_c ∈ { 0 , 1 , 2 } and fixed dimension, we can furthermore bound the index of a solvable normal subgroup.
In dimension three, we are able to prove almost abelianity for projective varieties with klt singularities and ℚℚ\mathbb{Q}blackboard_Q-trivial canonical divisor.",[''],[]
"In this work, photon bunching from LED light was observed for the first time using SiPMs. The bunching signature was observed with a significance of 7.3⁢σ7.3𝜎7.3~{}\sigma7.3 italic_σ using 97 hs of data. The light was spectrally filtered using a 1 nm bandpass filter and an Etalon filter to ensure temporal coherence of the field and its coherence time was measured to be τC=(13.0±1.3)subscript𝜏𝐶plus-or-minus13.01.3\tau_{C}=(13.0\pm 1.3)italic_τ start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT = ( 13.0 ± 1.3 ) ps. The impact of SiPM non-idealities in these kinds of measurements is explored, and we describe the methodology to process SiPM analog waveforms and the event selection used to mitigate these non-idealities.",[''],"['Argentina', 'Germany', 'Argentina', 'Argentina', 'Germany', 'Germany', 'Argentina']"
"We propose a model of a twisted accretion disc around a Kerr black hole
interacting with a secondary black hole of a smaller mass on an inclined eccentric orbit.
We use parameters of the system, which may be appropriate for
the so-called ’precessing massive’ model of OJ 287.
We calculate expressions for torque exerted on the disc by the secondary and a contribution of the secondary
to the apsidal precession of disc elements by a double averaging procedure over the periods of
the secondary and the disc elements. These expressions are used at all
scales of interest, including the ones inside the binary orbit. We calculate numerically
the evolution of the disc tilt and twist assuming a flat initial configuration. We consider the disc
aspect ratio h/r=10−3ℎ𝑟superscript103h/r=10^{-3}italic_h / italic_r = 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, a rather large viscosity parameter α=0.1𝛼0.1\alpha=0.1italic_α = 0.1 and several values of the primary
rotational parameter, χ𝜒\chiitalic_χ. We find that, after a few periods of Lense-Thirring precession of the
orbit, the disc relaxes to a quasi-stationary configuration in the precessing frame with a non-trivial
distribution of the disc inclination angle, β𝛽\betaitalic_β, over the radial scale.
 We propose an analytic model for this configuration. We show that
the presence of the twisted disc leads to multiple crossings of the disc by the secondary per one orbital period, with time periods between the crossings being different from the flat disc model. Our results should be taken into account in the modelling of OJ 287. They can also be applied to similar sources.",[''],[]
"We present time-series near-infrared (NIR) spectra for the classical Cepheid, CP Cephei, from the Astrophysical Research Consortium 3.5-m telescope and NIR spectrograph, TripleSpec, at Apache Point Observatory, NM, USA. Spectral observations were made at three points on the ascending portion of the visible phase diagram for the star. Carbon monoxide (CO) was detected in absorption in the 2.3-micron band head for each observation. We observed that the equivalent width of the 3-1 transition of the CO band head decreased by half from our first observation to the second, or slightly over one day out of the 17.867-day period. Our third observation occurred 54 days after the first (slightly over three periods for the star) and showed similar CO levels to the first observation, suggesting that the CO is in the stellar atmosphere and varies with pulsation.",[''],[]
,[''],[]
"We introduce the Whitehead complex, a one-complex associated to a finite regular cover of the rose and show that it is connected if and only if the fundamental group of the associated cover is generated by its intersection with the set of elements in proper free factors of 𝐅nsubscript𝐅𝑛\mathbf{F}_{n}bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. The Whitehead complex admits an action of Out⁢(𝐅n)Outsubscript𝐅𝑛\mathrm{Out}(\mathbf{F}_{n})roman_Out ( bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) by isometries if the associated cover corresponds to a characteristic subgroup of 𝐅nsubscript𝐅𝑛\mathbf{F}_{n}bold_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. We prove that the Whitehead complex of the rose has infinite diameter and is nonhyperbolic, implying it is not quasi-isometric to the free splitting complex or the free factor complex.",[''],[]
"In this work, we report a study of the equilibrium configurations and the radial stability of spherically symmetric relativistic Neutron Stars(NS) with polytropic model in a modified f⁢(R,T)=R+2⁢λ⁢T+ξ⁢T2𝑓𝑅𝑇𝑅2𝜆𝑇𝜉superscript𝑇2f(R,T)=R+2\lambda T+\xi T^{2}italic_f ( italic_R , italic_T ) = italic_R + 2 italic_λ italic_T + italic_ξ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT gravity (where T𝑇Titalic_T is the trace of the conserved energy-momentum tensor Tμ⁢νsubscript𝑇𝜇𝜈T_{\mu\nu}italic_T start_POSTSUBSCRIPT italic_μ italic_ν end_POSTSUBSCRIPT of the matter-energy, λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ are the modified gravity parameters). We investigate the neutron stars properties such as mass(M𝑀Mitalic_M), radius(R𝑅Ritalic_R), pressure(P𝑃Pitalic_P) and energy density(ρ𝜌\rhoitalic_ρ) and their dependence on the modified gravity parameters λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ corresponding to different central density (ρcsubscript𝜌𝑐\rho_{c}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT) of the NS. For λ=0,−1,−3,−5𝜆0135\lambda=0,-1,-3,-5italic_λ = 0 , - 1 , - 3 , - 5 with ξ=0𝜉0\xi=0italic_ξ = 0 and central density ρc=1.5×1018⁢kg⁢m−3subscript𝜌𝑐1.5superscript1018kgsuperscriptm3\rho_{c}=1.5\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.5 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, we find the maximum mass of the NS as M=1.06⁢M⊙𝑀1.06subscript𝑀direct-productM=1.06M_{\odot}italic_M = 1.06 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT, 1.19⁢M⊙1.19subscript𝑀direct-product1.19M_{\odot}1.19 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT 1.61⁢M⊙1.61subscript𝑀direct-product1.61M_{\odot}1.61 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and 2.47⁢M⊙2.47subscript𝑀direct-product2.47~{}M_{\odot}2.47 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT corresponding to the radius(R𝑅Ritalic_R) 10.40910.40910.40910.409 km, 10.73710.73710.73710.737 km, 11.46111.46111.46111.461 km and 12.11912.11912.11912.119 km. respectively. This higher value of NS mass can be compared with observational constraints like gravitational wave data(GW170817) which is ≈\approx≈ 2.33 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. For a given λ=−6𝜆6\lambda=-6italic_λ = - 6 and ξ=0𝜉0\xi=0italic_ξ = 0, we find that as ρcsubscript𝜌𝑐\rho_{c}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT increases from ρc=1.1×1018⁢kg⁢m−3subscript𝜌𝑐1.1superscript1018kgsuperscriptm3\rho_{c}=1.1\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.1 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT to ρc=1.6×1018⁢kg⁢m−3subscript𝜌𝑐1.6superscript1018kgsuperscriptm3\rho_{c}=1.6\times 10^{18}~{}\rm{kg~{}m^{-3}}italic_ρ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 1.6 × 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT roman_kg roman_m start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, the maximum mass Mm⁢a⁢xsubscript𝑀𝑚𝑎𝑥M_{max}italic_M start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT of the NS decreases from 4.19⁢M⊙4.19subscript𝑀direct-product4.19M_{\odot}4.19 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT to 3.23⁢M⊙3.23subscript𝑀direct-product3.23M_{\odot}3.23 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT(giving mass of stellarmass Black Hole ⪆3⁢M⊙greater-than-or-approximately-equalsabsent3subscript𝑀direct-product\gtrapprox 3M_{\odot}⪆ 3 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT), while it’s radius R𝑅Ritalic_R decreases 13.86⁢km13.86km13.86\rm{km}13.86 roman_km to 11.54⁢km11.54km11.54\rm{km}11.54 roman_km. With the fixed value of ξ=10−27𝜉superscript1027\xi=10^{-27}italic_ξ = 10 start_POSTSUPERSCRIPT - 27 end_POSTSUPERSCRIPT and λ=0,−1,−3,−5𝜆0135\lambda=0,-1,-3,-5italic_λ = 0 , - 1 , - 3 , - 5, we find the maximum mass M=1.06⁢M⊙𝑀1.06subscript𝑀direct-productM=1.06M_{\odot}italic_M = 1.06 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT, 1.34⁢M⊙1.34subscript𝑀direct-product1.34M_{\odot}1.34 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT 1.89⁢M⊙1.89subscript𝑀direct-product1.89M_{\odot}1.89 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and 3.39⁢M⊙3.39subscript𝑀direct-product3.39~{}M_{\odot}3.39 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT corresponding to the radius R=10.409𝑅10.409R=10.409italic_R = 10.409 km, 10.84310.84310.84310.843 km, 11.54911.54911.54911.549 km and 11.68011.68011.68011.680 km. respectively.
Taking our observational constraints i.e. GW170817 (BNS Merger) mass - radius data, observed pulsars PSRJ1614-2230, PSRJ0348+0432 maximum mass - radius data; we found that posterior distribution plot of mass &\&& radius gives good result and the corner plot of modified gravity parameters λ𝜆\lambdaitalic_λ and ξ𝜉\xiitalic_ξ are giving very good posterior results. So, for a range of values of λ𝜆\lambdaitalic_λ with ξ=0(≠0)𝜉annotated0absent0\xi=0(\neq 0)italic_ξ = 0 ( ≠ 0 ), we found that the mass M𝑀Mitalic_M and the radius R𝑅Ritalic_R of the NS lie within the range given by the GW170817 gravitational wave data given by LIGO, Pulsars &\&& Millisecond Pulsars data and the NICER (Neutron star Interior Composition ExploreR) mass-radius data given by NASA.",[''],['India']
,[''],[]
,[''],[]
"In this paper, we consider classes of decision tables closed under
removal of attributes (columns) and changing of decisions attached to rows.
For decision tables from closed classes, we study lower bounds on the minimum
cardinality of reducts, which are minimal sets of attributes that allow us
to recognize, for a given row, the decision attached to it. We assume that the
number of rows in decision tables from the closed class is not bounded from above by
a constant. We divide the set of such closed classes into two families. In
one family, only standard lower bounds Ω(log\Omega(\logroman_Ω ( roman_log cl(T)){\rm cl}(T))roman_cl ( italic_T ) ) on the
minimum cardinality of reducts for decision tables hold, where cl⁢(T)cl𝑇{\rm cl}(T)roman_cl ( italic_T )
is the number of decision classes in the table T𝑇Titalic_T. In another family, these
bounds can be essentially tightened up to Ω⁢(cl⁢(T)1/q)Ωclsuperscript𝑇1𝑞\Omega({\rm cl}(T)^{1/q})roman_Ω ( roman_cl ( italic_T ) start_POSTSUPERSCRIPT 1 / italic_q end_POSTSUPERSCRIPT ) for
some natural q𝑞qitalic_q.",[''],[]
"This work elicits LLMs’ inherent ability to handle long contexts without fine-tuning.
The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs’ context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs’ long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model’s self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs’ context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs’ context window’s length.","['Machine', 'Learning,', 'ICML']",[]
"In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is span-based. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.",[''],[]
"In this work, the description of the moduli space of principal G𝐺Gitalic_G-bundles as double quotient of loop groups is used to construct an étale local r𝑟ritalic_r-matrix for the Hitchin integrable system.",[''],[]
"We prove a finiteness theorem for subgroups of bounded rank in hyperbolic 3333-manifold groups. As a consequence, we show that every bounded rank covering tower of closed hyperbolic 3333-manifolds is a tower of finite covers associated to a fibration over a 1111-orbifold.",[''],[]
"The quasi-optical propagation of millimeter-wave (mmWave) signals enables high-accuracy localization algorithms that employ geometric approaches or machine learning models. However, most algorithms require information on the indoor environment, may entail the collection of large training datasets, or bear an infeasible computational burden for commercial off-the-shelf (COTS) devices. In this work, we propose to use tiny neural networks (NNs) to learn the relationship between angle difference-of-arrival (ADoA) measurements and locations of a receiver in an indoor environment. To relieve training data collection efforts, we resort to a self-supervised approach by bootstrapping the training of our neural network through location estimates obtained from a state-of-the-art localization algorithm. We evaluate our scheme via mmWave measurements from indoor 60-GHz double-directional channel sounding. We process the measurements to yield dominant multipath components, use the corresponding angles to compute ADoA values, and finally obtain location fixes. Results show that the tiny NN achieves sub-meter errors in 74% of the cases, thus performing as good as or even better than the state-of-the-art algorithm, with significantly lower computational complexity.",[''],[]
,[''],"['Netherlands', 'Netherlands', 'UK', 'UK', 'UK']"
"In U⁢(1)𝑈1U(1)italic_U ( 1 ) lattice gauge theory with compact U⁢(1)𝑈1U(1)italic_U ( 1 ) variables, we construct the
symmetry operator, i.e., the topological defect, for the axial U⁢(1)𝑈1U(1)italic_U ( 1 )
non-invertible symmetry. This requires a lattice formulation of chiral gauge
theory with an anomalous matter content and we employ the lattice formulation
on the basis of the Ginsparg–Wilson relation. Then, the invariance of the
symmetry operator under the gauge transformation of the gauge field on the
defect is realized, imitating the prescription by Karasik in continuum theory,
by integrating the lattice Chern–Simons term on the defect over
smooth lattice gauge transformations. The projection operator for
allowed magnetic fluxes on the defect then automatically emerges with lattice
regularization. The resulting symmetry operator is manifestly gauge invariant
under lattice gauge transformations.",[''],"['[', 'Japan']"
,[''],[]
"Nuclear spins in solid-state platforms are promising for building rotation sensors due to their long coherence times. Among these platforms, nitrogen-vacancy centers have attracted considerable attention with ambient operating conditions. However, the current performance of NV gyroscopes remains limited by the degraded coherence when operating with large spin ensembles. Protecting the coherence of these systems requires a systematic study of the coherence decay mechanism. Here we present the use of nitrogen-15 nuclear spins of NV centers in building gyroscopes, benefiting from its simpler energy structure and vanishing nuclear quadrupole term compared with nitrogen-14 nuclear spins, though suffering from different challenges in coherence protection. We systematically reveal the coherence decay mechanism of the nuclear spin in different NV electronic spin manifolds and further develop a robust coherence protection protocol based on controlling the NV electronic spin only, achieving a 15-fold dephasing time improvement. With the developed coherence protection, we demonstrate an emulated gyroscope by measuring a designed rotation rate pattern, showing an order-of-magnitude sensitivity improvement.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"Solid-state platforms based on electro-nuclear spin systems are attractive candidates for rotation sensing due to their excellent sensitivity, stability, and compact size, compatible with industrial applications. Conventional spin-based gyroscopes measure the accumulated phase of a nuclear spin superposition state to extract the rotation rate and thus suffer from spin dephasing. Here, we propose a gyroscope protocol based on a two-spin system that includes a spin intrinsically tied to the host material, while the other spin is isolated. The rotation rate is then extracted by measuring the relative rotation angle between the two spins starting from their population states, robust against spin dephasing. In particular, the relative rotation rate between the two spins can be enhanced by their hyperfine coupling by more than an order of magnitude, further boosting the achievable sensitivity. The ultimate sensitivity of the gyroscope is limited by the lifetime of the spin system and compatible with a broad dynamic range, even in the presence of magnetic noises or control errors due to initialization and qubit manipulations. Our result enables precise measurement of slow rotations and exploration of fundamental physics.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model.
At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT.
Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM’s performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.",[''],[]
"Motivated by explosive releases of energy in fusion, space and astrophysical plasmas, we consider the nonlinear convective stability of stratified magnetohydrodynamic (MHD) equilibria in 2D. We demonstrate that, unlike the Schwarzschild criterion in hydrodynamics (“entropy must increase upwards for convective stability”), the so-called modified Schwarzschild criterion for 2D MHD (or for any kind of fluid dynamics with more than one source of pressure) guarantees only linear stability. As a result, in 2D MHD (unlike in hydrodynamics) there exist metastable equilibria that are unstable to nonlinear perturbations despite being stable to linear ones. We show that the minimum-energy configurations attainable by these atmospheres via non-diffusive reorganization can be determined by solving a combinatorial optimization problem. We find inter alia that these minimum-energy states are usually 2D, even when the original metastable equilibrium was 1D. We demonstrate with direct numerical simulations that these 2D states are fairly accurate predictors of the final state reached by laminar relaxation of metastable equilibria at small Reynolds number. To describe relaxation at large Reynolds number, we construct a statistical mechanical theory based on the maximization of Boltzmann’s mixing entropy that is analogous to the Lynden-Bell statistical mechanics of self-gravitating systems and collisionless plasmas, and to the Robert-Sommeria-Miller (RSM) theory of 2D vortex turbulence. The minimum-energy states described above are, we show, the low-temperature limit of this theory. We demonstrate that the predictions of the statistical mechanics are in reasonable agreement with direct numerical simulations.",[''],"['USA', 'UK', 'USA', 'USA']"
"This paper studies how to recover parameters in diagonal Gaussian mixture models using tensors. High-order moments of the Gaussian mixture model are estimated from samples. They form incomplete symmetric tensors generated by hidden parameters in the model. We propose to use generating polynomials to compute incomplete symmetric tensor approximations. The obtained decomposition is utilized to recover parameters in the model. We prove that our recovered parameters are accurate when the estimated moments are accurate. Using high-order moments enables our algorithm to learn Gaussian mixtures with more components. For a given model dimension and order, we provide an upper bound of the number of components in the Gaussian mixture model that our algorithm can compute.","['Key words and phrases:', 'Gaussian mixture, symmetric tensor decomposition,\ngenerating polynomial, moments']",[]
"Consider the transverse isometric action of a finite dimensional Lie algebra 𝔤𝔤\mathfrak{g}fraktur_g on a Riemannian foliation. This paper studies the equivariant Morse-Bott theory on the leaf space of the Riemannian foliations in this setting. Among other things, we establish a foliated version of the Morse-Bott lemma for a 𝔤𝔤\mathfrak{g}fraktur_g-invariant basic Morse-Bott function, and a foliated version of the usual handle presentation theorem. In the non-equivariant case, we apply these results to present a new proof of the Morse inequalities on Riemannian foliations. In the equivariant case, we apply these results to study Hamiltonian action of an abelian Lie algebra on a presymplectic manifold whose underlying foliation is also Riemannian, and extend the Kirwan surjectivity and injectivity theorem in equivariant symplectic geometry to this situation. Among other things, this implies the Kirwan surjectivity and injectivity hold for Hamiltonian torus actions on symplectic orbifolds.",[''],[]
"This paper aims to tackle the problem of modeling dynamic urban street scenes from monocular videos.
Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes.
However, significant limitations are their slow training and rendering speed, coupled with the critical need for high precision in tracked vehicle poses.
We introduce Street Gaussians, a new explicit scene representation that tackles all these limitations.
Specifically, the dynamic urban street is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background.
To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a dynamic spherical harmonics model for the dynamic appearance.
The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 133 FPS (1066×\times×1600 resolution) within half an hour of training.
The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets.
Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets.
Furthermore, the proposed representation delivers performance on par with that achieved using precise ground-truth poses, despite relying only on poses from an off-the-shelf tracker.
The code is available at
https://zju3dv.github.io/street_gaussians/.",[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
"A Hardy-Littlewood triple is a 3-tuple of integers with the form (n,n+2,n+6)𝑛𝑛2𝑛6(n,n+2,n+6)( italic_n , italic_n + 2 , italic_n + 6 ). In this paper, we study Hardy-Littlewood triples of the form (p,Pa,Pb)𝑝subscript𝑃𝑎subscript𝑃𝑏(p,P_{a},P_{b})( italic_p , italic_P start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) and improve the upper and lower bound orders of it, where p𝑝pitalic_p is a prime and Prsubscript𝑃𝑟P_{r}italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT has at most r𝑟ritalic_r prime factors. Our new results generalize and improve the previous results.","['Key words and phrases:', 'Prime,', 'Goldbach-type problems,', 'Sieve,', 'Application of sieve method']",[]
,[''],[]
"In this letter, the size (height and weight) of fictional characters in animations, superhero series, movies, and other media is studied.
We find that the distributions of character height and weight approximately follow lognormal distributions in common to five selected works.
We propose a mechanism governing this lognormal behavior based on the principle of maximum entropy and the Weber-Fechner law.
Moreover, we provide a comparison to the size distributions of real animals.
Although the size distributions of fictional characters and real animals are both lognormal, the distributions are essentially different, particularly in the scaling between height and weight.",[''],['Japan']
"Let Prsubscript𝑃𝑟P_{r}italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT denote an integer with at most r𝑟ritalic_r prime factors counted with multiplicity. In this paper we prove that for any 0<λ<140𝜆140<\lambda<\frac{1}{4}0 < italic_λ < divide start_ARG 1 end_ARG start_ARG 4 end_ARG, the inequality {p}<p−λ𝑝superscript𝑝𝜆\{\sqrt{p}\}<p^{-\lambda}{ square-root start_ARG italic_p end_ARG } < italic_p start_POSTSUPERSCRIPT - italic_λ end_POSTSUPERSCRIPT has infinitely many solutions in primes p𝑝pitalic_p such that p+2=Pr𝑝2subscript𝑃𝑟p+2=P_{r}italic_p + 2 = italic_P start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, where r=⌊81−4⁢λ⌋𝑟814𝜆r=\lfloor\frac{8}{1-4\lambda}\rflooritalic_r = ⌊ divide start_ARG 8 end_ARG start_ARG 1 - 4 italic_λ end_ARG ⌋. This generalizes the previous result of Cai.","['Key words and phrases:', 'Prime,', 'Goldbach-type problems,', 'Sieve,', 'Application of sieve method']",[]
,[''],[]
"In the era of data-driven economies, incentive systems and loyalty programs, have
become ubiquitous in various sectors, including advertising, retail, travel, and
financial services. While these systems offer advantages for both users and companies,
they necessitate the transfer and analysis of substantial amounts of sensitive data.
Privacy concerns have become increasingly pertinent, necessitating the development of
privacy-preserving incentive protocols. Despite the rising demand for secure and
decentralised systems, the existing landscape lacks a comprehensive solution.
In this work, we propose the Boomerang protocol, a novel decentralised
privacy-preserving incentive protocol that leverages cryptographic black box
accumulators to securely store user interactions within the incentive system.
Moreover, the protocol employs zero-knowledge proofs based on BulletProofs to
transparently compute rewards for users, ensuring verifiability while preserving their
privacy. To further enhance public verifiability and transparency, we utilise a smart contract on a Layer 1 blockchain to verify these
zero-knowledge proofs. The careful combination of black box accumulators with selected
elliptic curves in the zero-knowledge proofs makes the Boomerang protocol highly
efficient.
Our proof of concept implementation shows that we can handle up to 23.6 million users
per day, on a single-threaded backend server with financial costs of approximately 2
US$. Using the Solana blockchain we can handle 15.5 million users per
day with approximate costs of 0.00011 US$ per user.
The versatility of the the Boomerang protocol is demonstrated through its
applications in personalised privacy-preserving advertising, data collection, and
health and fitness tracking. Overall, the Boomerang protocol represents a
significant advancement in privacy-preserving incentive protocols, laying the
groundwork for a more secure and privacy-centric future.",[''],[]
"In this paper, our focus is on investigating the impact of cosmological constant on relativistic quantum systems comprising spin-0 scalar particles. Our analysis centers around the Klein-Gordon equation, and we obtain both approximate and exact analytical solutions for spin-0 particles of the quantum system. Afterwards, we explore quantum oscillator fields by considering the Klein-Gordon oscillator within the same space-time characterized by a cosmological constant. We obtain an approximate expression for the energy eigenvalue of the oscillator fields. In fact, the energy spectrum in both scenarios are examined and show the influences of the cosmological constant and geometry’s topology. Our investigation is situated within the context of a magnetic universe-a four-dimensional cosmological space-time recognized as the Bonnor-Melvin universe.",[''],[]
,[''],[]
"Video lectures are becoming more popular and in demand as online classroom teaching is becoming more prevalent. Massive Open Online Courses (MOOCs), such as NPTEL, have been creating high-quality educational content that is freely accessible to students online. A large number of colleges across the country are now using NPTEL videos in their classrooms. So more video lectures are being recorded, maintained, and uploaded. These videos generally contain information about that video before the lecture begins. We generally observe that these educational videos have metadata containing five to six attributes: Institute Name, Publisher Name, Department Name, Professor Name, Subject Name, and Topic Name. It would be easy to maintain these videos if we could organize them according to their categories. The indexing of these videos based on this information is beneficial for students all around the world to efficiently utilise these videos. In this project, we are trying to get the metadata information mentioned above from the video lectures.",[''],[]
"People living with Type 1 Diabetes (T1D) lose the ability to produce
insulin naturally. To compensate, they inject synthetic insulin. One
common way to inject insulin is through automated insulin delivery
systems, which use sensors to monitor their metabolic state and an
insulin pump device to adjust insulin to adapt.
In this paper, we present the Metabolic Operating System, a new
automated insulin delivery system that we designed from the ground up
using security first principles. From an architecture perspective, we
apply separation principles to simplify the core system and isolate
non-critical functionality from the core closed-loop algorithm. From
an algorithmic perspective, we evaluate trends in insulin technology
and formulate a simple, but effective, algorithm given the
state-of-the-art. From a safety perspective, we build in multiple
layers of redundancy to ensure that the person using our system
remains safe.
Fundamentally, this paper is a paper on real-world experiences
building and running an automated insulin delivery system. We report
on the design iterations we make based on experiences working with one
individual using our system. Our evaluation shows that an automated
insulin delivery system built from the ground up using security first
principles can still help manage T1D effectively.

Our source code is open source and available on GitHub (link omitted).",[''],[]
"We investigate physical consequences of non-linear electrodynamic coupled to parameters that signal violation Lorentz-symmetry breaking (LSV). Our undertaking is done by considering a general non-linear photonic Lagrangian which coupled to the Carroll-Field-Jackiw’s model (CFJ). Our endeavor reveals how the (meta) material constitutive properties of the vacuum and wave propagation are affected by the interference of the LSV parameters LSV with the specific non-linear electrodynamic model under consideration. We also discuss the refractive indices for this new medium characterized by the coupling between non-linearities and the operators that carry the LSV message. Our results show that the QED-vacuum responds with birefringence and a dispersive propagation of waves. Subsequently, we consider the electromagnetic radiation produced by a moving charged particle interacting with this new medium. Our inspection illustrates that the emitted radiation reproduces the features of the Cherenkov effect for certain intensities of background magnetic fields . Finally, we compute the static potential profile within the framework of the gauge-invariant, but path-dependent, variables formalism. A logarithmic correction to the usual static Coulomb potential emerges driven by the LSV parameter and there also appear corrections due to the non-linearity; nevertheless, the logarithm behavior drops out whenever the LSV parameter is switched off.",[''],"['Chile', 'Brasil']"
"In this paper, we conduct a comprehensive exploration of the relativistic quantum dynamics of spin-0 scalar particles, as described by the Duffin-Kemmer-Petiau (DKP) equation, within the framework of a magnetic space-time. Our focus is on the Bonnor-Melvin-Lambda (BML) solution, a four-dimensional magnetic universe characterized by a magnetic field that varies with axial distance. To initiate this investigation, we derive the radial equation using a suitable wave function ansatz and subsequently employ special functions to solve it. Furthermore, we extend our analysis to include Duffin-Kemmer-Petiau oscillator fields within the same BML space-time background. We derive the corresponding radial equation and solve it using special functions. Significantly, our results show that the geometry’s topology and the cosmological constant (both are related with the magnetic field strength) influences the eigenvalue solution of spin-0 DKP fields and DKP-oscillator fields, leading to substantial modifications in the overall outcomes.",[''],[]
"We study heavy-flavor hadron production in high-energy pp collisions, assuming the formation of a small, deconfined and expanding fireball where charm quarks can undergo rescattering and hadronization. We adopt the same in-medium hadronization mechanism developed for heavy-ion collisions, which involves Local Color-Neutralization (LCN) through recombination of charm quarks with nearby opposite color charges from the background fireball. Diquark excitations in the hot medium favor the formation of charmed baryons. The recombination process, involving closely aligned partons from the same fluid cell, effectively transfers the collective flow of the system to the final charmed hadrons. This framework can qualitatively reproduce the observed experimental findings in heavy-flavor particle-yield ratios, pTsubscript𝑝𝑇p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT-spectra and elliptic-flow coefficients. Our results provide new, complementary support to the idea that the collective phenomena observed in small systems have the same origin as those observed in heavy-ion collisions.",[''],[]
"Convolutional Neural Networks (CNN) are widely used to face challenging tasks like speech recognition, natural language processing or computer vision. As CNN architectures get larger and more complex, their computational requirements increase, incurring significant energetic costs and challenging their deployment on resource-restricted devices. In this paper, we propose Optimizing Convolutional Neural Network Architecture (OCNNA), a novel CNN optimization and construction method based on pruning and knowledge distillation designed to establish the importance of convolutional layers. The proposal has been evaluated though a thorough empirical study including the best known datasets (CIFAR-10, CIFAR-100 and Imagenet) and CNN architectures (VGG-16, ResNet-50, DenseNet-40 and MobileNet), setting Accuracy Drop and Remaining Parameters Ratio as objective metrics to compare the performance of OCNNA against the other state-of-art approaches. Our method has been compared with more than 20 convolutional neural network simplification algorithms obtaining outstanding results. As a result, OCNNA is a competitive CNN constructing method which could ease the deployment of neural networks into IoT or resource-limited devices.",[''],"['Spain', 'Spain', 'Spain']"
,[''],[]
,[''],[]
"Cognitive maps are a proposed concept on how the brain efficiently organizes memories and retrieves context out of them. The entorhinal-hippocampal complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place cell dynamics and cognitive map representations. Here, we use multi-modal inputs consisting of images and word embeddings. The network learns the similarities between novel inputs and the training database and therefore the representation of the cognitive map successfully. Subsequently, the prediction of the network can be used to infer from one modality to another with over 90%percent9090\%90 % accuracy. The proposed method could therefore be a building block to improve current AI systems for better understanding of the environment and the different modalities in which objects appear. The association of specific modalities with certain encounters can therefore lead to context awareness in novel situations when similar encounters with less information occur and additional information can be inferred from the learned cognitive map. Cognitive maps, as represented by the entorhinal-hippocampal complex in the brain, organize and retrieve context from memories, suggesting that large language models (LLMs) like ChatGPT could harness similar architectures to function as a high-level processing center, akin to how the hippocampus operates within the cortex hierarchy. Finally, by utilizing multi-modal inputs, LLMs can potentially bridge the gap between different forms of data (like images and words), paving the way for context-awareness and grounding of abstract concepts through learned associations, addressing the grounding problem in AI.",[''],"['Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'author']"
"Let ℓℓ\ellroman_ℓ be an odd prime and K𝐾Kitalic_K a field of characteristic different from ℓℓ\ellroman_ℓ. Let K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG be an algebraic closure of K𝐾Kitalic_K. Assume that K𝐾Kitalic_K contains a primitive ℓℓ\ellroman_ℓth root of unity.
Let n≠ℓ𝑛ℓn\neq\ellitalic_n ≠ roman_ℓ be another odd prime.
Let f⁢(x)𝑓𝑥f(x)italic_f ( italic_x ) and h⁢(x)ℎ𝑥h(x)italic_h ( italic_x ) be degree n𝑛nitalic_n polynomials with coefficients in K𝐾Kitalic_K and without repeated roots.
Let us consider superelliptic curves
Cf,ℓ:yℓ=f⁢(x):subscript𝐶𝑓ℓsuperscript𝑦ℓ𝑓𝑥C_{f,\ell}:y^{\ell}=f(x)italic_C start_POSTSUBSCRIPT italic_f , roman_ℓ end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT = italic_f ( italic_x ) and Ch,ℓ:yℓ=h⁢(x):subscript𝐶ℎℓsuperscript𝑦ℓℎ𝑥C_{h,\ell}:y^{\ell}=h(x)italic_C start_POSTSUBSCRIPT italic_h , roman_ℓ end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT = italic_h ( italic_x ) of genus (n−1)⁢(ℓ−1)/2𝑛1ℓ12(n-1)(\ell-1)/2( italic_n - 1 ) ( roman_ℓ - 1 ) / 2, and their jacobians J(f,ℓ)superscript𝐽𝑓ℓJ^{(f,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT and J(h,ℓ)superscript𝐽ℎℓJ^{(h,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT, which are
(n−1)⁢(ℓ−1)/2𝑛1ℓ12(n-1)(\ell-1)/2( italic_n - 1 ) ( roman_ℓ - 1 ) / 2-dimensional abelian varieties over K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG.
Suppose that one of the polynomials is irreducible and the other reducible over K𝐾Kitalic_K.
We prove that if J(f,ℓ)superscript𝐽𝑓ℓJ^{(f,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT and J(h,ℓ)superscript𝐽ℎℓJ^{(h,\ell)}italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT are isogenous over K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG then both endomorphism algebras End0⁢(J(f,ℓ))superscriptEnd0superscript𝐽𝑓ℓ\mathrm{End}^{0}(J^{(f,\ell)})roman_End start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_J start_POSTSUPERSCRIPT ( italic_f , roman_ℓ ) end_POSTSUPERSCRIPT ) and End0⁢(J(h,ℓ))superscriptEnd0superscript𝐽ℎℓ\mathrm{End}^{0}(J^{(h,\ell)})roman_End start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_J start_POSTSUPERSCRIPT ( italic_h , roman_ℓ ) end_POSTSUPERSCRIPT )
contain an invertible element of multiplicative order n𝑛nitalic_n.","['Key words and phrases: superelliptic curves, jacobians, isogenies of abelian varieties']",[]
"If the extraction of sensor fingerprints represents nowadays an important forensic tool for sensor attribution, it has been shown recently in [1, 2, 3] that images coming from several sensors were more prone to generate False Positives (FP) by presenting a common ”leak”. In this paper, we investigate the possible cause of this leak and after inspecting the EXIF metadata of the sources causing FP, we found out that they were related to the Adobe Lightroom or Photoshop softwares. The cross-correlation between residuals on images presenting FP reveals periodic peaks showing the presence of a periodic pattern. By developing our own images with Adobe Lightroom we are able to show that all developments from raw images (or 16 bits per channel coded) to 8 bits-coded images also embed a periodic 128×128128128128\times 128128 × 128 pattern very similar to a watermark. However, we also show that the watermark depends on both the content and the architecture used to develop the image. The rest of the paper presents two different ways of removing this watermark, one by removing it from the image noise component, and the other by removing it in the pixel domain. We show that for a camera presenting FP in [3], we were able to prevent the False Positives. A discussion with Adobe representatives informed us that the company decided to add this pattern in order to induce dithering.","['Index', 'Terms: ', 'PRNU,', 'False-Positive,', 'Watermarking,', 'Watermark', 'Removal']","['jan.butora@cnrs.fr', 'patrick.bas@cnrs.fr']"
,[''],[]
"In addition to the Standard Model, the introduction of a singlet complex scalar field that acquires vacuum expectation value may give rise to a cosmologically stable pseudo-Nambu-Goldstone boson (pNGB), a suitable dark matter (DM) candidate. This work extends this scenario
by including a second cosmologically stable particle: a fermion singlet. The pNGB and the new fermion can be regarded as DM candidates simultaneously, both interacting with the Standard Model through Higgs portals via two non-degenerate Higgs bosons. We explore the thermal freeze-out of this scenario, with particular emphasis on the increasing yield of the pNGB before it completely decouples (recently called Bouncing DM). We test the model under collider, relic abundance, and direct detection, and we explore the consequences of the yield bouncing on indirect detection observables today.",[''],[]
"Recommender systems aim to recommend the most suitable items to users from a large number of candidates. Their computation cost grows as the number of user requests and the complexity of services (or models) increases.
Under the limitation of computation resources (CRs), how to make a trade-off between computation cost and business revenue becomes an essential question.
The existing studies focus on dynamically allocating CRs in queue truncation scenarios (i.e., allocating the size of candidates), and formulate the CR allocation problem as an optimization problem with constraints. Some of them focus on single-phase CR allocation, and others focus on multi-phase CR allocation but introduce some assumptions about queue truncation scenarios. However, these assumptions do not hold in other scenarios, such as retrieval channel selection and prediction model selection. Moreover, existing studies ignore the state transition process of requests between different phases, limiting the effectiveness of their approaches.
This paper proposes a Reinforcement Learning (RL) based Multi-Phase Computation Allocation approach (RL-MPCA), which aims to maximize the total business revenue under the limitation of CRs. RL-MPCA formulates the CR allocation problem as a Weakly Coupled MDP problem and solves it with an RL-based approach. Specifically, RL-MPCA designs a novel deep Q-network to adapt to various CR allocation scenarios, and calibrates the Q-value by introducing multiple adaptive Lagrange multipliers (adaptive-λ𝜆\lambdaitalic_λ) to avoid violating the global CR constraints.
Finally, experiments on the offline simulation environment and online real-world recommender system validate the effectiveness of our approach.","['Computation', 'Resource', 'Allocation,', 'Deep', 'Reinforcement', 'Learning,', 'Recommender', 'System,', 'Weakly', 'Coupled', 'MDP']","['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Spurred by consistent advances and innovation in deep learning, object detection applications have become prevalent, particularly in autonomous driving that leverages various visual data. As convolutional neural networks (CNNs) are being optimized, the performances and computation speeds of object detection in autonomous driving have been significantly improved. However, due to the exponentially rapid growth in the complexity and scale of data used in object detection, there are limitations in terms of computation speeds while conducting object detection solely with classical computing. Motivated by this, quantum convolution-based object detection (QCOD) is proposed to adopt quantum computing to perform object detection at high speed. The QCOD utilizes our proposed fast quantum convolution that uploads input channel information and re-constructs output channels for achieving reduced computational complexity and thus improving performances. Lastly, the extensive experiments with KITTI autonomous driving object detection dataset verify that the proposed fast quantum convolution and QCOD are successfully operated in real object detection applications.","['Index', 'Terms: ', 'Quantum', 'Machine', 'Learning,', 'Quantum', 'Convolutional', 'Neural', 'Network,', 'Object', 'Detection,', 'Autonomous', 'Driving']",[]
"We apply a computational modelling approach to investigate the relative effectiveness of general isolation practices for mitigation of COVID-19 outbreaks in residential care facilities. Our study focuses on policies intended to reduce contact between residents, without regard to confirmed infection status. Despite the ubiquity of such policies, and their controversial association with adverse physical and mental health outcomes, little evidence exists evaluating their effectiveness at mitigating outbreaks. Through detailed simulations of COVID-19 outbreaks in residential care facilities, our results demonstrate that general isolation of residents provides little additional impact beyond what is achievable through isolation of confirmed cases and deployment of personal protective equipment.",[''],"['Australia', 'Australia', 'Australia', 'Australia', 'Australia', 'Australia', 'Australia', 'Australia']"
"The shuffle relation among multiple zeta values is algebraically expressed as the shuffle algebra. In this paper, the shuffle algebra structure for multiple zeta values is extended to a Hopf algebra structure, for which the key idea is the lifting of the shuffle multiplication to Chen fractions as the function multiplication. The linear span of Chen fractions can be equipped with a locality Hopf algebra structure, and the pushforward of the coproduct gives us the desired construction on the shuffle algebra.",[''],[]
"Defect detection is one of the most important yet challenging tasks in the quality control stage in the manufacturing sector.
In this work, we introduce a Tensor Convolutional Neural Network (T-CNN) and examine its performance on a real defect detection application in one of the components of the ultrasonic sensors produced at Robert Bosch’s manufacturing plants. Our quantum-inspired T-CNN operates on a reduced model parameter space to substantially improve the training speed and performance of an equivalent CNN model without sacrificing accuracy. More specifically, we demonstrate how T-CNNs are able to reach the same performance as classical CNNs as measured by quality metrics, with up to fifteen times fewer parameters and 4%percent44\%4 % to 19%percent1919\%19 % faster training times. Our results demonstrate that the T-CNN greatly outperforms the results of traditional human visual inspection, providing value in a current real application in manufacturing.",[''],"['Spain', 'Spain', 'Spain', 'Spain', 'Canada']"
,[''],[]
"Effective monitoring of walnut water status and stress level across the whole orchard is an essential step towards precision irrigation management of walnuts, a significant crop in California. This study presents a machine learning approach using Random Forest (RF) models to map stem water potential (SWP) by integrating high-resolution multispectral remote sensing imagery from Unmanned Aerial Vehicle (UAV) flights with weather data. From 2017 to 2018, five flights of an UAV equipped with a seven-band multispectral camera were conducted over a commercial walnut orchard, paired with concurrent ground measurements of sampled walnut plants. The RF regression model, utilizing vegetation indices derived from orthomosaiced UAV imagery and weather data, effectively estimated ground-measured SWPs, achieving an R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of 0.63 and a mean absolute error (MAE) of 0.80 bars. The integration of weather data was particularly crucial for consolidating data across various flight dates. Significant variables for SWP estimation included wind speed and vegetation indices such as NDVI, NDRE, and PSRI. A reduced RF model excluding red-edge indices of NDRE and PSRI, demonstrated slightly reduced accuracy (R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.54). Additionally, the RF classification model predicted water stress levels in walnut trees with 85% accuracy, surpassing the 80% accuracy of the reduced classification model. The results affirm the efficacy of UAV-based multispectral imaging combined with machine learning, incorporating thermal data, NDVI, red-edge indices, and weather data, in walnut water stress estimation and assessment. This methodology offers a scalable, cost-effective tool for data-driven precision irrigation management at an individual plant level in walnut orchards.",[''],[]
,[''],[]
"The field of few-shot learning (FSL) has shown promising results in scenarios where training data is limited, but its vulnerability to backdoor attacks remains largely unexplored. We first explore this topic by first evaluating the performance of the existing backdoor attack methods on few-shot learning scenarios. Unlike in standard supervised learning, existing backdoor attack methods failed to perform an effective attack in FSL due to two main issues. Firstly, the model tends to overfit to either benign features or trigger features, causing a tough trade-off between attack success rate and benign accuracy. Secondly, due to the small number of training samples, the dirty label or visible trigger in the support set can be easily detected by victims, which reduces the stealthiness of attacks. It seemed that FSL could survive from backdoor attacks. However, in this paper, we propose the Few-shot Learning Backdoor Attack (FLBA) to show that FSL can still be vulnerable to backdoor attacks. Specifically, we first generate a trigger to maximize the gap between poisoned and benign features. It enables the model to learn both benign and trigger features, which solves the problem of overfitting. To make it more stealthy, we hide the trigger by optimizing two types of imperceptible perturbation, namely attractive and repulsive perturbation, instead of attaching the trigger directly. Once we obtain the perturbations, we can poison all samples in the benign support set into a hidden poisoned support set and fine-tune the model on it. Our method demonstrates a high Attack Success Rate (ASR) in FSL tasks with different few-shot learning paradigms while preserving clean accuracy and maintaining stealthiness. This study reveals that few-shot learning still suffers from backdoor attacks, and its security should be given attention.",[''],[]
,[''],[]
"Currently cryptocurrencies and Decentralized Finance (DeFi), which enable financial services on public blockchains, represents a new growing trend in finance. In contrast to financial markets, ruled by traditional corporations, DeFi is completely transparent as it keeps records of all transactions that occur in the network and makes them publicly available.
The availability of the data represents an opportunity to analyze and understand the market from the complexity that emerges from the interactions of the actors (users, bots and companies) operating in the embedded market. In this paper we focus on the Ethereum network and our main goal is to show that the properties of the underlying transaction network provide further and useful information to forecast the evolution of the market. We aim to separate the non-redundant effects of the blockchain transaction network properties from classic technical indicators and social media trends in the future price of Ethereum. To this end, we build two machine learning models to predict the future trend of the market. The first one serves as a base model and considers a set of the most relevant features according to the current scientific literature—including technical indicators and social media trends. The second model considers the features of the base model, together with the network properties computed from the transaction networks. We found that the full model outperforms the base model and can anticipate 46% more rises in the price than the base model and 19% more falls. Thus, we conclude that indicators based on network properties provide valuable information to forecast the future direction of the market that can not be explained neither by traditional indicators, or social media trends. Hence, our results represent a first step towards a new family of DeFi market indicators based on the complexity of the underlying transaction network.",[''],"['(Spain)', '(Spain)', 'Spain', '(Spain)', '(Spain)']"
,[''],[]
"In the light of S⁢U⁢(3)𝑆𝑈3SU(3)italic_S italic_U ( 3 ) flavor symmetry, the effective interaction Hamiltonian in tensor form is obtained by virtue of group representation theory. The strong and electromagnetic breaking effects are treated as a spurion octet so that the flavor singlet principle can be utilized as the criterion to determine the form of effective Hamiltonian for all charmonium two body decays. Moreover, a synthetical nonet is introduced to include both octet and singlet representations for meson description, and resorting to the mixing angle the pure octet and singlet states are combined into the observable pseudoscalar and vector particles, so that the empirically effective Hamiltonian can be obtained in a concise way. As an application, by virtue of this scenario the relative phase between the strong and electromagnetic amplitudes is studied for vector-pseudoscalar meson final state. In data analysis of samples taken in e+⁢e−superscript𝑒superscript𝑒e^{+}e^{-}italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT collider, the details of experimental effects, such as energy spread and initial state radiative correction are taken into consideration in order to make full use of experimental information and acquire the accurate and delicate results.",[''],[]
"Existing music-driven 3D dance generation methods mainly concentrate on high-quality dance generation, but lack sufficient control during the generation process.
To address these issues, we propose a unified framework capable of generating high-quality dance movements and supporting multi-modal control, including genre control, semantic control, and spatial control. First, we decouple the dance generation network from the dance control network, thereby avoiding the degradation in dance quality when adding additional control information. Second, we design specific control strategies for different control information and integrate them into a unified framework.
Experimental results show that the proposed dance generation framework outperforms state-of-the-art methods in terms of motion quality and controllability.",[''],[]
"The understanding of the convoluted evolution of infant brain networks during the first postnatal year is pivotal for identifying the dynamics of early brain connectivity development. Thanks to the valuable insights into the brain’s anatomy, existing deep learning frameworks focused on forecasting the brain evolution trajectory from a single baseline observation. While yielding remarkable results, they suffer from three major limitations. First, they lack the ability to generalize to multi-trajectory prediction tasks, where each graph trajectory corresponds to a particular imaging modality or connectivity type (e.g., T1-w MRI). Second, existing models require extensive training datasets to achieve satisfactory performance which are often challenging to obtain. Third, they do not efficiently utilize incomplete time series data. To address these limitations, we introduce FedGmTE-Net++, a federated graph-based multi-trajectory evolution network. Using the power of federation, we aggregate local learnings among diverse hospitals with limited datasets. As a result, we enhance the performance of each hospital’s local generative model, while preserving data privacy. The three key innovations of FedGmTE-Net++ are: (i) presenting the first federated learning framework specifically designed for brain multi-trajectory evolution prediction in a data-scarce environment, (ii) incorporating an auxiliary regularizer in the local objective function to exploit all the longitudinal brain connectivity within the evolution trajectory and maximize data utilization, (iii) introducing a two-step imputation process, comprising a preliminary KNN-based precompletion followed by an imputation refinement step that employs regressors to improve similarity scores and refine imputations. Our comprehensive experimental results showed the outperformance of FedGmTE-Net++ in brain multi-trajectory prediction from a single baseline graph in comparison with benchmark methods. Our source code is available at https://github.com/basiralab/FedGmTE-Net-plus.",[''],[]
,[''],"['Iran', 'Iran']"
,[''],[]
,[''],[]
"The task of Visual Relationship Recognition (VRR) aims to identify relationships between two interacting objects in an image and is particularly challenging due to the widely-spread and highly imbalanced distribution of <<<subject, relation, object>>> triplets. To overcome the resultant performance bias in existing VRR approaches, we introduce DiffAugment – a method which first augments the tail classes in the linguistic space by making use of WordNet and then utilizes the generative prowess of Diffusion Models to expand the visual space for minority classes. We propose a novel hardness-aware component in diffusion which is based upon the hardness of each <<<S,R,O>>> triplet and demonstrate the effectiveness of hardness-aware diffusion in generating visual embeddings for the tail classes. We also propose a novel subject and object based seeding strategy for diffusion sampling which improves the discriminative capability of the generated visual embeddings. Extensive experimentation on the GQA-LT dataset shows favorable gains in the subject/object and relation average per-class accuracy using Diffusion augmented samples.",[''],[]
"WiFi Channel State Information (CSI)-based human activity recognition (HAR) enables contactless, long-range sensing in spatially constrained environments while preserving visual privacy. However, despite the presence of numerous WiFi-enabled devices around us, few expose CSI to users, resulting in a lack of sensing hardware options. Variants of the Espressif ESP32 have emerged as potential low-cost and easy-to-deploy solutions for WiFi CSI-based HAR. In this work, four ESP32-S3-based 2.4GHz directional antenna systems are evaluated for their ability to facilitate long-range through-wall HAR. Two promising systems are proposed, one of which combines the ESP32-S3 with a directional biquad antenna. This combination represents, to the best of our knowledge, the first demonstration of such a system in WiFi-based HAR. The second system relies on the built-in printed inverted-F antenna (PIFA) of the ESP32-S3 and achieves directionality through a plane reflector. In a comprehensive evaluation of line-of-sight (LOS) and non-line-of-sight (NLOS) HAR performance, both systems are deployed in an office environment spanning a distance of 18 meters across five rooms. In this experimental setup, the Wallhack1.8k dataset, comprising 1806 CSI amplitude spectrograms of human activities, is collected and made publicly available. Based on Wallhack1.8k, we train activity recognition models using the EfficientNetV2 architecture to assess system performance in LOS and NLOS scenarios. For the core NLOS activity recognition problem, the biquad antenna and PIFA-based systems achieve accuracies of 92.0±plus-or-minus\pm±3.5 and 86.8±plus-or-minus\pm±4.7, respectively, demonstrating the feasibility of long-range through-wall HAR with the proposed systems.","['Index', 'Terms: ', 'Human', 'Activity', 'Recognition,', 'WiFi,', 'Channel', 'State', 'Information,', 'Through-Wall', 'Sensing,', 'ESP32']",['martin.kampel}@tuwien.ac.at']
"Nuclear magnetic resonance (NMR) and magnetic resonance imaging (MRI) are versatile tools with broad applications from physics and chemistry to geology and medical studies. In this mini-review, we consider the concepts of NMR and MRI technologies from their fundamental origins to applications in medical science. We start from a quantum mechanical basis and consider the significant importance of NMR and MRI in clinical research. Furthermore, we briefly introduce different types of NMR systems. We also investigate some of the most important applications of MRI techniques to provide valuable methods for visualizing the inside of the body and soft tissues.",[''],[]
"While in [16] we studied classes of Fredholm-type operators defined by the homomorphism ΠΠ\Piroman_Π from L⁢(X)𝐿𝑋L(X)italic_L ( italic_X ) onto the Calkin algebra 𝒞⁢(X)𝒞𝑋\mathcal{C}(X)caligraphic_C ( italic_X ), X𝑋Xitalic_X being a Banach space, we study in this paper two classes of Fredholm-type operators defined by the homomorphism π𝜋\piitalic_π from L⁢(X)𝐿𝑋L(X)italic_L ( italic_X ) onto the algebra 𝒞0⁢(X)=L⁢(X)/F0⁢(X),subscript𝒞0𝑋𝐿𝑋subscript𝐹0𝑋\mathcal{C}_{0}(X)=L(X)/F_{0}(X),caligraphic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) = italic_L ( italic_X ) / italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) , where F0⁢(X)subscript𝐹0𝑋F_{0}(X)italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_X ) is the ideal of finite rank operators in L⁢(X).𝐿𝑋L(X).italic_L ( italic_X ) . Then we define an index for Fredholm-type operators and we show that this new index satisfies similar properties as the usual Fredholm index.",[''],[]
"Neural implicit fields, such as the neural signed distance field (SDF) of a shape, have emerged as a powerful representation for many applications, e.g., encoding a 3D shape and performing collision detection. Typically, implicit fields are encoded by Multi-layer Perceptrons (MLP) with positional encoding (PE) to capture high-frequency geometric details. However, a notable side effect of such PE-equipped MLPs is the noisy artifacts present in the learned implicit fields. While increasing the sampling rate could in general mitigate these artifacts, in this paper we aim to explain this adverse phenomenon through the lens of Fourier analysis. We devise a tool to determine the appropriate sampling rate for learning an accurate neural implicit field without undesirable side effects. Specifically, we propose a simple yet effective method to estimate the intrinsic frequency of a given network with randomized weights based on the Fourier analysis of the network’s responses. It is observed that a PE-equipped MLP has an intrinsic frequency much higher than the highest frequency component in the PE layer. Sampling against this intrinsic frequency following the Nyquist-Sannon sampling theorem allows us to determine an appropriate training sampling rate. We empirically show in the setting of SDF fitting that this recommended sampling rate is sufficient to secure accurate fitting results, while further increasing the sampling rate would not further noticeably reduce the fitting error. Training PE-equipped MLPs simply with our sampling strategy leads to performances superior to the existing methods.","['Index', 'Terms: ', 'SDF, neural representation, positional encoding,', 'Fourier analysis, spectrum analysis, neural network.']",[]
"Dempster-Shafer Theory (DST) as an effective and robust framework for handling uncertain information is applied in decision-making and pattern classification. Unfortunately, its real-time application is limited by the exponential computational complexity. People attempt to address the issue by taking advantage of its mathematical consistency with quantum computing to implement DST operations on quantum circuits and realize speedup. However, the progress so far is still impractical for supporting large-scale DST applications. In this paper, we find that Boolean algebra as an essential mathematical tool bridges the definition of DST and quantum computing. Based on the discovery, we establish a flexible framework mapping any set-theoretically defined DST operations to corresponding quantum circuits for implementation. More critically, this new framework is not only uniform but also enables exponential acceleration for computation and is capable of handling complex applications. Focusing on tasks of classification, we based on a classical attribute fusion algorithm putting forward a quantum evidential classifier, where quantum mass functions for attributes are generated with a simple method and the proposed framework is applied for fusing the attribute evidence. Compared to previous methods, the proposed quantum classifier exponentially reduces the computational complexity to linear. Tests on real datasets validate the feasibility.","['Index', 'Terms: ', 'Dempster-Shafer', 'Theory,', 'Quantum circuit,', 'Classification,', 'Information fusion,', 'Quantum computing.']",[]
"A new variant of Newton’s method - named Backtracking New Q-Newton’s method (BNQN) - which has strong theoretical guarantee, is easy to implement, and has good experimental performance, was recently introduced by the third author.
Experiments performed previously showed some remarkable properties of the basins of attractions for finding roots of polynomials and meromorphic functions, with BNQN. In general, they look more smooth than that of Newton’s method.
In this paper, we continue to experimentally explore in depth this remarkable phenomenon, and connect BNQN to Newton’s flow and Voronoi’s diagram. This link poses a couple of challenging puzzles to be explained. Experiments also indicate that BNQN is more robust against random perturbations than Newton’s method and Random Relaxed Newton’s method.",[''],[]
,[''],[]
"Land use / land cover (LULC) modeling is a challenging task due to long-range dependencies between geographic features and distinct spatial patterns related to topography, ecology, and human development. We identify a strong connection between modeling spatial patterns of land use and the task of image inpainting from computer vision, and conduct a study of a modified PixelCNN architecture with approximately 19 million parameters for modeling LULC. Compared with a benchmark spatial statistical model, we find that the former is capable of capturing much richer spatial correlation patterns such as roads and water bodies but does not produce a calibrated predictive distribution, suggesting the need for further tuning. We find evidence of predictive underdispersion with regard to important ecologically-relevant land use statistics such as patch count and adjacency, which can be mitigated to some extent by manipulating sampling variability.",[''],[]
"In this paper we present some extensions of recent noncentral moderate deviation results in the literature.
In the first part we generalize the results in [1] by considering a general Lévy process
{S⁢(t):t≥0}conditional-set𝑆𝑡𝑡0\{S(t):t\geq 0\}{ italic_S ( italic_t ) : italic_t ≥ 0 } instead of a compound Poisson process. In the second part we assume that {S⁢(t):t≥0}conditional-set𝑆𝑡𝑡0\{S(t):t\geq 0\}{ italic_S ( italic_t ) : italic_t ≥ 0 }
has bounded variation and it is not a subordinator; thus, in some sense, we have the difference of two independent
non-null subordinators. In this way we generalize the results in [7] for Skellam processes.
 
Keywords: large deviations, weak convergence, Mittag-Leffler function, tempered stable subordinators.
2000 Mathematical Subject Classification: 60F10, 60F05, 60G22, 33E12.",[''],[]
,[''],[]
"Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process – mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to “get stuck,” which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than >100absent100>100> 100k alternatives within 100 or fewer expensive queries.",[''],[]
"We present 3D fully kinetic shearing-box (SB) simulations of pair-plasma magnetorotational turbulence with unprecedented macro-to-microscopic scale separation. We retrieve the expected fluid-model behavior of turbulent magnetic fields and angular-momentum transport, and observe fundamental differences in turbulent fluctuation spectra linked with plasma heating. For the first time, we provide a definitive demonstration of nonthermal particle acceleration in kinetic magnetorotational turbulence agnostically of SB initial conditions, by means of a novel strategy exploiting synchrotron cooling.",[''],"['Belgium', 'Belgium', 'USA', 'USA', 'Belgium', 'USA', 'USA', 'USA', 'USA', 'USA']"
,[''],[]
"In this work, we use the term “quantum chaos” to refer to spectral correlations similar to those found in random matrix theory. Quantum chaos can be diagnosed through the analysis of level statistics using the spectral form factor, which detects both short- and long-range level correlations. The spectral form factor corresponds to the Fourier transform of the two-point spectral correlation function and exhibits a typical slope-dip-ramp-plateau structure (aka correlation hole) when the system is chaotic. We discuss how this structure could be detected through the dynamics of two physical quantities accessible to experimental many-body quantum systems: the survival probability and the spin autocorrelation function. When the system is small, the dip reaches values that are large enough at times which are short enough to be detected with current experimental platforms and commercially available quantum computers.",[''],"['USA', 'India', 'USA', 'Mexico', 'USA', 'Luxembourg', 'USA', 'USA', 'USA', 'USA', 'Luxembourg', 'Spain', 'Mexico', 'USA']"
"We show here that numerous examples abound where changing topology does not necessarily close the bulk insulating charge gap as demanded in the standard non-interacting picture. From extensive determinantal and dynamical cluster quantum Monte Carlo simulations of the half-filled and quarter-filled Kane-Mele-Hubbard model, we show that for sufficiently strong interactions at either half- or quarter-filling, a transition between topological and trivial insulators occurs without the closing of a charge gap. To shed light on this behavior, we illustrate that an exactly solvable model reveals that while the single-particle gap remains, the many-body gap does in fact close. These two gaps are the same in the non-interacting system but depart from each other as the interaction turns on. We purport that for interacting systems, the proper probe of topological phase transitions is the closing of the many-body rather than the single-particle gap.",[''],"['USA', 'USA']"
"Most tidal disruption events (TDEs) are currently found in time-domain optical and soft X-ray surveys, both of which are prone to significant obscuration. The infrared (IR), however, is a powerful probe of dust-enshrouded environments, and hence, we recently performed a systematic search of NEOWISE mid-IR data for nearby, obscured TDEs within roughly 200 Mpc. We identified 18 TDE candidates in galactic nuclei, using difference imaging to uncover nuclear variability amongst significant host galaxy emission. These candidates were selected based on the following IR light curve properties: (1) LW2≳1042greater-than-or-equivalent-tosubscript𝐿W2superscript1042L_{\mathrm{W2}}\gtrsim 10^{42}italic_L start_POSTSUBSCRIPT W2 end_POSTSUBSCRIPT ≳ 10 start_POSTSUPERSCRIPT 42 end_POSTSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT at peak, (2) fast rise, followed by a slow, monotonic decline, (3) no significant prior variability, and (4) no evidence for AGN activity in WISE colors. The majority of these sources showed no variable optical counterpart, suggesting that optical surveys indeed miss numerous obscured TDEs. Using narrow line ionization levels and variability arguments, we identified 6 sources as possible underlying AGN, yielding a total of 12 TDEs in our gold sample. This gold sample yields a lower limit on the IR-selected TDE rate of 2.0±0.3×10−5plus-or-minus2.00.3superscript1052.0\pm 0.3\times 10^{-5}2.0 ± 0.3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT galaxy−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT year−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT (1.3±0.2×10−7plus-or-minus1.30.2superscript1071.3\pm 0.2\times 10^{-7}1.3 ± 0.2 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT Mpc−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT year−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT), which is comparable to optical and X-ray TDE rates. The IR-selected TDE host galaxies do not show a green valley overdensity nor a preference for quiescent, Balmer strong galaxies, which are both overrepresented in optical and X-ray TDE samples. This IR-selected sample represents a new population of dusty TDEs that have historically been missed by optical and X-ray surveys and helps alleviate tensions between observed and theoretical TDE rates and the so-called missing energy problem.","['Accretion (14);', 'Supermassive black holes (1663);', 'Tidal disruption (1696);', 'Transient sources (1851);', 'Time domain astronomy (2109)']","['USA', 'Fellow', 'USA', 'USA', 'USA', 'Israel', 'USA', 'USA', 'USA', 'USA', 'Germany', 'Germany', 'Germany', 'USA', 'Germany', 'USA', 'USA', 'Germany', 'USA', 'Netherlands']"
"Network reconstruction consists in determining the unobserved pairwise
couplings between N𝑁Nitalic_N nodes given only observational data on the resulting
behavior that is conditioned on those couplings — typically a time-series or
independent samples from a graphical model. A major obstacle to the
scalability of algorithms proposed for this problem is a seemingly unavoidable
quadratic complexity of O⁢(N2)𝑂superscript𝑁2O(N^{2})italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), corresponding to the requirement of each
possible pairwise coupling being contemplated at least once, despite the fact
that most networks of interest are sparse, with a number of non-zero couplings
that is only O⁢(N)𝑂𝑁O(N)italic_O ( italic_N ). Here we present a general algorithm applicable to a broad
range of reconstruction problems that achieves its result in subquadratic
time, with a data-dependent complexity loosely upper bounded by
O⁢(N3/2⁢log⁡N)𝑂superscript𝑁32𝑁O(N^{3/2}\log N)italic_O ( italic_N start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT roman_log italic_N ), but with a more typical log-linear complexity of
O⁢(N⁢log2⁡N)𝑂𝑁superscript2𝑁O(N\log^{2}N)italic_O ( italic_N roman_log start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_N ). Our algorithm relies on a stochastic second neighbor search
that produces the best edge candidates with high probability, thus bypassing
an exhaustive quadratic search. In practice, our algorithm achieves a
performance that is many orders of magnitude faster than the quadratic
baseline, allows for easy parallelization, and thus enables the reconstruction
of networks with hundreds of thousands and even millions of nodes and edges.",[''],['Austria']
"Does Donald Trump speak differently from other presidents? If so, in what ways? Are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Trump’s speech patterns diverge from those of all major party nominees for the presidency in recent history. Some notable findings include Trump’s employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. Furthermore, Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values are comparably closer to those of the Democrats. These differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular time trends.",[''],"['*', '[', '[', '[']"
,[''],[]
"It is common to observe a notable non-monotonic dependence of thermal conductivity on applied magnetic field in magnetic insulators. This prevalent behavior prompts the need for an explanation involving components present in a wide range of systems. We report the field-dependence of thermal conductivity in the well-characterized effective spin-1/2 paramagnetic insulator CsYbSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT. Along with the data, we propose that the observed non-monotonic field dependence results from the hybridization of acoustic phonons with spin-flip excitations across the Zeeman gap, where the magnetoelastic coupling arises via modulation of the magnetic g𝑔gitalic_g-tensor by local strain.
This hypothesis aligns with a simple theoretical model that qualitatively reproduces key features of the data on CsYbSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT. Our results provide a starting point to understand the magnetic field dependence of thermal conductivity in a broad spectrum of magnetic insulators.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"Multi-cloud systems facilitate a cost-efficient and geographically-distributed deployment of microservice-based applications by temporary leasing virtual nodes with diverse pricing models. To preserve the cost-efficiency of multi-cloud deployments, it is essential to redeploy microservices onto the available nodes according to a dynamic resource configuration, which is often performed to better accommodate workload variations.
However, this approach leads to frequent service disruption since applications are continuously shutdown and redeployed in order to apply the new resource assignment. To overcome this issue, we propose a re-orchestration scheme that migrates microservice at runtime based on a rolling update scheduling logic. Specifically, we propose an integer linear optimization problem that minimizes the cost associated to multi-cloud virtual nodes and that ensures that delay-sensitive microservices are co-located on the same regional cluster. The resulting rescheduling order guarantees no service disruption by repacking microservices between the available nodes without the need to turn off the outdated microservice instance before redeploying the updated version. In addition, we propose a two-step heuristic scheme that effectively approximates the optimal solution at the expense of close-to-zero service disruption and QoS violation probability. Results show that proposed schemes achieve better performance in terms of cost mitigation, low service disruption and low QoS violation probability compared to baseline schemes replicating Kubernetes scheduler functionalities.","['Index', 'Terms: ', 'Microservice re-orchestration, cost minimization, resource allocation, multi-cloud systems, optimization']",['dsiracusa@fbk.eu']
,[''],[]
"We study the inclusive production of hadrons with bottom flavor at the LHC and its luminosity upgrade.
We describe the collinear fragmentation of singly b𝑏bitalic_b-flavored hadrons, B𝐵Bitalic_B mesons and ΛbsubscriptΛ𝑏\Lambda_{b}roman_Λ start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT baryons, via the KKSS07 determination of fragmentation functions, while for charmed B𝐵Bitalic_B mesons, Bc(1S0)B_{c}(^{1}S_{0})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and Bc(3S1)B_{c}(^{3}S_{1})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) particles, we employ the novel ZCFW22 set, built on the basis of state-of-the-art nonrelativistic QCD inputs.
We use the Jethad multimodular working environment to analyze rapidity and transverse-momentum distributions for observables sensitive to the associated emission of two hadrons or a hadron-plus-jet system.
Our reference formalism is the NLL/NLO+NLLsuperscriptNLO{\rm NLL/NLO^{+}}roman_NLL / roman_NLO start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT hybrid collinear and high-energy factorization, where the standard collinear description is improved by the inclusions of energy logarithms resummed up to the next-to-leading approximation and beyond.
We provide a corroborating evidence that b𝑏bitalic_b-flavor emissions act as fair stabilizers of the high-energy resummation, thus serving as valuable tools for precision studies of high-energy QCD.
As a bonus, we highlight that the predicted production-rate hierarchy between noncharmed b𝑏bitalic_b-hadrons and charmed Bc(1S0)B_{c}(^{1}S_{0})italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) mesons is in line with recent LHCb estimates.
This serves as simultaneous benchmark both for the hybrid factorization and the single-parton fragmentation mechanism from the nonrelativistic QCD effective theory.",[''],['[']
,[''],[]
"The evolution of the temperature dependence of pseudogap
ΔΔ\Deltaroman_Δ*(T) in optimally doped (OD) YBa22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTO7−δ7𝛿{}_{7-\delta}start_FLOATSUBSCRIPT 7 - italic_δ end_FLOATSUBSCRIPT
(YBCO) films with Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 88.7 K under the influence of a magnetic
field B𝐵Bitalic_B up to 8 T has been studied in detail. It has been
established that the shape of ΔΔ\Deltaroman_Δ*(T) for various B𝐵Bitalic_B over the
entire range from the pseudogap opening temperature T𝑇Titalic_T* to
T01subscript𝑇01T_{01}italic_T start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT, below which superconducting fluctuations occur, has a wide
maximum at the BEC-BCS crossover temperature Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT, which is
typical for OD films and untwinned YBCO single crystals. T𝑇Titalic_T* was
shown to be independent on B𝐵Bitalic_B, whereas Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT shifts to the low
temperature region along with increase of B𝐵Bitalic_B, while the maximum
value of ΔΔ\Deltaroman_Δ*(Tp⁢a⁢i⁢rsubscript𝑇𝑝𝑎𝑖𝑟T_{pair}italic_T start_POSTSUBSCRIPT italic_p italic_a italic_i italic_r end_POSTSUBSCRIPT) remains practically constant
regardless of B𝐵Bitalic_B. It was revealed that as the field increases, the
low-temperature maximum near the 3D-2D transition temperature
T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is blurred and disappears at B𝐵Bitalic_B > 5 T. Moreover, above the
Ginzburg temperature TGsubscript𝑇𝐺T_{G}italic_T start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, which limits superconducting
fluctuations from below, at B𝐵Bitalic_B > 0.5 T, a minimum appears on
ΔΔ\Deltaroman_Δ*(T) at Tm⁢i⁢nsubscript𝑇𝑚𝑖𝑛T_{min}italic_T start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT, which becomes very pronounced with a
further increase in the field. As a result, the overall value of
ΔΔ\Deltaroman_Δ*(T) decreases noticeably most likely due to pair-breaking
affect of a magnetic field. A comparison of ΔΔ\Deltaroman_Δ*(T) near
Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT with the Peters-Bauer theory shows that the density of
fluctuating Cooper pairs actually decreases from <n↑↑{}_{\uparrow}start_FLOATSUBSCRIPT ↑ end_FLOATSUBSCRIPTn↓↓{}_{\downarrow}start_FLOATSUBSCRIPT ↓ end_FLOATSUBSCRIPT> ≈\approx≈
0.31 at B𝐵Bitalic_B = 0 to <n↑↑{}_{\uparrow}start_FLOATSUBSCRIPT ↑ end_FLOATSUBSCRIPTn↓↓{}_{\downarrow}start_FLOATSUBSCRIPT ↓ end_FLOATSUBSCRIPT> ≈\approx≈
0.28 in the field 8 T. The observed behavior of ΔΔ\Deltaroman_Δ*(T) around
Tm⁢i⁢nsubscript𝑇𝑚𝑖𝑛T_{min}italic_T start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT is assumed to be due to the influence of a two-dimensional
vortex lattice created by the magnetic field, which prevents the
formation of fluctuating Cooper pairs near Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT.
Keywords: high-temperature superconductors, YBCO films, excess
conductivity, fluctuation conductivity, pseudogap, magnetic field,
coherence length.",[''],['Poland']
"Visual attribution in medical imaging seeks to make evident the diagnostically-relevant components of a medical image, in contrast to the more common detection of diseased tissue deployed in standard machine vision pipelines (which are less straightforwardly interpretable/explainable to clinicians).

We here present a novel generative visual attribution technique, one that leverages latent diffusion models in combination with domain-specific large language models, in order to generate normal counterparts of abnormal images. The discrepancy between the two hence gives rise to a mapping indicating the diagnostically-relevant image components.
To achieve this, we deploy image priors in conjunction with appropriate conditioning mechanisms in order to control the image generative process, including natural language text prompts acquired from medical science and applied radiology. We perform experiments and quantitatively evaluate our results on the COVID-19 Radiography Database containing labelled chest X-rays with differing pathologies via the Frechet Inception Distance (FID), Structural
Similarity (SSIM) and Multi Scale Structural Similarity Metric (MS-SSIM) metrics obtained between real and generated images.
The resulting system also exhibits a range of latent capabilities including zero-shot localized disease induction, which are evaluated with real examples from the cheXpert dataset.",[''],"['UK', 'ammaradeel7@gmail.com', 'UK', 'Pakistan', 'UK']"
"Context:Twenty-two extragalactic fast X-ray transients (FXTs) have now been discovered from two decades of Chandra data (analyzing ∼similar-to{\sim}∼259 Ms of data), with 17 associated with distant galaxies (≳greater-than-or-equivalent-to{\gtrsim}≳100 Mpc). Different mechanisms and progenitors have been proposed to explain their properties; nevertheless, after analyzing their timing, spectral parameters, host-galaxy properties, luminosity function, and volumetric rates, their nature remains uncertain.
Aims:We interpret a sub-sample of nine FXTs that show a plateau or a fast-rise light curve within the framework of a binary neutron star (BNS) merger magnetar model.
Methods:We fit their light curves and derive magnetar (magnetic field and initial rotational period) and ejecta (ejecta mass and opacity) parameters. This model predicts two zones: an orientation-dependent free zone (where the magnetar spin-down X-ray photons escape freely to the observer) and a trapped zone (where the X-ray photons are initially obscured and only escape freely once the ejecta material becomes optically thin). We argue that six FXTs show properties consistent with the free zone and three FXTs with the trapped zone.
Results:This sub-sample of FXTs has a similar distribution of magnetic fields and initial rotation periods to those inferred for short gamma-ray bursts (SGRBs), suggesting a possible association.
We compare the predicted ejecta emission fed by the magnetar emission (called merger-nova) to the optical and near-infrared upper limits of two FXTs, XRT 141001 and XRT 210423 where contemporaneous optical observations are available. The non-detections place lower limits on the redshifts of XRT 141001 and XRT 210423 of z≳1.5greater-than-or-equivalent-to𝑧1.5z{\gtrsim}1.5italic_z ≳ 1.5 and ≳0.1greater-than-or-equivalent-toabsent0.1{\gtrsim}0.1≳ 0.1, respectively.
Conclusions:If the magnetar remnants lose energy via gravitational waves (GWs), it should be possible to detect similar objects with the current advanced LIGO detectors out to a redshift z≲0.03less-than-or-similar-to𝑧0.03z{\lesssim}0.03italic_z ≲ 0.03, while future GW detectors will be able to detect them out to z≈0.5𝑧0.5z{\approx}0.5italic_z ≈ 0.5.","['Key', 'Words.: ', 'X-ray: general –', 'X-ray: bursts –', 'X-ray: magnetars']",[]
,[''],[]
"In this article, we demonstrate how black hole quasi-normal modes can emerge from a Dirichlet brickwall model normal modes. We consider a probe scalar field in a BTZ-geometry with a Dirichlet brickwall and demonstrate that as the wall approaches the event horizon, the corresponding poles in the retarded correlator become dense and yield an effective branch-cut. The associated discontinuity of the correlator carries the information of the black hole quasi-normal modes. We further demonstrate that a non-vanishing angular momentum non-perturbatively enhances the pole-condensing. We hypothesize that it is also related to quantum chaotic features of the corresponding spectral form factor, which has been observed earlier. Finally we discuss the underlying algebraic justification of this approximate thermalization in terms of the trace of the algebra.",[''],"['Germany', 'India.', 'Germany', 'India.']"
,[''],[]
"We conduct a large-scale fine-grained comparative analysis
of machine translations (MT) against human translations (HT) through
the lens of morphosyntactic divergence.
Across three language pairs and two types of divergence
defined as the structural difference between the source and the target,
MT is consistently more conservative than HT, with less morphosyntactic diversity, more convergent patterns, and more one-to-one alignments.
Through analysis on different decoding algorithms,
we attribute this discrepancy to the use of beam search
that biases MT towards more convergent patterns.
This bias is most amplified when the convergent pattern appears around 50% of the time in training data.
Lastly, we show that for a majority of morphosyntactic divergences,
their presence in HT is
correlated with decreased MT performance, presenting a greater challenge for MT systems.",[''],[]
"For a group G𝐺Gitalic_G and a positive integer n𝑛nitalic_n write Bn⁢(G)={x∈G:|xG|≤n}subscript𝐵𝑛𝐺conditional-set𝑥𝐺superscript𝑥𝐺𝑛B_{n}(G)=\{x\in G:|x^{G}|\leq n\}italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_G ) = { italic_x ∈ italic_G : | italic_x start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT | ≤ italic_n }. If s≥1𝑠1s\geq 1italic_s ≥ 1 and w𝑤witalic_w is a group word, say that G𝐺Gitalic_G satisfies the
(n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word w𝑤witalic_w if there exists a subset S⊆G𝑆𝐺S\subseteq Gitalic_S ⊆ italic_G such that |S|≤s𝑆𝑠|S|\leq s| italic_S | ≤ italic_s and all w𝑤witalic_w-values of G𝐺Gitalic_G are contained in Bn⁢(G)⁢Ssubscript𝐵𝑛𝐺𝑆B_{n}(G)Sitalic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_G ) italic_S. In a natural way, this condition emerged in the study of probabilistically nilpotent groups of class two. In this paper we obtain the following results.


Let w𝑤witalic_w be a multilinear commutator word on k𝑘kitalic_k variables and let G𝐺Gitalic_G be a group satisfying the (n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word w𝑤witalic_w. Then G𝐺Gitalic_G has a soluble subgroup T𝑇Titalic_T such that [G:T]delimited-[]normal-:𝐺𝑇[G:T][ italic_G : italic_T ] and the derived length of T𝑇Titalic_T are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded. (Theorem 1.1.)


Let k≥1𝑘1k\geq 1italic_k ≥ 1 and G𝐺Gitalic_G be a group satisfying the (n,s)𝑛𝑠(n,s)( italic_n , italic_s )-covering condition with respect to the word γksubscript𝛾𝑘\gamma_{k}italic_γ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Then (1)
γ2⁢k−1⁢(G)subscript𝛾2𝑘1𝐺\gamma_{2k-1}(G)italic_γ start_POSTSUBSCRIPT 2 italic_k - 1 end_POSTSUBSCRIPT ( italic_G ) has a subgroup T𝑇Titalic_T such that [γ2⁢k−1⁢(G):T]delimited-[]normal-:subscript𝛾2𝑘1𝐺𝑇[\gamma_{2k-1}(G):T][ italic_γ start_POSTSUBSCRIPT 2 italic_k - 1 end_POSTSUBSCRIPT ( italic_G ) : italic_T ] and |T′|superscript𝑇normal-′|T^{\prime}|| italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded; and (2) G𝐺Gitalic_G has a nilpotent subgroup U𝑈Uitalic_U such that [G:U]delimited-[]normal-:𝐺𝑈[G:U][ italic_G : italic_U ] and the nilpotency class of U𝑈Uitalic_U are both (k,n,s)𝑘𝑛𝑠(k,n,s)( italic_k , italic_n , italic_s )-bounded. (Theorem 1.2.)","['Key words and phrases: conjugacy classes, word values, nilpotent groups']",[]
"In this paper we continue investigating connections between Floer
theory and dynamics of Hamiltonian systems, focusing on the barcode
entropy of Reeb flows. Barcode entropy is the exponential growth
rate of the number of not-too-short bars in the Floer or symplectic
homology persistence module. The key novel result is that the
barcode entropy is bounded from below by the topological entropy of
any hyperbolic invariant set. This, combined with the fact that the
topological entropy bounds the barcode entropy from above,
established by Fender, Lee and Sohn, implies that in dimension three
the two types of entropy agree. The main new ingredient of the proof
is a variant of the Crossing Energy Theorem for Reeb flows.","['Key words and phrases:', 'Periodic orbits,', 'Reeb flows,', 'Floer homology, topological\nentropy, barcode entropy, persistence modules']",[]
"Linear-Quadratic (LQ) problems that arise in systems and controls include the classical optimal control problems of the Linear Quadratic Regulator (LQR) in both its deterministic and stochastic forms, as well as 𝖧∞superscript𝖧{\sf H}^{\infty}sansserif_H start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT-analysis (the Bounded Real Lemma), the Positive Real Lemma, and general Integral Quadratic Constraints (IQCs) tests. We present a unified treatment of all of these problems using an approach which converts linear-quadratic problems to matrix-valued linear-linear problems with a positivity constraint. This is done through a system representation where the joint state/input covariance (the outer product in the deterministic case) matrix is the fundamental object. LQ problems then become infinite-dimensional semidefinite programs, and the key tool used is that of linear-conic duality. Linear Matrix Inequalities (LMIs) emerge naturally as conal constraints on dual problems. Riccati equations characterize extrema of these special LMIs, and therefore provide solutions to the dual problems. The state-feedback structure of all optimal signals in these problems emerge out of alignment (complementary slackness) conditions between primal and dual problems. Perhaps the new insight gained from this approach is that first LMIs, and then second, Riccati equations arise naturally in dual, rather than primal problems. Furthermore, while traditional LQ problems are set up in 𝖫2superscript𝖫2{\sf L}^{2}sansserif_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT spaces of signals, their equivalent covariance-representation problems are most naturally set up in 𝖫1superscript𝖫1{\sf L}^{1}sansserif_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT spaces of matrix-valued signals.",[''],[]
"Starting from the Kirchhoff-Huygens representation and Duhamel’s principle of time-domain wave equations, we propose novel butterfly-compressed Hadamard integrators for self-adjoint wave equations in both time and frequency domain in an inhomogeneous medium. First, we incorporate the leading term of Hadamard’s ansatz into the Kirchhoff-Huygens representation to develop a short-time valid propagator. Second, using the Fourier transform in time, we derive the corresponding Eulerian short-time propagator in frequency domain; on top of this propagator, we further develop a time-frequency-time (TFT) method for the Cauchy problem of time-domain wave equations. Third, we further propose the time-frequency-time-frequency (TFTF) method for the corresponding point-source Helmholtz equation, which provides Green’s functions of the Helmholtz equation for all angular frequencies within a given frequency band. Fourth, to implement TFT and TFTF methods efficiently, we introduce butterfly algorithms to compress oscillatory integral kernels at different frequencies. As a result, the proposed methods can construct wave field beyond caustics implicitly and advance spatially overturning waves in time naturally with quasi-optimal computational complexity and memory usage. Furthermore, once constructed the Hadamard integrators can be employed to solve both time-domain wave equations with various initial conditions and frequency-domain wave equations with different point sources. Numerical examples for two-dimensional wave equations illustrate the accuracy and efficiency of the proposed methods.","['Time-dependent wave equation', 'Helmholtz equationHigh frequency wave', 'Hadamard’s ansatz', 'Butterfly algorithm', 'Caustics']",[]
"Information aging has gained prominence in characterizing communication protocols for timely remote estimation and control applications. This work proposes an Age of Information (AoI)-aware threshold-based dynamic frame slotted ALOHA (T-DFSA) for contention resolution in random access machine-type communication networks. Unlike conventional DFSA that maximizes the throughput in each frame, the frame length and age-gain threshold in T-DFSA are determined to minimize the normalized average AoI reduction of the network in each frame. At the start of each frame in the proposed protocol, the common Access Point (AP) stores an estimate of the age-gain distribution of a typical node. Depending on the observed status of the slots, age-gains of successful nodes, and maximum available AoI, the AP adjusts its estimation in each frame. The maximum available AoI is exploited to derive the maximum possible age-gain at each frame and thus, to avoid overestimating the age-gain threshold, which may render T-DFSA unstable. Numerical results validate our theoretical analysis and demonstrate the effectiveness of the proposed T-DFSA compared to the existing optimal frame slotted ALOHA, threshold-ALOHA, and age-based thinning protocols in a considerable range of update generation rates.","['Index', 'Terms: ', 'Age of information, random access, dynamic frame slotted', 'ALOHA,', 'Internet of', 'Things, stochastic arrivals.']",[]
"This paper investigates the high-level decision-making problem in highway scenarios regarding lane changing and over-taking other slower vehicles. In particular, this paper aims to improve the Travel Assist feature for automatic overtaking and lane changes on highways. About 9 million samples including lane images and other dynamic objects are collected in simulation. This data; Overtaking on Simulated HighwAys (OSHA) dataset is released to tackle this challenge. To solve this problem, an architecture called SwapTransformer is designed and implemented as an imitation learning approach on the OSHA dataset. Moreover, auxiliary tasks such as future points and car distance network predictions are proposed to aid the model in better understanding the surrounding environment. The performance of the proposed solution is compared with a multi-layer perceptron (MLP) and multi-head self-attention networks as baselines in a simulation environment. We also demonstrate the performance of the model with and without auxiliary tasks. All models are evaluated based on different metrics such as time to finish each lap, number of overtakes, and speed difference with speed limit. The evaluation shows that the SwapTransformer model outperforms other models in different traffic densities in the inference phase.",[''],[]
"Pearl’s causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a deep causal generative model, which utilizes the pre-trained model and can provably sample from identifiable interventional and counterfactual distributions. Our algorithm, called Modular-DCM, uses adversarial training to learn the network weights, and to the best of our knowledge, is the first algorithm that can make use of pre-trained models and provably sample from any identifiable causal query in the presence of latent confounders with high-dimensional data. We demonstrate the utility of our algorithm using semi-synthetic and real-world datasets containing images as variables in the causal structure.",[''],[]
"In this note, we use recent advances concerning the K-stability of ℚℚ\mathbb{Q}blackboard_Q-Fano varieties to provide settings for which Vojta’s conjecture holds.","['Key words and phrases:', 'Vojta’s conjecture,', 'K-stability,', 'Fano varieties']",[]
"We prove that in a theory T𝑇Titalic_T stable over a predicate P𝑃Pitalic_P, for any λ>|T|𝜆𝑇\lambda>|T|italic_λ > | italic_T |, there is a λ𝜆\lambdaitalic_λ-prime model over any complete set A𝐴Aitalic_A with a λ𝜆\lambdaitalic_λ-saturated P𝑃Pitalic_P-part.",[''],[]
,[''],[]
,[''],[]
,[''],[]
"Multiple access (MA) is a crucial part of any wireless system and refers to techniques that make use of the resource dimensions (e.g., time, frequency, power, antenna, code, message, etc) to serve multiple users/devices/machines/services, ideally in the most efficient way. Given the increasing needs of multi-functional wireless networks for integrated communications, sensing, localization, computing, coupled with the surge of machine learning / artificial intelligence (AI) in wireless networks, MA techniques are expected to experience a paradigm shift in 6G and beyond. In this paper, we provide a tutorial, survey and outlook of past, emerging and future MA techniques and pay a particular attention to how wireless network intelligence and multi-functionality will lead to a re-thinking of those techniques. The paper starts with an overview of orthogonal, physical layer multicasting, space domain, power domain, rate-splitting, code domain MAs, and MAs in other domains, and highlight the importance of researching universal multiple access to shrink instead of grow the knowledge tree of MA schemes by providing a unified understanding of MA schemes across all resource dimensions. It then jumps into rethinking MA schemes in the era of wireless network intelligence, covering AI for MA such as AI-empowered resource allocation, optimization, channel estimation, receiver designs, user behavior predictions for different MA schemes, and MA for AI such as federated learning/edge intelligence and over the air computation. We then discuss MA for network multi-functionality and the interplay between MA and integrated
sensing, localization, and communications, covering MA for joint sensing and communications, multimodal sensing-aided communications, multimodal sensing and digital twin-assisted communications, and communication-aided sensing/localization systems. We finish with studying MA for emerging intelligent applications such as semantic communications, metaverse, virtual reality, smart radio and reconfigurable intelligent surfaces, and massive connectivity and random access in Internet-of-Things, before presenting a roadmap toward 6G standardization. Throughout the text, we also point out numerous directions that are promising for future research.","['Index', 'Terms: ', 'Multiple', 'Access,', 'Orthogonal', 'Multiple', 'Access,', 'Non-Orthogonal', 'Multiple', 'Access,', 'Space', 'Division', 'Multiple', 'Access,', 'Code', 'Domain', 'Multiple', 'Access,', 'Rate-Splitting', 'Multiple', 'Access,', 'Universal', 'Multiple', 'Access,', 'Artificial', 'Intelligence,', 'Machine', 'Learning,', 'Integrated', 'Sensing and', 'Communications,', 'Semantic', 'Communications,', 'Reconfigurable', 'Intelligent', 'Surfaces,', 'Metaverse,', 'Augmented', 'Reality,', 'Internet-of-Things, 6G.']",[]
,[''],[]
,[''],[]
"Active fluid transport is a hallmark of many biological transport networks. While
animal circulatory systems generally rely on a single heart to drive flows,
other organisms employ decentralized local pumps to distribute fluids and nutrients.
Here, we study the decentralized pumping mechanism
in the slime mold Physarum polycephalum which is locally triggered by
active release, uptake, and transport of a chemical solute within the
organism’s vascular network to drive global oscillations.
Based on a conceptual network model combining active elasticity and
fluid transport we identify a set of contractile modes specific to each network and show that modes corresponding
to large-scale oscillations are preferentially and robustly excited both
in model simulations and
in experimental data obtained from living Physarum plasmodia. These dominant
modes are computed explicitly and shown to drive large-scale flows within the
organism.
Furthermore, Physarum must transport nutrients over long distances.
As each mode corresponds to pure shuttle flow, long-range, directed transport
must rely on a non-linear coupling beyond harmonic dynamics. Using simulations,
we demonstrate that the network’s transport capability is optimized when two
dominant modes are excited at a phase shift of π/2𝜋2\pi/2italic_π / 2, resulting in contractile
excitations similar to those observed in real Physarum.
Our results provide a conceptual framework for understanding active
decentralized transport in Physarum and other contractile
biological networks, such as brain vasculature, as well as decentralized transportation
networks more generally.",[''],"['U.S.A.', 'U.S.A.', 'U.S.A.']"
,[''],[]
,[''],[]
"LiDAR is used in autonomous driving to provide 3D spatial information and enable accurate perception in off-road environments, aiding in obstacle detection, mapping, and path planning. Learning-based LiDAR semantic segmentation utilizes machine learning techniques to automatically classify objects and regions in LiDAR point clouds. Learning-based models struggle in off-road environments due to the presence of diverse objects with varying colors, textures, and undefined boundaries, which can lead to difficulties in accurately classifying and segmenting objects using traditional geometric-based features. In this paper, we address this problem by harnessing the LiDAR intensity parameter to enhance object segmentation in off-road environments. Our approach was evaluated in the RELLIS-3D data set and yielded promising results as a preliminary analysis with improved mIoU for classes ”puddle” and ”grass” compared to more complex deep learning-based benchmarks111https://github.com/MOONLABIISERB/lidar-intensity-predictor/tree/main. The methodology was evaluated for compatibility across both Velodyne and Ouster LiDAR systems, assuring its cross-platform applicability. This analysis advocates for the incorporation of calibrated intensity as a supplementary input, aiming to enhance the prediction accuracy of learning based semantic segmentation frameworks.

222The work is supported by TIH iHUB Drishti-IIT Jodhpur under project number 23 and accepted for publication at International Symposium on Experimental Robotics 2023.",[''],[]
"Machine learning, particularly neural networks, has rapidly permeated most activities and work where data has a story to tell. Recently, deep learning has started to be used for solving differential equations with input from physics, also known as Physics-Informed Neural Networks (PINNs). We present a study showing the efficacy of PINNs for solving the Zerilli and the Regge-Wheeler equations in the time domain to calculate the quasi-normal oscillation modes of a Schwarzschild black hole. We compare the extracted modes with those obtained with finite difference methods.
Although the PINN results are competitive, with a few percent differences in the quasi-normal modes estimates relative to those computed with finite difference methods, the real power of PINNs will emerge when applied to large dimensionality problems.",[''],[]
,[''],[]
"When implementing hierarchical federated learning over wireless networks, scalability assurance and the ability to handle both interference and device data heterogeneity are crucial. This work introduces a learning method designed to address these challenges, along with
a scalable transmission scheme that efficiently uses a single wireless resource
through over-the-air computation. To provide resistance against data heterogeneity, we employ gradient aggregations. Meanwhile, the impact of interference is minimized through optimized receiver normalizing factors. For this, we model a multi-cluster wireless network using stochastic geometry, and characterize the mean squared error of the aggregation estimations as a function of the network parameters.
We show that despite the interference and the data heterogeneity, the proposed scheme achieves high learning accuracy and can significantly outperform the conventional hierarchical algorithm.","['Index', 'Terms: ', 'Federated learning, hierarchical networks, over-the-air computation, interference, stochastic geometry.']","['{seyaa,vjfodor}@kth.se']"
"In ultraviolet (UV) astronomical observations, photons from the sources are very few compared to the visible or infrared (IR) wavelength ranges. Detectors operating in the UV usually employ a photon-counting mode of operation. These detectors usually have an image intensifier sensitive to UV photons and a readout mechanism that employs photon counting. The development of readouts for these detectors is resource-intensive and expensive. In this paper, we describe the development of a low-cost UV photon-counting detector processing unit that employs a Raspberry Pi with its in built readout to perform the photon-counting operation. Our system can operate in both 3×3333\times 33 × 3 and 5×5555\times 55 × 5 window modes at 30 frames per sec (fps), where 5×5555\times 55 × 5 window mode also enables the provision of detection of double events. The system can be built quickly from readily available custom-off-the-shelf (COTS) components and is thus used in inexpensive CubeSats or small satellite missions. This low-cost solution promises to broaden access to UV observations, advancing research possibilities in space-based astronomy.",[''],"['India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India', 'India']"
"Flamelet-based methods are extensively used in modeling turbulent hydrocarbon flames. However, these models have yet to be established for (lean) premixed hydrogen flames.
While flamelet models exist for laminar thermo-diffusively unstable hydrogen flames, for which consideration of curvature effects has resulted in improved model predictions [1],
it is still unclear whether these models are directly applicable to turbulent hydrogen flames.
Therefore, a detailed assessment of stretch effects on thermochemical states in a turbulent lean premixed hydrogen-air slot flame through finite-rate chemistry simulations is conducted.
Strain and curvature are examined individually using a composition space model, revealing their distinct influences on thermochemical states.
An a-priori analysis confirms that the previously developed tabulated manifolds fall short of capturing all turbulent flame phenomena,
necessitating a novel manifold incorporating both strain and curvature variations.
These results underscore the significance of these variations in developing manifold-based combustion models for turbulent lean hydrogen flames.","['Key words and phrases:', 'Turbulent premixed flames;', 'Thermodiffusive instability;', 'Hydrogen combustion;', 'Preferential diffusion;', 'Strain and curvature;', 'Flamelet modeling']",[]
"Visual obstacle discovery is a key step towards autonomous navigation of indoor mobile robots.
Successful solutions have many applications in multiple scenes.
One of the exceptions is the reflective ground.
In this case,
the reflections on the floor resemble the true world,
which confuses the obstacle discovery and leaves navigation unsuccessful.
We argue that the key to this problem lies in obtaining discriminative features for reflections and obstacles.
Note that obstacle and reflection can be separated by the ground plane in 3D space.
With this observation,
we firstly introduce a pre-calibration based ground detection scheme that uses robot motion to predict the ground plane.
Due to the immunity of robot motion to reflection,
this scheme avoids failed ground detection caused by reflection.
Given the detected ground,
we design a ground-pixel parallax to describe the location of a pixel relative to the ground.
Based on this,
a unified appearance-geometry feature representation is proposed to describe objects inside rectangular boxes.
Eventually,
based on segmenting by detection framework,
an appearance-geometry fusion regressor is designed to utilize the proposed feature to discover the obstacles.
It also prevents our model from concentrating too much on parts of obstacles instead of whole obstacles.
For evaluation,
we introduce a new dataset for Obstacle on Reflective Ground (ORG),
which comprises 15 scenes with various ground reflections,
a total of more than 200 image sequences and 3400 RGB images.
The pixel-wise annotations of ground and obstacle provide a comparison to our method and other methods.
By reducing the misdetection of the reflection,
the proposed approach outperforms others.
The source code and the dataset will be available at https://github.com/XuefengBUPT/IndoorObstacleDiscovery-RG.","['Reflective', 'Ground', 'Obstacle', 'Discovery', 'Homography']",[]
,[''],[]
,[''],[]
"Multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. Recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. However, these methods often include complex modules that entail heavy computation and lack interpretability. In this paper, we propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel framework to address these challenges in multi-label image classification tasks. Our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. This structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. We enhance representation learning by incorporating a mixture density network into contrastive learning and generating Gaussian mixture distributions to explore the epistemic uncertainty of the feature encoder. We validate the effectiveness of our framework through experimentation with datasets from the computer vision and medical imaging domains. Our method outperforms the existing state-of-the-art methods while achieving a low computational footprint on both datasets. Visualization analyses also demonstrate that ProbMCL-learned classifiers maintain a meaningful semantic topology.",[''],[]
"Let Md(k)⁢(n)subscriptsuperscript𝑀𝑘𝑑𝑛M^{({k})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( italic_k ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) be the manifold of n𝑛nitalic_n-tuples (x1,…,xn)∈(ℝd)nsubscript𝑥1…subscript𝑥𝑛superscriptsuperscriptℝ𝑑𝑛(x_{1},\ldots,x_{n})\in(\mathbb{R}^{d})^{n}( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ∈ ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT having non-k𝑘kitalic_k-equal coordinates. We show that, for d≥2𝑑2d\geq 2italic_d ≥ 2, Md(3)⁢(n)subscriptsuperscript𝑀3𝑑𝑛M^{({3})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) is rationally formal if and only if n≤6𝑛6n\leq 6italic_n ≤ 6. This stands in sharp contrast with the fact that all classical configuration spaces Md(2)⁢(n)=Conf ⁢(ℝd,n)subscriptsuperscript𝑀2𝑑𝑛Conf superscriptℝ𝑑𝑛M^{({2})}_{d}(n)=\text{Conf\hskip 1.13809pt}(\hskip 0.56905pt\mathbb{R}^{d},n)italic_M start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) = Conf ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , italic_n ) are rationally formal, just as are all complements of arrangements of arbitrary complex subspaces with geometric lattice of intersections. The rational non formality of Md(3)⁢(n)subscriptsuperscript𝑀3𝑑𝑛M^{({3})}_{d}(n)italic_M start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_n ) for n>6𝑛6n>6italic_n > 6 is established via detection of non-trivial triple Massey products assessed through Poincaré duality.",[''],[]
"We present a comparative study of the molecular gas in two galaxies from the LEGUS sample: barred spiral NGC 1313 and flocculent spiral NGC 7793. These two galaxies have similar masses, metallicities, and star formation rates, but NGC 1313 is forming significantly more massive star clusters than NGC 7793, especially young massive clusters (<10absent10<10< 10 Myr, >104absentsuperscript104>10^{4}> 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT).
Using ALMA CO(2-1) observations of the two galaxies with the same sensitivities and resolutions of 13 pc, we directly compare the molecular gas in these two similar galaxies to determine the physical conditions responsible for their large disparity in cluster formation.
By fitting size-linewidth relations for the clouds in each galaxy, we find that NGC 1313 has a higher intercept than NGC 7793, implying that its clouds have higher kinetic energies at a given size scale. NGC 1313 also has more clouds near virial equilibrium than NGC 7793, which may be connected to its higher rate of massive cluster formation. However, these virially bound clouds do not show a stronger correlation with young clusters than that of the general cloud population. 
We find surprisingly small differences between the distributions of molecular cloud populations in the two galaxies, though the largest of those differences are that NGC 1313 has higher surface densities and lower free-fall times.","['star formation;', 'ALMA; spiral galaxies']","['USA', 'USA', 'USA', 'USA', 'USA', 'Sweden', 'USA', 'Researcher', 'USA', '82071', 'UK', 'USA', 'USA', 'USA', 'Italy', 'Italy', '53706', '55105', 'Australia', 'Australia', 'USA', 'Germany', 'USA', 'USA', 'Australia', 'Australia', 'USA', 'Switzerland', 'Sweden', 'USA', 'USA', 'USA', 'USA', 'USA', 'México']"
"We compare the molecular cloud properties in sub-galactic regions of two galaxies, barred spiral NGC 1313, which is forming many massive clusters, and flocculent spiral NGC 7793, which is forming significantly fewer massive clusters despite having a similar star formation rate to NGC 1313.
We find that there are larger variations in cloud properties between different regions within each galaxy than there are between the galaxies on a global scale, especially for NGC 1313.
There are higher masses, linewidths, pressures, and virial parameters in the arms of NGC 1313 and center of NGC 7793 than in the interarm and outer regions of the galaxies.
The massive cluster formation of NGC 1313 may be driven by its greater variation in environments, allowing more clouds with the necessary conditions to arise, although no one parameter seems primarily responsible for the difference in star formation.
Meanwhile NGC 7793 has clouds that are as massive and have as much kinetic energy as clouds in the arms of NGC 1313, but have densities and pressures more similar to the interarm regions and so are less inclined to collapse and form stars.
The cloud properties in NGC 1313 and NGC 7793 suggest that spiral arms, bars, interarm regions, and flocculent spirals each represent distinct environments with regard to molecular cloud populations.
We see surprisingly little difference in surface densities between the regions, suggesting that the differences in surface densities frequently seen between arm and interarm regions of lower-resolution studies are indicative of the sparsity of molecular clouds, rather than differences in their true surface density.","['star formation;', 'ALMA; spiral galaxies']","['USA', 'USA', 'USA', 'USA', 'USA', 'Sweden', 'USA', 'Researcher', 'USA', '82071', 'UK', 'USA', 'USA', 'USA', 'Italy', 'Italy', '53706', '55105', 'Australia', 'Australia', 'USA', 'Germany', 'USA', 'USA', 'Australia', 'Australia', 'USA', 'Switzerland', 'Sweden', 'USA', 'USA', 'USA', 'USA', 'USA', 'México']"
,[''],[]
"We introduce the entangled quantum polynomial hierarchy 𝖰𝖤𝖯𝖧𝖰𝖤𝖯𝖧\mathsf{QEPH}sansserif_QEPH as the class of problems that are efficiently verifiable given alternating quantum proofs that may be entangled with each other.
We prove 𝖰𝖤𝖯𝖧𝖰𝖤𝖯𝖧\mathsf{QEPH}sansserif_QEPH collapses to its second level. In fact, we show that a polynomial number of alternations collapses to just two.
As a consequence, 𝖰𝖤𝖯𝖧=𝖰𝖱𝖦⁢(𝟣)𝖰𝖤𝖯𝖧𝖰𝖱𝖦1\mathsf{QEPH}=\mathsf{QRG(1)}sansserif_QEPH = sansserif_QRG ( sansserif_1 ), the class of problems having one-turn quantum refereed games, which is known to be contained in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE.
This is in contrast to the unentangled quantum polynomial hierarchy 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH, which contains 𝖰𝖬𝖠⁢(𝟤)𝖰𝖬𝖠2\mathsf{QMA(2)}sansserif_QMA ( sansserif_2 ).

We also introduce a generalization of the quantum-classical polynomial hierarchy 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH where the provers send probability distributions over strings (instead of strings) and denote it by 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧\mathsf{DistributionQCPH}sansserif_DistributionQCPH.
Conceptually, this class is intermediate between 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH and 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH.
We prove 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧=𝖰𝖢𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{DistributionQCPH}=\mathsf{QCPH}sansserif_DistributionQCPH = sansserif_QCPH, suggesting that only quantum superposition (not classical probability) increases the computational power of these hierarchies.
To prove this equality, we generalize a game-theoretic result of Lipton and Young (1994) which says that the provers can send distributions that are uniform over a polynomial-size support.
We also prove the analogous result for the polynomial hierarchy, i.e., 𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖯𝖧=𝖯𝖧𝖣𝗂𝗌𝗍𝗋𝗂𝖻𝗎𝗍𝗂𝗈𝗇𝖯𝖧𝖯𝖧\mathsf{DistributionPH}=\mathsf{PH}sansserif_DistributionPH = sansserif_PH.
These results also rule out certain approaches for showing 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH collapses.
Finally, we show that 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH and 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH are contained in 𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH, resolving an open question of Gharibian et al. (2022).",[''],[]
"Autonomous driving has rapidly developed and shown promising performance with recent advances in hardware and deep learning methods. High-quality datasets are fundamental for developing reliable autonomous driving algorithms. Previous dataset surveys tried to review the datasets but either focused on a limited number or lacked detailed investigation of the characters of datasets. To this end, we present an exhaustive study of over 200 autonomous driving datasets from multiple perspectives, including sensor modalities, data size, tasks, and contextual conditions. We introduce a novel metric to evaluate the impact of each dataset, which can also be a guide for establishing new datasets. We further analyze the annotation process and quality of datasets. Additionally, we conduct an in-depth analysis of the data distribution of several vital datasets. Finally, we discuss the development trend of the future autonomous driving datasets.","['Index', 'Terms: ', 'Dataset, influence, annotation, autonomous driving.']",[]
"The notions of Hausdorff and Fourier dimensions are ubiquitous in harmonic analysis and geometric measure theory. It is known that any hypersurface in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT has Hausdorff dimension d𝑑ditalic_d. However, the Fourier dimension depends on the finer geometric properties of the hypersurface. For instance, the Fourier dimension of a hyperplane is 0, and the Fourier dimension of a hypersurface with non-vanishing Gaussian curvature is d𝑑ditalic_d. Recently, Harris has shown that the Euclidean light cone in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT has Fourier dimension d−1𝑑1d-1italic_d - 1, which leads one to conjecture that the Fourier dimension of a hypersurface equals the number of non-vanishing principal curvatures. We prove this conjecture for all d𝑑ditalic_d-dimensional cones and cylinders in ℝd+1superscriptℝ𝑑1\mathbb{R}^{d+1}blackboard_R start_POSTSUPERSCRIPT italic_d + 1 end_POSTSUPERSCRIPT generated by hypersurfaces in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT with non-vanishing Gaussian curvature. In particular, cones and cylinders are not Salem. Our method involves substantial generalizations of Harris’s strategy.","['Key words and phrases:', 'Fourier dimension,', 'Hausdorff dimension,', 'Salem set,', 'Gaussian curvature,', 'Principal curvature,', 'Oscillatory integrals,', 'Stationary phase,', 'Conical and cylindrical hypersurfaces']",[]
"Recently, diffusion models have demonstrated their effectiveness in generating extremely high-quality images and have found wide-ranging applications, including automatic sketch colorization. However, most existing models use text to guide the conditional generation, with fewer attempts exploring the potential advantages of using image tokens as conditional inputs for networks. As such, this paper exhaustively investigates image-guided models, specifically targeting reference-based sketch colorization, which aims to colorize sketch images using reference color images. We investigate three critical aspects of reference-based diffusion models: the shortcomings compared to text-based counterparts, the training strategies, and the capability in zero-shot, sequential text-based manipulation. We introduce two variations of an image-guided latent diffusion model using different image tokens from the pre-trained CLIP image encoder, and we propose corresponding manipulation methods to adjust their results sequentially using weighted text inputs. We conduct comprehensive evaluations of our models through qualitative and quantitative experiments, as well as a user study. Code link: https://github.com/ydk-tellurion/colorizeDiffusion.",[''],[]
,[''],[]
"Neural networks (NNs) are increasingly used in always-on safety-critical applications deployed on hardware accelerators (NN-HAs) employing various memory technologies. Reliable continuous operation of NN is essential for safety-critical applications. During online operation, NNs are susceptible to single and multiple permanent and soft errors due to factors such as radiation, aging, and thermal effects. Explicit NN-HA testing methods cannot detect transient faults during inference, are unsuitable for always-on applications, and require extensive test vector generation and storage.
Therefore, in this paper, we propose the
uncertainty fingerprint approach representing the online fault status of NN. Furthermore, we propose a dual head NN topology specifically designed to produce uncertainty fingerprints and the primary prediction of the NN in a single shot. During the online operation, by matching the uncertainty fingerprint, we can concurrently self-test NNs with up to 100%percent100100\%100 % coverage with a low false positive rate while maintaining a similar performance of the primary task. Compared to existing works, memory overhead is reduced by up to 243.7243.7243.7243.7 MB, multiply and accumulate (MAC) operation is reduced by up to 10000×10000\times10000 ×, and false-positive rates are reduced by up to 89%percent8989\%89 %.","['Index', 'Terms: ', 'Self-testing, concurrent testing, testing neural network, uncertainty estimation.']",[]
"Disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. However, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. To help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. Our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. Most importantly, experts have used our open-source Python implementation since April 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. Other organizations can readily adapt this implementation to create rankings from the outputs of their tailored univariate methods across large-scale streams.",[''],[]
"We introduce Deep Set Linearized Optimal Transport, an algorithm designed for the efficient simultaneous embedding of point clouds into an L2−limit-fromsuperscript𝐿2L^{2}-italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT -space. This embedding preserves specific low-dimensional structures within the Wasserstein space while constructing a classifier to distinguish between various classes of point clouds. Our approach is motivated by the observation that L2−limit-fromsuperscript𝐿2L^{2}-italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT -distances between optimal transport maps for distinct point clouds, originating from a shared fixed reference distribution, provide an approximation of the Wasserstein-2 distance between these point clouds, under certain assumptions.
To learn approximations of these transport maps, we employ input convex neural networks (ICNNs) and establish that, under specific conditions, Euclidean distances between samples from these ICNNs closely mirror Wasserstein-2 distances between the true distributions. Additionally, we train a discriminator network that attaches weights these samples and creates a permutation invariant classifier
to differentiate between different classes of point clouds. We showcase the advantages of our algorithm over the standard deep set approach through experiments on a flow cytometry dataset with a limited number of labeled point clouds.",[''],[]
"DSLR cameras can achieve multiple zoom levels via shifting lens distances or swapping lens types.
However, these techniques are not possible on smartphone devices due to space constraints.
Most smartphone manufacturers adopt a hybrid zoom system: commonly a Wide (W) camera at a low zoom level and a Telephoto (T) camera at a high zoom level.
To simulate zoom levels between W and T, these systems crop and digitally upsample images from W, leading to significant detail loss.
In this paper, we propose an efficient system for hybrid zoom super-resolution on mobile devices, which captures a synchronous pair of W and T shots and leverages machine learning models to align and transfer details from T to W.
We further develop an adaptive blending method that accounts for depth-of-field mismatches, scene occlusion, flow uncertainty, and alignment errors.
To minimize the domain gap, we design a dual-phone camera rig to capture real-world inputs and ground-truths for supervised training.
Our method generates a 12-megapixel image in 500ms on a mobile platform and compares favorably against state-of-the-art methods under extensive evaluation on real-world scenarios.","['hybrid zoom, dual camera fusion, deep neural networks']",['GoogleUSA']
"We introduce the notion of quota trees in directed graphs. Given a
nonnegative integer “quota” for each vertex of a directed multigraph
G𝐺Gitalic_G, a quota tree is an immersed rooted tree which hits each vertex of
G𝐺Gitalic_G the prescribed number of times. When the quotas are all one, the
tree is actually embedded and we recover the usual notion of a
spanning arborescence (directed spanning tree). The usual algorithms
which produce spanning arborescences with various properties typically
have (sometimes more complicated) “quota” analogues.
Our original motivation for studying quota trees was the problem of
characterizing the sizes of the Myhill-Nerode equivalence classes in a
connected deterministic finite-state automaton recognizing a given
regular language. We show that the obstruction to realizing a given
set of M-N class sizes is precisely the existence of a suitable quota
tree.
In this paper we develop the basic theory of quota trees.
We give necessary and sufficient conditions for the
existence of a quota tree (or forest) over a given directed graph with
specified quotas, solving the M-N class size problem as a special
case. We discuss some potential applications of quota trees and
forests, and connect them to the k𝑘kitalic_k lightest paths problem. We give
two proofs of the main theorem: one based on an algorithmic loop
invariant, and one based on direct enumeration of quota trees. For the
latter, we use Lagrange inversion to derive a formula which vastly
generalizes both the matrix-tree theorem and Cayley’s formula for
counting labeled trees. We give an efficient algorithm to sample
uniformly from the set of forests with given quotas, as well as a
generalization of Edmonds’ algorithm for computing a minimum-weight
quota forest.","['Key words and phrases: graph traversal, graph search, automata,', 'DFA, regular languages,', 'Myhill-Nerode, private information retrieval, graph immersions,\narborescences, spanning trees,', 'Edmonds’ algorithm, lightest paths,\nmatrix-tree, random trees,', 'Cayley formula,', 'Lagrange inversion,', 'Narayana numbers, combinatorial reciprocity']",[]
,[''],[]
"ABSTRACT: The Debye-Hückel (DH) formalism of bulk electrolytes equivalent to the gaussian-level closure of the electrostatic Schwinger-Dyson (SD) identities without the interionic hard-core (HC) coupling is extended via the cumulant treatment of these equations augmented by HC interactions. By confronting the monovalent ion activity and pressure predictions of our cumulant-corrected DH (CCDH) theory with hypernetted-chain (HNC) results and Monte-Carlo (MC) simulations from the literature, we show that this rectification extends the accuracy of the DH formalism from submolar into molar salt concentrations. In the case of internal energies or the general case of divalent electrolytes mainly governed by charge correlations, the improved accuracy of the CCDH theory is limited to submolar ion concentrations. Comparison with experimental data from the literature shows that via the adjustment of the hydrated ion radii, the CCDH formalism can equally reproduce the non-uniform effect of salt increment on the ionic activity coefficients up to molar concentrations. The inequality satisfied by these HC sizes coincides with the cationic branch of the Hofmeister series.",[''],['Turkey']
"We present a comprehensive analysis of the Hubble Space Telescope
observations of the atmosphere of WASP-121 b, a ultra-hot Jupiter.
After reducing the transit, eclipse, and phase-curve observations
with a uniform methodology and addressing the biases from
instrument systematics, sophisticated atmospheric retrievals are
used to extract robust constraints on the thermal structure,
chemistry, and cloud properties of the atmosphere.
Our analysis shows that the observations are consistent with a
strong thermal inversion beginning at ∼similar-to\sim∼104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT Pa on the
dayside, solar to subsolar metallicity Z𝑍Zitalic_Z
(i.e., −0.77<log⁡(Z)<0.050.77𝑍0.05-0.77<\log(Z)<0.05- 0.77 < roman_log ( italic_Z ) < 0.05), and super-solar C/O ratio
(i.e., 0.59<C/O<0.870.59C/O0.870.59<\textrm{C/O}<0.870.59 < C/O < 0.87).
More importantly, utilizing the high signal-to-noise ratio and
repeated observations of the planet, we identify the following
unambiguous time-varying signals in the data: i) a shift of
the putative hotspot offset between the two phase-curves and
ii) varying spectral signatures in the transits and eclipses.
By simulating the global dynamics of WASP-121 b
atmosphere at high-resolution, we show that the identified signals
are consistent with quasi-periodic weather patterns, hence
atmospheric variability, with signatures at the level probed by
the observations (∼similar-to\sim∼5% to ∼similar-to\sim∼10%) that change on a
timescale of ∼similar-to\sim∼5 planet days; in the simulations, the
weather patterns arise from the formation and movement of storms
and fronts, causing hot (as well as cold) patches of atmosphere
to deform, separate, and mix in time.","['Exoplanet atmospheric variability (2020),', 'Exoplanet atmospheric composition (2021),', 'Bayesian statistics (1900),', 'Astrophysical fluid dynamics (101),', 'Astronomy data analysis (1858)']","['work.', 'USA.', 'Kingdom', 'work.', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Kingdom', 'Kingdom', 'France', 'Netherlands', 'Kingdom', 'Germany', 'UK', 'Sweden', 'Spain', 'USA', 'Kingdom', 'France', 'Kingdom']"
"Achieving effective and seamless human-robot collaboration requires two key outcomes: enhanced team performance and fostering a positive human perception of both the robot and the collaboration. This paper investigates the capability of the proposed task planning framework to realize these objectives by integrating human leading/following preference and performance into its task allocation and scheduling processes. We designed a collaborative scenario wherein the robot autonomously collaborates with participants. The outcomes of the user study indicate that the proactive task planning framework successfully attains the aforementioned goals. We also explore the impact of participants’ leadership and followership styles on their collaboration. The results reveal intriguing relationships between these factors, which warrant further investigation in future studies.",[''],[]
,[''],[]
"In order to study exoplanets, a comprehensive characterization of the fundamental properties of the host stars, such as angular diameter, temperature, luminosity, and age, is essential, as the formation and evolution of exoplanets are directly influenced by the host stars at various points in time. In this paper, we present interferometric observations taken of directly imaged planet host 51 Eridani at the CHARA Array. We measure the limb-darkened angular diameter of 51 Eridani to be θLD=0.450±0.004subscript𝜃LDplus-or-minus0.4500.004\theta_{\rm LD}=0.450\pm 0.004italic_θ start_POSTSUBSCRIPT roman_LD end_POSTSUBSCRIPT = 0.450 ± 0.004 mas and combining with the Gaia zero-point corrected parallax, we get a stellar radius of 1.45±0.01plus-or-minus1.450.011.45\pm 0.011.45 ± 0.01 R⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. We use the PARSEC isochrones to estimate an age of 23.2−1.6+1.7subscriptsuperscript23.21.71.623.2^{+1.7}_{-1.6}23.2 start_POSTSUPERSCRIPT + 1.7 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 1.6 end_POSTSUBSCRIPT Myr and a mass of 1.550±0.005plus-or-minus1.5500.0051.550\pm 0.0051.550 ± 0.005 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. The age and mass agree well with values in the literature, determined through a variety of methods ranging from dynamical age trace-backs to lithium depletion boundary methods. We derive a mass of 4.1−0.4+0.5subscriptsuperscript4.10.50.44.1^{+0.5}_{-0.4}4.1 start_POSTSUPERSCRIPT + 0.5 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.4 end_POSTSUBSCRIPT MJupJup{}_{\rm Jup}start_FLOATSUBSCRIPT roman_Jup end_FLOATSUBSCRIPT for 51 Eri b using the Sonora Bobcat models, which further supports the possibility of 51 Eri b forming under either the hot-start formation model or the warm-start formation model.",[''],['USA']
,[''],[]
"Vision transformers (ViTs) have achieved promising results on a variety of computer vision tasks. However, their quadratic complexity in the number of input tokens limits their application, especially in resource-constrained settings. Previous approaches that address this challenge by employing gradual token reduction assume that token redundancy in one layer implies redundancy in all the following layers. We demonstrate empirically that this assumption is often incorrect, i.e., tokens that are redundant in one layer can be useful in later layers. Based on this key insight, we propose a novel token propagation controller (TPC) that incorporates two different token-distributions, namely pause probability and restart probability, to control the reduction and reuse of tokens respectively, resulting in more efficient token utilization. To improve the estimates of token-distributions, we propose a smoothing mechanism that acts as a regularizer and helps remove noisy outliers. Furthermore, to improve the training-stability of our proposed TPC, we introduce a model stabilizer that is able to implicitly encode local image structures and minimize accuracy fluctuations during model training. We conduct extensive experiments on the ImageNet-1K dataset using DeiT, LV-ViT, and Swin models to demonstrate the effectiveness of the proposed method.
For example, compared to baseline models, our proposed method improves the efficiency of the DeiT-S model by 21.7%percent21.721.7\%21.7 % (FLOPs) while increasing the classification accuracy by 0.4%percent0.40.4\%0.4 %.",[''],[]
"A recently-established necessary condition for polynomials that preserve the class of entrywise nonnegative matrices of a fixed order is shown to be necessary and sufficient for the class of nonnegative monomial matrices. Along the way, we provide a formula for computing an arbitrary power of a monomial matrix and a formula for computing the polynomial of a nonnegative monomial matrix.",[''],[]
"Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. 
Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. 
Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers. 
Results: Our models based on CNN architecture achieve precision ranging from 0.71 to 0.82. The trained model for automatic code content highlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming the trained models for other formatting styles. The BERT models have even lower recalls and F1 scores than the CNN models. Our analysis of failure cases indicates that the majority of the failure cases are missing identification (i.e., the model misses the content that is supposed to be highlighted) due to the models tend to learn the frequently highlighted words while struggling to learn less frequent words.
Conclusion: Our findings suggest that it is possible to develop recommendation models for highlighting information for answers with different formatting styles on Stack Overflow.",[''],[]
"Speaker representation learning is critical for modern voice recognition systems. While supervised learning techniques require extensive labeled data, unsupervised methodologies can leverage vast unlabeled corpora, offering a scalable solution. This paper introduces self-supervised reflective learning (SSRL), a novel paradigm that streamlines existing iterative unsupervised frameworks. SSRL integrates self-supervised knowledge distillation with online clustering to refine pseudo labels and train the model without iterative bottlenecks.
Specifically, a teacher model continually refines pseudo labels through online clustering, providing dynamic supervision signals to train the student model. The student model undergoes noisy student training with input and model noise to boost its modeling capacity. The teacher model is updated via an exponential moving average of the student, acting as an ensemble of past iterations. Further, a pseudo label queue retains historical labels for consistency, and noisy label modeling directs learning towards clean samples.
Experiments on VoxCeleb show SSRL’s superiority over current iterative approaches, surpassing the performance of a 5-round method in just a single training round. Ablation studies validate the contributions of key components like noisy label modeling and pseudo label queues. Moreover, consistent improvements in pseudo labeling and the convergence of cluster counts demonstrate SSRL’s effectiveness in deciphering unlabeled data. This work marks an important advancement in efficient and accurate speaker representation learning through the novel reflective learning paradigm.","['Index', 'Terms: \n', 'Self-supervised learning, self-labeling, knowledge distillation, noisy label modeling, speaker recognition']",[]
"We present our general-purpose mobile manipulation system consisting of a custom robot platform and key algorithms spanning perception and planning.
To extensively test the system in the wild and benchmark its performance, we choose a grocery shopping scenario in an actual, unmodified grocery store.
We derive key performance metrics from detailed robot log data collected during six week-long field tests, spread across 18 months.
These objective metrics, gained from complex yet repeatable tests, drive the direction of our research efforts and let us continuously improve our system’s performance.
We find that thorough end-to-end system-level testing of a complex mobile manipulation system can serve as a reality-check for state-of-the-art methods in robotics.
This effectively grounds robotics research efforts in real world needs and challenges, which we deem highly useful for the advancement of the field.
To this end, we share our key insights and takeaways to inspire and accelerate similar system-level research projects.",[''],['firstname.lastname@tri.global']
"We consider a Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT semiflow {φt}t≥0subscriptsubscript𝜑𝑡𝑡0\{\varphi_{t}\}_{t\geq 0}{ italic_φ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t ≥ 0 end_POSTSUBSCRIPT on a Banach space X𝑋Xitalic_X admitting a stable fixed point x𝑥xitalic_x.
We show, along the lines of the parameterization method [CFdlL03a], the existence of a Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT invariant foliation tangent to X1subscript𝑋1X_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at x𝑥xitalic_x, for an arbitrary D⁢φt⁢(x)𝐷subscript𝜑𝑡𝑥D\varphi_{t}(x)italic_D italic_φ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x )-invariant subspace X1⊂Xsubscript𝑋1𝑋X_{1}\subset Xitalic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊂ italic_X satisfying some additional spectral conditions.
Uniqueness ensues in a subclass of sufficiently smooth invariant foliations tangent to X1subscript𝑋1X_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at x𝑥xitalic_x.
We then draw relations to Koopman theory, and thereby establish the existence and uniqueness, in some appropriate sense, of Crsuperscript𝐶𝑟C^{r}italic_C start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT Koopman eigenfunctions.
We demonstrate that these results apply to the case of the Navier-Stokes system, the archetypal example considered by the modern upheaval of applied ’Koopmanism’.",[''],[]
,[''],[]
"We report the observations of two self-lensing pulses from KIC 12254688 in Transiting Exoplanet Survey Satellite (TESS) light curves. This system, containing a F2V star and white-dwarf companion, was amongst the first self-lensing binary systems discovered by the Kepler Space Telescope over the past decade. Each observed pulse occurs when the white dwarf transits in front of its companion star, gravitationally lensing the star’s surface, thus making it appear brighter to a distant observer. These two pulses are the very first self-lensing events discovered in TESS observations. We describe the methods by which the data were acquired and detrended, as well as the best-fit binary parameters deduced from our self-lensing+radial velocity model. We highlight the difficulties of finding new self-lensing systems with TESS, and we discuss the types of self-lensing systems that TESS may be more likely to discover in the future.","['Compact binary stars (283),', 'Gravitational microlensing (672),', 'White', 'Dwarf', 'Stars (1799)']","['01854', '01854', '01854', '01854', '01854', '01854', '01854']"
"We address the choice of penalty parameter in the Smoothness-Penalized Deconvolution (SPeD) method of estimating a probability density under additive measurement error.
Cross-validation gives an unbiased estimate of the risk (for the present sample size n𝑛nitalic_n) with a given penalty parameter, and this function can be minimized as a function of the penalty parameter.
Least-squares cross-validation, which has been proposed for the similar Deconvoluting Kernel Density Estimator (DKDE), performs quite poorly for SPeD.
We instead estimate the risk function for a smaller sample size n1<nsubscript𝑛1𝑛n_{1}<nitalic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_n with a given penalty parameter, using this to choose the penalty parameter for sample size n1subscript𝑛1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and then use the asymptotics of the optimal penalty parameter to choose for sample size n𝑛nitalic_n.
In a simulation study, we find that this has dramatically better performance than cross-validation, is an improvement over a SURE-type method previously proposed for this estimator, and compares favorably to the classic DKDE with its recommended plug-in method.
We prove that the maximum error in estimating the risk function is of smaller order than its optimal rate of convergence.",[''],[]
"Time series forecasting task predicts future trends based on historical information. Recent U-Net-based methods have demonstrated superior performance in predicting real-world datasets. However, the performance of these models is lower than patch-based models or linear models. In this work, we propose a symmetric and hierarchical framework, Kernel-U-Net, which cuts the input sequence into slices at each layer of the network and then computes them using kernels. Furthermore, it generalizes the concept of convolutional kernels in classic U-Net to accept custom kernels that follow the same design pattern. Compared to the existing linear or transformer-based solution, our model contains 3 advantages: 1) A small number of parameters: the parameters size is O⁢(l⁢o⁢g⁢(L)2)𝑂𝑙𝑜𝑔superscript𝐿2O(log(L)^{2})italic_O ( italic_l italic_o italic_g ( italic_L ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) where L𝐿Litalic_L is the look-back window size, 2) Flexibility: its kernels can be customized and fitted to the datasets, 3) Computation efficiency: the computation complexity of transformer modules is reduced to O⁢(l⁢o⁢g⁢(L)2)𝑂𝑙𝑜𝑔superscript𝐿2O(log(L)^{2})italic_O ( italic_l italic_o italic_g ( italic_L ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) if they are placed close to the latent vector. Kernel-U-Net accuracy was greater than or equal to the state-of-the-art model on six (out of seven) real-world datasets.",[''],[]
,[''],[]
"One of the most critical applications undertaken by coalitions of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) is reaching predefined targets by following the most time-efficient routes while avoiding collisions. Unfortunately, UAVs are hampered by limited battery life, and UGVs face challenges in reachability due to obstacles and elevation variations. Existing literature primarily focuses on one-to-one coalitions, which constrains the efficiency of reaching targets. In this work, we introduce a novel approach for a UAV-UGV coalition with a variable number of vehicles, employing a modified mean-shift clustering algorithm to segment targets into multiple zones. Each vehicle utilizes Multi-agent Deep Deterministic Policy Gradient (MADDPG) and Multi-agent Proximal Policy Optimization (MAPPO) — two advanced reinforcement learning algorithms — to form an effective coalition for navigating obstructed environments without collisions. This approach of assigning targets to various circular zones, based on density and range, significantly reduces the time required to reach these targets. Moreover, introducing variability in the number of UAVs and UGVs in a coalition enhances task efficiency by enabling simultaneous multi-target engagement. The results of our experimental evaluation demonstrate that our proposed method substantially surpasses current state-of-the-art techniques, nearly doubling efficiency in terms of target navigation time and task completion rate.",[''],[]
"Existing object recognition models have been shown to lack robustness in diverse geographical scenarios due to significant domain shifts in design and context. Class representations need to be adapted to more accurately reflect an object concept under these shifts. In the absence of training data from target geographies, we hypothesize that geography-specific descriptive knowledge of object categories can be leveraged to enhance robustness. For this purpose, we explore the feasibility of probing a large-language model for geography-specific object knowledge, and we investigate integrating knowledge in zero-shot and learnable soft prompting with the CLIP vision-language model. In particular, we propose a geography knowledge regularization method to ensure that soft prompts trained on a source set of geographies generalize to an unseen target set of geographies. Our gains on DollarStreet when generalizing from a model trained only on data from Europe are as large as +2.8 on countries from Africa, and +4.6 on the hardest classes. We further show
competitive performance vs. few-shot target training, and provide insights into how descriptive knowledge captures geographical differences.",[''],[]
,[''],[]
"The Evidential Regression Network (ERN) represents a novel approach that integrates deep learning with Dempster-Shafer’s theory to predict a target and quantify the associated uncertainty. Guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. This paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. Initially, we define the region where the models can’t effectively learn from the samples. Following this, we thoroughly analyze the ERN and investigate this constraint. Leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ERN to learn from the whole training set. Our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.",[''],[]
"First-order phase transitions produce abrupt changes to the character of both ground and excited electronic states. Here we conduct electronic compressibility measurements to map the spin phase diagram and Landau level (LL) energies of monolayer WSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT in a magnetic field. We resolve a sequence of first-order phase transitions between completely spin-polarized LLs and states with LLs of both spins. Unexpectedly, the LL gaps are roughly constant over a wide range of magnetic fields below the transitions, which we show reflects a preference for opposite spin excitations of the spin-polarized ground state. These transitions also extend into compressible regimes, with a sawtooth boundary between full and partial spin polarization. We link these observations to the important influence of LL filling on the exchange energy beyond a smooth density-dependent contribution. Our results show that WSe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT realizes a unique hierarchy of energy scales where such effects induce re-entrant magnetic phase transitions tuned by density and magnetic field.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Japan', 'Japan', 'USA', 'USA', 'USA', 'USA', 'USA']"
"In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data.",[''],[]
"PSR J1012+5307 is a millisecond pulsar with an extremely low-mass (ELM) white dwarf (WD) companion in an orbit of 14.5 hours. Magnetic braking (MB) plays an important role in influencing the orbital evolution of binary systems with a low-mass (<1−2⁢M⊙absent12subscript𝑀direct-product<1-2~{}M_{\odot}< 1 - 2 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) donor star. At present, there exist several different MB descriptions. In this paper, we investigate the formation of PSR J1012+5307 as a probe to test the plausible MB model. Employing a detailed stellar evolution model by the MESA code, we find that the Convection And Rotation Boosted MB and the ’Intermediate’ MB models can reproduce the WD mass, WD radius, WD surface gravity, neutron-star mass, and orbital period observed in PSR J1012+5307. However, our simulated WD has higher effective temperature than the observation. Other three MB mechanisms including the standard MB model are too weak to account for the observed orbital period in a Hubble time. A long cooling timescale caused by H-shell flashes of the WD may alleviate the discrepancy between the simulated effective temperature and the observed value.","['Stars: evolution:', 'Magnetic braking –', 'Stars:', 'White dwarfs –Binaries: general –', 'Pulsars:', 'PSR', 'J1012+5307']","['chenwc@pku.edu.cn', 'chenwc@pku.edu.cn', 'China', 'chenwc@pku.edu.cn', 'China', 'chenwc@pku.edu.cn', 'China']"
,[''],[]
,[''],[]
"We show that a complete, two-sided, stable minimal hypersurface in 𝐑5superscript𝐑5\mathbf{R}^{5}bold_R start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT is flat.",[''],[]
"Remote Sensing Target Fine-grained Classification (TFGC) is of great significance in both military and civilian fields. Due to location differences, growth in data size, and centralized server storage constraints, these data are usually stored under different databases across regions/countries. However, privacy laws and national security concerns constrain researchers from accessing these sensitive remote sensing images for further analysis. Additionally, low-resource remote sensing devices encounter challenges in terms of communication overhead and efficiency when dealing with the ever-increasing data and model scales. To solve the above challenges, this paper proposes a novel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed PRFL. The proposed framework allows each client to learn global and local knowledge to enhance the local representation of private data in environments with extreme statistical heterogeneity (non. Independent and Identically Distributed, IID). Thus, it provides highly customized models to clients with differentiated data distributions. Moreover, the framework minimizes communication overhead and improves efficiency while ensuring satisfactory performance, thereby enhancing robustness and practical applicability under resource-scarce conditions. We demonstrate the effectiveness of the proposed PRFL on the classical TFGC task by leveraging four public datasets.",[''],[]
"We show that small perturbations of the spatially homogeneous equilibrium of a thermally driven compressible viscous fluid are globally stable. Specifically, any weak solution of the evolutionary Navier–Stokes–Fourier system driven by thermal convection converges to an equilibrium as time goes to infinity. The main difficulty to overcome is the fact the problem does not admit any obvious Lyapunov function. The result applies, in particular, to the Rayleigh–Bénard convection problem.",[''],[]
"In terms of human-computer interaction, it is becoming more and more important to correctly understand the user’s emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This staged classification method can help the model to better focus on different levels of emotional information, thereby improving the performance of the model. Extensive experiments show that TS-GCL has superior performance on IEMOCAP and MELD datasets compared with previous methods.","['Index', 'Terms: \ngraph contrastive learning, graph convolutional network, multimodal emotion recognition, two-stage classification']","['aiwei@hnu.edu.cn', 'fuchen.zhang@csuft.edu.cn', 'mengtao@hnu.edu.cn', 'yuntaoshou@csuft.edu.cn', 'hongen.shao@csuft.edu.cn', 'lik@newpaltz.edu']"
"Thyroid cancer is the most common endocrine malignancy, and accurately distinguishing between benign and malignant thyroid tumors is crucial for developing effective treatment plans in clinical practice. Pathologically, thyroid tumors pose diagnostic challenges due to improper specimen sampling. In this study, we have designed a three-stage model using representation learning to integrate pixel-level and slice-level annotations for distinguishing thyroid tumors. This structure includes a pathology structure recognition method to predict structures related to thyroid tumors, an encoder-decoder network to extract pixel-level annotation information by learning the feature representations of image blocks, and an attention-based learning mechanism for the final classification task. This mechanism learns the importance of different image blocks in a pathological region, globally considering the information from each block. In the third stage, all information from the image blocks in a region is aggregated using attention mechanisms, followed by classification to determine the category of the region. Experimental results demonstrate that our proposed method can predict microscopic structures more accurately. After color-coding, the method achieves results on unstained pathology slides that approximate the quality of Hematoxylin and eosin staining, reducing the need for stained pathology slides. Furthermore, by leveraging the concept of indirect measurement and extracting polarized features from structures correlated with lesions, the proposed method can also classify samples where membrane structures cannot be obtained through sampling, providing a potential objective and highly accurate indirect diagnostic technique for thyroid tumors.",[''],[]
"Sequential recommenders are crucial to the success of online applications, e.g., e-commerce, video streaming, and social media. While model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. On the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. Inspired by the success of pre-trained models in peer AI fields, we propose a novel pre-trained sequential recommendation framework: PrepRec. We learn universal item representations by modeling item popularity dynamics. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. In addition, with a simple post-hoc interpolation, PrepRec can improve the performance of existing sequential recommenders on average by 13.8% in Recall@10 and 29.5% in NDCG@10. We provide an anonymized implementation of PrepRec at https://anonymous.4open.science/r/PrepRec--2F60/.","['Recommender', 'System,', 'Neural', 'Collaborative', 'Filtering,', 'Sequential', 'Recommendation,', 'Zero-shot', 'Sequential', 'Recommendation']","['AveUrbanaIllinois61801', 'AveUrbanaIllinois61801', 'AveUrbanaIllinois61801']"
"We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. We also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in TTS frameworks.","['Index', 'Terms: \nspeech synthesis, neural transducer, zero-shot adaptive', 'TTS, speech representation.']",[]
"We consider MRL maps (Markov-Renyi-Lüroth), a class of interval maps with infinitely many branches that can have parabolic fixed points. We prove that for every MRL map T𝑇Titalic_T, the Lyapunov spectrum can be expressed in terms of the Legendre transform of the topological pressure of −t⁢log⁡|T′|𝑡superscript𝑇′-t\log|T^{\prime}|- italic_t roman_log | italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT |, generalizing previous results in the area. We also show that the Lyapunov spectrum coincides with a function directly related to the Newton-Raphson method applied to the topological pressure of −t⁢log⁡|T′|𝑡superscript𝑇′-t\log|T^{\prime}|- italic_t roman_log | italic_T start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT |.","['Key words and phrases:', 'Lyapunov spectrum, thermodynamic formalism,', 'Newton-Raphson method.']",[]
"We propose a method for estimating a log-concave density on ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT from samples, under the assumption that there exists an orthogonal transformation that makes the components of the random vector independent. While log-concave density estimation is hard both computationally and statistically, the independent components assumption alleviates both issues, while still maintaining a large non-parametric class. We prove that under mild conditions, at most 𝒪~⁢(ϵ−4)~𝒪superscriptitalic-ϵ4\tilde{\mathcal{O}}(\epsilon^{-4})over~ start_ARG caligraphic_O end_ARG ( italic_ϵ start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT ) samples (suppressing constants and log factors) suffice for our proposed estimator to be within ϵitalic-ϵ\epsilonitalic_ϵ of the original density in squared Hellinger distance. On the computational front, while the usual log-concave maximum likelihood estimate can be obtained via a finite-dimensional convex program, it is slow to compute – especially in higher dimensions. We demonstrate through numerical experiments that our estimator can be computed efficiently, making it more practical to use.",[''],"['Columbia', 'Columbia', 'Columbia']"
"Real-time safety metrics are important for the automated driving system (ADS) to assess the risk of driving situations and to assist the decision-making. Although a number of real-time safety metrics have been proposed in the literature, systematic performance evaluation of these safety metrics has been lacking. As different behavioral assumptions are adopted in different safety metrics, it is difficult to compare the safety metrics and evaluate their performance. To overcome this challenge, in this study, we propose an evaluation framework utilizing logged vehicle trajectory data, in that vehicle trajectories for both subject vehicle (SV) and background vehicles (BVs) are obtained and the prediction errors caused by behavioral assumptions can be eliminated. Specifically, we examine whether the SV is in a collision unavoidable situation at each moment, given all near-future trajectories of BVs. In this way, we level the ground for a fair comparison of different safety metrics, as a good safety metric should always alarm in advance to the collision unavoidable moment. When trajectory data from a large number of trips are available, we can systematically evaluate and compare different metrics’ statistical performance. In the case study, three representative real-time safety metrics, including the time-to-collision (TTC) [1], the PEGASUS Criticality Metric (PCM) [2] and the Model Predictive Instantaneous Safety Metric (MPrISM) [3], are evaluated using a large-scale simulated trajectory dataset. The results demonstrate that the MPrISM achieves the highest recall and the PCM has the best accuracy. The proposed evaluation framework is important for researchers, practitioners, and regulators to characterize different metrics, and to select appropriate metrics for different applications. Moreover, by conducting failure analysis on moments when a safety metric failed, we can identify its potential weaknesses which are valuable for its potential refinements and improvements.","['Index', 'Terms: ', 'Safety metric, autonomous vehicle, logged trajectory data,']",[]
"The values of two-player general-sum differential games are viscosity solutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy approximations for such games suffer from the curse of dimensionality (CoD). Alleviating CoD through physics-informed neural networks (PINN) encounters convergence issues when value discontinuity is present due to state constraints. On top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. To address these challenges, we propose in this paper a Pontryagin-mode neural operator that outperforms existing state-of-the-art (SOTA) on safety performance across games with parametric state constraints. Our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. We show that the discontinuity of costate dynamics (in the presence of state constraints) effectively enables the learning of discontinuous values, without requiring manually supervised data as suggested by the current SOTA. More importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance.",[''],[]
"Specific emitter identification (SEI) technology is significant in device administration scenarios, such as self-organized networking and spectrum management, owing to its high security.
For nonlinear and non-stationary electromagnetic signals, SEI often employs variational modal decomposition (VMD) to decompose the signal in order to effectively characterize the distinct device fingerprint.
However, the trade-off of VMD between the robustness to noise and the ability to preserve signal information has not been investigated in the current literature.
Moreover, the existing VMD algorithm does not utilize the stability of the intrinsic distortion of emitters within a certain
temporal span, consequently constraining its practical applicability in SEI.
In this paper, we propose a joint variational modal decomposition (JVMD) algorithm, which is an improved version of VMD by simultaneously implementing modal decomposition on multi-frame signals.
The consistency of multi-frame signals in terms of the central frequencies and the inherent modal functions (IMFs) is exploited, which effectively highlights the distinctive characteristics among emitters and reduces noise.
Additionally, the complexity of JVMD is analyzed, which is proven to be more computational-friendly than VMD.
Simulations of both modal decomposition and SEI that involve real-world datasets are presented to illustrate that when compared with VMD, the JVMD algorithm improves the accuracy of device classification and the robustness towards noise.","['Index', 'Terms: ', 'Intrinsic modal functions (IMFs), radio frequency fingerprints (RFFs), specific emitter identification (SEI), variational mode decomposition (VMD)']",['yhuang24@kennesaw.edu']
"The use of sub-Terahertz (sub-THz) band is gaining considerable attention in 6G networks. In this study, we introduce hardware and propagation integrated 3D Propagation Model to describe sub-THz channels and discuss its advantages over both deterministic and stochastic 6G channel models. The undiscovered mutuality of localization and communication is presented and its potential in integrated sensing and communication (ISAC) applications is highlighted. Afterward, a real-time sub-THz localization experiment is conducted to show the impact of the mispositioned and misaligned narrow beams on service quality. In continuation, we highlight the most current challenges and developments in THz localization and explore the potential of sub-THz frequencies to efficiently utilize the ultra-wideband spectrum. In the end, the open issues that need to be overcome to provide high spatial resolution and millidegree-level angle of arrival estimation in ISAC applications have been explored.",[''],[]
"Reasoning over sports videos for question answering is an important task with numerous applications, such as player training and information retrieval. However, this task has not been explored due to the lack of relevant datasets and the challenging nature it presents. Most datasets for video question answering (VideoQA) focus mainly on general and coarse-grained understanding of daily-life videos, which is not applicable to sports scenarios requiring professional action understanding and fine-grained motion analysis. In this paper, we introduce the first dataset, named Sports-QA, specifically designed for the sports VideoQA task. The Sports-QA dataset includes various types of questions, such as descriptions, chronologies, causalities, and counterfactual conditions, covering multiple sports. Furthermore, to address the characteristics of the sports VideoQA task, we propose a new Auto-Focus Transformer (AFT) capable of automatically focusing on particular scales of temporal information for question answering.
We conduct extensive experiments on Sports-QA, including baseline studies and the evaluation of different methods. The results demonstrate that our AFT achieves state-of-the-art performance111The data and codes will be released..",[''],[]
,[''],[]
,[''],[]
"Natural Language Processing (NLP) is now a cornerstone of requirements automation. One compelling factor behind the growing adoption of NLP in Requirements Engineering (RE) is the prevalent use of natural language (NL) for specifying requirements in industry. NLP techniques are commonly used for automatically classifying requirements, extracting important information, e.g., domain models and glossary terms, and performing quality assurance tasks, such as ambiguity handling and completeness checking. With so many different NLP solution strategies available and the possibility of applying machine learning alongside, it can be challenging to choose the right strategy for a specific RE task and to evaluate the resulting solution in an empirically rigorous manner. This book chapter presents guidelines for the selection of NLP techniques as well as for their evaluation in the context of RE. In particular, we discuss how to choose among different strategies such as traditional NLP, feature-based machine learning, and language-model-based methods. Our ultimate hope for this chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in quickly initiating themselves into the NLP technologies most pertinent to the RE field.",[''],"['[', '[']"
"This article is concerned with the rigorous connections between the inertial Qian–Sheng model and the Ericksen–Leslie model for the liquid crystal flow, under a more general condition of coefficients. More specifically, in the framework of Hilbert expansions, we show that: (i) when the elastic coefficients tend to zero (also called the uniaxial limit), the smooth solution to the inertial Qian–Sheng model converges to that to the full inertial Ericksen–Leslie model; (ii) when the elastic coefficients and the inertial coefficient tend to zero simultaneously, the smooth solution to the inertial Qian–Sheng model converges to that to the noninertial Ericksen–Leslie model.
Keywords. Liquid crystals, Ericksen–Leslie model, Qian–Sheng model, Q𝑄Qitalic_Q-tensor theory
AMS subject classifications. Primary, 35Q35; Secondary, 35Q30, 76D05",[''],[]
"While significant advancements have been made in video question answering (VideoQA), the potential benefits of enhancing model generalization through tailored difficulty scheduling have been largely overlooked in existing research. This paper seeks to bridge that gap by incorporating VideoQA into a curriculum learning (CL) framework that progressively trains models from simpler to more complex data. Recognizing that conventional self-paced CL methods rely on training loss for difficulty measurement, which might not accurately reflect the intricacies of video-question pairs, we introduce the concept of uncertainty-aware CL. Here, uncertainty serves as the guiding principle for dynamically adjusting the difficulty. Furthermore, we address the challenge posed by uncertainty by presenting a probabilistic modeling approach for VideoQA. Specifically, we conceptualize VideoQA as a stochastic computation graph, where the hidden representations are treated as stochastic variables. This yields two distinct types of uncertainty: one related to the inherent uncertainty in the data and another pertaining to the model’s confidence. In practice, we seamlessly integrate the VideoQA model into our framework and conduct comprehensive experiments. The findings affirm that our approach not only achieves enhanced performance but also effectively quantifies uncertainty in the context of VideoQA.","['Index', 'Terms: ', 'Video question answering, curriculum learning, uncertainty, stochastic computation graph.']",[]
"The advent of Large Language Models has revolutionized information retrieval, ushering in a new era of expansive knowledge accessibility. While these models excel in providing open-world knowledge, effectively extracting answers in diverse linguistic environments with varying levels of literacy remains a formidable challenge. Retrieval Augmented Generation (RAG) emerges as a promising solution, bridging the gap between information availability and multilingual comprehension. However, deploying RAG models in real-world scenarios demands careful consideration of various factors.
This paper addresses the critical challenges associated with implementing RAG models in multicultural environments. We delve into essential considerations, including data feeding strategies, timely updates, mitigation of hallucinations, prevention of erroneous responses, and optimization of delivery speed. Our work involves the integration of a diverse array of tools, meticulously combined to facilitate the seamless adoption of RAG models across languages and literacy levels within a multicultural organizational context. Through strategic tweaks in our approaches, we achieve not only effectiveness but also efficiency, ensuring the accelerated and accurate delivery of information in a manner that is tailored to the unique requirements of multilingual and multicultural settings",[''],[]
"This paper discusses the limitations of evaluating Masked Language Models (MLMs) in code completion tasks. We highlight that relying on accuracy-based measurements may lead to an overestimation of models’ capabilities by neglecting the syntax rules of programming languages. To address these issues, we introduce a technique called SyntaxEval in which Syntactic Capabilities are used to enhance the evaluation of MLMs. SyntaxEval automates the process of masking elements in the model input based on their  Syntax Trees (ASTs). We conducted a case study on two popular MLMs using data from GitHub repositories. Our results showed negative causal effects between the node types and MLMs’ accuracy. We conclude that MLMs under study fail to predict some syntactic capabilities.","['deep learning, code generation, interpretability, transformers']",['MaryWilliamsburgVirginiaUSA']
"When ultrasonic wave is irradiated on materials, a small static stress is required to get materials yielding and flowing. This is called acoustic softening effect, also known as Blaha effect for a long time. In the past, this effect was explained by several continuum scale or meso-scale solid mechanics theories such as stress superposition or energy superposition theory, or crystal/dislocation plasticity. Due to a lot of microscopic complexities happening inside the materials during ultrasonic vibration, fully understanding of acoustic softening effect is not easy. In this paper, traditional solid mechanics theory is expanded by introducing several concepts in semi-conductor physics. Four new aspects were introduced to understand acoustic softening effect. Firstly, contrary to most existed work in acoustic softening research area which treats ultrasound as waves, it was treated as particles. Secondly, crystal/dislocation plastic theory was simplified to a single equation. Thirdly, concepts of photoelectric effect or photo-voltaic effect were introduced. Analogy of electron movement due to light wave and defect movement due to ultrasonic wave was illustrated. Particularly, as light wave is treated as photon, ultrasonic wave is treated as phonon in this paper. Fourthly, defects such as point defects or line defects are assumed to have certain bonding energy. Their bonding energies are assumed to be quantized or discontinuous. The band gap theory used in photo-voltaic theory is embraced to understand defects movements in solid mechanics due to ultrasonic phonon.
Keywords: Wave-Particle Duality; Ultrasonic Wave; Acoustic Softening, Photoelectric Effect; Photo-voltaic Effect",[''],[]
The hot spots conjecture of J. Rauch states that the second Neumann eigenfunction of the Laplace operator on a bounded Lipschitz domain in ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT attains its extrema only on the boundary of the domain. We present an analogous problem for domains with mixed Dirichlet-Neumann boundary conditions. We then solve this problem for Euclidean triangles and a class of planar domains bounded by the graphs of certain piecewise smooth functions.,[''],[]
"Linear RMS-flux relation has been well established in different spectral states of all accreting systems. In this work, we study the evolution of the frequency-dependent RMS-flux relation of MAXI J1820+070 during the initial decaying phase of the 2018 outburst with Insight-HXMT over a broad energy range 1–150 keV.
As the flux decreases, we first observe a linear RMS-flux relation at frequencies from 2 mHz to 10 Hz, while such a relation breaks at varying times for different energies, leading to a substantial reduction in the slope.
Moreover, we find that the low-frequency variability exhibits the highest sensitivity to the break, which occurs prior to the hard-to-hard state transition time determined through time-averaged spectroscopy, and the time deviation increases with energy. The overall evolution of the RMS-flux slope and intercept suggests the presence of a two-component Comptonization system. One component is radially extended, explaining the strong disk-corona coupling before the break, while the other component extends vertically, contributing to the reduction of the disk-corona coupling after the break. A further vertical expansion of the latter component is required to accommodate the dynamic evolution observed in the RMS-flux slope.
In conclusion, we suggest that the RMS-flux slope in 1–150 keV band can be employed as an indicator of the disk-corona coupling and the hard-to-hard state transition in MAXI J1820+070 could be partially driven by the changes in the corona geometry.","['accretion (14) – black holes (162) –', 'High energy astrophysics(739)']","['China', 'wangyn@bao.ac.cn', 'China', 'China']"
"We study the efficiency of fair allocations using the well-studied price of fairness concept, which quantitatively measures the worst-case efficiency loss when imposing fairness constraints.
Previous works provided partial results on the price of fairness with well-known fairness notions such as envy-freeness up to one good (EF1) and envy-freeness up to any good (EFX).
In this paper, we give a complete characterization for the price of envy-freeness in various settings.
In particular, we first consider the two-agent case under the indivisible-goods setting and present tight ratios for the price of EF1 (for scaled utility) and EFX (for unscaled utility), which resolve questions left open in the literature.
Next, we consider the mixed goods setting which concerns a mixture of both divisible and indivisible goods.
We focus on envy-freeness for mixed goods (EFM), which generalizes both envy-freeness and EF1, as well as its strengthening called envy-freeness up to any good for mixed goods (EFXM), which generalizes envy-freeness and EFX.
To this end, we settle the price of EFM and EFXM by providing a complete picture of tight bounds for two agents and asymptotically tight bounds for n𝑛nitalic_n agents, for both scaled and unscaled utilities.",[''],"['zihao004@e.ntu.edu.sg', 'sxliu@hit.edu.cn', 'xinhang.lu@unsw.edu.au', 'bstao@sjtu.edu.cn', 'ychtao@umich.edu']"
"To gain a better understanding of the Andromeda galaxy M31 and its role in the Local Group, measuring its mass precisely is essential. In this work, we have constructed the rotation curve of M31 out to ∼similar-to\sim∼125 kpc using 13,679 M31 objects obtained from various sources, including the LAMOST data release 9 (LAMOST DR9), the DESI survey, and relevant literature. We divide all objects in our sample into bulge, disk and halo components. For the sources in the M31 disk, we have measured their circular velocities by a kinematic model with asymmetric drift corrections. For the bulge and halo objects, we calculate their velocity dispersions and use the spherical and projected Jeans equation to obtain the circular velocities. Our findings indicate a nearly isotropic nature for the M31 bulge, while the halo exhibits tangential anisotropy. The results show that the rotation curve remains constant at ∼similar-to\sim∼220 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT up to radius ∼similar-to\sim∼25 kpc and gradually decreases to ∼similar-to\sim∼170 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT further out. Based on the newly determined rotation curve, we have constructed a mass distribution model for M31. Our measurement of the M31 virial mass is Mvir=1.14−0.35+0.51×1012⁢M⊙subscript𝑀virsubscriptsuperscript1.140.510.35superscript1012subscript𝑀direct-productM_{\rm vir}=1.14^{+0.51}_{-0.35}\times 10^{12}M_{\odot}italic_M start_POSTSUBSCRIPT roman_vir end_POSTSUBSCRIPT = 1.14 start_POSTSUPERSCRIPT + 0.51 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.35 end_POSTSUBSCRIPT × 10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT within rvir=220±25subscript𝑟virplus-or-minus22025r_{\rm vir}=220\pm 25italic_r start_POSTSUBSCRIPT roman_vir end_POSTSUBSCRIPT = 220 ± 25 kpc.",[''],[]
"Optical quantum routers which play a crucial role in quantum networks, have been extensively studied in both theory and experiment, resulting in significant advancements in their performance. However, these routers impose stringent requirements for achieving optimal routing performance, where the incident photon frequency must be in strict resonance with one or several specific frequencies. To address this challenge, we have designed an efficient quantum router capable of stable output with 100% transfer rate over the entire energy band of coupled-resonator waveguide (CRW) by coupling a giant atom to two or more semi-infinite CRWs. We also explain and prove the fundamental physical mechanism behind this distinctive phenomenon as the result of destructive interference between two waves composing the final reflected wave. We hope that quantum router with output results unaffected by the energy of the incoming information carriers present a more reliable solution for the implementation of quantum networks.
Keywords: Quantum Router, Single-Photon Router, Single-Photon Transport, Semi-Infinite Coupled-Resonator Waveguides, Giant Atom",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
"Diffusion models have emerged as powerful generative tools, rivaling GANs in sample quality and mirroring the likelihood scores of autoregressive models. A subset of these models, exemplified by DDIMs, exhibit an inherent asymmetry: they are trained over T𝑇Titalic_T steps but only sample from a subset of
T𝑇Titalic_T during generation. This selective sampling approach, though optimized for speed, inadvertently misses out on vital information from the unsampled steps, leading to potential compromises in sample quality. To address this issue, we present the S22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-DMs, which is a new training method by using an innovative Ls⁢k⁢i⁢psubscript𝐿𝑠𝑘𝑖𝑝L_{skip}italic_L start_POSTSUBSCRIPT italic_s italic_k italic_i italic_p end_POSTSUBSCRIPT, meticulously designed to reintegrate the information omitted during the selective sampling phase. The benefits of this approach are manifold: it notably enhances sample quality, is exceptionally simple to implement, requires minimal code modifications, and is flexible enough to be compatible with various sampling algorithms. On the CIFAR10 dataset, models trained using our algorithm showed an improvement of 3.27% to 14.06% over models trained with traditional methods across various sampling algorithms (DDIMs, PNDMs, DEIS) and different numbers of sampling steps (10, 20, …, 1000). On the CELEBA dataset, the improvement ranged from 8.97% to 27.08%. Access to the code and additional resources is provided in the github.","['Machine', 'Learning,', 'ICML']",[]
"Quantum computing offers significant acceleration capabilities over its classical counterpart in various application domains. Consequently, there has been substantial focus on improving quantum computing capabilities. However, to date, the security implications of these quantum computing platforms have been largely overlooked. With the emergence of cloud-based quantum computing services, it is critical to investigate the extension of classical computer security threats to the realm of quantum computing.
In this study, we investigated timing-based side-channel vulnerabilities within IBM’s cloud-based quantum service.
The proposed attack effectively subverts the confidentiality of the executed quantum algorithm, using a more realistic threat model compared to existing approaches. Our experimental results, conducted using IBM’s quantum cloud service, demonstrate that with just 10 measurements, it is possible to identify the underlying quantum computer that executed the circuit. Moreover, when evaluated using the popular Grover circuit, we showcase the ability to leak the quantum oracle with a mere 500 measurements. These findings underline the pressing need to address timing-based vulnerabilities in quantum computing platforms and advocate for enhanced security measures to safeguard sensitive quantum algorithms and data.","['Index', 'Terms: ', 'Quantum computing, side-channel, security, cloud computing, timing side-channel']",['USA']
"Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes or learning to directly generate the corresponding markup sequences from the table images. However, existing approaches either count on additional heuristic rules to recover the table structures, or face challenges in capturing long-range dependencies within tables, resulting in increased complexity. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time regresses logical location as well as spatial location of table cells in a unified network. Our proposed LORE is conceptually simpler, easier to train, and more accurate than other paradigms of TSR. Moreover, inspired by the persuasive success of pre-trained models on a number of computer vision and natural language processing tasks, we propose two pre-training tasks to enrich the spatial and logical representations at the feature level of LORE, resulting in an upgraded version called LORE++. The incorporation of pre-training in LORE++ has proven to enjoy significant advantages, leading to a substantial enhancement in terms of accuracy, generalization, and few-shot capability compared to its predecessor. Experiments on standard benchmarks against methods of previous paradigms demonstrate the superiority of LORE++, which highlights the potential and promising prospect of the logical location regression paradigm for TSR.","['Index', 'Terms: ', 'Table structure recognition, pre-trained vision model, document understanding.']",[]
"The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at https://goatlmm.github.io/, contributing to ongoing research in this vital field.",[''],[]
"Multimodal deep learning utilizing imaging and diagnostic reports has made impressive progress in the field of medical imaging diagnostics, demonstrating a particularly strong capability for auxiliary diagnosis in cases where sufficient annotation information is lacking. Nonetheless, localizing diseases accurately without detailed positional annotations remains a challenge. Although existing methods have attempted to utilize local information to achieve fine-grained semantic alignment, their capability in extracting the fine-grained semantics of the comprehensive contextual within reports is limited. To solve this problem, we introduce a new method that takes full sentences from textual reports as the basic units for local semantic alignment. Our approach combines chest X-ray images with their corresponding textual reports, performing contrastive learning at both global and local levels. The leading results obtained by our method on multiple datasets confirm its efficacy in the task of lesion localization.",[''],[]
"FinTech platforms facilitated by digital payments are watching growth rapidly, which enable the distribution of mutual funds personalized to individual investors via mobile Apps. As the important intermediation of financial products investment, these platforms distribute thousands of mutual funds obtaining impressions under guaranteed delivery (GD) strategy required by fund companies. Driven by the profit from fund purchases of users, the platform aims to maximize each transaction amount of customers by promoting mutual funds to these investors who will be interested in. Different from the conversions in traditional advertising or e-commerce recommendations, the investment amount in each purchase varies greatly even for the same financial product, which provides a significant challenge for the promotion recommendation of mutual funds. In addition to predicting the click-through rate (CTR) or the conversion rate (CVR) as in traditional recommendations, it is essential for FinTech platforms to estimate the customers’ purchase amount for each delivered fund and achieve an effective allocation of impressions based on the predicted results to optimize the total expected transaction value (ETV). In this paper, we propose an ETV-optimized customer allocation framework (EOCA) that aims to maximize the total ETV of recommended funds, under the constraints of GD dealt with fund companies. EOCA consists of two phases: a prediction phase of the customer purchase amount followed by a constrained allocation phase. Specifically, we propose an entire space deep probabilistic model with a novel-designed loss function to predict the purchase amount when a promotional fund is exposed to a user, which involves not only the conversion rate prediction but also the post-conversion purchase amount estimation. Based on the predicted ETV, we design a heuristic algorithm to solve the large-scale constrained combinatorial optimization problem to suggest which fund each user should be exposed to in order to maximize the total purchase amount. To the best of our knowledge, it’s the first attempt to solve the GD problem for financial product promotions based on customer purchase amount prediction. We conduct extensive experiments on large-scale real-world datasets and online tests based on LiCaiTong, Tencent’s wealth management platform, to demonstrate the effectiveness of our proposed EOCA framework.","['FinTech platform, customer allocation, purchase amount prediction']","['TencentShenzhenChina', 'FiT,TencentShenzhenChina', 'FiT,TencentShenzhenChina', '(SZ)ShenzhenChina', 'TencentShenzhenChina']"
"We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",[''],[]
"Modern recommender systems have seen substantial success, yet they remain vulnerable to malicious activities, notably poisoning attacks. These attacks involve injecting malicious data into the training datasets of RS, thereby compromising their integrity and manipulating recommendation outcomes for gaining illicit profits. This survey paper provides a systematic and up-to-date review of the research landscape on Poisoning Attacks against Recommendation (PAR). A novel and comprehensive taxonomy is proposed, categorizing existing PAR methodologies into three distinct categories: Component-Specific, Goal-Driven, and Capability Probing. For each category, we discuss its mechanism in detail, along with associated methods. Furthermore, this paper highlights potential future research avenues in this domain. Additionally, to facilitate and benchmark the empirical comparison of PAR, we introduce an open-source library, ARLib, which encompasses a comprehensive collection of PAR models and common datasets. The library is released at https://github.com/CoderWZW/ARLib.",[''],[]
"Two-sided matching markets have been widely studied in the literature due to their rich applications. Since participants are usually uncertain about their preferences, online algorithms have recently been adopted to learn them through iterative interactions. Wang et al. (2022) initiate the study of this problem in a many-to-one setting with responsiveness. However, their results are far from optimal and lack guarantees of incentive compatibility. An extension of Kong and Li (2023) to this more general setting achieves a near-optimal bound for player-optimal regret. Nevertheless, due to the substantial requirement for collaboration, a single player’s deviation could lead to a huge increase in its own cumulative rewards and an O⁢(T)𝑂𝑇O(T)italic_O ( italic_T ) regret for others. In this paper, we aim to enhance the regret bound in many-to-one markets while ensuring incentive compatibility. We first propose the adaptively explore-then-deferred-acceptance (AETDA) algorithm for responsiveness setting and derive an O⁢(N⁢min⁡{N,K}⁢C⁢log⁡T/Δ2)𝑂𝑁𝑁𝐾𝐶𝑇superscriptΔ2O(N\min\left\{N,K\right\}C\log T/\Delta^{2})italic_O ( italic_N roman_min { italic_N , italic_K } italic_C roman_log italic_T / roman_Δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) upper bound for player-optimal stable regret while demonstrating its guarantee of incentive compatibility, where N𝑁Nitalic_N represents the number of players, K𝐾Kitalic_K is the number of arms, T𝑇Titalic_T denotes the time horizon, C𝐶Citalic_C is arms’ total capacities and ΔΔ\Deltaroman_Δ signifies the minimum preference gap among players. This result is a significant improvement over Wang et al. (2022). And to the best of our knowledge, it constitutes the first player-optimal guarantee in matching markets that offers such robust assurances. We also consider broader substitutable preferences, one of the most general conditions to ensure the existence of a stable matching and cover responsiveness. We devise an online DA (ODA) algorithm and establish an O⁢(N⁢K⁢log⁡T/Δ2)𝑂𝑁𝐾𝑇superscriptΔ2O(NK\log T/\Delta^{2})italic_O ( italic_N italic_K roman_log italic_T / roman_Δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) player-pessimal stable regret bound for this setting. Compared with Wang et al. (2022), this algorithm not only achieves a better result but also applies to more general markets.",[''],[]
"Video Question Answering (VideoQA) has emerged as a vital tool to evaluate agents’ ability to understand human daily behaviors. Despite the recent success of large vision language models in many multi-modal tasks, complex situation reasoning over videos involving multiple human-object interaction events still remains challenging. In contrast, humans can easily tackle it by using a series of episode memories as anchors to quickly locate question-related key moments for reasoning. To mimic this effective reasoning strategy, we propose the Glance-Focus model. One simple way is to apply an action detection model to predict a set of actions as key memories. However, these actions within a closed set vocabulary are hard to generalize to various video domains. Instead of that, we train an Encoder-Decoder to generate a set of dynamic event memories at the glancing stage. Apart from using supervised bipartite matching to obtain the event memories, we further design an unsupervised memory generation method to get rid of dependence on event annotations. Next, at the focusing stage, these event memories act as a bridge to establish the correlation between the questions with high-level event concepts and low-level lengthy video content. Given the question, the model first focuses on the generated key event memory, then focuses on the most relevant moment for reasoning through our designed multi-level cross-attention mechanism. We conduct extensive experiments on four Multi-Event VideoQA benchmarks including STAR, EgoTaskQA, AGQA, and NExT-QA. Our proposed model achieves state-of-the-art results, surpassing current large models in various challenging reasoning tasks. The code and models are available at https://github.com/ByZ0e/Glance-Focus.",[''],[]
"Thouless pumping, a dynamical version of the integer quantum Hall effect, represents the quantized charge pumped during an adiabatic cyclic evolution. Here we report experimental observations of nontrivial topological pumping that is induced by disorder even during a topologically trivial pumping trajectory. With a 41-qubit superconducting quantum processor, we develop a Floquet engineering technique to realize cycles of adiabatic pumping by simultaneously varying the on-site potentials and the hopping couplings. We demonstrate Thouless pumping in the presence of disorder and show its breakdown as the strength of disorder increases. Moreover, we observe two types of topological pumping that are induced by on-site potential disorder and hopping disorder, respectively. Especially, an intrinsic topological pump that is induced by quasi-periodic hopping disorder has never been experimentally realized before. Our highly controllable system provides a valuable quantum simulating platform for studying various aspects of topological physics in the presence of disorder.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'Japan', 'Japan', 'USA', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"This paper explores opportunities and challenges of task (goal)-oriented and semantic communications for next-generation (NextG) communication networks through the integration of multi-task learning. This approach employs deep neural networks representing a dedicated encoder at the transmitter and multiple task-specific decoders at the receiver, collectively trained to handle diverse tasks including semantic information preservation, source input reconstruction, and integrated sensing and communications. To extend the applicability from point-to-point links to multi-receiver settings, we envision the deployment of decoders at various receivers, where decentralized learning addresses the challenges of communication load and privacy concerns, leveraging federated learning techniques that distribute model updates across decentralized nodes. However, the efficacy of this approach is contingent on the robustness of the employed deep learning models. We scrutinize potential vulnerabilities stemming from adversarial attacks during both training and testing phases. These attacks aim to manipulate both the inputs at the encoder at the transmitter and the signals received over the air on the receiver side, highlighting the importance of fortifying semantic communications against potential multi-domain exploits. Overall, the joint and robust design of task-oriented communications, semantic communications, and integrated sensing and communications in a multi-task learning framework emerges as the key enabler for context-aware, resource-efficient, and secure communications ultimately needed in NextG network systems.","['Index', 'Terms: ', 'Task-oriented communications, semantic communications, integrated sensing and communications, deep learning, multi-task learning, distributed learning, security.']","['USA', 'USA', 'USA', 'USA']"
"Zermelo navigation is not only a fundamental tool in Finsler geometry but also a fundamental approach to the geometrization of dynamics in physics. In this paper, we consider the Zermelo navigation problem on optical Riemannian space and, via Zermelo/Randers/spacetime triangle, explore the generation of new spacetimes from pre-existing ones. Whether the Randers metric has reversible geodesics corresponds to the presence of time-reversal symmetry in the generated spacetime. In cases where the Randers metric has reversible geodesics, we utilize a radial vector field to generate new static spacetimes from existing ones. For example, we can generate Schwarzschild, Rindler, de Sitter, and Schwarzschild-de Sitter spacetimes from flat spacetime. In fact, the Zermelo navigation method allows for the derivation of a variety of static spacetimes from flat spacetime. For multi-parameter spacetimes, they can be generated through various navigation paths. However, for some spacetimes, not all navigation paths may exist. In the second scenario, when the Randers metric does not have reversible geodesics, we employ a rotational vector field to transform non-flat static metrics into slowly rotating spacetimes. Alternatively, using a mixed vector field, we generate slowly rotating spacetimes starting from flat spacetime. We provide examples of generating Kerr spacetimes and Kerr-de Sitter spacetimes.",[''],"['China', 'China']"
"In this article, we introduce a notion of twisted set-theoretic Yang-Baxter solution, which is a triplet (X,f,R)𝑋𝑓𝑅(X,f,R)( italic_X , italic_f , italic_R ), where (X,R)𝑋𝑅(X,R)( italic_X , italic_R ) is a Yang-Baxter set and f:X→X:𝑓→𝑋𝑋f:X\to Xitalic_f : italic_X → italic_X is an automorphism of (X,R)𝑋𝑅(X,R)( italic_X , italic_R ). We present a cohomology theory for it, and use cocycles of twisted biquandles in amalgamation with Alexander numbering to construct state-sum invariant of knots and knotted surfaces. Additionally, we introduce a twisted version of cohomology theory for Yang-Baxter sets and give applications to knot theory.","['Key words and phrases:', 'Twisted', 'Yang-Baxter sets, cohomology, twisted biquandles, cocycle knot invariants']",[]
"The goal of this Article is to perform a systematic study the global entanglement and coherence length dynamics in a natural light-harvesting system Fenna-–Matthews–-Olson (FMO) complex across various parameters of a dissipative environment from low to high temperatures, weak to strong system-environment coupling, and non-Markovian environments. The non-perturbative numerically exact hierarchical equations of motions method is employed to generate the dynamics of the system. We found that entanglement is driven primarily by the strength of interaction between the system and environment, and it is modulated by the interplay between temperature and non-Markovianity. In contrast, coherence length is found not to be sensitive to non-Markovianity. Our results do not show the direct correlation between global entanglement and the efficiency of the excitation energy transfer.",[''],['States']
"This is the first paper in a series that studies
smooth relative Lie algebra homologies and cohomologies
based on the theory of formal manifolds and formal Lie groups.
In this paper, we lay the foundations for this study by introducing the notion of formal manifolds in the context of differential geometry, inspired by the notion of formal schemes in algebraic geometry.
We develop the basic theory for formal manifolds, including a generalization of the theory of vector-valued distributions and generalized functions on smooth manifolds to the setting of formal manifolds. Additionally, we establish Poincaré’s lemma for de Rham complexes with coefficients in formal functions, formal generalized functions, compactly supported formal densities, or compactly supported formal distributions.","['Key words and phrases: manifold, generalized function, de', 'Rham complex,', 'Poincaré’s lemma']",[]
"We establish a connection between the Alexander polynomial of a knot and its
twisted and L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-versions with the triangulations that appear in
3-dimensional hyperbolic geometry. Specifically, we introduce twisted
Neumann–Zagier matrices of ordered ideal triangulations and use them to provide
formulas for the Alexander polynomial and its variants, the twisted Alexander
polynomial and the L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-Alexander torsion.","['Key words and phrases:', 'Alexander polynomial, twisted', 'Alexander polynomial,', 'L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-Alexander torsion,', 'Neumann–Zagier matrices,\nordered ideal triangulation,', 'Mahler measure,', 'Fuglede-Kadison determinant']",[]
"The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while maintaining exceptional accuracy with non-poisoned datasets.",[''],[]
"Coherent small-amplitude unsteadiness of the shock wave and the separation region over a canonical double cone flow, termed in literature as oscillation-type unsteadiness, is experimentally studied at Mach 6. The double cone model is defined by three non-dimensional geometric parameters: fore- and aft-cone angles (θ1subscript𝜃1\theta_{1}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and θ2subscript𝜃2\theta_{2}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), and ratio of the conical slant lengths (ΛΛ\Lambdaroman_Λ). Previous studies of oscillations have been qualitative in nature, and mostly restricted to a special case of the cone model with fixed θ1=0∘subscript𝜃1superscript0\theta_{1}=0^{\circ}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT and θ2=90∘subscript𝜃2superscript90\theta_{2}=90^{\circ}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT (referred to as the spike-cylinder model), where ΛΛ\Lambdaroman_Λ becomes the sole governing parameter. In the present effort we investigate the self-sustained flow oscillations in the θ1subscript𝜃1\theta_{1}italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-ΛΛ\Lambdaroman_Λ parameter space for fixed θ2=90∘subscript𝜃2superscript90\theta_{2}=90^{\circ}italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT using time-resolved schlieren visualization. The experiments reveal two distinct sub-types of oscillations, characterized by the motion (or lack thereof) of the separation point on the fore-cone surface. The global time scale associated with flow oscillation is extracted using spectral proper orthogonal decomposition. The non-dimensional frequency (Strouhal number) of oscillation is seen to exhibit distinct scaling for the two oscillation sub-types. The relationship observed between the local flow properties, instability of the shear layer, and geometric constraints on the flow suggests that an aeroacoustic feedback mechanism sustains the oscillations. Based on this insight, a simple model with no empiricism is developed for the Strouhal number. The model predictions are found to match well with experimental measurements. The model provides helpful physical insight into the nature of the self-sustained flow oscillations over a double cone at high-speeds.",[''],['012']
,[''],[]
"We compare, with data from the quasars, the Hubble parameter measurements, and the Pantheon+ type Ia supernova, three different relations between X-ray luminosity (LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT) and ultraviolet luminosity (LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT) of quasars. These three relations consist of the standard and two redshift-evolutionary LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT-LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT relations which are constructed respectively by considering a redshift dependent correction to the luminosities of quasars and using the statistical tool called copula. By employing the PAge approximation for a cosmological-model-independent description of the cosmic background evolution and dividing the quasar data into the low-redshift and high-redshift parts, we find that the constraints on the PAge parameters from the low-redshift and high-redshift data, which are obtained with the redshift-evolutionary relations, are consistent with each other, while they are not when the standard relation is considered. If the data are used to constrain the coefficients of the relations and the PAge parameters simultaneously, then the observations support the redshift-evolutionary relations at more than 3⁢σ3𝜎3\sigma3 italic_σ. The Akaike and Bayes information criteria indicate that there is strong evidence against the standard relation and mild evidence against the redshift-evolutionary relation constructed by considering a redshift dependent correction to the luminosities of quasars. This suggests that the redshift-evolutionary LXsubscript𝐿𝑋L_{X}italic_L start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT-LU⁢Vsubscript𝐿𝑈𝑉L_{UV}italic_L start_POSTSUBSCRIPT italic_U italic_V end_POSTSUBSCRIPT relation of quasars constructed from copula is favored by the observations.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"We study the issue of temperature in a steady system around a black hole event horizon, contrasting it with the appearance of divergence in a thermal equilibrium system.
We focus on a spherically symmetric system governed by general relativity, particularly examining the steady state with radial heat conduction.
Employing an appropriate approximation, we derive exact solutions that illuminate the behaviors of number density, local temperature, and heat in the proximity of a black hole.
We demonstrate that a carefully regulated heat inflow can maintain finite local temperatures at the black hole event horizon, even without considering the back-reaction of matter.
This discovery challenges conventional expectations that the local temperature near the event horizon diverges in scenarios of thermal equilibrium.
This implications shows that there’s an intricate connection between heat and gravity in the realm of black hole thermodynamics.",[''],['Korea']
,[''],[]
"Quantization is of significance for compressing the over-parameterized deep neural models and deploying them on resource-limited devices.
Fixed-precision quantization suffers from
performance drop due to the limited numerical representation ability.
Conversely, mixed-precision quantization (MPQ) is advocated to compress the model effectively by allocating heterogeneous bit-width for layers. MPQ is typically organized into a searching-retraining two-stage process. Previous works only focus on determining the optimal bit-width configuration in the first stage efficiently, while ignoring the considerable time costs in the second stage.
However, retraining always consumes hundreds of GPU-hours on the cutting-edge GPUs, thus hindering deployment efficiency significantly.
In this paper, we devise a one-shot training-searching paradigm for mixed-precision model compression.
Specifically, in the first stage, all potential bit-width configurations are coupled and thus optimized simultaneously within a set of shared weights.
However, our observations reveal a previously unseen and severe bit-width interference phenomenon among highly coupled weights during optimization, leading to considerable performance degradation under a high compression ratio.
To tackle this problem, we first design a bit-width scheduler to dynamically freeze the most turbulent bit-width of layers during training, to ensure the rest bit-widths converged properly.
Then, taking inspiration from information theory, we present an information distortion mitigation technique to align the behaviour of the bad-performing bit-widths to the well-performing ones.
In the second stage, an inference-only greedy search scheme is devised to evaluate the goodness of configurations without introducing any additional training costs.
Extensive experiments on three representative models and three datasets demonstrate the effectiveness of the proposed method.",[''],[]
"Autonomous driving has attracted significant attention from both academia and industries, which is expected to offer a safer and more efficient driving system.
However, current autonomous driving systems are mostly based on a single vehicle, which has significant limitations which still poses threats to driving safety. Collaborative perception with connected and autonomous vehicles (CAVs) shows a promising solution to overcoming these limitations. In this article, we first identify the challenges of collaborative perception, such as data sharing asynchrony, data volume, and pose errors. Then, we discuss the possible solutions to address these challenges with various technologies, where the research opportunities are also elaborated. Furthermore, we propose a scheme to deal with communication efficiency and latency problems, which is a channel-aware collaborative perception framework to dynamically adjust the communication graph and minimize latency, thereby improving perception performance while increasing communication efficiency.
Finally, we conduct experiments to demonstrate the effectiveness of our proposed scheme.","['Index', 'Terms: ', 'Collaborative perception, autonomous driving, connected and autonomous vehicle, vehicle-to-everything (V2X) communication.']",[]
"We propose DDN-SLAM, a real-time dense neural implicit semantic SLAM system designed for dynamic scenes. While existing neural implicit SLAM systems perform well in static scenes, they often encounter challenges in real-world environments with dynamic interferences, leading to ineffective tracking and mapping. DDN-SLAM utilizes the priors provided by the deep semantic system, combined with conditional probability fields, for segmentation.By constructing depth-guided static masks and employing joint multi-resolution hashing encoding, we ensure fast hole filling and high-quality mapping while mitigating the effects of dynamic information interference. To enhance tracking robustness, we utilize sparse feature points validated with optical flow and keyframes, enabling loop closure detection and global bundle optimization. Furthermore, DDN-SLAM supports monocular, stereo, and RGB-D inputs, operating robustly at a frequency of 20-30Hz. Extensive experiments on 6 virtual/real datasets demonstrate that our method outperforms state-of-the-art approaches in both dynamic and static scenes.",[''],[]
,[''],[]
"Understanding if attractive fermions in an unbalanced occupation of its flavors can give rise to a superfluid state in two dimensions (2D), realizing the Fulde-Ferrel-Larkin-Ovchinnikov (FFLO) state, presents a long-standing question. A limitation on its solution by numerics is posed by the sign problem, which constrains the applicability of quantum Monte Carlo techniques at sufficiently low temperatures and large lattice sizes, where a potential signature of polarized superfluidity would be unambiguous. By using a recently explored argument that the sign problem may be used instead to infer quantum critical behavior, we explore the regime where partial polarization occurs in the phase diagram, further showing that the average sign ⟨𝒮⟩delimited-⟨⟩𝒮\langle{\cal S}\rangle⟨ caligraphic_S ⟩ of quantum Monte Carlo weights tracks the criticality between balanced (or fully polarized) and polarized phases. Using the attractive Hubbard model with an unbalanced population, our investigation expands the scope of problems in which ⟨𝒮⟩delimited-⟨⟩𝒮\langle{\cal S}\rangle⟨ caligraphic_S ⟩ can be used for monitoring critical behavior, providing compelling albeit indirect evidence for the robustness of an FFLO phase in 2D.",[''],"['China', 'China', 'China', 'Russia', 'Russia', 'China']"
"Implicit Neural Representation (INR) has emerged as an effective method for unsupervised image denoising. However, INR models are typically overparameterized; consequently, these models are prone to overfitting during learning, resulting in suboptimal results, even noisy ones. To tackle this problem, we propose a general recipe for regularizing INR models in image denoising. In detail, we propose to iteratively substitute the supervision signal with the mean value derived from both the prediction and supervision signal during the learning process. We theoretically prove that such a simple iterative substitute can gradually enhance the signal-to-noise ratio of the supervision signal, thereby benefiting INR models during the learning process. Our experimental results demonstrate that INR models can be effectively regularized by the proposed approach, relieving overfitting and boosting image denoising performance.",[''],[]
"Despite the recent progress in deep neural networks (DNNs), it remains challenging to explain the predictions made by DNNs. Existing explanation methods for DNNs mainly focus on post-hoc explanations where another explanatory model is employed to provide explanations. The fact that post-hoc methods can fail to reveal the actual original reasoning process of DNNs raises the need to build DNNs with built-in interpretability. Motivated by this, many self-explaining neural networks have been proposed to generate not only accurate predictions but also clear and intuitive insights into why a particular decision was made. However, existing self-explaining networks are limited in providing distribution-free uncertainty quantification for the two simultaneously generated prediction outcomes (i.e., a sample’s final prediction and its corresponding explanations for interpreting that prediction). Importantly, they also fail to establish a connection between the confidence values assigned to the generated explanations in the interpretation layer and those allocated to the final predictions in the ultimate prediction layer. To tackle the aforementioned challenges, in this paper, we design a novel uncertainty modeling framework for self-explaining networks, which not only demonstrates strong distribution-free uncertainty modeling performance for the generated explanations in the interpretation layer but also excels in producing efficient and effective prediction sets for the final predictions based on the informative high-level basis explanations. We perform the theoretical analysis for the proposed framework. Extensive experimental evaluation demonstrates the effectiveness of the proposed uncertainty framework.",[''],[]
"The Atomic Cluster Expansion (ACE) (Drautz, Phys. Rev. B 99, 2019) has been widely applied in high energy physics, quantum mechanics and atomistic modeling to construct many-body interaction models respecting physical symmetries. Computational efficiency is achieved by allowing non-physical self-interaction terms in the model.
We propose and analyze an efficient method to evaluate and parameterize an orthogonal, or, non-self-interacting cluster expansion model. We present numerical experiments demonstrating improved conditioning and more robust approximation properties than the original expansion in regression tasks both in simplified toy problems and in applications in the machine learning of interatomic potentials.",[''],[]
,[''],[]
"Point cloud completion is an indispensable task for recovering complete point clouds due to incompleteness caused by occlusion, limited sensor resolution, etc.
The family of coarse-to-fine generation architectures has recently exhibited great success in point cloud completion and gradually became mainstream.
In this work, we unveil one of the key ingredients behind these methods: meticulously devised feature extraction operations with explicit cross-resolution aggregation.
We present Cross-Resolution Transformer that efficiently performs cross-resolution aggregation with local attention mechanisms.
With the help of our recursive designs, the proposed operation can capture more scales of features than common aggregation operations, which is beneficial for capturing fine geometric characteristics.
While prior methodologies have ventured into various manifestations of inter-level cross-resolution aggregation, the effectiveness of intra-level one and their combination has not been analyzed.
With unified designs, Cross-Resolution Transformer can perform intra- or inter-level cross-resolution aggregation by switching inputs.
We integrate two forms of Cross-Resolution Transformers into one up-sampling block for point generation, and following the coarse-to-fine manner, we construct CRA-PCN to incrementally predict complete shapes with stacked up-sampling blocks.
Extensive experiments demonstrate that our method outperforms state-of-the-art methods by a large margin on several widely used benchmarks.
Codes are available at https://github.com/EasyRy/CRA-PCN.",[''],[]
"Multi-modal Learning has attracted widespread attention in medical image analysis. Using multi-modal data, whole slide images (WSIs) and clinical information, can improve the performance of deep learning models in the diagnosis of axillary lymph node metastasis. However, clinical information is not easy to collect in clinical practice due to privacy concerns, limited resources, lack of interoperability, etc.
Although patient selection can ensure the training set to have multi-modal data for model development, missing modality of clinical information can appear during test. This normally leads to performance degradation, which limits the use of multi-modal models in the clinic. To alleviate this problem, we propose a bidirectional distillation framework consisting of a multi-modal branch and a single-modal branch. The single-modal branch acquires the complete multi-modal knowledge from the multi-modal branch, while the multi-modal learns the robust features of WSI from the single-modal. We conduct experiments on a public dataset of Lymph Node Metastasis in Early Breast Cancer to validate the method. Our approach not only achieves state-of-the-art performance with an AUC of 0.861 on the test set without missing data, but also yields an AUC of 0.842 when the rate of missing modality is 80%. This shows the effectiveness of the approach in dealing with multi-modal data and missing modality. Such a model has the potential to improve treatment decision-making for early breast cancer patients who have axillary lymph node metastatic status.","['Index', 'Terms: ', 'Missing modality,', 'Whole slide image,', 'Clinical data.']",['yanglin@westlake.edu.cn']
"The quantum SearchRank algorithm is a promising tool for a future quantum search engine based on PageRank quantization. However, this algorithm loses its functionality when the N/M𝑁𝑀N/Mitalic_N / italic_M ratio between the network size N𝑁Nitalic_N and the number of marked nodes M𝑀Mitalic_M is sufficiently large. We propose a modification of the algorithm, replacing the underlying Szegedy quantum walk with a semiclassical walk. To maintain the same time complexity as the quantum SearchRank algorithm we propose a simplification of the algorithm. This new algorithm is called Randomized SearchRank, since it corresponds to a quantum walk over a randomized mixed state. The performance of the SearchRank algorithms is first analyzed on an example network, and then statistically on a set of different networks of increasing size and different number of marked nodes. On the one hand, to test the search ability of the algorithms, it is computed how the probability of measuring the marked nodes decreases with N/M𝑁𝑀N/Mitalic_N / italic_M for the quantum SearchRank, but remarkably it remains at a high value around 0.90.90.90.9 for our semiclassical algorithms, solving the quantum SearchRank problem. The time complexity of the algorithms is also analyzed, obtaining a quadratic speedup with respect to the classical ones. On the other hand, the ranking functionality of the algorithms has been investigated, obtaining a good agreement with the classical PageRank distribution. Finally, the dependence of these algorithms on the intrinsic PageRank damping parameter has been clarified. Our results suggest that this parameter should be below a threshold so that the execution time does not increase drastically.",[''],"['Spain', 'Spain', 'Spain.']"
"We investigate the problem of holomorphic algebraizibility for real hypersurfaces in complex space. We introduce a new invariant of a (real-analytic) Levi-nondegenerate hypersurface called the jet transcendence degree. Using this invariant, we solve in the negative the Conjecture of Huang, Ji and Yau on the algabraizability of real hypersurfaces with algebraic syzygies.",[''],[]
There has recently been some interest in optimizing the error term in the asymptotic for the fourth moment of Dirichlet L𝐿Litalic_L-functions and a closely related mixed moment of L𝐿Litalic_L-functions involving automorphic L𝐿Litalic_L-functions twisted by Dirichlet characters. We obtain an improvement for the error term of the latter.,"['Key words and phrases:', 'Dirichlet', 'L𝐿Litalic_L-functions, modular forms, moments.']",[]
"The use of very high energy electrons (VHEE) for radiotherapy has been actively studied for over two decades due to its advantageous dose distribution, deep penetration depth and great potential of ultra-high dose-rate irradiation. However, the high entrance dose of VHEE beams can damage the surface skin of patients and hinder its widespread application. To address this challenge, a novel method utilizing only two dipole magnets is presented in this article. By adjusting the magnet strengths, the electron beams can be guided along different angular directions towards a specific position as deep as 20 cm inside a water phantom, creating a maximum dose over the target region and significantly reducing the entrance dose Supported by Monte Carlo simulations, such a beam delivery approach contains two major advantages over previous methods: first, it is insensitive to beam energy spread, releasing the constraints on accelerator performance, and second, the dose peak position can be accurately controlled in both lateral and longitudinal directions. In addition, we also show that a flattop dose peak can be generated by the weighted sum of VHEE beams focusing at different positions. These results demonstrate that VHEE beams can be compactly delivered into a deep-seated tumor region in a controllable manner, thus advancing the development of the VHEE radiotherapy towards the practical clinical applications in the near future.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Late fusion multi-view clustering (LFMVC) has become a rapidly growing class of methods in the multi-view clustering (MVC) field, owing to its excellent computational speed and clustering performance. One bottleneck faced by existing late fusion methods is that they are usually aligned to the average kernel function, which makes the clustering performance highly dependent on the quality of datasets. Another problem is that they require subsequent k-means clustering after obtaining the consensus partition matrix to get the final discrete labels, and the resulting separation of the label learning and cluster structure optimization processes limits the integrity of these models. To address the above issues, we propose an integrated framework named One-Step Late Fusion Multi-view Clustering with Compressed Subspace (OS-LFMVC-CS). Specifically, we use the consensus subspace to align the partition matrix while optimizing the partition fusion, and utilize the fused partition matrix to guide the learning of discrete labels. A six-step iterative optimization approach with verified convergence is proposed. Sufficient experiments on multiple datasets validate the effectiveness and efficiency of our proposed method.",[''],[]
"There is growing evidence that high-mass star formation (HMSF) is a multiscale, dynamical process in molecular clouds, where filaments transport gas material between larger and smaller scales. We analyze here multiscale gas dynamics in an HMSF filamentary cloud, G034.43+00.24 (G34), using APEX observations of C1818{}^{18}start_FLOATSUPERSCRIPT 18 end_FLOATSUPERSCRIPTO (2-1), HCO+{}^{+}start_FLOATSUPERSCRIPT + end_FLOATSUPERSCRIPT/H1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCO+{}^{+}start_FLOATSUPERSCRIPT + end_FLOATSUPERSCRIPT (3-2), and HCN/H1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCN (3-2) lines. We find large-scale, filament-aligned velocity gradients from C1818{}^{18}start_FLOATSUPERSCRIPT 18 end_FLOATSUPERSCRIPTO emission, which drive filamentary gas inflows onto dense clumps in the middle ridge of G34. The nature of these inflows is gravity-driven.
We also find clump-scale gas infall in the middle ridge of MM2, MM4, and MM5 clumps from other lines. Their gas infall rates could depend on large-scale filamentary gas inflows since the infall/inflow rates on these two scales are comparable.
We confirm that the multiscale, dynamical HMSF scenario is at work in G34.
It could be driven by gravity up to the filament scale, beyond which turbulence originating from several sources including gravity could be in effect in G34.","['Star forming regions (1565);', 'Molecular clouds (1072);', 'Infrared dark clouds (787);', 'High-mass stars (1834);', 'Molecular gas (1073)']","['China', 'China', 'China']"
"Ultra-low-noise laser sources are crucial for a variety of applications, including microwave synthesizers, optical gyroscopes, and the manipulation of quantum systems. Silicon photonics has emerged as a promising solution for high-coherence applications due to its ability to reduce system size, weight, power consumption, and cost (SWaP-C). Semiconductor lasers based on self-injection locking (SIL) have reached fiber laser coherence, but typically require a high-Q external cavity to suppress coherence collapse through frequency-selective feedback. Lasers based on external-cavity locking (ECL) are a low-cost and turnkey operation option, but their coherence is generally inferior to SIL lasers. In this work, we demonstrate quantum-dot (QD) lasers grown directly on Si that achieve SIL laser coherence under turnkey ECL. The high-performance QD laser offers a scalable and low-cost heteroepitaxial integration platform. Moreover, the QD laser’s chaos-free nature enables a 16 Hz Lorentzian linewidth under ECL using a low-Q external cavity, and improves the frequency noise by an additional order of magnitude compared to conventional quantum-well lasers.",[''],[]
"We present recent progress in calculating the semileptonic
form factors hA1⁢(w)subscriptℎsubscript𝐴1𝑤h_{A_{1}}(w)italic_h start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_w ) for the B¯→D∗⁢ℓ⁢ν¯→¯𝐵superscript𝐷∗ℓ¯𝜈\bar{B}\to D^{\ast}\ell\bar{\nu}over¯ start_ARG italic_B end_ARG → italic_D start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT roman_ℓ over¯ start_ARG italic_ν end_ARG decays.
We use the Oktay-Kronfeld (OK) action for the charm and bottom
valence quarks and the HISQ action for light quarks.
We adopt the Newton method combined with the scanning method to
find a good initial guess for the χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT minimizer in the fitting
of the 2pt correlation functions.
The main advantage is that the Newton method lets us to consume all
the time slices allowed by the physical positivity.
We report the first, reliable, but preliminary results for
hA1⁢(w)/ρA1subscriptℎsubscript𝐴1𝑤subscript𝜌subscript𝐴1h_{A_{1}}(w)/\rho_{A_{1}}italic_h start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_w ) / italic_ρ start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT at zero recoil (w=1𝑤1w=1italic_w = 1).
Here we use a MILC HISQ ensemble (a=0.12𝑎0.12a=0.12italic_a = 0.12 fm, Mπsubscript𝑀𝜋M_{\pi}italic_M start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT = 220
MeV, and Nf=2+1+1subscript𝑁𝑓211N_{f}=2+1+1italic_N start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = 2 + 1 + 1 flavors).",[''],[]
"Identifying a reasonably small Hilbert space that completely describes an unknown quantum state is crucial for efficient quantum information processing. We introduce a general dimension-certification protocol for both discrete and continuous variables that is fully evidence-based, relying solely on the experimental data collected and no other assumptions whatsoever. Using the Bayesian concept of relative belief, we take the effective dimension of the state as the smallest one such that the posterior probability is larger than the prior, as dictated by the data. The posterior probabilities associated with the relative-belief ratios measure the strength of the evidence provide by these ratios so that we can assess whether there is weak or strong evidence in favor or against a particular dimension. Using experimental data from spectral-temporal and polarimetry measurements, we demonstrate how to correctly assign Bayesian plausible error bars for the obtained effective dimensions. This makes relative belief a conservative and easy-to-use model-selection method for any experiment.",[''],"['Korea', 'Korea', 'Germany', 'Germany', 'Germany', 'Canada', 'Belarus', 'Spain', 'Germany']"
"Evolutionary Multitasking (EMT) paradigm, an emerging research topic in evolutionary computation, has been successfully applied in solving high-dimensional feature selection (FS) problems recently.
However, existing EMT-based FS methods suffer from several limitations, such as a single mode of multitask generation, conducting the same generic evolutionary search for all tasks, relying on implicit transfer mechanisms through sole solution encodings, and employing single-objective transformation, which result in inadequate knowledge acquisition, exploitation, and transfer.
To this end, this paper develops a novel EMT framework for multiobjective high-dimensional feature selection problems, namely MO-FSEMT. In particular, multiple auxiliary tasks are constructed by distinct formulation methods to provide diverse search spaces and information representations and then simultaneously addressed with the original task through a multi-slover-based multitask optimization scheme. Each task has an independent population with task-specific representations and is solved using separate evolutionary solvers with different biases and search preferences. A task-specific knowledge transfer mechanism is designed to leverage the advantage information of each task, enabling the discovery and effective transmission of high-quality solutions during the search process.
Comprehensive experimental results demonstrate that our MO-FSEMT framework can achieve overall superior performance compared to the state-of-the-art FS methods on 26 datasets. Moreover, the ablation studies verify the contributions of different components of the proposed MO-FSEMT.","['Index', 'Terms: ', 'Feature selection,', 'Evolutionary', 'Multitasking,', 'High-dimensional classification,', 'Multi-objective optimization']",[]
"We consider multi-user semantic communications over broadcast channels. While most existing works consider that each receiver requires either the same or independent semantic information, this paper explores the scenario where the semantic information desired by different receivers is different but correlated. In particular, we investigate semantic communications over Gaussian broadcast channels where the transmitter has a common observable source but the receivers wish to recover hierarchical semantic information in adaptation to their channel conditions. Inspired by the capacity achieving property of superposition codes, we propose a deep learning based superposition coded modulation (DeepSCM) scheme. Specifically, the hierarchical semantic information is first extracted and encoded into basic and enhanced feature vectors. A linear minimum mean square error (LMMSE) decorrelator is then developed to obtain a refinement from the enhanced features that is uncorrelated with the basic features. Finally, the basic features and their refinement are superposed for broadcasting after probabilistic modulation. Experiments are conducted for two-receiver image semantic broadcasting with coarse and fine classification as hierarchical semantic tasks. DeepSCM outperforms the benchmarking coded-modulation scheme without a superposition structure, especially with large channel disparity and high order modulation. It also approaches the performance upperbound as if there were only one receiver.","['Index', 'Terms: ', 'Semantic communications, digital modulation, superposition coding, broadcast channel.']",[]
,[''],[]
"We describe team ielab from CSIRO and The University of Queensland’s approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval.",[''],[]
"Mergers of binary compact objects, accompanied with electromagnetic (EM) counterparts, offer excellent opportunities to explore varied cosmological models, since gravitational waves (GW) and EM counterparts always carry the information of luminosity distance and redshift, respectively.
f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity, which alters the background evolution and provides a friction term in the propagation of GW, can be tested by comparing the modified GW luminosity distance with the EM luminosity distance. Considering the third–generation gravitational–wave detectors, Einstein Telescope and two Cosmic Explorers, we simulate a series of GW events of binary neutron stars (BNS) and neutron-star-black-hole (NSBH) binary with EM counterparts. These simulations can be used to constrain f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity (specially the Power-law model f⁢(T)=T+α⁢(−T)β𝑓𝑇𝑇𝛼superscript𝑇𝛽f(T)=T+\alpha(-T)^{\beta}italic_f ( italic_T ) = italic_T + italic_α ( - italic_T ) start_POSTSUPERSCRIPT italic_β end_POSTSUPERSCRIPT in this work) and other cosmological parameters, such as β𝛽\betaitalic_β and Hubble constant. In addition, combining simulations with current observations of type Ia supernovae and baryon acoustic oscillations, we obtain tighter limitations for f⁢(T)𝑓𝑇f(T)italic_f ( italic_T ) gravity. We find that the estimated precision significantly improved when all three data sets are combined (Δ⁢β∼0.03similar-toΔ𝛽0.03\Delta\beta\sim 0.03roman_Δ italic_β ∼ 0.03), compared to analyzing the current observations alone (Δ⁢β∼0.3similar-toΔ𝛽0.3\Delta\beta\sim 0.3roman_Δ italic_β ∼ 0.3). Simultaneously, the uncertainty of the Hubble constant can be reduced to approximately 1%percent11\%1 %.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Communication protocols form the bedrock of our interconnected world, yet vulnerabilities within their implementations pose significant security threats.
Recent developments have seen a surge in fuzzing-based research dedicated to uncovering these vulnerabilities within protocol implementations.
However, there still lacks a systematic overview of protocol fuzzing for answering the essential questions such as what the unique challenges are, how existing works solve them, etc.
To bridge this gap, we conducted a comprehensive investigation of related works from both academia and industry.
Our study includes a detailed summary of the specific challenges in protocol fuzzing, and provides a systematic categorization and overview of existing research efforts. Furthermore, we explore and discuss potential future research directions in protocol fuzzing. This survey serves as a foundational guideline for researchers and practitioners in the field.","['Protocol,', 'Fuzz', 'Testing,', 'Security']","['AnShaanxiChina710071', 'AveSingaporeSingaporeSingapore639798', 'AnShaanxiChina710071', 'ProvinceChina210023', 'AveSingaporeSingaporeSingapore639798', 'AveSingaporeSingaporeSingapore639798', 'DistrictBeijingBeijingChina100085', 'AveSingaporeSingaporeSingapore639798', 'StSingaporeSingaporeSingapore188065']"
"The abstract should appear at the top of the left-hand column of text, about
0.5 inch (12 mm) below the title area and no more than 3.125 inches (80 mm) in
length. Leave a 0.5 inch (12 mm) space between the end of the abstract and the
beginning of the main text. The abstract should contain about 100 to 150
words, and should be identical to the abstract text submitted electronically
along with the paper cover sheet. All manuscripts must be in English, printed
in black ink.",[''],[]
,[''],[]
"In the domain of large-scale software development, the demands for dynamic and multifaceted static code analysis exceed the capabilities of traditional tools. To bridge this gap, we present CodeFuse-Query, a system that redefines static code analysis through the fusion of Domain Optimized System Design and Logic Oriented Computation Design.
CodeFuse-Query reimagines code analysis as a data computation task, support scanning over 10 billion lines of code daily and more than 300 different tasks. It optimizes resource utilization, prioritizes data reusability, applies incremental code extraction, and introduces tasks types specially for Code Change, underscoring its domain-optimized design.
The system’s logic-oriented facet employs Datalog, utilizing a unique two-tiered schema, COREF, to convert source code into data facts. Through Gödel, a distinctive language, CodeFuse-Query enables formulation of complex tasks as logical expressions, harnessing Datalog’s declarative prowess.
This paper provides empirical evidence of CodeFuse-Query’s transformative approach, demonstrating its robustness, scalability, and efficiency. We also highlight its real-world impact and diverse applications, emphasizing its potential to reshape the landscape of static code analysis in the context of large-scale software development.Furthermore, in the spirit of collaboration and advancing the field, our project is open-sourced and the repository is available for public access111https://github.com/codefuse-ai/CodeFuse-Query.",[''],[]
"Hallucinations are a type of output error produced by deep neural networks. While this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. Here, we define hallucinations in ASR as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. The similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. We show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. To address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (ASR) model to hallucination at test time, which does not require access to the training dataset. We demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that have similar baseline word error rates. We further explore the relationship between the types of ASR errors and the types of dataset noise to determine what types of noise are most likely to create hallucinatory outputs. We devise a framework for identifying hallucinations by analysing their semantic connection with the ground truth and their fluency. Finally, we discover how to induce hallucinations with a random noise injection to the utterance.",[''],[]
"Unmanned Aerial Vehicle (UAV) visual geo-localization aims to match images of the same geographic target captured from different views, i.e., the UAV view and the satellite view.
It is very challenging due to the large appearance differences in UAV-satellite image pairs.
Previous works map images captured by UAVs and satellites to a shared feature space and employ a classification framework to learn location-dependent features while neglecting the overall distribution shift between the UAV view and the satellite view.
In this paper, we address these limitations by introducing distribution alignment of the two views to shorten their distance in a common space.
Specifically, we propose an end-to-end network, called PVDA (Progressive View Distribution Alignment).
During training, feature encoder, location classifier, and view discriminator are jointly optimized by a novel progressive adversarial learning strategy.
Competition between feature encoder and view discriminator prompts both of them to be stronger.
It turns out that the adversarial learning is progressively emphasized until UAV-view images are indistinguishable from satellite-view images.
As a result, the proposed PVDA becomes powerful in learning location-dependent yet view-invariant features with good scalability towards unseen images of new locations.
Compared to the state-of-the-art methods, the proposed PVDA requires less inference time but has achieved superior performance on the University-1652 dataset.","['UAV visual geo-localization', 'UAV view satellite view distribution alignment adversarial learning.']",[]
"This paper addresses the task of Unmanned Aerial Vehicles (UAV) visual geo-localization, which aims to match images of the same geographic target taken by different platforms, i.e., UAVs and satellites.
In general, the key to achieving accurate UAV-satellite image matching lies in extracting visual features that are robust against viewpoint changes, scale variations, and rotations.
Current works have shown that part matching is crucial for UAV visual geo-localization since part-level representations can capture image details and help to understand the semantic information of scenes.
However, the importance of preserving semantic characteristics in part-level representations is not well discussed.
In this paper, we introduce a transformer-based adaptive semantic aggregation method that regards parts as the most representative semantics in an image.
Correlations of image patches to different parts are learned in terms of the transformer’s feature map.
Then our method decomposes part-level features into an adaptive sum of all patch features.
By doing this, the learned parts are encouraged to focus on patches with typical semantics.
Extensive experiments on the University-1652 dataset have shown the superiority of our method over the current works.",['UAV visual geo-localization transformer part matching.'],[]
"The blooming of social media and face recognition (FR) systems has increased people’s concern about privacy and security. A new type of adversarial privacy cloak (class-universal) can be applied to all the images of regular users, to prevent malicious FR systems from acquiring their identity information. In this work, we discover the optimization dilemma in the existing methods – the local optima problem in large-batch optimization and the gradient information elimination problem in small-batch optimization. To solve these problems, we propose Gradient Accumulation (GA) to aggregate multiple small-batch gradients into a one-step iterative gradient to enhance the gradient stability and reduce the usage of quantization operations. Experiments show that our proposed method achieves high performance on the Privacy-Commons dataset against black-box face recognition models.",[''],[]
"Confined active particles constitute simple, yet realistic, examples
of systems that converge into a non-equilibrium steady state. We
investigate a run-and-tumble particle in one spatial dimension,
trapped by an external potential, with a given distribution g⁢(t)𝑔𝑡g(t)italic_g ( italic_t ) of
waiting times between tumbling events whose mean value is equal to
τ𝜏\tauitalic_τ. Unless g⁢(t)𝑔𝑡g(t)italic_g ( italic_t ) is an exponential distribution (corresponding to
a constant tumbling rate), the process is non-Markovian, which makes
the analysis of the model particularly challenging. We use an
analytical framework involving effective position-dependent tumbling
rates, to develop a numerical method that yields the full steady-state
distribution (SSD). The method is very efficient and requires modest
computing resources, including in the large-deviations and/or
small-τ𝜏\tauitalic_τ regime, where the SSD can be related to the the
large-deviation function, s⁢(x)𝑠𝑥s(x)italic_s ( italic_x ), via the scaling relation Pst⁢(x)∼e−s⁢(x)/τsimilar-tosubscript𝑃st𝑥superscript𝑒𝑠𝑥𝜏P_{{\rm st}}(x)\sim e^{-s\left(x\right)/\tau}italic_P start_POSTSUBSCRIPT roman_st end_POSTSUBSCRIPT ( italic_x ) ∼ italic_e start_POSTSUPERSCRIPT - italic_s ( italic_x ) / italic_τ end_POSTSUPERSCRIPT.",[''],"['Israel', 'Israel']"
"Despite the recent remarkable achievement in gaze estimation, efficient and accurate personalization of gaze estimation without labels is a practical problem but rarely touched on in the literature.
To achieve efficient personalization, we take inspiration from the recent advances in Natural Language Processing (NLP) by updating a negligible number of parameters, “prompts”, at the test time.
Specifically, the prompt is additionally attached without perturbing original network and can contain less than 1% of a ResNet-18’s parameters. Our experiments show high efficiency of the prompt tuning approach. The proposed one can be 10 times faster in terms of adaptation speed than the methods compared.
However, it is non-trivial to update the prompt for personalized gaze estimation without labels. At the test time, it is essential to ensure that the minimizing of particular unsupervised loss leads to the goals of minimizing gaze estimation error. To address this difficulty, we propose to meta-learn the prompt to ensure that its updates align with the goal. Our experiments show that the meta-learned prompt can be effectively adapted even with a simple symmetry loss. In addition, we experiment on four cross-dataset validations to show the remarkable advantages of the proposed method.",[''],[]
"Spatio-temporal video grounding (or STVG) task aims at locating a spatio-temporal tube for a specific instance given a text query. Despite advancements, current methods easily suffer the distractors or heavy object appearance variations in videos due to insufficient object information from the text, leading to degradation. Addressing this, we propose a novel framework, context-guided STVG (CG-STVG), which mines discriminative instance context for object in videos and applies it as a supplementary guidance for target localization. The key of CG-STVG lies in two specially designed modules, including instance context generation (ICG), which focuses on discovering visual context information (in both appearance and motion) of the instance, and instance context refinement (ICR), which aims to improve the instance context from ICG by eliminating irrelevant or even harmful information from the context. During grounding, ICG, together with ICR, are deployed at each decoding stage of a Transformer architecture for instance context learning. Particularly, instance context learned from one decoding stage is fed to the next stage, and leveraged as a guidance containing rich and discriminative object feature to enhance the target-awareness in decoding feature, which conversely benefits generating better new instance context for improving localization finally. Compared to existing methods, CG-STVG enjoys object information in text query and guidance from mined instance visual context for more accurate target localization. In our experiments on three benchmarks, including HCSTVG-v1/-v2 and VidSTG, CG-STVG sets new state-of-the-arts in m_tIoU and m_vIoU on all of them, showing its efficacy. The code will be released at https://github.com/HengLan/CGSTVG.",[''],[]
,[''],[]
"With the increase in the number of electric vehicles (EV), there is a need for the development of the EV charging infrastructure (EVCI) to facilitate fast charging, thereby mitigating the EV congestion at charging stations. The role of the public charging station depot is to charge the vehicle, prioritizing the achievement of the desired state of charge (SoC) value for the EV battery or charging till the departure of the EV, whichever occurs first. The integration of cyber and physical components within EVCI defines it as a cyber physical power system (CPPS), increasing its vulnerability to diverse cyber attacks. When an EV interfaces with the EVCI, mutual exchange of data takes place via various communication protocols like the Open Charge Point Protocol (OCPP), and IEC 61850. Unauthorized access to this data by intruders leads to cyber attacks, potentially resulting in consequences like energy theft, and revenue loss. These scenarios may cause the EVCI to incur higher charges than the actual energy consumed or the EV owners to remit payments that do not correspond adequately to the amount of energy they have consumed. This article proposes an EVCI architecture connected to the utility grid and uses the EVCI data to identify the anomalies or outliers present in the EV transmitted data, particularly focusing on SoC irregularities. The proposed methodology involves utilizing a ridge regression based machine learning (ML) model for predicting changes in the SoC. The adversaries have the capability of spoofing these change in SoC values, consequently making the EVCI incapable of achieving the desired task. Three distinct spoofing techniques namely, decimal shifting, incremental array spoofing, and random spoofing are implemented on the data and subsequently tested with the proposed methodology. The results show that the proposed methodology detects the anomaly accurately and also classifies the type of spoofing that causes the anomaly.","['Index', 'Terms: ', 'EVCI,', 'SoC, fast charging, spoofing, anomaly detection,', 'Ridge regression,']",[]
"For long wavelength gravitational wave (GW), it is easy to diffract when it is lensed by celestial objects. Traditional diffractive integral formula has ignored large angle diffraction, which is adopted in most of cases. However, in some special cases (e. g. a GW source lensed by its companion in a binary system, where the lens is very close to the source), large angle diffraction could be important. Our previous works have proposed a new general diffractive integral formula which has including large angle diffraction case. In this paper, we have investigated how much difference between this general diffractive formula and traditional diffractive integral formula could be under these special cases with different parameters. We find that the module of amplification factor for general diffractive formula could become smaller than that of traditional diffractive integral basically with a factor rF≃0.674similar-to-or-equalssubscript𝑟𝐹0.674r_{F}\simeq 0.674italic_r start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ≃ 0.674 when the distance between lens and sources is DLS=1subscript𝐷LS1D_{\rm LS}=1italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT = 1 AU and lens mass ML=1⁢M⊙subscript𝑀L1subscript𝑀direct-productM_{\rm L}=1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT = 1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. Their difference is so significant that it is detectable. Furthermore, we find that the proportionality factor rFsubscript𝑟𝐹r_{F}italic_r start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT is gradually increasing from 0.5 to 1 with increasing DLSsubscript𝐷LSD_{\rm LS}italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT and it is decreasing with increasing MLsubscript𝑀LM_{\rm L}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT. As long as DLS≲3less-than-or-similar-tosubscript𝐷LS3D_{\rm LS}\lesssim 3italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT ≲ 3 AU (with ML=1⁢M⊙subscript𝑀L1subscript𝑀direct-productM_{\rm L}=1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT = 1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT) or ML≳0.1⁢M⊙greater-than-or-equivalent-tosubscript𝑀L0.1subscript𝑀direct-productM_{\rm L}\gtrsim 0.1M_{\odot}italic_M start_POSTSUBSCRIPT roman_L end_POSTSUBSCRIPT ≳ 0.1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT (with DLS=1subscript𝐷LS1D_{\rm LS}=1italic_D start_POSTSUBSCRIPT roman_LS end_POSTSUBSCRIPT = 1 AU ), the difference between new and traditional formulas is enough significant to be detectable. It is promising to test this new general diffractive formula by next-generation GW detectors in the future GW detection.",[''],[]
,[''],[]
"The development of multi-modal medical foundation models has attracted significant attention in the field of medicine and healthcare due to their promising prospects in various clinical applications. One area of focus in this research direction is the extractions of features at different scales. While previous studies have explored feature learning at individual scales, investigation on integrating the diverse scales and modalities of information is lacking, which may hinder the potential for mutual reinforcement among these features. This paper aims to bridge this gap by proposing a method that effectively exploits multi-scale and cross-modality information to enhance the performance of medical foundation models. The proposed method simultaneously exploit features at the local, instance, modality and global aspects, facilitating comprehensive representation learning within the models. We evaluate the effectiveness of the proposed method on six open-source datasets across different clinical tasks, demonstrating its ability to enhance the performance of medical foundation models.",[''],[]
"We report recent progress in data analysis on the two point
correlation functions which will be prerequisite to obtain
semileptonic form factors for the B(s)→D(s)⁢ℓ⁢ν→subscript𝐵𝑠subscript𝐷𝑠ℓ𝜈B_{(s)}\to D_{(s)}\ell\nuitalic_B start_POSTSUBSCRIPT ( italic_s ) end_POSTSUBSCRIPT → italic_D start_POSTSUBSCRIPT ( italic_s ) end_POSTSUBSCRIPT roman_ℓ italic_ν
decays. We use a MILC HISQ ensemble for the measurement. We use the
HISQ action for light quarks, and the Oktay-Kronfeld (OK) action for
the heavy quarks (b𝑏bitalic_b and c𝑐citalic_c). We used a sequential Bayesian method
for the data analysis. Here we test the new fitting methodology of
Benjamin J. Choi in a completely independent manner.",[''],[]
"A network can contain numerous spanning trees. If two spanning trees Ti,Tjsubscript𝑇𝑖subscript𝑇𝑗T_{i},T_{j}italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT do not share any common edges, Tisubscript𝑇𝑖T_{i}italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Tjsubscript𝑇𝑗T_{j}italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are said to be pairwisely edge-disjoint. For spanning trees T1,T2,…,Tmsubscript𝑇1subscript𝑇2…subscript𝑇𝑚T_{1},T_{2},...,T_{m}italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, if any two of them are pairwisely edge-disjoint, they are called completely edge-independent spanning trees (CEISTs for short). CEISTs can facilitate many network functionalities, and constructing CEISTs as maximally allowed as possible in a given network is a worthy undertaking.
In this paper, we establish the maximal number of CEISTs in the locally twisted cube network, and propose an algorithm to construct ⌊n2⌋𝑛2\lfloor\frac{n}{2}\rfloor⌊ divide start_ARG italic_n end_ARG start_ARG 2 end_ARG ⌋ CEISTs in L⁢T⁢Qn𝐿𝑇subscript𝑄𝑛LTQ_{n}italic_L italic_T italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, the n𝑛nitalic_n-dimensional locally twisted cube. The proposed algorithm has been actually implemented, and we present the outputs. Network broadcasting in the L⁢T⁢Qn𝐿𝑇subscript𝑄𝑛LTQ_{n}italic_L italic_T italic_Q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT was simulated using ⌊n2⌋𝑛2\lfloor\frac{n}{2}\rfloor⌊ divide start_ARG italic_n end_ARG start_ARG 2 end_ARG ⌋ CEISTs, and the performance compared with broadcasting using a single tree.","['Broadcasting;', 'Edge-disjoint;', 'CEISTs;', 'Locally twisted cubes;', 'Spanning trees;', 'Tree embedding.']",[]
"We consider a time-fractional subdiffusion equation with a Caputo derivative in time,
a general second-order elliptic spatial operator, and a right-hand side that is non-smooth in time.
The presence of the latter may lead to locking problems in our time stepping
procedure recently introduced in [4, 2]. Hence,
a generalized version of the residual barrier is proposed to rectify the issue.
We also consider related alternatives to this generalized algorithm, and, furthermore, show that this new residual barrier
may be useful in the case of a negative reaction coefficient.",[''],[]
"The elderly population is increasing rapidly around the world. There are no enough caretakers for them. Use of AI-based in-home medical care systems is gaining momentum due to this. Human fall detection is one of the most important tasks of medical care system for the aged people. Human fall is a common problem among elderly people. Detection of a fall and providing medical help as early as possible is very important to reduce any further complexity. The chances of death and other medical complications can be reduced by detecting and providing medical help as early as possible after the fall. There are many state-of-the-art fall detection techniques available these days, but the majority of them need very high computing power. In this paper, we proposed a lightweight and fast human fall detection system using pose estimation. We used ‘Movenet’ for human joins key-points extraction. Our proposed method can work in real-time on any low-computing device with any basic camera. All computation can be processed locally, so there is no problem of privacy of the subject. We used two datasets ‘GMDCSA’ and ‘URFD’ for the experiment. We got the sensitivity value of 0.9375 and 0.9167 for the dataset ‘GMDCSA’ and ‘URFD’ respectively. The source code and the dataset GMDCSA of our work are available online to access.",[''],[]
"Bayesian networks are powerful tools for probabilistic analysis and have been widely used in machine learning and data science. Unlike the parameters learning mode of neural networks, Bayes classifiers only use sample features to determine the classification results without a time-consuming training process. We study the construction of quantum Bayes classifiers (QBCs) and design a naïve QBC and three semi-naïve QBCs (SN-QBCs). These QBCs are applied to image classification.
A local features sampling method is employed to extract a limited number of features from images to reduce the computational complexity. These features are then used to construct Bayesian networks and generate QBCs. We simulate these QBCs on the MindQuantum quantum platform and test them on the MNIST and Fashion-MNIST datasets. Results show that these QBCs based on a limited number of features exhibit good classification accuracies. The classification accuracies of QBCs on the MNIST dataset surpass that of the classical Bayesian network and quantum neural networks that utilize all feature points.",[''],['China']
"Mobile Edge Computing (MEC) is a new computing paradigm that enables cloud computing and information technology (IT) services to be delivered at the network’s edge. By shifting the load of cloud computing to individual local servers, MEC helps meet the requirements of ultralow latency, localized data processing, and extends the potential of Internet of Things (IoT) for end-users. However, the crosscutting nature of MEC and the multidisciplinary components necessary for its deployment have presented additional security and privacy concerns. Fortunately, Artificial Intelligence (AI) algorithms can cope with excessively unpredictable and complex data, which offers a distinct advantage in dealing with sophisticated and developing adversaries in the security industry. Hence, in this paper we comprehensively provide a survey of security and privacy in MEC from the perspective of AI.
On the one hand, we use European Telecommunications Standards Institute (ETSI) MEC reference architecture as our based framework while merging the Software Defined Network (SDN) and Network Function Virtualization (NFV) to better illustrate a serviceable platform of MEC. On the other hand, we focus on new security and privacy issues, as well as potential solutions from the viewpoints of AI. Finally, we
comprehensively discuss the opportunities and challenges associated with applying AI to MEC security and privacy
as possible future research directions.","['Index', 'Terms: ', 'Mobile', 'Edge', 'Computing, 5G,', 'Internet of', 'Things,', 'Artificial', 'Intelligence,', 'Machine', 'Learning,', 'Security and', 'Privacy,', 'Software', 'Defined', 'Network', 'Security,', 'Virtual', 'Machine security.']",[]
"Optimized blockade is an efficient tool in generating a single-magnon state, that is fundamental to manipulate the magnonic systems at the quantum level. In this study, we consider a hybrid system in which a qubit is strongly coupled to N𝑁Nitalic_N magnons via the exchange interaction. The qubit and the magnon modes are subject to the probing field and driving fields, respectively. It is interesting to find the scalable conditions in minimizing the equal-time second-order correlation function g(2)⁢(0)superscript𝑔20g^{(2)}(0)italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) for each magnon with respect to N𝑁Nitalic_N. In particular, the simultaneous blockade is optimized when (i) the detuning between the qubit (magnon) and the probing (driving field) field is N𝑁\sqrt{N}square-root start_ARG italic_N end_ARG times the magnon-qubit coupling strength, (ii) the probing intensity is 3⁢N3𝑁3\sqrt{N}3 square-root start_ARG italic_N end_ARG times the driving intensity, and (iii) the relative phase between probing and driving fields is 2/(3N2/(3\sqrt{N}2 / ( 3 square-root start_ARG italic_N end_ARG) times the ratio of the system decay rate to the magnon-qubit coupling strength. More than a high-degree blockade, we can generate a significant population on the single-magnon state. With experimental-relevant driving intensity and decay rate, the correlation function can achieve about g(2)⁢(0)∼10−7similar-tosuperscript𝑔20superscript107g^{(2)}(0)\sim 10^{-7}italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) ∼ 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT in company with a large single-magnon population P1∼0.24similar-tosubscript𝑃10.24P_{1}\sim 0.24italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∼ 0.24 when N=1𝑁1N=1italic_N = 1 and g(2)⁢(0)∼10−7similar-tosuperscript𝑔20superscript107g^{(2)}(0)\sim 10^{-7}italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ) ∼ 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT with P1∼0.12similar-tosubscript𝑃10.12P_{1}\sim 0.12italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∼ 0.12 when N=2𝑁2N=2italic_N = 2.",[''],"['China', 'China']"
"Existing contrastive language-image pre-training aims to learn a joint representation by matching abundant image-text pairs. However, the number of image-text pairs in medical datasets is usually orders of magnitude smaller than that in natural datasets. Besides, medical image-text pairs often involve numerous complex fine-grained correspondences. This paper aims to enhance the data efficiency by introducing multiple-to-multiple local relationship modeling to capture denser supervisions. More specifically, we propose a Medical Language-Image Pre-training (MLIP) framework, which exploits the limited image-text medical data more efficiently through patch-sentence matching. Furthermore, we introduce a masked contrastive learning strategy with semantic integrity estimation to reduce redundancy in images while preserving the underlying semantics. Our evaluation results show that MLIP outperforms previous work in zero/few-shot classification and few-shot segmentation tasks by a large margin.",[''],[]
"We study single-photon scattering spectra of a giant atom chirally
coupled to a one-dimensional waveguide at multiple connection points,
and examine chirality induced effects in the scattering spectra by
engineering the chirality of the coupling strengths. We show that
the transmission spectra typically possess an anti-Lorentzian lineshape
with a nonzero minimum, but when the chirality satisfies some specific
conditions independent of the number of coupling points, the transmission spectrum of an incident photon can undergo a transition from complete
transmission to total reflection at multiple frequency “windows”,
the width of which can be flexibly tuned in situ by engineering the
coupling strengths of a certain disordered coupling point. Moreover,
we show that a perfect nonreciprocal photon scattering can be achieved
due to the interplay between internal atomic spontaneous emission
and the chirally external decay to the waveguide, in contrast to that
induced by the non-Markovian retardation effect. We also consider the
non-Markovian retardation effect on the scattering spectra, which allows
for a photonic band gap even with only two chiral coupling points.
The giant-atom-waveguide system with chiral coupling is a promising
candidate for realizing single-photon routers with multiple channels.",[''],"['China', 'China', 'China', 'China', 'China']"
"In the context of measurement-induced entanglement phase transitions, the influence of quantum noises, which are inherent in real physical systems, is of great importance and experimental relevance.
In this Letter, we present a comprehensive theoretical analysis of the effects of both temporally uncorrelated and correlated quantum noises on entanglement generation and information protection.
This investigation reveals that entanglement within the system follows q−1/3superscript𝑞13q^{-1/3}italic_q start_POSTSUPERSCRIPT - 1 / 3 end_POSTSUPERSCRIPT scaling for both types of quantum noises, where q𝑞qitalic_q represents the noise probability.
The scaling arises from the Kardar-Parisi-Zhang fluctuation with effective length scale Leff∼q−1similar-tosubscript𝐿effsuperscript𝑞1L_{\text{eff}}\sim q^{-1}italic_L start_POSTSUBSCRIPT eff end_POSTSUBSCRIPT ∼ italic_q start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
Moreover, the timescales of information protection are explored and shown to follow q−1/2superscript𝑞12q^{-1/2}italic_q start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT and q−2/3superscript𝑞23q^{-2/3}italic_q start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT scaling for temporally uncorrelated and correlated noises, respectively.
The former scaling can be interpreted as a Hayden-Preskill protocol, while the latter is a direct consequence of Kardar-Parisi-Zhang fluctuations.
We conduct extensive numerical simulations using stabilizer formalism to support the theoretical understanding.
This Letter not only contributes to a deeper understanding of the interplay between quantum noises and measurement-induced phase transition but also provides a new perspective to understand the effects of Markovian and non-Markovian noises on quantum computation.",[''],"['China', 'China', 'China', 'USA']"
,[''],[]
,[''],[]
"In the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. Although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. Also prior works in the area of medical question summarisation have been limited to the English language. This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. To address this gap, we introduce the Multimodal Medical Codemixed Question Summarization (MMCQS) dataset, which combines Hindi-English codemixed medical queries with visual aids. This integration enriches the representation of a patient’s medical condition, providing a more comprehensive perspective. We also propose a framework named MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing our MMCQS dataset, we demonstrate the value of integrating visual information from images to improve the creation of medically detailed summaries. This multimodal strategy not only improves healthcare decision-making but also promotes a deeper comprehension of patient queries, paving the way for future exploration in personalized and responsive medical care. Our dataset, code, and pre-trained models will be made publicly available.
https://github.com/ArkadeepAcharya/MedSumm-ECIR2024
Keywords: Mutimodal Summarization, LLM, VLM, Codemixing, Clinical Queries.",[''],[]
"The rapid increase in \acEV adoption provides a promising solution for reducing carbon emissions and fossil fuel dependency in transportation systems. However, the increasing numbers of \acEVs pose significant challenges to the electrical grids. In addition, the number of \acDER and \acMGs is increasing on a global scale to meet the energy demand, consequently changing the energy infrastructure. Recently, energy-sharing methods have been proposed to share excess energy from \acDERs and \acEVs in \acEVCI and \acMGs. Accommodating this sharing mechanism with the existing electrical distribution systems is a critical issue concerning the economic, reliability, and resilience aspects. This study examines the ever-changing field of EVCI and the critical role of \acP2P energy trading in mitigating the problems with grid management that result from unorganized EV charging and intermittency in \acDER. Also, the possibilities of energy sharing in electrical distribution systems for microgrids and EVCI on various energy-sharing methods and algorithms are discussed in detail. Furthermore, the application of market clearing algorithms like game theory, double auction theory, blockchain technology, optimization techniques, machine learning algorithms, and other models from the existing literature are presented. This paper discusses the policies, economic benefits, environmental impacts, societal advantages, and challenges in distribution systems related to sharing in \acEVCI and \acMGs. A roadmap for future research and sharing strategies is provided to guide policymakers, researchers, and industry stakeholders toward a sustainable, resilient, and efficient energy market by integrating P2P technology into EVCIs and \acMGs.","['Index', 'Terms: ', 'Blockchain technology, electric vehicle, electric vehicle charging infrastructure, electrical distribution systems, double auction theory, game theory, machine learning, peer-to-peer energy trading, sharing models, vehicle-to-grid.']",[]
"Few-shot Class-Incremental Learning (FSCIL) aims to continuously learn new classes based on very limited training data without forgetting the old ones encountered.
Existing studies solely relied on pure visual networks, while in this paper we solved FSCIL by leveraging the Vision-Language model (e.g., CLIP) and propose a simple yet effective framework, named Learning Prompt with Distribution-based Feature Replay (LP-DiF).
We observe that simply using CLIP for zero-shot evaluation can substantially outperform the most influential methods.
Then, prompt tuning technique is involved to further improve its adaptation ability, allowing the model to continually capture specific knowledge from each session.
To prevent the learnable prompt from forgetting old knowledge in the new session, we propose a pseudo-feature replay approach.
Specifically, we preserve the old knowledge of each class by maintaining a feature-level Gaussian distribution with a diagonal covariance matrix, which is estimated by the image features of training images and synthesized features generated from a VAE.
When progressing to a new session, pseudo-features are sampled from old-class distributions combined with training images of the current session to optimize the prompt, thus enabling the model to learn new knowledge while retaining old knowledge.
Experiments on three prevalent benchmarks, i.e., CIFAR100, mini-ImageNet, CUB-200, and two more challenging benchmarks, i.e. SUN-397 and CUB-200*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT proposed in this paper showcase the superiority of LP-DiF, achieving new state-of-the-art (SOTA) in FSCIL.
Code is publicly available at https://github.com/1170300714/LP-DiF.",[''],[]
"The generalization error curve of certain kernel regression method aims at determining the exact order of generalization error with various source condition, noise level and choice of the regularization parameter rather than the minimax rate.
In this work, under mild assumptions, we rigorously provide a full characterization of the generalization error curves of the kernel gradient descent method (and a large class of analytic spectral algorithms) in kernel regression.
Consequently, we could sharpen the near inconsistency of kernel interpolation and clarify the saturation effects of kernel regression algorithms with higher qualification, etc.
Thanks to the neural tangent kernel theory, these results greatly improve our understanding of the generalization behavior of training the wide neural networks.
A novel technical contribution, the analytic functional argument, might be of independent interest.",[''],[]
"Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It’s enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences.
Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accuracy of PLLaMa’s responses to various academic inquiries, ensuring its effective and reliable application in the field.
To support further research and development, we have made the model’s checkpoints and source codes accessible to the scientific community. These resources are available for download at https://github.com/Xianjun-Yang/PLLaMa.",[''],[]
"Recent literature on Weil–Petersson random hyperbolic surfaces has met a
consistent obstacle: the necessity to condition the model, prohibiting certain rare geometric
patterns (which we call tangles), such as short closed geodesics or embedded surfaces of
short boundary length. The main result of this article is a Moebius inversion formula, allowing to
integrate the indicator function of the set of tangle-free surfaces in a systematic, tractable
way. It is inspired by a key step of Friedman’s celebrated proof of Alon’s conjecture. We further
prove that our tangle-free hypothesis significantly reduces the number of local topological types
of short geodesics, replacing the exponential proliferation observed on tangled surfaces by a
polynomial growth.","['Key words and phrases:', 'Random hyperbolic surfaces,', 'Weil–Petersson form, moduli space,\nspectral gap, closed geodesic,', 'Selberg trace formula.']",[]
"We have conducted a theoretical investigation of the topological phenomena associated with chiral superconducting pairing states induced in a doped Kane-Mele model on a honeycomb lattice. Through numerical analysis, we have obtained exotic phase diagrams for both the d+i⁢d𝑑𝑖𝑑d+iditalic_d + italic_i italic_d and p+i⁢p𝑝𝑖𝑝p+ipitalic_p + italic_i italic_p superconducting states. In the case of the d+i⁢d𝑑𝑖𝑑d+iditalic_d + italic_i italic_d pairing state, higher Chern number states with |C|=±4𝐶plus-or-minus4\left|C\right|=\pm 4| italic_C | = ± 4 emerge. The Chern number decreases as the spin-orbit coupling is introduced. For the p+i⁢p𝑝𝑖𝑝p+ipitalic_p + italic_i italic_p pairing state, additional phase transition lines are present in the overdoped region near the Van Hove singularity point, leading to the emergence of higher Chern number phases with |C|=±6𝐶plus-or-minus6\left|C\right|=\pm 6| italic_C | = ± 6. These higher Chern number phases are further verified through the bulk-edge correspondence.
To understand the origin of the exotic topological phase diagrams in the chiral superconducting state, we have examined the electronic structure at the phase transition lines. This investigation provides insight into the complex interplay between chiral superconductivity and topological properties, potentially paving the way for the discovery of new materials with unique topological properties.",[''],['China']
,[''],['Japan']
"An important aspect of solar energetic particle (SEP) events is their source populations.
Elemental abundance enhancements of impulsive SEP events, originating in presumed coronal
reconnection episodes, can be fitted to steep power laws of A/Q,
where A and Q are the atomic mass and ionic charge.
Since thermal electron energies are enhanced and
nonthermal electron distributions arise in the reconnection process, we might expect that ionic
charge states Q would be increased through ionization interactions with those electron populations
during the acceleration process. The temperature estimated from the SEPs corresponds to the charge state during the acceleration process, while the actual charge state measured in situ may be modified as the SEPs pass through the corona.
We examine whether the temperature estimation from the A/Q would differ with various kappa values
in a kappa function representing high-energy tail deviating from a Maxwellian velocity distribution.
We find that the differences in the A/Q between a Maxwellian and an extreme kappa distribution are only about 10-30%. We fit power-law enhancement of element abundances as a function of their A/Q with various kappa values. Then, we find that the derived source region temperature is not significantly affected by whether or not the electron velocity distribution deviates from a Maxwellian, i.e., thermal, distribution. Assuming that electrons are heated in the acceleration region, the agreement of the SEP charge state during acceleration with typical active region temperatures suggests that SEPs are accelerated and leave the acceleration region in a shorter time than the ionization time scale.","['The', 'Sun (1693) —', 'Solar', 'Energetic', 'Particles (1491) —', 'Non-thermal radiation sources (1119)']","['Korea', 'USA', 'USA', 'USA']"
"We study the quantum oscillations of inter-layer capacitance in an excitonic insulating electron-hole double layer with the Hartree Fock mean-field theory.
Such oscillations could be simply understood from the physical picture “exciton formed by electron/hole Landau levels”, where the direct gap between the electron-hole Landau levels will oscillate with exciton chemical potential and the inverse of the magnetic field.
We also find that the excitonic order parameters can be destroyed by a strong magnetic field.
At this time, the system becomes two independent quantum Hall liquids and the inter-layer capacitance oscillates to zero at zero temperature.",[''],"['China', 'China', 'China']"
"In this paper we propose a minimal model for free reeds taking into account the significant phenomena. This free reed model may be used to build models of free reed instruments which permit numerical simulations. Several definitions for the section by which the airflow passes through the reed are reviewed and a new one is proposed which takes into account the entire escape area under the reed and the reed thickness. To derive this section, it is necessary to distinguish the neutral section (the only section of the reed which always keeps its length constant while moving) from the upstream or downstream sections. A minimal configuration is chosen to permit the instabilities of both (-,+) and (+,-) reeds on the basis of a linear analysis of instabilities conditions. This configuration is used to illustrate, with temporal simulations, the minimal model for both kinds of reeds and to discuss the model assumptions. Some clues are given about the influence, on the playing frequency and on the dynamic of the sound, of two main parameters of the geometrical model: the size of the volume and the level of the excitation. It is shown that the playing frequency of a (+,-) reed can vary in a large range according to the size of the volume upstream of the reed; that the playing frequency is nearly independent of the excitation but that the dynamic of the sound increases with the excitation level. Some clues are also proposed to determine the nature of the bifurcation for free reeds: it seems that free reeds may present inverse bifurcations. The influence of the reed thickness is also studied for configurations where the reed length or the reed width vary to keep the mass constant. This study shows that the reed thickness can have a great influence on the sound magnitude, the playing frequency and the magnitude of the reed displacement which justifies its introduction in the reed model.
This article has been published in Acta Acustica united with Acustica, Vol. 93 (2007), p. 122-144.",[''],[]
"We present an alternative temporal approach for convolution, providing a new algorithm, called the taches-algorithm. Based on interferences between the successive delayed and amplified output signals associated respectively with the impulses constituting the input signal, the taches-algorithm can give access immediately to the new output sample and have a low latency response even without using vector-based optimisation of the calculation. With the taches-algorithm it seems easy to change (even in real-time) the impulse response while running the calculation, simply by updating the impulse response to use it for next samples, a task rather difficult to achieve using FFT convolution. Real-time audio demonstrations using notably Pure Data and simple explanations of the taches-algorithm will be given.
Paper 7412 presented at the 125th Convention of the Audio Engineering Society, Amsterdam, 2008",[''],"['France', 'France', 'France', 'France']"
,[''],[]
"Hierarchical beam search in mmWave communications incurs substantial training overhead, necessitating deep learning-enabled beam predictions to effectively leverage channel priors and mitigate this overhead. In this study, we introduce a comprehensive probabilistic model of power distribution in beamspace, and formulate the joint optimization problem of probing beam selection and probabilistic beam prediction as an entropy minimization problem. Then, we propose a greedy scheme to iteratively and alternately solve this problem, where a transformer-based beam predictor is trained to estimate the conditional power distribution based on the probing beams and user location within each iteration, and the trained predictor selects an unmeasured beam that minimizes the entropy of remaining beams. To further reduce the number of interactions and the computational complexity of the iterative scheme, we propose a two-stage probing beam selection scheme. Firstly, probing beams are selected from a location-specific codebook designed by an entropy-based criterion, and predictions are made with corresponding feedback. Secondly, the optimal beam is identified using additional probing beams with the highest predicted power values. Simulation results demonstrate the superiority of the proposed schemes compared to hierarchical beam search and beam prediction with uniform probing beams.","['Index', 'Terms: \n\nmmWave communication, beam prediction, probing beam selection, deep learning, entropy minimization.']",[]
"We investigate self-gravitating solutions of the Einstein-Skyrme theory coupled to spin-isospin Dirac fermions and consider the dependence of the spectral flow on the effective gravitational coupling constant and on the Yukawa coupling.
It is shown that the effects of the backreaction of the fermionic mode may strongly deform the configuration.
In particular, the energy conditions may be violated, and regular anti-gravitating asymptotically flat solutions with negative ADM mass may emerge.",[''],"['Kazakhstan', 'Kazakhstan', 'Kyrgyzstan', 'Russia', 'Kazakhstan', 'Kyrgyzstan', 'Russia', 'Germany', 'Russia', 'Germany', 'Germany']"
"We prove large and moderate deviations for the output of Gaussian fully connected neural networks. The main achievements concern deep neural networks (i.e., when the model has more than one hidden layer) and hold for bounded and continuous pre-activation functions. However, for deep neural networks fed by a single input, we have results even if the pre-activation is ReLU. When the network is shallow (i.e., there is exactly one hidden layer) the large and moderate principles hold for quite general pre-activations and in an infinite-dimensional setting.
 
Keywords: Asymptotic behavior, Contraction principle, Deep neural networks, ReLU pre-activation function.
Mathematics Subject Classification: 60F10, 60F05, 68T07",[''],[]
"We define a leaf which is a domain in the closure ℌ¯=ℌ∪ℝ∪{∞}¯ℌℌℝ\overline{{\mathfrak{H}}}={\mathfrak{H}}\cup{\mathbb{R}}\cup\{\infty\}over¯ start_ARG fraktur_H end_ARG = fraktur_H ∪ blackboard_R ∪ { ∞ } of the complex upper half plane ℌ={z∈ℂ∣Im⁢z>0}ℌconditional-set𝑧ℂIm𝑧0{\mathfrak{H}}=\{z\in{\mathbb{C}}\mid{\mathrm{Im}\,}z>0\}fraktur_H = { italic_z ∈ blackboard_C ∣ roman_Im italic_z > 0 } for any linear transformation of an inner product space over the real number field ℝℝ{\mathbb{R}}blackboard_R.
If the dimension of the inner product space is at least 3,
the leaf is convex on the Poincaré metric, and then simply connected, and contains all eigenvalues with nonnegative imaginary part.
Moreover, if the linear transformation is normal, the leaf is the eigenvalue geodesic polygon, which is the minimum convex domain in ℌ¯¯ℌ\overline{{\mathfrak{H}}}over¯ start_ARG fraktur_H end_ARG containing all eigenvalues with nonnegative imaginary part.
We discuss the application of the geometric properties of a leaf to the operator norm.",[''],[]
"Sensors play a crucial role in advanced apparatuses and it is persistently pursued to improve their sensitivities. Recently, the singularity of a non-Hermitian system, known as the exceptional point (EP), has drawn much attention for this goal. Response of the eigenfrequency shift to a perturbation ϵitalic-ϵ\epsilonitalic_ϵ follows the ϵ1/nsuperscriptitalic-ϵ1𝑛\epsilon^{1/n}italic_ϵ start_POSTSUPERSCRIPT 1 / italic_n end_POSTSUPERSCRIPT-dependence at an n𝑛nitalic_nth-order EP, leading to significantly enhanced sensitivity via a high-order EP. However, due to the requirement of increasingly complicated systems, great difficulties will occur along the path of increasing the EP order to enhance the sensitivity. Here we report that by utilizing the spectral anomaly of the coherent perfect absorption (CPA), the sensitivity at a third-order EP can be further enhanced owing to the cooperative effects of both CPA and EP. We realize this synthetically enhanced sensor using a pseudo-Hermitian cavity magnonic system composed of two yttrium iron garnet spheres and a microwave cavity. The detectable minimum change of the magnetic field reaches 4.2×10−214.2superscript10214.2\times 10^{-21}4.2 × 10 start_POSTSUPERSCRIPT - 21 end_POSTSUPERSCRIPT T. It opens a new avenue to design novel sensors using hybrid non-Hermitian quantum systems.",[''],[]
"The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering.
In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website.
We propose SeeAct, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web.
We evaluate on the recent Mind2Web benchmark.
In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites.
We show that GPT-4V presents a great potential for web agents—it can successfully complete 50505050% of the tasks on live websites if we manually ground its textual plans into actions on the websites.
This substantially outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2) specifically fine-tuned for web agents.
However, grounding still remains a major challenge.
Existing LMM grounding strategies like set-of-mark prompting turns out not effective for web agents, and the best grounding strategy we develop in this paper leverages both the HTML text and visuals.
Yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement.111Code and evaluation tool will be released at https://github.com/OSU-NLP-Group/SeeAct.",[''],[]
"A method is proposed to produce a classical optical state that is ‘intersystem nonseparable’ and a close analog of the ϕ+superscriptitalic-ϕ\phi^{+}italic_ϕ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT Bell state. A derivation of the CHSH-Bell inequality is sketched within the framework of classical polarization optics using noncontextuality for factorizable states as an axiom rather than any hidden variable theory, and it is shown that the classical state violates this inequality.",[''],[]
"We consider how the theory of optimal quantum measurements determines the maximum information available to the receiving party of a quantum key distribution (QKD) system employing linearly independent but non-orthogonal quantum states. Such a setting is characteristic of several practical QKD protocols. Due to non-orthogonality, the receiver is not able to discriminate unambiguously between the signals.
To understand the fundamental limits that this imposes, the quantity of interest is the maximum mutual information between the transmitter (Alice) and the receiver, whether legitimate (Bob) or an eavesdropper (Eve).
To find the optimal measurement – taken individually or collectively – , we use a framework based on operator algebra and general results derived from singular value decomposition, achieving optimal solutions for von Neumann measurements and positive operator-valued measures (POVMs).
The formal proof and quantitative analysis elaborated for two signals allow one to conclude that optimal von Neumann measurements are uniquely defined and provide a higher information gain compared to POVMs. Interestingly, collective measurements not only do not provide additional information gain with respect to individual ones, but also suffer from a gain reduction in the case of POVMs.",[''],['Italy']
"In this article we explore the holographic approach to neutron stars in the realm of Quantum Field Theory (QFT). We delve into the structures of neutron stars, emphasizing the application of the AdS/CFT duality in modeling them. We discuss both ”bottom-up” and ”top-down” holographic models, comparing their predictions with astrophysical observations. Finally, we demonstrate the potential broader applications of the holography method in areas like superconductivity, highlighting the methodological significance of string theory and QFT in astrophysics.

Key words


Holography, neutron stars, quantum chromodynamics",[''],['University']
"This article presents a priori error estimates of the miscible displacement of one incompressible fluid by another through a porous medium characterized by a coupled system of nonlinear elliptic and parabolic equations. The study utilizes the H⁢(div)𝐻divH(\mathrm{div})italic_H ( roman_div ) conforming virtual element method (VEM) for the approximation of the velocity, while a non-conforming virtual element approach is employed for the concentration. The pressure is discretised using the standard piecewise discontinuous polynomial functions. These spatial discretization techniques are combined with a backward Euler difference scheme for time discretization. The article also includes numerical results that validate the theoretical estimates presented.
Keywords: Miscible fluid flow, coupled elliptic-parabolic problem, convergence analysis, virtual element methods",[''],[]
,[''],[]
,[''],[]
,[''],[]
"The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.
In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum’s biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 132 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum’s total block value and outline possible mitigations.",[''],"['hlioba@ethz.ch', 'vpahari@mpi-sws.org', 'eric.schertenleib@gmail.com']"
"Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI’s creative potential becomes imperative for its responsible development and application.
This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human.
This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity.
This methodological shift facilitates a statistically quantifiable evaluation of AI’s creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI’s creative abilities with those of specific human groups.
Building on this foundation, we discuss the application of statistical creativity in contemporary prompt-conditioned autoregressive models.
In addition to defining and analyzing a measure of creativity, we introduce an actionable training guideline, effectively bridging the gap between theoretical quantification of creativity and practical model training.
Through these multifaceted contributions, the paper establishes a cohesive, continuously evolving, and transformative framework for assessing and fostering statistical creativity in AI models.",[''],[]
"RGB-T semantic segmentation is a key technique for autonomous driving scenes understanding.
For the existing RGB-T semantic segmentation methods, however, the effective exploration of the complementary relationship between different modalities is not implemented in the information interaction between multiple levels.
To address such an issue, the Context-Aware Interaction Network (CAINet) is proposed for RGB-T semantic segmentation, which constructs interaction space to exploit auxiliary tasks and global context for explicitly guided learning.
Specifically, we propose a Context-Aware Complementary Reasoning (CACR) module aimed at establishing the complementary relationship between multimodal features with the long-term context in both spatial and channel dimensions.
Further, considering the importance of global contextual and detailed information, we propose the Global Context Modeling (GCM) module and Detail Aggregation (DA) module, and we introduce specific auxiliary supervision to explicitly guide the context interaction and refine the segmentation map.
Extensive experiments on two benchmark datasets of MFNet and PST900 demonstrate that the proposed CAINet achieves state-of-the-art performance. The code is available at https://github.com/YingLv1106/CAINet.","['Index', 'Terms: ', 'RGB-T semantic segmentation, context-aware complementation, global context, detail aggregation.']",[]
"Anomaly detection on attributed networks aims to find the nodes whose behaviors are significantly different from other majority nodes. Generally, network data contains information about relationships between entities, and the anomaly is usually embodied in these relationships. Therefore, how to comprehensively model complex interaction patterns in networks is still a major focus. It can be observed that anomalies in networks violate the homophily assumption. However, most existing studies only considered this phenomenon obliquely rather than explicitly. Besides, the node representation of normal entities can be perturbed easily by the noise relationships introduced by anomalous nodes. To address the above issues, we present a novel contrastive learning framework for anomaly detection on attributed networks, SCALA, aiming to improve the embedding quality of the network and provide a new measurement of qualifying the anomaly score for each node by introducing sparsification into the conventional method. Extensive experiments are conducted on five benchmark real-world datasets and the results show that SCALA consistently outperforms all baseline methods significantly.",[''],[]
"The study of Graph Neural Networks (GNNs) has received considerable interest in the past few years. By extending deep learning to graph-structured data, GNNs can solve a diverse set of tasks in fields including social science, chemistry, and medicine. The development of GNN architectures has largely been focused on improving empirical performance on tasks like node or graph classification. However, a line of recent work has instead sought to find GNN architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness.
While there is no consensus on the best way to define the expressiveness of a GNN, it can be viewed from several well-motivated perspectives. Perhaps the most natural approach is to study the universal approximation properties of GNNs, much in the way that this has been studied extensively for MLPs. Another direction focuses on the extent to which GNNs can distinguish between different graph structures, relating this to the graph isomorphism test. Besides, a GNN’s ability to compute graph properties such as graph moments has been suggested as another form of expressiveness. All of these different definitions are complementary and have yielded different recommendations for GNN architecture choices. In this review paper, we would like to give an overview of the notion of ”expressive power” of GNNs and provide some valuable insights regarding the design choices of GNNs.",[''],[]
"Bielliptic surfaces appear as quotient of a product of two elliptic curves and were classified by Bagnera-Franchis. We give a concrete way of computing their GW-invariants with point insertions using a floor diagram algorithm. Using the latter, we are able to prove the quasi-modularity of their generating series by relating them to generating series of graphs for which we also prove quasi-modularity results. We propose a refinement of these invariants by inserting a λ𝜆\lambdaitalic_λ-class in the considered GW-invariants.",[''],[]
"Defining a successful notion of a multivariate quantile has been an open problem for more
than half a century, motivating a plethora of possible solutions. Of
these, the approach of [8] and
[25] leading to M-quantiles, is very appealing for
its mathematical elegance – combining elements of convex analysis and
probability theory. The key idea is the description of a convex
function (the K-function) whose gradient (the K-transform) is in
one-to-one correspondence between all of ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and the unit ball in
ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. By analogy with the d=1𝑑1d=1italic_d = 1 case where the K-transform
is a cumulative distribution function-like object (an M-distribution), the fact that its
inverse is guaranteed to exist lends itself
naturally to providing the basis for the definition of a quantile
function for all d≥1𝑑1d\geq 1italic_d ≥ 1. Over the past twenty years the resulting M-quantiles
have seen applications in a variety of fields, primarily for the
purpose of detecting outliers in multidimensional spaces.
In this article we prove that for odd d≥3𝑑3d\geq 3italic_d ≥ 3, it is not the gradient but a
poly-Laplacian of the K-function that is (almost
everywhere) proportional to the density
function. For d𝑑ditalic_d even one cannot establish a differential equation connecting
the K-function with the density.
These results show that usage of the K-transform for outlier
detection in higher odd-dimensions is in principle flawed,
as the K-transform does not originate from inversion of a true M-distribution.
We demonstrate these conclusions in two dimensions
through examples from non-standard asymmetric distributions. Our
examples illustrate a feature of the K-transform whereby regions in
the domain with higher density map to larger volumes in the co-domain,
thereby producing a magnification effect that moves inliers closer to
the boundary of the co-domain than outliers. This feature obviously
disrupts any outlier detection mechanism that relies on the inverse K-transform.","['multivariate distribution function, multivariate quantile, geometric quantile, outlier detection,']",[]
,[''],[]
"The introduction of the European Union Artificial Intelligence Act, the NIST Artificial Intelligence Risk Management Framework,
and related norms demands a better understanding and implementation
of novel risk analysis
approaches to evaluate systems with Artificial Intelligence components. This paper provides a
cybersecurity risk analysis framework that can help assessing such systems. We use an
illustrative
example concerning automated driving systems.",[''],"['Spain', 'Spain', 'Spain', 'Spain']"
"The primary objective of this work is to construct spaces that are ""pseudocompact but not countably compact,"" abbreviated as P-NC,
while endowing them with additional properties.
First, motivated by an old problem of van Douwen concerning first
countable P-NC spaces,
we construct from CH a locally compact and locally countable first
countable P-NC space with countable spread.
A space is deemed densely countably compact, denoted as DCC for brevity,
if it possesses a dense, countable compact subspace. Moreover, a space qualifies as
densely relatively countably compact, abbreviated as DRC, if it contains a
dense subset D𝐷Ditalic_D
such that every infinite subset of D𝐷Ditalic_D has an accumulation point in X𝑋Xitalic_X.
A countably compact space is DCC,
a DCC space is DRC,
and a DRC space is evidently pseudocompact.
The Tychonoff plank is a DCC space but is not countably compact.
A ΨΨ\Psiroman_Ψ-space belongs to the class of DRC spaces but is not DCC.
Lastly, if p∈ω*𝑝superscript𝜔p\in{\omega}^{*}italic_p ∈ italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT is not a P-point, then T⁢(p)𝑇𝑝T(p)italic_T ( italic_p ),
representing the type of p𝑝pitalic_p in ω*superscript𝜔{\omega}^{*}italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, constitutes a pseudocompact subspace of
ω*superscript𝜔{\omega}^{*}italic_ω start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT that is not DRC.
Berner constructed a first countable example which separates DRC and pseudocompactness,
but his example is not “hereditary” and it has cardinality 𝔠+superscript𝔠\mathfrak{c}^{+}fraktur_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT.
When considering a topological property denoted as Q𝑄Qitalic_Q,
we define a space X𝑋Xitalic_X as ""hereditarily Q𝑄Qitalic_Q""
if every regular closed subspace of X𝑋Xitalic_X also possesses property Q𝑄Qitalic_Q.
The Tychonoff plank and the ΨΨ\Psiroman_Ψ-spaces are not hereditary examples.
However, the aforementioned space T⁢(p)𝑇𝑝T(p)italic_T ( italic_p ) is a hereditary example,
albeit not being first countable.
In this paper we want to find (first countable) examples
which separates these properties hereditarily.
We have obtained the following result.


(1)

There is aDCC  space X𝑋Xitalic_X such that no H∈R⁢C⁢(X)+𝐻𝑅𝐶superscript𝑋H\in RC(X)^{+}italic_H ∈ italic_R italic_C ( italic_X ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is countably compact.



(2)

If CH holds, then there is a DRC space Y𝑌Yitalic_Y such that no H∈R⁢C⁢(Y)+𝐻𝑅𝐶superscript𝑌H\in RC(Y)^{+}italic_H ∈ italic_R italic_C ( italic_Y ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is DCC.



(3)

If CH holds, then there is a first countable pseudocompact space Z𝑍Zitalic_Z
such that no H∈R⁢C⁢(Z)+𝐻𝑅𝐶superscript𝑍H\in RC(Z)^{+}italic_H ∈ italic_R italic_C ( italic_Z ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT
is DRC.","['Key words and phrases: conditionally compact, countably compact, relatively countably compact, pseudocompact']",[]
"Consumer-resource dynamics is central in determining biomass transport across ecosystems. The assumptions of mass action, chemostatic conditions and stationarity in stochastic feeding dynamics lead to Holling type II functional responses, whose use is widespread in macroscopic models of population dynamics. However, to be useful for parameter inference, stochastic population models need to be identifiable, this meaning that model parameters can be uniquely inferred from a large number of model observations. In this contribution we study parameter identifiability in a multi-resource consumer-resource model, for which we can obtain the steady-state and out-of-equilibrium probability distributions of predator’s abundances by analytically solving the master equation. Based on these analytical results, we can conduct in silico experiments by tracking the abundance of consumers that are either searching for or handling prey, data then used for maximum likelihood parameter estimation. We show that, when model observations are recorded out of equilibrium, feeding parameters are truly identifiable, whereas if sampling is done at stationarity, only ratios of rates can be inferred from data. We discuss the implications of our results when inferring parameters of general dynamical models.","['stochastic consumer-resource models, master equation, out-of-equilibrium distribution, parameter inference, multi-resource', 'Holling type', 'II feeding dynamics']","['Spain.', 'Spain.']"
"The Polynomial-Time Hierarchy (𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH) is a staple of classical complexity theory, with applications spanning randomized computation to circuit lower bounds to “quantum advantage” analyses for near-term quantum computers.
Quantumly, however, despite the fact that at least four definitions of quantum 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH exist, it has been challenging to prove analogues for these of even basic facts from 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH.
This work studies three quantum-verifier based generalizations of PH, two of which are from [Gharibian, Santha, Sikora, Sundaram, Yirka, 2022] and use classical strings (𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH) and quantum mixed states (𝖰𝖯𝖧𝖰𝖯𝖧\mathsf{QPH}sansserif_QPH) as proofs, and one of which is new to this work, utilizing quantum pure states (𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH) as proofs.
We first resolve several open problems from [GSSSY22], including a collapse theorem and a Karp-Lipton theorem for 𝖰𝖢𝖯𝖧𝖰𝖢𝖯𝖧\mathsf{QCPH}sansserif_QCPH. Then, for our new class 𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH, we show one-sided error reduction 𝗉𝗎𝗋𝖾𝖰𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧\mathsf{pureQPH}sansserif_pureQPH, as well as the first bounds relating these quantum variants of PH, namely 𝖰𝖢𝖯𝖧⊆𝗉𝗎𝗋𝖾𝖰𝖯𝖧⊆𝖤𝖷𝖯𝖯𝖯𝖰𝖢𝖯𝖧𝗉𝗎𝗋𝖾𝖰𝖯𝖧superscript𝖤𝖷𝖯𝖯𝖯\mathsf{QCPH}\subseteq\mathsf{pureQPH}\subseteq\mathsf{EXP}^{\mathsf{PP}}sansserif_QCPH ⊆ sansserif_pureQPH ⊆ sansserif_EXP start_POSTSUPERSCRIPT sansserif_PP end_POSTSUPERSCRIPT.",[''],[]
"We explicitly provide minimal Gröbner bases for simple, finite-dimensional modules of complex Lie algebras of types A and C, using a weighted ordering that is compatible with the PBW filtration on the universal enveloping algebras.",[''],[]
"Let f:X⟶Y:𝑓⟶𝑋𝑌f\,:\,X\,\longrightarrow\,Yitalic_f : italic_X ⟶ italic_Y be a generically smooth nonconstant morphism between irreducible projective
curves, defined over an algebraically closed field, which is étale on an open subset of Y𝑌Yitalic_Y that contains both
the singular locus of Y𝑌Yitalic_Y and the image, in Y𝑌Yitalic_Y, of the singular locus of X𝑋Xitalic_X. We prove that the following
statements are equivalent:


(1)

The homomorphism of étale fundamental groups



f*:π1et⁢(X)⟶π1et⁢(Y):subscript𝑓⟶superscriptsubscript𝜋1et𝑋superscriptsubscript𝜋1et𝑌f_{*}\,:\,\pi_{1}^{\rm et}(X)\,\longrightarrow\,\pi_{1}^{\rm et}(Y)italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT : italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_et end_POSTSUPERSCRIPT ( italic_X ) ⟶ italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_et end_POSTSUPERSCRIPT ( italic_Y )



induced by f𝑓fitalic_f is surjective.



(2)

There is no nontrivial étale covering ϕ:Y′⟶Y:italic-ϕ⟶superscript𝑌′𝑌\phi\,:\,Y^{\prime}\,\longrightarrow\,Yitalic_ϕ : italic_Y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⟶ italic_Y admitting
a morphism q:X⟶Y′:𝑞⟶𝑋superscript𝑌′q\,:\,X\,\longrightarrow\,Y^{\prime}italic_q : italic_X ⟶ italic_Y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT such that ϕ∘q=fitalic-ϕ𝑞𝑓\phi\circ q\,=\,fitalic_ϕ ∘ italic_q = italic_f.



(3)

The fiber product X×YXsubscript𝑌𝑋𝑋X\times_{Y}Xitalic_X × start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT italic_X is connected.




(4)

dimH0⁢(X,f*⁢f*⁢𝒪X)= 1dimensionsuperscript𝐻0𝑋superscript𝑓subscript𝑓subscript𝒪𝑋1\dim H^{0}(X,\,f^{*}f_{*}{\mathcal{O}}_{X})\,=\,1roman_dim italic_H start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ( italic_X , italic_f start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT caligraphic_O start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ) = 1.



(5)

𝒪Y⊂f*⁢𝒪Xsubscript𝒪𝑌subscript𝑓subscript𝒪𝑋{\mathcal{O}}_{Y}\,\subset\,f_{*}{\mathcal{O}}_{X}caligraphic_O start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ⊂ italic_f start_POSTSUBSCRIPT * end_POSTSUBSCRIPT caligraphic_O start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT is the maximal semistable subsheaf.



(6)

The pullback f*⁢Esuperscript𝑓𝐸f^{*}Eitalic_f start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_E of every stable sheaf E𝐸Eitalic_E on Y𝑌Yitalic_Y is also stable.","['Key words and phrases: Étale over singular locus, stable bundle, genuinely ramified map']",[]
"Wireless communication highly depends on the cellular ground base station (GBS). A failure of the cellular GBS, fully or partially, during natural or man-made disasters creates a communication gap in the disaster-affected areas. In such situations, public safety communication (PSC) can significantly save the national infrastructure, property, and lives. Throughout emergencies, the PSC can provide mission-critical communication and video transmission services in the affected area. Unmanned aerial vehicles (UAVs) as flying base stations (UAV-BSs) are particularly suitable for PSC services as they are flexible, mobile, and easily deployable. This manuscript considers a multi-UAV-assisted PSC network with an observational UAV receiving videos from the affected area’s ground users (AGUs) and transmitting them to the nearby GBS via a relay UAV. The objective of the proposed study is to maximize the average utility of the video streams generated by the AGUs upon reaching the GBS. This is achieved by optimizing the positions of the observational and relay UAVs, as well as the distribution of communication resources, such as bandwidth, and transmit power, while satisfying the system-designed constraints, such as transmission rate, rate outage probability, transmit power budget, and available bandwidth. To this end, a joint UAVs placement and resource allocation problem is mathematically formulated. The proposed problem poses a significant challenge for a solution. Considering the block coordinate descent and successive convex approximation techniques, an efficient iterative algorithm is proposed. Finally, simulation results are provided which show that our proposed approach outperforms the existing methods.","['Index', 'Terms: ', 'Public safety communication networks (PSCNs),', 'UAVs, video transmission, resource allocation.']",[]
"Social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos.
While previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. Brand personalities are shown to be affecting consumers’ behaviours and social interactions and thus are proven to be a key aspect of marketing strategies.
Current open-source multimodal LLMs are not directly suited for this task. Hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities.
Our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain English caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned social media caption. Along with brand personality, our system also gives users the flexibility to provide hashtags, Instagram handles, URLs, and named entities they want the caption to contain, making the captions more semantically related to the social media handles. Comparative evaluations against various baselines demonstrate the effectiveness of our approach, both qualitatively and quantitatively.",[''],[]
"The PandaX-4T distillation system, designed for the removal of krypton and radon from xenon, was evaluated for its radon removal efficiency using a 222222{}^{222}start_FLOATSUPERSCRIPT 222 end_FLOATSUPERSCRIPTRn source during the online distillation process. The PandaX-4T dark matter detector was employed to monitor the temporal evolution of radon activity.
To determine the radon reduction factor, the experimental data of radon atoms introduced into and bypassed the distillation system was compared. The results indicate that, the PandaX-4T distillation system achieved a radon reduction factor exceeding 190 at a flow rate of 10 slpm and a reflux ratio of 1.44. Gas-only online distillation process of a flow rate of 20 slpm was also conducted, without observing significant reduction of radon levels in the detector. This observation suggests that the migration flow of radon atoms from the liquid phase to the gas phase is limited, and the flow rate and duration of the process may be insignificant compared to the total xenon mass of 6 tons.
This study provides the evidence supporting the efficient removal of radon using cryogenic distillation systems. Furthermore, it demonstrates that the distillation method could control radon background levels effectively in liquid xenon-based experiments.",[''],[]
We study the possibility of FDM.,[''],"['India', 'India']"
"Self-supervised learning (SSL) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels.
Hypothesizing that SSL models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns).
Motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing SSL models to their supervised counterparts. Our findings demonstrate that SSL has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness—exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. Ultimately, this work underscores SSL’s potential in human-centric computing, particularly high-stakes, data-scarce application domains like healthcare.",[''],[]
"Machine learning models underpin many modern financial systems for use cases such as fraud detection and churn prediction. Most are based on supervised learning with hand-engineered features, which relies heavily on the availability of labelled data. Large self-supervised generative models have shown tremendous success in natural language processing and computer vision, yet so far they haven’t been adapted to multivariate time series of financial transactions. In this paper, we present a generative pretraining method that can be used to obtain contextualised embeddings of financial transactions. Benchmarks on public datasets demonstrate that it outperforms state-of-the-art self-supervised methods on a range of downstream tasks. We additionally perform large-scale pretraining of an embedding model using a corpus of data from 180 issuing banks containing 5.1 billion transactions and apply it to the card fraud detection problem on hold-out datasets. The embedding model significantly improves value detection rate at high precision thresholds and transfers well to out-of-domain distributions.","['transaction embeddings, self-supervised learning, generative modelling, multivariate time series, fraud detection']","['LabFeaturespaceCambridgeUK', 'LabFeaturespaceCambridgeUK', 'LabFeaturespaceCambridgeUK', 'LabFeaturespaceCambridgeUK', 'LabFeaturespaceCambridgeUK']"
"Perceiving the complete shape of occluded objects is essential for human and machine intelligence. While the amodal segmentation task is to predict the complete mask of partially occluded objects, it is time-consuming and labor-intensive to annotate the pixel-level ground truth amodal masks. Box-level supervised amodal segmentation addresses this challenge by relying solely on ground truth bounding boxes and instance classes as supervision, thereby alleviating the need for exhaustive pixel-level annotations. Nevertheless, current box-level methodologies encounter limitations in generating low-resolution masks and imprecise boundaries, failing to meet the demands of practical real-world applications. We present a novel solution to tackle this problem by introducing a directed expansion approach from visible masks to corresponding amodal masks. Our approach involves a hybrid end-to-end network based on the overlapping region - the area where different instances intersect. Diverse segmentation strategies are applied for overlapping regions and non-overlapping regions according to distinct characteristics. To guide the expansion of visible masks, we introduce an elaborately-designed connectivity loss for overlapping regions, which leverages correlations with visible masks and facilitates accurate amodal segmentation. Experiments are conducted on several challenging datasets and the results show that our proposed method can outperform existing state-of-the-art methods with large margins.",[''],[]
"Stereo matching and semantic segmentation are significant tasks in binocular satellite 3D reconstruction. However, previous studies primarily view these as independent parallel tasks, lacking an integrated multitask learning framework. This work introduces a solution, the Single-branch Semantic Stereo Network (S33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTNet), which innovatively combines semantic segmentation and stereo matching using Self-Fuse and Mutual-Fuse modules. Unlike preceding methods that utilize semantic or disparity information independently, our method identifies and leverages the intrinsic link between these two tasks, leading to a more accurate understanding of semantic information and disparity estimation. Comparative testing on the US3D dataset proves the effectiveness of our S33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTNet. Our model improves the mIoU in semantic segmentation from 61.38 to 67.39, and reduces the D1-Error and average endpoint error (EPE) in disparity estimation from 10.051 to 9.579 and 1.439 to 1.403 respectively, surpassing existing competitive methods. Our codes are available at: https://github.com/CVEO/S3Net.",[''],[]
,[''],[]
"This paper discusses pairing double/debiased machine learning (DDML) with stacking, a model averaging method for combining multiple candidate learners, to estimate structural parameters. We introduce two new stacking approaches for DDML: short-stacking exploits the cross-fitting step of DDML to substantially reduce the computational burden and pooled stacking enforces common stacking weights over cross-fitting folds. Using calibrated simulation studies and two applications estimating gender gaps in citations and wages, we show that DDML with stacking is more robust to partially unknown functional forms than common alternative approaches based on single pre-selected learners. We provide Stata and R software implementing our proposals.
Keywords: causal inference, partially linear model, high-dimensional models, super learners, nonparametric estimation 
JEL: C21, C26, C52, C55, J01, J08",[''],[]
"Multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an “intra-modal redundancy” issue. (2) Duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an “inter-modal redundancy” issue. To address these, we propose a new framework, Prototypical Information Bottlenecking and Disentangling (PIBD), consisting of Prototypical Information Bottleneck (PIB) module for intra-modal redundancy and Prototypical Information Disentanglement (PID) module for inter-modal redundancy. Specifically, a variant of information bottleneck, PIB, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. PID module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. Extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods. The code is released 111https://github.com/zylbuaa/PIBD.git.",[''],[]
"Advances in image diffusion models have recently led to notable improvements in the generation of high-quality images.
In combination with Neural Radiance Fields (NeRFs), they enabled new opportunities in 3D generation.
However, most generative 3D approaches are object-centric and applying them to editing existing photorealistic scenes is not trivial.
We propose SIGNeRF, a novel approach for fast and controllable NeRF scene editing and scene-integrated object generation.
A new generative update strategy ensures 3D consistency across the edited images, without requiring iterative optimization.
We find that depth-conditioned diffusion models inherently possess the capability to generate 3D consistent views by requesting a grid of images instead of single views.
Based on these insights, we introduce a multi-view reference sheet of modified images.
Our method updates an image collection consistently based on the reference sheet and refines the original NeRF with the newly generated image set in one go.
By exploiting the depth conditioning mechanism of the image diffusion model, we gain fine control over the spatial location of the edit and enforce shape guidance by a selected region or an external mesh.",[''],[]
"A topological space is said to be DRC (\DRS) iff it possesses a dense,
relatively countably compact (or relatively sequentially compact, respectively) subspace.
The concept of
selectively pseudocompact game Sp(X) and the
selectively sequentially pseudocompact game Ssp(X) were
introduced by Dorantes-Aldama and Shakhmatov.
They explored the relationship between the existence of a winning strategy
and a stationary winning strategy for player P in these games.
In particular, they observed that there exists a stationary winning strategy
in the game Sp(X) (Ssp(X)) for Player P iff X𝑋Xitalic_X is DRC (or \DRS, respectively).
In this paper we introduce natural weakening of the properties
DRC and \DRS:
a space X𝑋Xitalic_X is DRCω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT (DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT)  iff there is a
sequence ⟨Dn:n∈ω⟩delimited-⟨⟩:subscript𝐷𝑛𝑛𝜔\left\langle D_{n}:n\in{\omega}\right\rangle⟨ italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ italic_ω ⟩ of dense subsets of X𝑋Xitalic_X such that every sequence
⟨dn:n∈ω⟩delimited-⟨⟩:subscript𝑑𝑛𝑛𝜔\left\langle d_{n}:n\in{\omega}\right\rangle⟨ italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ italic_ω ⟩ with
dn∈Dnsubscript𝑑𝑛subscript𝐷𝑛d_{n}\in D_{n}italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT has an accumulation point (or contains a convergent subsequence, respectively).
These properties are also equivalent
to the existence of some limited knowledge winning strategy on the
corresponding games S⁢p⁢(X)𝑆𝑝𝑋Sp(X)italic_S italic_p ( italic_X ) and S⁢s⁢p⁢(X)𝑆𝑠𝑝𝑋Ssp(X)italic_S italic_s italic_p ( italic_X ).
Clearly, \DRS implies DRC and DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT, DRC or DRSω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT imply DRCω𝜔{}_{\omega}start_FLOATSUBSCRIPT italic_ω end_FLOATSUBSCRIPT.
The main part of this paper is devoted to prove that apart from these trivial implications, consistently there are no
other implications between these properties.","['Key words and phrases: countably compact, relatively countably compact, relatively sequentially compact,\npseudocompact']",[]
"The structure of the irreducible collective spaces of the group
S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ), which many-particle nuclear states are classified
according to the chain S⁢p⁢(12,R)⊃U⁢(6)⊃S⁢O⁢(6)⊃S⁢Up⁢n⁢(3)⊗S⁢O⁢(2)⊃S⁢O⁢(3)superset-of𝑆𝑝12𝑅𝑈6superset-of𝑆𝑂6superset-oftensor-product𝑆subscript𝑈𝑝𝑛3𝑆𝑂2superset-of𝑆𝑂3Sp(12,R)\supset U(6)\supset SO(6)\supset SU_{pn}(3)\otimes SO(2)\supset SO(3)italic_S italic_p ( 12 , italic_R ) ⊃ italic_U ( 6 ) ⊃ italic_S italic_O ( 6 ) ⊃ italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) ⊗ italic_S italic_O ( 2 ) ⊃ italic_S italic_O ( 3 ) of the proton-neutron
symplectic model (PNSM), is considered in detail. This chain of the
PNSM was shown to correspond to a microscopic shell-model version of
the Bohr-Mottelson collective model. The construction of the
relevant shell-model representations of the S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ) group along
this chain is considered for three nuclei with varying collective
properties and from different mass regions. It is shown that the
S⁢Up⁢n⁢(3)𝑆subscript𝑈𝑝𝑛3SU_{pn}(3)italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) basis states of the S⁢p⁢(12,R)𝑆𝑝12𝑅Sp(12,R)italic_S italic_p ( 12 , italic_R ) representations are
always Pauli allowed for υ≥υ0𝜐subscript𝜐0\upsilon\geq\upsilon_{0}italic_υ ≥ italic_υ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, but organized
in a different way into different S⁢O⁢(6)𝑆𝑂6SO(6)italic_S italic_O ( 6 ) shells. This is in
contrast to the case of filling the levels of the standard
three-dimensional harmonic oscillator and using the plethysm
operation. Although the S⁢Up⁢n⁢(3)𝑆subscript𝑈𝑝𝑛3SU_{pn}(3)italic_S italic_U start_POSTSUBSCRIPT italic_p italic_n end_POSTSUBSCRIPT ( 3 ) multiplets with υ<υ0𝜐subscript𝜐0\upsilon<\upsilon_{0}italic_υ < italic_υ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT are not all Pauli forbidden, it is safe to discard
them, as it was actually done in the practical applications.",[''],"['Russia', 'Bulgaria']"
"Source-free domain adaptation (SFDA) aims to transfer knowledge learned from a source domain to an unlabeled target domain, where the source data is unavailable during adaptation. Existing approaches for SFDA focus on self-training usually including well-established entropy minimization and pseudo-labeling techniques.
Recent work suggested a co-learning strategy to improve the quality of the generated target pseudo-labels using robust pre-trained networks such as Swin-B. However, since the generated pseudo-labels depend on the source model, they may be noisy due to domain shift.
In this paper, we view SFDA from the perspective of label noise learning and learn to de-confuse the pseudo-labels.
More specifically, we learn a noise transition matrix of the pseudo-labels to capture the label corruption of each class and learn the underlying true label distribution.
Estimating the noise transition matrix enables a better true class-posterior estimation results with better prediction accuracy.
We demonstrate the effectiveness of our approach applied with several SFDA methods: SHOT, SHOT++, and AaD.
We obtain state-of-the-art results on three domain adaptation datasets: VisDA, DomainNet, and OfficeHome.",[''],[]
"The burgeoning field of Artificial Intelligence Generated Content (AIGC) is witnessing rapid advancements, particularly in video generation. This paper introduces AIGCBench, a pioneering comprehensive and scalable benchmark designed to evaluate a variety of video generation tasks, with a primary focus on Image-to-Video (I2V) generation. AIGCBench tackles the limitations of existing benchmarks, which suffer from a lack of diverse datasets, by including a varied and open-domain image-text dataset that evaluates different state-of-the-art algorithms under equivalent conditions. We employ a novel text combiner and GPT-4 to create rich text prompts, which are then used to generate images via advanced Text-to-Image models. To establish a unified evaluation framework for video generation tasks, our benchmark includes 11 metrics spanning four dimensions to assess algorithm performance. These dimensions are control-video alignment, motion effects, temporal consistency, and video quality. These metrics are both reference video-dependent and video-free, ensuring a comprehensive evaluation strategy. The evaluation standard proposed correlates well with human judgment, providing insights into the strengths and weaknesses of current I2V algorithms. The findings from our extensive experiments aim to stimulate further research and development in the I2V field. AIGCBench represents a significant step toward creating standardized benchmarks for the broader AIGC landscape, proposing an adaptable and equitable framework for future assessments of video generation tasks.",[''],[]
,[''],[]
"A large part of the discussion on entanglement islands has explored the specific setup of 2⁢d2𝑑2d2 italic_d JT gravity with a flat heatbath coupled to a 2⁢d2𝑑2d2 italic_d CFT.
In this paper, we consider a more general setup and treatment of islands in a d−limit-from𝑑d-italic_d -dimensional AdS black hole background. The quantum fields modeling the Hawking radiation have a scale and are consistently inherited from a conformal parent theory; their symmetries are thus compatible with those of curved backgrounds. We demonstrate explicitly that the existence of islands is sensitive to the choice of CFT used to model the Hawking radiation.
We compute the renormalised entanglement entropy of conformal fields on a negatively curved background in d𝑑ditalic_d dimensions at zero temperature as well as the thermal regulated entropy of an entangling region near the UV boundary. Using the latter quantity as the entropy of the Hawking radiation, we find that islands never emerge for d>2𝑑2d>2italic_d > 2.",[''],[]
"Recent research has shown the potential of deep learning in multi-parametric MRI-based visual pathway (VP) segmentation. However, obtaining labeled data for training is laborious and time-consuming. Therefore, it is crucial to develop effective algorithms in situations with limited labeled samples. In this work, we propose a label-efficient deep learning method with self-ensembling (LESEN). LESEN incorporates supervised and unsupervised losses, enabling the student and teacher models to mutually learn from each other, forming a self-ensembling mean teacher framework. Additionally, we introduce a reliable unlabeled sample selection (RUSS) mechanism to further enhance LESEN’s effectiveness. Our experiments on the human connectome project (HCP) dataset demonstrate the superior performance of our method when compared to state-of-the-art techniques, advancing multimodal VP segmentation for comprehensive analysis in clinical and research settings. The implementation code will be available at: https://github.com/aldiak/Semi-Supervised-Multimodal-Visual-Pathway- Delineation.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Microwave electric field sensing is of importance for a wide range of applications in areas of remote sensing, radar astronomy and communications. Over the past decade, Rydberg atoms, owing to their exaggerated response to microwave electric fields, plentiful optional energy levels and integratable preparation methods, have been used in ultra-sensitive, wide broadband, traceable, stealthy microwave electric field sensing. This review first introduces the basic concept of quantum sensing, properties of Rydberg atoms and principles of quantum sensing of microwave electric fields with Rydberg atoms. Then an overview of this very active research direction is gradually expanded, covering progresses of sensitivity and bandwidth in Rydberg atoms based microwave sensing, superheterodyne quantum sensing with microwave-dressed Rydberg atoms, quantum-enhanced sensing of microwave electric field, recent advanced quantum measurement systems and approaches to further improve the performance of microwave electric field sensing. Finally, a brief outlook on future development directions is discussed.",[''],[]
"E-commerce platforms usually present an ordered list, mixed with several organic items and an advertisement, in response to each user’s page view request. This list, the outcome of ad auction and allocation processes, directly impacts the platform’s ad revenue and gross merchandise volume (GMV). Specifically, the ad auction determines which ad is displayed and the corresponding payment, while the ad allocation decides the display positions of the advertisement and organic items. The prevalent methods of segregating the ad auction and allocation into two distinct stages face two problems: 1) Ad auction does not consider externalities, such as the influence of actual display position and context on ad Click-Through Rate (CTR); 2) The ad allocation, which utilizes the auction-winning ad’s payment to determine the display position dynamically, fails to maintain incentive compatibility (IC) for the advertisement. For instance, in the auction stage employing the traditional Generalized Second Price (GSP) , even if the winning ad increases its bid, its payment remains unchanged. This implies that the advertisement cannot secure a better position and thus loses the opportunity to achieve higher utility in the subsequent ad allocation stage. Previous research often focused on one of the two stages, neglecting the two-stage problem, which may result in suboptimal outcomes.

Therefore, this paper proposes a deep automated mechanism that integrates ad auction and allocation, ensuring both IC and Individual Rationality (IR) in the presence of externalities while maximizing revenue and GMV. The mechanism takes candidate ads and the ordered list of organic items as input. For each candidate ad, several candidate allocations are generated by inserting the ad in different positions of the ordered list of organic items. For each candidate allocation, a list-wise model takes the entire allocation as input and outputs the predicted result for each ad and organic item to model the global externalities. Finally, an automated auction mechanism, modeled by deep neural networks, is executed to select the optimal allocation. Consequently, this mechanism simultaneously decides the ranking, payment, and display position of the ad. Furthermore, the proposed mechanism results in higher revenue and GMV than state-of-the-art baselines in offline experiments and online A/B tests.","['Automated', 'Mechanism', 'Design,', 'Ad', 'Auction,', 'Externalities,', 'Ad', 'Allocation']","['MeituanBeijingChina', 'MeituanBeijingChina', 'MeituanBeijingChina', 'MeituanBeijingChina', 'MeituanBeijingChina', 'MeituanBeijingChina']"
"The back-end module of Distributed Collaborative Simultaneous Localization and Mapping (DCSLAM) requires solving a nonlinear Pose Graph Optimization (PGO) under a distributed setting, also known as S⁢E⁢(d)𝑆𝐸𝑑SE(d)italic_S italic_E ( italic_d )-synchronization.
Most existing distributed graph optimization algorithms employ a simple sequential partitioning scheme, which may result in unbalanced subgraph dimensions due to the different geographic locations of each robot, and hence imposes extra communication load.
Moreover, the performance of current Riemannian optimization algorithms can be further accelerated.
In this letter, we propose a novel distributed pose graph optimization algorithm combining multi-level partitioning with an accelerated Riemannian optimization method.
Firstly, we employ the multi-level graph partitioning algorithm to preprocess the naive pose graph to formulate a balanced optimization problem.
In addition, inspired by the accelerated coordinate descent method, we devise an Improved Riemannian Block Coordinate Descent (IRBCD) algorithm and the critical point obtained is globally optimal.
Finally, we evaluate the effects of four common graph partitioning approaches on the correlation of the inter-subgraphs, and discover that the Highest scheme has the best partitioning performance.
Also, we implement simulations to quantitatively demonstrate that our proposed algorithm outperforms the state-of-the-art distributed pose graph optimization protocols111We make the code available at https://github.com/tjcunhao/distributed-pose-graph..","['Index', 'Terms: ', 'Distributed', 'Pose', 'Graph', 'Optimization ,', 'Graph', 'Partitioning ,', 'CSLAM ,', 'Accelerated', 'Riemannian', 'Optimization']",[]
"We describe how the spin Hall effect (SHE) can be studied from ab-initio by combining
density functional theory with the non-equilibrium Green’s functions technique for quantum
transport into the so-called DFT+NEGF method. After laying down our theoretical approach,
in particular discussing how to compute charge and spin bond currents, DFT+NEGF calculations
are carried out for ideal clean systems. In these the transport is ballistic and the linear
response limit is met. The SHE emerges in a central region attached to two leads when we apply
a bias voltage so that electrons are accelerated by a uniform electric field. As a result, we
obtain a finite spin-Hall current and, by performing a scaling analysis with respect to the
system size, we estimate the “ballistic” spin Hall conductivity (SHC). We consider 5⁢d5𝑑5d5 italic_d
metals with fcc and bcc crystal structures, finding that the SHC exhibits a rough qualitative
dependence on the d𝑑ditalic_d-band filling, and comment on these results in relation to existing
literature. Finally, within the same DFT+NEGF approach, we also predict the appearance of
a current-induced spin dipole moment inside the materials’ unit cell and estimate its magnitude.",[''],"['Ireland', 'Ireland', 'Spain', 'Spain', 'Spain', 'Ireland', 'Ireland']"
"Object detection models represented by YOLO series have been widely used and have achieved great results on the high quality datasets, but not all the working conditions are ideal. To settle down the problem of locating targets on low quality datasets, the existing methods either train a new object detection network, or need a large collection of low-quality datasets to train. However, we propose a framework in this paper and apply it on the YOLO models called DiffYOLO. Specifically, we extract feature maps from the denoising diffusion probabilistic models to enhance the well-trained models, which allows us fine-tune YOLO on high-quality datasets and test on low-quality datasets. The results proved this framework can not only prove the performance on noisy datasets, but also prove the detection results on high-quality test datasets. We will supplement more experiments later (with various datasets and network architectures).",[''],[]
"Recently, Maurice Chayet and Skip Garibaldi introduced a class of commutative non-associative algebras.
In previous work, we gave an explicit description of these algebras for groups of type G2,F4subscript𝐺2subscript𝐹4G_{2},F_{4}italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT and certain forms of E6subscript𝐸6E_{6}italic_E start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT in terms of octonion and Albert algebras. In this paper, we extend this further by dealing with E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT in terms of generalised Freudenthal triple systems.","['Key words and phrases: non-associative algebras, exceptional groups,', 'Lie algebras,', 'Frobenius algebras,', 'E7']",[]
,[''],[]
"Diffusion Magnetic Resonance Imaging (dMRI) plays a crucial role in the noninvasive investigation of tissue microstructural properties and structural connectivity in the in vivo human brain. However, to effectively capture the intricate characteristics of water diffusion at various directions and scales, it is important to employ comprehensive q-space sampling. Unfortunately, this requirement leads to long scan times, limiting the clinical applicability of dMRI. To address this challenge, we propose SSOR, a Simultaneous q-Space sampling Optimization and Reconstruction framework.
We jointly optimize a subset of q-space samples using a continuous representation of spherical harmonic functions and a reconstruction network. Additionally, we integrate the unique properties of diffusion magnetic resonance imaging (dMRI) in both the q-space and image domains by applying l⁢1𝑙1l1italic_l 1-norm and total-variation regularization.The experiments conducted on HCP data demonstrate that SSOR has promising strengths both quantitatively and qualitatively and exhibits robustness to noise.",[''],[]
"We present enhanced sensing of radio frequency (RF) electric fields (E-fields) by the combined polarizability of Rydberg atoms and the optimized local oscillator (LO) fields of supergheterodyne receiving. Our modified theoretical model reveals the dependencies of sensitivity of E-field amplitude measurement on the polarizability of Rydberg states and the strength of the LO RF field. The enhanced sensitivity of megahertz(MHz) E-field are demonstrated at an optimal LO field for three different Rydberg states 43⁢D5/243subscriptD52\rm 43D_{5/2}43 roman_D start_POSTSUBSCRIPT 5 / 2 end_POSTSUBSCRIPT, 60⁢S1/260subscriptS12\rm 60S_{1/2}60 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT, and 90⁢S1/290subscriptS12\rm 90S_{1/2}90 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT. The sensitivity of 63 MHz for the 90⁢S1/290subscriptS12\rm 90S_{1/2}90 roman_S start_POSTSUBSCRIPT 1 / 2 end_POSTSUBSCRIPT state reaches 0.96 μ⁢V/cm/Hz𝜇VcmHz\mu\rm V/cm/\sqrt{Hz}italic_μ roman_V / roman_cm / square-root start_ARG roman_Hz end_ARG that is about an order of magnitude higher than those already published. This result closely approaches the theoretical sensitivity limit of RF dipole antennas, and indicates the potential for breaking the limit in measuring sub-MHz E-fields. This atomic sensor based on Rydberg Stark effect with heterodyne technique is expected to boost an alternative solution to electric dipole antennas.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'zlj@sxu.edu.cn', 'China', 'China', 'China', 'China']"
"We show that any pair of Hadamard subfactors arising from complex Hadamard matrices of order 3333 are either equal or inner conjugate. If the pair of Hadamard subfactors are distinct, their intersection is shown to be a subfactor of the hyperfinite type I⁢I1𝐼subscript𝐼1II_{1}italic_I italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT factor R𝑅Ritalic_R. We compute its first relative commutant and characterize this subfactor by identifying it with a vertex model subfactor of the Krishnan-Sunder type. A few key invariants, including the Pimsner-Popa probabilistic number, the angle, and the Connes-Størmer relative entropy for the pair of Hadamard subfactors are computed to understand their relative position.",[''],[]
"The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. Authors are advised to check the author instructions for the journal they are submitting to for word limits and if structural elements like subheadings, citations, or equations are permitted.",[''],"['*', '[', '[']"
"Generative artificial intelligence (GenAI) offers various services to users through content creation, which is believed to be one of the most important components in future networks.
However, training and deploying big artificial intelligence models (BAIMs) introduces substantial computational and communication overhead.
This poses a critical challenge to centralized approaches, due to the need of high-performance computing infrastructure and the reliability, secrecy and timeliness issues in long-distance access of cloud services.
Therefore, there is an urging need to decentralize the services, partly moving them from the cloud to the edge and establishing native GenAI services to enable private, timely, and personalized experiences.
In this paper, we propose a brand-new bottom-up BAIM architecture with synergetic big cloud model and small edge models, and design a distributed training framework and a task-oriented deployment scheme for efficient provision of native GenAI services. The proposed framework can facilitate collaborative intelligence, enhance adaptability, gather edge knowledge and alleviate edge-cloud burden.
The effectiveness of the proposed framework is demonstrated through an image generation use case. Finally, we outline fundamental research directions to fully exploit the collaborative potential of edge and cloud for native GenAI and BAIM applications.","['Index', 'Terms: ', 'Generative', 'AI, big', 'AI model, cloud-edge collaboration.']",[]
"While Transformer-based pre-trained language models and their variants exhibit strong semantic representation capabilities, the question of comprehending the information gain derived from the additional components of PLMs remains an open question in this field.
Motivated by recent efforts that prove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture capabilities, even outperforming Graph Neural Networks (GNNs),
this paper aims to quantify whether simple MLPs can further enhance the already potent ability of PLMs to capture linguistic information.
Specifically, we design a simple yet effective probing framework containing MLPs components based on BERT structure and conduct extensive experiments encompassing 10 probing tasks spanning three distinct linguistic levels.
The experimental results demonstrate that MLPs can indeed enhance the comprehension of linguistic structure by PLMs.
Our research provides interpretable and valuable insights into crafting variations of PLMs utilizing MLPs for tasks that emphasize diverse linguistic structures.",[''],[]
"UDIL (unified descriptive intensional logic) aims to be an alternative and improved version of Bealer’s logic111for an introduction see [25, 9] (but see the present work for a correction regarding the generalization rule for T2). fulfilling the goal of unifying Bealer’s systems T1 and T2 together with adding features to deal with definite descriptions and singular terms and their related philosophical problems (there are interesting connections to Zalta’s more restricted parallel second-order version in his book Axiomatic Metaphysics). UDIL also allows a much shorter and transparent proof of soundness, in particular with regards to a notoriously difficult preliminary lemma. UDIL stands out as being both formally and philosophically distinct from mainstream approaches to intensionality. One motivation for UDIL is to contribute to the Leibnizean goal of a formal philosophy, that is, a philosophy in which arguments and proofs are carried out entirely within a formal system. 03B65(Primary) 03B45, 03B42, 03A05 (Secondary).",[''],[]
,[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Korea']"
,[''],[]
"A family of two-unitary complex Hadamard matrices (CHM) stemming from a particular matrix,
of size 36363636 is constructed.
Every matrix in this orbit remains unitary after operations of
partial transpose and reshuffling which makes it
a distinguished subset of CHM.
It provides a novel solution to the quantum version of the Euler
problem, in which each field of the Graeco-Latin square of size six contains a symmetric
superposition of all 36363636 officers with phases being multiples of
sixth root of unity. This simplifies previously known solutions
as all amplitudes of the superposition are equal and the set of phases
consists of 6666 elements only. Multidimensional parameterization
allows for more flexibility in a potential experimental treatment.",[''],[]
"This work is concerned with numerical simulation of water freezing
and thawing at pore scale, resolving the complex three-dimensional
geometry of the porous medium. The used model of a porous structure
represents a container partially filled with spherical glass beads.
It has been created artificially by simulation of spheres gradually
falling into the container and organizing themselves due to gravity
and mutual collisions. For this purpose, an original model has been
developed, based on particle interaction forces exponentially decreasing
with distance . This model allows for accurate simulation of collisions
with the coefficient of restitution anywhere between zero and one.
The implementation is notably simple as it employs readily available
high order ODE solvers with time step adaptivity, resolving the moments
of collision in a natural way. For the modeling of the freezing and
thawing processes, two approaches have been utilized: The phase field
approach has been compared to the more simple solution of the heat
equation in a heterogeneous medium, with phase transitions focusing
based on temperature. The phase field approach considers the effects
of surface tension leading to premelting, whereas the simplified model
assumes that surface tension is neglected. The formulation of both
models contains novel components tailored for the given situation.
Their numerical solution has been implemented using an efficient hybrid
parallel algorithm based on the finite volume method and the Runge-Kutta-Merson
solver with adaptive time stepping. Qualitative comparison of the
results of both phase transition modeling approaches is performed
and the influence of surface tension is analyzed. Numerical stability,
accuracy, and computational costs are also discussed.",[''],[]
"In extremely large-scale multiple input multiple output (XL-MIMO) systems for future sixth-generation (6G) communications, codebook-based beam training stands out as a promising technology to acquire channel state information (CSI). Despite their effectiveness, when the pilot overhead is limited, existing beam training methods suffer from significant achievable rate degradation for remote users with low signal-to-noise ratio (SNR). To tackle this challenge, leverging the error-correcting capability of channel codes, we introduce channel coding theory into hierarchical beam training to extend the coverage area. Specifically, we establish the duality between hierarchical beam training and channel coding, and the proposed coded beam training scheme serves as a general framework. Then, we present two specific implementations exemplified by coded beam training methods based on Hamming codes and convolutional codes, during which the beam encoding and decoding processes are refined respectively to better accommodate to the beam training problem. Simulation results have demonstrated that, the proposed coded beam training method can enable reliable beam training performance for remote users with low SNR, while keeping training overhead low.","['Index', 'Terms: ', 'Beam training, channel codes, hierarchical codebook, convolutional codes,', 'Hamming codes.']",[]
"Many RGBT tracking researches primarily focus on modal fusion design, while overlooking the effective handling of target appearance changes. While some approaches have introduced historical frames or fuse and replace initial templates to incorporate temporal information, they have the risk of disrupting the original target appearance and accumulating errors over time. To alleviate these limitations, we propose a novel Transformer RGBT tracking approach, which mixes spatio-temporal multimodal tokens from the static multimodal templates and multimodal search regions in Transformer to handle target appearance changes, for robust RGBT tracking. We introduce independent dynamic template tokens to interact with the search region, embedding temporal information to address appearance changes, while also retaining the involvement of the initial static template tokens in the joint feature extraction process to ensure the preservation of the original reliable target appearance information that prevent deviations from the target appearance caused by traditional temporal updates. We also use attention mechanisms to enhance the target features of multimodal template tokens by incorporating supplementary modal cues, and make the multimodal search region tokens interact with multimodal dynamic template tokens via attention mechanisms, which facilitates the conveyance of multimodal-enhanced target change information. Our module is inserted into the transformer backbone network and inherits joint feature extraction, search-template matching, and cross-modal interaction. Extensive experiments on three RGBT benchmark datasets show that the proposed approach maintains competitive performance compared to other state-of-the-art tracking algorithms while running at 39.1 FPS.","['Index', 'Terms: ', 'RGBT tracking,', 'Transformer,', 'Cross-modal interaction,', 'Spatio-Temporal', 'Multimodal', 'Tokens.']",[]
,[''],"['Austria', 'Netherlands']"
"The availability of the Global Positioning System (GPS) trajectory data is increasing along with the availability of different GPS receivers and with the increasing use of various mobility services. GPS trajectory is an important data source which is used in traffic density detection, transport mode detection, mapping data inferences with the use of different methods such as image processing and machine learning methods. While the data size increases, efficient representation of this type of data is becoming difficult to be used in these methods. A common approach is the representation of GPS trajectory information such as average speed, bearing, etc. in raster image form and applying analysis methods. In this study, we evaluate GPS trajectory data rasterization using the spatial join functions of QGIS, PostGIS+QGIS, and our iterative spatial structured grid aggregation implementation coded in the Python programming language. Our implementation is also parallelizable, and this parallelization is also included as the fourth method. According to the results of experiment carried out with an example GPS trajectory dataset, QGIS method and PostGIS+QGIS method showed relatively low performance with respect to our method using the metric of total processing time. PostGIS+QGIS method achieved the best results for spatial join though its total performance decreased quickly while test area size increases. On the other hand, both of our methods’ performances decrease directly proportional to GPS point. And our methods’ performance can be increased proportional to the increase with the number of processor cores and/or with multiple computing clusters.","['Rasterization,', 'GPS trajectory,', 'Data aggregation,', 'Spatial join,', 'Parallelization']",[]
We investigate the Hardy and Rellich inequalities for classes of antisymmetric and odd functions and general exponent p𝑝pitalic_p. The obtained constants are better than the classical ones.,"['Key words and phrases:', 'Hardy inequality,', 'Rellich inequality, antisymmetric function, odd function, weight']",[]
"Classical spin systems with non-coplanar ground states typically exhibit nonlinear magnetization curves characterized by kinks and jumps. Our article briefly summarizes the most important related analytical results. In a comprehensive case study, we then address AF-square kagomé and AF/FM-square kagomé spin lattices equipped with additional cross-plaquette interactions. It is known that these systems have non-coplanar ground states that assume a cuboctahedral structure in the absence of a magnetic field. When a magnetic field H𝐻Hitalic_H is switched on, a rich variety of different phases develops from the cuboctahedral ground state, which are studied in their dependence on H𝐻Hitalic_H and a cross-plaquette coupling constant J3>0subscript𝐽30J_{3}>0italic_J start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0.
For the AF square-kagomé spin lattice, we carefully identify and describe seven phases that appear in a phase diagram with five triple points. The transitions between these phases are predominantly discontinuous, although two cases exhibit continuous transitions. In contrast, the phase diagram of the AF/FM square-kagomé
model shows only four phases with a single triple point,
but these also lead to exotic magnetization curves.
Here, too, there are two types of phase boundaries belonging to continuous and discontinuous transitions.",[''],"['Germany.', 'Germany', 'Germany']"
,[''],[]
"In
this paper we would like to introduce some new methods for studying magic type-colorings of graphs or domination of graphs, based on combinatorial
spectrum on polynomial rings. We hope that this concept will be potentially
useful for the graph theorists.",[''],[]
"For integers k≥1𝑘1k\geq 1italic_k ≥ 1 and n≥2⁢k+1𝑛2𝑘1n\geq 2k+1italic_n ≥ 2 italic_k + 1, the Schrijver graph S⁢(n,k)𝑆𝑛𝑘S(n,k)italic_S ( italic_n , italic_k ) has as vertices all k𝑘kitalic_k-element subsets of [n]:={1,2,…,n}assigndelimited-[]𝑛12…𝑛[n]:=\{1,2,\ldots,n\}[ italic_n ] := { 1 , 2 , … , italic_n } that contain no two cyclically adjacent elements, and an edge between any two disjoint sets.
More generally, for integers k≥1𝑘1k\geq 1italic_k ≥ 1, s≥2𝑠2s\geq 2italic_s ≥ 2, and n≥s⁢k+1𝑛𝑠𝑘1n\geq sk+1italic_n ≥ italic_s italic_k + 1, the s𝑠sitalic_s-stable Kneser graph S⁢(n,k,s)𝑆𝑛𝑘𝑠S(n,k,s)italic_S ( italic_n , italic_k , italic_s ) has as vertices all k𝑘kitalic_k-element subsets of [n]delimited-[]𝑛[n][ italic_n ] in which any two elements are in cyclical distance at least s𝑠sitalic_s.
We prove that all the graphs S⁢(n,k,s)𝑆𝑛𝑘𝑠S(n,k,s)italic_S ( italic_n , italic_k , italic_s ), in particular Schrijver graphs S⁢(n,k)=S⁢(n,k,2)𝑆𝑛𝑘𝑆𝑛𝑘2S(n,k)=S(n,k,2)italic_S ( italic_n , italic_k ) = italic_S ( italic_n , italic_k , 2 ), admit a Hamilton cycle that can be computed in time 𝒪⁢(n)𝒪𝑛{\mathcal{O}}(n)caligraphic_O ( italic_n ) per generated vertex.",[''],[]
"The diagrammatic theory of strongly correlated systems includes two types of
selfconsistent perturbative analysis: ΦΦ\Phiroman_Φ derivability, or conserving
approximations, and iterative parquet theory. Becker and Grosser
[W. Becker and D. Grosser, Nuov. Cim. A 10, 343 (1972)]
first showed that crossing symmetry and elastic unitarity (conservation)
could not both be satisfied in any approximation to the two-particle
Bethe-Salpeter equation for the transition matrix. Jackson and Smith
[A. D. Jackson and R. A. Smith, Phys. Rev. A 36, 2517 (1987)],
later proved in particular that, despite their close affinity,
ΦΦ\Phiroman_Φ derivability and parquet are fundamentally irreconcilable.
Parquet theory computes the two-body scattering amplitude,
respecting its crossing symmetry. ΦΦ\Phiroman_Φ derivability computes the
nonequilibrium one-body dynamics, respecting conservation in the two-body
response. Parquet cannot safeguard conservation and ΦΦ\Phiroman_Φ derivability
cannot guarantee crossing symmetry, yet both are physical requirements. We
investigate these “failure modes” within a generalized Hamiltonian
approach. The two methods’ respective relation to the exact ground state
sheds light on their complementary shortcomings.",[''],['Australia']
,[''],[]
"In the last years, social media has gained an unprecedented amount of attention, playing a pivotal role in shaping the contemporary landscape of communication and connection. However, Coordinated Inhautentic Behaviour (CIB), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, has emerged as a tactic to exploit the online discourse.
In this study, we quantify the efficacy of CIB tactics by defining a general framework for evaluating the influence of a subset of nodes in a directed tree.
We design two algorithms that provide optimal and greedy post-hoc placement strategies that lead to maximising the configuration influence.
We then consider cascades from information spreading on Twitter to compare the observed behaviour with our algorithms.
The results show that, according to our model, coordinated accounts are quite inefficient in terms of their network influence, thus suggesting that they may play a less pivotal role than expected.
Moreover, the causes of these poor results may be found in two separate aspects: a bad placement strategy and a scarcity of resources.","['Trees,', 'Influence,', 'Coordinated', 'Inhautentic', 'Behaviour']","['295RomaItaly', 'SienaSienaItaly', '295RomaItaly', '295RomaItaly']"
,[''],[]
"Online contextual reasoning and association across consecutive video frames are critical to perceive instances in visual tracking. However, most current top-performing trackers persistently lean on sparse temporal relationships between reference and search frames via an offline mode. Consequently, they can only interact independently within each image-pair and establish limited temporal correlations. To alleviate the above problem, we propose a simple, flexible and effective video-level tracking pipeline, named ODTrack, which densely associates the contextual relationships of video frames in an online token propagation manner. ODTrack receives video frames of arbitrary length to capture the spatio-temporal trajectory relationships of an instance, and compresses the discrimination features (localization information) of a target into a token sequence to achieve frame-to-frame association. This new solution brings the following benefits: 1) the purified token sequences can serve as prompts for the inference in the next video frame, whereby past information is leveraged to guide future inference; 2) the complex online update strategies are effectively avoided by the iterative propagation of token sequences, and thus we can achieve more efficient model representation and computation. ODTrack achieves a new SOTA performance on seven benchmarks, while running at real-time speed.
Code and models are available at https://github.com/GXNU-ZhongLab/ODTrack.",[''],[]
"The aim of this paper is to derive explicit formulas
for two distinct values. The first is the total number of symmetric peaks in a set partition of [n]delimited-[]𝑛[n][ italic_n ]
with exactly k𝑘kitalic_k blocks, and the second one is the total number of non-symmetric peaks in a set partition of [n]delimited-[]𝑛[n][ italic_n ]
with exactly k𝑘kitalic_k blocks. We represent these results in two ways. First by using the theory of generating functions,
and the second by using combinatorial tools.
Keywords: Symmetric peaks, Non-symmetric peaks, Set partitions and Generating functions.",[''],[]
"Let (X,ω)𝑋𝜔(X,\omega)( italic_X , italic_ω ) be a compact Kähler manifold and θ𝜃\thetaitalic_θ be a smooth closed real (1,1)11(1,1)( 1 , 1 )-form that represents a big cohomology class. In this paper, we show that for p≥1𝑝1p\geq 1italic_p ≥ 1, the high energy space ℰp⁢(X,θ)superscriptℰ𝑝𝑋𝜃\mathcal{E}^{p}(X,\theta)caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) can be endowed with a metric dpsubscript𝑑𝑝d_{p}italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT that makes (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) a complete geodesic metric space. The weak geodesics in ℰp⁢(X,θ)superscriptℰ𝑝𝑋𝜃\mathcal{E}^{p}(X,\theta)caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) are the metric geodesic for (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ). Moreover, for p>1𝑝1p>1italic_p > 1, the geodesic metric space (ℰp⁢(X,θ),dp)superscriptℰ𝑝𝑋𝜃subscript𝑑𝑝(\mathcal{E}^{p}(X,\theta),d_{p})( caligraphic_E start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_θ ) , italic_d start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) is uniformly convex.","['Key words and phrases:', 'Kähler', 'Manifolds,', 'Pluripotential', 'Theory,', 'Monge-Ampère', 'Measures,', 'Finite', 'Energy', 'Classes']",[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
"Possible forms of black hole images, viewed by a distant observer, are calculated basing on general relativity and equations of motion in the Kerr-Newman metric. Black hole image is a gravitationally lensed image of the black hole event horizon. It may be viewed as a black spot on the celestial sphere, projected inside the position of classical black hole shadow. In the nearest future it would be possible to verify modified gravity theories by observations of astrophysical black hole with Space Observatory Millimetron.",[''],"['Russia', 'Russia']"
"For a
modulus of continuity ω𝜔\omegaitalic_ω
and Banach spaces X,Y𝑋𝑌X,Yitalic_X , italic_Y we introduce and study the subspaces VC˙Υ0,ω⁢(X,Y)subscriptsuperscript˙VC0𝜔Υ𝑋𝑌\dot{\operatorname{VC}}^{0,\omega}_{\Upsilon}(X,Y)over˙ start_ARG roman_VC end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( italic_X , italic_Y ) of vanishing scales Υ∈{small,large,far}Υsmalllargefar\Upsilon\in\{\operatorname{small},\operatorname{large},\operatorname{far}\}roman_Υ ∈ { roman_small , roman_large , roman_far } of the homogeneous Hölder space C˙0,ω⁢(X,Y).superscript˙𝐶0𝜔𝑋𝑌\dot{C}^{0,\omega}(X,Y).over˙ start_ARG italic_C end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT ( italic_X , italic_Y ) .
For a wide class of couples X𝑋Xitalic_X and Y𝑌Yitalic_Y, we characterize the subspaces of functions approximable by smooth and Lipschitz and boundedly supported functions in terms of these three vanishing scales.
In the particular case X=ℝn,𝑋superscriptℝ𝑛X=\mathbb{R}^{n},italic_X = blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , we identify the spaces VC˙Υ0,ω⁢(ℝn,Y)subscriptsuperscript˙VC0𝜔Υsuperscriptℝ𝑛𝑌\dot{\operatorname{VC}}^{0,\omega}_{\Upsilon}(\mathbb{R}^{n},Y)over˙ start_ARG roman_VC end_ARG start_POSTSUPERSCRIPT 0 , italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_Y ) with the corresponding vanishing mean oscillation spaces VMOΥω⁢(ℝn,Y)subscriptsuperscriptVMO𝜔Υsuperscriptℝ𝑛𝑌\mathrm{VMO}^{\omega}_{\Upsilon}(\mathbb{R}^{n},Y)roman_VMO start_POSTSUPERSCRIPT italic_ω end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Υ end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_Y ), thus providing a proof for the density of test functions also on these spaces.","['Key words and phrases: smooth approximation, vanishing mean oscillation,', 'Hölder spaces,', 'Banach spaces']",[]
,[''],[]
,[''],[]
"Language similarities can be caused by genetic relatedness, areal contact, universality, or chance.
Colexification, i.e. a type of similarity where a single lexical form is used to convey multiple meanings, is underexplored. In our work, we shed light on the linguistic causes of cross-lingual similarity in colexification and phonology, by exploring genealogical stability (persistence) and contact-induced change (diffusibility). We construct large-scale graphs incorporating semantic, genealogical, phonological and geographical data for 1,966 languages.
We then show the potential of this resource, by investigating several established hypotheses from previous work in linguistics, while proposing new ones.
Our results strongly support a previously established hypothesis in the linguistic literature, while offering contradicting evidence to another.
Our large scale resource opens for further research across disciplines, e.g. in multilingual NLP and comparative linguistics.",[''],[]
,[''],[]
"The Tulczyjew triple on a principal bundle with connection is constructed in a convenient trivialisation. A reduction by the structure group is performed leading to the triple on the trivialised Atiyah algebroid and a presentation of this algebroid via a double vector bundle morphism. The dynamics of physical systems with configuration manifolds having the structure of a principal bundle with connection or the Atiyah algebroid is discussed and applied to the example of an axially symmetric body confined to a sphere.
Keywords: Hamiltonian mechanics, Lagrangian mechanics, Tulczyjew triple, Ehresmann connection Lie Algebroid
MSC: 22E70, 53D05, 53Z05, 70E17, 70H33.",[''],[]
"Large languages models (LLMs) trained on datasets of publicly available source code have established a new state-of-the-art in code completion.
However, these models are mostly unaware of the code that already exists within a specific project, preventing the models from making good use of existing APIs.
Instead, LLMs often invent, or “hallucinate”, non-existent APIs or produce variants of already existing code.
Although the API information is available to IDEs, the input size limit of LLMs prevents code completion techniques from including all relevant context into the prompt.
This paper presents De-Hallucinator, an LLM-based code completion technique that grounds the predictions of a model through a novel combination of retrieving suitable API references and iteratively querying the model with increasingly suitable context information in the prompt.
The approach exploits the observation that LLMs often predict code that resembles the desired completion, but that fails to correctly refer to already existing APIs.
De-Hallucinator automatically identifies project-specific API references related to the code prefix and to the model’s initial predictions and adds these references into the prompt.
Our evaluation applies the approach to the task of predicting API usages in open-source Python projects.
We show that De-Hallucinator consistently improves the predicted code across four state-of-the-art LLMs compared to querying the model only with the code before the cursor.
In particular, the approach improves the edit distance of the predicted code by 23–51% and the recall of correctly predicted API usages by 24–61% relative to the baseline.",[''],"['StuttgartStuttgartGermany', 'StuttgartStuttgartGermany']"
"We present Image Sculpting, a new framework for editing 2D images by incorporating tools from 3D geometry and graphics. This approach differs markedly from existing methods, which are confined to 2D spaces and typically rely on textual instructions, leading to ambiguity and limited control. Image Sculpting converts 2D objects into 3D, enabling direct interaction with their 3D geometry. Post-editing, these objects are re-rendered into 2D, merging into the original image to produce high-fidelity results through a coarse-to-fine enhancement process. The framework supports precise, quantifiable, and physically-plausible editing options such as pose editing, rotation, translation, 3D composition, carving, and serial addition. It marks an initial step towards combining the creative freedom of generative models with the precision of graphics pipelines.††   Code and project page available here.",[''],[]
"The braiding operations of quantum states have attracted substantial attention due to their great potential for realizing topological quantum computations. In this paper, we show that a three-fold degenerate eigen subspace can be obtained in a four-level Hamiltonian which is the minimal physical system. Braiding operations are proposed to apply to dressed states in the subspace. The topology of the braiding diagram can be characterized through physical methods once that the sequential braiding pulses are adopted. We establish an equivalent relationship function between the permutation group and the output states where different output states correspond to different values of the function. The topological transition of the braiding happens when two operations overlap, which is detectable through the measurement of the function. Combined with the phase variation method, we can analyze the wringing pattern of the braiding. Therefore, the experimentally-feasible system provides a platform to investigate braiding dynamics, the SU(3) physics and the qutrit gates.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"This paper focuses
on the initial boundary value problem of two-dimensional non-resistive MHD equations in a half space. We prove that the MHD equations have a unique global strong solution around the equilibrium state (0,𝐞𝟏)0subscript𝐞1(0,\bf{e_{1}})( 0 , bold_e start_POSTSUBSCRIPT bold_1 end_POSTSUBSCRIPT ) for Dirichlet boundary condition of velocity and modified Neumann boundary condition of magnetic.

MSC: 35A01; 35Q30; 76D05

Key words: Non-resistive MHD,
  Global regularity,  Asymptotic estimates,  Half space",[''],[]
"The present work shows the correspondence between f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity and a dual scalar-tensor theory (with an antisymmetric tensor field) when the affine connection is considered to have an antisymmetric part. It turns out that the f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) action in presence of spacetime torsion can be recast to a n⁢o⁢n−m⁢i⁢n⁢i⁢m⁢a⁢l⁢l⁢y𝑛𝑜𝑛𝑚𝑖𝑛𝑖𝑚𝑎𝑙𝑙𝑦non-minimallyitalic_n italic_o italic_n - italic_m italic_i italic_n italic_i italic_m italic_a italic_l italic_l italic_y coupled scalar-tensor theory with a 2-rank massless antisymmetric tensor field in the Einstein frame, where the scalar field gets coupled with the antisymmetric field through derivative coupling(s).",[''],['Russia']
"We present a theoretical study of the medium modifications on the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT balance (xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT) of dijets in Xe+Xe collisions at sNN=5.44subscript𝑠NN5.44\sqrt{s_{\rm NN}}=5.44square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 5.44 TeV.
The initial production of dijets is carried out by the POWHEG+PYTHIA8 prescription, which matches the next-to-leading order (NLO) QCD matrix elements with the parton shower (PS) effect. The in-medium evolution in nucleus-nucleus collisions is described by the SHELL model with a transport approach. The theoretical results of the dijet xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT in Xe+Xe collisions exhibit more imbalanced distributions than that in p+p, consistent with the recently reported ATLAS data. By utilizing the Interleaved Flavor Neutralisation, an infrared-and-collinear-safe jet flavor algorithm, to identify the flavor of the reconstructed jets, we classify dijets processes into three categories: gluon-gluon (g⁢g𝑔𝑔ggitalic_g italic_g), quark-gluon (q⁢g𝑞𝑔qgitalic_q italic_g) and quark-quark (q⁢q𝑞𝑞qqitalic_q italic_q), and investigate the respective medium modification patterns and fraction changes of the g⁢g𝑔𝑔ggitalic_g italic_g, q⁢g𝑞𝑔qgitalic_q italic_g, and q⁢q𝑞𝑞qqitalic_q italic_q components of the dijet sample in Xe+Xe collisions. It is shown that the q⁢g𝑞𝑔qgitalic_q italic_g component plays a key role in the increased imbalance of the dijet xJsubscript𝑥Jx_{\rm J}italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT, and especially the q1⁢g2subscript𝑞1subscript𝑔2q_{1}g_{2}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (quark-jet-leading) dijets experience more significant asymmetric energy loss than the g1⁢q2subscript𝑔1subscript𝑞2g_{1}q_{2}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (gluon-jet-leading) dijets as traversing the QGP. By comparing the Δ⁢⟨xJ⟩Δdelimited-⟨⟩subscript𝑥J\Delta\langle x_{\rm J}\rangleroman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ of inclusive, c⁢c¯𝑐¯𝑐c\bar{c}italic_c over¯ start_ARG italic_c end_ARG and b⁢b¯𝑏¯𝑏b\bar{b}italic_b over¯ start_ARG italic_b end_ARG dijets in Xe+Xe collisions, we observe Δ⁢⟨xJ⟩incl.>Δ⁢⟨xJ⟩c⁢c¯>Δ⁢⟨xJ⟩b⁢b¯Δsubscriptdelimited-⟨⟩subscript𝑥JinclΔsubscriptdelimited-⟨⟩subscript𝑥Jc¯cΔsubscriptdelimited-⟨⟩subscript𝑥Jb¯b\Delta\langle x_{\rm J}\rangle_{\rm incl.}>\Delta\langle x_{\rm J}\rangle_{\rm
c%
\bar{c}}>\Delta\langle x_{\rm J}\rangle_{\rm b\bar{b}}roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_incl . end_POSTSUBSCRIPT > roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_c over¯ start_ARG roman_c end_ARG end_POSTSUBSCRIPT > roman_Δ ⟨ italic_x start_POSTSUBSCRIPT roman_J end_POSTSUBSCRIPT ⟩ start_POSTSUBSCRIPT roman_b over¯ start_ARG roman_b end_ARG end_POSTSUBSCRIPT. Moreover, ρXe,Pbsubscript𝜌XePb\rho_{\rm Xe,Pb}italic_ρ start_POSTSUBSCRIPT roman_Xe , roman_Pb end_POSTSUBSCRIPT, the ratios of nuclear modification factors of dijets in Xe+Xe to that in Pb+Pb, are calcualted, which indicates that the yield suppression of dijets in Pb+Pb is more pronounced than that in Xe+Xe due to the larger radius of the lead nucleus.",[''],"['China', 'China', 'China', 'China']"
"I identify a point-symmetric morphology of the supernova remnant (SNR) G352.7-0.1 and propose that the outer axially-symmetric structure is the remnant of a common envelope evolution (CEE) of the progenitor system, while the inner structure is the ejecta of a thermonuclear explosion triggered by the merger of a white dwarf (WD) and the core of an asymptotic giant branch (AGB) star. The main radio structure of SNR G352.7-0.1 forms an outer (large) ellipse. The bright X-ray emitting gas forms a smaller ellipse with a symmetry axis inclined to the symmetry axis of the large radio ellipse. The high abundance of iron and the energy of its X-ray lines suggest a type Ia supernova (SN Ia). The massive swept-up gas suggests a relatively massive progenitor system. I propose a scenario with progenitors of initial masses of MZAMS,1≃5−7⁢M⊙similar-to-or-equalssubscript𝑀ZAMS157subscript𝑀direct-productM_{\rm ZAMS,1}\simeq 5-7M_{\odot}italic_M start_POSTSUBSCRIPT roman_ZAMS , 1 end_POSTSUBSCRIPT ≃ 5 - 7 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and MZAMS,2≃4−5⁢M⊙similar-to-or-equalssubscript𝑀ZAMS245subscript𝑀direct-productM_{\rm ZAMS,2}\simeq 4-5M_{\odot}italic_M start_POSTSUBSCRIPT roman_ZAMS , 2 end_POSTSUBSCRIPT ≃ 4 - 5 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. At a later phase, the WD remnant of the primary star and the AGB secondary star experience a CEE that ejects the circumstellar material that swept up more ISM to form the large elliptical radio structure. An explosion during the merger of the WD with the core of the AGB star triggered a super-Chandrasekhar thermonuclear explosion that formed the inner structure that is bright in X-ray. A tertiary star in the system caused the misalignment of the two symmetry axes. This study adds to the rich variety of evolutionary routes within the different scenarios of normal and peculiar SNe Ia.","['Type', 'Ia supernovae –', 'Supernova remnants –', 'Common envelope binary stars –', 'Planetary nebulae –', 'Stellar jets']",['soker@physics.technion.ac.il']
"We report on a search for a new Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT (Lμ−Lτsubscript𝐿𝜇subscript𝐿𝜏L_{\mu}-L_{\tau}italic_L start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT - italic_L start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT) vector boson performed at the NA64 experiment employing a high energy muon beam and a missing energy-momentum technique.
Muons from the M2 beamline at the CERN Super Proton Synchrotron with a momentum of 160 GeV/c are directed to an active target. A signal event is a single scattered muon with momentum <<< 80 GeV/c in the final state, accompanied by missing energy, i.e. no detectable activity in the downstream calorimeters.
For a total statistic of (1.98±0.02)×1010plus-or-minus1.980.02superscript1010(1.98\pm 0.02)\times 10^{10}( 1.98 ± 0.02 ) × 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT muons on target, no event is observed in the expected signal region. This allows us to set new limits on part of the remaining (mZ′,gZ′)subscript𝑚superscript𝑍′subscript𝑔superscript𝑍′(m_{Z^{\prime}},\ g_{Z^{\prime}})( italic_m start_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) parameter space which could provide an explanation for the muon (g−2)μsubscript𝑔2𝜇(g-2)_{\mu}( italic_g - 2 ) start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT anomaly. Additionally, our study excludes part of the parameter space suggested by the thermal Dark Matter relic abundance.
Our results pave the way to explore Dark Sectors and light Dark Matter with muon beams in a unique and complementary way to other experiments.",[''],"['CERN', 'Switzerland', 'Switzerland', 'Switzerland', 'Italia', 'Italia', 'Switzerland', 'Switzerland', 'Switzerland', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'Chile', 'Chile', 'Greece', 'CERN', 'Switzerland', 'CERN', 'Chile', 'Germany', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'Germany', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'CERN', 'Chile', 'Chile', 'CERN', 'Chile', 'Chile', 'CERN', 'CERN', 'Chile', 'Chile', 'Chile', 'Chile', 'Spain', 'Switzerland', 'CERN', 'CERN', 'Canada', 'CERN', 'CERN', 'CERN', 'Chile', 'Chile', 'Switzerland', 'CERN', 'CERN', 'CERN', 'Spain', 'Germany', 'CERN', 'CERN', 'CERN', 'Chile', 'Chile', 'CERN']"
,[''],[]
"Out-of-distribution (OOD) detection plays a crucial role in ensuring the security of neural networks. Existing works have leveraged the fact that In-distribution (ID) samples form a subspace in the feature space, achieving state-of-the-art (SOTA) performance. However, the comprehensive characteristics of the ID subspace still leave under-explored. Recently, the discovery of Neural Collapse (𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C) sheds light on novel properties of the ID subspace. Leveraging insight from 𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C, we observe that the Principal Angle between the features and the ID feature subspace forms a superior representation for measuring the likelihood of OOD. Building upon this observation, we propose a novel 𝒩⁢𝒞𝒩𝒞\mathcal{NC}caligraphic_N caligraphic_C-inspired OOD scoring function, named Entropy-enhanced Principal Angle (EPA), which integrates both the global characteristic of the ID subspace and its inner property. We experimentally compare EPA with various SOTA approaches, validating its superior performance and robustness across different network architectures and OOD datasets.",[''],[]
"Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance.",[''],[]
"In this work, we provide a detailed analysis of the issue of encoding of quantum information which is invariant with respect to arbitrary Lorentz transformations. We significantly extend already known results and provide compliments where necessary.
In particular, we introduce novel schemes for invariant encoding which utilize so-called pair-wise helicity – a physical parameter characterizing pairs of electric-magnetic charges. We also introduce new schemes for ordinary massive and massless particles based on states with fixed total momentum, in contrast to all protocols already proposed, which assumed equal momenta of all the particles involved in the encoding scheme.
Moreover, we provide a systematic discussion of already existing protocols and show directly that they are invariant with respect to Lorentz transformations drawn according to any distribution, a fact which was not manifestly shown in previous works.",[''],"['Poland', 'Poland']"
"One class of statistical hypothesis testing procedures is the indisputable equivalence tests, whose main objective is to establish practical equivalence rather than the usual statistical significant difference. These hypothesis tests are prone in “bioequivalence studies,” where one would wish to show that, for example, an existing drug and a new one under development have the same therapeutic effect. In this article, we consider a two-stage randomized (RAND2) p𝑝pitalic_p-value utilizing the uniformly most powerful (UMP) p𝑝pitalic_p-value in the first stage when multiple two-one-sided hypotheses are of interest. We investigate the behavior of the distribution functions of the two p𝑝pitalic_p-values when there are changes in the boundaries of the null or alternative hypothesis or when the chosen parameters are too close to these boundaries. We also consider the behavior of the power functions to an increase in sample size. Specifically, we investigate the level of conservativity to the sample sizes to see if we control the α𝛼\alphaitalic_α level when using either of the two p𝑝pitalic_p-values for any sample size. In multiple tests, we evaluate the performance of the two p𝑝pitalic_p-values in estimating the proportion of true null hypotheses. We conduct a family-wise error rate control using an adaptive Bonferroni procedure with a plug-in estimator to account for the multiplicity that arises from the multiple hypotheses under consideration. We verify the various claims in this research using simulation study and real-world data analysis.",[''],['[']
"In this paper, the sharp quantitative weighted bounds for the iterated commutators of a class of multilinear operators were systematically studied. This class of operators contains multilinear Calderón-Zygmund operators, multilinear Fourier integral operators, and multilinear Littlewood-Paley square operators as its typical examples. These were done only under two pretty much general assumptions of pointwise sparse domination estimates. We first established local decay estimates and quantitative weak A∞subscript𝐴A_{\infty}italic_A start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT decay estimates for iterated commutators of this class of operators. Then, we considered the corresponding Coifman-Fefferman inequalities and the mixed weak type estimates associated with Sawyer’s conjecture. Beyond that, the Fefferman-Stein inequalities with respect to arbitrary weights and weighted modular inequalities were also given. As applications, it was shown that all the conclusions aforementioned can be applied to multilinear ω𝜔\omegaitalic_ω-Calderón-Zygmund operators, multilinear maximal singular integral operators, multilinear pseudo-differential operators, Stein’s square functions, and higher order Calderón commutators.","['Key words and phrases: multilinear operators, iterated commutators, sparse operators, modular inequalities \n2020', 'Mathematics', 'Subject', 'Classification.', 'Primary 42B20,', 'Secondary 42B25.']",[]
"Many-body open quantum systems (OQS) have a profound impact on various subdisciplines of physics, chemistry, and biology. Thus, the development of a computer program capable of accurately, efficiently, and versatilely simulating many-body OQS is highly desirable. In recent years, we have focused on the advancement of numerical algorithms based on the fermionic hierarchical equations of motion (HEOM) theory. Being in-principle exact, this approach allows for the precise characterization of many-body correlations, non-Markovian memory, and non-equilibrium thermodynamic conditions. These efforts now lead to the establishment of a new computer program, HEOM for QUantum Impurity with a Correlated Kernel, version 2 (HEOM-QUICK2), which, to the best of our knowledge, is currently the only general-purpose simulator for fermionic many-body OQS. Compared with version 1, the HEOM-QUICK2 program features more efficient solvers for stationary states, more accurate treatment of non-Markovian memory, and improved numerical stability for long-time dissipative dynamics. Integrated with quantum chemistry software, HEOM-QUICK2 has become a valuable theoretical tool for the precise simulation of realistic many-body OQS, particularly the single atomic or molecular junctions. Furthermore, the unprecedented precision achieved by HEOM-QUICK2 enables accurate simulation of low-energy spin excitations and coherent spin relaxation. The unique usefulness of HEOM-QUICK2 is demonstrated through several examples of strongly correlated quantum impurity systems under non-equilibrium conditions. Thus, the new HEOM-QUICK2 program offers a powerful and comprehensive tool for studying many-body OQS with exotic quantum phenomena and exploring applications in various disciplines.


Key words: open quantum systems; hierarchical equations of motion; non-Markovian dynamics; spin excitation and relaxation; strong electron correlation.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Let k𝑘kitalic_k be a positive integer and let G𝐺Gitalic_G be a graph with n𝑛nitalic_n vertices.
A connected k𝑘kitalic_k-subpartition of G𝐺Gitalic_G is a collection of k𝑘kitalic_k pairwise disjoint sets (a.k.a. classes) of vertices in G𝐺Gitalic_G such that each set induces a connected subgraph.
The connected k𝑘kitalic_k-partition polytope of G𝐺Gitalic_G, denoted by 𝒫⁢(G,k)𝒫𝐺𝑘\mathcal{P}(G,k)caligraphic_P ( italic_G , italic_k ), is defined as the convex hull of the incidence vectors of all connected k𝑘kitalic_k-subpartitions of G𝐺Gitalic_G.
Many applications arising in off-shore oil-drilling, forest planning, image processing, cluster analysis, political districting, police patrolling, and biology are modeled in terms of finding connected (sub)partitions of a graph.
This study focus on the facial structure of 𝒫⁢(G,k)𝒫𝐺𝑘\mathcal{P}(G,k)caligraphic_P ( italic_G , italic_k ) and the computational complexity of the corresponding separation problems.
We first propose a set of valid inequalities having non-null coefficients associated with a single class that extends and generalizes the ones in the literature of related problems, show sufficient conditions for these inequalities to be facet-defining, and design a polynomial-time separation algorithm for them.
We also devise two sets of inequalities that consider multiple classes, prove when they define facets, and study the computational complexity of associated separation problems.",[''],"['hande.yaman}@kuleuven.be', 'hande.yaman}@kuleuven.be', 'hande.yaman}@kuleuven.be']"
,[''],[]
,[''],[]
"We study the spontaneous configuration transitions of an active semi-flexible polymer
between spiral and non-spiral states, and show that
the configuration dynamics is fully described by a subcritical pitchfork bifurcation.
Exploiting the fact that active polymer barely moves in spiral states and exhibits net displacements in non-spiral states, we prove that the motion of the active polymer is consistent with a run-and-tumble-like dynamics.
Moreover, we find that there exists an optimal self-propelling force, at which the probabilities of finding the polymer in the spiral and non-spiral state become equal, that maximizes the diffusion coefficient.",[''],"['Iran.', 'France.', 'Iran.']"
"Monitoring cameras are extensively utilized in industrial production to monitor equipment running. With advancements in computer vision, device recognition using image features is viable. This paper presents a vision-assisted identification system that implements real-time automatic equipment labeling through image matching in surveillance videos. The system deploys the ORB algorithm to extract image features and the GMS algorithm to remove incorrect matching points. According to the principles of clustering and template locality, a method known as Local Adaptive Clustering (LAC) has been established to enhance label positioning. This method segments matching templates using the cluster center, which improves the efficiency and stability of labels. The experimental results demonstrate that LAC effectively curtails the label drift.","['Index', 'Terms: ', 'Image', 'Matching,', 'Local', 'Clustering,', 'Automatic', 'Identification']",['2023200830@mail.buct.edu.cn']
,[''],[]
,[''],[]
"We prove a new determinantal formula for the characters of irreducible representations of orthosymplectic Lie superalgebras analogous to the formula developed by Moens and Jeugt (J. Algebraic Combin., 2003) for general linear Lie superalgebras.
Our proof uses the Jacobi–Trudi type formulas for orthosymplectic characters. As a consequence, we show that
the odd symplectic characters
introduced by Proctor (Invent. Math., 1988)
are the same as the
orthosymplectic characters with some specialized indeterminates.
We also give a generalization of an odd symplectic character identity due to Brent, Krattenthaler and Warnaar (J. Combin. Theory Ser. A, 2016).","['Key words and phrases: orthosymplectic', 'Schur functions, hook', 'Schur polynomials, determinantal formula']",[]
"JPEG is a widely used compression scheme to efficiently reduce the volume of the transmitted images at the expense of visual perception drop. The artifacts appear among blocks due to the information loss in the compression process, which not only affects the quality of images but also harms the subsequent high-level tasks in terms of feature drifting. High-level vision models trained on high-quality images will suffer performance degradation when dealing with compressed images, especially on mobile devices. In recent years, numerous learning-based JPEG artifacts removal methods have been proposed to handle visual artifacts. However, it is not an ideal choice to use these JPEG artifacts removal methods as a pre-processing for compressed image classification for the following reasons: 1) These methods are designed for human vision rather than high-level vision models. 2) These methods are not efficient enough to serve as a pre-processing on resource-constrained devices. To address these issues, this paper proposes a novel lightweight adaptive feature de-drifting module (AFD-Module) to boost the performance of pre-trained image classification models when facing compressed images. First, a Feature Drifting Estimation Network (FDE-Net) is devised to generate the spatial-wise Feature Drifting Map (FDM) in the DCT domain. Next, the estimated FDM is transmitted to the Feature Enhancement Network (FE-Net) to generate the mapping relationship between degraded features and corresponding high-quality features. Specially, a simple but effective RepConv block equipped with structural re-parameterization is utilized in FE-Net, which enriches feature representation in the training phase while keeping efficiency in the deployment phase. After training on limited compressed images, the AFD-Module can serve as a “plug-and-play” module for pre-trained classification models to improve their performance on compressed images. Experiments on images compressed once (i.e. ImageNet-C) and multiple times demonstrate that our proposed AFD-Module can comprehensively improve the accuracy of the pre-trained classification models and significantly outperform the existing methods.","['Index', 'Terms: ', 'JPEG compression,', 'Feature', 'Drifting,', 'Image', 'Classification,', 'Feature', 'Enhancement']",[]
"We prove that the Cuntz–Pimsner algebra of every Temperley–Lieb subproduct system is K⁢K𝐾𝐾KKitalic_K italic_K-self-dual. We show also that every such Cuntz–Pimsner algebra has a canonical KMS-state, which we use to construct a Fredholm module representative for the fundamental class of the duality. This allows us to describe the K𝐾Kitalic_K-homology of the Cuntz–Pimsner algebras by explicit Fredholm modules.
Both the construction of the dual class and the proof of duality rely in a crucial way on quantum symmetries of Temperley–Lieb subproduct systems.
In the simplest case of Arveson’s 2222-shift our work establishes U⁢(2)𝑈2U(2)italic_U ( 2 )-equivariant K⁢K𝐾𝐾KKitalic_K italic_K-self-duality of S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT.","['Key words and phrases:', 'Subproduct systems, quantum groups,', 'K\u2062K𝐾𝐾KKitalic_K italic_K-theory,', 'Spanier–Whitehead duality,', 'Poincaré duality,', 'KMS-states']",[]
"We resolve a long standing question regarding the suitable effective diffusion coefficient of the spherically-symmetric transport equation, which is valid at long times. To that end, we generalize a transport solution in three dimensions for homogeneous media, to include general collisional properties, including birth-death events and linearly anisotropic scattering. This is done by introducing an exact scaling law relating the Green function of the pure-scattering case with the general collision case, which is verified using deterministic and Monte-Carlo simulations. Importantly, the effective diffusion coefficient is identified by inspecting the transport solution at long times.",[''],['Israel']
"Mode-pairing quantum key distribution (MP-QKD) can surpass the repeaterless rate-transmittance bound (Pirandola-Laurenza-Ottaviani-Banchi bound) without requiring global phase locking, exhibiting remarkable flexibility.
However, MP-QKD necessitates equal communication distances in two channels, which is a challenging requirement in practical applications.
To address this limitation, we extend the original MP-QKD to asymmetric cases.
Our decoy-state estimation confirms that asymmetric channel transmittances and asymmetric intensities do not compromise the security of the protocol.
We focus on the pulse-intensity relationship, a key factor for optimizing the performance of asymmetric MP-QKD.
Unlike previous asymmetric protocols, the intensities of different bases in asymmetric MP-QKD cannot be decoupled.
We introduce an optimal-pulse-intensity method, adaptable to various scenarios, to enhance key rates by calculating ideal pulse intensities.
Simulation results in various representative scenarios indicate that our method effectively reduces the impact of asymmetric channel distances on MP-QKD performance, enhancing its practical applicability.",[''],['China']
"Modern deep learning models, growing larger and more complex, have demonstrated exceptional generalization and accuracy due to training on huge datasets. This trend is expected to continue. However, the increasing size of these models poses challenges in training, as traditional centralized methods are limited by memory constraints at such scales. This paper proposes an asynchronous decentralized training paradigm for large modern deep learning models that harnesses the compute power of regular heterogeneous PCs with limited resources connected across the internet to achieve favourable performance metrics. Ravnest facilitates decentralized training by efficiently organizing compute nodes into clusters with similar data transfer rates and compute capabilities, without necessitating that each node hosts the entire model. These clusters engage in Zero-Bubble Asynchronous Model Parallel training, and a Parallel Multi-Ring All-Reduce method is employed to effectively execute global parameter averaging across all clusters. We have framed our asynchronous SGD loss function as a block structured optimization problem with delayed updates and derived an optimal convergence rate of O⁢(1K)𝑂1𝐾O\left(\frac{1}{\sqrt{K}}\right)italic_O ( divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_K end_ARG end_ARG ). We further discuss linear speedup with respect to the number of participating clusters and the bound on the staleness parameter.",[''],[]
,[''],[]
"The recovery of 3D human mesh from monocular images has significantly been developed in recent years. However, existing models usually ignore spatial and temporal information, which might lead to mesh and image misalignment and temporal discontinuity. For this reason, we propose a novel Spatio-Temporal Alignment Fusion (STAF) model. As a video-based model, it leverages coherence clues from human motion by an attention-based Temporal Coherence Fusion Module (TCFM). As for spatial mesh-alignment evidence, we extract fine-grained local information through predicted mesh projection on the feature maps. Based on the spatial features, we further introduce a multi-stage adjacent Spatial Alignment Fusion Module (SAFM) to enhance the feature representation of the target frame. In addition to the above, we propose an Average Pooling Module (APM) to allow the model to focus on the entire input sequence rather than just the target frame. This method can remarkably improve the smoothness of recovery results from video. Extensive experiments on 3DPW, MPII3D, and H36M demonstrate the superiority of STAF. We achieve a state-of-the-art trade-off between precision and smoothness. Our code and more video results are on the project page https://yw0208.github.io/staf/.",[''],[]
"Optical two-dimensional (2D) spectroscopy under pump-probe geometry
has achieved significant successes in one-quantum research. However,
due to the typical phase matching condition, its implementation on
the measurement of double-quantum (2Q) coherence have been limited
for long, until recently Farrell and Zanni realized detecting 2Q signal
with a permuted–pump–probe pulse sequence in 2D infrared spectroscopy.
Here, we promote this technique to 2D electronic spectroscopy. Using
this pulse sequence, both the 2Q and zero-quantum (0Q) signal will
be detected. We present that with the propagation phase of the probe
pulse and by applying a rotating frame, the 2Q and 0Q coherence exhibit
distinct effective oscillation frequencies during the scanned interval.
These frequencies may share the same sign. We propose that 2Q and
0Q coherence could be separated onto different spectra using phase
cycling techniques and causality enforcement. Our experimental demonstration
on measuring the electronic 2Q coherence of rubidium atoms yields
broadband spectra. Notably, we simultaneously observe not only the
doubly excited state of an individual rubidium atom but also the collective
resonances of dipole-dipole interactions of both D1subscript𝐷1D_{1}italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and D2subscript𝐷2D_{2}italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT
lines.",[''],"['China', 'China', 'China', 'China', 'China']"
"Explainability in deep networks has gained increased importance in recent years. We argue herein that an AI must be tasked not just with a task but also with an explanation of why said task was accomplished as such. We present a basic framework—Task and Explanation Network (TENet)—which fully integrates task completion and its explanation.
We believe that the field of AI as a whole should insist—quite emphatically—on explainability.",[''],[]
"Leakages are a major risk in water distribution networks as they cause water loss and increase contamination risks. Leakage detection is a difficult task due to the complex dynamics of water distribution networks. In particular, small leakages are hard to detect. From a machine-learning perspective, leakages can be modeled as concept drift. Thus, a wide variety of drift detection schemes seems to be a suitable choice for detecting leakages. In this work, we explore the potential of model-loss-based and distribution-based drift detection methods to tackle leakage detection. We additionally discuss the issue of temporal dependencies in the data and propose a way to cope with it when applying distribution-based detection. We evaluate different methods systematically for leakages of different sizes and detection times. Additionally, we propose a first drift-detection-based technique for localizing leakages.",[''],[]
"Assistive robots should be able to wash, fold or iron clothes.
However, due to the variety, deformability and self-occlusions of clothes, creating general-purpose robot systems for cloth manipulation is challenging. Synthetic data is a promising direction to improve generalization, though its usability is often limited by the sim-to-real gap.
To advance the use of synthetic data for cloth manipulation and to enable tasks such as robotic folding, we present a synthetic data pipeline to train keypoint detectors for almost flattened cloth items. To test its performance, we have also collected a real-world dataset.
We train detectors for both T-shirts, towels and shorts and obtain an average precision of 64.3%. Fine-tuning on real-world data improves performance to 74.2%. Additional insight is provided by discussing various failure modes of the keypoint detectors and by comparing different approaches to obtain cloth meshes and materials.
We also quantify the remaining sim-to-real gap and argue that further improvements to the fidelity of cloth assets will be required to further reduce this gap. The code, dataset and trained models are available at https://github.com/tlpss/synthetic-cloth-data.","['Index', 'Terms: ', 'Deep', 'Learning for', 'Visual', 'Perception,', 'Simulation and', 'Animation,', 'Data', 'Sets for', 'Robotic', 'Vision']",[]
"Large language models (LLMs) have been extensively used as the backbones for general-purpose agents, and some economics literature suggest that LLMs are capable of playing various types of economics games.
Following these works, to overcome the limitation of evaluating LLMs using static benchmarks, we propose to explore competitive games as an evaluation for LLMs to incorporate multi-players and dynamicise the environment.
By varying the game history revealed to LLMs-based players, we find that most of LLMs are rational in that they play strategies that can increase their payoffs, but not as rational as indicated by Nash Equilibria (NEs).
Moreover, when game history are available, certain types of LLMs, such as  GPT4, can converge faster to the NE strategies, which suggests higher rationality level in comparison to other models.
In the meantime, certain types of LLMs can win more often when game history are available, and we argue that the winning rate reflects the reasoning ability with respect to the strategies of other players.
Throughout all our experiments, we observe that the ability to strictly follow the game rules described by natural languages also vary among the LLMs we tested.
In this work, we provide an economics arena for the LLMs research community as a dynamic simulation to test the above-mentioned abilities of LLMs, i.e. rationality, strategic reasoning ability, and instruction-following capability.",[''],[]
"Star formation takes place in filamentary molecular clouds which arise by physical processes that take place in the cold, neutral medium (CNM). We address the necessary conditions for this diffuse (n≈30𝑛30n\approx 30italic_n ≈ 30 cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT), cold (T ≈\approx≈ 60 K), magnetized gas undergoing shock waves and supersonic turbulence, to produce filamentary structures capable of fragmenting into cluster forming regions. Using RAMSES and a magnetized CNM environment as our initial conditions, we simulate a 0.5 kpc turbulent box to model a uniform gas with magnetic field strength of 7 μ⁢G𝜇𝐺\mu Gitalic_μ italic_G, varying the 3D velocity dispersion via decaying turbulence. We use a surface density of 320⁢M⊙⁢p⁢c−2320subscript𝑀direct-product𝑝superscript𝑐2320M_{\odot}pc^{-2}320 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT italic_p italic_c start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT, representative of the inner 4.0 kpc CMZ of the Milky Way and typical luminous galaxies. Filamentary molecular clouds are formed dynamically via shocks within a narrow range of velocity dispersions in the CNM of 5 - 10 km/s with a preferred value at 8 km/s. Cluster sink particles appear in filaments which exceed their critical line mass, occurring optimally for velocity dispersions of 8 km/s. Tracking the evolution of magnetic fields, we find that they lead to double the dense star forming gas than in purely hydro runs. Perpendicular orientations between magnetic field and filaments can increase the accretion rates onto filaments and hence their line masses. Because magnetic fields help support gas, MHD runs result in average temperatures an order of magnitude higher than unmagnetized counterparts. Finally, we find magnetic fields delay the onset of cluster formation by ∝0.4proportional-toabsent0.4\propto 0.4∝ 0.4 Myr.",[''],[]
"Benefitting from the vast spatial degrees of freedom, the amalgamation of integrated sensing and communication (ISAC) and massive multiple-input multiple-output (MIMO) is expected to simultaneously improve spectral and energy efficiencies as well as the sensing capability.
However, a large number of antennas deployed in massive MIMO-ISAC raises critical challenges in acquiring both accurate channel state information and target parameter information.
To overcome these two challenges with a unified framework, we first analyze their underlying system models and then propose a novel tensor-based approach that addresses both the channel estimation and target sensing problems.
Specifically, by parameterizing the high-dimensional communication channel exploiting a small number of physical parameters, we associate the channel state information with the sensing parameters of targets in terms of angular, delay, and Doppler dimensions.
Then, we propose a shared training pattern adopting the same time-frequency resources such that both the channel estimation and target parameter estimation can be formulated as a canonical polyadic decomposition problem with a similar mathematical expression.
On this basis, we first investigate the uniqueness condition of the tensor factorization and the maximum number of resolvable targets by utilizing the specific Vandermonde structure.
Then, we develop a unified tensor-based algorithm to estimate the parameters including angles, time delays, Doppler shifts, and reflection/path coefficients of the targets/channels.
In addition, we propose a segment-based shared training pattern to facilitate the channel and target parameter estimation for the case with significant beam squint effects.
Simulation results verify our theoretical analysis and the superiority of the proposed unified algorithms in terms of estimation accuracy, sensing resolution, and training overhead reduction.","['Index', 'Terms: ', 'Integrated sensing and communication, massive', 'MIMO, channel estimation, target parameter estimation, tensor decomposition.']",[]
"This paper introduces a new type of soft continuum robot, called SCoReS, which is capable of self-controlling continuously its curvature at the segment level; in contrast to previous designs which either require external forces or machine elements, or whose variable curvature capabilities are discrete—depending on the number of locking mechanisms and segments. The ability to have a variable curvature, whose control is continuous and independent from external factors, makes a soft continuum robot more adaptive in constrained environments, similar to what is observed in nature in the elephant’s trunk or ostrich’s neck for instance which exhibit multiple curvatures. To this end, our soft continuum robot enables reconfigurable variable curvatures utilizing a variable stiffness growing spine based on micro-particle granular jamming for the first time. We detail the design of the proposed robot, presenting its modeling through beam theory and FEA simulation—which is validated through experiments. The robot’s versatile bending profiles are then explored in experiments and an application to grasp fruits at different configurations is demonstrated. A narrated video detailing the work can be seen at https://youtu.be/H6SCK0NjGpE.","['Index', 'Terms: ', 'Continuous stiffness regulation, variable curvature, soft robot applications, soft robot materials and design.']",[]
"We consider the 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT problem, the problem of minimizing the weighted number of tardy jobs on a single machine. This problem is one of the most basic and fundamental problems in scheduling theory, with several different applications both in theory and practice. We prove that 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is W[1]-hard with respect to the number p#subscript𝑝#p_{\#}italic_p start_POSTSUBSCRIPT # end_POSTSUBSCRIPT of different processing times in the input, as well as with respect to the number w#subscript𝑤#w_{\#}italic_w start_POSTSUBSCRIPT # end_POSTSUBSCRIPT of different weights in the input. This, along with previous work, provides a complete picture for 1∣∣∑wjUj1\mid\mid\sum w_{j}U_{j}1 ∣ ∣ ∑ italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT from the perspective of parameterized complexity, as well as almost tight complexity bounds for the problem under the Exponential Time Hypothesis (ETH).",[''],[]
,[''],[]
"Micro-environmental acidity is a common feature of the tumor. One of the causes behind tumor acidity is lactate production by hypoxic cells of the tumor. Hypoxia is a direct result of the establishment of oxygen gradients. It is commonly observed in the tumor in an in-vitro experimental setup and also in-vivo situation. Here, we propose a mathematical model to analyses the production of lactate by hypoxic cells, and it is used as an alternative fuel by normoxic cells in tumor tissue in-vitro and in-vivo conditions.
In this article, we study the effects of unequal oxygen concentration at the tumor boundaries on lactate status in the tumor. The effects of presence of the necrotic core in the tumor on the lactate concentration profile is examined. The results have good agreement with experimental data and align with the theoretical findings of previous studies. The analytical results show that lactate levels are elevated in an in-vivo tumor compared to that in an in-vitro tumor. Also, during the onset of necrotic core formation, the effects of necrotic core on lactate levels are noticed.
Knowledge of the lactate status in a patient’s tumor may be helpful in choosing the rightful and precious medicines for cancer treatment.",[''],[]
"The astrophysical origin of binary black hole (BBH) mergers remains uncertain[1] though many events have been observed by the LIGO-Virgo-KAGRA network. Such mergers are predicted to originate in the vicinity of massive black holes (MBHs)[2, 3, 4, 5]. Especially, GW190814, due to its secondary mass and mass ratio being beyond the expectations of isolated stellar evolution theories, is a promising event that has happened in an active galactic nucleus(AGN) disk[6]. In this model, a compact object resides in the vicinity of a merging BBH. Here we report multiple pieces of evidence pointing to the fact that GW190814 is a BBH merging near a compact object. The orbital motion of BBHs around the third body produces a line-of-sight acceleration (LSA) and induces a varying Doppler shift[7, 8]. Using a waveform template that considers LSA, we perform Bayesian inference on a few BBH events with a high signal-to-noise ratio in the gravitational-wave transient catalog (GWTC). Compared to the model for isolated BBH mergers, we obtain significantly higher network signal-to-noise ratios for GW190814 by that with the LSA and constrain the LSA to a=0.0014−0.0022+0.0014⁢c⁢s−1𝑎subscriptsuperscript0.00140.00140.0022𝑐superscripts1a=0.0014^{+0.0014}_{-0.0022}~{}c~{}\mathrm{s}^{-1}italic_a = 0.0014 start_POSTSUPERSCRIPT + 0.0014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.0022 end_POSTSUBSCRIPT italic_c roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. In addition, the logarithmic Bayes factor for the LSA case over the isolated case is 16.616.616.616.6, which means the LSA model is significantly preferred by the GW data. We conclude that this is the first indication showing merging BBHs are located near a compact object.",[''],[]
This paper introduces for the first time the concepts of non-coherent interfaces and microstructure-driven interface forces in the framework of micromorphic elasticity. It is shown that such concepts are of paramount importance when studying the response of finite-size mechanical metamaterials at the homogenized macro-scale. The need of introducing interface forces is elucidated through numerical examples comparing reduced relaxed micromorphic simulations to their full-microstructured counterparts. These results provide a milestone for the understanding of metamaterials’ modeling at the homogenized scale and for the use of micromorphic-type models to achieve an accurate upscaling towards larger-scale metamaterials’ structures.,[''],[]
,"['Key words and phrases: multirate explicit stabilized methods,', 'Rush–Larsen, electrophysiology, monodomain model, ionic model, local time-stepping']",[]
"We present two infinite families of coherent quantum speed limits (QSLs) for general unitary dynamics by employing the Hölder’s inequality for matrix norms.
Our approach clearly highlights the contribution of the coherence of the evolved states, and provides novel QSL bounds characterized by coherence measures based on Schatten p𝑝pitalic_p-norm or Hellinger distance.
We illustrate our findings with relevant models, demonstrating our bounds are much tighter than the established ones and asymptotically saturable in the adiabatic limit.
Our results show that rapid quantum dynamics requires coherent superpositions of energy eigenstates, singling out coherence as a key resource for the evolution of quantum systems.",[''],"['China', 'China']"
"The RADiCAL Collaboration is conducting R&D on high performance electromagnetic (EM) calorimetry to address the challenges expected in future collider experiments under conditions of high luminosity and/or high irradiation (FCC-ee, FCC-hh and fixed target and forward physics environments). Under development is a sampling calorimeter approach, known as RADiCAL modules, based on scintillation and wavelength-shifting (WLS) technologies and photosensor, including SiPM and SiPM-like technology. The modules discussed herein consist of alternating layers of very dense (W) absorber and scintillating crystal (LYSO:Ce) plates, assembled to a depth of 25 X0subscript𝑋0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. The scintillation signals produced by the EM showers in the region of EM shower maximum (shower max) are transmitted to SiPM located at the upstream and downstream ends of the modules via quartz capillaries which penetrate the full length of the module. The capillaries contain DSB1 organic plastic WLS filaments positioned within the region of shower max, where the shower energy deposition is greatest, and fused with quartz rod elsewhere. The wavelength shifted light from this spatially-localized shower max region is then propagated to the photosensors. This paper presents the results of an initial measurement of the time resolution of a RADiCAL module over the energy range 25 GeV ≤\leq≤ E ≤\leq≤ 150 GeV using the H2 electron beam at CERN. The data indicate an energy dependence of the time resolution that follows the functional form: σt=a/E⊕bsubscript𝜎𝑡direct-sum𝑎𝐸𝑏\sigma_{t}=a/\sqrt{E}\oplus bitalic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a / square-root start_ARG italic_E end_ARG ⊕ italic_b, where a = 256 G⁢e⁢V𝐺𝑒𝑉\sqrt{GeV}square-root start_ARG italic_G italic_e italic_V end_ARG ps and b = 17.5 ps. The time resolution measured at the highest electron beam energy for which data was currently recorded (150 GeV) was found to be σtsubscript𝜎𝑡\sigma_{t}italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 27 ps.",[''],[]
,[''],[]
"Images generated by most of generative models trained with limited data often exhibit deficiencies in either fidelity, diversity, or both. One effective solution to address the limitation is few-shot generative model adaption. However, the type of approaches typically rely on a large-scale pre-trained model, serving as a source domain, to facilitate information transfer to the target domain. In this paper, we propose a method called Information Transfer from the Built Geodesic Surface (ITBGS), which contains two module: Feature Augmentation on Geodesic Surface (FAGS); Interpolation and Regularization (I&R). With the FAGS module, a pseudo-source domain is created by projecting image features from the training dataset into the Pre-Shape Space, subsequently generating new features on the Geodesic surface. Thus, no pre-trained models is needed for the adaption process during the training of generative models with FAGS. I&R module are introduced for supervising the interpolated images and regularizing their relative distances, respectively, to further enhance the quality of generated images. Through qualitative and quantitative experiments, we demonstrate that the proposed method consistently achieves optimal or comparable results across a diverse range of semantically distinct datasets, even in extremely few-shot scenarios.",[''],[]
"The attention mechanism has been proven effective on various visual tasks in recent years. In the semantic segmentation task, the attention mechanism is applied in various methods, including the case of both Convolution Neural Networks (CNN) and Vision Transformer (ViT) as backbones.
However, we observe that the attention mechanism is vulnerable to patch-based adversarial attacks.
Through the analysis of the effective receptive field, we attribute it to the fact that the wide receptive field brought by global attention may lead to the spread of the adversarial patch.
To address this issue, in this paper, we propose a Robust Attention Mechanism (RAM) to improve the robustness of the semantic segmentation model, which can notably relieve the vulnerability against patch-based attacks. Compared to the vallina attention mechanism, RAM introduces two novel modules called Max Attention Suppression and Random Attention Dropout, both of which aim to refine the attention matrix and limit the influence of a single adversarial patch on the semantic segmentation results of other positions.
Extensive experiments demonstrate the effectiveness of our RAM to improve the robustness of semantic segmentation models against various patch-based attack methods under different attack settings.",[''],"['[', '[']"
,[''],[]
"In recent years, the Vision Transformer (ViT) model has gradually become mainstream in various computer vision tasks, and the robustness of the model has received increasing attention. However, existing large models tend to prioritize performance during training, potentially neglecting the robustness, which may lead to serious security concerns. In this paper, we establish a new challenge: exploring how to use a small number of additional parameters for adversarial finetuning to quickly and effectively enhance the adversarial robustness of a standardly trained model. To address this challenge, we develop the novel LNLoRA module, incorporating a learnable layer normalization before the conventional LoRA module, which helps mitigate magnitude differences in parameters between the adversarial and standard training paradigms.
Furthermore, we propose the FullLoRA-AT framework by integrating the learnable LNLoRA modules into all key components of ViT-based models while keeping the pretrained model frozen, which can significantly improve the model robustness via adversarial finetuning in a parameter-efficient manner.
Extensive experiments on CIFAR-10, CIFAR-100, and Imagenette demonstrate the superiority of our proposed FullLoRA-AT framework. It achieves comparable robustness with full finetuning while only requiring about 5% of the learnable parameters. This also effectively addresses concerns regarding extra model storage space and enormous training time caused by adversarial finetuning.",[''],[]
,[''],[]
"We introduce a new challenge to the software development community: 1) leveraging AI to accurately detect and flag up secrets in code and on popular document sharing platforms that frequently used by developers, such as Confluence and 2) automatically remediating the detections (e.g. by suggesting password vault functionality). This is a challenging, and mostly unaddressed task. Existing methods leverage heuristics and regular expressions, that can be very noisy, and therefore increase toil on developers. The next step - modifying code itself - to automatically remediate a detection, is a complex task. We introduce two baseline AI models that have good detection performance and propose an automatic mechanism for remediating secrets found in code, opening up the study of this task to the wider community.","['artificial intelligence, software engineering, cybersecurity']","['Chase', 'Chase', 'Chase', 'Chase', 'Chase']"
"Parallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis process compared with conventional auto-regressive models. Although parallel models have benefits in many aspects, they become naturally unfit for incremental synthesis due to their fully parallel architecture such as transformer. In this work, we propose Incremental FastPitch, a novel FastPitch variant capable of incrementally producing high-quality Mel chunks by improving the architecture with chunk-based FFT blocks, training with receptive-field constrained chunk attention masks, and inference with fixed size past model states. Experimental results show that our proposal can produce speech quality comparable to the parallel FastPitch, with a significant lower latency that allows even lower response time for real-time speech applications.",[''],[]
"Many researchers around the world are researching to get control solutions that enhance robots’ ability to navigate in dynamic environments autonomously. However, until these days robots have limited capability and many navigation tasks on Earth and other planets have been difficult so far.
This paperwork presents the development of a control system for a differential drive-wheeled mobile robot that autonomously controls its position, heading, and speed based on destination information given and surrounding data gathered through mounted proximity and GPS sensors. The intelligence of this control system is implemented by using a fuzzy logic algorithm which is a very powerful tool to handle un-modeled systems like the dynamically changing environment dealt with in this research. The fuzzy controller is used to address the problems associated with navigation in an obstacle-strewn environment. Such issues include position estimation, path planning, and obstacle avoidance. 
In this study modeling, design, and simulation of the system have been done. The simulation result shows that the developed mobile robot travels successfully from any location to the destination location without colliding with obstacles. 
Keywords:- Mobile Robot; Fuzzy Logic; Navigation; Obstacle avoidance",[''],[]
"The model of directed polymer in a random environment is a fundamental model of
interaction between a simple random walk and ambient disorder. This interaction
gives rise to complex phenomena and transitions from a central limit theory
to novel statistical behaviours. Despite its intense study, there are still many aspects and phases
which have not yet been identified. In this review we focus on the current status
of our understanding of the transition between weak and strong disorder phases,
give an account of some of the methods that the study of the model has motivated
and highlight some open questions.","['Key words and phrases: random polymers, disordered systems, phase transitions, weak and strong disorder, martingales, fractional moment method, coarse graining, pinning models, heavy tail disorder, hierarchical lattices, intermediate disorder regime']",[]
"This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",[''],[]
"With the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. Beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. The majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. These comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. Therefore, in this study, we propose a novel Vision and Graph Fused Attention Network (VGA) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and further explore visual tampering features, as well as the textual information hidden in images. We conduct extensive experiments on three datasets, demonstrating that VGA can effectively detect multimodal rumors and outperform state-of-the-art methods significantly.","['rumor detection, multimodal fusion, propagation structure, social media']","['UniversityHaidianBeijingChina', 'UniversityHaidianBeijingChina', 'UniversityHaidianBeijingChina', 'UniversityHaidianBeijingChina']"
"The motivation of this paper is to investigate the joint distribution of succession and Eulerian statistics.
We first investigate the enumerators for the joint distribution of descents, big ascents and successions over all permutations in the symmetric group.
As an generalization a result of Diaconis-Evans-Graham (Adv. in Appl. Math., 61 (2014), 102–124),
we show that two triple set-valued statistics of permutations are equidistributed on symmetric groups.
We then introduce the definition of proper left-to-right minimum.
We discover that the joint distribution of the succession and proper left-to-right minimum statistics over permutations is a symmetric distribution.
In the final part, we discuss the relationship between the fixfix{\rm fix\,}roman_fix and cyccyc{\rm cyc\,}roman_cyc (p,q)𝑝𝑞(p,q)( italic_p , italic_q )-Eulerian polynomials and
the joint distribution of succession and several Eulerian-type statistics.


Keywords: Eulerian polynomials; Fixed points; Successions; Proper left-to-right minima",[''],[]
"Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target.
One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets.
However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge.
In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge.
First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM).
Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor.
Extensive experiments results demonstrate the superiority of MPPT against the state-of-the-art baseline methods.",[''],[]
"Multichannel convolutive blind speech source separation refers to the problem of separating different speech sources from the observed multichannel mixtures without much a priori information about the mixing system. Multichannel nonnegative matrix factorization (MNMF) has been proven to be one of the most powerful separation frameworks and the representative algorithms such as MNMF and the independent low-rank matrix analysis (ILRMA) have demonstrated great performance. However, the sparseness properties of speech source signals are not fully taken into account in such a framework. It is well known that speech signals are sparse in nature, which is considered in this work to improve the separation performance. Specifically, we utilize the Bingham and Laplace distributions to formulate a disjoint constraint regularizer, which is subsequently incorporated into both MNMF and ILRMA. We then derive majorization-minimization rules for updating parameters related to the source model, resulting in the development of two enhanced algorithms: s-MNMF and s-ILRMA. Comprehensive simulations are conducted, and the results unequivocally demonstrate the efficacy of our proposed methodologies.",[''],[]
"Data augmentation (DA) encodes invariance and provides implicit regularization critical to a model’s performance in image classification tasks.
However, while DA improves average accuracy, recent studies have shown that its impact can be highly class dependent: achieving optimal average accuracy comes at the cost of significantly hurting individual class accuracy by as much as 20%percent2020\%20 % on ImageNet. There has been little progress in resolving class-level accuracy drops due to a limited understanding of these effects. In this work, we present a framework for understanding how DA interacts with class-level learning dynamics. Using higher-quality multi-label annotations on ImageNet, we systematically categorize the affected classes and find that the majority are inherently ambiguous, co-occur, or involve fine-grained distinctions, while DA controls the model’s bias towards one of the closely related classes.
While many of the previously reported performance drops are explained by multi-label annotations, our analysis of class confusions reveals other sources of accuracy degradation.
We show that simple class-conditional augmentation strategies informed by our framework improve performance on the negatively affected classes.",[''],[]
,[''],[]
"A subgraph of an edge-colored graph is rainbow if all of its edges have different colors. Let G𝐺Gitalic_G and H𝐻Hitalic_H be two graphs. The anti-Ramsey number ar⁢(G,H)ar𝐺𝐻{\rm ar}(G,H)roman_ar ( italic_G , italic_H ) is the maximum number of colors of an edge-coloring of G𝐺Gitalic_G that does not contain a rainbow copy of H𝐻Hitalic_H. In this paper, we study the anti-Ramsey numbers of Kksubscript𝐾𝑘K_{k}italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in complete multi-partite graphs. We determine the values of the anti-Ramsey numbers of Kksubscript𝐾𝑘K_{k}italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in complete k𝑘kitalic_k-partite graphs and in balanced complete r𝑟ritalic_r-partite graphs for r≥k𝑟𝑘r\geq kitalic_r ≥ italic_k.
Keywords: anti-Ramsey number; multi-partite graph; extremal coloring",[''],[]
"Regular black holes (RBHs) – geometries free from curvature singularities – arise naturally in theories of non linear electrodynamics. Here we study the absorption, and superradiant amplification, of a monochromatic planar wave in a charged, massive scalar field impinging on the electrically-charged Ayón-Beato-García (ABG) RBH. Comparisons are drawn with absorption and superradiance for the Reissner-Nordström (RN) black hole in linear electrodynamics. We find that, in a certain parameter regime, the ABG absorption cross section is negative, due to superradiance, and moreover it is unbounded from below as the momentum of the wave approaches zero; this phenomenon of “unbounded superradiance” is absent in the RN case. We show how the parameter space can be divided into regions, using the bounded/unbounded and absorption/amplification boundaries. After introducing a high-frequency approximation based on particle trajectories, we calculate the absorption cross section numerically, via the partial-wave expansion, as function of wave frequency, and we present a gallery of results. The cross section of the ABG RBH is found to be larger (smaller) than in the RN case when the field charge has the same (opposite) sign as the black hole charge. We show that it is possible to find “mimics”: situations in which the cross sections of both black holes are very similar. We conclude with a discussion of unbounded superradiance, and superradiant instabilities.",[''],"['Brazil.', 'Kingdom.', 'Brazil.', 'Kingdom.', 'Brazil.', 'Portugal.']"
,[''],[]
"The d𝑑ditalic_d-dimensional hypercube graph Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT has as vertices all subsets of {1,…,d}1…𝑑\{1,\ldots,d\}{ 1 , … , italic_d }, and an edge between any two sets that differ in a single element.
The Ruskey-Savage conjecture asserts that every matching of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, d≥2𝑑2d\geq 2italic_d ≥ 2, can be extended to a Hamilton cycle, i.e., to a cycle that visits every vertex exactly once.
We prove that every matching of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, d≥2𝑑2d\geq 2italic_d ≥ 2, can be extended to a cycle that visits at least a 2/3232/32 / 3-fraction of all vertices.",[''],[]
,[''],[]
"Different index concepts for linear differential-algebraic equations are defined in the general Banach space setting, and compared. For regular finite-dimensional linear differential-algebraic equations, all these indices exist and are equivalent. For infinite-dimensional systems, the situation is more complex. It is proven that although some indices imply others, in general they are not equivalent. The situation is illustrated with a number of examples.",[''],[]
"Artificial neural networks (ANNs) have permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. However, the inherent limitations of traditional neural networks arise due to their relatively fixed network structures and activation functions. 1, The type of activation function is single and relatively fixed, which leads to poor ”unit representation ability” of the network, and it is often used to solve simple problems with very complex networks; 2, the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. To address the aforementioned issues, this study proposes a novel neural network called X-Net. By utilizing our designed Alternating Backpropagation mechanism, X-Net dynamically selects appropriate activation functions based on derivative information during training to enhance the network’s representation capability for specific tasks. Simultaneously, it accurately adjusts the network structure at the neuron level to accommodate tasks of varying complexities and reduce computational costs. Through a series of experiments, we demonstrate the dual advantages of X-Net in terms of reducing model size and improving representation power. Specifically, in terms of the number of parameters, X-Net is only 3%percent\%% of baselines on average, and only 1.4%percent\%% under some tasks. In terms of representation ability, X-Net can achieve an average R2superscript𝑅2R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT=0.985 on the fitting task by only optimizing the activation function without introducing any parameters. Finally, we also tested the ability of X-Net to help scientific discovery on data from multiple disciplines such as society, energy, environment, and aerospace, and achieved concise and good results.",[''],"['*', '[', '[']"
,[''],[]
,[''],[]
"We discuss representations of product systems (of W*superscript𝑊W^{*}italic_W start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-correspondences) over the semigroup ℤ+nsubscriptsuperscriptℤ𝑛\mathbb{Z}^{n}_{+}blackboard_Z start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and show that, under certain pureness and Szego positivity conditions, a completely contractive representation can be dilated to an isometric representation. For n=1,2𝑛12n=1,2italic_n = 1 , 2 this is known to hold in general (without assuming the conditions) but, for n≥3𝑛3n\geq 3italic_n ≥ 3, it does not hold in general (as is known for the special case of isometric dilations of a tuple of commuting contractions). Restricting to the case of tuples of commuting contractions, our result reduces to a result of Barik, Das, Haria and Sarkar.
Our dilation is explicitly constructed and we present some applications.","['Key words and phrases:', 'Completely contractive representation,', 'W*superscript𝑊W^{*}italic_W start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-correspondence, product system, isometric dilation,', 'Szegö positivity']",[]
"We devise an autonomous quantum thermal machine consisting of three pairwise-interacting qubits, two of which are locally coupled to separate classical reservoirs. The machine operates autonomously, as it requires no time-coherent control, external driving or quantum bath engineering, and is instead propelled by a chemical potential bias between the reservoirs. Under ideal conditions, we show that this out-of-equilibrium system can deterministically generate a maximally entangled steady-state between two of the qubits, or in fact, any desired pure two-qubit entangled state, emerging as a dark state of the system. The entanglement production is also robust, such that nearly-maximally-entangled states can be generated well-away from the ideal regime of operation. Furthermore, we show that our machine architecture can be generalised to a configuration with 2⁢n−12𝑛12n-12 italic_n - 1 qubits, in which only a potential bias and two-body interactions are sufficient to generate genuine multipartite maximally entangled steady states in the form of a W state of n𝑛nitalic_n qubits.",[''],"['Sweden', 'Sweden', 'Sweden', 'Sweden', 'Augsburg', 'Sweden', 'Sweden', 'Sweden']"
"In this paper we study a class of variable coefficient third order partial differential operators on ℝn+1superscriptℝ𝑛1\mathbb{R}^{n+1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT, containing, as a subclass, some variable coefficient operators of KdV-type in any space dimension. For such a class, as well as for the adjoint class, we obtain a Carleman estimate and the local solvability at any point of ℝn+1superscriptℝ𝑛1\mathbb{R}^{n+1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT. A discussion of possible applications in the context of dispersive equations is provided.","['Key words and phrases:', 'Third order equations with variable coefficients, variable coefficient', 'KdV-type equations,', 'Carleman estimates, local solvability']",[]
"This paper presents the effects of non-minimal Lorentz-violation operators in superconductivity. By constructing a Lorentz-Violating Ginzburg-Landau theory of superconductivity with a five-dimensional operator, we discuss the influence of higher dimensional Lorentz-Violating operators in the London’s depth penetration, in the coherence length and critical magnetic field.",[''],"['Brazil.', 'Brazil', 'Brazil', 'Brazil', 'Turkey']"
"We extend Ziv and Lempel’s model of finite-state encoders to the
realm of lossy compression of individual sequences. In particular, the model
of the encoder includes a finite-state reconstruction codebook followed by
an information lossless finite-state encoder that compresses the
reconstruction codeword with no additional distortion. We first derive two
different lower
bounds to the compression ratio that depend on the number of states of the
lossless encoder.
Both bounds are asymptotically achievable by
conceptually simple coding schemes. We then show that when the number of
states of the lossless encoder is large enough in terms of the reconstruction
block-length, the performance can be improved, sometimes significantly so.
In particular, the improved performance is achievable using a random-coding
ensemble that is universal, not only in terms of the source sequence, but also in terms
of the distortion measure.",[''],[]
"While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data. Our model directly provides answers for 78.2%percent78.278.2\%78.2 % of the known queries and opts to search for 77.2%percent77.277.2\%77.2 % of the unknown ones. This results in the API being utilized only 62%percent6262\%62 % of the time.",[''],[]
"The proliferation of low-quality online information in today’s era has underscored the need for robust and automatic mechanisms to evaluate the trustworthiness of online news publishers. In this paper, we analyse the trustworthiness of online news media outlets by leveraging a dataset of 4033 news stories from 40 different sources. We aim to infer the trustworthiness level of the source based on the classification of individual articles’ content. The trust labels are obtained from NewsGuard, a journalistic organization that evaluates news sources using well-established editorial and publishing criteria. The results indicate that the classification model is highly effective in classifying the trustworthiness levels of the news articles. This research has practical applications in alerting readers to potentially untrustworthy news sources, assisting journalistic organizations in evaluating new or unfamiliar media outlets and supporting the selection of articles for their trustworthiness assessment.","['Online', 'News,', 'Transparency and', 'Reputability of', 'Online', 'News', 'Sources,', 'Multiclass', 'Classification,', 'Data', 'Science for', 'Social', 'Good']","['LuccaItaly55100', 'IIT-CNRItaly55100', 'LuccaItaly', 'LuccaItaly']"
"Much debate nowadays is devoted to the impacts of modern information and communication technology on global carbon emissions. Green information and communication technology is a paradigm creating a sustainable and environmentally friendly computing field that tries to minimize the adverse effects on the environment. Green information and communication technology are under constant development nowadays. Thus, in this paper, we undertake the problem of performance bugs that, until recently, have never been studied so profoundly. We assume that inappropriate software implementations can have a crucial influence on global carbon emissions. Here, we classify those performance bugs and develop inappropriate implementations of four programs written in C++. To mitigate these simulated performance bugs, measuring software and hardware methods that can estimate the increased carbon footprint properly were proposed.","['Index', 'Terms: \n\ncarbon footprint, green computing, performance bugs, software engineering']","['iztok.fister1@um.si', 'dusan.fister@um.si', 'vili.podgorelec@um.si', 'iztok.fister@um.si']"
"Classical numerical schemes exist for solving PDEs numerically, and recently, neural network-based methods have been developed. However, methodologies using neural networks, such as PINN and neural operators, lack robustness and generalization power. To compensate for such drawbacks, there are many types of research combining classical numerical schemes and machine learning methods by replacing a small portion of the numerical schemes with neural networks. In this work, we focus on hyperbolic conservation laws and replace numerical fluxes in the numerical schemes by neural operator. For this, we construct losses that are motivated by numerical schemes for conservation laws and approximate numerical flux by FNO. Through experiments, we show that our methodology has advantages of both numerical schemes and FNO by comparing with original methods. For instance, we demonstrate our method gains robustness, resolution invariance property, and feasibility of a data-driven method. Our method especially has the ability to predict continuously in time and generalization power on the out-of-distribution samples, which are challenges to be tackled for existing neural operator methods.",[''],[]
"We describe computer calculations which show that if L𝐿Litalic_L is a 5-Engel Lie
algebra over a field of characteristic zero, or over a field of prime
characteristic p>7𝑝7p>7italic_p > 7,  then L𝐿Litalic_L is nilpotent of class at most 11. We use
the representation theory of the symmetric group to show that the problem can
be reduced to showing that certain four generator Lie superalgebras satisfying
relations derived from the 5-Engel identity are nilpotent of class at most 11.
We also describe computer calculations which show that if G𝐺Gitalic_G is a finite
5-Engel p𝑝pitalic_p-group for a prime p>7𝑝7p>7italic_p > 7 then G𝐺Gitalic_G is nilpotent of class at most 10.",[''],[]
"Minimizing data storage poses a significant challenge in large-scale metagenomic projects. In this paper, we present a new method for improving the encoding of FASTQ files generated by metagenomic sequencing. This method incorporates metagenomic classification followed by a recursive filter for clustering reads by DNA sequence similarity to improve the overall reference-free compression. In the results, we show an overall improvement in the compression of several datasets. As hypothesized, we show a progressive compression gain for higher coverage depth and number of identified species. Additionally, we provide an implementation that is freely available at https://github.com/cobilab/mizar and can be customized to work with other FASTQ compression tools.",[''],[]
"According to the World Health Organization (WHO), air pollution kills seven million people every year. Outdoor air pollution is a major environmental health problem affecting low, middle, and high-income countries. In the past few years, the research community has explored IoT-enabled machine learning applications for outdoor air pollution prediction. The general objective of this paper is to systematically review applications of machine learning and Internet of Things (IoT) for outdoor air pollution prediction and the combination of monitoring sensors and input features used. Two research questions were formulated for this review. 1086 publications were collected in the initial PRISMA stage. After the screening and eligibility phases, 37 papers were selected for inclusion. A cost-based analysis was conducted on the findings to highlight high-cost monitoring, low-cost IoT and hybrid enabled prediction. Three methods of prediction were identified: time series, feature-based and spatio-temporal. This review’s findings identify major limitations in applications found in the literature, namely lack of coverage, lack of diversity of data and lack of inclusion of context-specific features. This review proposes directions for future research and underlines practical implications in healthcare, urban planning, global synergy and smart cities.",[''],[]
"This research explores the reliability of deep learning, specifically Long Short-Term Memory (LSTM) networks, for estimating the Hurst parameter in fractional stochastic processes. The study focuses on three types of processes: fractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process, and linear fractional stable motions (lfsm). The work involves a fast generation of extensive datasets for fBm and fOU to train the LSTM network on a large volume of data in a feasible time. The study analyses the accuracy of the LSTM network’s Hurst parameter estimation regarding various performance measures like RMSE, MAE, MRE, and quantiles of the absolute and relative errors. It finds that LSTM outperforms the traditional statistical methods in the case of fBm and fOU processes; however, it has limited accuracy on lfsm processes. The research also delves into the implications of training length and valuation sequence length on the LSTM’s performance. The methodology is applied by estimating the Hurst parameter in Li-ion battery degradation data and obtaining confidence bounds for the estimation. The study concludes that while deep learning methods show promise in parameter estimation of fractional processes, their effectiveness is contingent on the process type and the quality of training data.",[''],[]
,[''],['France']
"Existing chain-based rotating leader BFT SMR protocols for the partially synchronous network model that commit blocks with O⁢(1)𝑂1O(1)italic_O ( 1 ) minimum latency have block periods of at least 2⁢δ2𝛿2\delta2 italic_δ (where δ𝛿\deltaitalic_δ is the message transmission latency). While a protocol with a block period of δ𝛿\deltaitalic_δ exists under the synchronous model, its minimum commit latency is linear in the size of the system.
To close this gap, we present the first chain-based BFT SMR protocols with best-case delays of δ𝛿\deltaitalic_δ between the proposals of distinct honest leaders, and minimum commit latencies of 3⁢δ3𝛿3\delta3 italic_δ. We present three protocols for the partially synchronous network model under different notions of optimistic responsiveness, two of which implement pipelining and one of which does not. All of our protocols achieve reorg resilience and two have short view lengths; properties that many existing chain-based BFT SMR protocols lack. We experimentally evaluate our protocols and show that they achieve significant increases in throughput and reductions in latency compared to the state-of-the-art, Jolteon. Our results also demonstrate that techniques commonly employed to reduce communication complexity—such as vote-pipelining and the use of designated vote-aggregators—actually reduce practical performance in many settings.",[''],['j.tobkin}@supraoracles.com']
"The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling. A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling. Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. Audio samples and codes are available at https://comosvc.github.io/.",[''],[]
"It was proposed that the tensor product structure of the Hilbert space is uniquely determined by the Hamiltonian’s spectrum, for most finite-dimensional cases satisfying certain conditions.
I show that, for more than three qudits, any such method can only lead to infinitely many tensor product structures. The number of additional continuous parameters needed to find a unique solution is exponential in the number of qudits. In addition, even if the result were unique, such a Hamiltonian would not entangle subsystems.
These results affect some proposals to recover the 3d space from the Hamiltonian.","['tensor product structure; entanglement; emergent spacetime;', 'Hilbert space fundamentalism.']",['holotronix@gmail.com']
"Channel state information (CSI) is important to reap the full benefits of millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems. The traditional channel estimation methods using pilot frames (PF) lead to excessive overhead. To reduce the demand for PF, data frames (DF) can be adopted for joint channel estimation and data recovery. However, the computational complexity of the DF-based methods is prohibitively high. To reduce the computational complexity, we propose a joint channel estimation and data recovery (JCD) method assisted by a small number of PF for mmWave massive MIMO systems. The proposed method has two stages. In Stage 1, differing from the traditional PF-based methods, the proposed PF-assisted method is utilized to capture the angle of arrival (AoA) of principal components (PC) of channels. In Stage 2, JCD is designed for parallel implementation based on the multi-user decoupling strategy. The theoretical analysis demonstrates that the PF-assisted JCD method can achieve equivalent performance to the Bayesian-optimal DF-based method, while greatly reducing the computational complexity. Simulation results are also presented to validate the analytical results.","['Index', 'Terms: ', 'MmWave massive', 'MIMO, joint channel estimation and data recovery,', 'PF-assisted, principal components.']",[]
"Magnetic reconnection is an important process in astrophysical environments, as it re-configures magnetic field topology and converts magnetic energy into thermal and kinetic energy.
In extreme astrophysical systems, such as black hole coronae and pulsar magnetospheres, radiative cooling modifies the energy partition by radiating away internal energy, which can lead to the radiative collapse of the reconnection layer. In this paper, we perform two- and three-dimensional simulations to model the MARZ (Magnetic Reconnection on Z) experiments, which are designed to access cooling rates in the laboratory necessary to investigate reconnection in a previously unexplored radiatively-cooled regime. These simulations are performed in GORGON, an Eulerian two-temperature resistive magnetohydrodynamic code, which models the experimental geometry comprising two exploding wire arrays driven by 20 MA of current on the Z machine (Sandia National Laboratories). Radiative losses are implemented using non-local thermodynamic equilibrium tables computed using the atomic code Spk, and we probe the effects of radiation transport by implementing both a local radiation loss model and P1/313{}_{1/3}start_FLOATSUBSCRIPT 1 / 3 end_FLOATSUBSCRIPT multi-group radiation transport. The load produces highly collisional, super-Alfvénic (MA≈1.5subscript𝑀𝐴1.5M_{A}\approx 1.5italic_M start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ≈ 1.5), supersonic (MS≈4−5)subscript𝑀𝑆45(M_{S}\approx 4-5)( italic_M start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ≈ 4 - 5 ) strongly driven plasma flows which generate an elongated reconnection layer (L/δ≈100,SL≈400formulae-sequence𝐿𝛿100subscript𝑆𝐿400L/\delta\approx 100,\,S_{L}\approx 400italic_L / italic_δ ≈ 100 , italic_S start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ≈ 400). The reconnection layer undergoes radiative collapse when the radiative losses exceed the rates of Ohmic and compressional heating (τcool−1/τH−1≈100superscriptsubscript𝜏cool1superscriptsubscript𝜏𝐻1100\tau_{\text{cool}}^{-1}/\tau_{H}^{-1}\approx 100italic_τ start_POSTSUBSCRIPT cool end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT / italic_τ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ≈ 100); this generates a cold strongly compressed current sheet, leading to an accelerated reconnection rate, consistent with theoretical predictions. Finally, the current sheet is also unstable to the plasmoid instability, but the magnetic islands are extinguished by strong radiative cooling before ejection from the layer.",[''],['USA']
"User facing ‘platform safety technology’ encompasses an array of tools offered by platforms to help people protect themselves from harm, for example allowing people to report content and unfollow or block other users. These tools are an increasingly important part of online safety: in the UK, legislation has made it a requirement for large platforms to offer them. However, little is known about user engagement with such tools. We present findings from a nationally representative survey of UK adults covering their awareness of and experiences with seven common safety technologies. We show that experience of online harms is widespread, with 67% of people having seen what they perceived as harmful content online; 26% of people have also had at least one piece of content removed by content moderation. Use of safety technologies is also high, with more than 80% of people having used at least one. Awareness of specific tools is varied, with people more likely to be aware of ‘post-hoc’ safety tools, such as reporting, than preventative measures. However, satisfaction with safety technologies is generally low. People who have previously seen online harms are more likely to use safety tools, implying a ‘learning the hard way’ route to engagement. Those higher in digital literacy are also more likely to use some of these tools, raising concerns about the accessibility of these technologies to all users. Additionally, women are more likely to engage in particular types of online ‘safety work’. We discuss the implications of our results for those seeking a safer online environment.


Keywords: Safety technology, User controls, User empowerment tools, Online Safety, Online harms, Survey research, Public attitudes",[''],[]
"A metric measure space equipped with a Dirichlet form is called recurrent if its Hausdorff dimension is less than its walk dimension. In bounded domains of such spaces we study the parabolic Anderson models



∂tu⁢(t,x)=Δ⁢u⁢(t,x)+β⁢u⁢(t,x)⁢W˙α⁢(t,x)subscript𝑡𝑢𝑡𝑥Δ𝑢𝑡𝑥𝛽𝑢𝑡𝑥subscript˙𝑊𝛼𝑡𝑥\partial_{t}u(t,x)=\Delta u(t,x)+\beta u(t,x)\,\dot{W}_{\alpha}(t,x)∂ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_u ( italic_t , italic_x ) = roman_Δ italic_u ( italic_t , italic_x ) + italic_β italic_u ( italic_t , italic_x ) over˙ start_ARG italic_W end_ARG start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT ( italic_t , italic_x )



where the noise Wαsubscript𝑊𝛼W_{\alpha}italic_W start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT is white in time and colored in space when α>0𝛼0\alpha>0italic_α > 0 while for α=0𝛼0\alpha=0italic_α = 0 it is also white in space. Both Dirichlet and Neumann boundary conditions are considered. Besides proving existence and uniqueness in the Itô sense we also get precise Lpsuperscript𝐿𝑝L^{p}italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT estimates for the moments and intermittency properties of the solution as a consequence. Our study reveals new exponents which are intrinsically associated to the geometry of the underlying space and the results for instance apply in metric graphs or fractals like the Sierpiński gasket for which we prove scaling invariance properties of the models.",[''],[]
"In this paper, we are concerned with the micro-macro Parareal algorithm for the simulation of initial-value problems.
In this algorithm, a coarse (fast) solver is applied sequentially over the time domain, and a fine (time-consuming) solver is applied as a corrector in parallel over smaller chunks of the time interval.
Moreover, the coarse solver acts on a reduced state variable, which is coupled to the fine state variable through appropriate coupling operators.
We first provide a contribution to the convergence analysis of the micro-macro Parareal method for multiscale linear ordinary differential equations (ODEs).
Then, we extend a variant of the micro-macro Parareal algorithm for scalar stochastic differential equations (SDEs) to higher-dimensional SDEs.
2020 MSC codes: 65L11, 34E13, 65C30, 68Q10, 65C35, 60H35;
Keywords: Parallel-in-time; Parareal; multiscale; McKean-Vlasov SDE; micro-macro; moment model; reduced model.",[''],[]
,[''],[]
"We survey the current state of affairs in the study of thresholds and sharp thresholds in random structures on the occasion of the recent proof of the Kahn–Kalai Conjecture by Park and Pham and the fairly recent proof of the satisfiability conjecture for large k𝑘kitalic_k by Ding, Sly, and Sun. Random discrete structures appear as fundamental objects of study in many scientific and mathematical fields including statistical physics, combinatorics, algorithms and complexity, social choice theory, coding theory, and statistics. While the models and properties of interest in these fields vary widely, much progress has been made through the development of general tools applicable to large families of models and properties all at once. Historically these tools originated to solve or make progress on specific, difficult conjectures in the areas mentioned above. We will survey recent progress on some of these hard problems and describe some challenges for the future.
This survey was prepared in conjunction with a talk for the Current Events Bulletin at the 2024 Joint Mathematics Meetings in San Francisco.",[''],[]
"By conceiving physical systems as 3D many-body point clouds, geometric graph neural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased promising performance. In particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. However, current geometric GNNs only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. To address this limitation, tensor networks, widely employed by computational physics to handle many-body systems using high-order tensors, have been introduced. Nevertheless, integrating these tensorized networks into the message-passing framework of GNNs faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. In response, we introduce an innovative equivariant Matrix Product State (MPS)-based message-passing strategy, through achieving an efficient implementation of the tensor contraction operation. Our method effectively models complex many-body relationships, suppressing mean-field approximations, and captures symmetries within geometric graphs. Importantly, it seamlessly replaces the standard message-passing and layer-aggregation modules intrinsic to geometric GNNs. We empirically validate the superior accuracy of our approach on benchmark tasks, including predicting classical Newton systems and quantum tensor Hamiltonian matrices. To our knowledge, our approach represents the inaugural utilization of parameterized geometric tensor networks.",[''],[]
Insert your english abstract here.,[''],[]
"Cut and project sets
are obtained by taking an irrational slice of a lattice and projecting it to
a lower dimensional subspace, and are fully characterised by the shape of
the slice (window) and the choice of the lattice. In this context we seek to quantify
fluctuations from the asymptotics for point counts. We obtain uniform upper
bounds on the discrepancy depending on the diophantine properties of the
lattice as well as universal lower bounds on the average of the discrepancy.
In an appendix, Michael Björklund and Tobias Hartnick obtain lower bounds on
the L2superscriptL2\mathrm{L}^{2}roman_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-norm of the discrepancy also depending on the diophantine class; these lower bounds match our uniform upper
bounds and both are therefore sharp.
Using the sufficient criteria of Burago–Kleiner and
Aliste-Prieto–Coronel–Gambaudo we find an explicit full-measure class of
cut and project sets that are biLipschitz equivalent to
lattices; the lower bounds on the variance indicate that this is the largest
class of cut-and-project sets for which those sufficient criteria can apply.",[''],[]
"Economic models produce moment inequalities, which can be used to form tests of the true parameters. Confidence sets (CS) of the true parameters are derived by inverting these tests. However, they often lack analytical expressions, necessitating a grid search to obtain the CS numerically by retaining the grid points that pass the test. When the statistic is not asymptotically pivotal, constructing the critical value for each grid point in the parameter space adds to the computational burden. In this paper, we convert the computational issue into a classification problem by using a support vector machine (SVM) classifier. Its decision function provides a faster and more systematic way of dividing the parameter space into two regions: inside vs. outside of the confidence set. We label those points in the CS as 1 and those outside as -1. Researchers can train the SVM classifier on a grid of manageable size and use it to determine whether points on denser grids are in the CS or not. We establish certain conditions for the grid so that there is a tuning that allows us to asymptotically reproduce the test in the CS. This means that in the limit, a point is classified as belonging to the confidence set if and only if it is labeled as 1 by the SVM.",[''],[]
"In physics and engineering literature, the distribution of the excursion-above-zero time distribution (exceedance distribution) for a stationary Gaussian process has been approximated by a stationary switching process with independently distributed switching times.
The approach matched the covariance of the clipped Gaussian process with the one for the stationary switching process and the distribution of the latter was used as the so-called independent interval approximation (IIA).
The approach successfully assessed the persistency exponent for many physically important processes but left an unanswered question when such an approach leads to a mathematically meaningful and proper exceedance distribution.
Here we address this question by proposing an alternative matching of the expected values of the clipped Slepian process and the corresponding switched process initiated at the origin.
The method has allowed resolving the mathematical correctness of the matching method for a large subclass of the Gaussian processes with monotonic covariance, for which we provide a sufficient condition for the validity of the IIA.
Within this class, the IIA produces a valid distribution for the excursion time and is represented in an explicit stochastic form that connects directly to the covariance of the underlying Gaussian process.
We compare the excursion level distributions as well as the corresponding persistency exponents obtained through the IIA method with numerically computed exact distributions, and the simulated distribution for several important Gaussian models.
We also argue that for stationary Gaussian processes with a non-monotonic covariance, the IIA fails and should not be used.","['Key words and phrases:', 'Slepian model,', 'Gaussian process, level crossing distributions, switching process, clipped process, renewal process']",[]
"Network meta-analysis (NMA) combines evidence from multiple trials to compare the effectiveness of a set of interventions. In public health research, interventions are often complex, made up of multiple components or features. This makes it difficult to define a common set of interventions on which to perform the analysis. One approach to this problem is component network meta-analysis (CNMA) which uses a meta-regression framework to define each intervention as a subset of components whose individual effects combine additively. In this paper, we are motivated by a systematic review of complex interventions to prevent obesity in children. Due to considerable heterogeneity across the trials, these interventions cannot be expressed as a subset of components but instead are coded against a framework of characteristic features. To analyse these data, we develop a bespoke CNMA-inspired model that allows us to identify the most important features of interventions. We define a meta-regression model with covariates on three levels: intervention, study, and follow-up time, as well as flexible interaction terms. By specifying different regression structures for trials with and without a control arm, we relax the assumption from previous CNMA models that a control arm is the absence of intervention components. Furthermore, we derive a correlation structure that accounts for trials with multiple intervention arms and multiple follow-up times. Although our model was developed for the specifics of the obesity data set, it has wider applicability to any set of complex interventions that can be coded according to a set of shared features.",[''],[]
"While it is commonly accepted that the disorder induced by magnetic ion doping in quantum magnets usually generates a rugged free-energy landscape resulting in slow or glassy spin dynamics, the disorder/distortion effects associated with non-magnetic ion sites doping are still illusive. Here, using AC susceptibility measurements, we show that the mixture of Sn/Ti on the non-magnetic ion sites of pyrochlore Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT(Ti1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPTSnx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPT)22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT induces an antiferromagnetic ground state despite both parent compounds, Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTTi22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT, and Yb22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTSn22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT, order ferromagnetically. Local structure studies through neutron total scattering reveals the local distortion in the non-magnetic ion sites and its strong correlation with the magnetic phase switching. Our study, for the first time, demonstrates the local distortion as induced by the non-magnetic ion site mixture could be a new path to achieve magnetic phase switching, which has been traditionally obtained by external stimuli such as temperature, magnetic field, pressure, strain, light etc.",[''],['Croatia']
"We present aMUSEd, an open-source, lightweight masked image model (MIM) for text-to-image generation based on MUSE (Chang et al. (2023)). With 10% of MUSE's parameters, aMUSEd is focused on fast image generation. We believe MIM is underexplored compared to latent diffusion (Rombach et al. (2022)), the prevailing approach for text-to-image generation. Compared to latent diffusion, MIM requires fewer inference steps (Chang et al. (2023)) and is more interpretable. Additionally, MIM can be fine-tuned to learn additional styles with only a single image (Sohn et al. (2023)). We hope to encourage further exploration of MIM by demonstrating its effectiveness on large-scale text-to-image generation and releasing reproducible training code. We also release checkpoints for two models which directly produce images at 256x256 and 512x512 resolutions.",[''],[]
,[''],[]
,[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Design of new drugs is a challenging process: a candidate molecule should satisfy multiple conditions to act properly and make the least side-effect – perfect candidates selectively attach to and influence only targets, leaving off-targets intact.
The amount of experimental data about various properties of molecules constantly grows, promoting data-driven approaches.
However, the applicability of typical predictive machine learning techniques can be substantially limited by a lack of experimental data about a particular target.
For example, there are many known Thrombin inhibitors (acting as anticoagulants), but a very limited number of known Protein C inhibitors (coagulants).
In this study, we present our approach to suggest new inhibitor candidates by building an effective representation of chemical space.
For this aim, we developed a deep learning model – autoencoder, trained on a large set of molecules in the SMILES format to map the chemical space.
Further, we applied different sampling strategies to generate novel coagulant candidates.
Symmetrically, we tested our approach on anticoagulant candidates, where we were able to predict their inhibition towards Thrombin.
We also compare our approach with MegaMolBART – another deep learning generative model, but exploiting similar principles of navigation in a chemical space.",[''],[]
,[''],[]
"It is a popular hypothesis in neuroscience that ganglion cells in the retina are activated by selectively detecting visual features in an observed scene.
While ganglion cell firings can be predicted via data-trained deep neural nets, the networks remain indecipherable, thus providing little understanding of the cells’ underlying operations.
To extract knowledge from the cell firings, in this paper we learn an interpretable graph-based classifier from data to predict the firings of ganglion cells in response to visual stimuli.
Specifically, we learn a positive semi-definite (PSD) metric matrix 𝐌⪰0succeeds-or-equals𝐌0{\mathbf{M}}\succeq 0bold_M ⪰ 0 that defines Mahalanobis distances between graph nodes (visual events) endowed with pre-computed feature vectors; the computed inter-node distances lead to edge weights and a combinatorial graph that is amenable to binary classification.
Mathematically, we define the objective of metric matrix 𝐌𝐌{\mathbf{M}}bold_M optimization using a graph adaptation of large margin nearest neighbor (LMNN), which is rewritten as a semi-definite programming (SDP) problem.
We solve it efficiently via a fast approximation called Gershgorin disc perfect alignment (GDPA) linearization.
The learned metric matrix 𝐌𝐌{\mathbf{M}}bold_M provides interpretability: important features are identified along 𝐌𝐌{\mathbf{M}}bold_M’s diagonal, and their mutual relationships are inferred from off-diagonal terms.
Our fast metric learning framework can be applied to other biological systems with pre-chosen features that require interpretation.",[''],['Canada']
"Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by tracking concept saliency and similarity in pruned neurons during retraining. Our findings reveal that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. This demonstrates that models exhibit polysemantic capacities and can blend old and new concepts in individual neurons. While neuron pruning provides interpretability into model concepts, our results highlight the challenges of permanent concept removal for improved model safety. Monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts will be important directions for more robust model editing. Overall, our work strongly demonstrates the resilience and fluidity of concept representations in LLMs post concept removal.",[''],[]
A model of space-time foam in the form of an arbitrary distribution of spherical Euclidean wormholes is considered. A method for constructing the exact solution of Einstein’s Euclidean equations for the metric corresponding to this model is proposed. In the framework of our model we obtain the expression for the Euclidean action and its dependence on the parameters of wormholes in the explicit form. It is shown how the solutions obtained make it possible to determine all possible correlation functions associated with the parameters of virtual wormholes in the vacuum state.,[''],[]
"A general modulus of continuity is quantified for locally bounded, local, weak solutions to nonlocal parabolic equations,
under a minimal tail condition. Hölder modulus of continuity is then deduced under a slightly stronger tail condition.
These regularity estimates are demonstrated under the framework of nonlocal p𝑝pitalic_p-Laplacian with measurable kernels.
Mathematics Subject Classification (2020): 35R11, 35K65, 35B65, 47G20

Key Words: Hölder regularity, parabolic p𝑝pitalic_p-Laplacian, nonlocal operators, intrinsic scaling",[''],[]
"This study tasckles the problem of many-objective sequence optimization for semi-automated robotic disassembly operations. To this end, we employ a many-objective genetic algorithm (MaOGA) algorithm inspired by the Non-dominated Sorting Genetic Algorithm (NSGA)-III, along with robotic-disassembly-oriented constraints and objective functions derived from geometrical and robot simulations using 3-dimensional (3D) geometrical information stored in a 3D Computer-Aided Design (CAD) model of the target product. The MaOGA begins by generating a set of initial chromosomes based on a contact and connection graph (CCG), rather than random chromosomes, to avoid falling into a local minimum and yield repeatable convergence. The optimization imposes constraints on feasibility and stability as well as objective functions regarding difficulty, efficiency, prioritization, and allocability to generate a sequence that satisfies many preferred conditions under mandatory requirements for semi-automated robotic disassembly.
The NSGA-III-inspired MaOGA also utilizes non-dominated sorting and niching with reference lines to further encourage steady and stable exploration and uniformly lower the overall evaluation values. Our sequence generation experiments for a complex product (36 parts) demonstrated that the proposed method can consistently produce feasible and stable sequences with a 100% success rate, bringing the multiple preferred conditions closer to the optimal solution required for semi-automated robotic disassembly operations.","['Index', 'Terms: ', 'Robotic disassembly,', 'Disassembly sequence,', 'Many-objective optimization,', 'NSGA-III']",[]
"The growing demand for natural interactions with technology underscores the importance of achieving realistic touch sensations in digital environments. Realizing this goal highly depends on comprehensive databases of finger-surface interactions, which need further development. Here, we present SENS3, an extensive open-access repository of multisensory data acquired from fifty surfaces when two participants explored them with their fingertips through static contact, pressing, tapping, and sliding. SENS3 encompasses high-fidelity visual, audio, and haptic information recorded during these interactions, including videos, sounds, contact forces, torques, positions, accelerations, skin temperature, heat flux, and surface photographs. Additionally, it incorporates thirteen participants’ psychophysical sensation ratings while exploring these surfaces freely. We anticipate that SENS3 will be valuable for advancing multisensory texture rendering, user experience development, and touch sensing in robotics.","['Texture', 'Dataset', 'Haptic', 'Multisensory', 'Sensation']",[]
"Given a prime power q𝑞qitalic_q and a positive integer n𝑛nitalic_n, let 𝔽qnsubscript𝔽superscript𝑞𝑛\mathbb{F}_{q^{n}}blackboard_F start_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT represents a finite extension of degree n𝑛nitalic_n of the finite field 𝔽qsubscript𝔽𝑞{\mathbb{F}_{q}}blackboard_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT. In this article, we investigate the existence of m𝑚mitalic_m elements in arithmetic progression, where every element is primitive and at least one is normal with prescribed norms. Moreover, for n≥6,q=3k,m=2formulae-sequence𝑛6formulae-sequence𝑞superscript3𝑘𝑚2n\geq 6,q=3^{k},m=2italic_n ≥ 6 , italic_q = 3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , italic_m = 2 we establish that there are only 10101010 possible exceptions.",[''],[]
"Predictions for processes involving soft photons,
up to next-to-leading power (NLP) in the photon energy,
can be obtained using the Low-Burnett-Kroll (LBK) theorem.
The consistency of the theorem has been a recent topic of investigation
since it is traditionally formulated in terms of a non-radiative
amplitude, which is evaluated with unphysical momenta.
We address such questions and propose a formulation of the
LBK theorem which relies on the evaluation of the non-radiative
amplitude with on-shell, physical momenta.
We use this form to numerically study the impact
of NLP contributions to cross-sections for p⁢p𝑝𝑝ppitalic_p italic_p and
e−⁢e+superscript𝑒superscript𝑒e^{-}e^{+}italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT processes involving soft-photon emission.",[''],[]
"The geodesic method has played a crucial role in understanding the circular orbits generated by compact objects, culminating in the definition of the photon sphere, which was later generalized to a photon surface in arbitrary spacetimes. This new formulation extends the concept of the photon sphere in a broader sense, including dynamical spacetimes, as shown by the Vaidya solution. The photon surface essentially defines the null geodesics, which are originally tangent to the temporal surface, and keeps them confined to this surface. However, this formalism does not cover all classes of particles, and to overcome this limitation, a more comprehensive approach, denoted as the “massive particle surface”, has been proposed that also accounts for charged massive particles. Indeed, the photon surface concept is recovered when the charge and mass of the particles are zero. In this work, we use these three formalisms to check the consistency of the results for the values of the radius of the photon sphere (rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT) and the radius of the “innermost stable circular orbit” (ISCO) (rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT) for some gravitational models. In our results, the first model is described by conformal gravity, with the peculiarity that g00≠−g11−1subscript𝑔00superscriptsubscript𝑔111g_{00}\neq-g_{11}^{-1}italic_g start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT ≠ - italic_g start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. The second model, i.e. Culetu model, is developed by coupling General Relativity (GR) with nonlinear electrodynamics (NLED), which requires the consideration of the effective metric (geffμ⁢νsuperscriptsubscript𝑔eff𝜇𝜈g_{\rm eff}^{\mu\nu}italic_g start_POSTSUBSCRIPT roman_eff end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_μ italic_ν end_POSTSUPERSCRIPT) for geodesic approaches, for example.
Under these circumstances, we have found that the value for the radius of the photon sphere (rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT) obtained by the massive particle surface formalism in the conformal gravity case does not agree with the values obtained by the geodesic and photon surface formalisms. Similarly, the values for rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT differ between the geodesic and the massive particle surface formalisms. In Culetu’s model, we found the same values for the radius of the photon sphere rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT when we consider the effective metric in the geodesic and photon surface formalisms. However, when we apply the massive particle surface formalism, we find an inconsistency with the values of the other two formalisms. Finally, we have examined the expressions for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT and rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT for a spherically symmetric and generally static metric arising from the massive particle surface method. We find that the expression for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT, for example, differs from the photon surface method, as does the expression for rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT, which differs from the geodesic formalism. Moreover, we highlight a significant difference in the two expressions obtained for a static and spherically symmetric metric in general, as they exhibit a dependence on the metric function −g11=B⁢(r)subscript𝑔11𝐵𝑟-g_{11}=B(r)- italic_g start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = italic_B ( italic_r ), unlike the other expressions for rp⁢ssubscript𝑟𝑝𝑠r_{ps}italic_r start_POSTSUBSCRIPT italic_p italic_s end_POSTSUBSCRIPT and rISCOsubscript𝑟ISCOr_{\rm ISCO}italic_r start_POSTSUBSCRIPT roman_ISCO end_POSTSUBSCRIPT in the other two formalisms.",[''],"['Brazil', 'Brazill', 'Portugal', 'Portugal', 'Brazill', 'Brazil', 'Portugal', 'Brazill']"
"Connected and automated vehicles (CAVs) have become a transformative technology that can change our daily life.
Currently, millimeter-wave (mmWave) bands are identified as the promising CAV connectivity solution. While it can provide high data rate, their realization faces many challenges such as high attenuation during mmWave signal propagation and mobility management. Existing solution has to initiate pilot signal to measure channel information, then apply signal processing to calculate the best narrow beam towards the receiver end to guarantee sufficient signal power. This process takes significant overhead and time, hence not suitable for vehicles. In this study, we propose an autonomous and low-cost testbed to collect extensive co-located mmWave signal and other sensors data such as LiDAR (Light Detection and Ranging), cameras, ultrasonic, etc, traditionally for “automated”, to facilitate mmWave vehicular communications. Intuitively, these sensors can build a 3D map around the vehicle and signal propagation path can be estimated, eliminating iterative the process via pilot signals. This multimodal data fusion, together with AI, is expected to bring significant advances in “connected” research.","['Index', 'Terms: ', 'Vehicular communication, mmWave communication, sensor fusion, machine learning.']",['2hsun@uga.edu']
"We introduce the video detours problem for navigating instructional videos. Given a source video and a natural language query asking to alter the how-to video’s current path of execution in a certain way, the goal is to find a related “detour video” that satisfies the requested alteration. To address this challenge, we propose VidDetours, a novel video-language approach that learns to retrieve the targeted temporal segments from a large repository of how-to’s using video-and-text conditioned queries. Furthermore, we devise a language-based pipeline that exploits how-to video narration text to create weakly supervised training data.
We demonstrate our idea applied to the domain of how-to cooking videos, where a user can detour from their current recipe to find steps with alternate ingredients, tools, and techniques. Validating on a ground truth annotated dataset of 16K samples, we show our model’s significant improvements over best available methods for video retrieval and question answering, with recall rates exceeding the state of the art by 35%.",[''],[]
"The investigation of many-body interactions holds significant importance in both quantum foundations and information. Hamiltonians coupling multiple particles at once, beyond others, can lead to a faster entanglement generation, multiqubit gate implementation and improved error correction. As an increasing number of quantum platforms enable the realization of such physical settings, it becomes interesting to study the verification of many-body interaction resources. In this work, we explore the possibility of higher-order couplings detection through the quantum Fisher information. For a family of symmetric and translationally invariant k𝑘kitalic_k-body Ising-like Hamiltonians, we derive the bounds on the quantum Fisher information in product states. Due to its ordering with respect to the order of interaction, we demonstrate the possibility of detecting many-body couplings for a given Hamiltonian from the discussed family by observing violations of an appropriate bound.",[''],"['Poland', 'Poland', 'Poland', 'Poland', 'Poland']"
"The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://physio.inesctec.pt.","['Retrieval-augmented generation', 'Information extraction', 'Conversational health agents']",[]
,[''],[]
"Most existing video diffusion models (VDMs) are limited to mere text conditions. Thereby, they are usually lacking in control over visual appearance and geometry structure of the generated videos. This work presents MoonShot, a new video generation model that conditions simultaneously on multimodal inputs of image and text. The model builts upon a core module, called multimodal video block (MVB), which consists of conventional spatialtemporal layers for representing video features, and a decoupled cross-attention layer to address image and text inputs for appearance conditioning. In addition, we carefully design the model architecture such that it can optionally integrate with pre-trained image ControlNet modules for geometry visual conditions, without needing of extra training overhead as opposed to prior methods. Experiments show that with versatile multimodal conditioning mechanisms, MoonShot demonstrates significant improvement on visual quality and temporal consistency compared to existing models. In addition, the model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing, unveiling its potential to serve as a fundamental architecture for controllable video generation. Models will be made public on https://github.com/salesforce/LAVIS.",[''],[]
"Energy disaggregation is a promising solution to access detailed information on energy consumption in a household, by itemizing its total energy consumption. However, in real-world applications, overfitting remains a challenging problem for data-driven disaggregation methods. First, the available real-world datasets are biased towards the most frequently used appliances. Second, both real and synthetic publicly-available datasets are limited in number of appliances, which may not be sufficient for a disaggregation algorithm to learn complex relations among different types of appliances and their states. To address the lack of appliance data, we propose two physics-informed data generators: one for high sampling rate signals (kHz) and another for low sampling rate signals (Hz). These generators rely on prior knowledge of the physics of appliance energy consumption, and are capable of simulating a virtually unlimited number of different appliances and their corresponding signatures for any time period. Both methods involve defining a mathematical model, selecting centroids corresponding to individual appliances, sampling model parameters around each centroid, and finally substituting the obtained parameters into the mathematical model. Additionally, by using Principal Component Analysis and Kullback-Leibler divergence, we demonstrate that our methods significantly outperform the previous approaches.","['Index', 'Terms: \nenergy disaggregation, non-intrusive load monitoring, synthetic data, physics-informed methods']",['H.Ouerdane@skoltech.ru']
"High-energy photons may oscillate with axion-like particles (ALPs) when they propagate through the Milky Way’s magnetic field, resulting in an alteration in the observed photon energy spectrum. The ultra-high energy gamma-ray spectra, measured by the Large High Altitude Air Shower Observatory (LHAASO) up to 𝒪⁢(1)⁢PeV𝒪1PeV\mathcal{O}(1)~{}\mathrm{PeV}caligraphic_O ( 1 ) roman_PeV, provide a promising opportunity to investigate the ALP-photon oscillation effect. In this study, we utilize the gamma-ray spectra of four Galactic sources measured by LHAASO, including the Crab Nebula, LHAASO J2226+6057, LHAASO J1908+0621, and LHAASO J1825-1326, to explore this effect. We employ the CLssubscriptCLs\rm CL_{s}roman_CL start_POSTSUBSCRIPT roman_s end_POSTSUBSCRIPT method to set constraints on the ALP parameters.
Combing the observations of the four sources, our analysis reveals that the ALP-photon coupling ga⁢γsubscript𝑔𝑎𝛾g_{a\gamma}italic_g start_POSTSUBSCRIPT italic_a italic_γ end_POSTSUBSCRIPT is constrained to be smaller than
1.4×10−101.4superscript10101.4\times 10^{-10}1.4 × 10 start_POSTSUPERSCRIPT - 10 end_POSTSUPERSCRIPT GeV−1superscriptGeV1{\rm GeV}^{-1}roman_GeV start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT for the ALP mass of ∼4×10−7⁢eVsimilar-toabsent4superscript107eV\sim 4\times 10^{-7}~{}\mathrm{eV}∼ 4 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT roman_eV at the 95% C.L.
By combing the observations of the Crab Nebula from LHAASO and other experiments, we find that the ALP-photon coupling could be set to be about 7.2×10−117.2superscript10117.2\times 10^{-11}7.2 × 10 start_POSTSUPERSCRIPT - 11 end_POSTSUPERSCRIPT GeV−1superscriptGeV1{\rm GeV}^{-1}roman_GeV start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT
for the ALP mass ∼4×10−7⁢eVsimilar-toabsent4superscript107eV\sim 4\times 10^{-7}~{}\mathrm{eV}∼ 4 × 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT roman_eV , which is in close proximity to the CAST constraint.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets.",['text augmentation data augmentation mask filling language modeling'],[]
,[''],[]
,[''],[]
"Inference on overall ranking of a set of entities, such as chess players, subpopulations or hospitals, is an important problem. Estimation of ranks based on point estimates of means does not account for the uncertainty in those estimates. Treating estimated ranks without regard for uncertainty is problematic. We propose a Bayesian solution. It is competitive with recent frequentist methods, and more effective and informative, and is as easy to implement as it is to compute the posterior means and variances of the entity means. Using credible sets, we created novel credible distributions for the rank vector of the entities. We evaluate the Bayesian procedure in terms of accuracy and stability in two applications and a simulation study. Frequentist approaches cannot take account of covariates, but the Bayesian method handles them easily.",[''],[]
"Let T𝑇Titalic_T be a satellite knot, link, or spatial graph in a 3-manifold M𝑀Mitalic_M that is either S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT or a lens space. Let 𝔟0subscript𝔟0\mathfrak{b}_{0}fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and 𝔟1subscript𝔟1\mathfrak{b}_{1}fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT denote genus 0 and genus 1 bridge number, respectively. Suppose that T𝑇Titalic_T has a companion knot K𝐾Kitalic_K and wrapping number ω𝜔\omegaitalic_ω with respect to K𝐾Kitalic_K. When K𝐾Kitalic_K is not a torus knot, we show that 𝔟1⁢(T)≥ω⁢𝔟1⁢(K)subscript𝔟1𝑇𝜔subscript𝔟1𝐾\mathfrak{b}_{1}(T)\geq\omega\mathfrak{b}_{1}(K)fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_T ) ≥ italic_ω fraktur_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_K ). There are previously known counter-examples if K𝐾Kitalic_K is a torus knot. Along the way, we generalize and give a new proof of Schubert’s result that 𝔟0⁢(T)≥ω⁢𝔟0⁢(K)subscript𝔟0𝑇𝜔subscript𝔟0𝐾\mathfrak{b}_{0}(T)\geq\omega\mathfrak{b}_{0}(K)fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_T ) ≥ italic_ω fraktur_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_K ). We also prove versions of the theorem applicable to when T𝑇Titalic_T is a “lensed satellite” or when there is a torus separating components of T𝑇Titalic_T.",[''],[]
"Controlling complex dynamical systems is generally associated with minimizing certain control objectives with known dynamics under the variational calculus framework. For systems with unknown dynamics, an additional step of dynamics modeling is required. However, any inaccuracy in dynamics modeling will lead to sub-optimality in the resulting control function. Another set of approaches for controlling unknown dynamical systems - reinforcement learning, folds the dynamics modeling into controller training via value function approximation or policy gradient through extensively interacting with the environment, but it suffers from low data efficiency. To address these, we introduce NODEC, a novel framework for controlling unknown dynamical systems, which combines dynamics modelling and controller training using a coupled neural ODE model. Through an intriguing interplay between the two coupled neural networks, NODEC learns system dynamics as well as optimal controls that guides the unknown dynamical system towards target states. Our experiments demonstrate the effectiveness and data efficiency of NODEC for learning optimal control of unknown dynamical systems.",[''],[]
"Photodissociated gas bears the signature of the dynamical evolution of the
ambient interstellar medium impacted by the mechanical and radiative feedback
from an expanding H ii region. Here we present an analysis of the kinematics of
the young Trifid nebula, based on velocity-resolved observations of the far-infrared fine-structure lines of [C ii] at 158 µm and [O i] at 63 µm. The distribution of the photodissociated regions (PDRs) surrounding the nebula is consistent with a shell-like structure created by the H ii region expanding with a velocity of 5 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. Comparison of ratios of [C ii] and [O i]63 µm intensities for identical velocity components with PDR models indicate a density of 1044{}^{4}start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT. The red- and blue-shifted PDR shells with a combined mass of 516 M⊙subscriptMdirect-product\mathrm{M}_{\odot}roman_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT have a kinetic energy of ∼1047similar-toabsentsuperscript1047\sim 10^{47}∼ 10 start_POSTSUPERSCRIPT 47 end_POSTSUPERSCRIPT erg. This is consistent with the thermal energy of the H ii region as well as with the energy deposited by the stellar wind luminosity from HD 169442A, an O7 V star, over the 0.5 Myr lifetime of the star. The observed momentum of the PDR shell is lower than what theoretical calculations predict for the radial momentum due to the shell being swept up by an expanding H ii region, which suggests that significant mass loss has occurred in M20 due to the dispersal of the surrounding gas by the advancing ionization front.","['ISM: clouds –', 'ISM: kinematics and dynamics – submillimetre:', 'ISM –', 'ISM: structure\n– stars: formation –', 'ISM:individual (M20)']","['India', 'USA']"
"Over the past century, an intense debate in statistical mechanics has been about the correctness of Boltzmann’s surface entropy versus Gibbs’ volume entropy, for isolated systems. Both entropies make significantly different predictions for systems with few degrees of freedom. Even in the thermodynamic limit, they can disagree—while Boltzmann entropy allows negative absolute temperatures to exist, Gibbs entropy precludes such a possibility. Here, we show that modifying Boltzmann’s entropy via a relative energy tolerance eliminates thermodynamic inconsistencies in several model systems with unbounded energy spectra by ensuring positive, finite temperatures. Concomitantly, the proposed entropy allows for negative temperatures in systems with bounded spectra and closely matches canonical ensemble predictions. This work conclusively remedies the prevalent deficiencies of the Gibbs and Boltzmann entropy formulations and paves the way for the use of the modified Boltzmann entropy in the microcanonical ensemble, allowing negative temperatures to exist.",[''],['India']
"Visible-infrared person re-identification (VI-ReID) is challenging due to the significant cross-modality discrepancies between visible and infrared images.
While existing methods have focused on designing complex network architectures or using metric learning constraints to learn modality-invariant features, they often overlook which specific component of the image causes the modality discrepancy problem.
In this paper, we first reveal that the difference in the amplitude component of visible and infrared images is the primary factor that causes the modality discrepancy and further propose a novel Frequency Domain modality-invariant feature learning framework (FDMNet) to reduce modality discrepancy from the frequency domain perspective.
Our framework introduces two novel modules, namely the Instance-Adaptive Amplitude Filter (IAF) module and the Phrase-Preserving Normalization (PPNorm) module, to enhance the modality-invariant amplitude component and suppress the modality-specific component at both the image- and feature-levels.
Extensive experimental results on two standard benchmarks, SYSU-MM01 and RegDB, demonstrate the superior performance of our FDMNet against state-of-the-art methods.",[''],[]
"This paper reviews (and expands) some recent results on the modeling of aggregation-diffusion phenomena at various scales, focusing on the emergence of collective dynamics as a result of the competition between attractive and repulsive phenomena - especially (but not exclusively) in the context of attractive chemotaxis phenomena.
At microscopic scales, particles (or other agents) are represented by spheres of radius δ>0𝛿0\delta>0italic_δ > 0 and we discuss both soft-sphere models (with a pressure term penalizing the overlap of the particles) and hard-sphere models (in which overlap is prohibited). The first case leads to so-called “blob models” which have received some attention recently as a tool to approximate non-linear diffusion by particle systems. The hard-sphere model
is similar to a classical model for congested crowd motion.
We will review well-posedness results for these models and discuss their relationship to classical continuum description of aggregation-diffusion phenomena in the limit δ→0→𝛿0\delta\to 0italic_δ → 0: the classical nonlinear drift diffusion equation and its incompressible counterpart.
In the second part of the paper, we discuss recent results on the emergence and evolution of sharp interfaces when a large population of particles is considered at appropriate space and time scales:
At some intermediate time scale, phase separation occurs and a sharp interface appears which evolves according to a Stefan free boundary problem (and the density function eventually relaxes to a characteristic function - metastable steady state for the original problem). At a larger time scale the attractive forces lead to surface tension phenomena and the evolution of the sharp interface can be described by a Hele-Shaw free boundary problem with surface tension. At that same time scale, we will also discuss the emergence of contact angle conditions for problems set in bounded domains.",[''],[]
"A fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. Such problems are traditionally modeled as non-stationary Markov decision processes (NSMDP). However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts “safely” to account for the non-stationary evolution of the environment. We argue that both these assumptions are invalid in practice—updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. We present a heuristic search algorithm called Adaptive Monte Carlo Tree Search (ADA-MCTS) that addresses these challenges. We show that the agent can learn the updated dynamics of the environment over time and then act as it learns, i.e., if the agent is in a region of the state space about which it has updated knowledge, it can avoid being pessimistic. To quantify “updated knowledge,” we disintegrate the aleatoric and epistemic uncertainty in the agent’s updated belief and show how the agent can use these estimates for decision-making. We compare the proposed approach with the multiple state-of-the-art approaches in decision-making across multiple well-established open-source problems and empirically show that our approach is faster and highly adaptive without sacrificing safety.",[''],[]
"Nonnegative tensor factorization (NTF) has become an important tool for feature extraction and part-based representation with preserved intrinsic structure information from nonnegative high-order data.
However, the original NTF methods utilize Euclidean or Kullback-Leibler divergence as the loss function which treats each feature equally leading to the neglect of the side-information of features.
To utilize correlation information of features and manifold information of samples, we introduce Wasserstein manifold nonnegative tensor factorization (WMNTF), which minimizes the Wasserstein distance between the distribution of input tensorial data and the distribution of reconstruction.
Although some researches about Wasserstein distance have been proposed in nonnegative matrix factorization (NMF), they ignore the spatial structure information of higher-order data.
We use Wasserstein distance (a.k.a. Earth Mover’s distance or Optimal Transport distance) as a metric and add a graph regularizer to a latent factor.
Experimental results demonstrate the effectiveness of the proposed method compared with other NMF and NTF methods.",[''],[]
"Using large training datasets enhances the generalization capabilities of neural networks.
Semi-supervised learning (SSL) is useful when there are few labeled data and a lot of unlabeled data.
SSL methods that use data augmentation are most successful for image datasets.
In contrast, texts do not have consistent augmentation methods as images.
Consequently, methods that use augmentation are not as effective in text data as they are in image data.
In this study, we compared SSL algorithms that do not require augmentation; these are self-training, co-training, tri-training, and tri-training with disagreement.
In the experiments, we used 4 different text datasets for different tasks.
We examined the algorithms from a variety of perspectives by asking experiment questions and suggested several improvements.
Among the algorithms, tri-training with disagreement showed the closest performance to the Oracle; however, performance gap shows that new semi-supervised algorithms or improvements in existing methods are needed.","['Index', 'Terms: \nsemi supervised learning, self-training, co-training, tri-training, tri-training with disagreement']","['tkesgin@yildiz.edu.tr', 'amasyali@yildiz.edu.tr']"
"The crystallographic restriction theorem constrains two-dimensional
nematicity to display either Ising (Z2subscript𝑍2Z_{2}italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) or three-state-Potts
(Z3subscript𝑍3Z_{3}italic_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) critical behaviors, both of which are dominated by amplitude
fluctuations. Here, we use group theory and microscopic modeling to
show that this constraint is circumvented in a 30∘superscript3030^{\circ}30 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT-twisted
hexagonal bilayer due to its emergent quasicrystalline symmetries.
We find a critical phase dominated by phase fluctuations of a Z6subscript𝑍6Z_{6}italic_Z start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT
nematic order parameter and bounded by two Berezinskii-Kosterlitz-Thouless
(BKT) transitions, which displays only quasi-long-range nematic order.
The electronic spectrum in the critical phase displays a thermal pseudogap-like
behavior, whose properties depend on the anomalous critical exponent.
We also show that an out-of-plane magnetic field induces nematic phase
fluctuations that suppress the two BKT transitions via a mechanism
analogous to the Hall viscoelastic response of the lattice, giving
rise to a putative nematic quantum critical point with emergent continuous
symmetry. Finally, we demonstrate that even in the case of an untwisted
bilayer, a critical phase emerges when the nematic order parameter
changes sign between the two layers, establishing an odd-parity nematic
state.",[''],"['USA', 'USA', 'USA']"
"Hille’s theorem is a powerful classical result in vector measure theory.
It asserts that the application of a closed, unbounded linear operator commutes with strong/Bochner integration of functions taking values in a Banach space.
This note shows that Hille’s theorem also holds in the setting of complete locally convex spaces.
Keywords. Bochner integral ∙∙\bullet∙ closed operator ∙∙\bullet∙ Hille’s theorem ∙∙\bullet∙ locally convex space ∙∙\bullet∙ strong integral ∙∙\bullet∙ unbounded operator
2020 Mathematics Subject Classification. 28B05 ∙∙\bullet∙ 28C20 ∙∙\bullet∙ 46G10",[''],[]
"Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.",[''],[]
"We provide an exposition of a ‘horizontal’ generalization of Goodman’s surgery operation on (pseudo-)Anosov flows.
This operation is performed by cutting along a specific kind of annulus that is transverse to the flow and regluing with a Dehn twist of the appropriate sign.
We then show that performing horizontal Goodman surgery on a transitive pseudo-Anosov flow yields an almost equivalent flow, i.e. the original flow and the surgered flow are orbit equivalent after drilling out a finite collection of closed orbits.
We obtain some almost equivalence results by applying this theorem on examples of the surgery operation.
Along the way, we also show a structural stability result for pseudo-Anosov flows.",[''],[]
"The Global Ecosystem Dynamics Investigation (GEDI) is a spaceborne lidar instrument that collects near-global measurements of forest structure. While expansive in scope, GEDI samples are spatially sparse and cover a small fraction of the land surface. Converting the sparse samples into spatially complete predictive maps is of practical importance for a number of ecological studies. A complicating factor is that GEDI collects measurements over forested and non-forested land alike, with no automatic labeling of the land type. Such classification is important, as it categorically influences the probability distribution of the spatial process and the ecological interpretation of the observations/predictions. We propose and implement a spatial mixture model, separating the observations and the greater spatial domain into two latent classes. The latent classes are governed by a Bernoulli spatial process, with spatial effects driven by a Gaussian process. Within each class, the process is governed by a separate spatial model, describing the unique probabilistic attributes. Model predictions take the form of scalar predictions of the GEDI observables as well as discrete labeling of the class membership. Inference is conducted through a Bayesian paradigm, yielding rich quantification of prediction and uncertainty through posterior predictive distributions. We demonstrate the method using GEDI data over Wollemi National Park, Australia, using optical data from Landsat 8 as model covariates. When compared to a single spatial model, the mixture model achieves much higher posterior predictive densities on the true value. When compared to a random forest model, a common algorithmic approach in the remote sensing community, the random forest achieves better absolute prediction accuracy for prediction locations far from observed training data locations, but at the expense of location-specific assessments of uncertainty. The unsupervised binary classifications of the mixture model appear broadly ecologically interpretable as forest and non-forest when compared to optical imagery, but further comparison to ground-truth data is required.",[''],[]
"In designing external validation studies of clinical prediction models,
contemporary sample size calculation methods are based on the
frequentist inferential paradigm. One of the widely reported metrics of
model performance is net benefit (NB), and the relevance of conventional
inference around NB as a measure of clinical utility is doubtful. Value
of Information methodology quantifies the consequences of uncertainty in
terms of its impact on clinical utility of decisions. We introduce the
expected value of sample information (EVSI) for validation as the
expected gain in NB from conducting an external validation study of a
given size. We propose algorithms for EVSI computation, and in a case
study demonstrate how EVSI changes as a function of the amount of
current information and future study’s sample size. Value of Information
methodology provides a decision-theoretic lens to the process of
planning a validation study of a risk prediction model and can
complement conventional methods when designing such studies.",[''],[]
"We investigate the impact of confinement density (i.e the number of individuals in a group per unit area of available space) on transitions from polarized to milling state, using groups of rummy-nose tetrafish (Hemigrammus rhodostomus) under controlled experimental conditions. We demonstrate for the first time a continuous state transition controlled by confinement density in a group of live animals. During this transition, the school exhibits a bistable state, wherein both polarization and milling states coexist, with the group randomly alternating between them. A simple two-state Markov process describes the observed transition remarkably
well. Importantly, the confinement density influences the statistics of this bistability, shaping the distribution of transition times between states. Our findings suggest that confinement plays a crucial role in state transitions for moving animal groups, and, more generally, they constitute a solid experimental benchmark for active matter models of macroscopic, self-propelled, confined agents.",[''],['France']
"This work examines the effects of variations in machine learning training regimes and learning paradigms on the corresponding energy consumption.
While increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also supports the fading perception of energy consumption and carbon emission.
Therefore, the goal of this work is to create awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. Multiple setups with different hyperparameter initializations are evaluated on two different hardware configurations to obtain meaningful results.
Experiments on pretraining and multitask training are conducted on top of the baseline results to determine their potential towards sustainable machine learning.",[''],[]
,[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"We use the VERITAS imaging air Cherenkov Telescope (IACT) array to obtain the first measured angular diameter of β𝛽\betaitalic_β UMa at visual wavelengths using stellar intensity interferometry (SII) and independently constrain the limb-darkened angular diameter.
The age of the Ursa Major moving group has been assessed from the ages of its members, including nuclear member Merak (β𝛽\betaitalic_β UMa), an A1-type subgiant, by comparing effective temperature and luminosity constraints to model stellar evolution tracks.
Previous interferometric limb-darkened angular-diameter measurements of β𝛽\betaitalic_β UMa in the near-infrared (CHARA Array, 1.149 ±plus-or-minus\pm± 0.014 mas) and mid-infrared (Keck Nuller, 1.08 ±plus-or-minus\pm± 0.07 mas), together with the measured parallax and bolometric flux, have constrained the effective temperature.
This paper presents current VERITAS-SII observation and analysis procedures to derive squared visibilities from correlation functions.
We fit the resulting squared visibilities to find a limb-darkened angular diameter of 1.07±0.04⁢(stat)±0.05plus-or-minus1.070.04stat0.051.07\pm 0.04{\rm~{}(stat)}\pm 0.051.07 ± 0.04 ( roman_stat ) ± 0.05 (sys) mas, using synthetic visibilities from a stellar atmosphere model that provides a good match to the spectrum of β𝛽\betaitalic_β UMa in the optical wave band. The VERITAS-SII limb-darkened angular diameter yields an effective temperature of 9700±200±200plus-or-minus97002002009700\pm 200\pm 2009700 ± 200 ± 200 K,
consistent with ultraviolet spectrophotometry, and an age of 390±29±32plus-or-minus3902932390\pm 29\pm 32390 ± 29 ± 32 Myr, using MESA Isochrones and Stellar Tracks (MIST). This age is consistent with 408 ±plus-or-minus\pm± 6 Myr from the CHARA Array angular diameter.","['Long baseline interferometry (932),', 'Fundamental parameters of stars (555),', 'Astronomy data modeling (1859)']","['USA', 'USA', 'USA', 'USA', 'Germany', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Germany', 'USA', 'USA', 'USA', 'Canada', 'France', 'USA', 'Ireland', 'USA', 'Ireland', 'USA', '3N6', 'USA', 'Germany', 'Germany', 'Ireland', 'USA', 'Canada', 'USA', 'USA', 'USA', 'Germany', 'USA', 'USA', 'USA', 'Germany', 'USA', 'USA', 'Canada']"
"As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those languages.
Finally, we find that increasing the number of languages in the instruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual generalization. Our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses.",[''],[]
"Density estimation, a central problem in machine learning, can be performed using Normalizing Flows (NFs). NFs comprise a sequence of invertible transformations, that turn a complex target distribution into a simple one, by exploiting the change of variables theorem.
Neural Autoregressive Flows (NAFs) and Block Neural Autoregressive Flows (B-NAFs) are arguably the most perfomant members of the NF family. However, they suffer scalability issues and training instability due to the constraints imposed on the network structure.
In this paper, we propose a novel solution to these challenges by exploiting transformers to define a new class of neural flows called Transformer Neural Autoregressive Flows (T-NAFs). T-NAFs treat each dimension of a random variable as a separate input token, using attention masking to enforce an autoregressive constraint. We take an amortization-inspired approach where the transformer outputs the parameters of an invertible transformation. The experimental results demonstrate that T-NAFs consistently match or outperform NAFs and B-NAFs across multiple datasets from the UCI benchmark. Remarkably, T-NAFs achieve these results using an order of magnitude fewer parameters than previous approaches, without composing multiple flows.",[''],[]
"We numerically address the issue of which monopole operators are
relevant under renormalization group flow in three-dimensional
parity-invariant noncompact QED with 4444 flavors of massless
two-component Dirac fermion. Using lattice simulation and finite-size
scaling analysis of the free energy to introduce monopole-antimonopole
pairs in N=4𝑁4N=4italic_N = 4 and N=12𝑁12N=12italic_N = 12 flavor noncompact QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, we estimate
the infrared scaling dimensions of monopole operators that introduce
2⁢π2𝜋2\pi2 italic_π and 4⁢π4𝜋4\pi4 italic_π fluxes around them. We first show that the
estimates for the monopole scaling dimensions are consistent with
the large-N𝑁Nitalic_N expectations for N=12𝑁12N=12italic_N = 12 QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. Applying the same
procedure in N=4𝑁4N=4italic_N = 4 QED33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, we estimate the scaling dimension of
4⁢π4𝜋4\pi4 italic_π flux monopole operator to be 3.7⁢(3)3.733.7(3)3.7 ( 3 ), which allows the
possibility of the operator being irrelevant. This finding offers
support to the scenario in which higher-flux monopoles are irrelevant
deformations to the Dirac spin liquid phase that could be realized
on certain non-bipartite lattices by forbidding 2⁢π2𝜋2\pi2 italic_π-flux monopoles.",[''],"['11788', '33199', '33199']"
"We consider the problem of designing contextual bandit algorithms in the “cross-learning” setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of O~⁢(T⁢K)~𝑂𝑇𝐾\widetilde{O}(\sqrt{TK})over~ start_ARG italic_O end_ARG ( square-root start_ARG italic_T italic_K end_ARG ), independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.
At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between estimation of the unknown distribution and the actions played by the algorithm. This technique may be of independent interest for other learning problems involving estimation of an unknown context distribution.",[''],[]
"This paper presents a new synthetic dataset of ID and travel documents, called SIDTD.
The SIDTD dataset is created to help training and evaluating forged ID documents detection systems.
Such a dataset has become a necessity as ID documents contain personal information and a public dataset of real documents can not be released.
Moreover, forged documents are scarce, compared to legit ones, and the way they are generated varies from one fraudster to another resulting in a class of high intra-variability.
In this paper we trained state-of-the-art models on this dataset and we compare them to the performance achieved in larger, but private, datasets.
The creation of this dataset will help to document image analysis community to progress in the task of ID document verification.",[''],[]
,[''],[]
"We study orbits of semigroups of SL⁢(2,ℤ)SL2ℤ\text{SL}(2,\mathbb{Z})SL ( 2 , blackboard_Z ), and demonstrate reciprocity obstructions: we show that certain such orbits avoid squares, but not as a consequence of such obstructions on the Zariski closure, and not as a consequence of congruence obstructions. This is in analogy to the reciprocity obstructions recently used to disprove the Apollonian local-global conjecture. We give an example of such an orbit which is known exactly, and misses all squares together with an explicit finite list of sporadic values: the corresponding semigroup is not thin, but its Zariski closure does not miss squares. We also demonstrate thin semigroups with reciprocity obstructions, including semigroups associated to continued fractions formed from finite alphabets. Zaremba’s conjecture states that for continued fractions with coefficients chosen from {1,…,5}1…5\{1,\ldots,5\}{ 1 , … , 5 }, every positive integer appears as a denominator. Bourgain and Kontorovich proposed a generalization of Zaremba’s conjecture in the context of semigroups associated to finite alphabets. We disprove their conjecture. In particular, we demonstrate classes of finite continued fraction expansions which never represent rationals with square denominator, but not as a consequence of congruence obstructions, and for which the limit set has Hausdorff dimension exceeding 1/2121/21 / 2. An example of such a class is continued fractions of the form [0;a1,a2,…,an,1,1,2]0subscript𝑎1subscript𝑎2…subscript𝑎𝑛112[0;a_{1},a_{2},\ldots,a_{n},1,1,2][ 0 ; italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , 1 , 1 , 2 ], where the aisubscript𝑎𝑖a_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are chosen from the set {4,8,12,…,128}4812…128\{4,8,12,\ldots,128\}{ 4 , 8 , 12 , … , 128 }. The object at the heart of these results is a semigroup Ψ⊆Γ1⁢(4)ΨsubscriptΓ14\Psi\subseteq\Gamma_{1}(4)roman_Ψ ⊆ roman_Γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 4 ) which preserves Kronecker symbols.","['Key words and phrases:', 'Thin semigroup, thin group, reciprocity obstruction, continued fraction,', 'Zaremba’s conjecture, local-global conjecture,', 'Hausdorff dimension']",[]
"A nonlocal model of peridynamic type for dynamic brittle damage is introduced consisting of two phases, one elastic and the other inelastic. Evolution from the elastic to the inelastic phase depends on material strength.
Existence and uniqueness of the displacement-failure set pair
follow from the initial value problem. The displacement-failure pair satisfies energy balance. The length scale of nonlocality ϵitalic-ϵ\epsilonitalic_ϵ is taken to be small relative to the domain in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, d=2,3𝑑23d=2,3italic_d = 2 , 3. The new nonlocal model delivers a two point strain dynamics on a subset of ℝd×ℝdsuperscriptℝ𝑑superscriptℝ𝑑\mathbb{R}^{d}\times\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. This dynamics provides an energy that interpolates between volume energy corresponding to elastic behavior and surface energy corresponding to failure.
The deformation energy resulting in material failure over a region R𝑅Ritalic_R is given by a d−1𝑑1d-1italic_d - 1 dimensional integral that is uniformly bounded as ϵ→0→italic-ϵ0\epsilon\rightarrow 0italic_ϵ → 0. For fixed ϵitalic-ϵ\epsilonitalic_ϵ, this energy is nonzero for d−1𝑑1d-1italic_d - 1 dimensional regions R𝑅Ritalic_R associated with flat crack surfaces. The failure energy is the Griffith fracture energy for a given crack R𝑅Ritalic_R in terms of its area for d=3𝑑3d=3italic_d = 3 (or length for d=2𝑑2d=2italic_d = 2). This energy follows directly from the nonlocal model without sending ϵitalic-ϵ\epsilonitalic_ϵ to zero.
Simulations illustrate fracture evolution through generation of an internal traction free boundary as a wake left behind a moving strain concentration. Crack paths are seen to follow a maximal strain energy density criterion.",[''],[]
"What does learning to model relationships between strings teach Large Language Models about the visual world?
We systematically evaluate LLMs’ abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text. As language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study. Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world. Furthermore, experiments on self-supervised visual representation learning, utilizing images generated with text models, highlight the potential to train vision models capable of making semantic assessments of natural images using just LLMs.
††footnotetext: Project page: https://vision-checkup.github.io/",[''],[]
"It is a well-known fact that the category 𝖢𝖺𝗍⁢(𝐂)𝖢𝖺𝗍𝐂\mathsf{Cat}(\bf{C})sansserif_Cat ( bold_C ) of internal categories
in a category 𝐂𝐂\bf{C}bold_C has a description in terms of crossed modules, when
𝐂=𝐆𝐫𝐂𝐆𝐫\bf{C}=\bf{Gr}bold_C = bold_Gr is the category of groups. The proof of this result heavily uses
the fact that any split epimorphism decomposes as a semi-direct product. An
equivalent statement does not hold in the category 𝐌𝐨𝐧𝐌𝐨𝐧\bf{Mon}bold_Mon of monoids. In a
previous work on quadratic algebras, [3] I constructed an internal
category in the category of monoids, see Section 6. Based on this
construction, this paper will introduce the notion of a crossed semi-bimodule
and show that it gives rise to an object in 𝖢𝖺𝗍⁢(𝐌𝐨𝐧)𝖢𝖺𝗍𝐌𝐨𝐧\mathsf{Cat}(\bf{Mon})sansserif_Cat ( bold_Mon ). I will also relate
this new notion to the crossed semi-modules introduced earlier by A.
Patchkoria [2].",[''],[]
"Utilizing the bounds on primordial magnetic fields (PMFs), their contributions
to secondary gravitational waves (GWs) and the results from the pulsar timing
arrays (PTAs), we arrive at constraints on the epoch of reheating.
We find that the combined spectral density of primary and secondary GWs
(generated by the PMFs) can, in general, be described as a broken power
law with five different indices.
We show that the PMFs that have a blue tilt and satisfy the other observational
constraints can generate secondary GWs of strengths suggested by the PTA data.",[''],"['India', 'India', 'India']"
"Context: Cybercrime groups, driven by financial and geopolitical motives, launch advanced persistent threat (APT) attacks. The attacks consist of adversarial techniques, which adversaries perform step-by-step by during cyberattacks. Cybersecurity vendors often publish cyber threat intelligence (CTI) reports, referring to the written artifacts on technical and forensic analysis of the techniques used by the malware in APT attacks. To defend organizations, prevalent techniques used by malware in APT attacks and the association among the techniques need to be identified. Objective: The goal of this research is to inform cybersecurity practitioners about how adversaries form cyberattacks through an analysis of adversarial techniques documented in cyberthreat intelligence reports. Dataset: We use 594 adversarial techniques cataloged in MITRE ATT&CK. We systematically construct a set of 667 CTI reports that MITRE ATT&CK used as citations in the descriptions of the cataloged adversarial techniques. Methodology: We analyze the frequency and trend of adversarial techniques, followed by a qualitative analysis of the implementation of techniques. Next, we perform association rule mining to identify pairs of techniques recurring in APT attacks. We then perform qualitative analysis to identify the underlying relations among the techniques in the recurring pairs. Findings: The set of 667 CTI reports documents 10,370 techniques in total, and we identify 19 prevalent techniques accounting for 37.3% of documented techniques. We also identify 425 statistically significant recurring pairs and seven types of relations among the techniques in these pairs. The top three among the seven relationships suggest that techniques used by the malware inter-relate with one another in terms of (a) abusing or affecting the same system assets, (b) executing in sequences, and (c) overlapping in their implementations. We identify that obtaining information on the operating and network system of the victim environment is the most prevalent technique and appears in the highest number of recurring pairs. We identify that spear-phishing is the most prevalent way of initial infection. We also identify three prevalent misuses of system functionalities: macro in office documents, registry in Windows, and task scheduler. We also identify that mimicking legitimate users through compromised credentials is the most prevalent persistence-related technique used by malware. Overall, the study quantifies how adversaries leverage techniques through malware in APT attacks based on publicly reported documents. We advocate organizations prioritize their defense against the identified prevalent techniques and actively hunt for potential malicious intrusion based on the identified pairs of techniques.","['Tactics, techniques, and procedures,', 'ATT&CK,', 'APT attacks,', 'Multi-stage attacks, malware, cyber-criminal groups, cyber-threat actors,', 'TTPs,', 'Advanced persistent threats,', 'Threat hunting,', 'Cyberattack']","['UniversityRaleighNCUSA', 'UniversityRaleighNCUSA', 'UniversityRaleighNCUSA', 'UniversityRaleighNCUSA']"
,[''],[]
"Motivated by the goals of dataset pruning and defect identification, a growing body of methods have been developed to score individual examples within a dataset.
These methods, which we call “example difficulty scores”, are typically used to rank or categorize examples, but the consistency of rankings between different training runs, scoring methods, and model architectures is generally unknown.
To determine how example rankings vary due to these random and controlled effects, we systematically compare different formulations of scores over a range of runs and model architectures.
We find that scores largely share the following traits: they are noisy over individual runs of a model, strongly correlated with a single notion of difficulty, and reveal examples that range from being highly sensitive to insensitive to the inductive biases of certain model architectures. Drawing from statistical genetics, we develop a simple method for fingerprinting model architectures using a few sensitive examples.
These findings guide practitioners in maximizing the consistency of their scores (e.g. by choosing appropriate scoring methods, number of runs, and subsets of examples), and establishes comprehensive baselines for evaluating scores in the future.",[''],"['University', 'Institute', 'University', 'Institute', 'Amazon.', 'MosaicML.', 'DeepMind', 'University', 'Institute', 'University', 'Institute']"
,[''],[]
"We study the problem of learning equivariant neural networks via gradient descent. The incorporation of known symmetries (“equivariance”) into neural nets has empirically improved the performance of learning pipelines, in domains ranging from biology to computer vision. However, a rich yet separate line of learning theoretic research has demonstrated that actually learning shallow, fully-connected (i.e. non-symmetric) networks has exponential complexity in the correlational statistical query (CSQ) model, a framework encompassing gradient descent. In this work, we ask: are known problem symmetries sufficient to alleviate the fundamental hardness of learning neural nets with gradient descent? We answer this question in the negative. In particular, we give lower bounds for shallow graph neural networks, convolutional networks, invariant polynomials, and frame-averaged networks for permutation subgroups, which all scale either superpolynomially or exponentially in the relevant input dimension. Therefore, in spite of the significant inductive bias imparted via symmetry, actually learning the complete classes of functions represented by equivariant neural networks via gradient descent remains hard.",[''],[]
,[''],"['Kingdom', 'marc.delord@kcl.ac.uk', 'Kingdom', 'Kingdom', 'Kingdom', 'Kingdom', 'Kingdom', 'Kingdom', 'Kingdom']"
"WISE J224607.6–052634.9 (W2246–0526) is a hot dust-obscured galaxy at z𝑧zitalic_z = 4.601, and the most luminous obscured quasar known to date. W2246–0526 harbors a heavily obscured supermassive black hole that is most likely accreting above the Eddington limit. We present observations with the Atacama Large Millimeter/submillimeter Array (ALMA) in seven bands, including band 10, of the brightest far-infrared (FIR) fine-structure emission lines of this galaxy: [OI]63⁢μ⁢m63μm{}_{63\upmu\mathrm{m}}start_FLOATSUBSCRIPT 63 roman_μ roman_m end_FLOATSUBSCRIPT, [OIII]88⁢μ⁢m88μm{}_{88\upmu\mathrm{m}}start_FLOATSUBSCRIPT 88 roman_μ roman_m end_FLOATSUBSCRIPT, [NII]122⁢μ⁢m122μm{}_{122\upmu\mathrm{m}}start_FLOATSUBSCRIPT 122 roman_μ roman_m end_FLOATSUBSCRIPT, [OI]145⁢μ⁢m145μm{}_{145\upmu\mathrm{m}}start_FLOATSUBSCRIPT 145 roman_μ roman_m end_FLOATSUBSCRIPT, [CII]158⁢μ⁢m158μm{}_{158\upmu\mathrm{m}}start_FLOATSUBSCRIPT 158 roman_μ roman_m end_FLOATSUBSCRIPT, [NII]205⁢μ⁢m205μm{}_{205\upmu\mathrm{m}}start_FLOATSUBSCRIPT 205 roman_μ roman_m end_FLOATSUBSCRIPT, [CI]370⁢μ⁢m370μm{}_{370\upmu\mathrm{m}}start_FLOATSUBSCRIPT 370 roman_μ roman_m end_FLOATSUBSCRIPT, and [CI]609⁢μ⁢m609μm{}_{609\upmu\mathrm{m}}start_FLOATSUBSCRIPT 609 roman_μ roman_m end_FLOATSUBSCRIPT. A comparison of the data to a large grid of Cloudy radiative transfer models reveals that a high hydrogen density (nH∼3×103similar-tosubscript𝑛H3superscript103n_{\mathrm{H}}\sim 3\times 10^{3}italic_n start_POSTSUBSCRIPT roman_H end_POSTSUBSCRIPT ∼ 3 × 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT) and extinction (AV∼300similar-tosubscript𝐴V300A_{\mathrm{V}}\sim 300italic_A start_POSTSUBSCRIPT roman_V end_POSTSUBSCRIPT ∼ 300 mag), together with extreme ionization (l⁢o⁢g⁢(U)=−0.5𝑙𝑜𝑔𝑈0.5log(U)=-0.5italic_l italic_o italic_g ( italic_U ) = - 0.5) and a high X-ray to UV ratio (αox≥−0.8subscript𝛼ox0.8\alpha_{\mathrm{ox}}\geq-0.8italic_α start_POSTSUBSCRIPT roman_ox end_POSTSUBSCRIPT ≥ - 0.8) are required to reproduce the observed nuclear line ratios. The values of αoxsubscript𝛼ox\alpha_{\mathrm{ox}}italic_α start_POSTSUBSCRIPT roman_ox end_POSTSUBSCRIPT and U𝑈Uitalic_U are among the largest found in the literature and imply the existence of an X-ray-dominated region (XDR). In fact, this component explains the a priori very surprising non-detection of the [OIII]88⁢μ⁢m88μm{}_{88\upmu\mathrm{m}}start_FLOATSUBSCRIPT 88 roman_μ roman_m end_FLOATSUBSCRIPT emission line, which is actually suppressed, instead of boosted, in XDR environments. Interestingly, the best-fitted model implies higher X-ray emission and lower CO content than what is detected observationally, suggesting the presence of a molecular gas component that should be further obscuring the X-ray emission over larger spatial scales than the central region that is being modeled. These results highlight the need for multiline infrared observations to characterize the multiphase gas in high redshift quasars and, in particular, W2246–0526 serves as an extreme benchmark for comparisons of interstellar medium conditions with other quasar populations at cosmic noon and beyond.","['Key', 'Words.: \ngalaxies:', 'ISM – galaxies: nuclei – galaxies: active - galaxies: individual (WISE', 'J2246-0526) – quasars: emission lines']",[]
"International comparisons of hierarchical time series data sets based on survey data, such as annual country-level estimates of school enrollment rates, can suffer from large amounts of missing data due to differing coverage of surveys across countries and across times.
A popular approach to handling missing data in these settings is through multiple imputation, which can be especially effective when there is an auxiliary variable that is strongly predictive of and has a smaller amount of missing data than the variable of interest.
However, standard methods for multiple imputation of hierarchical time series data can perform poorly when the auxiliary variable and the variable of interest are have a nonlinear relationship.
Performance of standard multiple imputation methods can also suffer if the substantive analysis model of interest is uncongenial to the imputation model, which can be a common occurrence for social science data if the imputation phase is conducted independently of the analysis phase.
We propose a Bayesian method for multiple imputation of hierarchical nonlinear time series data that uses a sequential decomposition of the joint distribution and incorporates smoothing splines to account for nonlinear relationships between variables.
We compare the proposed method with existing multiple imputation methods through a simulation study and an application to secondary school enrollment data.
We find that the proposed method can lead to substantial performance increases for estimation of parameters in uncongenial analysis models and for prediction of individual missing values.",[''],[]
,[''],[]
,[''],[]
"On 2022 February 15, an impressive filament eruption was observed off the solar eastern limb from three remote-sensing viewpoints, namely Earth, STEREO-A, and Solar Orbiter. In addition to representing the most-distant observed filament at extreme ultraviolet wavelengths—captured by Solar Orbiter’s field of view extending to above 6 R⊙subscript𝑅direct-productR_{\odot}italic_R start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT—this event was also associated with the release of a fast (∼similar-to\sim∼2200 km⋅⋅\cdot⋅s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT) coronal mass ejection (CME) that was directed towards BepiColombo and Parker Solar Probe. These two probes were separated by 2∘{}^{\circ}start_FLOATSUPERSCRIPT ∘ end_FLOATSUPERSCRIPT in latitude, 4∘{}^{\circ}start_FLOATSUPERSCRIPT ∘ end_FLOATSUPERSCRIPT in longitude, and 0.03 au in radial distance around the time of the CME-driven shock arrival in situ. The relative proximity of the two probes to each other and to the Sun (∼similar-to\sim∼0.35 au) allows us to study the mesoscale structure of CMEs at Mercury’s orbit for the first time. We analyse similarities and differences in the main CME-related structures measured at the two locations, namely the interplanetary shock, the sheath region, and the magnetic ejecta. We find that, despite the separation between the two spacecraft being well within the typical uncertainties associated with determination of CME geometric parameters from remote-sensing observations, the two sets of in-situ measurements display some profound differences that make understanding of the overall 3D CME structure particularly challenging. Finally, we discuss our findings within the context of space weather at Mercury’s distances and in terms of the need to investigate solar transients via spacecraft constellations with small separations, which has been gaining significant attention during recent years.","['Solar filament eruptions (1981);', 'Solar coronal mass ejections (310);', 'Interplanetary magnetic fields (824);', 'Interplanetary shocks (829)']","['USA', 'USA', 'USA', 'USA', 'USA', 'UK', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Germany', 'Germany', 'USA', 'USA', 'USA', 'Belgium', 'Russia', 'Belgium', 'USA', 'USA', 'Spain', 'Spain', 'USA', 'Finland', 'Finland', 'Finland', 'Austria', 'Austria', 'Germany', 'Germany', 'USA', 'USA', 'Belgium', 'Romania']"
,[''],[]
"We present a comprehensive study of hydrodynamic theories for superfluids with dipole symmetry. Taking diffusion as an example, we systematically construct a hydrodynamic framework that incorporates an intrinsic dipole degree of freedom in analogy to spin density in micropolar (spinful) fluids. Subsequently, we study a dipole condensed phase and propose a model that captures the spontaneous breaking of the U⁢(1)𝑈1U(1)italic_U ( 1 ) charge. The theory explains the role of the inverse Higgs constraint for this class of theories, and naturally generates the gapless field.
Next, we introduce finite temperature theory using the Hamiltonian formalism and study the hydrodynamics of ideal fracton superfluids. Finally, we postulate a derivative counting scheme and incorporate dissipative effects using the method of irreversible thermodynamics. We verify the consistency of the dispersion relations and argue that our counting is systematic.",[''],[]
,[''],[]
"A simple and effective method for the alignment of generative models is the best-of-n𝑛nitalic_n policy, where n𝑛nitalic_n samples are drawn from a base policy, and ranked based on a reward function, and the highest ranking one is selected. A commonly used analytical expression in the literature claims that the KL divergence between the best-of-n𝑛nitalic_n policy and the base policy is equal to log⁡(n)−(n−1)/n.𝑛𝑛1𝑛\log(n)-(n-1)/n.roman_log ( italic_n ) - ( italic_n - 1 ) / italic_n . We disprove the validity of this claim, and show that it is an upper bound on the actual KL divergence. We also explore the tightness of this upper bound in different regimes. Finally, we propose a new estimator for the KL divergence and empirically show that it provides a tight approximation through a few examples.",[''],[]
"This work concerns maps of commutative noetherian local rings containing a field of positive characteristic. Given such a map φ𝜑\varphiitalic_φ of finite flat dimension, the results relate homological properties of the relative Frobenius of φ𝜑\varphiitalic_φ to those of the fibers of φ𝜑\varphiitalic_φ. The focus is on the complete intersection property and the Gorenstein property.",[''],[]
"Model uncertainty poses a significant challenge to the implementation of safety-critical control systems. With this as motivation, this paper proposes a safe control design approach that guarantees the robustness of nonlinear feedback systems in the presence of matched or unmatched unmodelled system dynamics and external disturbances. Our approach couples control barrier functions (CBFs) with a new uncertainty/disturbance estimator to ensure robust safety against input and state-dependent model uncertainties. We prove upper bounds on the estimator’s error and estimated outputs. We use an uncertainty estimator-based composite feedback control law to adaptively improve robust control performance under hard safety constraints by compensating for the matched uncertainty. Then, we robustify existing CBF constraints with this uncertainty estimate and the estimation error bounds to ensure robust safety via a quadratic program (CBF-QP). We also extend our method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which causes relative degree differences with respect to control input and disturbance.
We assume the relative degree difference is at most one, resulting in a second-order cone (SOC) condition.
The proposed robust HOCBFs method is demonstrated in a simulation of an uncertain elastic actuator control problem.
Finally, the efficacy of our method is experimentally demonstrated on a tracked robot with slope-induced matched and unmatched perturbations.",[''],[]
"Let V𝑉Vitalic_V be a set of n𝑛nitalic_n points in ℝdsuperscriptℝ𝑑\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, and suppose that the distance between each pair of points is revealed independently with probability p𝑝pitalic_p. We study when this information is sufficient to reconstruct large subsets of V𝑉Vitalic_V, up to isometry.
Strong results for d=1𝑑1d=1italic_d = 1 have been obtained by Girão, Illingworth, Michel, Powierski, and Scott. In this paper, we investigate higher dimensions, and show that if p>n−2/(d+4)𝑝superscript𝑛2𝑑4p>n^{-2/(d+4)}italic_p > italic_n start_POSTSUPERSCRIPT - 2 / ( italic_d + 4 ) end_POSTSUPERSCRIPT, then we can reconstruct almost all of V𝑉Vitalic_V up to isometry, with high probability. We do this by relating it to a polluted graph bootstrap percolation result, for which we adapt the methods of Balogh, Bollobás, and Morris.",[''],[]
"Defending from cyberattacks requires practitioners to operate on high-level adversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattack incidents describe the chain of malicious actions with respect to time. To avoid repeating cyberattack incidents, practitioners must proactively identify and defend against recurring chain of actions - which we refer to as temporal attack patterns. Automatically mining the patterns among actions provides structured and actionable information on the adversary behavior of past cyberattacks. The goal of this paper is to aid security practitioners in prioritizing and proactive defense against cyberattacks by mining temporal attack patterns from cyberthreat intelligence reports. To this end, we propose ChronoCTI, an automated pipeline for mining temporal attack patterns from cyberthreat intelligence (CTI) reports of past cyberattacks. To construct ChronoCTI, we build the ground truth dataset of temporal attack patterns and apply state-of-the-art large language models, natural language processing, and machine learning techniques. We apply ChronoCTI on a set of 713 CTI reports, where we identify 124 temporal attack patterns - which we categorize into nine pattern categories. We identify that the most prevalent pattern category is to trick victim users into executing malicious code to initiate the attack, followed by bypassing the anti-malware system in the victim network. Based on the observed patterns, we advocate organizations to train users about cybersecurity best practices, introduce immutable operating systems with limited functionalities, and enforce multi-user authentications. Moreover, we advocate practitioners to leverage the automated mining capability of ChronoCTI and design countermeasures against the recurring attack patterns.","['Index', 'Terms: ', 'Advanced persistent threat,', 'Tactics,', 'Techniques, and', 'Procedures,', 'ATT&CK,', 'Temporal pattern,', 'Cyberthreat intelligence,', 'CTI reports,', 'Knowledge graph, attack graph']",[]
"This paper presents
a concrete and a symbolic rewriting
logic semantics for
parametric time Petri nets with inhibitor arcs (PITPNs), a
flexible model
of timed systems
where
parameters are allowed in firing bounds.
We prove that our semantics is bisimilar to the “standard” semantics
of PITPNs.
This allows us to use
the rewriting logic tool Maude,
combined with SMT solving, to
provide sound and complete formal analyses for PITPNs.
We develop and implement a new general folding
approach for symbolic reachability, so that Maude-with-SMT
reachability analysis
terminates whenever the parametric state-class graph of the PITPN is
finite.
Our work opens up
the possibility of using the many formal analysis capabilities of
Maude—including full LTL model checking, analysis with
user-defined analysis strategies, and even statistical model
checking—for such nets.
We illustrate this by explaining how almost all formal analysis and
parameter synthesis methods
supported by the state-of-the-art PITPN tool
Roméo can be performed using Maude with SMT. In addition, we also support
analysis and parameter
synthesis from parametric initial markings, as well as full
LTL model
checking and analysis with
user-defined execution strategies.
Experiments show that our methods outperform
Roméo in many cases.",[''],[]
"We present a framework for generating full-bodied photorealistic avatars that gesture according to the conversational dynamics of a dyadic interaction.
Given speech audio, we output multiple possibilities of gestural motion for an individual, including face, body, and hands.
The key behind our method is in combining the benefits of sample diversity from vector quantization with the high-frequency details obtained through diffusion to generate more dynamic, expressive motion.
We visualize the generated motion using highly photorealistic avatars that can express crucial nuances in gestures (e.g. sneers and smirks).
To facilitate this line of research, we introduce a first-of-its-kind multi-view conversational dataset that allows for photorealistic reconstruction.
Experiments show our model generates appropriate and diverse gestures, outperforming both diffusion- and VQ-only methods. Furthermore, our perceptual evaluation highlights the importance of photorealism (vs. meshes) in accurately assessing subtle motion details in conversational gestures.
Code and dataset available on project page.",[''],[]
"We extend the Calderón-Zygmund theory for nonlocal equations to
strongly coupled system of linear nonlocal equations ℒAs⁢u=fsubscriptsuperscriptℒ𝑠𝐴𝑢𝑓\mathcal{L}^{s}_{A}u=fcaligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_u = italic_f, where the operator ℒAssubscriptsuperscriptℒ𝑠𝐴\mathcal{L}^{s}_{A}caligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT is formally given by



ℒAs⁢u=∫ℝnA⁢(x,y)|x−y|n+2⁢s⁢(x−y)⊗(x−y)|x−y|2⁢(u⁢(x)−u⁢(y))⁢𝑑y.subscriptsuperscriptℒ𝑠𝐴𝑢subscriptsuperscriptℝ𝑛𝐴𝑥𝑦superscript𝑥𝑦𝑛2𝑠tensor-product𝑥𝑦𝑥𝑦superscript𝑥𝑦2𝑢𝑥𝑢𝑦differential-d𝑦\mathcal{L}^{s}_{A}u=\int_{\mathbb{R}^{n}}\frac{A(x,y)}{|x-y|^{n+2s}}\frac{(x-%
y)\otimes(x-y)}{|x-y|^{2}}(u(x)-u(y))dy.caligraphic_L start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_u = ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT divide start_ARG italic_A ( italic_x , italic_y ) end_ARG start_ARG | italic_x - italic_y | start_POSTSUPERSCRIPT italic_n + 2 italic_s end_POSTSUPERSCRIPT end_ARG divide start_ARG ( italic_x - italic_y ) ⊗ ( italic_x - italic_y ) end_ARG start_ARG | italic_x - italic_y | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ( italic_u ( italic_x ) - italic_u ( italic_y ) ) italic_d italic_y .



For 0<s<10𝑠10<s<10 < italic_s < 1 and A:ℝn×ℝn→ℝ:𝐴→superscriptℝ𝑛superscriptℝ𝑛ℝA:\mathbb{R}^{n}\times\mathbb{R}^{n}\to\mathbb{R}italic_A : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → blackboard_R taken to be symmetric and serving as
a variable coefficient for the operator, the system under consideration is the fractional version of the classical Navier-Lamé linearized elasticity system. The study of the coupled system of nonlocal equations is motivated by its appearance in nonlocal mechanics, primarily in peridynamics. Our regularity result states that if A⁢(⋅,y)𝐴⋅𝑦A(\cdot,y)italic_A ( ⋅ , italic_y ) is uniformly Holder continuous and infx∈ℝnA⁢(x,x)>0subscriptinfimum𝑥superscriptℝ𝑛𝐴𝑥𝑥0\inf_{x\in\mathbb{R}^{n}}A(x,x)>0roman_inf start_POSTSUBSCRIPT italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_A ( italic_x , italic_x ) > 0, then for f∈Ll⁢o⁢cp,𝑓subscriptsuperscript𝐿𝑝𝑙𝑜𝑐f\in L^{p}_{loc},italic_f ∈ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l italic_o italic_c end_POSTSUBSCRIPT , for p≥2𝑝2p\geq 2italic_p ≥ 2, the solution vector u∈Hl⁢o⁢c2⁢s−δ,p𝑢subscriptsuperscript𝐻2𝑠𝛿𝑝𝑙𝑜𝑐u\in H^{2s-\delta,p}_{loc}italic_u ∈ italic_H start_POSTSUPERSCRIPT 2 italic_s - italic_δ , italic_p end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l italic_o italic_c end_POSTSUBSCRIPT for some δ∈(0,s)𝛿0𝑠\delta\in(0,s)italic_δ ∈ ( 0 , italic_s ).",[''],[]
"Visual odometry estimates the motion of a moving camera based on visual input. Existing methods, mostly focusing on two-view point tracking, often ignore the rich temporal context in the image sequence, thereby overlooking the global motion patterns and providing no assessment of the full trajectory reliability. These shortcomings hinder performance in scenarios with occlusion, dynamic objects, and low-texture areas. To address these challenges, we present the Long-term Effective Any Point Tracking (LEAP) module. LEAP innovatively combines visual, inter-track, and temporal cues with mindfully selected anchors for dynamic track estimation. Moreover, LEAP’s temporal probabilistic formulation integrates distribution updates into a learnable iterative refinement module to reason about point-wise uncertainty. Based on these traits, we develop LEAP-VO, a robust visual odometry system adept at handling occlusions and dynamic scenes. Our mindful integration showcases a novel practice by employing long-term point tracking as the front-end. Extensive experiments demonstrate that the proposed pipeline significantly outperforms existing baselines across various visual odometry benchmarks.",[''],[]
"Hot dust in the proximity of AGNs strongly emits in the Near Infrared producing a red excess that, in type 2 sources, can be modeled to measure its temperature. In the era of high spatial-resolution multi-wavelength data, mapping the hot dust around Supermassive Black Holes is important for the efforts to achieve a complete picture of the dust role and distribution around these compact objects.
In this work we propose a methodology to detect the hot dust emission in the proximity of Type 2 AGNs and measure its temperature using K-band spectra (λcsubscript𝜆𝑐\lambda_{c}italic_λ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 2.2 μ𝜇\muitalic_μm).
To achieve this, we have developed NIRDust, a Python package for modeling K-band spectra, estimate the dust temperature and characterize the involved uncertainties. We tested synthetic and real spectra in order to check the performance and suitability of the physical model over different types of data.
Our tests on synthetic spectra demonstrated that the obtained results are influenced by the signal-to-noise ratio (S/N) of the input spectra. However, we accurately characterized the uncertainties, which remained below ∼similar-to\sim∼150 K for an average S/N per pixel exceeding 20. Applying NIRDust to NGC 5128 (Centaurus A), observed with the Gemini South Telescope, we estimated a dust temperature of 662 and 667 K from Flamingos-2 spectra and 697 and 607  K from GNIRS spectra using two different approaches.",[''],[]
"Relativistic jets accompany the collapse of massive stars, the merger of compact objects, or the accretion of gas in active galactic nuclei. They carry information about the central engine and generate electromagnetic radiation. No self-consistent simulations have been able to follow these jets from their birth at the black hole scale to the Newtonian dissipation phase, making the inference of central engine property through astronomical observations undetermined. We present the general relativistic moving-mesh framework to achieve the continuity of jet simulations throughout space-time. We implement the general relativistic extension for the moving-mesh relativistic hydrodynamic code-JET, and develop a tetrad formulation to utilize the HLLC Riemann solver in the general relativistic moving mesh code. The new framework is able to trace the radial movement of the relativistic jets from the central region where strong gravity holds all the way to distances of jet dissipation.","['General', 'Relativistic,', 'Relativistic jet,', 'HLLC']","['Germany', 'Germany']"
"For any set S𝑆Sitalic_S, the free magmatic algebra spanned by card⁢(S)card𝑆{\mbox{card}(S)}card ( italic_S ) binary products is the vector space spanned by the set of all planar rooted binary trees with the internal nodes colored by the elements of S𝑆Sitalic_S, graded by the number of leaves of a tree. We show that it has a unique structure of coassociative coalgebra such that the coproduct
satisfies the unital infinitesimal condition with each magmatic product, and prove an analog of Aguiar-Sottile’s formula in this context, describing the coproduct in terms of the Moebius basis for the Tamari order. The last result allows us to compute the subspace of primitive elements of any unital infinitesimal S𝑆Sitalic_S-magmatic bialgebra. As an example, we construct a set of generators of the dual of Pilaud and Pons bialgebra of integer relations and compute an explicit basis of its subspace of primitive elements.","['Key words and phrases: ', 'Magmatic algebras, bialgebras,', 'Tamari order, binary rooted trees']",[]
"As time progresses, the need for more secure applications grows exponentially. The different types of sensitive information that is being transferred virtually has sparked a rise in systems that leverage blockchain. Different sectors are beginning to use this disruptive technology to evaluate the risks and benefits. Sectors like finance, medicine, higher education, and wireless communication have research regarding blockchain. Futhermore, the need for security standards in this area of research is pivotal. In recent past, several attacks on blockchain infrastructures have resulted in hundreds of millions dollars lost and sensitive information compromised. Some of these attacks include DAO attacks, bZx attacks, and Parity Multisignature Wallet Double Attacks which targeted vulnerabilities within smart contracts on the Ethereum network. These attacks exposed the weaknesses of current smart contract development practices which has led to the increase in distrust and adoption of systems that leverage blockchain for its functionality. In this paper, I identify common software vulnerabilities and attacks on blockchain infrastructures, thoroughly detail the smart contract development process and propose a model for ensuring a stronger security standard for future systems leveraging smart contracts. The purpose for proposing a model is to promote trust among end users in the system which is a foundational element for blockchain adoption in the future.","['Index', 'Terms: ', 'Smart', 'Contract,', 'Blockchain,', 'Software', 'Development,', 'Cybersecurity']",['crawford@cs.ua.edu']
"We obtain asymptotic formulae for the second discrete moments of the Riemann zeta function over arithmetic progressions 12+i⁢(a⁢n+b)12𝑖𝑎𝑛𝑏\frac{1}{2}+i(an+b)divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_i ( italic_a italic_n + italic_b ).
It reveals noticeable relation between the discrete moments and the continuous moment of the Riemann zeta function.
Especially, when a𝑎aitalic_a is a positive integer, main terms of the formula are equal to those for the continuous mean value.
The proof requires the rational approximation of eπ⁢k/asuperscript𝑒𝜋𝑘𝑎e^{\pi k/a}italic_e start_POSTSUPERSCRIPT italic_π italic_k / italic_a end_POSTSUPERSCRIPT for positive integers k𝑘kitalic_k.","['Key words and phrases: the', 'Riemann ζ𝜁\\zetaitalic_ζ-function']",[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
"We present the results of an optical link to a corner cube on board a tethered balloon at 300 m altitude including a Tip/Tilt compensation for the balloon tracking. Our experiment measures the carrier phase of a 1542 nm laser, which is the useful signal for frequency comparison of distant clocks. An active phase noise compensation of the carrier is implemented, demonstrating a fractional frequency stability of 8×10−198superscript10198\times 10^{-19}8 × 10 start_POSTSUPERSCRIPT - 19 end_POSTSUPERSCRIPT after 16 s averaging, which slightly (factor ∼similar-to\sim∼ 3) improves on best previous links via an airborne platform. This state-of-the-art result is obtained with a transportable set-up that enables a fast field deployment.",[''],"['France', 'France', 'France', 'France', 'France', 'France', 'France', 'France']"
,[''],[]
"Interferometers play a crucial role in high-precision displacement measurement such as gravitational-wave detection.
Conventional interferometer designs require accurate laser alignment, including the laser pointing and the waist position, to maintain high interference contrast during motion. Although the corner reflector returns the reflected beam in parallel, there is still a problem of lateral beam shift which reduces the interference contrast. This paper presents a new compact interferometric sensor head design for measuring translations with auto-alignment. It works without laser beam alignment adjustment and maintains high interferometric contrast during arbitrary motion (tilts as well as lateral translation). Automatic alignment of the measuring beam with the reference beam is possible by means of a secondary reflection design with a corner reflector. A 20×10×10⁢mm3201010superscriptmm320\times 10\times 10\,\mathrm{mm}^{3}20 × 10 × 10 roman_mm start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT all-glass quasi-monolithic sensor head is built based on UV adhesive bonding and tested by a piezoelectric (PZT) positioning stage. Our sensor head achieved a displacement sensitivity of 1⁢pm/Hz1/21pmsuperscriptHz121\,\mathrm{pm}/\mathrm{Hz}^{1/2}1 roman_pm / roman_Hz start_POSTSUPERSCRIPT 1 / 2 end_POSTSUPERSCRIPT at 1⁢Hz1Hz{\rm 1\,Hz}1 roman_Hz with a tilt dynamic range over ±200⁢mradplus-or-minus200mrad\pm 200\,\mathrm{mrad}± 200 roman_mrad. This optical design can be widely used for high-precision displacement measurement over a large tilt dynamic range, such as torsion balances and seismometers.",[''],['China']
,[''],[]
,[''],[]
"Background: The established GAseous Detector with GErmanium Tagging (GADGET) detection system is used to measure weak, low-energy β𝛽\betaitalic_β-delayed proton decays. It consists of the gaseous Proton Detector equipped with a MICROMEGAS (MM) readout to detect protons and other charged particles calorimetrically, surrounded by the Segmented Germanium Array (SeGA) for high-resolution detection of prompt γ𝛾\gammaitalic_γ-rays.

Purpose: To upgrade GADGET’s Proton Detector to operate as a compact Time Projection Chamber (TPC) for the detection, 3D imaging and identification of low-energy β𝛽\betaitalic_β-delayed single- and multi-particle emissions mainly of interest to astrophysical studies.

Method: A new high granularity MM board with 1024 pads has been designed, fabricated, installed and tested. A high-density data acquisition system based on Generic Electronics for TPCs (GET) has been installed and optimized to record and process the gas avalanche signals collected on the readout pads. The TPC’s performance has been tested using a 220220{}^{220}start_FLOATSUPERSCRIPT 220 end_FLOATSUPERSCRIPTRn α𝛼\alphaitalic_α-particle source and cosmic-ray muons. In addition, decay events in the TPC have been simulated by adapting the ATTPCROOT data analysis framework. Further, a novel application of 2D convolutional neural networks for GADGET II event classification is introduced. The optimization of data throughput is also addressed.
Results: The GADGET II TPC is capable of detecting and identifying α𝛼\alphaitalic_α-particles, as well as measuring their track direction, range, and energy. The extracted energy resolution of the GADGET II TPC using P10 gas is about 5.4% at 6.288 MeV (220220{}^{220}start_FLOATSUPERSCRIPT 220 end_FLOATSUPERSCRIPTRn α𝛼\alphaitalic_α-events), computed using charge integration. Based on a systematic simulation study, we estimated the detection efficiency of the GADGET II TPC for protons and α𝛼\alphaitalic_α-particles, respectively. It has also been demonstrated that the GADGET II TPC is capable of tracking minimum ionizing particles (i.e. cosmic-ray muons). From these measurements, the electron drift velocity was measured under typical operating conditions. In addition to being one of the first generation of micro pattern gaseous detectors (MPGDs) to utilize a resistive anode applied to low-energy nuclear physics, the GADGET II TPC will also be the first TPC surrounded by a high-efficiency array of high-purity germanium γ𝛾\gammaitalic_γ-ray detectors. 
Conclusions: The TPC of GADGET II has been designed, fabricated and tested, and is ready for operation at the Facility for Rare Isotope Beams (FRIB) for radioactive beam-line experiments.",[''],"['USA', 'USA', 'USA', 'France', 'Spain.', 'USA', 'Israel.', 'Canada.', 'Switzerland']"
,[''],[]
,[''],[]
"In 1902, Paul Stäckel constructed an analytic function f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) in a neighborhood of the origin, which was transcendental, and with the property that both f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) and its inverse, as well as its derivatives, assumed algebraic values at all algebraic points in this neighborhood. Inspired by this result, Mahler in 1976 questioned the existence of an transcendental entire function f⁢(z)𝑓𝑧f(z)italic_f ( italic_z ) such that f⁢(ℚ¯)𝑓¯ℚf(\overline{\mathbb{Q}})italic_f ( over¯ start_ARG blackboard_Q end_ARG ) and f−1⁢(ℚ¯)superscript𝑓1¯ℚf^{-1}(\overline{\mathbb{Q}})italic_f start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( over¯ start_ARG blackboard_Q end_ARG ) are subsets of ℚ¯.¯ℚ\overline{\mathbb{Q}}.over¯ start_ARG blackboard_Q end_ARG . This problem was solved by Marques and Moreira in 2017. As Stäcklel’s result involved derivatives, it is natural to question whether we have an analogous result for transcendental entire functions involving derivatives. In this article, we show that there are an uncountable amount of such functions.","['Key words and phrases:', 'Mahler', 'Problem, transcendental functions, arithmetic behavior.']",[]
"Next-generation data networks need to support Tb/s rates. In-phase and quadrature (IQ) modulation combine phase and intensity information to increase the density of encoded data, reduce overall power consumption by minimising the number of channels, and increase noise tolerance. To reduce errors when decoding the received signal, intersymbol interference must be minimised. This is achieved with pure phase modulation, where the phase of the optical signal is controlled without changing its intensity. Phase modulators are characterised by the voltage required to achieve a π𝜋\piitalic_π phase shift Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPT, the device length L, and their product Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL. To reduce power consumption, IQ modulators are needed with<<<1V drive voltages and compact (sub-cm) dimensions, which translate in Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL<<<1Vcm. Si and LiNbO33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT (LN) IQ modulators do not currently meet these requirements, because Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL>>>1Vcm. Here, we report a double single-layer graphene (SLG) Mach-Zehnder modulator (MZM) with pure phase modulation in the transparent regime, where optical losses are minimised and remain constant with increasing voltage. Our device has Vπ⁢L∼similar-tosubscript𝑉𝜋𝐿absentV_{\pi}L\simitalic_V start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT italic_L ∼0.3Vcm, matching state-of-the-art SLG-based MZMs and plasmonic LN MZMs, but with pure phase modulation and low insertion loss (∼similar-to\sim∼5dB), essential for IQ modulation. Our Vπ⁢Lsubscript𝑉𝜋𝐿V_{\pi}Litalic_V start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT italic_L is∼similar-to\sim∼5 times lower than the lowest thin-film LN MZMs, and∼similar-to\sim∼3 times lower than the lowest Si MZMs. This enables devices with complementary metal-oxide semiconductor compatible Vπ𝜋{}_{\pi}start_FLOATSUBSCRIPT italic_π end_FLOATSUBSCRIPTL (<<<1Vcm) and smaller footprint than LN or Si MZMs, improving circuit density and reducing power consumption by one order of magnitude.",[''],"['UK', 'Belgium', 'Italy', 'Italy', 'Italy', 'UK']"
,[''],[]
"In this work we first give a upper bound for the modulus of q𝑞qitalic_q-transcendental
entire functions, then prove certain sums associated with their zeros
are convergent, and derive the asymptotic behaviors of their associated
heat kernels.",['Key words and phrases: \nq-Transcendental functions; heat kernels; q𝑞qitalic_q-Bessel functions.'],[]
"In recent years, foundation models (FMs) have solidified their role as cornerstone advancements in the deep learning domain. By extracting intricate patterns from vast datasets, these models consistently achieve state-of-the-art results across a spectrum of downstream tasks, all without necessitating extensive computational resources [1].
Notably, MedCLIP [2], a vision-language contrastive learning-based medical FM, has been designed using unpaired image-text training. While the medical domain has often adopted unpaired training to amplify data [3], the exploration of potential security concerns linked to this approach hasn’t kept pace with its practical usage. Notably, the augmentation capabilities inherent in unpaired training also indicate that minor label discrepancies can result in significant model deviations. In this study, we frame this label discrepancy as a backdoor attack problem. We further analyze its impact on medical FMs throughout the FM supply chain. Our evaluation primarily revolves around MedCLIP, emblematic of medical FM employing the unpaired strategy. We begin with an exploration of vulnerabilities in MedCLIP stemming from unpaired image-text matching, termed BadMatch. BadMatch is achieved using a modest set of wrongly labeled data. Subsequently, we disrupt MedCLIP’s contrastive learning through BadDist-assisted BadMatch by introducing a Bad-Distance between the embeddings of clean and poisoned data. Intriguingly, when BadMatch and BadDist are combined, a slight 0.05 percent of misaligned image-text data can yield a staggering 99 percent attack success rate, all the while maintaining MedCLIP’s efficacy on untainted data. Additionally, combined with BadMatch and BadDist, the attacking pipeline consistently fends off backdoor assaults across diverse model designs, datasets, and triggers. Also, our findings reveal that current defense strategies are insufficient in detecting these latent threats in medical FMs’ supply chains. Code and pre-trained models can be found at https://github.com/ubc-tea/Backdoor_Multimodal_Foundation_Model.","['Index', 'Terms: ', 'Backdoor', 'Attack,', 'Foundation', 'Models,', 'Vision-Text', 'Models.', 'Contrastive', 'Learning']","['Columbia', 'Institute', 'University']"
,[''],[]
,[''],[]
"We consider wave scattering from a system of highly contrasting resonators with time-modulated material parameters. In this setting, the wave equation reduces to a system of coupled Helmholtz equations that models the scattering problem. We consider the one-dimensional setting. In order to understand the energy of the system, we prove a novel higher-order discrete, capacitance matrix approximation of the subwavelength resonant quasifrequencies. Further, we perform numerical experiments to support and illustrate our analytical results and show how periodically time-dependent material parameters affect the scattered wave field.",[''],[]
"This study seeks to understand the origins of intermittency in quantities of interest in pool boiling, such as bubble departure diameter and departure time. The intermittency of nucleation site activity due to nonuniform and unsteady near-wall temperatures is well-established; however few mechanistic models have been developed that predict such intermittency. Here we assume a fluctuating pressure field at a nucleation site due to adjacent bubble activity, which acts in combination with convective effects to alter bubble growth depending on the phase of the pressure oscillation with respect to the instant of bubble nucleation. The results suggest that even when a single departure frequency is assumed for nearby bubbles, its effect on the nucleation site being considered is to cause aperiodicity and intermittency in bubble departure quantities. The effects of pressure field phase angle, degree of superheat, and choice of force balance model on the bubble departure quantities are examined. The phase angle of the pressure fluctuation at the instant of bubble nucleation is shown to play a major role in determining bubble departure diameter and growth time. Departure diameter is observed to have a broad distribution over long times of observation, belying the assumption of a unique value. Period doubling of the ebullition cycle is observed for some conditions, a phenomenon documented by other investigators. The effects of dynamic contact angle",[''],['55455']
"We explore the potential of enhancing LLM performance in astronomy-focused question-answering through targeted, continual pre-training. By employing a compact 7B-parameter LLaMA-2 model and focusing exclusively on a curated set of astronomy corpus—comprising abstracts, introductions, and conclusions—we achieve notable improvements in specialized topic comprehension. While general LLMs like GPT-4 outperform in broader question-answering scenarios due to superior reasoning capabilities, our findings suggest that continual pre-training with limited resources can still enhance model performance on specialized topics. Additionally, we present an extension of AstroLLaMA: the fine-tuning of the 7B LLaMA model on a domain-specific conversational dataset, culminating in the release of the chat-enabled AstroLLaMA for community use. Comprehensive quantitative benchmarking is currently in progress and will be detailed in an upcoming full paper. The model, AstroLLaMA-Chat, is now available at https://huggingface.co/universeTBD, providing the first open-source conversational AI tool tailored for the astronomy community.",[''],"['Spain', 'Technology', 'USA', 'Australia', 'Australia', 'USA', 'USA', 'Spain', 'Urbana-Champaign', 'Australia', 'Australia', 'Kingdom', 'Switzerland', 'USA', 'Australia', 'Australia']"
,[''],[]
"Striking a balance between precision and efficiency presents a prominent challenge in the bird’s-eye-view (BEV) 3D object detection. Although previous camera-based BEV methods achieved remarkable performance by incorporating long-term temporal information, most of them still face the problem of low efficiency. One potential solution is knowledge distillation. Existing distillation methods only focus on reconstructing spatial features, while overlooking temporal knowledge. To this end, we propose TempDistiller, a Temporal knowledge Distiller, to acquire long-term memory from a teacher detector when provided with a limited number of frames. Specifically, a reconstruction target is formulated by integrating long-term temporal knowledge through self-attention operation applied to the feature of teachers. Subsequently, novel features are generated for masked student features via a generator. Ultimately, we utilize this reconstruction target to reconstruct the student features. In addition, we also explore temporal relational knowledge when inputting full frames for the student model. We verify the effectiveness of the proposed method on the nuScenes benchmark. The experimental results show our method obtain an enhancement of +1.6 mAP and +1.1 NDS compared to the baseline, a speed improvement of approximately 6 FPS after compressing temporal knowledge, and the most accurate velocity estimation.",[''],[]
,[''],[]
,[''],[]
,[''],[]
"Visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called “object constancy” across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have a similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. During the inference, latent representations are randomly initialized and iteratively updated by integrating the information in different viewpoints with neural networks. Experiments on several specifically designed synthetic datasets have shown that the proposed method can effectively learn from multiple unspecified viewpoints.","['Index', 'Terms: \ncompositional scene representations, object-centric learning, unsupervised learning, deep generative models, variational inference, object constancy.']",[]
"Equipped with sensing, networking, and computing capabilities, Internet of Things (IoT) such as smartphones, wearables, smart speakers, and household robots have been seamlessly weaved into our daily lives.
Recent advancements in Generative AI exemplified by GPT, LLaMA, DALL-E, and Stable Difussion hold immense promise to push IoT to the next level. In this article, we share our vision and views on the benefits that Generative AI brings to IoT, and discuss some of the most important applications of Generative AI in IoT-related domains. Fully harnessing Generative AI in IoT is a complex challenge. We identify some of the most critical challenges including high resource demands of the Generative AI models, prompt engineering, on-device inference, offloading, on-device fine-tuning, federated learning, security, as well as development tools and benchmarks, and discuss current gaps as well as promising opportunities on enabling Generative AI for IoT. We hope this article can inspire new research on IoT in the era of Generative AI.","['Index', 'Terms: ', 'Internet of', 'Things,', 'IoT,', 'AIoT,', 'Generative', 'AI,', 'Large', 'Language', 'Models,', 'LLMs,', 'Diffusion', 'Models,', 'Edge', 'AI']",[]
"We revisit the construction of the Hilbert space of non-relativistic particles moving in three spatial dimensions. This is given by the space of sections of a line bundle that can in general be topologically non-trivial. Such bundles are classified by a set of integers—one for each pair of particles—and arise physically when we describe the interactions of dyons, particles which carry both electric and magnetic charges. The choice of bundle fixes the representation of the Euclidean group carried by the Hilbert space. These representations are shown to recover the ‘pairwise helicity’ formalism recently discussed in the literature.",[''],[]
,[''],[]
"The second law lies at the heart of thermodynamics, characterizing the convertibility of thermodynamic states by a single quantity, the entropy. A fundamental question in quantum information theory is whether one can formulate an analogous second law characterizing the convertibility of resources for quantum information processing. In 2008, a promising formulation was proposed, where quantum-resource convertibility is characterized by the optimal performance of a variant of another fundamental task in quantum information processing, quantum hypothesis testing. The core of this formulation was to prove a lemma that identifies a quantity indicating the optimal performance of this task—the generalized quantum Stein’s lemma—to seek out a counterpart of the thermodynamic entropy in quantum information processing. However, in 2023, a logical gap was found in the existing proof of the generalized quantum Stein’s lemma, throwing into question once again whether such a formulation is possible at all. In this work, we construct a proof of the generalized quantum Stein’s lemma by developing alternative techniques to circumvent the logical gap of the existing analysis. With our proof, we redeem the formulation of quantum resource theories equipped with the second law as desired. These results affirmatively settle the fundamental question about the possibility of bridging the analogy between thermodynamics and quantum information theory.",[''],"['Japan', '3G1', '2Y5']"
"We propose a formalism which defines chaos in both quantum and classical systems in an equivalent manner by means of adiabatic transformations. The complexity of adiabatic transformations which preserve classical time-averaged trajectories (quantum eigenstates) in response to Hamiltonian deformations serves as a measure of chaos. This complexity is quantified by the (properly regularized) fidelity susceptibility. Our exposition clearly showcases the common structures underlying quantum and classical chaos and allows us to distinguish integrable, chaotic but non-thermalizing, and ergodic regimes. We apply the fidelity susceptibility to a model of two coupled spins and demonstrate that it successfully predicts the universal onset of chaos, both for finite spin S𝑆Sitalic_S and in the classical limit S→∞→𝑆S\to\inftyitalic_S → ∞. Interestingly, we find that finite S𝑆Sitalic_S effects are anomalously large close to integrability.",[''],[]
"In systems with a real Bloch Hamiltonian band nodes can be characterised by a non-Abelian frame-rotation charge. The ability of these band nodes to annihilate pairwise is path dependent, since by braiding nodes in adjacent gaps the sign of their charges can be changed.
Here, we theoretically construct and numerically confirm two concrete methods to experimentally probe these non-Abelian braiding processes and charges in ultracold atomic systems.
We consider a coherent superposition of two bands that can be created by moving atoms through the band singularities at some angle in momentum space. Analyzing the dependency on the frame charges, we demonstrate an interferometry scheme passing through two band nodes, which reveals the relative frame charges and allows for measuring the multi-gap topological invariant. The second method relies on a single wavepacket probing two nodes sequentially, where the frame charges can be determined from the band populations. Our results present a feasible avenue for measuring non-Abelian charges of band nodes and the experimental verification of braiding procedures directly, which can be applied in a variety of settings including the recently discovered anomalous non-Abelian phases arising under periodic driving.",[''],"['Kingdom', 'Kingdom', 'Kingdom', 'Kingdom']"
"We study the effect of ferromagnetic metals (FM) on the circularly polarized modes of an electromagnetic cavity and show that broken time-reversal symmetry leads to a dichroic response of the cavity modes. With one spin-split band, the Zeeman coupling between the FM electrons and cavity modes leads to an anticrossing for mode frequencies comparable to the spin splitting. However, this is only the case for one of the circularly polarized modes, while the other is unaffected by the FM, allowing for the determination of the spin-splitting of the FM using polarization-dependent transmission experiments. Moreover, we show that for two spin-split bands, also the lifetimes of the cavity modes display a polarization-dependent response. The reduced lifetime of modes of only one polarization could potentially be used to engineer and control circularly polarized cavities.",[''],['Norway']
We develop a transfer operator approach for the calculation of Rényi entanglement entropies in arbitrary (i.e. Abelian and non-Abelian) pure lattice gauge theory projected entangled pair states in 2+1 dimensions. It is explicitly shown how the long-range behavior of these quantities gives rise to an entanglement area law in both the thermodynamic limit and in the continuum. We numerically demonstrate the applicability of our method to the ℤ2subscriptℤ2\mathds{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT lattice gauge theory and relate some entanglement properties to the confinement-deconfinement transition therein. It is argued on general grounds that Rényi entanglement entropies do not qualify as a complete probe of confinement or deconfinement properties in comparison to other genuine (nonlocal) observables.,[''],[]
"We present new follow-up observations of two ultra-diffuse galaxies (UDGs), part of a total sample of five chosen for their distorted morphologies, suggestive of tidal influence. Using Hubble Space Telescope Advanced Camera for Surveys F555W and F814W imaging, we identify 8±2plus-or-minus828\pm 28 ± 2 globular clusters (GCs) in KUG 0203-Dw1 and 6±2plus-or-minus626\pm 26 ± 2 in KDG 013, abundances that are fairly typical for normal dwarf galaxies of similar stellar mass. Jansky Very Large Array data reveal a clear H i detection of KUG 0203-Dw1 with a gas mass estimate of log⁡MH⁢i/M⊙≲7.4less-than-or-similar-tosubscript𝑀Hisubscript𝑀direct-product7.4\log{M_{\rm{H}\,\rm{\textsc{i}}\ }/M_{\odot}}\lesssim 7.4roman_log italic_M start_POSTSUBSCRIPT roman_H i end_POSTSUBSCRIPT / italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT ≲ 7.4 and evidence of active stripping by the host. H i gas is found near the location of KDG 013 but is likely unrelated to the UDG itself due to the morphology and the numerous gas tails within the host group. Given that these UDGs have GC abundances typical for galaxies at their luminosity, these findings suggest that they likely originated as normal dwarf galaxies that have been subjected to significant stripping and tidal heating, causing them to become more diffuse. These two UDGs complete a sample of five exhibiting tidal features in the Canada-France-Hawaii Telescope Legacy Survey area (CFHTLS; ∼1502similar-toabsentsuperscript1502\sim 150^{2}∼ 150 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT deg), including UDGs with and without UV emission, indicative of recent star formation. Four UDGs in this sample, consistent with dwarfs ‘puffed-up’ by tidal interactions, contrast with an outlier, suggesting a dwarf merger origin. These findings indicate that tidal heating of dwarfs is a viable formation pathway for UDGs.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'Canada', 'Canada', 'USA', 'Canada', 'Canada']"
"We developed a tool that measures equivalent widths of various lines in low resolution optical spectra, and it was applied to stellar spectra obtained as part of SDSS-V and LAMOST programs.
These lines, such as Li I which directly indicates stellar youth, or optical H I and Ca II which in emission indicate activity associated with stellar youth, are commonly seen in YSOs.
We observe several notable differences in the properties of these lines between YSOs and the field stars. Using these data, we devise a set of criteria through which it is possible to confirm the youth of stars that have been observed by the ABYSS program, as well as to identify likely young stars that have serendipitously been observed by other programs. We examine the decrement of H lines seen in emission in CTTSs, and estimate the properties of the accretion stream that is responsible for the production of these lines. Finally, we examine the evolution of Li I as a function of age, and characterize the scatter in its abundance that appears to be intrinsic in young M dwarfs.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'México', 'USA', 'Chile', 'USA', 'México', 'México', 'USA', 'USA']"
"“Changing-look” Active Galactic Nuclei (CL-AGNs) are challenging our basic ideas about the physics of accretion flows and of circumnuclear gas around supermassive black holes (SMBHs).
Using first-year Sloan Digital Sky Survey V (SDSS-V) repeated spectroscopy of nearly 29,000 previously-known AGNs, combined with dedicated follow-up spectroscopic observations, and publicly available optical light curves, we have identified 116 CL-AGNs where (at least) one broad emission line has essentially (dis-)appeared, as well as 88 other extremely variable systems.
Our CL-AGN sample, with 107 newly identified cases, is among the largest reported to date, and includes ∼0.4%similar-toabsentpercent0.4\sim 0.4\%∼ 0.4 % of the AGNs re-observed in the first year of SDSS-V operations.
Among our CL-AGNs, 67% exhibit dimming while 33% exhibit brightening.
Our data and sample probe extreme AGN spectral variability on timescales of months to decades, including some cases of recurring transitions on surprisingly short timescales (≲2less-than-or-similar-toabsent2\lesssim 2≲ 2 months in the rest frame).
We find that CL events are preferentially found in lower Eddington ratio (fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT) systems: Our CL-AGNs have a fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT distribution that significantly differs from that of a redshift- and a carefully constructed, luminosity-matched control sample (pKS≲2×10−4less-than-or-similar-tosubscript𝑝KS2superscript104p_{\rm KS}\lesssim 2\times 10^{-4}italic_p start_POSTSUBSCRIPT roman_KS end_POSTSUBSCRIPT ≲ 2 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT; median fEdd≈0.025subscript𝑓Edd0.025f_{\mathrm{Edd}}\approx 0.025italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT ≈ 0.025 vs. 0.0430.0430.0430.043).
This preference for low fEddsubscript𝑓Eddf_{\mathrm{Edd}}italic_f start_POSTSUBSCRIPT roman_Edd end_POSTSUBSCRIPT strengthens previous findings of higher CL-AGN incidence at lower Eddington ratios, found in much smaller samples of spectroscopically confirmed CL-AGNs.
Finally, we show that the broad Mg ii emission line in our CL-AGN sample tends to vary significantly less than the broad Hβ𝛽\betaitalic_β emission line.
Our large CL-AGN sample demonstrates the advantages and challenges in using multi-epoch spectroscopy from large surveys to study extreme AGN variability, SMBH fueling, and AGN physics.","['Supermassive black holes (1663),', 'Quasars (1319),', 'Active galactic nuclei (16)']","['Israel', 'Israel', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Chile', 'Chile', 'Chile', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Chile', 'USA', 'Germany', 'USA', 'USA', 'USA', 'Chile', 'Chile', 'China', 'USA', 'USA', 'USA', 'USA', 'Israel', 'Chile', 'USA', 'China', 'USA', 'Germany', 'USA', 'USA', 'Moscow', 'USA', 'USA', 'Canada']"
,[''],[]
"Detection of redshifted \ionHi 21cm emission is a potential probe for investigating the Universe’s first billion years. However, given the significantly brighter foreground, detecting 21cm is observationally difficult. The Earth’s ionosphere considerably distorts the signal at low frequencies by introducing directional-dependent effects. Here, for the first time, we report the use of Artificial Neural Networks (ANNs) to extract the global 21cm signal characteristics from the composite all-sky averaged signal, including foreground and ionospheric effects such as refraction, absorption, and thermal emission from the ionosphere’s F and D-layers. We assume a ’perfect’ instrument and neglect instrumental calibration and beam effects. To model the ionospheric effect, we considered the static and time-varying ionospheric conditions for the mid-latitude region where LOFAR is situated. In this work, we trained the Artificial Neural Network (ANN) model for various situations using a synthetic set of the global 21cm signals created by altering its parameter space based on the ""tanh\rm\tanhroman_tanh"" parameterized model and the Accelerated Reionization Era Simulations (ARES) algorithm. The obtained result shows that the ANN model can extract the global signal parameters with an accuracy of ≥96%absentpercent96\geq 96\%≥ 96 % in the final study when we include foreground and ionospheric effects. On the other hand, a similar ANN model can extract the signal parameters from the final prediction dataset with an accuracy ranging from 97%percent9797\%97 % to 98%percent9898\%98 % when considering more realistic sets of the global 21cm signals based on physical models.",[''],[]
"In dense neutrino gases, the neutrino-neutrino coherent forward scattering gives rise to a complex flavor oscillation phenomenon not fully incorporated in simulations of neutron star mergers (NSM) and core collapse supernovae (CCSNe). Moreover, it has been proposed to be chaotic, potentially limiting our ability to predict neutrino flavor transformations in simulations. To address this issue, we explore how small flavor perturbations evolve within a narrow centimeter-scale region inside a NSM and a toy neutrino distribution. Our findings reveal that paths in the flavor state space of solutions with similar initial conditions diverge exponentially, exhibiting chaos. This inherent chaos makes the microscopic scales of neutrino flavor transformations unpredictable. However, the domain-averaged neutrino density matrix remains relatively stable, with chaos minimally affecting it. This particular property suggests that domain-averaged quantities remain reliable despite the exponential amplification of errors.",[''],"['USA', 'Salvador', 'USA']"
"The growth of active galactic nuclei (AGN) occurs under some form of obscuration in a large fraction of the population. The difficulty in constraining this population leads to high uncertainties in cosmic X-ray background and galaxy evolution models. Using an SDSS-WISE cross-match, we target infrared luminous AGN (W⁢1−W⁢2𝑊1𝑊2W1-W2italic_W 1 - italic_W 2 > 0.8, and monochromatic rest-frame luminosity above λ⁢Lλ𝜆subscript𝐿𝜆\lambda L_{\lambda}italic_λ italic_L start_POSTSUBSCRIPT italic_λ end_POSTSUBSCRIPT(12 µ⁢mtimes12micrometer12\text{\,}\mathrm{\SIUnitSymbolMicro m}start_ARG 12 end_ARG start_ARG times end_ARG start_ARG roman_µ roman_m end_ARG) ≈\approx≈ 3 ×\times× 104444{}^{44}start_FLOATSUPERSCRIPT 44 end_FLOATSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT), but with passive galaxy-like optical spectra (Optically Quiescent Quasars; OQQs). We find 47 objects that show no significant [O iii]λ𝜆\lambdaitalic_λ5007 emission, a typically strong AGN optical emission line. As a comparison sample, we examine SDSS-selected Type 2 quasars (QSO2s), which show a significant [O iii]λ𝜆\lambdaitalic_λ5007 line by definition. We find a 1:16 ratio of OQQs compared to QSO2s, suggesting that the OQQ duty cycle is likely much shorter than that of QSO2s (though selection biases are not fully quantified). We consider observed properties in comparison with other galaxy types, and examine them for consistency with theories on their intrinsic nature: chiefly (a) a high covering factor for surrounding obscuring matter, preventing the detection of high-ionisation emission lines – ‘cocooned AGN’; or (b) ionised gas being absent on the kpc scales of the Narrow Line Region (NLR), perhaps due to a ‘switching on’ or ‘young’ AGN. OQQs do not obviously fit the standard paradigm for merger-driven AGN and host galaxy evolution, implying we may be missing part of the flow of AGN evolution.",[''],[]
"Molecular anisotropy plays an important role in the glass transition of a liquid. Recently, a novel glass state has been discovered by optical microscopy experiments on suspensions of ellipsoidal colloids. ’Liquid glass’ is a disordered analog of a nematic liquid crystal, where rotation motion is hindered but particles diffuse freely. Global nematic order is suppressed as clusters of aligned particles intertwine. We perform Brownian dynamics simulations to test the structure and dynamics of a dense system of soft ellipsoidal particles.
As seen in experiments and in accordance with predictions from mode coupling theory, on the time scale of our simulations rotation motion is frozen but translation motion persists in liquid glass. Analyses of the dynamic structure functions for translation and rotation corroborates the presence of two separate glass transitions for rotation and translation, respectively. Even though the equilibrium state should be a nematic, aligned structures remain small and orientational order rapidly decays with increasing size. Long-wavelength fluctuations are remnants of the isotropic-nematic transition.",[''],"['Germany', 'Germany', 'Germany']"
"Amidst all candidates of physics beyond the Standard Model, string theory provides a unique proposal
for incorporating gauge and gravitational interactions.
In string theory, a four-dimensional theory that unifies quantum mechanics and gravity is obtained automatically if one posits that the additional dimensions predicted by the theory are small and curled up, a concept known as compactification. The gauge sector of the theory is specified by the topology and geometry of the extra dimensions, and the challenge is to reproduce all the features of the Standard Model of Particle Physics from them. We review the state-of-the-art in reproducing the Standard Model from string compactifications, together with the lessons drawn from this fascinating quest. We describe novel scenarios and mechanisms that string theory provides to address some of the Standard Model puzzles, as well as the most frequent signatures of new physics that could be detected in future experiments. We finally comment on recent developments that connect, in a rather unexpected way, the Standard Model with Quantum Gravity, and that may change our field theory notion of naturalness.",[''],[]
,[''],[]
"We present results for the τ1subscript𝜏1\tau_{1}italic_τ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and τ1⁢asubscript𝜏1𝑎\tau_{1a}italic_τ start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT 1-Jettiness global event shape distributions, for Deep Inelastic Scattering (DIS), at the N33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTLL + 𝒪⁢(αs2)𝒪superscriptsubscript𝛼𝑠2{\cal O}(\alpha_{s}^{2})caligraphic_O ( italic_α start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )
level of accuracy. These event-shape distributions quantify and characterize the pattern of final state radiation in electron-nucleus collisions. They can be used as a probe of nuclear structure functions, nuclear medium effects in jet production, and for a precision extraction of the QCD strong coupling. The results presented here, along with the corresponding numerical codes, can be used for analyses with HERA data, in EIC simulation studies, and for eventual comparison with real EIC data.",[''],"['China', 'USA', 'USA', 'USA', 'China', 'China', 'China', 'USA']"
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
