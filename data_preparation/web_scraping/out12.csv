abstract,keyword,country
,[''],"['Davis', 'Davis']"
"We show evidence of particle acceleration at GEV energies associated directly with protons from the prompt emission of a long-duration M6-class solar flare on July 17, 2023, rather than from protons acceleration by shocks from its associated Coronal Mass Ejection (CME), which erupted with a speed of 1342 km/s. Solar Energetic Particles (SEP) accelerated by the blast have reached Earth, up to an almost S3 (strong) category of a radiation storm on the NOAA scale.
Also, we show a temporal correlation between the fast rising of GOES-16 proton and muon excess at ground level in the count rate of the New-Tupi muon detector at the central SAA region.
A Monte Carlo spectral analysis based on muon excess at New-Tupi is consistent with the acceleration of electrons and protons (ions) up to relativistic energies (GeV energy range) in the impulsive phase of the flare. In addition, we present another two marginal particle excesses (with low confidence) at ground-level detectors in correlation with the solar flare prompt emission.","['sun:activity, high-speed stream, cosmic rays modulation']","['Brazil', 'Brazil', 'Brazil']"
"Metamaterials with functional responses, such as wave-based responses or deformation-induced property variation under external stimuli, can exhibit varying properties or functionalities under different conditions. Herein, we aim at rapid inverse design of these metamaterials to meet target qualitative functional behaviors. This inverse problem is challenging due to its intractability and the existence of non-unique solutions. Past works mainly focus on deep-learning-based methods that are data-demanding, require time-consuming training and hyperparameter tuning, and are non-interpretable. To overcome these limitations, we propose the Random-forest-based Interpretable Generative Inverse Design (RIGID), a single-shot inverse design method to achieve the fast generation of metamaterial designs with on-demand functional behaviors. Unlike most existing methods, by exploiting the interpretability of the random forest, we eliminate the need to train an inverse model mapping responses to designs. Based on the likelihood of target satisfaction derived from the trained forward model, one can sample design solutions using Markov chain Monte Carlo methods. The RIGID method therefore functions as a generative model that captures the conditional distribution of satisfying solutions given a design target. We demonstrate the effectiveness and efficiency of RIGID on both acoustic and optical metamaterial design problems where only small datasets (less than 250 training samples) are available. Synthetic design problems are created to further illustrate and validate the mechanism of likelihood estimation in RIGID. This work offers a new perspective on solving on-demand inverse design problems, showcasing the potential for incorporating interpretable machine learning into generative design and eliminating its large data requirement.",[''],[]
,[''],[]
,[''],[]
"Building open-ended learning agents involves challenges in pre-trained language model (LLM) and reinforcement learning (RL) approaches. LLMs struggle with context-specific real-time interactions, while RL methods face efficiency issues for exploration. To this end, we propose OpenContra, a co-training framework that cooperates LLMs and GRL to construct an open-ended agent capable of comprehending arbitrary human instructions.
The implementation comprises two stages: (1) fine-tuning an LLM to translate human instructions into structured goals, and curriculum training a goal-conditioned RL policy to execute arbitrary goals; (2) collaborative training to make the LLM and RL policy learn to adapt each, achieving open-endedness on instruction space.
We conduct experiments on Contra, a battle royale FPS game with a complex and vast goal space.
The results show that an agent trained with OpenContra comprehends arbitrary human instructions and completes goals with a high completion ratio, which proves that OpenContra may be the first practical solution for constructing open-ended embodied agents.","['Machine', 'Learning,', 'ICML']",[]
,[''],[]
,[''],[]
"In the wake of large language models, there has been a resurgence of claims and questions about the Turing test and its value for AI, which are reminiscent of decades of practical “Turing” tests. If AI were quantum physics, by now several “Schrödinger’s” cats could have been killed. Better late than never, it is time for a historical reconstruction of Turing’s beautiful thought experiment. In this paper I present a wealth of evidence, including new archival sources, give original answers to several open questions about Turing’s 1950 paper, and address the core question of the value of Turing’s test.","['Alan', 'Turing,', 'Turing test,', 'Thought experiment,', 'Foundations of', 'AI & computer science,', 'Galileo', 'Galilei,', 'History of science,', 'History of', 'AI']",['PauloBrazil']
"Online recruitment platforms typically employ Person-Job Fit models in the core service that automatically match suitable job seekers with appropriate job positions. While existing works leverage historical or contextual information, they often disregard a crucial aspect: job seekers’ social relationships in professional networks. This paper emphasizes the importance of incorporating professional networks into the Person-Job Fit model. Our innovative approach consists of two stages: (1) defining a Workplace Heterogeneous Information Network (WHIN) to capture heterogeneous knowledge, including professional connections and pre-training representations of various entities using a heterogeneous graph neural network; (2) designing a Contextual Social Attention Graph Neural Network (CSAGNN) that supplements users’ missing information with professional connections’ contextual information. We introduce a job-specific attention mechanism in CSAGNN to handle noisy professional networks, leveraging pre-trained entity representations from WHIN. We demonstrate the effectiveness of our approach through experimental evaluations conducted across three real-world recruitment datasets from LinkedIn, showing superior performance compared to baseline models.","['Person-Job', 'Fit,', 'Heterogeneous', 'Information', 'Network,', 'Graph', 'Neural', 'Network']","['UniversityBeijingChina', 'ResearchBeijingChina', 'UniversityBostonUSA', 'ResearchBeijingChina', 'ResearchBeijingChina', 'ResearchBeijingChina', 'CorporationBeijingChina', 'CorporationBeijingChina', 'CorporationBeijingChina']"
"Recent years have seen a lot of progress in algorithms for learning parameters of spreading dynamics from both full and partial data. Some of the remaining challenges include model selection under the scenarios of unknown network structure, noisy data, missing observations in time, as well as an efficient incorporation of prior information to minimize the number of samples required for an accurate learning. Here, we introduce a universal learning method based on scalable dynamic message-passing technique that addresses these challenges often encountered in real data. The algorithm leverages available prior knowledge on the model and on the data, and reconstructs both network structure and parameters of a spreading model. We show that a linear computational complexity of the method with the key model parameters makes the algorithm scalable to large network instances.",[''],['USA']
,[''],[]
,[''],[]
"The prediction of tumor progression and chemotherapy response has been recently tackled exploiting Tumor Infiltrating Lymphocytes (TILs) and the nuclear protein Ki67 as prognostic factors.
Recently, deep neural networks (DNNs) have been shown to achieve top results in estimating Ki67 expression and simultaneous determination of intratumoral TILs score in breast cancer cells. However,
in the last ten years the extraordinary progress induced by deep models proliferated
at least as much as their resource demand.
The exorbitant computational costs required to query (and in some cases also to store) a deep model represent a strong limitation in resource-limited contexts, like that of IoT-based applications to support healthcare personnel.
To this end, we propose a resource consumption-aware DNN for the effective estimate of the percentage of Ki67-positive cells in breast cancer screenings. Our approach reduced up to 75%percent7575\%75 % and 89%percent8989\%89 % the usage of memory and disk space respectively, up to 1.5×1.5\times1.5 × the energy consumption, and preserved or improved the overall accuracy of a benchmark state-of-the-art solution. Encouraged by such positive results, we developed and structured the adopted framework so as to allow its general purpose usage, along with a public software repository to support its usage.","['Tumor infiltrating lymphocytes,', 'Ki67 protein,', 'Resource-limited learning,', 'Resource-limited devices,', 'DNN compression,', 'Deep learning.']","['18MilanItaly20133', '(JRC)IspraItaly', '18MilanItaly20133', 'MilanItaly20072', 'MilanItaly20089', '18MilanItaly20133', 'SystemsRomeItaly', '18MilanItaly20133', 'SystemsRomeItaly']"
"Growth in the penetration of renewable energy sources makes supply more uncertain and leads to an increase in the system imbalance. This trend, together with the single imbalance pricing, opens an opportunity for balance responsible parties (BRPs) to perform energy arbitrage in the imbalance settlement mechanism. To this end, we propose a battery control framework based on distributional reinforcement learning (DRL). Our proposed control framework takes a risk-sensitive perspective, allowing BRPs to adjust their risk preferences: we aim to optimize a weighted sum of the arbitrage profit and a risk measure while constraining the daily number of cycles for the battery. We assess the performance of our proposed control framework using the Belgian imbalance prices of 2022 and compare two state-of-the-art RL methods, deep Q learning and soft actor-critic. Results reveal that the distributional soft actor-critic method can outperform other methods. Moreover, we note that our fully risk-averse agent appropriately learns to hedge against the risk related to the unknown imbalance price by (dis)charging the battery only when the agent is more certain about the price.",[''],[]
"The potential for augmenting the segmentation of brain tumors through the use of few-shot learning is vast. Although several deep learning networks (DNNs) demonstrate promising results in terms of segmentation, they require a substantial quantity of training data in order to produce suitable outcomes. Furthermore, a major issue faced by most of these models is their ability to perform well when faced with unseen classes. To address these challenges, we propose a one-shot learning model for segmenting brain tumors in magnetic resonance images (MRI) of the brain, based on a single prototype similarity score. Leveraging the recently developed techniques of few-shot learning, which involve the utilization of support and query sets of images for training and testing purposes, we strive to obtain a definitive tumor region by focusing on slices that contain foreground classes. This approach differs from other recent DNNs that utilize the entire set of images. The training process for this model is carried out iteratively, with each iteration involving the selection of random slices that contain foreground classes from randomly sampled data as the query set, along with a different random slice from the same sample as the support set. In order to distinguish the query images from the class prototypes, we employ a metric learning-based approach that relies on non-parametric thresholds. We employ the multimodal Brain Tumor Image Segmentation (BraTS) 2021 dataset, which comprises 60 training images and 350 testing images. The effectiveness of the model is assessed using the mean dice score and mean Intersection over Union (IoU) score. The experimental results demonstrate a dice score of 83.42, which exceeds the performance of other works in the literature. Moreover, the proposed one-shot segmentation model surpasses conventional methods in terms of computational time, memory usage, and the amount of data employed.","['Index', 'Terms: \nbrain tumor, magnetic resonance images, few-shot learning']",[]
"I use QAOA to solve the Hamiltonian Circle problem. First, inspired by Lucas [8], I define the QUBO form of Hamiltonian Cycle an transform it to a quantum circuit by embedding the problem of n𝑛nitalic_n vertices to an encoding of (n−1)2superscript𝑛12(n-1)^{2}( italic_n - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT qubits. Then, I calcluate the spectrum of the cost hamiltonian for both triangle case and square case and justify my definition. I also write a python program to generate the cost hamiltonian automatically for finding the hamiltonian cycle in an arbitrary graph. I test the correctess of the hamailtonian by analyze their energy spectrums. Since the (n−1)2superscript𝑛12(n-1)^{2}( italic_n - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT embedding limit my simulation of graph size to be less than 5555, I decide to test the correctness, only for small and simple graph in this project. I implement the QAOA algorithm using qiskit and run the simulation for the triangle case and the square case, which are easy to test the correctness, both with and without noise. A very interesting result I got is that for the square case, the QAOA get much better result on a noisy simulator than a noiseless simulator! The explanation for this phenomena require further investigation, perhaps quantum noise can actually be helpful, rather than harmful in the annealing algorithms. I also use two different kinds of mixer, Rxsubscript𝑅𝑥R_{x}italic_R start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT mixer and Rysubscript𝑅𝑦R_{y}italic_R start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT circuit to run the simulation. It turns out that Rxsubscript𝑅𝑥R_{x}italic_R start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT mixer performs much better than Rysubscript𝑅𝑦R_{y}italic_R start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT mixer in this problem.",[''],[]
"The Bayesian reconstruction entropy is considered an alternative to the Shannon-Jaynes entropy, as it does not exhibit the asymptotic flatness characteristic of the Shannon-Jaynes entropy and obeys the scale invariance. It is commonly utilized in conjunction with the maximum entropy method to derive spectral functions from Euclidean time correlators produced by lattice QCD simulations. This study expands the application of the Bayesian reconstruction entropy to the reconstruction of spectral functions for Matsubara or imaginary-time Green’s functions in quantum many-body physics. Furthermore, it extends the Bayesian reconstruction entropy to implement the positive-negative entropy algorithm, enabling the analytic continuations of matrix-valued Green’s functions on an element-wise manner. Both the diagonal and off-diagonal components of the matrix-valued Green’s functions are treated equally. Benchmark results for the analytic continuations of synthetic Green’s functions indicate that the Bayesian reconstruction entropy, when combined with the preblur trick, demonstrates comparable performance to the Shannon-Jaynes entropy. Notably, it exhibits greater resilience to noises in the input data, particularly when the noise level is moderate.",[''],['China']
"In this article, we discuss how a kind of hybrid computation, which employs symbolic, numeric, classic, and quantum algorithms, allows us to conduct Hartree-Fock electronic structure computation of molecules. In the proposed algorithm, we replace the Hartree-Fock equations with a set of equations composed of multivariate polynomials. We transform those polynomials to the corresponding Gröbner bases, and then we investigate the corresponding quotient ring, wherein the orbital energies, the LCAO coefficients, or the atomic coordinates are represented by the variables in the ring. In this quotient ring, the variables generate the transformation matrices that represent the multiplication with the monomial bases, and the eigenvalues of those matrices compose the roots of the equation. The quantum phase estimation (QPE) algorithm enables us to record those roots in the quantum states, which would be used in the input data for more advanced and more accurate quantum computations.",[''],[]
,[''],[]
,[''],[]
"Let R𝑅Ritalic_R be a finitely generated ℕℕ\mathbb{N}blackboard_N-graded algebra domain over a Noetherian ring and let I𝐼Iitalic_I be a homogeneous ideal of R𝑅Ritalic_R. Given P∈Ass⁡(R/I)𝑃Ass𝑅𝐼P\in\operatorname{Ass}(R/I)italic_P ∈ roman_Ass ( italic_R / italic_I ) one defines the v𝑣vitalic_v-invariant vP⁢(I)subscript𝑣𝑃𝐼v_{P}(I)italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I ) of I𝐼Iitalic_I at P𝑃Pitalic_P as the least c∈ℕ𝑐ℕc\in\mathbb{N}italic_c ∈ blackboard_N such that P=I:f:𝑃𝐼𝑓P=I:fitalic_P = italic_I : italic_f for some f∈Rc𝑓subscript𝑅𝑐f\in R_{c}italic_f ∈ italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. A classical result of Brodmann [1] asserts that Ass⁡(R/In)Ass𝑅superscript𝐼𝑛\operatorname{Ass}(R/I^{n})roman_Ass ( italic_R / italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) is constant for large n𝑛nitalic_n. So it makes sense to consider a prime ideal P∈Ass⁡(R/In)𝑃Ass𝑅superscript𝐼𝑛P\in\operatorname{Ass}(R/I^{n})italic_P ∈ roman_Ass ( italic_R / italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) for all the large n𝑛nitalic_n and investigate how vP⁢(In)subscript𝑣𝑃superscript𝐼𝑛v_{P}(I^{n})italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) depends on n𝑛nitalic_n. We prove that vP⁢(In)subscript𝑣𝑃superscript𝐼𝑛v_{P}(I^{n})italic_v start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) is eventually a linear function of n𝑛nitalic_n.
When R𝑅Ritalic_R is the polynomial ring over a field this statement has been proved independently also by Ficarra and Sgroi in their recent preprint [4].","['Key words and phrases:', 'Associated primes, v-invariant']",[]
"Image-to-image translation has gained popularity in the medical field to transform images from one domain to another.
Medical image synthesis via domain transformation is advantageous in its ability to augment an image dataset where images for a given class is limited. From the learning perspective, this process contributes to data-oriented robustness of the model by inherently broadening the model’s exposure to more diverse visual data and enabling it to learn more generalized features. In the case of generating additional neuroimages, it is advantageous to obtain unidentifiable medical data and augment smaller annotated datasets. This study proposes the development of a CycleGAN model for translating neuroimages from one field strength to another (e.g., 3 Tesla to 1.5). This model was compared to a model based on DCGAN architecture. CycleGAN was able to generate the synthetic and reconstructed images with reasonable accuracy. The mapping function from the source (3 Tesla) to target domain (1.5 Tesla) performed optimally with an average PSNR value of 25.69 ±plus-or-minus\pm± 2.49 dB and an MAE value of 2106.27 ±plus-or-minus\pm± 1218.37.",[''],"['*', '[']"
,[''],[]
"Learning from demonstration is a powerful method for teaching robots new skills, and more demonstration data often improves policy learning. However, the high cost of collecting demonstration data is a significant bottleneck. Videos, as a rich data source, contain knowledge of behaviors, physics, and semantics, but extracting control-specific information from them is challenging due to the lack of action labels. In this work, we introduce a novel framework, Any-point Trajectory Modeling (ATM), that utilizes video demonstrations by pre-training a trajectory model to predict future trajectories of arbitrary points within a video frame. Once trained, these trajectories provide detailed control guidance, enabling the learning of robust visuomotor policies with minimal action-labeled data. Our method’s effectiveness is demonstrated across 130 simulation tasks, focusing on language-conditioned manipulation tasks. Visualizations and code are available at: https://xingyu-lin.github.io/atm.",[''],[]
"We reaffirm the claim of Lee et al. [preceding Comment, Phys. Rev. A 108, 066401 (2023)] that the expression of quantum dual total correlation of a multipartite system in terms of quantum relative entropy as proposed in previous work [A. Kumar, Phys. Rev. A 96, 012332 (2017)] is not correct. We provide alternate expression(s) of quantum dual total correlation in terms of quantum relative entropy. We, however, prescribe that in computing quantum dual total correlation one should use its expression in terms of von Neumann entropy.",[''],['India']
"Coarse-to-fine schemes are widely used in traditional single-image motion deblur; however, in the context of deep learning, existing multi-scale algorithms not only require the use of complex modules for feature fusion of low-scale RGB images and deep semantics, but also manually generate low-resolution pairs of images that do not have sufficient confidence. In this work, we propose a multi-scale network based on single-input and multiple-outputs(SIMO) for motion deblurring. This simplifies the complexity of algorithms based on a coarse-to-fine scheme. To alleviate restoration defects impacting detail information brought about by using a multi-scale architecture, we combine the characteristics of real-world blurring trajectories with a learnable wavelet transform module to focus on the directional continuity and frequency features of the step-by-step transitions between blurred images to sharp images. In conclusion, we propose a multi-scale network with a learnable discrete wavelet transform (MLWNet), which exhibits state-of-the-art performance on multiple real-world deblurred datasets, in terms of both subjective and objective quality as well as computational efficiency. Our code will be open-sourced on github later.",[''],[]
"The laws of model size, data volume, computation and model performance have been extensively studied in the field of Natural Language Processing (NLP). However, the scaling laws in Optical Character Recognition (OCR) have not yet been investigated. To address this, we conducted comprehensive studies that involved examining the correlations between performance and the scale of models, data volume and computation in the field of text recognition. Conclusively, the study demonstrates smooth power laws between performance and model size, as well as training data volume, when other influencing factors are held constant. Additionally, we have constructed a large-scale dataset called REBU-Syn, which comprises 6 million real samples and 18 million synthetic samples. Based on our scaling law and new dataset, we have successfully trained a scene text recognition model, achieving a new state-of-the-art on 6 common test benchmarks with a top-1 average accuracy of 97.42%percent\%%.",[''],[]
"Estimating the 6D object pose from a single RGB image often involves noise and indeterminacy due to challenges such as occlusions and cluttered backgrounds.
Meanwhile, diffusion models have shown appealing performance in generating high-quality images from random noise with high indeterminacy through step-by-step denoising.
Inspired by their denoising capability, we propose a novel diffusion-based framework (6D-Diff) to handle the noise and indeterminacy in object pose estimation for better performance.
In our framework, to establish accurate 2D-3D correspondence, we formulate 2D keypoints detection as a reverse diffusion (denoising) process.
To facilitate such a denoising process, we design a Mixture-of-Cauchy-based forward diffusion process and condition the reverse process on the object features.
Extensive experiments on the LM-O and YCB-V datasets demonstrate the effectiveness of our framework.",[''],[]
,[''],[]
"Decision-making is a dynamic process requiring perception, memory, and reasoning to make choices and find optimal policies.
Traditional approaches to decision-making suffer from sample efficiency and generalization, while large-scale self-supervised pretraining has enabled fast adaptation with fine-tuning or few-shot learning in language and vision.
We thus argue to integrate knowledge acquired from generic large-scale self-supervised pretraining into downstream decision-making problems.
We propose Pretrain-Then-Adapt pipeline and survey recent work on data collection, pretraining objectives and adaptation strategies for decision-making pretraining and downstream inference.
Finally, we identify critical challenges and future directions for developing decision foundation model with the help of generic and flexible self-supervised pretraining.",[''],[]
"Computational imaging (CI) has been attracting a lot of interest in recent years for its superiority over traditional imaging in various applications. In CI systems, information is generally acquired in an encoded form and subsequently decoded via processing algorithms, which is quite in line with the information transmission mode of modern communication, and leads to emerging studies from the viewpoint of information optical imaging.
Currently, one of the most important issues to be theoretically studied for CI is to quantitatively evaluate the fundamental ability of information acquisition, which is essential for both objective performance assessment and efficient design of imaging system.
In this paper, by incorporating the Bayesian filtering paradigm, we propose a framework for CI that enables quantitative evaluation and design of the imaging system, and demonstate it based on ghost imaging. In specific, this framework can provide a quantitative evaluation on the acquired information through Fisher information and Cramér-Rao Lower Bound (CRLB), and the intrinsic performance of the imaging system can be accessed in real-time.
With simulation and experiments, the framework is validated and compared with existing linear unbiased algorithms.
In particular, the image retrieval can reach the CRLB.
Furthermore, information-driven adaptive design for optimizing the information acquisition procedure is also achieved.
By quantitative describing and efficient designing, the proposed framework is expected to promote the practical applications of CI techniques.",[''],[]
"Design patterns provide a systematic way to convey solutions to recurring modeling challenges. This paper introduces design patterns for hybrid modeling, an approach that combines modeling based on first principles with data-driven modeling techniques. While both approaches have complementary advantages there are often multiple ways to combine them into a hybrid model, and the appropriate solution will depend on the problem at hand. In this paper, we provide four base patterns that can serve as blueprints for combining data-driven components with domain knowledge into a hybrid approach. In addition, we also present two composition patterns that govern the combination of the base patterns into more complex hybrid models. Each design pattern is illustrated by typical use cases from application areas such as climate modeling, engineering, and physics.",[''],"['[', '[', '[']"
,[''],[]
"Complex dynamical systems are notoriously difficult to model because some degrees of freedom (e.g., small scales) may be computationally unresolvable or are incompletely understood, yet they are dynamically important. For example, the small scales of cloud dynamics and droplet formation are crucial for controlling climate, yet are unresolvable in global climate models. Semi-empirical closure models for the effects of unresolved degrees of freedom often exist and encode important domain-specific knowledge. Building on such closure models and correcting them through learning the structural errors can be an effective way of fusing data with domain knowledge. Here we describe a general approach, principles, and algorithms for learning about structural errors. Key to our approach is to include structural error models inside the models of complex systems, for example, in closure models for unresolved scales. The structural errors then map, usually nonlinearly, to observable data. As a result, however, mismatches between model output and data are only indirectly informative about structural errors, due to a lack of labeled pairs of inputs and outputs of structural error models. Additionally, derivatives of the model may not exist or be readily available. We discuss how structural error models can be learned from indirect data with derivative-free Kalman inversion algorithms and variants, how sparsity constraints enforce a “do no harm” principle, and various ways of modeling structural errors. We also discuss the merits of using non-local and/or stochastic error models. In addition, we demonstrate how data assimilation techniques can assist the learning about structural errors in non-ergodic systems. The concepts and algorithms are illustrated in two numerical examples based on the Lorenz-96 system and a human glucose-insulin model.",[''],[]
"We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently contain distributional information, liberating the network from a single output to concurrently generate multiple samples proves to be highly effective. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with two intriguing properties: highly compressed representation and more general zero-shot conditional generation. We demonstrate the efficacy of DDN and these intriguing properties through experiments on CIFAR-10 and FFHQ.",[''],[]
"The tasks of designing
messenger RNAs and non-coding RNAs are
discrete optimization problems, and
several versions of these problems are NP-hard.
As an alternative to commonly used local search methods,
we formulate these problems
as continuous optimization and develop
a general framework for this optimization based on
a new concept of “expected partition function”.
The basic idea is to start with a distribution over all possible candidate sequences,
and extend the objective function from a sequence to a distribution. We then use gradient descent-based optimization methods
to improve the extended objective function, and the distribution
will gradually shrink towards a one-hot sequence (i.e., a single sequence).
We consider two important case studies within this framework,
the mRNA design problem
optimizing for partition function (i.e., ensemble free energy)
and the non-coding RNA design problem optimizing for conditional (i.e., Boltzmann) probability.
In both cases, our approach demonstrate promising preliminary results. We make our code available at https://github.com/KuNyaa/RNA_Design_codebase.",[''],[]
"We investigate the embedding formalism in conjunction with the Mellin transform to determine tree-level gluon amplitudes in AdS/CFT. Detailed computations of three to five-point correlators are conducted, ultimately distilling what were previously complex results for five-point correlators into a more succinct and comprehensible form. We then proceed to derive a recursion relation applicable to a specific class of n𝑛nitalic_n-point gluon amplitudes. This relation is instrumental in systematically constructing amplitudes for a range of topologies. We illustrate its efficacy by specifically computing six to eight-point functions.
Despite the complexity encountered in the intermediate steps of the recursion, the higher-point correlator is succinctly expressed as a polynomial in boundary coordinates, upon which a specific differential operator acts. Remarkably, we observe that these amplitudes strikingly mirror their counterparts in flat space, traditionally computed using standard Feynman rules. This intriguing similarity has led us to propose a novel dictionary: comprehensive rules that bridge AdS Mellin amplitudes with flat-space gluon amplitudes.",[''],[]
,[''],[]
"We consider phenomenological aspects of a natural class of
Standard Model-like supersymmetric F-theory vacua realized through
flux breaking of rigid E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT gauge factors.
Three
generations of Standard Model matter
are realized in many of these vacua.
We further
find that many other Standard Model-like features
are naturally compatible
with these constructions. For example, dimension-4 and 5 terms associated
with proton decay are ubiquitously suppressed. Many of these features are
due to the group theoretical structure
of E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT and associated F-theory geometry. In particular, a set of approximate global symmetries descends
from the E7subscript𝐸7E_{7}italic_E start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT group,
leading to exponential suppression of undesired
couplings.",[''],[]
"We present a new formulation for Yang-Mills scattering amplitudes in any number of dimensions and at any loop order, based on the same combinatorial and binary-geometric ideas in kinematic space recently used to give an all-order description of Tr ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT theory. We propose that in a precise sense the amplitudes for a suitably “stringy” form of these two theories are identical, up to a simple shift of kinematic variables. This connection is made possible by describing the amplitudes for n𝑛nitalic_n gluons via a “scalar scaffolding”, arising from the scattering of 2⁢n2𝑛2n2 italic_n colored scalars coming in n𝑛nitalic_n distinct pairs of flavors fusing to produce the gluons. Fundamental properties of the “u𝑢uitalic_u-variables”, describing the “binary geometry” for surfaces appearing in the topological expansion, magically guarantee that the kinematically shifted Tr ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT amplitudes satisfy the physical properties needed to be interpreted as scaffolded gluons. These include multilinearity, gauge invariance, and factorization on tree- and loop- level gluon cuts. Our “stringy” scaffolded gluon amplitudes coincide with amplitudes in the bosonic string for extra-dimensional gluon polarizations at tree-level, but differ (and are simpler) at loop-level. We provide many checks on our proposal, including matching non-trivial leading singularities through two loops. The simple counting problem underlying the u𝑢uitalic_u variables autonomously “knows” about everything needed to convert colored scalar to gluon amplitudes, exposing a striking “discovery” of Yang-Mills amplitudes from elementary combinatorial ideas in kinematic space.",[''],[]
,[''],[]
"Dark matter constitutes 26%percent2626\%26 % of the total energy in our universe, but its nature remains elusive. Among the assortment of viable dark matter candidates, particles and fields with masses lighter than 40⁢e⁢V40eV40\mathrm{eV}40 roman_e roman_V, called ultralight dark matter, stand out as particularly promising thanks to their feasible production mechanisms, consistency with current observations, and diverse and testable predictions. In light of ongoing and forthcoming experimental and observational efforts, it is important to advance the understanding of ultralight dark matter from theoretical and phenomenological perspectives: How does it interact with itself, ordinary matter, and gravity? What are some promising ways to detect it?
In this thesis, we aim to explore the dynamics and interaction of ultralight dark matter and other astrophysically accessible hypothetical fields in a relatively model-independent way. Without making specific assumptions about their ultraviolet physics, we first demonstrate a systematic approach for constructing a classical effective field theory for both scalar and vector dark fields and discuss conditions for its validity. Then, we explore the interaction of ultralight dark fields, both gravitational and otherwise, within various contexts such as nontopological solitons, neutron stars, and gravitational waves.",[''],[]
"The subsolar mass  primordial black hole (PBH) attracts attention as robust evidence of its primordial origin against the astrophysical black hole.
Not only with themselves, PBHs can also form binaries with ordinary astrophysical objects, catching them by  gravitational wave (GW) bremsstrahlung.
We discuss the detectability of the inspiral GWs from binaries consisting of a PBH and a  white dwarf (WD) by using space-borne gravitational wave interferometers like DECIGO. The conservative assessment shows the expected event number in three years by DECIGO is 𝒪⁢(10−6)𝒪superscript106\mathcal{O}(10^{-6})caligraphic_O ( 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT ) for MPBH∼0.1⁢M⊙similar-tosubscript𝑀PBH0.1subscript𝑀direct-productM_{\textrm{PBH}}\sim 0.1M_{\odot}italic_M start_POSTSUBSCRIPT PBH end_POSTSUBSCRIPT ∼ 0.1 italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.
Possible enhancement mechanisms of WD-PBH binary formation may amplify this event rate. We discuss how large enhancement associated with WDs is required to detect WD-PBH merger events without violating the existing constraints on the PBH-PBH merger by the ground-based detector.",[''],"['Japan', 'Japan', 'Japan', 'Japan', 'Japan']"
"In this work, we compare the supermassive black hole (SMBH) and host galaxy properties of X-ray obscured and unobscured AGN. For that purpose, we use ∼35 000similar-toabsent35000\sim 35\,000∼ 35 000 X-ray detected AGN in the 4XMM-DR11 catalogue for which there are available measurements for their X-ray spectral parameters, such as the hydrogen column density, NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT, and photon index, ΓΓ\Gammaroman_Γ, from the XMM2Athena Horizon 2020 European project. We construct the spectral energy distributions (SEDs) of the sources and we calculate the host galaxy properties via SED fitting analysis, utilising the CIGALE code. We apply strict photometric requirements and quality selection criteria to include only sources with robust X-ray and SED fitting measurements. Our sample consists of 1 443 AGN. In the first part of our analysis, we use different NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT thresholds (102323{}^{23}start_FLOATSUPERSCRIPT 23 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT or 102222{}^{22}start_FLOATSUPERSCRIPT 22 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT), taking also into account the uncertainties associated with the NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT measurements, to classify these sources into obscured and unobscured (or mildly obscured). We find that obscured AGN tend to live in more massive systems (by ∼0.1similar-toabsent0.1\sim 0.1∼ 0.1 dex) that have lower SFR (by ∼0.25similar-toabsent0.25\sim 0.25∼ 0.25 dex) compared to their unobscured counterparts. However, only the difference in stellar mass, M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT, appears statistically significant (>2⁢σabsent2𝜎>2\sigma> 2 italic_σ). The results do not depend on the NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT threshold used to classify AGN. The differences in M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT and SFR are not statistically significant for luminous AGN (log⁢(LX,2−10⁢KeV/erg⁢s−1)>44logsubscriptLX210KeVergsuperscripts144\rm log\,(L_{X,2-10\,KeV}/erg\,s^{-1})>44roman_log ( roman_L start_POSTSUBSCRIPT roman_X , 2 - 10 roman_KeV end_POSTSUBSCRIPT / roman_erg roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) > 44). Our findings also show that unobscured AGN have, on average, higher specific black hole accretion rates, λs⁢B⁢H⁢A⁢Rsubscript𝜆𝑠𝐵𝐻𝐴𝑅\lambda_{sBHAR}italic_λ start_POSTSUBSCRIPT italic_s italic_B italic_H italic_A italic_R end_POSTSUBSCRIPT, compared to their obscured counterparts, a parameter which is often used as a proxy of the Eddington ratio. In the second part of our analysis, we cross-match the 1 443 X-ray AGN with the SDSS DR16 quasar catalogue to obtain information on the SMBH properties of our sources. This results in 271 type 1 AGN, at z<1.9z1.9\rm z<1.9roman_z < 1.9. Our findings show that type 1 AGN with increased NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT (>1022absentsuperscript1022>10^{22}> 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT) tend to have higher black hole masses, MB⁢H𝐵𝐻{}_{BH}start_FLOATSUBSCRIPT italic_B italic_H end_FLOATSUBSCRIPT, compared to AGN with lower NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values, at similar M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT. The MB⁢H𝐵𝐻{}_{BH}start_FLOATSUBSCRIPT italic_B italic_H end_FLOATSUBSCRIPT/M*{}_{*}start_FLOATSUBSCRIPT * end_FLOATSUBSCRIPT ratio remains consistent for NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values below 102222{}^{22}start_FLOATSUPERSCRIPT 22 end_FLOATSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT, but it exhibits signs of an increase at higher NH𝐻{}_{H}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT values. Finally, we detect a correlation between ΓΓ\Gammaroman_Γ and Eddington ratio, but only for type 1 sources with N<H1022{}_{H}<10^{22}start_FLOATSUBSCRIPT italic_H end_FLOATSUBSCRIPT < 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−22{}^{-2}start_FLOATSUPERSCRIPT - 2 end_FLOATSUPERSCRIPT.",[''],[]
"Based on the covariant underdamped and overdamped Langevin equations
with Stratonovich coupling to multiplicative noises and the associated
Fokker-Planck equations on Riemannian manifold, we present
the first law of stochastic thermodynamics on the trajectory level.
The corresponding fluctuation theorems are also
established, with the total entropy production of the Brownian particle
and the heat reservoir playing the role of dissipation function.","['Langevin equation,', 'Fokker-Planck equation, fluctuation theorem,', 'Riemannian manifold']","['China', 'China', 'China']"
"The usual gravitational wave memory effect can be understood as a change in the separation of two initially comoving observers due to a burst of gravitational waves.
Over the past few decades, a wide variety of other, “persistent” observables which measure permanent effects on idealized detectors have been introduced, each probing distinct physical effects.
These observables can be defined in (regions of) any spacetime where there exists a notion of radiation, such as perturbation theory off of a fixed background, nonlinear plane wave spacetimes, or asymptotically flat spacetimes.
Many of the persistent observables defined in the literature have been considered only in asymptotically flat spacetimes, and the perturbative nature of such calculations has occasionally obscured deeper relationships between these observables that hold more generally.
The goal of this paper is to show how these more general results arise, and to do so we focus on two observables related to the separation between two, potentially accelerated observers.
The first is the curve deviation, which is a natural generalization of the displacement memory, and also contains what this paper proposes to call drift memory (previously called “subleading displacement memory”) and ballistic memory.
The second is a relative proper time shift that arises between the two observers, either at second order in their initial separation and relative velocity, or in the presence of relative acceleration.
The results of this paper are, where appropriate, entirely non-perturbative in the curvature of spacetime, and so could be used beyond leading order in asymptotically flat spacetimes.",[''],['Kingdom']
,[''],[]
"Context:The existence of low-mass giants with large amounts of lithium (Li) in their surfaces has challenged stellar evolution for decades. One of the possibilities usually discussed in the literature to explain these Li-rich giants involves the interaction with a close binary companion, a scenario that predicts that, when compared against their non-enriched counterparts, Li-rich giants should preferentially be found as part of binary systems.
Aims:We aim to assemble the largest possible sample of low-mass giants with well-measured Li abundances, to determine with high statistical significance the close binary fractions of Li-rich and Li-normal giants, and thus test the binary interaction scenario for the emergence of Li-rich giants.
Methods:We develop a method that uses radial velocities (RVs) at three different epochs to quantify the degree of RV variability, which we use as a proxy for the presence of a close binary companion. The method is tested and calibrated against samples of known RV standard stars and known spectroscopic binaries. We then assemble a sample of 1418 giants with available RVs from RAVE, GALAH, and Gaia, as well as stellar parameters and Li abundances from GALAH, to which we apply our variability classification. We can determine an evolutionary state for 1030 of these giants. We also compare the results of our RV variability analysis with binarity indicators from the Gaia mission.
Results:When applying our methodology to the control samples, we find that the accuracy of the classification is controlled by the precision of the RVs used in the analysis. For the set of RVs available for the giants, this accuracy is 80-85%. Consistent with seismic studies, the resulting sample of giants contains a fraction of Li-rich objects in the red clump (RC) that is twice as large as that in the first ascent red giant branch (RGB). Among RC giants, the fractions of Li-rich objects with high RV variability and with no RV variability are the same as those for Li-normal objects, but we find some evidence that these fractions may be different for giants in the first-ascent RGB. Analysis of binary indicators in Gaia DR3 shows a smaller fraction of binary giants than our criteria, but no relation can be seen between Li enrichment and binarity either.
Conclusions:Our RV variability analysis indicates that there is no preference for Li-rich giants in the RC to be part of binary systems, thus arguing against a binary interaction scenario for the genesis of the bulk of Li-rich giants at that evolutionary stage. On the other hand, Li-rich giants in the RGB appear to have a small but measurable preference for having close companions, something that deserves further scrutiny with more and better data. Additional measurements of the RVs of these giants at higher RV precision would greatly help in confirming and more robustly quantifying these results.","['Key', 'Words.: \nstars: abundances – stars: evolution – binaries: general']",[]
"Higher-order topological insulators in two spatial dimensions display fractional corner charges. While fractional charges in one dimension are known to be captured by a many-body bulk invariant, computed by the Resta formula, a many-body bulk invariant for higher-order topology and the corresponding fractional corner charges remains elusive despite several attempts. Inspired by recent work by Tada and Oshikawa, we propose a well-defined many-body bulk invariant for Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT symmetric higher-order topological insulators, which is valid for both non-interacting and interacting systems. Instead of relating them to the bulk quadrupole moment as was previously done, we show that in the presence of Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT rotational symmetry, this bulk invariant can be directly identified with quantized fractional corner charges. In particular, we prove that the corner charge is quantized as e/n𝑒𝑛e/nitalic_e / italic_n with Cnsubscript𝐶𝑛C_{n}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT symmetry, leading to a ℤnsubscriptℤ𝑛\mathbb{Z}_{n}blackboard_Z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT classification for higher-order topological insulators in two dimensions.",[''],"['USA', 'USA', 'USA']"
"The physical sciences require models tailored to specific nuances of different dynamics. In this work, we study outcome predictions in nuclear fusion tokamaks, where a major challenge are disruptions, or the loss of plasma stability with damaging implications for the tokamak. Although disruptions are difficult to model using physical simulations, machine learning (ML) models have shown promise in predicting these phenomena. Here, we first study several variations on masked autoregressive transformers, achieving an average of 5% increase in Area Under the Receiving Operating Characteristic metric above existing methods. We then compare transformer models to limited context neural networks in order to shed light on the “memory” of plasma effected by tokamaks controls. With these model comparisons, we argue for the persistence of a memory throughout the plasma in the context of tokamaks that our model exploits.",[''],[]
"With the rapid evolution of Natural Language Processing (NLP), Large Language Models (LLMs) like ChatGPT have emerged as powerful tools capable of transforming various sectors. Their vast knowledge base and dynamic interaction capabilities represent significant potential in improving education by operating as a personalized assistant. However, the possibility of generating incorrect, biased, or unhelpful answers are a key challenge to resolve when deploying LLMs in an education context. This work introduces an innovative architecture that combines the strengths of ChatGPT with a traditional information retrieval based chatbot framework to offer enhanced student support in higher education. Our empirical evaluations underscore the high promise of this approach.",[''],"['wskksw@mail.ubc.ca', 'ramosjasonwork@gmail.com', 'ramon.lawrence@ubc.ca']"
"With this paper, we begin a series of studies of extremal problems for estimating distributions of
martingale transforms of bounded martingales. The Bellman functions corresponding to such problems
are pointwise minimal diagonally concave functions on a horizontal strip, satisfying certain given boundary conditions. We describe the basic structures that arise when constructing such functions and present a solution in the case of asymmetric boundary conditions and a sufficiently small width of the strip.","['Key words and phrases: ', 'Bellman function, martingale transform, diagonally concave function']",[]
"The late time acceleration of the Universe has challenged contemporary cosmology since its discovery. General Relativity explains this phenomenon by introducing the cosmological constant, named the standard cosmological model (ΛΛ\Lambdaroman_ΛCDM). However, the cosmological constant solution has several drawbacks that have led cosmologists to explore and propose alternative models to explain the late time acceleration of the Universe. These alternatives span from models of a dynamical dark fluid, known as “dark energy”, to models of large-scale modifications of the gravitational interaction, known as “modified gravity”.
The first chapter briefly introduces background formulation, fundamental gravity theories, and cosmological observations. In chapters LABEL:Chapter2-LABEL:Chapter5, we investigate the dark sector of the Universe in modified gravity using Markov Chain Monte Carlo (MCMC) methods and large datasets derived from measurements of the background expansion of the Universe.
Chapter LABEL:Chapter2 discusses the acceleration of the Universe by incorporating bulk viscosity in f⁢(R,𝒯)𝑓𝑅𝒯f(R,\mathcal{T})italic_f ( italic_R , caligraphic_T ) gravity. Incorporating bulk viscosity into the f⁢(R,𝒯)𝑓𝑅𝒯f(R,\mathcal{T})italic_f ( italic_R , caligraphic_T ) gravity model violated the strong energy condition describing the accelerated expansion. In chapters LABEL:Chapter3 and LABEL:Chapter4, we examine the theoretical viability of f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity. We investigate f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity using the matter-dominated Universe and the effective equation of state. To achieve this, we constrain the two models with the Hubble dataset, Union 2.1 and Pantheon supernovae datasets, and the BAO dataset with the analyses of numerous cosmological parameters. The study indicates whether the f⁢(Q,𝒯)𝑓𝑄𝒯f(Q,\mathcal{T})italic_f ( italic_Q , caligraphic_T ) gravity models are supported by the observational data in comparison to the ΛΛ\Lambdaroman_ΛCDM scenario. The reconstructed models of dark energy exhibit accelerating behavior and deviate from the ΛΛ\Lambdaroman_ΛCDM at certain redshifts.
In chapter LABEL:Chapter5, we analyze the exponential f⁢(Q)𝑓𝑄f(Q)italic_f ( italic_Q ) gravity to examine the formation of structures and the viable cosmology. The study aims to reproduce feasible results within f⁢(Q)𝑓𝑄f(Q)italic_f ( italic_Q ) gravity using MCMC constraints and N-body + SPH simulations. We deduce CDM+baryons over density/temperature/mean molecular weight fields, matter power spectrum, bispectrum, two-point correlation function, and halo mass function. Therefore, the outcomes for small and large simulation boxes are appropriately compared. Chapter LABEL:Chapter6 finishes with concluding remarks and a discussion of the thesis with an eye toward the future.",[''],[]
"Research on algorithmic recourse typically considers how an individual can reasonably change an unfavorable automated decision when interacting with a fixed decision-making system.
This paper focuses instead on the online setting, where system parameters are updated dynamically according to interactions with data subjects.
Beyond the typical individual-level recourse, the online setting opens up new ways for groups to shape system decisions by leveraging the parameter update rule.
We show empirically that recourse can be improved when users coordinate by jointly computing their feature perturbations, underscoring the importance of collective action in mitigating adverse automated decisions.","['Recourse,', 'Collective', 'Recourse,', 'User', 'Agency']",[]
,[''],[]
"Recent work on object-centric world models aim to factorize representations in terms of objects in a completely unsupervised or self-supervised manner. Such world models are hypothesized to be a key component to address the generalization problem. While self-supervision has shown improved performance however, OOD generalization has not been systematically and explicitly tested. In this paper, we conduct an extensive study on the generalization properties of contrastive world model. We systematically test the model under a number of different OOD generalization scenarios such as extrapolation to new object attributes, introducing new conjunctions or new attributes. Our experiments show that the contrastive world model fails to generalize under the different OOD tests and the drop in performance depends on the extent to which the samples are OOD. When visualizing the transition updates and convolutional feature maps, we observe that any changes in object attributes (such as previously unseen colors, shapes, or conjunctions of color and shape) breaks down the factorization of object representations. Overall, our work highlights the importance of object-centric representations for generalization and current models are limited in their capacity to learn such representations required for human-level generalization.",[''],[]
,[''],[]
"We examine the transmission of quantum particles (phonons, electrons, and photons) across interfaces, identifying universal patterns in diverse physical scenarios. Starting with classical wave equations, we quantize them and derive kinetic equations. Those are matching conditions for the distribution functions of particles at the interface. We note the time irreversibility of the derived kinetic equations — an essential feature for accurately describing irreversible processes like heat transport. We identify the juncture in our derivation where the time symmetry of wave equations is disrupted, it is the assumption of the non-coherence of incident waves. Consequently, we infer that non-coherent transmission through the interface exhibits time irreversibility. We propose an experiment to validate this hypothesis.",[''],['Argentina']
"Observatories need to measure and evaluate the scientific output and overall impact of their facilities. An observatory bibliography consists of the papers published using that observatory’s data, typically gathered by searching the major journals for relevant keywords. Recently, the volume of literature and methods by which the publications pool is evaluated have increased. Efficient and standardized procedures are necessary to assign meaningful metadata, enable user-friendly retrieval, and provide the opportunity to derive reports, statistics, and visualizations to impart a deeper understanding of the research output.

In 2021, a group of observatory bibliographers from around the world convened online to continue the discussions presented in Lagerstrom (2015). We worked to extract general guidelines from our experiences, techniques, and lessons learnt. This paper explores the development, application, and current status of telescope bibliographies and future trends. The paper briefly describes the methodologies employed in constructing the databases, along with the various bibliometric techniques used to analyze and interpret them. We explain reasons for non-standardization and why it is essential for each observatory to identify metadata and metrics that are meaningful for them; caution the (over-)use of comparisons among various facilities that are, ultimately, not comparable through bibliometrics; and highlight the benefits of telescope bibliographies, both for researchers within the astronomical community and for stakeholders beyond the specific observatories. There is tremendous diversity in the ways bibliographers track publications and maintain databases, due to parameters such as resources (personnel, time, budget, IT capabilities), type of observatory, historical practices, and reporting requirements to funders and outside agencies. However, there are also common sets of Best Practices. This paper describes some of our results from our collaborative discussions.","['Astronomy', 'Databases (83) —', 'Astronomical reference materials (90) —', 'Observatories (1147) —', 'Telescopes (1689)']","['USA', 'Spain', 'Germany', 'USA', 'USA', 'Japan', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"We introduce a physics-informed neural network (PINN) method to study thermoacoustic interactions leading to combustion instability in combustors. Specifically, we employ a PINN to investigate thermoacoustic interactions in a bluff body anchored flame combustor, representative of ramjet and industrial combustors. Vortex shedding and acoustic oscillations appear in such combustors, and their interactions lead to the phenomenon of vortex-acoustic lock-in. Acoustic pressure fluctuations at three locations and the total flame heat release rate serve as the measured data. The coupled parameterized model is based on the acoustic equations and the van der Pol oscillator for vortex shedding. The PINN was applied in the combustor, where the measurements suitable for a future machine learning application were not anticipated at the time of the experiments, as is the case in the vast majority of available data in the literature. We demonstrate a good performance of PINN in generating the acoustic field (pressure and velocity fluctuations) in the entire spatiotemporal domain, along with estimating all the parameters of the model. Therefore, this PINN-based model can potentially serve as an effective tool in improving existing combustors or designing new thermoacoustically stable and structurally efficient combustors.",[''],[]
"A critical function of an organization is to foster the level of integration (coordination and cooperation) necessary to achieve its objectives. The need to coordinate and motivation to cooperate emerges from the myriad dependencies between an organization’s members and their work. Therefore, to reason about solutions to coordination and cooperation problems requires a robust representation that includes the underlying dependencies. We find that such a representation remains missing from formal organizational models, and we leverage semantics to bridge this gap. Drawing on well-established organizational research and our extensive fieldwork with one of North America’s largest municipalities, (1) we introduce an ontology, formalized in first-order logic, that operationalizes concepts like outcome, reward, and epistemic dependence, and their links to potential integration risks; and (2) present real-world applications of this ontology to analyze and support integration in complex government infrastructure projects. Our ontology is implemented and validated in both Z3 and OWL. Key features of our model include inferable dependencies, explainable coordination and cooperation risks, and actionable insights on how dependency structures within an organization can be altered to mitigate the risks. Conceptualizing real-world challenges like incentive misalignment, free-riding, and subgoal optimization in terms of dependency structures, our semantics-based approach represents a novel method for modelling and enhancing coordination and cooperation. Integrated within a decision-support system, our model may serve as an impactful aid for organizational design and effectiveness. More broadly, our approach underscores the transformative potential of semantics in deriving tangible, real-world value from existing organization theory.","['Index', 'Terms: ', 'Cooperation,', 'Coordination,', 'Dependence,', 'Organization,', 'Ontology,', 'OWL,', 'Z3']",['msf@eil.utoronto.ca']
"Analyzing the geometry of correlation sets constrained by general causal structures is of paramount importance for foundational and quantum technology research.
Addressing this task is generally challenging, prompting the development of diverse theoretical techniques for distinct scenarios. Recently, novel hybrid scenarios combining different causal assumptions within different parts of the causal structure have emerged.
In this work, we extend a graph theoretical technique to explore classical, quantum, and no-signaling distributions in hybrid scenarios,
where classical causal constraints and weaker no-signaling ones are used for different nodes of the causal structure.
By mapping such causal relationships into an undirected graph
we are able to characterize the associated sets of compatible distributions and analyze their relationships.
In particular we show how with our method we can construct minimal Bell-like inequalities capable of simultaneously distinguishing classical, quantum, and no-signaling behaviors, and efficiently estimate the corresponding bounds.
The demonstrated method will represent a powerful tool to study quantum networks and for applications in quantum information tasks.",[''],"['Italy', 'Italy', 'Brazil', 'Italy', 'Australia', 'Italy', 'Italy', 'Brazil', 'Brazil']"
,[''],[]
,[''],[]
,[''],[]
"Statistical Shape Modeling (SSM) is a quantitative method for analyzing morphological variations in anatomical structures. These analyses often necessitate building models on targeted anatomical regions of interest to focus on specific morphological features.
We propose an extension to particle-based shape modeling (PSM), a widely used SSM framework, to allow shape modeling to arbitrary regions of interest. Existing methods to define regions of interest are computationally expensive and have topological limitations. To address these shortcomings, we use mesh fields to define free-form constraints, which allow for delimiting arbitrary regions of interest on shape surfaces. Furthermore, we add a quadratic penalty method to the model optimization to enable computationally efficient enforcement of any combination of cutting-plane and free-form constraints.
We demonstrate the effectiveness of this method on a challenging synthetic dataset and two medical datasets.",[''],[]
"The description of the T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG deformation in terms of two-dimensional gravity is analyzed from the Hamiltonian point of view, in a manner analogous to the ADM description of general relativity. We find that the Hamiltonian constraints of the theory imply relations between target-space momentum at finite volume which are equivalent to the T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG finite volume flow equations. This fully-quantum T⁢T¯𝑇¯𝑇T\bar{T}italic_T over¯ start_ARG italic_T end_ARG result emerges already at the classical level within the gravitational theory. We exemplify the analysis for the case when the undeformed sector is a collection of D−2𝐷2D-2italic_D - 2 free massless scalars, where it is shown that –somewhat non-trivially– the target-space two-dimensional Poincaré symmetry is extended to D𝐷Ditalic_D dimensions. The connection between canonical quantization of this constrained Hamiltonian system and previous path integral quantizations is also discussed. We extend our analysis to the “gravitational” description of J⁢T¯𝐽¯𝑇J\bar{T}italic_J over¯ start_ARG italic_T end_ARG-type deformations, where it is found that the flow equations obtained involve deformations that twist the spatial boundary conditions.",[''],['Uruguay.']
"In this work we are motivated by factorization
of bosonic quantum dynamics and
we study the corresponding Lie algebras,
which can potentially be infinite dimensional.
To characterize such factorization,
we identify conditions for these Lie algebras
to be finite dimensional.
We consider cases where each free Hamiltonian term
is itself an element of the generated Lie algebra.
In our approach, we develop new tools to systematically divide skew-hermitian bosonic operators
into appropriate subspaces, and construct specific sequences of
skew-hermitian operators that are used to gauge the dimensionality of the Lie algebras themselves.
The significance of our result relies on conditions that constrain only the
independently controlled generators
in a particular Hamiltonian, thereby providing an effective algorithm for verifying the finiteness of the generated
Lie algebra.
In addition, our results are tightly connected to
mathematical work where the polynomials of creation and annihilation operators
are known as the Weyl algebra.
Our work paves the way for better understanding
factorization of bosonic dynamics relevant to quantum control and quantum technology.",[''],"['Germany', 'Germany', 'Malta', 'Germany']"
"Beineke, Harary and Ringel discovered a formula for the minimum genus of a
torus in which the n𝑛nitalic_n-dimensional hypercube graph can be embedded.
We give a new proof of the formula by building this surface
as a union of certain faces in the hypercube’s 2-skeleton. For odd dimension n𝑛nitalic_n, the entire 2-skeleton decomposes into
(n−1)/2𝑛12(n-1)/2( italic_n - 1 ) / 2 copies of the surface, and the intersection of any two copies is
the hypercube graph.",[''],[]
"We apply the shifted composition rule—an information-theoretic principle introduced in our earlier work [scr1]—to establish shift Harnack inequalities for the Langevin diffusion.
We obtain sharp constants for these inequalities for the first time, allowing us to investigate their relationship with other properties of the diffusion.
Namely, we show that they are equivalent to a sharp “local gradient-entropy” bound, and that they imply curvature upper bounds in a compelling reflection of the Bakry–Émery theory of curvature lower bounds.
Finally, we show that the local gradient-entropy inequality implies optimal concentration of the score, a.k.a. the logarithmic gradient of the density.",[''],[]
"We present a general framework for modeling materials using deep neural networks. Material represented by multidimensional characteristics (that mimic measurements) is used to train the neural autoencoder model in an unsupervised manner. The encoder is trying to predict the material parameters of a theoretical model, which is then used in a decoder part. The decoder, using the predicted parameters, reconstructs the input characteristics. The neural model is trained to capture a synthetically generated set of characteristics that can cover a broad range of material behaviors, leading to a model that can generalize on the underlying physics rather than just optimize the model parameters for a single measurement. After setting up the model we prove its usefulness in the complex problem of modeling magnetic materials in the frequency and current (out-of-linear range) domains simultaneously.","['Index', 'Terms: \n\nmaterials modeling, deep neural networks, synthetic data']","['Poland', 'Poland', 'Poland']"
,[''],[]
,[''],[]
"This work proposes a Reynolds number scaling of the required number of grid points to perform wall-modeled LES of turbulent flows encountering separation off a solid surface. Based on comparisons between the various time scales in a non-equilibrium turbulent boundary layer (due to the action of an external pressure gradient), a simple definition of the near-wall “under-equilibrium"" and “out-of-equilibrium"" scales is put forward (where “under-equilibrium"" scales are governed by a quasi-balance between the viscous and the pressure gradient terms). It is shown that this “under-equilibrium"" characteristic length scale varies with Reynolds number as lp∼R⁢e−2/3similar-tosubscript𝑙𝑝𝑅superscript𝑒23l_{p}\sim Re^{-2/3}italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ∼ italic_R italic_e start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT. The same scaling is obtained from a simplified Green’s function solution of the Poisson equation in the vicinity of the separation point. A-priori analysis is used to demonstrate that the resolution required to reasonably predict the wall-shear stress (for example, errors lower than approximately 10−15%10percent1510-15\%10 - 15 % in the entire domain) in several nonequilibrium flows is at least 𝒪⁢(10)𝒪10\mathcal{O}(10)caligraphic_O ( 10 )lpsubscript𝑙𝑝l_{p}italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT irrespective of the Reynolds number and the Clauser parameter. Further, a series of a-posteriori validation studies are performed to determine the accuracy of this scaling including the flow over the Boeing speed bump, Song-Eaton diffuser, Notre-Dame Ramp, and the backward-facing step. The results suggest that for these flows, scaling the computational grids (ΔΔ\Deltaroman_Δ) such that Δ/lpΔsubscript𝑙𝑝\Delta/l_{p}roman_Δ / italic_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is independent of the Reynolds number results in accurate predictions of flow separation at the same “nominal"" grid resolution across different Reynolds numbers. Finally, it is suggested that atleast locally, in the vicinity of the separation and reattachment points, the grid-point requirements for wall-modeled large eddy simulations may scale as R⁢e4/3𝑅superscript𝑒43Re^{4/3}italic_R italic_e start_POSTSUPERSCRIPT 4 / 3 end_POSTSUPERSCRIPT, which is more restrictive than the previously proposed flat-plate boundary layer-based estimates (∼R⁢e1similar-toabsent𝑅superscript𝑒1\sim Re^{1}∼ italic_R italic_e start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT) of Choi and Moin, Phys. Fluids, 2012 and Yang and Griffin, Phys. Fluids, 2021.",[''],"['University', 'Inc.', 'University']"
"Seasonal influenza causes on average 425,000 hospitalizations and 32,000 deaths per year in the United States.
Forecasts of influenza-like illness (ILI)—a surrogate for the proportion of patients infected with influenza—support public health decision making.
The goal of an ensemble forecast of ILI is to increase accuracy and calibration compared to individual forecasts and to provide a single, cohesive prediction of future influenza.
However, an ensemble may be composed of models that produce similar forecasts, causing issues with ensemble forecast performance and non-identifiability.
To improve upon the above issues we propose a novel Cluster-Aggregate-Pool or ‘CAP’ ensemble algorithm that first clusters together individual forecasts, aggregates individual models that belong to the same cluster into a single forecast (called a cluster forecast), and then pools together cluster forecasts via a linear pool.
When compared to a non-CAP approach, we find that a CAP ensemble improves calibration by approximately 10% while maintaining similar accuracy to non-CAP alternatives.
In addition, our CAP algorithm (i) generalizes past ensemble work associated with influenza forecasting and introduces a framework for future ensemble work, (ii) automatically accounts for missing forecasts from individual models, (iii) allows public health officials to participate in the ensemble by assigning individual models to clusters, and (iv) provide an additional signal about when peak influenza may be near.",[''],"['America', 'America', 'America', 'America']"
"Scientists are adopting new approaches to scale up their activities and goals. Progress in neurotechnologies, artificial intelligence, automation, and tools for collaboration promises new bursts of discoveries. However, compared to other disciplines and the industry, neuroscience laboratories have been slow to adopt key technologies to support collaboration, reproducibility, and automation. Drawing on progress in other fields, we define a roadmap for implementing automated research workflows for diverse research teams. We propose establishing a five-level capability maturity model for operations in neuroscience research. Achieving higher levels of operational maturity requires new technology-enabled methodologies, which we describe as “SciOps”. The maturity model provides guidelines for evaluating and upgrading operations in multidisciplinary neuroscience teams.",[''],[]
"Motivated by the question of how biological systems maintain homeostasis in changing environments,
Shinar and Feinberg introduced in 2010 the concept of absolute concentration robustness (ACR).
A biochemical system exhibits ACR in some species if the steady-state value of that species does not depend on initial conditions. Thus, a system
with ACR can maintain a constant level of one species even as the environment changes. Despite a great deal of interest
in ACR in recent years, the following basic question remains open: How can we determine quickly whether a given
biochemical system has ACR? Although various approaches to this problem have been proposed, we show that
they are incomplete. Accordingly, we present new methods for deciding ACR, which harness computational algebra. We
illustrate our results on several biochemical signaling networks.
MSC Codes:
37N25, 92E20, 12D10, 37C25, 65H14, 14Q20",[''],[]
"We prove that if A𝐴Aitalic_A is a computable Hopfian finitely presented structure, then A𝐴Aitalic_A has a computable d𝑑ditalic_d-Σ2subscriptΣ2\Sigma_{2}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Scott sentence if and only if the weak Whitehead problem for A𝐴Aitalic_A is decidable.
We use this to infer that every hyperbolic group as well as any polycyclic-by-finite group has a computable d𝑑ditalic_d-Σ2subscriptΣ2\Sigma_{2}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Scott sentence, thus covering two main classes of finitely presented groups. Our proof also implies that every weakly Hopfian finitely presented group is strongly defined by its ∃+superscript\exists^{+}∃ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT-types, a question which arose in a different context.",[''],[]
"Re-identifying participants in ultra-distance running competitions can be daunting due to the extensive distances and constantly changing terrain. To overcome these challenges, computer vision techniques have been developed to analyze runners’ faces, numbers on their bibs, and clothing. However, our study presents a novel gait-based approach for runners’ re-identification (re-ID) by leveraging various pre-trained human action recognition (HAR) models and loss functions. Our results show that this approach provides promising results for re-identifying runners in ultra-distance competitions. Furthermore, we investigate the significance of distinct human body movements when athletes are approaching their endurance limits and their potential impact on re-ID accuracy. Our study examines how the recognition of a runner’s gait is affected by a competition’s critical point (CP), defined as a moment of severe fatigue and the point where the finish line comes into view, just a few kilometers away from this location. We aim to determine how this CP can improve the accuracy of athlete re-ID. Our experimental results demonstrate that gait recognition can be significantly enhanced (up to a 9% increase in mAP) as athletes approach this point. This highlights the potential of utilizing gait recognition in real-world scenarios, such as ultra-distance competitions or long-duration surveillance tasks.",[''],[]
,[''],[]
"Large ensembles of stochastically evolving interacting particles
describe phenomena in diverse fields including statistical physics, neuroscience, biology, and engineering.
In such systems, the infinitesimal evolution of each particle depends only on its own state (or history)
and the states (or histories) of neighboring particles with respect to
an underlying, possibly random, interaction graph. While these high-dimensional processes are typically too
complex to be amenable to exact analysis, their dynamics are quite well understood when the interaction graph is
the complete graph. In this case, classical theorems show that in the limit as the number of particles goes to infinity, the dynamics of the empirical measure and the law of a typical particle coincide and can be characterized in terms of a much more tractable dynamical system of reduced dimension called the mean-field limit. In contrast, until recently not much was known about corresponding convergence results in the complementary case when the interaction graph is sparse (i.e., with uniformly bounded average degree). This article provides a brief survey of classical
work and then describes recent progress on the sparse regime that relies
on a combination of techniques from random graph theory, Markov random
fields, and stochastic analysis. The article concludes by discussing ramifications
for applications and posing several open problems.",[''],[]
"The Gouy phase is essential for accurately describing various wave phenomena, ranging from classical electromagnetic waves to matter waves and quantum optics. In this work, we employ phase-space methods based on the cross-Wigner transformation to analyze spatial and temporal interference in the evolution of matter waves characterized initially by a correlated Gaussian wave packet.
First, we consider the cross-Wigner of the initial function with its free evolution, and second for the evolution through a double-slit arrangement. Different from the wave function which acquires a global Gouy phase, we find that the cross-Wigner acquires a Gouy phase difference due to different evolution times. The results suggest that temporal like-Gouy phases are important for an accurate description of temporal interference.
Furthermore, we propose a technique based on the Wigner function to reconstruct the cross-Wigner from the spatial intensity interference term in a double-slit experiment with matter waves.",[''],"['Brazil', 'Brazil', 'Poland', 'Brazil', 'Brazil']"
"For strongly connected, pure n𝑛nitalic_n-dimensional regular CW-complexes, we show that
evenness (each (n−1)𝑛1(n{-}1)( italic_n - 1 )-cell is contained in an even number of n𝑛nitalic_n-cells)
is equivalent to generalizations of both cycle decomposition and traversability.",[''],[]
"This paper addresses the “curse of dimensionality” in the loss valuation of credit risk models. A dimension reduction methodology based on the Bayesian filter and smoother is proposed. This methodology is designed to achieve a fast and accurate loss valuation algorithm in credit risk modelling, but it can also be extended to valuation models of other risk types. The proposed methodology is generic, robust and can easily be implemented. Moreover, the accuracy of the proposed methodology in the estimation of expected loss and value-at-risk is illustrated by numerical experiments. The results suggest that, compared to the currently most used PCA approach, the proposed methodology provides more accurate estimation of expected loss and value-at-risk of a loss distribution. 
keywords: Bayesian filter, credit risk, loss valuation
2020 Mathematics Subject Classification: 62P05, 91G40",[''],"['Netherlands', 'Netherlands', 'Netherlands', 'Netherlands']"
"This paper proposes a computational model for policy administration.
As an organization evolves, new users and resources are gradually
placed under the mediation of the access control model. Each time
such new entities are added, the policy administrator must
deliberate on how the access control policy shall be revised to
reflect the new reality. A well-designed access control model must
anticipate such changes so that the administration cost does not
become prohibitive when the organization scales up. Unfortunately,
past Access Control research does not offer a formal way to quantify
the cost of policy administration. In this work, we propose to
model ongoing policy administration in an active learning
framework. Administration cost can be quantified in terms of query
complexity. We demonstrate the utility of this approach by applying
it to the evolution of protection domains. We also modelled
different policy administration strategies in our framework. This
allowed us to formally demonstrate that domain-based policies have a
cost advantage over access control matrices because of the use of
heuristic reasoning when the policy evolves. To the best of our
knowledge, this is the first work to employ an active learning
framework to study the cost of policy deliberation and demonstrate
the cost advantage of heuristic policy administration.","['Access control, policy administration, active learning,\nquery complexity, heuristics']","['CalgaryCalgaryCanada', 'CalgaryCalgaryCanada']"
"Rollback recovery strategies are well-known in
concurrent and distributed systems. In this context,
recovering from unexpected failures is even more
relevant given the non-deterministic nature of
execution, which means that it is practically
impossible to foresee all possible process interactions.

In this work, we consider a message-passing concurrent
programming language where processes interact through
message sending and receiving, but shared memory
is not allowed. In this context, we design a
checkpoint-based
rollback recovery strategy which does not
need a central coordination.
For this purpose, we extend the language
with three new operators: 𝖼𝗁𝖾𝖼𝗄𝖼𝗁𝖾𝖼𝗄\mathsf{check}sansserif_check,
𝖼𝗈𝗆𝗆𝗂𝗍𝖼𝗈𝗆𝗆𝗂𝗍\mathsf{commit}sansserif_commit, and 𝗋𝗈𝗅𝗅𝖻𝖺𝖼𝗄𝗋𝗈𝗅𝗅𝖻𝖺𝖼𝗄\mathsf{rollback}sansserif_rollback.
Furthermore, our approach
is purely asynchronous, which is an essential
ingredient to develop a source-to-source program
instrumentation implementing a rollback recovery
strategy.","['message-passing concurrency, rollback recovery, checkpointing']",['S/NValenciaSpain46022']
This template helps you to create a properly formatted LATEX manuscript.,[''],[]
"For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. We study the problem of determining a quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration as a generalization of Descartes’ rule of signs. We exploit the combinatorial properties of our definition for eigenvalue configuration to reduce a two-polynomial root counting problem into several single-polynomial root counting problems of symmetric polynomials. We then leverage the fundamental theorem of symmetric polynomials to derive a final quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration.",[''],"['USA', 'USA', 'Spain']"
,[''],[]
"Disformal transformations of Friedmann–Lemaître–Robertson–Walker and
Bianchi geometries are analyzed in the context of scalar–tensor gravity.
Novel aspects discussed are the 3+1313+13 + 1 splitting, the effective fluid
equivalent of the gravitational scalar, Bianchi models, stealth solutions
and de Sitter solutions with non–constant scalar field (which are
signatures of scalar–tensor gravity). Both pure disformal transformations
and more general ones are discussed.",[''],"['1Z7', 'Germany', '1Z7']"
"We investigate the role of the spectral dimension dssubscript𝑑𝑠d_{s}italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT in determining the universality of phase transitions on a complex network. Due to its structural heterogeneity, a complex network generally acts as a disordered system. Specifically, we study the synchronization and entrainment transitions in the nonequilibrium dynamics of the Kuramoto model and the phase transition of the equilibrium dynamics of the classical X⁢Y𝑋𝑌XYitalic_X italic_Y model, thereby covering a broad spectrum from nonlinear dynamics to statistical and condensed matter physics. Using linear theory, we obtain a general relationship between the dynamics occurring on the network and the underlying network properties. This yields the lower critical spectral dimension of the phase synchronization and entrainment transitions in the Kuramoto model as ds=4subscript𝑑𝑠4d_{s}=4italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 4 and ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2 respectively, whereas for the phase transition in the X⁢Y𝑋𝑌XYitalic_X italic_Y model it is ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2. To test our theoretical hypotheses, we employ a network where any two nodes on the network are connected with a probability proportional to a power law of the distance between the nodes; this realizes any desired ds∈[1,∞)subscript𝑑𝑠1d_{s}\in[1,\infty)italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ∈ [ 1 , ∞ ). Our detailed numerical study agrees well with the prediction of linear theory for the phase synchronization transition in the Kuramoto model. However, it shows a clear entrainment transition in the Kuramoto model and phase transition in the X⁢Y𝑋𝑌XYitalic_X italic_Y model at ds≳3greater-than-or-equivalent-tosubscript𝑑𝑠3d_{s}\gtrsim 3italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≳ 3, not ds=2subscript𝑑𝑠2d_{s}=2italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = 2 as predicted by linear theory. Our study indicates that network disorder in the region 2≤ds≲32subscript𝑑𝑠less-than-or-similar-to32\leq d_{s}\lesssim 32 ≤ italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≲ 3 seems to be relevant and have a profound effect on the dynamics.",[''],"['Germany', 'Switzerland']"
"The rapid growth of the ride-hailing industry has revolutionized urban transportation worldwide. Despite its benefits, equity concerns arise as underserved communities face limited accessibility to affordable ride-hailing services. A key issue in this context is the vehicle rebalancing problem, where idle vehicles are moved to areas with anticipated demand. Without equitable approaches in demand forecasting and rebalancing strategies, these practices can further deepen existing inequities. In the realm of ride-hailing, three main facets of fairness are recognized: algorithmic fairness, fairness to drivers, and fairness to riders. This paper focuses on enhancing both algorithmic and rider fairness through a novel vehicle rebalancing method. We introduce an approach that combines a Socio-Aware Spatial-Temporal Graph Convolutional Network (SA-STGCN) for refined demand prediction and a fairness-integrated Matching-Integrated Vehicle Rebalancing (MIVR) model for subsequent vehicle rebalancing. Our methodology is designed to reduce prediction discrepancies and ensure equitable service provision across diverse regions. The effectiveness of our system is evaluated using simulations based on real-world ride-hailing data. The results suggest that our proposed method enhances both accuracy and fairness in forecasting ride-hailing demand, ultimately resulting in more equitable vehicle rebalancing in subsequent operations. Specifically, the algorithm developed in this study effectively reduces the standard deviation and average customer wait times by 6.48% and 0.49%, respectively. This achievement signifies a beneficial outcome for ride-hailing platforms, striking a balance between operational efficiency and fairness.",[''],[]
"The recent progress in language-based open-vocabulary object detection can be largely attributed to finding better ways of leveraging large-scale data with free-form text annotations. Training such models with a discriminative objective function has proven successful, but requires good positive and negative samples. However, the free-form nature and the open vocabulary of object descriptions make the space of negatives extremely large. Prior works randomly sample negatives or use rule-based techniques to build them. In contrast, we propose to leverage the vast knowledge built into modern generative models to automatically build negatives that are more relevant to the original data. Specifically, we use large-language-models to generate negative text descriptions, and text-to-image diffusion models to also generate corresponding negative images. Our experimental analysis confirms the relevance of the generated negative data, and its use in language-based detectors improves performance on two complex benchmarks.",[''],[]
"This paper presents a novel Automatic Essay Scoring (AES) algorithm tailored for the Portuguese-language essays of Brazil’s Exame Nacional do Ensino Médio (ENEM), addressing the challenges in traditional human grading systems. This approach leverages advanced deep learning techniques to align closely with human grading criteria, targeting efficiency and scalability in evaluating large volumes of student essays. This research not only responds to the logistical and financial constraints of manual grading in Brazilian educational assessments but also promises to enhance fairness and consistency in scoring, marking a significant step forward in the application of AES in large-scale academic settings.",[''],[]
,[''],[]
This paper presents a regularized recursive identification algorithm with simultaneous on-line estimation of both the model parameters and the algorithms hyperparameters. A new kernel is proposed to facilitate the algorithm development. The performance of this novel scheme is compared with that of the recursive least-squares algorithm in simulation.,[''],[]
"In this work, we generalize the spacetime induced by a rotating cosmic string, taking into account anisotropic effects due the breaking of the Lorentz violation. In particular, we explore the energy levels of a massive spinless particle that is covariantly coupled to a uniform magnetic field aligned with the string. Subsequently, we introduce a scalar potential featuring both a Coulomb–type and a linear confining term and comprehensively solve the Klein–Gordon equations for each configuration. Finally, by imposing rigid–wall boundary conditions, we determine the Landau levels when the linear defect itself possesses magnetization. Notably, our analysis reveals the occurrence of Landau quantization even in the absence of gauge fields, provided the string possesses spin. Finally, the thermodynamic properties are computed as well in these scenarios.",[''],"['Brazil.', '45700-00,–Brazil', 'Brazil.']"
"Demagnetization in ferromagnetic transition metals driven by a
femtosecond laser pulse is a fundamental problem in solid state
physics, and its understanding is essential to the development of
spintronics devices. Ab initio calculation of time-dependent magnetic
moment in the velocity gauge so far has not been successful in
reproducing the large amount of demagnetization observed in
experiments. In this work, we propose a method to incorporate
intraband transitions within the velocity gauge through a convective
derivative in the crystal momentum space. Our results for
transition-element bulk crystals (bcc Fe, hcp Co and fcc Ni) based on
the time-dependent quantum Liouville equation show a dramatic
enhancement in the amount of demagnetization after the inclusion of an
intraband term, in agreement with experiments. We also find that the
effect of intraband transitions to each ferromagnetic material is
distinctly different because of their band structure and spin property
differences. Our finding has a far-reaching impact on understanding
of ultrafast demagnetization.","['femtomagnetism, all optical spin switching, time dependent quantum', 'Liouville equation, m-mixing, circularly-polarized laser field']","['USA', 'USA']"
,[''],[]
"Knowledge of exact analytical functional forms for the pair correlation function g2⁢(r)subscript𝑔2𝑟g_{2}(r)italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r ) and its corresponding structure factor S⁢(k)𝑆𝑘S(k)italic_S ( italic_k ) of disordered many-particle systems is limited.
For fundamental and practical reasons, it is highly desirable to add to the existing data base of analytical functional forms for such pair statistics.
Here, we design a plethora of such pair functions in direct and Fourier spaces across the first three Euclidean space dimensions that are realizable by diverse many-particle systems with varying degrees of correlated disorder across length scales, spanning a wide spectrum of hyperuniform, typical nonhyperuniform and antihyperuniform ones.
This is accomplished by utilizing an efficient inverse algorithm that determines equilibrium states with up to pair interactions at positive temperature that precisely match targeted forms for both g2⁢(r)subscript𝑔2𝑟g_{2}(r)italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r ) and S⁢(k)𝑆𝑘S(k)italic_S ( italic_k ).
Among other results, we realize an example with the strongest hyperuniform property among known positive-temperature equilibrium states, critical-point systems (implying unusual 1D systems with phase transitions) that are not in the Ising universality class, systems that attain self-similar pair statistics under Fourier transformation, and an experimentally feasible polymer model.
We show that our pair functions enable one to achieve systems with a wide range of translational order and self-diffusion coefficients 𝒟𝒟\cal Dcaligraphic_D, which are inversely related to one another.
One can design other realizable pair statistics via linear combinations of our functions or by applying our inverse procedure to other desirable functional forms.
Our approach facilitates the inverse design of materials with desirable physical and chemical properties by tuning their pair statistics.",[''],"['USA', 'USA', 'USA']"
,[''],[]
"We extend the notion of forward performance criteria to settings with random endowment in incomplete markets. Building on these results, we introduce and develop the novel concept of forward optimized certainty equivalent (forward OCE), which offers a genuinely dynamic valuation mechanism that accommodates progressively adaptive market model updates, stochastic risk preferences, and incoming claims with arbitrary maturities.
In parallel, we develop a new methodology to analyze the emerging stochastic optimization problems by directly studying the candidate optimal control processes for both the primal and dual problems. Specifically, we derive two new systems of forward-backward stochastic differential equations (FBSDEs) and establish necessary and sufficient conditions for optimality, and various equivalences between the two problems. This new approach is general and complements the existing one based on backward stochastic partial differential equations (backward SPDEs) for the related value functions. We, also, consider representative examples for both forward performance criteria with random endowment and forward OCE, and for the case of exponential criteria, we investigate the connection between forward OCE and forward entropic risk measures.",[''],[]
"Reinforcement learning (RL) is a powerful technique for training intelligent agents, but understanding why these agents make specific decisions can be quite challenging. This lack of transparency in RL models has been a long-standing problem, making it difficult for users to grasp the reasons behind an agent’s behaviour. Various approaches have been explored to address this problem, with one promising avenue being reward decomposition (RD). RD is appealing as it sidesteps some of the concerns associated with other methods that attempt to rationalize an agent’s behaviour in a post-hoc manner. RD works by exposing various facets of the rewards that contribute to the agent’s objectives during training. However, RD alone has limitations as it primarily offers insights based on sub-rewards and does not delve into the intricate cause-and-effect relationships that occur within an RL agent’s neural model. In this paper, we present an extension of RD that goes beyond sub-rewards to provide more informative explanations. Our approach is centred on a causal learning framework that leverages information-theoretic measures for explanation objectives that encourage three crucial properties of causal factors: causal sufficiency, sparseness, and orthogonality. These properties help us distill the cause-and-effect relationships between the agent’s states and actions or rewards, allowing for a deeper understanding of its decision-making processes. Our framework is designed to generate local explanations and can be applied to a wide range of RL tasks with multiple reward channels. Through a series of experiments, we demonstrate that our approach offers more meaningful and insightful explanations for the agent’s action selections.",[''],[]
"In this paper, we elaborate on correctly predicting Échelle spectrograms by employing the fully three-dimensional representation of Snell’s law to model the effects of prisms as cross-dispersers in Échelle spectrographs.
We find that it is not sufficient to simply apply the frequently used trigonometric prism dispersion equation to describe recorded spectra.
This vector equation approach is not limited to a single dispersive element when modeling multi-prism cross-disperser configurations.
Our results help to understand the main levers in an Échelle spectrograph as well as contribute to auto-calibration algorithms for minimizing calibration efforts in daily operation.","['Prism;', 'Echelle;', 'Cross-Disperser;', 'Snell’s law;', 'Sellmeier;', 'QtYETI']","['München', 'work', 'work']"
"It is our purpose to study complete space-like self-expanders in the Minkovski space.
By use of maximum principle of Omori-Yau type, we
can obtain the rigidity theorems on n𝑛nitalic_n-dimensional complete space-like self-expanders in the Minkovski space ℝ1n+1subscriptsuperscriptℝ𝑛11\mathbb{R}^{n+1}_{1}blackboard_R start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. For complete space-like self-expanders of dimension 2222, we give a classification of them under assumption of constant squared norm of the second fundamental form.",[''],[]
,[''],[]
"In this work, we consider constrained stochastic optimization problems under hidden convexity, i.e., those that admit a convex reformulation via non-linear (but invertible) map c⁢(⋅)𝑐⋅c(\cdot)italic_c ( ⋅ ). A number of non-convex problems ranging from optimal control, revenue and inventory management, to convex reinforcement learning all admit such a hidden convex structure. Unfortunately, in the majority of applications considered, the map c⁢(⋅)𝑐⋅c(\cdot)italic_c ( ⋅ ) is unavailable or implicit; therefore, directly solving the convex reformulation is not possible. On the other hand, the stochastic gradients with respect to the original variable are often easy to obtain. Motivated by these observations, we examine the basic projected stochastic (sub-) gradient methods for solving such problems under hidden convexity. We provide the first sample complexity guarantees for global convergence in smooth and non-smooth settings. Additionally, in the smooth setting, we improve our results to the last iterate convergence in terms of function value gap using the momentum variant of projected stochastic gradient descent.",[''],[]
"The increasing availability of temporal data poses a challenge to time-series and signal-processing domains due to its high numerosity and complexity. Symbolic representation outperforms raw data in a variety of engineering applications due to its storage efficiency, reduced numerosity, and noise reduction. The most recent symbolic aggregate approximation technique called ABBA demonstrates outstanding performance in preserving essential shape information of time series and enhancing the downstream applications. However, ABBA cannot handle multiple time series with consistent symbols, i.e., the same symbols from distinct time series are not identical. Also, working with appropriate ABBA digitization involves the tedious task of tuning the hyperparameters, such as the number of symbols or tolerance. Therefore, we present a joint symbolic aggregate approximation that has symbolic consistency, and show how the hyperparameter of digitization can itself be optimized alongside the compression tolerance ahead of time. Besides, we propose a novel computing paradigm that enables parallel computing of symbolic approximation. The extensive experiments demonstrate its superb performance and outstanding speed regarding symbolic approximation and reconstruction.",[''],['Republic']
"Diffusion models trained with mean squared error loss tend to generate unrealistic samples. Current state-of-the-art models rely on classifier-free guidance to improve sample quality, yet its surprising effectiveness is not fully understood. In this paper, We show that the effectiveness of classifier-free guidance partly originates from it being a form of implicit perceptual guidance. As a result, we can directly incorporate perceptual loss in diffusion training to improve sample quality. Since the score matching objective used in diffusion training strongly resembles the denoising autoencoder objective used in unsupervised training of perceptual networks, the diffusion model itself is a perceptual network and can be used to generate meaningful perceptual loss. We propose a novel self-perceptual objective that results in diffusion models capable of generating more realistic samples. For conditional generation, our method only improves sample quality without entanglement with the conditional input and therefore does not sacrifice sample diversity. Our method can also improve sample quality for unconditional generation, which was not possible with classifier-free guidance before.",[''],[]
,[''],[]
"The integration of sensorized vessels, enabling real-time data collection and machine learning-driven data analysis marks a pivotal advancement in the maritime industry. This transformative technology not only can enhance safety, efficiency, and sustainability but also usher in a new era of cost-effective and smart maritime transportation in our increasingly interconnected world. This study presents a deep learning-driven anomaly detection system augmented with interpretable machine learning models for identifying performance anomalies in an industrial sensorized vessel, called TUCANA. We Leverage a human-in-the-loop unsupervised process that involves utilizing standard and Long Short-Term Memory (LSTM) autoencoders augmented with interpretable surrogate models, i.e., random forest and decision tree, to add transparency and interpretability to the results provided by the deep learning models. The interpretable models also enable automated rule generation for translating the inference into human-readable rules. Additionally, the process also includes providing a projection of the results using t-distributed stochastic neighbor embedding (t-SNE), which helps with a better understanding of the structure and relationships within the data and assessment of the identified anomalies. We empirically evaluate the system using real data acquired from the vessel TUCANA and the results involve achieving over 80% precision and 90% recall with the LSTM model used in the process. The interpretable models also provide logical rules aligned with expert thinking, and the t-SNE-based projection enhances interpretability. Our system demonstrates that the proposed approach can be used effectively in real-world scenarios, offering transparency and precision in performance anomaly detection.","['Index', 'Terms: ', 'Performance', 'Anomaly', 'Detection,', 'Human-in-the-loop', 'Learning', 'Process,', 'Deep', 'Learning,', 'Interpretable', 'Machine', 'Learning,', 'Sensorized', 'Vessels,', 'Maritime', 'Industry.']","['mahshid.helali@mdu.se', 'lukasz.kulas}@pg.edu.pl']"
"Late-type stars are the most abundant in the galactic stellar population. These stars, with the similar internal structure to the Sun, are expected to have solar-like atmospheres.
Investigating the stellar parameters and chemical abundances on late-type stars is essential to provide valuable constraints about stellar age, chemical evolution, and atmosphere of exoplanets.
In this work, we present the study of the Near-UV and optical spectroscopic observation of three late-type stars: HR 8038, AC Her, HD 76446, as obtained from 36-inch MIRA/Oliver Observing Station.
We derived surface temperature, gravity, metallicity, and the chemical abundances of light element Carbon in the stellar atmosphere. The elemental abundance of the Carbon for HR 8038, AC Her, and HD 76446 are derived to be 95%, 97%, and 108%, respectively, of the solar value.",[''],"['[', '[', '[', '[', '[']"
"Both humans and social animals live in groups and are frequently faced to choose between options with different qualities. When there are no leader agents controlling the group decision, consensus can be achieved through repeated interactions among group members. Various studies on collective decision-making illustrate how the dynamics of the opinions are determined by the structure of the social network and the methods that individuals use to share and update their opinion upon a social interaction.
In this paper, we are interested in further exploring how cognitive, social, and environmental factors interactively contribute to determining the outcome of a collective best-of-n𝑛nitalic_n decision process involving asymmetric options, i.e., different costs and/or benefits for each option.
We propose and study a novel model capturing those different factors, i) the error in processing social information, ii) the number of zealots (i.e., asocial agents who never change their opinion), iii) the option qualities, iv) the social connectivity structure, and v) the degree centrality of the asocial agents. By using the heterogeneous mean-field approach, we study the impact of the above-mentioned factors in the decision dynamics. Our findings indicate that when susceptible agents, i.e., individuals who change their opinion to conform with others, use the voter model as a mechanism to update their opinion, both the number and the degree of connectivity of the zealots can lead the population to converge towards the lowest quality option. Instead, when susceptible agents use methods more cognitively demanding, the group is marginally impacted by the presence of zealots.
The results of the analytical model are complemented and extended by agent-based simulations.
Our analysis also shows that the network topology can modulate the influence of zealots on group dynamics. In fact, in homogeneous networks where all nodes have the same degree (numbers of neighbours), any location of the zealots has similar impact on the group dynamics. Instead, when the network is heterogeneous, our simulations confirm the model predictions that show that placing the zealots in the network hubs (nodes with several neighbours) has a much larger impact than placing them in lower-degree nodes.",[''],"['Belgium', 'Belgium', 'Belgium', 'Belgium', 'Belgium']"
"Treating the X⁢(4140)𝑋4140X(4140)italic_X ( 4140 ) as a compact JP⁢C=1++superscript𝐽𝑃𝐶superscript1absentJ^{PC}=1^{++}italic_J start_POSTSUPERSCRIPT italic_P italic_C end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + + end_POSTSUPERSCRIPT c⁢s⁢c¯⁢s¯𝑐𝑠¯𝑐¯𝑠cs\bar{c}\bar{s}italic_c italic_s over¯ start_ARG italic_c end_ARG over¯ start_ARG italic_s end_ARG state and using its mass as a reference scale, we systematically estimate the masses of doubly heavy tetraquark states Q⁢Q⁢q¯⁢q¯𝑄𝑄¯𝑞¯𝑞QQ\bar{q}\bar{q}italic_Q italic_Q over¯ start_ARG italic_q end_ARG over¯ start_ARG italic_q end_ARG where Q=c,b𝑄𝑐𝑏Q=c,bitalic_Q = italic_c , italic_b and q=u,d,s𝑞𝑢𝑑𝑠q=u,d,sitalic_q = italic_u , italic_d , italic_s. Their decay properties are studied with a simple rearrangement scheme. Based on our results, the lowest I⁢(JP)=0⁢(1+)𝐼superscript𝐽𝑃0superscript1I(J^{P})=0(1^{+})italic_I ( italic_J start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT ) = 0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) b⁢b⁢n¯⁢n¯𝑏𝑏¯𝑛¯𝑛bb\bar{n}\bar{n}italic_b italic_b over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG state is a stable tetraquark about 20 MeV below the B¯*⁢B¯superscript¯𝐵¯𝐵\bar{B}^{*}\bar{B}over¯ start_ARG italic_B end_ARG start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT over¯ start_ARG italic_B end_ARG threshold. The mass and width of the low-mass 0⁢(1+)0superscript10(1^{+})0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) c⁢c⁢n¯⁢n¯𝑐𝑐¯𝑛¯𝑛cc\bar{n}\bar{n}italic_c italic_c over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG (n=u,d𝑛𝑢𝑑n=u,ditalic_n = italic_u , italic_d) tetraquark are compatible with the Tc⁢c⁢(3875)+subscript𝑇𝑐𝑐superscript3875T_{cc}(3875)^{+}italic_T start_POSTSUBSCRIPT italic_c italic_c end_POSTSUBSCRIPT ( 3875 ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT observed by the LHCb Collaboration. The location of the lowest 0⁢(0+)0superscript00(0^{+})0 ( 0 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) and 0⁢(1+)0superscript10(1^{+})0 ( 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) b⁢c⁢n¯⁢n¯𝑏𝑐¯𝑛¯𝑛bc\bar{n}\bar{n}italic_b italic_c over¯ start_ARG italic_n end_ARG over¯ start_ARG italic_n end_ARG states are found to be close to the B¯⁢D¯𝐵𝐷\bar{B}Dover¯ start_ARG italic_B end_ARG italic_D and B¯*⁢Dsuperscript¯𝐵𝐷\bar{B}^{*}Dover¯ start_ARG italic_B end_ARG start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_D thresholds, respectively. We hope that the predicted ratios between partial widths of different channels may be helpful to identify compact tetraquark states from future measurements.",[''],['China']
"Ionic liquids (ILs) are appealing electrolytes for their favorable physicochemical properties. However, despite their longstanding use, understanding the capacitive behavior of ILs remains challenging. This is largely due to the formation of a non-conventional electric double layer (EDL) at the electrode-electrolyte interface. This study shows that the short-range Yukawa interactions, representing the large anisotropically charged ILs, demix IL to create a spontaneous surface charge separation, which is reinforced by the strongly coupled charge interaction.
The properties of the condensed layer, the onset of charge separation, and the rise of overscreening and crowding critically depend on the asymmetry of Yukawa interactions.",[''],"['University', 'University', 'University', 'University', 'University']"
"We present an X-ray and UV investigation of five X-ray flares detected on two active systems, CC Eri and AB Dor, using the AstroSat observatory. The peak X-ray luminosities of the flares in the 0.3–7.0 keV band are found to be within 1031−333133{}^{31-33}start_FLOATSUPERSCRIPT 31 - 33 end_FLOATSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. Preliminary spectral analysis indicates the presence of three and four-temperature corona for CC Eri and AB Dor, respectively, where the highest temperature is found to vary with flare. The flare temperatures peaked at 51–59 MK for CC Eri and 29–44 MK for AB Dor. The peak emission measures of the flaring loops are estimated to be ∼similar-to\sim∼105454{}^{54}start_FLOATSUPERSCRIPT 54 end_FLOATSUPERSCRIPT for CC Eri and ∼similar-to\sim∼105555{}^{55}start_FLOATSUPERSCRIPT 55 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT for AB Dor. Global metallic abundances were also found to increase during flares.",[''],"['[', '[', '[']"
"Understanding the origin of electron incoherence is the first step toward a theoretical description of the non-Fermi liquid behavior of the high-Tc𝑐{}_{c}start_FLOATSUBSCRIPT italic_c end_FLOATSUBSCRIPT cuprate superconductors. Such electron incoherence manifests itself most evidently in the non-Drude behavior of the optical response of the system and the anomalous density fluctuation behavior in the long wave length limit. The spectral weight transfer related to such dissipative response, which is absent in conventional Fermi liquid metal, has direct consequence on the dc transport property of the system in the normal state and the superfluid stiffness in the superconducting state. It is found that such electron incoherence remains significant even in the clean limit and at low temperature and thus must be attributed to the strong electron correlation effect in the cuprate superconductors. Here we study such an intrinsic effect in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model through the variational calculation of its optical conductivity σ⁢(ω)𝜎𝜔\sigma(\omega)italic_σ ( italic_ω ). We assume a resonating valence bond ground state as our starting point and find that a significant portion of the total optical spectral weight remains incoherent throughout the phase diagram. The optical absorption is found to extend all the way to an energy of the order of the bare band width. We find that both the total optical weight K¯¯𝐾\bar{K}over¯ start_ARG italic_K end_ARG and the integrated incoherent optical weight I𝐼Iitalic_I increase monotonically with doping, with their ratio Ri⁢n⁢c⁢o⁢h=I/K¯subscript𝑅𝑖𝑛𝑐𝑜ℎ𝐼¯𝐾R_{incoh}=I/\bar{K}italic_R start_POSTSUBSCRIPT italic_i italic_n italic_c italic_o italic_h end_POSTSUBSCRIPT = italic_I / over¯ start_ARG italic_K end_ARG decreasing monotonically with doping. Our results indicate that the majority part of electron incoherence in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model can be attributed to the electron fractionalization mechanism assumed in such a treatment. We also find that the Drude weight deduced from D=K¯−I𝐷¯𝐾𝐼D=\bar{K}-Iitalic_D = over¯ start_ARG italic_K end_ARG - italic_I scales linearly with hole doping, without any sign of a non-monotonic behavior in the overdoped regime. Our results form an estimate of the lower bound for electron incoherence in the 2D t−J𝑡𝐽t-Jitalic_t - italic_J model as the multi-spinon excitation processes are neglected in our treatment.",[''],['P.R.China']
"A Christ-Kiselev maximal theorem is proved for linear operators between quasi-Banach function lattices satisfying certain lattice geometrical conditions. The result is further explored for weighted Lorentz spaces, classical Lorentz spaces, and Wiener amalgams of Lebesgue function and sequence spaces. Extensions are made to Köthe dual operators and to operators on interpolation spaces of quasi-Banach function lattices. Several applications to maximal Fourier operators are presented.","['Key words and phrases:', 'Maximal operators, filtrations, function spaces,', 'Lorentz spaces,', 'Weiner amalgam spaces,', 'Fourier transform']",[]
"We employ the eigen microstate approach to explore the self-organized criticality (SOC) in two celebrated sandpile models, namely, the BTW model and the Manna model. In both models, phase transitions from the absorbing-state to the critical state can be understood by the emergence of dominant eigen microstates with significantly increased weights. Spatial eigen microstates of avalanches can be uniformly characterized by a linear system size rescaling. The first temporal eigen microstates reveal scaling relations in both models. Furthermore, by finite-size scaling analysis of the first eigen microstate, we numerically estimate critical exponents i.e., σ0⁢w1/v~1∝LDproportional-tosubscript𝜎0subscript𝑤1subscript~𝑣1superscript𝐿𝐷\sqrt{\sigma_{0}w_{1}}/\tilde{v}_{1}\propto L^{D}square-root start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG / over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∝ italic_L start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT and v~1∝LD⁢(1−τs)/2proportional-tosubscript~𝑣1superscript𝐿𝐷1subscript𝜏𝑠2\tilde{v}_{1}\propto L^{D(1-\tau_{s})/2}over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∝ italic_L start_POSTSUPERSCRIPT italic_D ( 1 - italic_τ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) / 2 end_POSTSUPERSCRIPT. Our findings could provide profound insights into eigen states of the universality and phase transition in non-equilibrium complex systems governed by self-organized criticality.",[''],"['China', 'China', 'China', 'China', 'China']"
"We propose a contour integral-based algorithm for computing a few singular
values of a matrix or a few generalized singular values of a matrix pencil.
Mathematically, the generalized singular values of a matrix pencil are the
eigenvalues of an equivalent Hermitian–definite matrix pencil, known as the
Jordan–Wielandt matrix pencil.
However, direct application of the FEAST solver does not fully exploit the
structure of this problem.
We analyze several projection strategies on the Jordan–Wielandt matrix pencil,
and propose an effective and robust scheme tailored to GSVD.
Both theoretical analysis and numerical experiments demonstrate that our
algorithm achieves rapid convergence and satisfactory accuracy.",[''],[]
"We develop a new efficient sequential approximate leverage score algorithm, SALSA, using methods from randomized numerical linear algebra (RandNLA) for large matrices. We demonstrate that, with high probability, the accuracy of SALSA’s approximations is within (1+𝒪⁢(ε))1𝒪𝜀(1+\mathcal{O}\left(\varepsilon\right))( 1 + caligraphic_O ( italic_ε ) ) of the true leverage scores. In addition, we show that the theoretical computational complexity and numerical accuracy of SALSA surpass existing approximations. These theoretical results are subsequently utilized to develop an efficient algorithm, named LSARMA, for fitting an appropriate ARMA model to large-scale time series data. Our proposed algorithm is, with high probability, guaranteed to find the maximum likelihood estimates of the parameters for the true underlying ARMA model. Furthermore, it has a worst-case running time that significantly improves those of the state-of-the-art alternatives in big data regimes. Empirical results on large-scale data strongly support these theoretical results and underscore the efficacy of our new approach.",[''],[]
"The survey is devoted to operator splitting methods in the abstract formulation and their applications in probability. While the survey is focused on multiplicative methods, the BCH formula is used to discuss exponential splitting methods and a short informal introduction to additive splitting is presented. We introduce frameworks and available deterministic and probabilistic results and concentrate on constructing a wide picture of the field of operator splitting methods, providing a rigorous description in the setting of abstract Cauchy problems and an informal discussion for further and parallel advances. Some limitations and common difficulties are listed, as well as examples of works that provide solutions or hints. No new results are provided. The bibliography contains illustrative deterministic examples and a selection of probability-related works.","['Key words and phrases:', 'Operator splitting methods,', 'Trotter-Kato formula, exponential splitting']",[]
"Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse contents intelligently and automatically.
To support such artificial intelligence-generated content (AIGC) services, future communication systems should fulfill much more stringent requirements (including data rate, throughput, latency, etc.) with limited yet precious spectrum resources.
To tackle this challenge, semantic communication (SemCom), dramatically reducing resource consumption via extracting and transmitting semantics, has been deemed as a revolutionary communication scheme. The advanced GAI algorithms facilitate SemCom on sophisticated intelligence for model training, knowledge base construction and channel adaption. Furthermore, GAI algorithms also play an important role in the management of SemCom networks.
In this survey, we first overview the basics of GAI and SemCom as well as the synergies of the two technologies. Especially, the GAI-driven SemCom framework is presented, where many GAI models for information creation, SemCom-enabled information transmission and information effectiveness for AIGC are discussed separately. We then delve into the GAI-driven SemCom network management involving with novel management layers, knowledge management, and resource allocation. Finally, we envision several promising use cases, i.e., autonomous driving, smart city, and the Metaverse for a more comprehensive exploration.","['Index', 'Terms: ', 'Semantic communication,', 'AIGC,', 'Generative', 'AI,', 'Intelligent wireless networks,', 'Knowledge management.']",[]
"Although planning is a crucial component of the autonomous driving stack, researchers have yet to develop robust planning algorithms that are capable of safely handling the diverse range of possible driving scenarios. Learning-based planners suffer from overfitting and poor long-tail performance [37]. On the other hand, rule-based planners generalize well, but might fail to handle scenarios that require complex driving maneuvers [10]. To address these limitations, we investigate the possibility of leveraging the common-sense reasoning capabilities of Large Language Models (LLMs) such as GPT4 [19] and Llama2 [28] to generate plans for self-driving vehicles. In particular, we develop a novel hybrid planner that leverages a conventional rule-based planner in conjunction with an LLM-based planner. Guided by commonsense reasoning abilities of LLMs, our approach navigates complex scenarios which existing planners struggle with, produces well-reasoned outputs while also remaining grounded through working alongside the rule-based approach. Through extensive evaluation on the nuPlan benchmark, we achieve state-of-the-art performance, outperforming all existing pure learning- and rule-based methods across most metrics.
Our code will be available at https://llmassist.github.io.",[''],[]
"In this paper, we present a comprehensive investigation of stress propagation in a two-dimensional elastic circular disk.
To accurately describe the displacements and stress fields within the disk, we employ a scalar and vector potential approach, representing them as sums of Bessel functions.
The determination of the coefficients for these expansions is accomplished in the Laplace space, where we compare the boundary conditions.
By converting the inverse Laplace transforms into complex integrals using residue calculus, we successfully derive explicit expressions for the displacements and stress fields.
Notably, these expressions encompass primary, secondary, and surface waves, providing a thorough characterization of the stress propagation phenomena within the disk.
Our findings contribute to the understanding of mechanical behavior in disk-shaped components and can be valuable in the design and optimization of such structures across various engineering disciplines.","['Linear elasticity', 'Navier-Cauchy equation', 'Shock propagation', 'Laplace transform,', 'Residue']",[]
"The synergy of language and vision models has given rise to Large Language and Vision Assistant models (LLVAs), designed to engage users in rich conversational experiences intertwined with image-based queries. These comprehensive multimodal models seamlessly integrate vision encoders with Large Language Models (LLMs), expanding their applications in general-purpose language and visual comprehension. The advent of Large Multimodal Models (LMMs) heralds a new era in Artificial Intelligence (AI) assistance, extending the horizons of AI utilization. This paper takes a unique perspective on LMMs, exploring their efficacy in performing image classification tasks using tailored prompts designed for specific datasets. We also investigate the LLVAs zero-shot learning capabilities. Our study includes a benchmarking analysis across four diverse datasets: MNIST, Cats Vs. Dogs, Hymnoptera (Ants Vs. Bees), and an unconventional dataset comprising Pox Vs. Non-Pox skin images. The results of our experiments demonstrate the model’s remarkable performance, achieving classification accuracies of 85%, 100%, 77%, and 79% for the respective datasets without any fine-tuning. To bolster our analysis, we assess the model’s performance post fine-tuning for specific tasks. In one instance, fine-tuning is conducted over a dataset comprising images of faces of children with and without autism. Prior to fine-tuning, the model demonstrated a test accuracy of 55%, which significantly improved to 83% post fine-tuning. These results, coupled with our prior findings, underscore the transformative potential of LLVAs and their versatile applications in real-world scenarios.","['Index', 'Terms: ', 'Large', 'Language', 'Models,', 'Large', 'Multimodal', 'Models,', 'Prompt', 'Engineering,', 'Classification']","['0000-0002-9717-3252', '0000-0002-5145-1990', '0000-0003-1521-5568', '0000-0003-2336-0490', '0000-0001-7389-3274']"
,[''],[]
"We generalize Integration-By-Parts (IBP) and differential equations methods to de Sitter amplitudes related to inflation. While massive amplitudes in de Sitter spacetime are usually regarded as highly intricate, we find they have remarkably hidden concise structures from the perspective of IBP. We find the irrelevance of IBP relations to propagator-types. This also leads to the factorization of the IBP relations of each vertex integral family corresponding to d⁢τidsubscript𝜏𝑖\mathrm{d}\tau_{i}roman_d italic_τ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT integration. Furthermore, with a smart construction of master integrals, the universal formulas for iterative reduction and d⁢logd\mathrm{d}\logroman_d roman_log-form differential equations of arbitrary vertex integral family are presented and proved. These formulas dominate all tree-level de Sitter amplitude and play a kernel role at the loop-level as well.",[''],[]
"Recently, Amnon Neeman settled a bold conjecture by Antieau, Gepner, and Heller regarding the relationship between the regularity of finite-dimensional noetherian schemes and the existence of bounded t𝑡titalic_t-structures on their derived categories of perfect complexes.
In this paper, we prove some very general results about the existence of bounded t𝑡titalic_t-structures on (not necessarily algebraic or topological) triangulated categories and their invariance under completion. Our general treatment, when specialized to the case of schemes, immediately gives us Neeman’s theorem as an application and significantly generalizes another remarkable theorem by Neeman about the equivalence of bounded t𝑡titalic_t-structures on the bounded derived categories of coherent sheaves. When specialized to other cases like (not necessarily commutative) rings, nonpositive DG-rings, connective 𝔼1subscript𝔼1\mathbb{E}_{1}blackboard_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-rings, triangulated categories without models, etc., we get many other applications.
Under mild finiteness assumptions, these results give a categorical obstruction, the singularity category in our sense, to the existence of bounded t𝑡titalic_t-structures on a triangulated category. The two key tools used in our treatment are the finitistic dimension for a triangulated category (a new concept introduced in the paper) and lifting t𝑡titalic_t-structures along completions of triangulated categories.",[''],[]
"In this article, we investigate periodically driven open quantum systems within the framework of Floquet-Lindblad master equations. Specifically, we discuss Lindblad master equations in the presence of a coherent, time-periodic driving and establish their general spectral features. We also clarify the notions of transient and non-decaying solutions from this spectral perspective, and then prove that any physical system described by a Floquet-Lindblad equation must have at least one physical non-equilibrium steady state (NESS), corresponding to an eigenoperator of the Floquet-Lindblad evolution superoperator 𝒰Fsubscript𝒰𝐹\mathcal{U}_{F}caligraphic_U start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT with unit eigenvalue. Since the Floquet-Lindblad formalism encapsulates the entire information regarding the NESS, it in principle enables us to obtain non-linear effects to all orders at once. The Floquet-Lindblad formalism thus provides a powerful tool for studying driven-dissipative solid-state systems, which we illustrate by deriving the nonlinear optical response of a simple two-band model of an insulating solid and comparing it with prior results established through Keldysh techniques.",[''],"['USA', 'USA', 'China', 'USA', 'Kong', 'China', 'China', 'USA', 'USA', 'Kong']"
"Multi-agent systems often require agents to collaborate with or compete against other agents with diverse goals, behaviors, or strategies. Agent modeling is essential when designing adaptive policies for intelligent machine agents in multi-agent systems, as this is the means by which the ego agent understands other agents’ behavior and extracts their meaningful policy representations. These representations can be used to enhance the ego agent’s adaptive policy which is trained by reinforcement learning. However, existing agent modeling approaches typically assume the availability of local observations from other agents (modeled agents) during training or a long observation trajectory for policy adaption. To remove these constrictive assumptions and improve agent modeling performance, we devised a Contrastive Learning-based Agent Modeling (CLAM) method that relies only on the local observations from the ego agent during training and execution. With these observations, CLAM is capable of generating consistent high-quality policy representations in real-time right from the beginning of each episode. We evaluated the efficacy of our approach in both cooperative and competitive multi-agent environments. Our experiments demonstrate that our approach achieves state-of-the-art on both cooperative and competitive tasks, highlighting the potential of contrastive learning-based agent modeling for enhancing reinforcement learning.",[''],[]
"In this paper, we present a signal processing framework for directed graphs. Unlike undirected graphs, a graph shift operator such as the adjacency matrix associated with a directed graph usually does not admit an orthogonal eigenbasis. This makes it challenging to define the Fourier transform. Our methodology leverages the polar decomposition to define two distinct eigendecompositions, each associated with different matrices derived from this decomposition. We propose to extend the frequency domain and introduce a Fourier transform that jointly encodes the spectral response of a signal for the two eigenbases from the polar decomposition. This allows us to define convolution following a standard routine. Our approach has two features: it is lossless as the shift operator can be fully recovered from factors of the polar decomposition. Moreover, it subsumes the traditional graph signal processing if the graph is directed. We present numerical results to show how the framework can be applied.","['Index', 'Terms: ', 'Directed graph, graph signal processing, polar decomposition']",[]
"Training large-scale language models is increasingly critical in various domains, but it is hindered by frequent failures, leading to significant time and economic costs. Current failure recovery methods in cloud-based settings inadequately address the diverse and complex scenarios that arise, focusing narrowly on erasing downtime for individual tasks without considering the overall cost impact on a cluster.
We introduce Unicron, a workload manager designed for efficient self-healing in large-scale language model training. Unicron optimizes the training process by minimizing failure-related costs across multiple concurrent tasks within a cluster. Its key features include in-band error detection for real-time error identification without extra overhead, a dynamic cost-aware plan generation mechanism for optimal reconfiguration, and an efficient transition strategy to reduce downtime during state changes. Deployed on a 128-GPU distributed cluster, Unicron demonstrates up to a 1.9×1.9\times1.9 × improvement in training efficiency over state-of-the-art methods, significantly reducing failure recovery costs and enhancing the reliability of large-scale language model training.",[''],[]
,[''],[]
"We extend prior work to derive three additional M-1-dimensional integral
representations – over the interval [0,1]01[0,1][ 0 , 1 ], where the prior version
was over the interval [0,∞]0[0,\infty][ 0 , ∞ ] – for products of M Slater orbitals
(such as appear in quantum transition amplitudes) that allows their
magnitudes of coordinate vector differences (square roots of polynomials)
|𝐱1−𝐱2|=x12−2⁢x1⁢x2⁢cos⁡θ+x22subscript𝐱1subscript𝐱2superscriptsubscript𝑥122subscript𝑥1subscript𝑥2𝜃superscriptsubscript𝑥22|{\bf x}_{1}-{\bf x}_{2}|=\sqrt{x_{1}^{2}-2x_{1}x_{2}\cos\theta+x_{2}^{2}}| bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | = square-root start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 2 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_cos italic_θ + italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG
to be moved from disjoint products of functions into a single quadratic
form whose square my be completed. This provides more alternatives
to Fourier transforms that introduce a 3M-dimensional momentum integral
for those products of Slater orbitals (in M separate denominators),
followed in many cases by another set of M-1-dimensional integral
representations to combine those denominators into one denominator
having a single (momentum) quadratic form. The current and prior work
is also slightly more compact than Gaussian transforms that introduce
an M-dimensional integral for products of M Slater orbitals, while
simultaneously moving them into a single (spatial) quadratic form
in a common exponential.
One may also use addition theorems for extracting the angular variables,
or even direct integration at times. Each method has its strengths
and weaknesses. We have found that two of these M-1-dimensional integral
representations over the interval [0,1]01[0,1][ 0 , 1 ] are numerically
stable, as was the prior version having integrals running over the interval
[0,∞]0[0,\infty][ 0 , ∞ ], and one does not need to test for a sufficiently large
upper integration limit as one does for the latter approach. The third integral
representation might have a better form for analytical reduction of integrals. For analytical
reductions of integrals arising from any of the three, however, there is the possible drawback for
large M of there being fewer tabled integrals over [0,1]01[0,1][ 0 , 1 ] than over
[0,∞]0[0,\infty][ 0 , ∞ ]. In particular, the results of both prior and current
representations have integration variables within square roots as
arguments of Macdonald functions. In a number of cases, these may be
converted to Meijer G-functions whose arguments have the form (a⁢x2+b⁢x+c)/x𝑎superscript𝑥2𝑏𝑥𝑐𝑥(ax^{2}+bx+c)/x( italic_a italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_b italic_x + italic_c ) / italic_x
for which a single tabled integral exists for the integrals from running
over the interval [0,∞]0[0,\infty][ 0 , ∞ ] of the prior paper, and from which
other forms may be found using the techniques given therein. This
is not so for integral representations over the interval [0,1]01[0,1][ 0 , 1 ].
Finally, we introduce a fourth integral representation that is not
easily generalizable to large M, but may well provide a bridge for
finding the requisite integrals for such Meijer G-functions over [0,1]01[0,1][ 0 , 1 ].",[''],[]
"The extensive adoption of Self-supervised learning (SSL) has led to an increased security threat from backdoor attacks. While existing research has mainly focused on backdoor attacks in image classification, there has been limited exploration into their implications for object detection. In this work, we propose the first backdoor attack designed for object detection tasks in SSL scenarios, termed Object Transform Attack (SSL-OTA). SSL-OTA employs a trigger capable of altering predictions of the target object to the desired category, encompassing two attacks: Data Poisoning Attack (NA) and Dual-Source Blending Attack (DSBA). NA conducts data poisoning during downstream fine-tuning of the object detector, while DSBA additionally injects backdoors into the pre-trained encoder. We establish appropriate metrics and conduct extensive experiments on benchmark datasets, demonstrating the effectiveness and utility of our proposed attack. Notably, both NA and DSBA achieve high attack success rates (ASR) at extremely low poisoning rates (0.5%). The results underscore the importance of considering backdoor threats in SSL-based object detection and contribute a novel perspective to the field.",[''],[]
,[''],"['USA', 'USA', 'USA', 'USA']"
"This paper explores the causal reasoning of large language models (LLMs) to enhance their interpretability and reliability in advancing artificial intelligence. Despite the proficiency of LLMs in a range of tasks, their potential for understanding causality requires further exploration. We propose a novel causal attribution model that utilizes “do-operators” for constructing counterfactual scenarios, allowing us to systematically quantify the influence of input numerical data and LLMs’ pre-existing knowledge on their causal reasoning processes. Our newly developed experimental setup assesses LLMs’ reliance on contextual information and inherent knowledge across various domains. Our evaluation reveals that LLMs’ causal reasoning ability depends on the context and domain-specific knowledge provided, and supports the argument that knowledge is, indeed, what LLMs principally require for sound causal reasoning. On the contrary, in the absence of knowledge, LLMs still maintain a degree of causal reasoning using the available numerical data, albeit with limitations in the calculations.
A Python implementation of our proposed method is available at https://github.com/ncsulsj/Causal_LLM.",[''],"['hengrc1@uci.edu', 'sliu56@ncsu.edu', 'songray@gmail.com']"
"In a previous paper [9] we studied an age-structured branching model without immigration. Here we consider a special case of the model, where the system is founded by a single particle with a random lifetime and the reproduction regime is supercritical. We show that there is a necessary and sufficient condition for the convergence of the Malthus normalized random measures e−α~⁢t⁢Xtsuperscript𝑒~𝛼𝑡subscript𝑋𝑡e^{-\tilde{\alpha}t}X_{t}italic_e start_POSTSUPERSCRIPT - over~ start_ARG italic_α end_ARG italic_t end_POSTSUPERSCRIPT italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where α~~𝛼\tilde{\alpha}over~ start_ARG italic_α end_ARG is a strictly positive Malthusian parameter. The convergence of e−α~⁢t⁢⟨Xt,f⟩superscript𝑒~𝛼𝑡subscript𝑋𝑡𝑓e^{-\tilde{\alpha}t}\langle X_{t},f\rangleitalic_e start_POSTSUPERSCRIPT - over~ start_ARG italic_α end_ARG italic_t end_POSTSUPERSCRIPT ⟨ italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_f ⟩ can be strengthened to hold with probability one under conditions weaker than those given in Jagers [24]. A central limit theorem of ⟨Xt,f⟩subscript𝑋𝑡𝑓\langle X_{t},f\rangle⟨ italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_f ⟩ is further proved.",[''],[]
"With rising concerns about the security of IoT devices, network operators need better ways to handle potential risks. Luckily, IoT devices show consistent patterns in how they communicate. But despite previous efforts, it remains unclear how knowledge of these patterns can be made available.
As data marketplaces become popular in different domains, this paper111This manuscript is the full version of our paper [1] accepted to the IEEE/IFIP NOMS 2024 conference. proposes creating a special marketplace focused on IoT cybersecurity. The goal is to openly share knowledge about IoT devices’ behavior, using structured data formats like Manufacturer Usage Description (MUD) files. To make this work, we employ technologies like blockchain and smart contracts to build a practical and secure foundation for sharing and accessing important information about how IoT devices should behave on the network.
Our contributions are two-fold.
(1) We identify the essential features of an effective marketplace for sharing data related to the expected behaviors of IoT devices. We develop a smart contract on the Ethereum blockchain with five concrete functions; and,
(2) We implement a prototype of our marketplace in a private chain environment—our codes are publicly released. We demonstrate how effectively our marketplace functions through experiments involving MUD files from consumer IoT devices. Our marketplace enables suppliers and consumers to share MUD data on the Ethereum blockchain for under a hundred dollars, promoting accessibility and participation.","['Index', 'Terms: \n', 'Decentralized data marketplace,', 'IoT behaviors,', 'MUD files']",['h.habibi@}unsw.edu.au']
"In recent work, Dao and Eisenbud define the notion of a Burch
index, expanding the notion of Burch rings of Dao, Kobayashi, and Takahashi, and show that for any module over a ring of Burch index at least 2, its
n𝑛nitalic_nth syzygy contains direct summands of the residue field for n=4𝑛4n=4italic_n = 4 or 5555 and all n≥7𝑛7n\geq 7italic_n ≥ 7. We investigate how this behavior is explained by the bar
resolution formed from appropriate differential graded (dg) resolutions, yielding a new proof that includes all n≥5𝑛5n\geq 5italic_n ≥ 5, which is sharp. When the module is Golod, we use instead the bar resolution formed from A∞subscript𝐴A_{\infty}italic_A start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT resolutions to identify such k𝑘kitalic_k summands explicitly for all n≥4𝑛4n\geq 4italic_n ≥ 4 and show that the number of these grows exponentially as the homological degree increases.","['Key words and phrases:', 'Burch']",[]
,[''],[]
"We investigate the tachyonic instability of Kerr-Newman (KN) black hole with a rotation parameter a𝑎aitalic_a in the Einstein-Chern-Simons-scalar theory coupled with a quadratic massive scalar field.
This instability analysis corresponds to exploring the onset of spontaneous scalarization for KN black holes.
First, we find no a𝑎aitalic_a-bound for α<0𝛼0\alpha<0italic_α < 0 case by considering (1+1)-dimensional analytical method.
A direct numerical method is adopted to explore (2+1)-dimensional time evolution of a massive scalar perturbation with positive and negative α𝛼\alphaitalic_α to obtain threshold curves numerically.
We obtain threshold curves αth⁢(a)subscript𝛼th𝑎\alpha_{\rm th}(a)italic_α start_POSTSUBSCRIPT roman_th end_POSTSUBSCRIPT ( italic_a ) of tachyonic instability for positive α𝛼\alphaitalic_α without any a𝑎aitalic_a-bounds.
We expect to find the same threshold curves αth⁢(a)subscript𝛼th𝑎\alpha_{\rm th}(a)italic_α start_POSTSUBSCRIPT roman_th end_POSTSUBSCRIPT ( italic_a ) of tachyonic instability for negative α𝛼\alphaitalic_α without any a𝑎aitalic_a-bound because its linearized scalar theory is invariant under the transformation of α→−α→𝛼𝛼\alpha\to-\alphaitalic_α → - italic_α and θ→−θ→𝜃𝜃\theta\to-\thetaitalic_θ → - italic_θ. In addition, it is found that the scalar mass term suppresses tachyonic instability of KN black holes.",[''],[]
,[''],[]
"Quantum cryptography is now considered as a promising technology due to its promise of unconditional security. In recent years, rigorous work is being done for the experimental realization of quantum key distribution (QKD) protocols to realize secure networks. Among various QKD protocols, coherent one way and differential phase shift QKD protocols have undergone rapid experimental developments due to the ease of experimental implementations with the present available technology. In this work, we have experimentally realized optical fiber based coherent one way and differential phase shift QKD protocols at telecom wavelength. Both protocols belong to a class of protocols named as distributed phase reference protocol in which weak coherent pulses are used to encode the information. Further, we have analysed the key rates with respect to different parameters such distance, disclose rate, compression ratio and detector dead time.",[''],"['India', 'India', 'India', 'India', 'India', 'author:anirban.pathak@gmail.com']"
Suppose G𝐺Gitalic_G is a finitely generated infinite group and 𝒢𝒢\mathcal{G}caligraphic_G is a graph of groups decomposition of G𝐺Gitalic_G such that the edge groups are finite. This paper establishes that the topology of the Floyd boundary of G𝐺Gitalic_G is uniquely determined by the topology of the Floyd boundary of each vertex group of 𝒢𝒢\mathcal{G}caligraphic_G.,"['Key words and phrases: ', 'Bass–Serre tree,', 'Floyd boundary, free products']",[]
"Autonomous vehicles increasingly utilize the vision-based perception module to acquire information about driving environments and detect obstacles. Correct detection and classification are important to ensure safe driving decisions. Existing works have demonstrated the feasibility of fooling the perception models such as object detectors and image classifiers with printed adversarial patches. However, most of them are indiscriminately offensive to every passing autonomous vehicle.
In this paper, we propose TPatch, a physical adversarial patch triggered by acoustic signals. Unlike other adversarial patches, TPatch remains benign under normal circumstances but can be triggered to launch a hiding, creating or altering attack by a designed distortion introduced by signal injection attacks towards cameras. To avoid the suspicion of human drivers and make the attack practical and robust in the real world, we propose a content-based camouflage method and an attack robustness enhancement method to strengthen it. Evaluations with three object detectors, YOLO V3/V5 and Faster R-CNN, and eight image classifiers demonstrate the effectiveness of TPatch in both the simulation and the real world. We also discuss possible defenses at the sensor, algorithm, and system levels.",[''],[]
"We construct a class of nonlinear coherent states (NLCSs) by introducing a more general nonlinear function and study their non-classical properties, specifically the second-order correlation function g(2)⁢(0)superscript𝑔20g^{(2)}(0)italic_g start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ( 0 ), Mandel parameter Q𝑄Qitalic_Q, squeezing, amplitude squared squeezing and Wigner function of the optical field.
The results indicate that the non-classical properties of the new types of even and odd NLCSs crucially depend on nonlinear functions. More concretely, we find that the new even NLCSs could exhibit the photon-bunching effect whereas the new odd NLCSs could show photon-antibunching effect. The degree of squeezing is also significantly affected by the parameter selection of these NLCSs. By employing various forms of nonlinear functions, it becomes possible to construct NLCSs with diverse properties, thereby providing a theoretical foundation for corresponding experimental investigations.",[''],"['China', 'China', 'China']"
"We report the occurrence of vibrational resonance (VR) and the underlying mechanism in a simple piecewise linear electronic circuit, namely the Murali-Lakshmanan-Chua (MLC) circuit, driven by an additional biharmonic signal with widely different frequency. When the amplitude of the high-frequency force is tuned, the resultant vibrational resonance is used to detect the low-frequency signal and also to enhance it into a high-frequency signal. Further, we also show that even when the low-frequency signal is changed from sine wave to square and sawtooth waves, vibrational resonance can be used to detect and enhance them into high-frequency signals. These behaviors, confirmed by experimental results, are illustrated with appropriate analytical and numerical solutions of the corresponding circuit equations describing the system. Finally, we also verify the signal detection in the above circuit even with the addition of noise.",[''],"['India.', 'India.', 'India.', 'India.', 'India.', 'India.']"
"The proliferation of images captured from millions of cameras and the advancement of facial recognition (FR) technology have made the abuse of FR a severe privacy threat. Existing works typically rely on obfuscation, synthesis, or adversarial examples to modify faces in images to achieve anti-facial recognition (AFR). However, the unmodified images captured by camera modules that contain sensitive personally identifiable information (PII) could still be leaked. In this paper, we propose a novel approach, CamPro, to capture inborn AFR images. CamPro enables well-packed commodity camera modules to produce images that contain little PII and yet still contain enough information to support other non-sensitive vision applications, such as person detection. Specifically, CamPro tunes the configuration setup inside the camera image signal processor (ISP), i.e., color correction matrix and gamma correction, to achieve AFR, and designs an image enhancer to keep the image quality for possible human viewers. We implemented and validated CamPro on a proof-of-concept camera, and our experiments demonstrate its effectiveness on ten state-of-the-art black-box FR models. The results show that CamPro images can significantly reduce face identification accuracy to 0.3% while having little impact on the targeted non-sensitive vision application. Furthermore, we find that CamPro is resilient to adaptive attackers who have re-trained their FR models using images generated by CamPro, even with full knowledge of privacy-preserving ISP parameters.",[''],"['{zwj_,sy_tsang,jianiliu,yushicheng,xji,wyxu}@zju.edu.cn']"
The assumption that the system Hamiltonian for entangled states is additive is widely used in orthodox quantum no-signalling arguments. It is shown that additivity implies a contradiction with the assumption that the system being studied is entangled.,[''],['kent.peacock@uleth.ca']
"Inadequate generality across different organs and tasks constrains the application of ultrasound (US) image analysis methods in smart healthcare. Building a universal US foundation model holds the potential to address these issues. Nevertheless, the development of such foundational models encounters intrinsic challenges in US analysis, i.e., insufficient databases, low quality, and ineffective features. In this paper, we present a universal US foundation model, named USFM, generalized to diverse tasks and organs towards label efficient US image analysis. First, a large-scale Multi-organ, Multi-center, and Multi-device US database was built, comprehensively containing over two million US images. Organ-balanced sampling was employed for unbiased learning. Then, USFM is self-supervised pre-trained on the sufficient US database. To extract the effective features from low-quality US images, we proposed a spatial-frequency dual masked image modeling method. A productive spatial noise addition-recovery approach was designed to learn meaningful US information robustly, while a novel frequency band-stop masking learning approach was also employed to extract complex, implicit grayscale distribution and textural variations. Extensive experiments were conducted on the various tasks of segmentation, classification, and image enhancement from diverse organs and diseases. Comparisons with representative US image analysis models illustrate the universality and effectiveness of USFM. The label efficiency experiments suggest the USFM obtains robust performance with only 20% annotation, laying the groundwork for the rapid development of US models in clinical practices.",[''],[]
,[''],[]
"Occlusion presents a significant challenge in human pose estimation. The challenges posed by occlusion can be attributed to the following factors: 1) Data: The collection and annotation of occluded human pose samples are relatively challenging. 2) Feature: Occlusion can cause feature confusion due to the high similarity between the target person and interfering individuals. 3) Inference: Robust inference becomes challenging due to the loss of complete body structural information. The existing methods designed for occluded human pose estimation usually focus on addressing only one of these factors. In this paper, we propose a comprehensive framework DAG (Data, Attention, Graph) to address the performance degradation caused by occlusion. Specifically, we introduce the mask joints with instance paste data augmentation technique to simulate occlusion scenarios. Additionally, an Adaptive Discriminative Attention Module (ADAM) is proposed to effectively enhance the features of target individuals. Furthermore, we present the Feature-Guided Multi-Hop GCN (FGMP-GCN) to fully explore the prior knowledge of body structure and improve pose estimation results. Through extensive experiments conducted on three benchmark datasets for occluded human pose estimation, we demonstrate that the proposed method outperforms existing methods. Code and data will be publicly available.",[''],[]
"Radical subgroups play an important role in both group theory and representation theory. In this paper we present
a strategy of classifying radical subgroups of finite reductive groups. As an application, we complete the proof
of the inductive blockwise Alperin weight condition for the Chevalley groups F4⁡(q)subscriptF4𝑞\operatorname{F}_{4}(q)roman_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_q ), contributing to the program
to prove the Alperin weight conjecture by verifying its inductive condition for simple groups.","['Key words and phrases:', 'Radical subgroups, finite reductive group,', 'Alperin weight conjecture, inductive blockwise', 'Alperin weight condition, exceptional groups of type', 'F4subscriptF4\\operatorname{F}_{4}roman_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT.']",[]
"In this supplementary material, we first provide more details about fundamentals of quantum channels, and properties of fixed points and extreme metastable states (EMSs) in Ramsey interferometry measurements (RIMs). Then we present Monte Carlo simulation results for a target system composed of multiple qubits, with the ancilla qubit under both RIMs and dynamical decoupling (DD) sequences. Moreover, we numerically demonstrate that quantum metastability is robust even when the target system suffers additional dissipation.",[''],"['China', 'China', 'China', 'China']"
"Question Answering over Knowledge Graph (KGQA) aims to seek answer entities for the natural language question from a large-scale Knowledge Graph (KG).
To better perform reasoning on KG, recent work typically adopts a pre-trained language model (PLM) to model the question, and a graph neural network (GNN) based module to perform multi-hop reasoning on the KG.
Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions.
To solve it, we aim to simplify the above two-module approach, and develop a more capable PLM that can directly support subgraph reasoning for KGQA, namely ReasoningLM.
In our approach, we propose a subgraph-aware self-attention mechanism to imitate the GNN for performing structured reasoning, and also adopt an adaptation tuning strategy to adapt the model parameters with 20,000 subgraphs with synthesized questions.
After adaptation, the PLM can be parameter-efficient fine-tuned on downstream tasks.
Experiments show that ReasoningLM surpasses state-of-the-art models by a large margin, even with fewer updated parameters and less training data.
Our codes and data are publicly available at https://github.com/RUCAIBox/ReasoningLM.",[''],[]
"Purpose:
Progression of hip osteoarthritis (hip OA) leads to pain and disability, likely leading to surgical treatment such as hip arthroplasty at the terminal stage. The severity of hip OA is often classified using the Crowe and Kellgren-Lawrence (KL) classifications. However, as the classification is subjective, we aimed to develop an automated approach to classify the disease severity based on the two grades using digitally-reconstructed radiographs (DRRs) from CT images.
Methods:
Automatic grading of the hip OA severity was performed using deep learning-based models. The models were trained to predict the disease grade using two grading schemes, i.e., predicting the Crowe and KL grades separately, and predicting a new ordinal label combining both grades and representing the disease progression of hip OA. The models were trained in classification and regression settings. In addition, the model uncertainty was estimated and validated as a predictor of classification accuracy. The models were trained and validated on a database of 197 hip OA patients, and externally validated on 52 patients. The model accuracy was evaluated using exact class accuracy (ECA), one-neighbor class accuracy (ONCA), and balanced accuracy.
Results:
The deep learning models produced a comparable accuracy of approximately 0.65 (ECA) and 0.95 (ONCA) in the classification and regression settings. The model uncertainty was significantly larger in cases with large classification errors (P<6e-3).
Conclusion:
In this study, an automatic approach for grading hip OA severity from CT images was developed. The models have shown comparable performance with high ONCA, which facilitates automated grading in large-scale CT databases and indicates the potential for further disease progression analysis. Classification accuracy was correlated with the model uncertainty, which would allow for the prediction of classification errors. The code will be made publicly available at https://github.com/NAIST-ICB/HipOA-Grading.",[''],"['*', '[', '[', '[']"
"As indoor applications grow in diversity, wireless sensing, vital in areas like localization and activity recognition, is attracting renewed interest. Indoor wireless sensing relies on signal processing, particularly channel state information (CSI) based signal parameter estimation. Nonetheless, regarding reflected signals induced by dynamic human targets, no satisfactory algorithm yet exists for estimating the acceleration of dynamic path length change (DPLC), which is crucial for various sensing tasks in this context. Hence, this paper proposes DP-AcE, a CSI based DPLC acceleration estimation algorithm. We first model the relationship between the phase difference of adjacent CSI measurements and the DPLC’s acceleration. Unlike existing works assuming constant velocity, DP-AcE considers both velocity and acceleration, yielding a more accurate and objective representation. Using this relationship, an algorithm combining scaling with Fourier transform is proposed to realize acceleration estimation. We evaluate DP-AcE via the acceleration estimation and acceleration-based fall detection with the collected CSI. Experimental results reveal that, using distance as the metric, DP-AcE achieves a median acceleration estimation percentage error of 4.38%. Furthermore, in multi-target scenarios, the fall detection achieves an average true positive rate of 89.56% and a false positive rate of 11.78%, demonstrating its importance in enhancing indoor wireless sensing capabilities.","['Index', 'Terms: ', 'Wireless sensing, channel state information, signal parameter estimation.']",[]
"The hybrid neural differentiable models mark a significant advancement in the field of scientific machine learning. These models, integrating numerical representations of known physics into deep neural networks, offer enhanced predictive capabilities and show great potential for data-driven modeling of complex physical systems. However, a critical and yet unaddressed challenge lies in the quantification of inherent uncertainties stemming from multiple sources. Addressing this gap, we introduce a novel method, DiffHybrid-UQ, for effective and efficient uncertainty propagation and estimation in hybrid neural differentiable models, leveraging the strengths of deep ensemble Bayesian learning and nonlinear transformations. Specifically, our approach effectively discerns and quantifies both aleatoric uncertainties, arising from data noise, and epistemic uncertainties, resulting from model-form discrepancies and data sparsity. This is achieved within a Bayesian model averaging framework, where aleatoric uncertainties are modeled through hybrid neural models. The unscented transformation plays a pivotal role in enabling the flow of these uncertainties through the nonlinear functions within the hybrid model. In contrast, epistemic uncertainties are estimated using an ensemble of stochastic gradient descent (SGD) trajectories. This approach offers a practical approximation to the posterior distribution of both the network parameters and the physical parameters. Notably, the DiffHybrid-UQ framework is designed for simplicity in implementation and high scalability, making it suitable for parallel computing environments. The merits of the proposed method have been demonstrated through problems governed by both ordinary and partial differentiable equations.",[''],[]
"The sparsity of reward feedback remains a challenging problem in online deep reinforcement learning (DRL). Previous approaches have utilized temporal credit assignment (CA) to achieve impressive results in multiple hard tasks. However, many CA methods relied on complex architectures or introduced sensitive hyperparameters to estimate the impact of state-action pairs. Meanwhile, the premise of the feasibility of CA methods is to obtain trajectories with sparse rewards, which can be troublesome in sparse-reward environments with large state spaces. To tackle these problems, we propose a simple and efficient algorithm called Policy Optimization with Smooth Guidance (POSG) that leverages a small set of sparse-reward demonstrations to make reliable and effective long-term credit assignments while efficiently facilitating exploration. The key idea is that the relative impact of state-action pairs can be indirectly estimated using offline demonstrations rather than directly leveraging the sparse reward trajectories generated by the agent. Specifically, we first obtain the trajectory importance by considering both the trajectory-level distance to demonstrations and the returns of the relevant trajectories. Then, the guidance reward is calculated for each state-action pair by smoothly averaging the importance of the trajectories through it, merging the demonstration’s distribution and reward information. We theoretically analyze the performance improvement bound caused by smooth guidance rewards and derive a new worst-case lower bound on the performance improvement. A comprehensive evaluation of POSG is conducted by benchmarking it with several state-of-the-art RL methods in four different sparse-reward environments with discrete and continuous action spaces. Extensive results demonstrate POSG’s significant advantages in control performance and convergence speed compared to benchmark DRL algorithms. Notably, the specific metrics and quantifiable results are investigated to demonstrate the superiority of POSG.",[''],"['*', '[', '[']"
"Backdoor attacks in the traditional graph neural networks (GNNs) field are easily detectable due to the dilemma of confusing labels.
To explore the backdoor vulnerability of GNNs and create a more stealthy backdoor attack method, a clean-label graph backdoor attack method(CGBA) in the node classification task is proposed in this paper.
Differently from existing backdoor attack methods, CGBA requires neither modification of node labels nor graph structure.
Specifically, to solve the problem of inconsistency between the contents and labels of the samples, CGBA selects poisoning samples in a specific target class and uses the label of sample as the target label (i.e., clean-label) after injecting triggers into the target samples. To guarantee the similarity of neighboring nodes, the raw features of the nodes are elaborately picked as triggers to further improve the concealment of the triggers.
Extensive experiments results show the effectiveness of our method.
When the poisoning rate is 0.04, CGBA can achieve an average attack success rate of 87.8%, 98.9%, 89.1%, and 98.5%, respectively.",[''],[]
"We study solutions to systems of stream inclusions f∈T⁢(f)𝑓𝑇𝑓f\in T(f)italic_f ∈ italic_T ( italic_f ), where T𝑇Titalic_T is assumed to be causal in the sense that elements in output streams are determined by a finite history of inputs.
For solving these inclusions we develop a correspondence of causality
and contraction with respect to the prefix distance on streams.
Now, based on this causality-contraction correspondence, we apply fixpoint principles for the spherically complete ultrametric space of streams to obtain solutions for causal stream inclusions.
The underlying fixpoint iterations induce fixpoint induction principles for reasoning about solutions of causal stream inclusions.
In addition, these fixpoint approximations induce anytime algorithms for computing finite stream prefixes of solutions.
We illustrate the use of these developments
for some central concepts of system design.","['Formal', 'Methods', 'Fixpoint', 'Approximation', 'Systems', 'Engineering.']",[]
"In open-domain Question Answering (QA), dense retrieval is crucial for finding relevant passages for answer generation. Typically, contrastive learning is used to train a retrieval model that maps passages and queries to the same semantic space. The objective is to make similar ones closer and dissimilar ones further apart. However, training such a system is challenging due to the false negative issue, where relevant passages may be missed during data annotation. Hard negative sampling, which is commonly used to improve contrastive learning, can introduce more noise in training. This is because hard negatives are those closer to a given query, and thus more likely to be false negatives. To address this issue, we propose a novel contrastive confidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly used loss for dense retrieval. Our analysis shows that the regularizer helps dense retrieval models be more robust against false negatives with a theoretical guarantee. Additionally, we propose a model-agnostic method to filter out noisy negative passages in the dataset, improving any downstream dense retrieval models. Through experiments on three datasets, we demonstrate that our method achieves better retrieval performance in comparison to existing state-of-the-art dense retrieval systems.",[''],[]
"This paper investigates block-level interference exploitation (IE) precoding for multi-user multiple-input single-output (MU-MISO) downlink systems. To overcome the need for symbol-level IE precoding to frequently update the precoding matrix, we propose to jointly optimize all the precoders or transmit signals within a transmission block. The resultant precoders only need to be updated once per block, and while not necessarily constant over all the symbol slots, we refer to the technique as block-level slot-variant IE precoding. Through a careful examination of the optimal structure and the explicit duality inherent in block-level power minimization (PM) and signal-to-interference-plus-noise ratio (SINR) balancing (SB) problems, we discover that the joint optimization can be decomposed into subproblems with smaller variable sizes. As a step further, we propose block-level slot-invariant IE precoding by adding a structural constraint on the slot-variant IE precoding to maintain a constant precoder throughout the block. A novel linear precoder for IE is further presented, and we prove that the proposed slot-variant and slot-invariant IE precoding share an identical solution when the number of symbol slots does not exceed the number of users. Numerical simulations demonstrate that the proposed precoders achieve a significant complexity reduction compared against benchmark schemes, without sacrificing performance.","['Index', 'Terms: ', 'MU-MISO, block-level precoding, symbol-level precoding, power minimization,', 'SINR balancing, interference exploitation.']",[]
"Incorporating symmetry as an inductive bias into multi-agent reinforcement learning (MARL) has led to improvements in generalization, data efficiency, and physical consistency. While prior research has succeeded in using perfect symmetry prior, the realm of partial symmetry in the multi-agent domain remains unexplored. To fill in this gap, we introduce the partially symmetric Markov game, a new subclass of the Markov game. We then theoretically show that the performance error introduced by utilizing symmetry in MARL is bounded, implying that the symmetry prior can still be useful in MARL even in partial symmetry situations. Motivated by this insight, we propose the Partial Symmetry Exploitation (PSE) framework that is able to adaptively incorporate symmetry prior in MARL under different symmetry-breaking conditions. Specifically, by adaptively adjusting the exploitation of symmetry, our framework is able to achieve superior sample efficiency and overall performance of MARL algorithms. Extensive experiments are conducted to demonstrate the superior performance of the proposed framework over baselines. Finally, we implement the proposed framework in real-world multi-robot testbed to show its superiority.",[''],[]
"In this paper, we scale evolutionary algorithms to high-dimensional optimization problems that deceptively possess a low effective dimensionality (certain dimensions do not significantly affect the objective function). To this end, an instantiation of the multiform optimization paradigm is presented, where multiple low-dimensional counterparts of a target high-dimensional task are generated via random embeddings. Since the exact relationship between the auxiliary (low-dimensional) tasks and the target is a priori unknown, a multiform evolutionary algorithm is developed for unifying all formulations into a single multi-task setting. The resultant joint optimization enables the target task to efficiently reuse solutions evolved across various low-dimensional searches via cross-form genetic transfers, hence speeding up overall convergence characteristics. To validate the overall efficacy of our proposed algorithmic framework, comprehensive experimental studies are carried out on well-known continuous benchmark functions as well as a set of practical problems in the hyper-parameter tuning of machine learning models and deep learning models in classification tasks and Predator-Prey games, respectively.","['Index', 'Terms: ', 'High-dimensional search, evolutionary multi-tasking, transfer optimization, random embeddings.']",[]
,[''],[]
"This work introduces the L3Cube-MahaSocialNER dataset, the first and largest social media dataset specifically designed for Named Entity Recognition (NER) in the Marathi language. The dataset comprises 18,000 manually labeled sentences covering eight entity classes, addressing challenges posed by social media data, including non-standard language and informal idioms. Deep learning models, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on the individual dataset with IOB and non-IOB notations. The results demonstrate the effectiveness of these models in accurately recognizing named entities in Marathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric information extraction and supports real-time applications, providing a valuable resource for public opinion analysis, news, and marketing on social media platforms. We also show that the zero-shot results of the regular NER model are poor on the social NER test set thus highlighting the need for more social NER datasets. The datasets and models are publicly available at https://github.com/l3cube-pune/MarathiNLP","['Named', 'Entity', 'Recognition,', 'Deep', 'Learning,', 'Natural', 'Language', 'Processing,', 'BERT, mBERT,', 'ALBERT,', 'RoBERTa,', 'Muril,', 'Indic bert,', 'Convolutional', 'Neural', 'Network,', 'Bidirectional long short-term memory,', 'Long short-term memory,', 'Marathi', 'NER,', 'Efficient', 'NLP']","['India', 'India', 'India', 'India', 'India']"
"We study the implementation of a Chebyshev spectral method with forward Euler integrator proposed in [6] to investigate a peridynamic nonlocal formulation of Richards’ equation. We prove the convergence of the fully-discretization of the model showing the existence and uniqueness of a solution to the weak formulation of the method by using the compactness properties of the approximated solution and exploiting the stability of the numerical scheme. We further support our results through numerical simulations, using initial conditions with different order of smoothness, showing reliability and robustness of the theoretical findings presented in the paper.","['Key words and phrases: ', 'Richards’ equation, nonlocal models, peridynamics,', 'Chebyshev spectral methods']",[]
,[''],[]
"We investigated the beat-to-beat fluctuation of the photoplethysmography (PPG) waveform. The motivation is that morphology variability extracted from the arterial blood pressure (ABP) has been found to correlate with baseline condition and short-term surgical outcome of the patients undergoing liver transplant surgery. Numerous interactions of physiological mechanisms regulating the cardiovascular system could underlie the variability of morphology. We used the unsupervised manifold learning algorithm, Dynamic Diffusion Map, to quantify the multivariate waveform morphological variation. Due to the physical principal of light absorption, PPG waveform signals are more susceptible to artifact and are nominally used only for visual inspection of data quality in clinical medical environment. But on the other hand, the noninvasive, easy-to-use nature of PPG grants a wider range of biomedical application, which inspired us to investigate the variability of morphology information from PPG waveform signal. We developed data analysis techniques to improve the performance and validated with the real-life clinical database. We investigated the beat-to-beat fluctuation of the photoplethysmography (PPG) waveform. The motivation is that morphology variability extracted from the arterial blood pressure (ABP) has been found to correlate with baseline condition and short-term surgical outcome of the patients undergoing liver transplant surgery. Numerous interactions of physiological mechanisms regulating the cardiovascular system could underlie the variability of morphology. We used the unsupervised manifold learning algorithm, Dynamic Diffusion Map, to quantify the multivariate waveform morphological variation. Due to the physical principal of light absorption, PPG waveform signals are more susceptible to artifact and are nominally used only for visual inspection of data quality in clinical medical environment. But on the other hand, the noninvasive, easy-to-use nature of PPG grants a wider range of biomedical application, which inspired us to investigate the variability of morphology information from PPG waveform signal. We developed data analysis techniques to improve the performance and validated with the real-life clinical database.",[''],[]
"We study nonequilibrium spin dynamics in differentially rotating systems, deriving an effective Hamiltonian for conduction electrons in the comoving frame. In contrast to conventional spin current generation mechanisms that require vorticity, our theory describes spins and spin currents arising from differentially rotating systems regardless of vorticity. We demonstrate the generation of spin currents in differentially rotating systems, such as liquid metals with Taylor-Couette flow.
Our alternative mechanism will be important in the development of nanomechanical spin devices.",[''],"['Japan', 'China.', 'Japan', 'Japan', 'China', 'Japan', 'Japan']"
"Distributed computing in Blockchain Technology (BCT) hinges on a trust assumption among independent nodes. Without a third-party interface or what’s known as a ‘Blockchain Oracle’, it can’t interact with the external world. This Oracle plays a crucial role by feeding extrinsic data into the Blockchain, ensuring that Smart Contracts operate accurately in real time. The ‘Oracle problem’ arises from the inherent difficulty in verifying the truthfulness of the data sourced by these Oracles. The genuineness of a Blockchain Oracle is paramount, as it directly influences the Blockchain’s reliability, credibility, and scalability. To tackle these challenges, a strategy rooted in Byzantine fault-tolerance ϕitalic-ϕ\phiitalic_ϕ is introduced. Furthermore, an autonomous system for sustainability and audibility, built on heuristic detection, is put forth. The effectiveness and precision of the proposed strategy outperformed existing methods using two real-world datasets, aimed to meet the authenticity standards for Blockchain Oracles.","['Index', 'Terms: ', 'Blockchain', 'Oracles,', 'Trust', 'Assumption,', 'Asymmetric', 'Byzantine', 'Quorums,', 'Smart', 'Contracts,', 'Oracle', 'Data', 'Reliability,', 'Blockchain', 'Scalability', 'Solutions,', 'Decentralized', 'Applications (DApps).']","['France', 'France', 'USA']"
"The paper is an attempt to apply the theory of dessins d’enfants to the theory of fullerenes. The classical results concerning the calculation of the dodecahedron Belyi function are presented and then applied to the calculation of the Belyi function of the barrel, and the euclidean geometry of the latter is investigated. The non-existence of the fullerene with the only hexagonal face is established by the methods of dessins d’enfants.",[''],[]
,[''],[]
,[''],[]
"Gas-particle flows are commonly simulated through two-fluid model at industrial-scale. However, these simulations need very fine grid to have accurate flow predictions, which is prohibitively demanding in terms of computational resources. To circumvent this problem, the filtered two-fluid model has been developed, where large-scale flow field is numerically resolved and small-scale fluctuations are accounted for through subgrid-scale modeling. In this study, we have performed fine-grid two-fluid simulations of dilute gas-particle flows in periodic domains and applied explicit filtering to generate datasets. Then, these datasets have been used to develop artificial neural network (ANN) models for closures such as the filtered drag force and solid phase stress for the filtered two-fluid model. The set of input variables for the subgrid drag force ANN model that has been found previously to work well for dense flow regimes is found to work as well for the dilute regime. In addition, we present a Galilean invariant tensor basis neural network (TBNN) model for the filtered solid phase stress which can capture nicely the anisotropic nature of the solid phase stress arising from subgrid-scale velocity fluctuations. Finally, the predictions provided by this new TBNN model are compared with those obtained from a simple eddy-viscosity ANN model.",[''],"['[', '[', '[', '[', '[', '[', '[']"
"This paper proposes a cyber-resilient distributed control strategy equipped with attack detection capabilities for islanded AC microgrids in the presence of bounded stealthy cyber attacks affecting both frequency and power information exchanged among neighboring distributed generators (DGs). The proposed control methodology relies on the construction of an auxiliary layer and the establishment of effective inter-layer cooperation between the actual DGs in the control layer and the virtual DGs in the auxiliary layer. This cooperation aims to achieve robust frequency restoration and proportional active power-sharing. It is shown that the in situ presence of a concealed auxiliary layer not only guarantees resilience against stealthy bounded attacks on both frequency and power-sharing but also facilitates a network-enabled attack identification mechanism. The paper provides rigorous proof of the stability of the closed-loop system and derives bounds for frequency and power deviations under attack conditions, offering insights into the impact of the attack signal, control and pinning gains, and network connectivity on the system’s convergence properties. The performance of the proposed controllers is illustrated by simulating a networked islanded AC microgrid in a Simulink environment showcasing both attributes of attack resilience and attack detection.","['Index', 'Terms: ', 'AC microgrids, cyber-security, network-enabled attack detection, resilient control, stealthy attacks.']",[]
We investigate the Galois structure of algebraic units in cyclic extensions of number fields and thereby obtain strong new results on the existence of independent Minkowski S𝑆Sitalic_S-units.,"['Key words and phrases:', 'Minkowski units,', 'Galois structure of algebraic units,', 'Krull-Schmidt decomposition,', 'Yakovlev diagram']",[]
"For a finite valued field extension (L/K,v)𝐿𝐾𝑣(L/K,v)( italic_L / italic_K , italic_v ) we describe the problem of find sets of generators for the corresponding extension 𝒪L/𝒪Ksubscript𝒪𝐿subscript𝒪𝐾\mathcal{O}_{L}/\mathcal{O}_{K}caligraphic_O start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT / caligraphic_O start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT of valuation rings. The main tool to obtain such sets are complete sets of (key) polynomials. We show that when the initial index coincide with the ramification index, sequences of key polynomials naturally give rise to sets of generators. We use this to prove Knaf’s conjecture for pure extensions.","['Key words and phrases:', 'Key polynomials,', 'Kähler differentials, the defect']",[]
,[''],[]
,[''],[]
"Context:Solar filaments, also called solar prominences when appearing on the solar limb, consist of dense, cool plasma suspended in the hot and tenuous corona, which are the main potential sources of solar storms.
Aims:To understand the onset mechanism of solar filaments, we investigate the eruption process of an inverted U-shaped solar filament and two precursory jet-like activities.
Methods:Utilizing observations from the New Vacuum Solar Telescope (NVST), Solar Dynamics Observatory (SDO), and Solar Terrestrial Relations Observatory-Ahead (STEREO-A), we investigate the event from two distinct observational perspectives: on the solar disk using NVST and SDO, and on the solar limb using STEREO-A. We employ both a non-linear force-free field model and a potential field model to reconstruct the coronal magnetic field, aiming to understand its magnetic properties.
Results:Two precursor jet-like activities were observed before the eruption, displaying an untwisted rotation. The second activity released an estimated twist of over two turns. During these two jet-like activities, “Y”-shaped brightenings, newly emerging magnetic flux accompanied by magnetic cancellation, and the formation of newly moving fibrils were identified. Combining these observational features, it can be inferred that these two precursor jet-like activities released the magnetic field constraining the filament and were caused by newly emerging magnetic flux. Before the filament eruption, it was observed that some moving flows had been ejected from the site as the onset of two jet-like activities, indicating the same physical process as two jet-like activities. Extrapolations revealed that the filament laid under the height of the decay index of 1.0 and had strong magnetic field (540 Gauss) and a high twist number (2.4 turns) before the eruption. An apparent rotational motion was observed during the filament eruption.
Conclusions:We deduce that the solar filament, exhibiting an inverted U-shape, is a significantly twisted flux rope. The eruption of the filament was initiated by the release of constraining magnetic fields through continuous magnetic reconnection. This reconnection process was caused by the emergence of newly magnetic flux.","['Key', 'Words.: ', 'Solar filament –', 'Solar filament eruptions –', 'Solar activity']",[]
"Linear Regression and neural networks are widely used to model data. Neural networks distinguish themselves from linear regression with their use of activation functions that enable modeling nonlinear functions. The standard argument for these activation functions is that without them, neural networks only can model a line. However, a novel explanation we propose in this paper for the impracticality of neural networks without activation functions, or linear neural networks, is that they actually reduce both training and testing performance. Having more parameters makes LNNs harder to optimize, and thus they require more training iterations than linear regression to even potentially converge to the optimal solution. We prove this hypothesis through an analysis of the optimization of an LNN and rigorous testing comparing the performance between both LNNs and linear regression on synthethic, noisy datasets.",[''],[]
,[''],[]
,[''],"['Italy.', 'davide.lauria@unical.it', 'zari.rachev@ttu.edu', 'zari.rachev@ttu.edu']"
"In this paper, we introduce semi-infinite tensor complementarity problem to provide an approach for considering a more realistic situation of the problem. We prove the necessary and sufficient conditions for the existence of the solution set. In this context, we study the error bounds of the solution set in terms of residual function.

Keywords: Semi-infinite tensor complementarity problem, error bound, residual function, R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-tensor.

AMS subject classifications: 90C30, 90C33, 15A69.",[''],[]
"Context:The far-infrared (FIR) distribution at high Galactic latitudes,
observed with Planck, is filamentary with coherent structures in
polarization. These structures are also closely related to
H i filaments with coherent velocity structures. There is a
long-standing debate about the physical nature of these
structures. They are considered either as velocity caustics,
fluctuations engraved by the turbulent velocity field or as cold
three-dimensional density structures in the interstellar medium (ISM).
Aims:We discuss different approaches to data analysis and interpretation in order to
work out the differences.
Methods:We considered mathematical preliminaries for the derivation of caustics
that characterize filamentary structures in the ISM. Using the
Hessian operator, we traced individual FIR filamentary structures in
H i from channel maps as observed and alternatively from data that
are provided by the velocity decomposition algorithm (VDA). VDA is
claimed to separate velocity caustics from density effects.
Results:Based on the strict mathematical definition, the so-called velocity
caustics are not actually caustics. These VDA data products may contain caustics
in the same way as the original H i observations. Caustics derived
by a Hessian analysis of both databases are nearly identical with a
correlation coefficient of 98%. However, the VDA algorithm leads to a
30% increase in the alignment uncertainties when fitting
FIR/H i orientation angles. Thus, the VDA velocity crowding concept
fails to explain the alignment of FIR/H i filaments at |b|>20⁢°𝑏20°|b|>20\degr| italic_b | > 20 °. We used H i absorption data to constrain the physical nature
of FIR/H i filaments and determine spin temperatures and volume
densities of FIR/H i filaments. H i filaments exist as cold neutral medium
(CNM)
structures; outside the filaments no CNM absorption is detectable.
Conclusions: The CNM in the diffuse ISM is exclusively located in filaments with FIR
counterparts. These filaments at high Galactic latitudes exist as cold
density structures; velocity crowding effects are negligible.","['Key', 'Words.: \nclouds –', 'ISM: structure – (ISM:) dust, extinction –\nturbulence – magnetic fields – magnetohydrodynamics (MHD)']",[]
"In this paper, we introduce set-valued tensor complementarity problem where the elements of the involved tensors are defined based on a set-valued mapping. We study several properties of the solution set under the framework of set-valued mapping. We provide the necessary and sufficient conditions for the zero solution of a set-valued tensor complementarity problem. We introduce limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property for the set of tensors and establish a connection between limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property and the level boundedness of the merit function of the corresponding set-valued tensor complementarity problem.

Keywords: Set-valued tensor complementarity problem, S𝑆Sitalic_S-tensor, semi-positive tensor, R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-tensor, merit function, limit R0subscript𝑅0R_{0}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-property.

AMS subject classifications: 15A69, 90C30, 90C33.",[''],[]
"In this letter, we propose a deep-unfolding-based framework (DUNet) to maximize the secrecy rate in reconfigurable intelligent surface (RIS) empowered multi-user wireless networks. To tailor DUNet, first we relax the problem, decouple it into beamforming and phase shift subproblems, and propose an alternative optimization (AO) based solution for the relaxed problem. Second, we apply Karush-Kuhn-Tucker (KKT) conditions to obtain a closed-form solutions for the beamforming and the phase shift. Using deep-unfolding mechanism, we transform the closed-form solutions into a deep learning model (i.e., DUNet) that achieves a comparable performance to that of AO in terms of accuracy and about 25.6 times faster.","['Index', 'Terms: ', 'Reconfigurable intelligent surface (RIS), beamforming, phase shift, secrecy rate, deep-unfolding.']",[]
"In order to fully harness the potential of machine learning, it is crucial to establish a system that renders the field more accessible and less daunting for individuals who may not possess a comprehensive understanding of its intricacies. The paper describes the design of a system that integrates AutoML, XAI, and synthetic data generation to provide a great UX design for users. The system allows users to navigate and harness the power of machine learning while abstracting its complexities and providing high usability. The paper proposes two novel classifiers, Logistic Regression Forest and Support Vector Tree, for enhanced model performance, achieving 96% accuracy on a diabetes dataset and 93% on a survey dataset. The paper also introduces a model-dependent local interpreter called MEDLEY and evaluates its interpretation against LIME, Greedy, and Parzen. Additionally, the paper introduces LLM-based synthetic data generation, library-based data generation, and enhancing the original dataset with GAN. The findings on synthetic data suggest that enhancing the original dataset with GAN is the most reliable way to generate synthetic data, as evidenced by KS tests, standard deviation, and feature importance. The authors also found that GAN works best for quantitative datasets.",[''],[]
"Unlimited sampling was recently introduced to deal with the clipping or saturation of measurements where a modulo operator is applied before sampling. In this paper, we investigate the identifiability of the model where measurements are acquired under a discrete Fourier transform (DFT) sensing matrix first followed by a modulo operator (modulo-DFT). Firstly, based on the theorems of cyclotomic polynomials, we derive a sufficient condition for uniquely identifying the original signal in modulo-DFT. Additionally, for periodic bandlimited signals (PBSs) under unlimited sampling which can be viewed as a special case of modulo-DFT, the necessary and sufficient condition for the unique recovery of the original signal are provided. Moreover, we show that when the oversampling factor exceeds 3⁢(1+1/P)311𝑃3(1+1/P)3 ( 1 + 1 / italic_P ), PBS is always identifiable from the modulo samples, where P𝑃Pitalic_P is the number of harmonics including the fundamental component in the positive frequency part.","['Index', 'Terms: ', 'Unlimited sampling,', 'DFT sensing matrix, periodic bandlimited signal, identifiability']",[]
,[''],[]
"In many causal studies, outcomes are ’censored by death,’ in the sense that they are neither observed nor defined for units who die. In such studies, the focus is usually on the stratum of ’always survivors’ up to a single fixed time s. Building on a recent strand of the literature, we propose an extended framework for the analysis of longitudinal studies, where units can die at different time points, and the main endpoints are observed and well-defined only up to the death time. We develop a Bayesian longitudinal principal stratification framework, where units are cross-classified according to the longitudinal death status. Under this framework, the focus is on causal effects for the principal strata of units that would be alive up to a time point s irrespective of their treatment assignment, where these strata may vary as a function of s. We can get precious insights into the effects of treatment by inspecting the distribution of baseline characteristics within each longitudinal principal stratum, and by investigating the time trend of both principal stratum membership and survivor-average causal effects. We illustrate our approach for the analysis of a longitudinal observational study aimed to assess, under the assumption of strong ignorability of treatment assignment, the causal effects of a policy promoting start-ups on firms’ survival and hiring policy, where firms’ hiring status is censored by death.",[''],"['Florence', 'Toscana', 'Florence', 'Institute']"
"Research into the prediction and analysis of perceived audio quality is hampered by the scarcity of openly available datasets of audio signals accompanied by corresponding subjective quality scores.
To address this problem, we present the Open Dataset of Audio Quality (ODAQ), a new dataset containing the results of a MUSHRA listening test conducted with expert listeners from 2 international laboratories. ODAQ contains 240 audio samples and corresponding quality scores. Each audio sample is rated by 26 listeners.
The audio samples are stereo audio signals sampled at 44.1 or 48 kHz and are processed by a total of 6 method classes, each operating at different quality levels.
The processing method classes are designed to generate quality degradations possibly encountered during audio coding and source separation, and the quality levels for each method class span the entire quality range.
The diversity of the processing methods, the large span of quality levels, the high sampling frequency, and the pool of international listeners make ODAQ particularly suited for further research into subjective and objective audio quality.
The dataset is released with permissive licenses, and the software used to conduct the listening test is also made publicly available.",[''],[]
"In this paper, we study the stability of traveling wave solutions arising from a credit rating migration problem with a free boundary, After some transformations, we turn the Free Boundary Problem into a fully nonlinear parabolic problem on a fixed domain and establish a rigorous stability analysis of the equilibrium in an exponentially weighted function space. It implies the convergence of the discounted value of bonds that stands as an attenuated traveling wave solution.","['Key words and phrases:', 'Free boundary problems; stability; traveling waves; fully nonlinear parabolic problems; credit rating migration']",[]
We determine when the integral homology of the classifying space of a P⁢U⁢(n)𝑃𝑈𝑛PU(n)italic_P italic_U ( italic_n )-gauge group over the sphere S2superscript𝑆2S^{2}italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT has torsion.,"['Key words and phrases: classifying space, torsion, cohomology, gauge group']",[]
"We present a framework to assist therapists and children with autism spectrum disorder in their Applied Behavioral Analysis (ABA) therapy. The framework was designed in collaboration with Spazio Autismo, an autism center in Mantova, Italy. The framework is a first step toward transitioning from the current paper-based to fully digital-supported therapy. We evaluated the framework over four months with 18 children diagnosed with classic autism, ranging from 4 to 7 years old. The framework integrates a mobile app that children and therapists use during the sessions with a backend for managing therapy workflow and monitoring progress. Our preliminary results show that the framework can improve the efficacy of the therapy sessions, reducing non-therapeutic time, increasing patient focus, and quickening the completion of the assigned objectives. It can also support therapists in preparing learning materials, data acquisition, and reporting. Finally, the framework demonstrated improved privacy and security of patients’ data while maintaining reliability.","['Index', 'Terms: \n', 'Autism,', 'Applied', 'Behavioural', 'Analysis,', 'Serious', 'Games,', 'Gamification']","['https://www.solcomantova.it/servizi/autismo/', 'Italy']"
,[''],[]
"Given an integer M≥2𝑀2M\geq 2italic_M ≥ 2, we deploy the generating function techniques to compute the number of M𝑀Mitalic_M-th roots of identity in some of the well-known finite groups of Lie type, more precisely for finite general linear groups, symplectic groups, orthogonal groups of all types and unitary groups over finite fields of odd characteristics.","['Key words and phrases: word maps, finite groups of', 'Lie type,', 'M𝑀Mitalic_M-th root']",[]
"We numerically study the coarsening of topological defects in 2D polar active matter and make several interesting observations and predictions. (i) The long time state is characterized by nonzero density of defects, in stark contrast to theoretical expectations. (ii) The kinetics of defect coarsening shows power law decay to steady state, as opposed to exponential decay in thermal equilibrium. (iii) Observations (i) and (ii) together suggest emergent screening of topological charges due to activity. (iv) Nontrivial defect coarsening in the active model leads to nontrivial steady state patterns. We investigate, characterize, and validate these patterns and discuss their biological significance.",[''],['560012']
"Neutron star contains a large number of nucleons and muons, if coupled with hidden ultralight particles, the orbit motion can produce sizable energy flux in addition to the binary’s gravitational quadrupole radiation. Here, we explore a scenario in which the scalar boson sourced by the binary is also coupled to the lowest dimensional photon operator, through which indirect electromagnetic radiation is generated beyond the scalar’s mass threshold. Using the observational data of two pulsar binaries, we place stringent constraints on the strength of such couplings.",[''],[]
,[''],[]
"We prove geometric upper bounds for the Poincaré and Logarithmic Sobolev constants for Brownian motion on manifolds with sticky reflecting boundary diffusion i.e. extended Wentzell-type boundary condition under general curvature assumptions on the manifold and its boundary. The method is based on an interpolation involving energy interactions between the boundary and the interior of the manifold. As side results we obtain explicit geometric bounds on the first nontrivial Steklov eigenvalue, for the norm of the boundary trace operator on Sobolev functions, and on the boundary trace logarithmic Sobolev constant. The case of Brownian motion with pure sticky reflection is also treated.",[''],[]
"We propose and analyze a unified structure-preserving parametric finite element method (SP-PFEM) for the anisotropic surface diffusion of curves in two dimensions (d=2)𝑑2(d=2)( italic_d = 2 ) and surfaces in three dimensions (d=3)𝑑3(d=3)( italic_d = 3 ) with an arbitrary anisotropic surface energy density γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), where 𝒏∈𝕊d−1𝒏superscript𝕊𝑑1\boldsymbol{n}\in\mathbb{S}^{d-1}bold_italic_n ∈ blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT represents the outward unit vector. By introducing a novel unified surface energy matrix 𝑮k⁢(𝒏)subscript𝑮𝑘𝒏\boldsymbol{G}_{k}(\boldsymbol{n})bold_italic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_n ) depending
on γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), the Cahn–Hoffman 𝝃𝝃\boldsymbol{\xi}bold_italic_ξ-vector and
a stabilizing function k⁢(𝒏):𝕊d−1→ℝ:𝑘𝒏→superscript𝕊𝑑1ℝk(\boldsymbol{n}):\ \mathbb{S}^{d-1}\to{\mathbb{R}}italic_k ( bold_italic_n ) : blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT → blackboard_R, we obtain a
unified and conservative variational formulation for the anisotropic surface diffusion via
different surface differential operators including the surface gradient operator, the surface divergence operator
and the surface Laplace–Beltrami operator. A SP-PFEM discretization is presented for the variational
problem. In order to establish the unconditional energy stability of the proposed SP-PFEM under
a very mild condition on γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ), we propose
a new framework via local energy estimate for proving energy stability/structure-preserving
properties of the parametric finite element method for the anisotropic surface diffusion. This framework
sheds light on how to prove unconditional energy stability of other numerical methods
for geometric partial differential equations.
Extensive numerical results are reported to demonstrate the efficiency and accuracy as well
as structure-preserving properties of the proposed SP-PFEM for the anisotropic surface diffusion
with arbitrary anisotropic surface energy density γ⁢(𝒏)𝛾𝒏\gamma(\boldsymbol{n})italic_γ ( bold_italic_n ) arising from different applications.",['anisotropic surface diffusion anisotropic surface energy density parametric finite element method structure-preserving unconditional energy stability'],[]
,[''],[]
,[''],[]
,[''],"['t.hristova@soton.ac.uk', 'l.magee@westernsydney.edu.au', 'karen.soldatic@westernsydney.edu.au']"
"Transportation has greatly benefited the cities’ development in the modern civilization process. Intelligent transportation, leveraging advanced computer algorithms, could further increase people’s daily commuting efficiency. However, intelligent transportation, as a cross-discipline, often requires practitioners to comprehend complicated algorithms and obscure neural networks, bringing a challenge for the advanced techniques to be trusted and deployed in practical industries. Recognizing the expressiveness of the pre-trained large language models, especially the potential of being augmented with abilities to understand and execute intricate commands, we introduce Open-TI. Serving as a bridge to mitigate the industry-academic gap, Open-TI is an innovative model targeting the goal of Turing Indistinguishable Traffic Intelligence, it is augmented with the capability to harness external traffic analysis packages based on existing conversations. Marking its distinction, Open-TI is the first method capable of conducting exhaustive traffic analysis from scratch - spanning from map data acquisition to the eventual execution in complex simulations. Besides, Open-TI is able to conduct task-specific embodiment like training and adapting the traffic signal control policies (TSC), explore demand optimizations, etc. Furthermore, we explored the viability of LLMs directly serving as control agents, by understanding the expected intentions from Open-TI, we designed an agent-to-agent communication mode to support Open-TI conveying messages to ChatZero (control agent), and then the control agent would choose from the action space to proceed the execution. We eventually provide the formal implementation structure, and the open-ended design invites further community-driven enhancements.",[''],"['*', '[']"
"The networked nature of multi-robot systems presents challenges in the context of multi-agent reinforcement learning.
Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots,
exhibiting poor performance in cooperative-competitive tasks. In this work we propose a physics-informed reinforcement learning approach able to learn distributed multi-robot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions.
Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor-critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multi-robot scenarios demonstrate the success of the proposed approach, surpassing previous multi-robot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to ×2absent2\times 2× 2 greater than the state-of-the-art with robot teams ×6absent6\times 6× 6 larger than the number of robots at training time).","['Index', 'Terms: ', 'Cooperative control, distributed systems, multi-robot systems, physics-informed neural networks, reinforcement learning.']",[]
"In the present work we revisit the problem
of the quantum droplet in atomic Bose-Einstein
condensates with an eye towards describing
its ground state in the large density, so-called
Thomas-Fermi limit. We consider the problem
as being separable into 3 distinct regions:
an inner one, where the Thomas-Fermi approximation
is valid, a sharp transition region where the
density abruptly drops towards the (vanishing)
background value and an outer region which
asymptotes to the background value.
We analyze the spatial extent of each of these
regions, and develop a systematic effective
description of the rapid intermediate transition
region. Accordingly, we derive a uniformly
valid description of the ground state that
is found to very accurately match our
numerical computations. As an additional application
of our considerations, we show that this formulations
allows for an analytical approximation of excited
states such as the (trapped) dark soliton in the large density
limit.",[''],"['USA', 'USA', 'USA']"
"Understanding the evolution of cooperation is pivotal in biology and social science. Public resources sharing is a common scenario in the real world. In our study, we explore the evolutionary dynamics of cooperation on a regular graph with degree k𝑘kitalic_k, introducing the presence of a third strategy, namely the benevolence, who does not evolve over time, but provides a fixed benefit to all its neighbors. We find that the presence of the benevolence can foster the development of cooperative behavior and it follows a simple rule: b/c>k−pS⁢(k−1)𝑏𝑐𝑘subscript𝑝𝑆𝑘1b/c>k-p_{S}(k-1)italic_b / italic_c > italic_k - italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_k - 1 ). Our results provide new insights into the evolution of cooperation in structured populations.",[''],[]
"Let p𝑝pitalic_p and q𝑞qitalic_q be two distinct odd primes, p<q𝑝𝑞p<qitalic_p < italic_q and Ep,q:y2=x3−p⁢q⁢x:subscript𝐸𝑝𝑞superscript𝑦2superscript𝑥3𝑝𝑞𝑥E_{p,q}:y^{2}=x^{3}-pqxitalic_E start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT : italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_x start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT - italic_p italic_q italic_x be an elliptic curve. Fix a line La.b:y=ab⁢x:subscript𝐿formulae-sequence𝑎𝑏𝑦𝑎𝑏𝑥L_{a.b}:y=\frac{a}{b}xitalic_L start_POSTSUBSCRIPT italic_a . italic_b end_POSTSUBSCRIPT : italic_y = divide start_ARG italic_a end_ARG start_ARG italic_b end_ARG italic_x where a∈ℤ,b∈ℕformulae-sequence𝑎ℤ𝑏ℕa\in\mathbb{Z},b\in\mathbb{N}italic_a ∈ blackboard_Z , italic_b ∈ blackboard_N and (a,b)=1𝑎𝑏1(a,b)=1( italic_a , italic_b ) = 1. We study sufficient conditions that p𝑝pitalic_p and q𝑞qitalic_q must satisfy so that there are infinitely many elliptic curves Ep,qsubscript𝐸𝑝𝑞E_{p,q}italic_E start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT that intersect La,bsubscript𝐿𝑎𝑏L_{a,b}italic_L start_POSTSUBSCRIPT italic_a , italic_b end_POSTSUBSCRIPT.","['Key words and phrases:', 'Elliptic', 'Curves,', 'Rational', 'Points']",[]
"With Wilson quarks, on-shell O(a𝑎aitalic_a) improvement of the lattice QCD action is achieved by including
the Sheikholeslami-Wohlert term and two further operators of mass dimension 5,
which amount to a mass-dependent rescaling of the bare parameters. We here focus on the rescaled bare coupling,
g~02=g02⁢(1+bg⁢a⁢mq)superscriptsubscript~𝑔02superscriptsubscript𝑔021subscript𝑏g𝑎subscript𝑚q{\tilde{g}_{0}^{2}}=g_{0}^{2}(1+b_{\rm g}am_{\rm q})over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 1 + italic_b start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT italic_a italic_m start_POSTSUBSCRIPT roman_q end_POSTSUBSCRIPT ), and the determination of bg⁢(g02)subscript𝑏gsuperscriptsubscript𝑔02b_{\rm g}(g_{0}^{2})italic_b start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT ( italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), which is currently only known
to 1-loop order of perturbation theory. We derive suitable improvement conditions in the chiral limit and
in a finite space-time volume and evaluate these for different pure gauge observables, both with and without the gradient flow.
The choice of β𝛽\betaitalic_β-values and the line of constant physics are motivated by the ALPHA collaboration’s
decoupling strategy to determine αs⁢(mZ)subscript𝛼𝑠subscript𝑚𝑍\alpha_{s}(m_{Z})italic_α start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPT ) [1]. However,
the improvement conditions and some insight into systematic effects may prove useful in other contexts, too.",[''],[]
"The problem of packing a set of circles into the smallest surrounding container is considered. This problem arises in different application areas such as automobile, textile, food, and chemical industries. The so-called circle packing problem can be cast as a nonconvex quadratically constrained program, and is difficult to solve in general. An iterative solution approach based on a bisection-type algorithm on the radius of the larger circle is provided. The present algorithm discretizes the container into small cells and solves two different integer linear programming formulations proposed for a restricted and a relaxed version of the original problem. The present algorithm is enhanced with solution space reduction, bound tightening and variable elimination techniques. Then, a computational study is performed to evaluate the performance of the algorithm. The present algorithm is compared with BARON and Gurobi that solve the original nonlinear formulation and heuristic methods from literature, and obtain promising results.",[''],['34956']
"We show that, contrary to the claim by Kumar [Phys. Rev. A 96, 012332 (2017)], the quantum dual total correlation of an n𝑛nitalic_n-partite quantum state cannot be represented as the quantum relative entropy between n−1𝑛1n-1italic_n - 1 copies of the quantum state and the product of n𝑛nitalic_n different reduced quantum states for n≥3𝑛3n\geq 3italic_n ≥ 3. Specifically, we argue that the latter fails to yield a finite value for generalized n𝑛nitalic_n-partite Greenberger-Horne-Zeilinger states.",[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Korea']"
"This paper proposes an alternative regularization method for handling the ultraviolet behavior of entanglement entropy. Utilizing an i⁢ϵ𝑖italic-ϵi\epsilonitalic_i italic_ϵ prescription in the Euclidean double cone geometry, it accurately reproduces the universal behavior of entanglement entropy. The method is demonstrated in the free boson theory in arbitrary dimensions and two-dimensional conformal field theories.
The findings highlight the effectiveness of the i⁢ϵ𝑖italic-ϵi\epsilonitalic_i italic_ϵ regularization method in addressing ultraviolet issues in quantum field theory and gravity, suggesting potential applications to other calculable quantities.",[''],[]
"Atacama Large Millimeter/Submillimeter Array (ALMA) has revolutionized the field of dust polarization in protoplanetary disks across multiple wavelengths. Previous observations and empirical modeling suggested multiple mechanisms of dust polarization toward HL Tau, including grain alignment and dust scattering. However, a detailed modeling of dust polarization based on grain alignment physics is not yet available. Here, using our updated POLARIS code, we perform numerical modeling of dust polarization arising from both grain alignment by Magnetically Enhanced Radiative Torque (MRAT) mechanism and self-scattering to reproduce the HL Tau polarization observed at three wavelengths 0.87, 1.3, and 3.1 mm. Our modeling results show that the observed multi-wavelength polarization could be reproduced only when large grains contain embedded iron inclusions and those with slow internal relaxation must have wrong internal alignment (i.e., the grain’s major axis parallel to its angular momentum). The abundance of iron embedded inside grains in the form of clusters is constrained to be ≳16greater-than-or-equivalent-toabsent16\gtrsim 16≳ 16%, and the number of iron atoms per cluster is Ncl∼2×103similar-tosubscript𝑁cl2superscript103N_{\rm cl}\sim 2\times 10^{3}italic_N start_POSTSUBSCRIPT roman_cl end_POSTSUBSCRIPT ∼ 2 × 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Maximum grain sizes probed at wavelengths λ𝜆\lambdaitalic_λ = 0.87, 1.3, and 3.1 mm are constrained at ∼similar-to\sim∼ 60, 90, and 130μ𝜇\,\muitalic_μm, respectively. Assuming a dust differential settling effect with grain sizes from the constraint gives the value of maximum grain size at the disk mid-plane to be millimeter-scaled.","['Protoplanetary disks;', 'Polarimetry;', 'Radio astronomy;', 'Circumstellar dust;', 'Magnetic field']","['Vietnam', 'Vietnam', 'Vietnam', 'Vietnam', 'Korea', 'Korea', 'Germany', 'Vietnam', 'Vietnam', 'Vietnam', 'Vietnam', 'Korea', 'Korea']"
"Patient-to-room assignment (PRA) is a scheduling problem in decision support for large hospitals. This work proposes Integer Programming (IP) formulations for dynamic PRA, where either full, limited or uncertain information on incoming patients is available. The applicability is verified through a computational study. Results indicate that large, real world instances can be solved to a high degree of optimality within (fractions of) seconds. Furthermore, different objectives are considered to ensure validity across varying practical requirements. So far, previous approaches for IP in PRA have only been applicable for small instances or special cases. Subsequently, we show that the modelling of gender conflicts and transfers are crucial modelling choices that determine whether the corresponding IPs are solvable in reasonable time.",[''],['*']
"A muonium consists of a positive muon associated with an orbital electron, and the spontaneous conversion to antimuonium serves as a clear indication of new physics beyond the Standard Model in particle physics.
One of the most important aspects in muonium-to-antimuonium conversion experiment (MACE) is to increase the muonium yield in vacuum to challenge the latest limit obtained in 1999.
This study focuses on a simulation of the muonium formation and diffusion in the perforated silica aerogel.
The independent simulation results can be well validated by experimental data.
By optimizing the target geometry, we find a maximum muonium emission efficiency of 7.92⁢(2)%7.92percent27.92(2)\%7.92 ( 2 ) % and a maximum vacuum yield of 1.134⁢(2)%1.134percent21.134(2)\%1.134 ( 2 ) % with a typical surface muon beam, indicating a 2.6 times and a 2.1 times enhancement, respectively.
Our results will pave the way for muonium experiments.",[''],['China']
"With a motive of ubiquitous connectivity over the globe with enhanced spectral efficiency, intelligent reflecting surfaces (IRS) integrated satellite-terrestrial communications is a topic of research interest in an infrastructure-deficient remote terrains. In line with this vision, this paper entails the performance analysis of satellite-terrestrial networks leveraging both aerial and terrestrial IRS nodes, with the support of high altitude platforms over diverse fading channels including shadowed Rician, Rician, and Nakagami-m𝑚mitalic_m fading channels. The merits of IRS in enhancing spectral efficiency is analyzed through closed-form expressions of outage probability and ergodic rate. Further, the average symbol error rate analysis for the higher-order quadrature amplitude modulation (QAM) schemes such as hexagonal QAM, rectangular QAM, cross QAM, and square QAM is performed. Practical constraints like antenna gains, path loss, and link fading are considered to characterize the satellite terrestrial links. Finally, a comparison between the high-altitude platforms based IRS node and terrestrial IRS nodes is performed and various insights are drawn under various fading scenarios and path loss conditions. This paper contribute towards understanding and potential implementation of IRS-integrated satellite-terrestrial networks for efficient and reliable communication.","['Index', 'Terms: \n', 'IRS,', 'HAP,', 'Nakagami-m𝑚mitalic_m,', 'Rician, shadowed', 'Rician, ergodic rate,', 'HQAM,', 'RQAM,', 'XQAM.']",[]
"We investigate edge and bulk states in Weyl-orbit based quantum Hall effect by measuring a Corbino-type device fabricated from a topological Dirac semimetal (Cd1−x1𝑥{}_{1-x}start_FLOATSUBSCRIPT 1 - italic_x end_FLOATSUBSCRIPTZnx𝑥{}_{x}start_FLOATSUBSCRIPT italic_x end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTAs22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT film.
Clear quantum Hall plateaus are observed when measuring one-sided terminals of the Corbino-type device.
This indicates that edge states of the Weyl-orbit quantum Hall effect form closed trajectories consisting of Fermi arcs and chiral zero modes independently on inner and outer sides.
On the other hand, the bulk resistance does not diverge at fields where the quantum Hall plateau appears, suggesting that the Weyl orbits in the bulk region are not completely localized when applying electric current through the bulk region.",[''],"['Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan']"
,[''],[]
"The intrinsic resolution is the primary limitation on the total energy resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal. This intrinsic resolution arises from two effects: fluctuations occurring in the process of energy transfer to luminescent centers within the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal and the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal’s non-proportional luminescence. Presently, experimental measurements regarding the intrinsic resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal are scarce, and the underlying physical mechanisms remain incompletely understood. In this paper, we aim to elucidate the concept of intrinsic resolution. We investigated the entire physical process of luminescence following energy deposition in the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal, quantifying the various components in the total energy resolution. We conducted a series of experimental measurements and Geant4 simulations, determining the intrinsic resolution of LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) crystal to 100 keV electrons as 2.12%. The non-proportionality contributes significantly at 1.43%, while fluctuations in the energy transfer process accounted for 0.27%. It is evident that non-proportionality in light output constitutes the primary source of intrinsic resolution. Horizontal and vertical unevenness in light collection contributed 0.25% and 0.07%, respectively. Statistical fluctuations showed the largest impact on the total energy resolution, at 2.86%. The contribution from fluctuations in single-photoelectron events was 0.77%. Furthermore, we reconstructed the photon response using Geant4, and the consistency between the simulated relative light yield and the experimentally measured one confirmed the reliability of the LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) detector mass model employed in the simulation.","['LaBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT(Ce) detector,', 'Energy', 'Response,', 'Intrinsic', 'Resolution,', 'Non-proportional', 'Light', 'Yield,', 'Energy', 'Transfer', 'Process']","['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
"This paper presents a parallel-in-time multilevel iterative method for solving differential algebraic equation, arising from a discretization of linear time-dependent partial differential equation. The core of the method is the multilevel Krylov method, introduced by Erlangga and Nabben [SIAM J. Sci. Comput., 30(2008), pp. 1572–1595]. In the method, special time restriction and interpolation operators are proposed to coarsen the time grid and to map functions between fine and coarse time grids. The resulting Galerkin coarse-grid system can be interpreted as time integration of an equivalent differential algebraic equation associated with a larger time step and a modified θ𝜃\thetaitalic_θ-scheme. A perturbed coarse time-grid matrix is used on the coarsest level to decouple the coarsest-level system, allowing full parallelization of the method. Within this framework, spatial coarsening can be included in a natural way, reducing further the size of the coarsest grid problem to solve. Numerical results are presented for the 1- and 2-dimensional heat equation using simulated parallel implementation, suggesting the potential computational speed-up of up to 9 relative to the single-processor implementation and the speed-up of about 3 compared to the sequential θ𝜃\thetaitalic_θ-scheme.",[''],[]
"Thermal leptogenesis is a mechanism that explains the observed asymmetry between matter and antimatter in the early universe. In this study, we review the impact of nonextensive Tsallis statistical mechanics on the early universe and study its effect on thermal leptogenesis. The study has found that the use of nonextensive statistical mechanics can affect the production of baryon asymmetry in thermal leptogenesis by modifying the equilibrium abundance of particles, decay, and washout parameters. Also, we show that nonextensive statistical mechanics potentially reduce the required right-handed neutrino mass scale.",[''],['Iran']
"In the domain of multivariate forecasting, transformer models stand out as powerful apparatus, displaying exceptional capabilities in handling messy datasets from real-world contexts. However, the inherent complexity of these datasets, characterized by numerous variables and lengthy temporal sequences, poses challenges, including increased noise and extended model runtime. This paper focuses on reducing redundant information to elevate forecasting accuracy while optimizing runtime efficiency. We propose a novel transformer forecasting framework enhanced by Principal Component Analysis (PCA) to tackle this challenge. The framework is evaluated by five state-of-the-art (SOTA) models and four diverse real-world datasets. Our experimental results demonstrate the framework’s ability to minimize prediction errors across all models and datasets while significantly reducing runtime. From the model perspective, one of the PCA-enhanced models: PCA+Crossformer, reduces mean square errors (MSE) by 33.3% and decreases runtime by 49.2% on average. From the dataset perspective, the framework delivers 14.3% MSE and 76.6% runtime reduction on Electricity datasets, as well as 4.8% MSE and 86.9% runtime reduction on Traffic datasets. This study aims to advance various SOTA models and enhance transformer-based time series forecasting for intricate data.",[''],[]
"Comets would have amorphous ice rather than crystalline one at the epoch of their accretion.
Cometary ice contains some impurities that govern the latent heat of ice crystallization, Lcrysubscript𝐿cryL_{\rm cry}italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT.
However, it is still controversial whether the crystallization process is exothermic or endothermic.
In this study, we perform one-dimensional simulations of the thermal evolution of km-sized comets and investigate the effect of the latent heat.
We find that the depth where amorphous ice can survive significantly depends on the latent heat of ice crystallization.
Assuming the cometary radius of 2⁢km2km2~{}$\mathrm{k}\mathrm{m}$2 roman_km, the depth of the amorphous ice mantle is approximately 100⁢m100m100~{}$\mathrm{m}$100 roman_m when the latent heat is positive (i.e., the exothermic case with Lcry=+9×104⁢J⁢kg−1subscript𝐿cry9superscript104Jsuperscriptkg1L_{\rm cry}=+9\times 10^{4}~{}$\mathrm{J}\,\mathrm{k}\mathrm{g}^{-1}$italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT = + 9 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT roman_J roman_kg start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT).
In contrast, when we consider the impure ice representing the endothermic case with Lcry=−9×104⁢J⁢kg−1subscript𝐿cry9superscript104Jsuperscriptkg1L_{\rm cry}=-9\times 10^{4}~{}$\mathrm{J}\,\mathrm{k}\mathrm{g}^{-1}$italic_L start_POSTSUBSCRIPT roman_cry end_POSTSUBSCRIPT = - 9 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT roman_J roman_kg start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, the depth of the amorphous ice mantle could exceed 1⁢km1km1~{}$\mathrm{k}\mathrm{m}$1 roman_km.
Although our numerical results indicate that these depths depend on the size and the accretion age of comets, the depth in a comet with the negative latent heat is a few to several times larger than the positive case for a given comet size.
This work suggests that the spatial distribution of the ice crystallinity in a comet nucleus depends on the latent heat, which can be different from the previous estimates assuming pure water ice.",[''],[]
"Low-dose \acET plays a crucial role in medical imaging, enabling the acquisition of functional information for various biological processes while minimizing the patient dose. However, the inherent randomness in the photon counting process is a source of noise which is amplified low-dose \acET. This review article provides an overview of existing post-processing techniques, with an emphasis on deep \acNN approaches. Furthermore, we explore future directions in the field of \acNN-based low-dose \acET. This comprehensive examination sheds light on the potential of deep learning in enhancing the quality and resolution of low-dose \acET images, ultimately advancing the field of medical imaging.","['Index', 'Terms: ', 'Low-Dose,', 'PET,', 'SPECT,', 'Deep', 'Learning']",[]
"A conducting cylinder with a central source of electrons, in a uniform magnetic field along its axis,
and radial temperature gradient, is considered at the stationary state.
Interaction of heat flux, magnetic field and charge distribution is discussed.
Four different models are considered, regarding of the electronic supply and possibility of electrons to leave the cylinder.",[''],[]
"We describe an experiment to measure the electromagnetic analog of gravitational wave memory, the so-called electromagnetic memory. Whereas gravitational wave memory is a residual displacement of test masses, electromagnetic memory is a residual velocity (i.e. kick) of test charges.
The source of gravitational wave memory is energy that is not confined to any bounded spatial region: in the case of binary black hole mergers the emitted energy of gravitational radiation as well as the recoil energy of the final black hole. Similarly, electromagnetic memory requires a source whose charges are not confined to any bounded spatial region.
While particle beams can provide unbounded charges, their currents are too small to be practical for such an experiment. Instead we propose a short microwave pulse applied to the center of a long dipole antenna. In this way the measurement of the kick can be done quickly enough that the finite size of the antenna does not come into play and it acts for our purposes the same as if it were an infinite antenna.",[''],[]
"We derive new estimates on analytic capacities of finite sequences
in the unit disc in Besov spaces with zero smoothness, which
sharpen the estimates obtained by N. K. Nikolski in 2005
and, for a range of parameters, are optimal.
The work is motivated both from the perspective of complex analysis by the description of sets of
zeros/uniqueness, and from the one of matrix analysis/operator theory
by estimates on norms of inverses.",[''],[]
,[''],[]
"Wind turbines are subjected to continuous rotational stresses and unusual external forces such as storms, lightning, strikes by flying objects, etc., which may cause defects in turbine blades. Hence, it requires a periodical inspection to ensure proper functionality and avoid catastrophic failure. The task of inspection is challenging due to the remote location and inconvenient reachability by human inspection. Researchers used images with cropped defects from the wind turbine in the literature. They neglected possible background biases, which may hinder real-time and autonomous defect detection using aerial vehicles such as drones or others. To overcome such challenges, in this paper, we experiment with defect detection accuracy by having the defects with the background using a two-step deep-learning methodology. In the first step, we develop virtual models of wind turbines to synthesize the near-reality images for four types of common defects - cracks, leading edge erosion, bending, and light striking damage. The Unity® perception package is used to generate wind turbine blade defects images with variations in background, randomness, camera angle, and light effects. In the second step, a customized U-Net architecture is trained to classify and segment the defect in turbine blades. The outcomes of U-Net architecture have been thoroughly tested and compared with 5-fold validation datasets. The proposed methodology provides reasonable defect detection accuracy, making it suitable for autonomous and remote inspection through aerial vehicles.
Keywords Defect Detection, Virtual Reality, Deep Learning, U-Net, Segmentation",[''],"['USA', 'USA', 'Bangladesh', 'USA', 'Bangladesh', 'Taiwan', 'USA']"
"In this short paper, we examine the main metrics used to evaluate textual coreference and we detail some of their limitations. We show that a unique score cannot represent the full complexity of the problem at stake, and is thus uninformative, or even misleading. We propose a new way of evaluating coreference, taking into account the context (in our case, the analysis of fictions, esp. novels). More specifically, we propose to distinguish long coreference chains (corresponding to main characters), from short ones (corresponding to secondary characters), and singletons (isolated elements). This way, we hope to get more interpretable and thus more informative results through evaluation.",[''],[]
"Exploring the physics of low-dimensional spin systems and their pressure-driven electronic and magnetic transitions are thriving research field in modern condensed matter physics. In this context, recently antiferromagnetic Cr-based compounds such as CrI33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, CrBr33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT, CrGeTe33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT have been investigated experimentally and theoretically for their possible spintronics applications. Motivated by the fundamental and industrial importance of these materials, we theoretically studied the electronic and magnetic properties of a relatively less explored Cr-based chalcogenide, namely LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT where 2D layers of magnetic Cr3+limit-from3{}^{3+}start_FLOATSUPERSCRIPT 3 + end_FLOATSUPERSCRIPT ions form a rectangular lattice. We employed density functional theory + Hubbard U𝑈Uitalic_U approach in conjunction with constrained random-phase approximation (cRPA) where the later was used to estimate the strength of U𝑈Uitalic_U. Our findings at ambient pressure show that the system exhibits semiconducting antiferromagnetic ground state with a gap of 0.5 eV and large Cr moments that corresponds to nominal S=3/2 spin-state. The 1st nearest neighbor (NN) interatomic exchange coupling (J11{}_{1}start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT) is found to be strongly antiferromagnetic (AFM), while 2nd NN couplings are relatively weaker ferromagnetic (FM), making this system a candidate for 1D non-frustrated antiferromagnetic spin-chain family of materials. Based on orbital resolved interactions, we demonstrated the reason behind two different types of interactions among 1st and 2nd NN despite their very similar bond lengths. We observe a significant spin-orbit coupling effect, giving rise to a finite magneto crystalline anisotropy, and Dzyaloshinskii-Moriya (DM) interaction. Further, we found that by applying uniaxial tensile strain along crystallographic a𝑎aitalic_a and b𝑏bitalic_b-axis, LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT exhibits a magnetic transition to a semi-conducting FM ground state, while compression gives rise to the realization of novel gapless semiconducting antiferromagnetic ground state. Thus, our findings can enrich the versatility of LaCrS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT and make it a promising candidate for industrial applications.",[''],"['India', 'India', 'India']"
"We revisit the study of the violation of the Leggett-Garg inequality in neutrino oscillation data as a mean to test some of the fundamental aspects of quantum mechanics. In particular, we consider the results by the Daya Bay and RENO reactor experiments, and the MINOS and NOvA accelerator experiments. We find that DB and MINOS exhibit a strong manifestation of Leggett-Garg violation, while for RENO and NOvA data the indication is weaker. Considering the particular baselines and energy ranges explored by each experiment, our results demonstrate that the Leggett-Garg violation is more evident for smaller baseline-to-energy ratio in all the data sets considered, a relevant aspect to be considered when searching for evidences of quantum mechanical decoherence on neutrino oscillations.",[''],['\\countryColombia']
,[''],[]
"Direct imaging of Earth-like exoplanets is one of the most prominent scientific drivers of the next generation of ground-based telescopes. Typically, Earth-like exoplanets are located at small angular separations from their host stars, making their detection difficult. Consequently, the adaptive optics (AO) system’s control algorithm must be carefully designed to distinguish the exoplanet from the residual light produced by the host star.
A new promising avenue of research to improve AO control builds on data-driven control methods such as Reinforcement Learning (RL). RL is an active branch of the machine learning research field, where control of a system is learned through interaction with the environment. Thus, RL can be seen as an automated approach to AO control, where its usage is entirely a turnkey operation. In particular, model-based reinforcement learning (MBRL) has been shown to cope with both temporal and misregistration errors. Similarly, it has been demonstrated to adapt to non-linear wavefront sensing while being efficient in training and execution.
In this work, we implement and adapt an RL method called Policy Optimization for AO (PO4AO) to the GHOST test bench at ESO headquarters, where we demonstrate a strong performance of the method in a laboratory environment. Our implementation allows the training to be performed parallel to inference, which is crucial for on-sky operation. In particular, we study the predictive and self-calibrating aspects of the method. The new implementation on GHOST running PyTorch introduces only around 700 µs of in addition to hardware, pipeline, and Python interface latency. We open-source well-documented code for the implementation and specify the requirements for the RTC pipeline. We also discuss the important hyperparameters of the method and how they affect the method. Further, the paper discusses the source of the latency and the possible paths for a lower latency implementation.",[''],"['Finland', 'Finland', 'Germany', 'Germany', 'Finland', 'Finland', 'Germany', 'France', 'France', 'Switzerland', 'Switzerland']"
"Reinforcement learning from human feedback (RLHF) emerges as a promising paradigm for aligning large language models (LLMs).
However, a notable challenge in RLHF is overoptimization, where beyond a certain threshold, the pursuit of higher rewards leads to a decline in human preferences.
In this paper, we observe the weakness of KL regularization which is commonly employed in existing RLHF methods to address overoptimization.
To mitigate this limitation, we scrutinize the RLHF objective in the offline dataset and propose uncertainty-penalized RLHF (UP-RLHF), which incorporates uncertainty regularization during RL-finetuning.
To enhance the uncertainty quantification abilities for reward models, we first propose a diverse low-rank adaptation (LoRA) ensemble by maximizing the nuclear norm of LoRA matrix concatenations.
Then we optimize policy models utilizing penalized rewards, determined by both rewards and uncertainties provided by the diverse reward LoRA ensembles.
Our experimental results, based on two real human preference datasets, showcase the effectiveness of diverse reward LoRA ensembles in quantifying reward uncertainty.
Additionally, uncertainty regularization in UP-RLHF proves to be pivotal in mitigating overoptimization, thereby contributing to the overall performance.","['Machine', 'Learning,', 'ICML']",[]
,[''],[]
"Many statistical problems require estimating a density function, say f𝑓fitalic_f, from data samples. In this work, for example, we are interested in highest-density regions (HDRs), i.e., minimum volume sets that contain a given probability. HDRs are typically computed using a density quantile approach, which, in the case of unknown densities, involves their estimation. This task turns out to be far from trivial, especially over increased dimensions and when data are sparse and exhibit complex structures (e.g., multimodalities or particular dependencies).
We address this challenge by exploring alternative approaches to build HDRs that overcome direct (multivariate) density estimation. First, we generalize the density quantile method–currently implementable on the basis of a consistent estimator of the density–to neighbourhood measures, i.e., measures that preserve the order induced in the sample by f𝑓fitalic_f. Second, we discuss a number of suitable probabilistic- and distance-based measures such as the k𝑘kitalic_k-nearest neighbourhood Euclidean distance. Third, motivated by the ubiquitous role of copula modeling in modern statistics, we explore its use in the context of probabilistic-based measures. An extensive comparison among the introduced measures is provided, and their implications for computing HDRs in real-world problems are discussed.",[''],[]
"Large language models (LLMs) have made significant advancements in natural language processing and are concurrently extending the language ability to other modalities, such as speech and vision. Nevertheless, most of the previous work focuses on prompting LLMs with perception abilities like auditory comprehension, and the effective approach for augmenting LLMs with speech synthesis capabilities remains ambiguous. In this paper, we conduct a comprehensive empirical exploration of boosting LLMs with the ability to generate speech, by combining pre-trained LLM LLaMA/OPT and text-to-speech synthesis model VALL-E. We compare three integration methods between LLMs and speech synthesis models, including directly fine-tuned LLMs, superposed layers of LLMs and VALL-E, and coupled LLMs and VALL-E using LLMs as a powerful text encoder. Experimental results show that, using LoRA method to fine-tune LLMs directly to boost the speech synthesis capability does not work well, and superposed LLMs and VALL-E can improve the quality of generated speech both in speaker similarity and word error rate (WER). Among these three methods, coupled methods leveraging LLMs as the text encoder can achieve the best performance, making it outperform original speech synthesis models with a consistently better speaker similarity and a significant (10.9%) WER reduction.",[''],[]
"Numerical simulations can model the physical processes that govern cardiovascular device deployment. When such simulations incorporate digital twins; computational models of patient-specific anatomy, they can expedite and de-risk the device design process. Nonetheless, the exclusive use of patient-specific data constrains the anatomic variability which can be precisely or fully explored. In this study, we investigate the capacity of Latent Diffusion Models (LDMs) to edit digital twins to create anatomic variants, which we term digital siblings. Digital twins and their corresponding siblings can serve as the basis for comparative simulations, enabling the study of how subtle anatomic variations impact the simulated deployment of cardiovascular devices, as well as the augmentation of virtual cohorts for device assessment. However, while diffusion models have been characterized in their ability to edit natural images, their capacity to anatomically edit digital twins has yet to be studied. Using a case example centered on 3D digital twins of cardiac anatomy, we implement various methods for generating digital siblings and characterize them through morphological and topological analyses. We specifically edit digital twins to introduce anatomic variation at different spatial scales and within localized regions, demonstrating the existence of bias towards common anatomic features. We further show that such anatomic bias can be leveraged for virtual cohort augmentation through selective editing, partially alleviating issues related to dataset imbalance and lack of diversity. Our experimental framework thus delineates the limits and capabilities of using latent diffusion models in synthesizing anatomic variation for in silico trials.",[''],[]
"Segmenting any object represents a crucial step towards achieving artificial general intelligence, and the ”Segment Anything Model” (SAM) has significantly advanced the development of foundational models in computer vision. We have high expectations regarding whether SAM can enhance highly accurate dichotomous image segmentation. In fact, the evidence presented in this article demonstrates that by inputting SAM with simple prompt boxes and utilizing the results output by SAM as input for IS5Net, we can greatly improve the effectiveness of highly accurate dichotomous image segmentation.","['Index', 'Terms: ', 'Segment', 'Anything', 'Model,', 'SAM, highly accurate dichotomous image segmentation,', 'DIS.']",[]
"Forecasting a key macroeconomic variable, consumer price index (CPI) inflation, for BRIC countries using economic policy uncertainty and geopolitical risk is a difficult proposition for policymakers at the central banks. This study proposes a novel filtered ensemble wavelet neural network (FEWNet) that can produce reliable long-term forecasts for CPI inflation. The proposal applies a maximum overlapping discrete wavelet transform to the CPI inflation series to obtain high-frequency and low-frequency signals. All the wavelet-transformed series and filtered exogenous variables are fed into downstream autoregressive neural networks to make the final ensemble forecast. Theoretically, we show that FEWNet reduces the empirical risk compared to single, fully connected neural networks. We also demonstrate that the rolling-window real-time forecasts obtained from the proposed algorithm are significantly more accurate than benchmark forecasting methods. Additionally, we use conformal prediction intervals to quantify the uncertainty associated with the forecasts generated by the proposed approach.
The excellent performance of FEWNet can be attributed to its capacity to effectively capture non-linearities and long-range dependencies in the data through its adaptable architecture.",[''],[]
"For the first time, we estimate the in-medium mass shift of
the two-flavored heavy mesons Bc,Bc*,Bs,Bs*,Dssubscript𝐵𝑐superscriptsubscript𝐵𝑐subscript𝐵𝑠superscriptsubscript𝐵𝑠subscript𝐷𝑠B_{c},B_{c}^{*},B_{s},B_{s}^{*},D_{s}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT , italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT and Ds*superscriptsubscript𝐷𝑠D_{s}^{*}italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT in symmetric nuclear
matter. The estimates are made by evaluating the lowest order one-loop self-energies.
The enhanced excitations of intermediate state
heavy-light mesons in symmetric nuclear matter are the origin of their negative mass shift.
Our results show that the magnitude of the mass shift for the Bcsubscript𝐵𝑐B_{c}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT meson (b¯⁢c¯𝑏𝑐\bar{b}cover¯ start_ARG italic_b end_ARG italic_c or b⁢c¯𝑏¯𝑐b\bar{c}italic_b over¯ start_ARG italic_c end_ARG)
is larger than
those of the ηc⁢(c¯⁢c)subscript𝜂𝑐¯𝑐𝑐\eta_{c}(\bar{c}c)italic_η start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( over¯ start_ARG italic_c end_ARG italic_c ) and ηb⁢(b¯⁢b)subscript𝜂𝑏¯𝑏𝑏\eta_{b}(\bar{b}b)italic_η start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ( over¯ start_ARG italic_b end_ARG italic_b ),
different from a naive expectation that it would
be in-between of them.
While, that of the Bc*superscriptsubscript𝐵𝑐B_{c}^{*}italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT shows the in-between of the J/ψ𝐽𝜓J/\psiitalic_J / italic_ψ and ΥΥ\Upsilonroman_Υ.
We observe that the lighter vector meson excitation
in each meson self-energy gives a dominant contribution for the corresponding meson mass shift,
Bc,Bs,subscript𝐵𝑐subscript𝐵𝑠B_{c},B_{s},italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , and Dssubscript𝐷𝑠D_{s}italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT.",[''],"['Brazil', 'Brazil', 'Brazil']"
"Nanoparticle-Enhanced Phase Change Materials (NePCM) have been a subject of intensive research owing to their potential for enhanced thermo-physical properties. However, their behavior during phase change processes, such as melting or solidification, remains inadequately understood. This investigation focuses on the melting process of NePCM in a square cavity, exploring distinct cases of melting from both the top and bottom sides. The NePCM comprises copper nanoparticles (2 nm in size) suspended in water. Our study involves different combinations of constant temperature boundary conditions and particle volume fractions. Utilizing a numerical model based on the one-fluid mixture approach combined with the single-domain enthalpy-porosity model, we account for the phase change process and particles’ interaction with the solid-liquid interface. When melting NePCM from the top side, convection effects are suppressed, resulting in a melting process primarily governed by conduction. Both NePCM and pure water melt at the same rate under these conditions. However, melting NePCM from the bottom side induces convection-dominated melting. For pure water, thermal convection leads to the formation of convection cells during melting. Contrastingly, melting NePCM triggers thermosolutal convection due to temperature and particle concentration gradients. The flow cells formed from thermosolutal convection in NePCM differ from those in pure water driven by pure thermal convection. Our simulations reveal that thermosolutal convection contributes to decelerating the solid-liquid interface, thereby prolonging NePCM melting compared to pure water. Surprisingly, the viscosity increase in NePCM plays a minimal role in the deceleration process, contrary to prior literature attributing slow-downs of the melting process of the NePCM primarily to increased viscosity.",[''],[]
"Motivated by recent developments in the construction of Newton–Okounkov bodies and toric degenerations via cluster algebras in [GHKK18, FO20], we consider a family of Newton–Okounkov polytopes of a complex smooth Fano variety X𝑋Xitalic_X related by a composition of tropicalized cluster mutations. According to the work of [HK15], the toric degeneration associated with each Newton–Okounkov polytope ΔΔ\Deltaroman_Δ in the family produces a Lagrangian torus fibration of X𝑋Xitalic_X over ΔΔ\Deltaroman_Δ. We investigate circumstances in which each Lagrangian torus fibration possesses a monotone Lagrangian torus fiber. We provide a sufficient condition, based on the data of tropical integer points and exchange matrices, for the family of constructed monotone Lagrangian tori to contain infinitely many monotone Lagrangian tori, no two of which are related by any symplectomorphisms. By employing this criterion and exploiting the correspondence between the tropical integer points and the dual canonical basis elements, we generate infinitely many distinct monotone Lagrangian tori on flag manifolds of arbitrary type except in a few cases.",[''],[]
"Let [n]:={1,2,…,n}assigndelimited-[]𝑛12…𝑛[n]:=\{1,2,\ldots,n\}[ italic_n ] := { 1 , 2 , … , italic_n }, and M𝑀Mitalic_M be a set of positive integers. We use ([n]M)binomialdelimited-[]𝑛𝑀\binom{\left[n\right]}{M}( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_M end_ARG ) to denote the family of all subsets of [n]delimited-[]𝑛[n][ italic_n ] whose sizes are in M𝑀Mitalic_M. The non-empty families 𝒜⊆([n]R)𝒜binomialdelimited-[]𝑛𝑅\mathcal{A}\subseteq\binom{\left[n\right]}{R}caligraphic_A ⊆ ( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_R end_ARG ) and ℬ⊆([n]S)ℬbinomialdelimited-[]𝑛𝑆\mathcal{B}\subseteq\binom{\left[n\right]}{S}caligraphic_B ⊆ ( FRACOP start_ARG [ italic_n ] end_ARG start_ARG italic_S end_ARG ) are said to be cross t𝑡titalic_t-intersecting if |A∩B|≥t𝐴𝐵𝑡|A\cap B|\geq t| italic_A ∩ italic_B | ≥ italic_t for all A∈𝒜𝐴𝒜A\in\mathcal{A}italic_A ∈ caligraphic_A and B∈ℬ𝐵ℬB\in\mathcal{B}italic_B ∈ caligraphic_B. In this paper, we determine the maximum sum of sizes of non-empty cross t𝑡titalic_t-intersecting families, and characterize the extremal families. We also prove similar results for finite vector spaces.

Key words: Erdős-Ko-Rado Theorem; non-empty cross t𝑡titalic_t-intersecting; finite sets ; vector spaces",[''],[]
"Masked Image Modeling (MIM) arises as a promising option for Vision Transformers among various self-supervised learning (SSL) methods. The essence of MIM lies in token-wise masked patch predictions, with targets patchified from images; or generated by pre-trained tokenizers or models. We argue targets from the pre-trained models usually exhibit spatial inconsistency, which makes it excessively challenging for the model to follow to learn more discriminative representations. To mitigate the issue, we introduce a novel self-supervision signal based on Dynamic Token Morphing (DTM), which dynamically aggregates contextually related tokens. DTM can be generally applied to various SSL frameworks, yet we propose a simple MIM that employs DTM to effectively improve the performance barely introducing extra training costs. Our experiments on ImageNet-1K and ADE20K evidently demonstrate the superiority of our methods. Furthermore, the comparative evaluation of iNaturalist and Fine-grained Visual Classification datasets further validates the transferability of our method on various downstream tasks. Our code will be released publicly.",[''],[]
"The Wilcoxon signed-rank test and the Wilcoxon-Mann-Whitney test are commonly employed in one sample and two sample mean tests for one-dimensional hypothesis problems. For high-dimensional mean test problems, we calculate the asymptotic distribution of the maximum of rank statistics for each variable and suggest a max-type test. This max-type test is then merged with a sum-type test, based on their asymptotic independence offered by stationary and strong mixing assumptions. Our numerical studies reveal that this combined test demonstrates robustness and superiority over other methods, especially for heavy-tailed distributions.",[''],[]
"We introduce hypergeometric-type sequences. They are linear combinations of interlaced hypergeometric sequences (of arbitrary interlacements). We prove that they form a subring of the ring of holonomic sequences. An interesting family of sequences in this class are those defined by trigonometric functions with linear arguments in the index and π𝜋\piitalic_π, such as Chebyshev polynomials, (sin2⁡(n⁢π/4)⋅cos⁡(n⁢π/6))nsubscript⋅superscript2𝑛𝜋4𝑛𝜋6𝑛\left(\sin^{2}\left(n\,\pi/4\right)\cdot\cos\left(n\,\pi/6\right)\right)_{n}( roman_sin start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_n italic_π / 4 ) ⋅ roman_cos ( italic_n italic_π / 6 ) ) start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, and compositions like (sin⁡(cos⁡(n⁢π/3)⁢π))nsubscript𝑛𝜋3𝜋𝑛\left(\sin\left(\cos(n\pi/3)\pi\right)\right)_{n}( roman_sin ( roman_cos ( italic_n italic_π / 3 ) italic_π ) ) start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT.
We describe an algorithm that computes a hypergeometric-type normal form of a given holonomic n⁢th𝑛thn\text{th}italic_n th term whenever it exists. Our implementation enables us to generate several identities for terms defined via trigonometric functions.","['Petkovšek’s algorithm', 'Hyper mfoldHyper', 'P-recursive sequences interlaced hypergeometric term m𝑚mitalic_m-fold indicator sequences']",[]
"There is a growing interest in the analysis of replication studies
of original findings
across many disciplines.
When testing a hypothesis for an effect size,
two Bayesian approaches stand out for their principled use of
the Bayes factor (BF), namely
the replication BF and the skeptical BF.
In particular, the latter BF
is based on the skeptical prior, which represents the
opinion of an investigator who is unconvinced by the
original findings and wants to challenge them.
We embrace the skeptical perspective, and elaborate a novel mixture prior which
incorporates skepticism while at the same time controlling for prior-data conflict within the original data.
Consistency properties of the resulting skeptical mixture BF are provided
together with an extensive analysis of the main features of our proposal.
Finally, we apply our methodology to
data from the Social Sciences Replication Project.
In particular we show that,
for some case studies
where prior-data conflict is an issue,
our method uses a more realistic prior and leads to
evidence-classification for replication success
which differs from the standard skeptical approach.",[''],[]
"Employing the projective formalism of determinant quantum Monte Carlo (DQMC) simulations, we meticulously explore the ground-state phase diagram and critical behavior of the half-filled Hubbard model on a square-hexagon-octagon (SHO) lattice. This lattice, a two-dimensional (2D) structure comprising squares, hexagons, and octagons, is representative of the biphenylene network (BPN). Our findings reveal an intriguing ground-state phase diagram, featuring an antiferromagnetic (AFM) Mott insulating phase enveloped by three valence-bond solid-like (VBS-like) insulating phases. Analyzing the single-particle gap, spin gap, and single-particle spectral function, we observe that the metallic state in the noninteracting case becomes unstable under the influence of Hubbard U𝑈Uitalic_U.
This interaction drives the system into a hexagon insulating phase before transitioning into an AFM Mott insulating phase. To quantify the critical exponents, we use finite-size scaling techniques. The critical exponents of quantum critical points between the AFM Mott insulating phase and two insulating phases, plaquette insulator and ethylene insulator, closely align with the 3D O(3) universality class. However, the critical exponents of quantum critical points between the hexagon insulating phase and the AFM Mott insulating phase deviate from the 3D O(3) universality class. This deviation is a finite-size effect and can be attributed to the coupling between the fluctuations of magnetic order parameter and very low-energy fermionic excitations. Our comprehensive study not only advances the understanding of correlation effects on the SHO lattice but also sheds light on the less-explored critical exponents in weakly insulating quantum critical point.",[''],"['China', 'China', 'China', 'China']"
,[''],"['China', 'China', 'China']"
"Over the past decade, visual gaze estimation has garnered growing attention within the research community, thanks to its wide-ranging application scenarios. While existing estimation approaches have achieved remarkable success in enhancing prediction accuracy, they primarily infer gaze directions from single-image signals and discard the huge potentials of the currently dominant text guidance. Notably, visual-language collaboration has been extensively explored across a range of visual tasks, such as image synthesis and manipulation, leveraging the remarkable transferability of large-scale Contrastive Language-Image Pre-training (CLIP) model. Nevertheless, existing gaze estimation approaches ignore the rich semantic cues conveyed by linguistic signals and priors in CLIP feature space, thereby yielding performance setbacks. In pursuit of making up this gap, we delve deeply into the text-eye collaboration protocol and introduce a novel gaze estimation framework in this paper, referred to as GazeCLIP. Specifically, we intricately design a linguistic description generator to produce text signals with coarse directional cues. Additionally, a CLIP-based backbone that excels in characterizing text-eye pairs for gaze estimation is presented. This is followed by the implementation of a fine-grained multi-modal fusion module aimed at modeling the interrelationships between heterogeneous inputs. Extensive experiments on three challenging datasets demonstrate the superiority of the proposed GazeCLIP which surpasses the previous approaches and achieves the state-of-the-art estimation accuracy.",[''],"['[', '[', '[', '[', '[']"
,[''],[]
"We study a generalized Witten’s finiteness conjecture for the skein modules of oriented compact 3333-manifolds with boundary.
We formulate an equivalent version of the generalized finiteness conjecture using handlebodies and 2-handles, and prove the conjecture for some classes with the handlebodies of genus 2222 and 3333 using the equivalent version.",[''],[]
"This paper sets out a framework for the valuation of insurance liabilities that is intended to be economically realistic, elementary, reasonably practically applicable, and as a special case to provide a basis for the valuation in regulatory solvency systems such as Solvency II and the SST. The valuation framework is based on the cost of producing the liabilities to an insurance company that is subject to solvency regulation (regulatory solvency capital requirements) and insolvency laws (consequences of failure) in finite discrete time. Starting from the replication approach of classical no-arbitrage theory, the framework additionally considers the nature and cost of capital (expressed by a “financiability condition”), that the liabilities may be required to be fulfilled only “in sufficiently many cases” (expressed by a “fulfillment condition”), production using “fully illiquid” assets in addition to tradables, and the asymmetry between assets and liabilities. We identify necessary and sufficient conditions on the capital investment under which the framework recovers the market prices of tradables, investigate extending production to take account of insolvency, implications of using illiquid assets in the production, and show how Solvency II and SST valuation can be derived with specific assumptions.",[''],[]
"This paper studies identification for a wide range of nonlinear panel data models, including binary choice, ordered repsonse, and other types of limited dependent variable models. Our approach accommodates dynamic models with any number of lagged dependent variables as well as other types of (potentially contemporary) endogeneity. Our identification strategy relies on a partial stationarity condition, which not only allows for an unknown distribution of errors but also for temporal dependencies in errors. We derive partial identification results under flexible model specifications and provide additional support conditions for point identification. We demonstrate the robust finite-sample performance of our approach using Monte Carlo simulations, with static and dynamic ordered choice models as illustrative examples.

Keywords: Panel Discrete Choice Models; Stationarity; Dynamic Models; Partial Identification; Endogeneity",[''],[]
"In condensed matter physics, the Kagome lattice and its inherent flat bands have attracted considerable attention for their potential to host a variety of exotic physical phenomena. Despite extensive efforts to fabricate thin films of Kagome materials aimed at modulating the flat bands through electrostatic gating or strain manipulation, progress has been limited. Here, we report the observation of a novel d𝑑ditalic_d-orbital hybridized Kagome-derived flat band in Ag/Si(111) 3×333\sqrt{3}\times\sqrt{3}square-root start_ARG 3 end_ARG × square-root start_ARG 3 end_ARG as revealed by angle-resolved photoemission spectroscopy. Our findings indicate that silver atoms on a silicon substrate form a Kagome-like structure, where a delicate balance in the hopping parameters of the in-plane d𝑑ditalic_d-orbitals leads to destructive interference, resulting in a flat band. These results not only introduce a new platform for Kagome physics but also illuminate the potential for integrating metal-semiconductor interfaces into Kagome-related research, thereby opening a new avenue for exploring ideal two-dimensional Kagome systems.",[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea']"
"We introduce a natural two-cardinal version of Bagaria’s sequence of derived topologies on ordinals. We prove that for our sequence of two-cardinal derived topologies, limit points of sets can be characterized in terms of a new iterated form of pairwise simultaneous reflection of certain kinds of stationary sets, the first few instances of which are often equivalent to notions related to strong stationarity, which has been studied previously in the context of strongly normal ideals [10]. The non-discreteness of these two-cardinal derived topologies can be obtained from certain two-cardinal indescribability hypotheses, which follow from local instances of supercompactness. Additionally, we answer several questions posed by the first author, Peter Holy and Philip White on the relationship between Ramseyness and indescribability in both the cardinal context and in the two-cardinal context.","['Key words and phrases: derived topology, stationary reflection, indescribable cardinals,', 'Ramsey cardinals,', 'Ramsey hierarchy']",[]
"This proceedings paper extends the scope of our conference talk, where we presented a comprehensive analysis of newly expanded and refined lattice data concerning the SU⁢(3)SU3\mathrm{SU}(3)roman_SU ( 3 ) gauge theory with Nf=8subscript𝑁𝑓8N_{f}=8italic_N start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = 8 light Dirac fermions — a theory positioned near the conformal window boundary. The analysis presented here makes use of a dilaton effective field theory and we delve deeper into the intricacies of the dilaton potential. We aim to clarify the connection between parameters appearing the potential and properties of the underlying gauge theory.",[''],[]
"Pretrained large-scale vision-language models such as CLIP have demonstrated excellent generalizability over a series of downstream tasks. However, they are sensitive to the variation of input text prompts and need a selection of prompt templates to achieve satisfactory performance. Recently, various methods have been proposed to dynamically learn the prompts as the textual inputs to avoid the requirements of laboring hand-crafted prompt engineering in the fine-tuning process. We notice that these methods are suboptimal in two aspects. First, the prompts of the vision and language branches in these methods are usually separated or uni-directionally correlated. Thus, the prompts of both branches are not fully correlated and may not provide enough guidance to align the representations of both branches. Second, it’s observed that most previous methods usually achieve better performance on seen classes but cause performance degeneration on unseen classes compared to CLIP. This is because the essential generic knowledge learned in the pretraining stage is partly forgotten in the fine-tuning process. In this paper, we propose Co-Articulated Multi-Modal Learning (COMMA) to handle the above limitations. Especially, our method considers prompts from both branches to generate the prompts to enhance the representation alignment of both branches. Besides, to alleviate forgetting about the essential knowledge, we minimize the feature discrepancy between the learned prompts and the embeddings of hand-crafted prompts in the pre-trained CLIP in the late transformer layers. We evaluate our method across three representative tasks of generalization to novel classes, new target datasets and unseen domain shifts. Experimental results demonstrate the superiority of our method by exhibiting a favorable performance boost upon all tasks with high efficiency. Code is available at https://github.com/hulianyuyy/COMMA",[''],[]
,[''],[]
"Motivated by their research on automorphism groups of pseudo-real Riemann surfaces, Bujalance, Cirre and Conder have conjectured that there are infinitely many primes p𝑝pitalic_p such that p+2𝑝2p+2italic_p + 2 has all its prime factors q≡−1𝑞1q\equiv-1italic_q ≡ - 1 mod (4)4(4)( 4 ). We use a theorem of Raikov to prove that the number of integers n≤x𝑛𝑥n\leq xitalic_n ≤ italic_x with only such prime factors q𝑞qitalic_q is asymptotic to c⁢x/ln⁡x𝑐𝑥𝑥cx/\sqrt{\ln x}italic_c italic_x / square-root start_ARG roman_ln italic_x end_ARG for a specific constant c=0.4865⁢…𝑐0.4865…c=0.4865\ldotsitalic_c = 0.4865 …. Heuristic arguments, following Hardy and Littlewood, then yield a conjecture that the number of such primes p≤x𝑝𝑥p\leq xitalic_p ≤ italic_x is asymptotic to c′⁢∫2x(ln⁡t)−3/2⁢𝑑tsuperscript𝑐′superscriptsubscript2𝑥superscript𝑡32differential-d𝑡c^{\prime}\int_{2}^{x}(\ln t)^{-3/2}dtitalic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∫ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT ( roman_ln italic_t ) start_POSTSUPERSCRIPT - 3 / 2 end_POSTSUPERSCRIPT italic_d italic_t for a constant c′=0.8981⁢…superscript𝑐′0.8981…c^{\prime}=0.8981\ldotsitalic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 0.8981 …. The theorem, the conjecture and a similar conjecture applying the Bateman–Horn Conjecture to other pseudo-real Riemann surfaces are supported by evidence from extensive computer searches.","['Key words and phrases:', 'Riemann surface, pseudo-real, prime number,', 'Riemann zeta function,', 'Dirichlet series,', 'Bateman–Horn', 'Conjecture']",[]
"Existing gait recognition benchmarks mostly include minor clothing variations in the laboratory environments, but lack persistent changes in appearance over time and space. In this paper, we propose the first in-the-wild benchmark CCGait for cloth-changing gait recognition, which incorporates diverse clothing changes, indoor and outdoor scenes, and multi-modal statistics over 92 days. To further address the coupling effect of clothing and viewpoint variations, we propose a hybrid approach HybridGait that exploits both temporal dynamics and the projected 2D information of 3D human meshes. Specifically, we introduce a Canonical Alignment Spatial-Temporal Transformer (CA-STT) module to encode human joint position-aware features, and fully exploit 3D dense priors via a Silhouette-guided Deformation with 3D-2D Appearance Projection (SilD) strategy. Our contributions are twofold: we provide a challenging benchmark CCGait that captures realistic appearance changes across an expanded and space, and we propose a hybrid framework HybridGait that outperforms prior works on CCGait and Gait3D benchmarks.
Our project page is available at
https://github.com/HCVLab/HybridGait.",[''],[]
"Proactively and naturally guiding the dialog from the non-recommendation context (e.g., Chit-chat) to the recommendation scenario (e.g., Music) is crucial for the Conversational Recommender System (CRS).
Prior studies mainly focus on planning the next dialog goal (e.g., chat on a movie star) conditioned on the previous dialog.
However, we find the dialog goals can be simultaneously observed at different levels, which can be utilized to improve CRS.
In this paper, we propose
Dual-space Hierarchical Learning (DHL)
to leverage multi-level goal sequences and their hierarchical relationships for conversational recommendation.
Specifically, we exploit multi-level goal sequences from both the representation space and the optimization space.
In the representation space, we propose the hierarchical representation learning where a cross attention module derives mutually enhanced multi-level goal representations.
In the optimization space, we devise the hierarchical weight learning to reweight lower-level goal sequences, and introduce bi-level optimization for stable update.
Additionally, we propose a soft labeling strategy to guide optimization gradually.
Experiments on two real-world datasets verify the effectiveness of our approach.
Code and data are available here.",[''],[]
"This work evaluated several cutting-edge large-scale foundation models based on self-supervision or weak supervision, including SeamlessM4T, SeamlessM4T v2, and Whisper-large-v3, on three code-switched corpora. We found that self-supervised models can achieve performances close to the supervised model, indicating the effectiveness of multilingual self-supervised pre-training. We also observed that these models still have room for improvement as they kept making similar mistakes and had unsatisfactory performances on modeling intra-sentential code-switching. In addition, the validity of several variants of Whisper was explored, and we concluded that they remained effective in a code-switching scenario, and similar techniques for self-supervised models are worth studying to boost the performance of code-switched tasks.",[''],[]
"Recently, fictitious identical particles have provided a promising way to overcome the fermion sign problem and have been used in path integral Monte Carlo (PIMC) to accurately simulate warm dense matter with up to 1000 electrons (T. Dornheim et al., arXiv:2311.08098 (2023)). The inclusion of fictitious identical particles in path integral molecular dynamics (PIMD) can provide another way to simulate fermion systems. In a recent paper (J. Chem. Phys. 159, 154107 (2023)), Feldman and Hirshberg improved the recursive formula for PIMD of N identical bosons, significantly reducing the computational complexity from O⁢(P⁢N3)𝑂𝑃superscript𝑁3O(PN^{3})italic_O ( italic_P italic_N start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) to O⁢(N2+P⁢N)𝑂superscript𝑁2𝑃𝑁O(N^{2}+PN)italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_P italic_N ). In this paper, we extend this latest recursive formula for bosons to PIMD of fictitious identical particles to improve the efficiency of simulating fermion systems. We also provide the virial estimator for calculating energy by using the recursive technique. As an example, we use the quadratic scaling PIMD for fictitious identical particles to study the simulation of hundreds of fermions in a two-dimensional periodic potential, in the hope of providing a simulation tool for two-dimensional Fermi-Hubbard model and other strongly correlated fermion systems, such as the simulation of ultracold fermionic gases in optical lattices.",[''],"['China', 'China', 'China']"
"Magnetic particle imaging (MPI) is an emerging medical imaging modality which has gained increasing interest in recent years.
Among the benefits of MPI are its high temporal resolution, and that the technique does not expose the specimen to any kind of ionizing radiation.
It is based on the non-linear response of magnetic nanoparticles to an applied magnetic field.
From the electric signal measured in receive coils, the particle concentration has to be reconstructed.
Due to the ill-posedness of the reconstruction problem, various regularization methods have been proposed for reconstruction ranging from early stopping methods, via classical Tikhonov regularization and iterative methods to modern machine learning approaches.
In this work, we contribute to the latter class: we propose a plug-and-play approach based on a generic zero-shot denoiser with an ℓ1superscriptℓ1\ell^{1}roman_ℓ start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT-prior. Moreover, we develop parameter selection strategies. Finally, we quantitatively and qualitatively evaluate the proposed algorithmic scheme on the 3D Open MPI data set with different levels of preprocessing.",[''],[]
"Uncertainty quantification is a critical aspect of machine learning models, providing important insights into the reliability of predictions and aiding the decision-making process in real-world applications. This paper proposes a novel way to use variance-based measures to quantify uncertainty on the basis of second-order distributions in classification problems. A distinctive feature of the measures is the ability to reason about uncertainties on a class-based level, which is useful in situations where nuanced decision-making is required. Recalling some properties from the literature, we highlight that the variance-based measures satisfy important (axiomatic) properties. In addition to this axiomatic approach, we present empirical results showing the measures to be effective and competitive to commonly used entropy-based measures.",[''],"['Munich', '(MCML)', 'Munich', '(MCML)', 'Munich', '(MCML)', 'Munich', '(MCML)', 'Munich', '(MCML)']"
"Ultracold neutrons are great experimental tools to explore the gravitational interaction in the regime of quantized states.
From a theoretical perspective, starting from a Dirac equation in curved spacetime, we applied a perturbative scheme to systematically derive the non-relativistic Schrödinger equation that governs the evolution of the neutron’s wave function in the Earth’s gravitational field. At the lowest order, this procedure reproduces a Schrödinger system affected by a linear Newtonian potential, but corrections due to both curvature and relativistic effects are present. Here, we argue that one should be very careful when going one step further in the perturbative expansion. Proceeding methodically with the help of the Foldy-Wouthuysen transformation and a formal post-Newtonian 1/c2−limit-from1superscript𝑐2\nicefrac{{1}}{{c^{2}}}-/ start_ARG 1 end_ARG start_ARG italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG -expansion, we derive the non-relativistic Hamiltonian for a generic static spacetime. By employing Fermi coordinates within this framework, we calculate the next-to-leading order corrections to the neutron’s energy spectrum. Finally, we evaluate them for typical experimental configurations, such as that of qBOUNCE, and note that, while the current precision for observations of ultracold neutrons may not yet enable to probe them, they could still be relevant in the future or in alternative circumstances.",[''],"['Austria', 'Chile', 'Chile', 'Austria', 'Chile']"
"The intrinsic alignment (IA) of galaxies acts as a systematic effect in weak lensing measurements and tends to introduce biases. It mimics the gravitational lensing signal which makes it difficult to distinguish it from the true gravitational weak lensing effect. Hence, it is critical to account for the noise for correctly interpreting the results. This study aims at a quantitative analysis of IA using the Tidal Alignment and Tidal Torquing (TATT) model. We also investigate how the signals for shear and galaxy-galaxy lensing behave upon changing the parameters of the TATT model.
The data for this study was prepared with a computational pipeline based on the Cocoa model to explore the parameter space of the intrinsic shape signal.
Through this work, we identify that linear terms of the intrinsic shape signal are dominant in the case of GGL while the higher-order terms dictate the shear signal.","['Intrinsic', 'Alignments —', 'Weak', 'Gravitational', 'Lensing —', 'Tidal', 'Alignment —', 'Tidal', 'Torquing —', 'Cosmic', 'Shear —', 'Galaxy', 'Alignments']",['States']
We prove that the singular set of a 2222-valued Lipschitz graph that is stationary for the area is of codimension 1111.,[''],[]
"Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use to exploit vulnerabilities. The interpretation of TTPs in the MITRE ATT&CK framework can be challenging for cybersecurity practitioners due to presumed expertise, complex dependencies, and inherent ambiguity. Meanwhile, advancements with Large Language Models (LLMs) have led to recent surge in studies exploring its uses in cybersecurity operations. This leads us to question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5) LLMs can comprehend and summarize TTPs to inform analysts of the intended purposes (i.e., tactics) of a cyberattack procedure. The state-of-the-art LLMs have shown to be prone to hallucination by providing inaccurate information, which is problematic in critical domains like cybersecurity. Therefore, we propose the use of Retrieval Augmented Generation (RAG) techniques to extract relevant contexts for each cyberattack procedure for decoder-only LLMs (without fine-tuning). We further contrast such approach against supervised fine-tuning (SFT) of encoder-only LLMs. Our results reveal that both the direct-use of decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only LLMs offer inaccurate interpretation of cyberattack procedures. Significant improvements are shown when RAG is used for decoder-only LLMs, particularly when directly relevant context is found. This study further sheds insights on the limitations and capabilities of using RAG for LLMs in interpreting TTPs.",[''],[]
"We study populations of oscillators, all-to-all coupled by means of quenched disordered phase shifts. While there is no traditional synchronization transition with a nonvanishing Kuramoto order parameter, the system demonstrates a specific order as the coupling strength increases. This order is characterized by partial phase locking, which is put into evidence by the introduced correlation order parameter and via frequency entrainment. Simulations with phase oscillators, Stuart-Landau oscillators, and chaotic Roessler oscillators demonstrate similar scaling of the correlation order parameter with the coupling and the system size and also similar behavior of the frequencies with maximal entrainment at some finite coupling.",[''],"['Germany', '(Italy)', 'Florence']"
"Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery.
However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space.
Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables.
We make the observation that closed-form equations often have structural characteristics and invariances (e.g., the commutative law) that could be further exploited to build more effective symbolic regression solutions.
Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps.
We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training.
Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR).
In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions.",[''],[]
,[''],[]
"In a scenario where multi-modal cameras are operating together, the problem of working with non-aligned images cannot be avoided. Yet, existing image fusion algorithms rely heavily on strictly registered input image pairs to produce more precise fusion results, as a way to improve the performance of downstream high-level vision tasks. In order to relax this assumption, one can attempt to register images first. However, the existing methods for registering multiple modalities have limitations, such as complex structures and reliance on significant semantic information. This paper aims to address the problem of image registration and fusion in a single framework, called BusRef. We focus on Infrared-Visible image registration and fusion task (IVRF). In this framework, the input unaligned image pairs will pass through three stages: Coarse registration, Fine registration and Fusion. It will be shown that the unified approach enables more robust IVRF. We also propose a novel training and evaluation strategy, involving the use of masks to reduce the influence of non-reconstructible regions on the loss functions, which greatly improves the accuracy and robustness of the fusion task. Last but not least, a gradient-aware fusion network is designed to preserve the complementary information.
The advanced performance of this algorithm is demonstrated by comparing it with different registration/fusion algorithms.",[''],[]
,[''],[]
"As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research.
This paper presents Safety and Over-Defensiveness Evaluation (SODE) benchmark: a collection of diverse safe and unsafe prompts with carefully designed evaluation methods that facilitate systematic evaluation, comparison, and analysis over ‘safety’ and ‘over-defensiveness.’
With SODE, we study a variety of LLM defense strategies over multiple state-of-the-art LLMs, which reveals several interesting and important findings, such as
(a) the widely popular ‘self-checking’ techniques indeed improve the safety against unsafe inputs, but this comes at the cost of extreme over-defensiveness on the safe inputs,
(b) providing a safety instruction along with in-context exemplars (of both safe and unsafe inputs) consistently improves safety and also mitigates undue over-defensiveness of the models,
(c) providing contextual knowledge easily breaks the safety guardrails and makes the models more vulnerable to generating unsafe responses.
Overall, our work reveals numerous such critical findings that we believe will pave the way and facilitate further research in improving the safety of LLMs.
WARNING: This paper contains several toxic and offensive model responses. Reader discretion is advised.",[''],[]
"Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming.
Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages.
In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks.
We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models.
In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence.
Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io).
At last, we also point out several challenging and promising directions for future research.",[''],"['TechnologyWuhanChina', 'UniversityVancouverCanada', 'TechnologyWuhanChina', 'ResearchUSA', 'UniversityChina', 'WalesAustralia', 'SydneyAustralia', 'TechnologyWuhanChina', 'ChicagoChicagoUSA']"
,[''],[]
"We consider the problem of red teaming LLMs on elementary calculations and algebraic tasks to evaluate how various prompting techniques affect the quality of outputs. We present a framework to procedurally generate numerical questions and puzzles, and compare the results with and without the application of several red teaming techniques. Our findings suggest that even though structured reasoning and providing worked-out examples slow down the deterioration of the quality of answers, the gpt-3.5-turbo and gpt-4 models are not well suited for elementary calculations and reasoning tasks, also when being red teamed.",[''],[]
,[''],[]
"The Multi-Objective Mixed-Integer Programming (MOMIP) problem is one of the most challenging. To derive its Pareto optimal solutions one can use the well-known Chebyshev scalarization and Mixed-Integer Programming (MIP) solvers. However, for a large-scale instance of the MOMIP problem, its scalarization may not be solved to optimality, even by state-of-the-art optimization packages, within the time limit imposed on the optimization.
If a MIP solver cannot derive the optimal solution within the assumed time limit, it provides the optimality gap, which gauges the quality of the approximate solution. However, for the MOMIP case, no information is provided on the lower and upper bounds of the components of the Pareto optimal outcome.
For the MOMIP problem with two and three objective functions, an algorithm is proposed to provide the so-called interval representation of the Pareto optimal outcome designated by the weighting vector when there is a time limit on solving the Chebyshev scalarization. Such interval representations can be used to navigate on the Pareto front.
The results of several numerical experiments on selected large-scale instances of the multi-objective, multidimensional 0-1 knapsack problem illustrate the proposed approach. The limitations and possible enhancements of the proposed method are also discussed.","['multi-objective mixed-integer programming, large-scale optimization,', 'Chebyshev scalarization,', 'Pareto front approximations, lower bounds, upper bounds,']",[]
"This work deals with a maximal monotone operator A𝐴Aitalic_A of type (D) in a Banach space whose dual space is strictly convex. We establish some representations for the value A⁢x𝐴𝑥Axitalic_A italic_x at a given point x𝑥xitalic_x via its values at nearby points of x𝑥xitalic_x. We show that the faces of A⁢x𝐴𝑥Axitalic_A italic_x are contained in the set of all weak*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT convergent limits of bounded nets of the operator at nearby points of x𝑥xitalic_x, then we obtain a representation for A⁢x𝐴𝑥Axitalic_A italic_x by use of this set. In addition, representations for the support function of A⁢x𝐴𝑥Axitalic_A italic_x based on the minimal-norm selection of the operator in certain Banach spaces are given.



Keywords:
Maximal monotone operator, monotone operator of type (D), minimal-norm selection, w-Kadec-Klee-property, w*{}^{*}start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT-Kadec-Klee-property, strictly convex space


MSC 2020: 47H05, 47H04, 47N10",[''],[]
"Robust control of quantum systems is an increasingly relevant field of study amidst the second quantum revolution, but there remains a gap between taming quantum physics and robust control in its modern analytical form that culminated in fundamental performance bounds. In general, quantum systems are not amenable to linear, time-invariant, measurement-based robust control techniques, and thus novel gap-bridging techniques must be developed. This survey is written for control theorists to highlight parallels between the current state of quantum control and classical robust control. We present issues that arise when applying classical robust control theory to quantum systems, typical methods used by quantum physicists to explore such systems and their robustness, as well as a discussion of open problems to be addressed in the field. We focus on general, practical applications and recent work to enable control researchers to contribute to advancing this burgeoning field.",[''],[]
"Achieving perfect control over the parameters defining a quantum gate is, in general, a very challenging task and at the same time, environmental interactions can introduce disturbances to the initial states as well. Here we address the problem of how the imperfections in unitaries and noise present in the input states affect the entanglement-generating power of a given quantum gate – we refer to it as imperfect (noisy) entangling power. We observe that, when the parameters of a given unitary are chosen randomly from a Gaussian distribution centered around the desired mean, the quenched average entangling power – averaged across multiple random samplings – exhibits intriguing behavior like it may increase or show nonmonotonic behavior with the increase of disorder strength for certain classes of diagonal unitary operators. For arbitrary unitary operators, the quenched average power tends to stabilize, showing almost constant behavior with variation in the parameters instead of oscillating. Our observations also reveal that, in the presence of a local noise model, the input states that maximize the entangling power of a given unitary operator differ considerably from the noiseless scenario. Additionally, we report that the rankings among unitary operators according to their entangling power in the noiseless case change depending on the noise model and noise strength.",[''],['India']
"When applying T-duality to a generic, non-extreme Killing horizon, T-duality is spacelike on one side and timelike on the other. We show, using simple examples from four-dimensional Einstein-Maxwell theory, that the image of the horizon is a singularity which can be understood as an interface between two different T-dual theories and their solutions. Using an embedding into type-II string theory, we show that the singularity occurs when scalars reach
the boundary of moduli space, resulting in a breakdown of the effective field theory due to the presence of tensionless strings.",[''],[]
,[''],[]
"Principal-agent problems arise when one party acts on behalf of another, leading to conflicts of interest. The economic literature has extensively studied principal-agent problems, and recent work has extended this to more complex scenarios such as Markov Decision Processes (MDPs). In this paper, we further explore this line of research by investigating how reward shaping under budget constraints can improve the principal’s utility. We study a two-player Stackelberg game where the principal and the agent have different reward functions, and the agent chooses an MDP policy for both players. The principal offers an additional reward to the agent, and the agent picks their policy selfishly to maximize their reward, which is the sum of the original and the offered reward. Our results establish the NP-hardness of the problem and offer polynomial approximation algorithms for two classes of instances: Stochastic trees and deterministic decision processes with a finite horizon.",[''],[]
"Denote by Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT the d𝑑ditalic_d-dimensional hypercube. Addressing a recent
question we estimate the number of ways the vertex set of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT
can be partitioned into
vertex disjoint smaller cubes. Among other results, we prove
that the asymptotic order
of this function is not much larger than the number of
perfect matchings of Qdsubscript𝑄𝑑Q_{d}italic_Q start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. We also describe
several new (and old) questions.",[''],[]
"We present multivariable extremum seeking (ES) designs that achieve unbiased convergence to the optimum. Two designs are introduced: one with exponential unbiased convergence (unbiased extremum seeker, uES) and the other with user-assignable prescribed-time unbiased convergence (unbiased PT extremum seeker, uPT-ES). In contrast to the conventional ES, which uses persistent sinusoids and results in steady-state oscillations around the optimum, the exponential uES employs an exponentially decaying amplitude in the perturbation signal (for achieving convergence) and an exponentially growing demodulation signal (for making the convergence unbiased). The achievement of unbiased convergence also entails employing an adaptation gain that is sufficiently large in relation to the decay rate of the perturbation amplitude. Stated concisely, the bias is eliminated by having the learning process outpace the waning of the perturbation. The other algorithm, uPT-ES, employs prescribed-time convergent/blow-up functions in place of constant amplitudes of sinusoids, and it also replaces constant-frequency sinusoids with chirp signals whose frequency grows over time. Among the convergence results in the ES literature, uPT-ES may be the strongest yet in terms of the convergence rate (prescribed-time) and accuracy (unbiased). To enhance the robustness of uES to a time-varying optimum, exponential functions are modified to keep oscillations at steady state. Stability analysis of the designs is based on a state transformation, averaging, local exponential/PT stability of the averaged system, local stability of the transformed system, and local exponential/PT stability of the original system. For numerical implementation of the developed ES schemes and comparison with previous ES designs, the problem of source seeking by a two-dimensional velocity-actuated point mass is considered.",[''],[]
"Dynamic control via optimized, piecewise-constant pulses is a common paradigm for open-loop control to implement quantum gates. While numerous methods exist for the synthesis of such controls, there are many open questions regarding the robustness of the resulting control schemes in the presence of model uncertainty; unlike in classical control, there are generally no analytical guarantees on the control performance with respect to inexact modeling of the system. In this paper a new robustness measure based on the differential sensitivity of the gate fidelity error to parametric (structured) uncertainties is introduced, and bounds on the differential sensitivity to parametric uncertainties are used to establish performance guarantees for optimal controllers for a variety of quantum gate types, system sizes, and control implementations. Specifically, it is shown how a maximum allowable perturbation over a set of Hamiltonian uncertainties that guarantees a given fidelity error, can be reliably computed. This measure of robustness is inversely proportional to the upper bound on the differential sensitivity of the fidelity error evaluated under nominal operating conditions. Finally, the results show that the nominal fidelity error and differential sensitivity upper bound are positively correlated across a wide range of problems and control implementations, suggesting that in the high-fidelity control regime, rather than there being a trade-off between fidelity and robustness, higher nominal gate fidelities are positively correlated with increased robustness of the controls in the presence of parametric uncertainties.",[''],"['USA', 'UK', 'USA', 'UK', 'UK']"
"For a relational structure 𝕏𝕏{\mathbb{X}}blackboard_X we investigate the partial order ⟨ℙ⁢(𝕏),⊂⟩ℙ𝕏\langle{\mathbb{P}}({\mathbb{X}}),\subset\rangle⟨ blackboard_P ( blackboard_X ) , ⊂ ⟩,
where ℙ⁢(𝕏):={f⁢[X]:f∈Emb(𝕏)}assignℙ𝕏conditional-set𝑓delimited-[]𝑋𝑓Emb𝕏{\mathbb{P}}({\mathbb{X}}):=\{f[X]:f\in\mathop{\rm Emb}\nolimits({\mathbb{X}})\}blackboard_P ( blackboard_X ) := { italic_f [ italic_X ] : italic_f ∈ roman_Emb ( blackboard_X ) }.
A previous analysis shows that 𝔥=ω1𝔥subscript𝜔1{\mathfrak{h}}=\omega_{1}fraktur_h = italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT implies that for each countable ordinal we have
ro(sq(ℙ⁢(α)))≅ro(P⁢(ω)/Fin)rosqℙ𝛼ro𝑃𝜔Fin\mathop{\rm ro}\nolimits(\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha)))\cong%
\mathop{\rm ro}\nolimits(P(\omega)/\mathop{\rm Fin})roman_ro ( roman_sq ( blackboard_P ( italic_α ) ) ) ≅ roman_ro ( italic_P ( italic_ω ) / roman_Fin ).
But in ZFC we have sq(ℙ⁢(α))≅∏i=0n((rpri(P⁢(ωγi)/ℐωγi))+)sisqℙ𝛼superscriptsubscriptproduct𝑖0𝑛superscriptsuperscriptsuperscriptrpsubscript𝑟𝑖𝑃superscript𝜔subscript𝛾𝑖subscriptℐsuperscript𝜔subscript𝛾𝑖subscript𝑠𝑖\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha))\cong\prod_{i=0}^{n}((\mathop{%
\rm rp}\nolimits^{r_{i}}(P(\omega^{\gamma_{i}})/{\mathcal{I}}_{\omega^{\gamma_%
{i}}}))^{+})^{s_{i}}roman_sq ( blackboard_P ( italic_α ) ) ≅ ∏ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( ( roman_rp start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_P ( italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) / caligraphic_I start_POSTSUBSCRIPT italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT,
where ∑i=n0ωγi+ri⁢si+ksuperscriptsubscript𝑖𝑛0superscript𝜔subscript𝛾𝑖subscript𝑟𝑖subscript𝑠𝑖𝑘\sum_{i=n}^{0}\omega^{\gamma_{i}+r_{i}}s_{i}+k∑ start_POSTSUBSCRIPT italic_i = italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_ω start_POSTSUPERSCRIPT italic_γ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_k is the presentation of α𝛼\alphaitalic_α in the Cantor normal form
and rp(𝔹)rp𝔹\mathop{\rm rp}\nolimits({\mathbb{B}})roman_rp ( blackboard_B ) denotes the reduced power of a Boolean algebra 𝔹𝔹{\mathbb{B}}blackboard_B modulo finite:
𝔹ω/Finsuperscript𝔹𝜔Fin{\mathbb{B}}^{\omega}/\mathop{\rm Fin}blackboard_B start_POSTSUPERSCRIPT italic_ω end_POSTSUPERSCRIPT / roman_Fin.
Consequently, ro(sq(ℙ⁢(α)))≅ro((P⁢(ω)/Fin)+∗π)rosqℙ𝛼ro∗superscript𝑃𝜔Fin𝜋\mathop{\rm ro}\nolimits(\mathop{\rm sq}\nolimits({\mathbb{P}}(\alpha)))\cong%
\mathop{\rm ro}\nolimits((P(\omega)/\mathop{\rm Fin})^{+}\ast\pi)roman_ro ( roman_sq ( blackboard_P ( italic_α ) ) ) ≅ roman_ro ( ( italic_P ( italic_ω ) / roman_Fin ) start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ∗ italic_π ),
where π𝜋\piitalic_π is an P⁢(ω)/Fin𝑃𝜔FinP(\omega)/\mathop{\rm Fin}italic_P ( italic_ω ) / roman_Fin-name for an σ𝜎\sigmaitalic_σ-closed separative atomless poset.
Here we consider uncountable ordinals.
Since sqℙ⁢(α)sqℙ𝛼\mathop{\rm sq}\nolimits{\mathbb{P}}(\alpha)roman_sq blackboard_P ( italic_α ) is isomorphic to the direct product ∏i=1n(sqℙ⁢(ωδi))sisuperscriptsubscriptproduct𝑖1𝑛superscriptsqℙsuperscript𝜔subscript𝛿𝑖subscript𝑠𝑖\prod_{i=1}^{n}(\mathop{\rm sq}\nolimits{\mathbb{P}}(\omega^{\delta_{i}}))^{s_%
{i}}∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( roman_sq blackboard_P ( italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT,
where α=ωδn⁢sn+…+ωδ1⁢s1+m𝛼superscript𝜔subscript𝛿𝑛subscript𝑠𝑛…superscript𝜔subscript𝛿1subscript𝑠1𝑚\alpha=\omega^{\delta_{n}}s_{n}+\dots+\omega^{\delta_{1}}s_{1}+mitalic_α = italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT + … + italic_ω start_POSTSUPERSCRIPT italic_δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m is the Cantor normal form for α𝛼\alphaitalic_α,
the analysis is reduced to the investigation of the posets of the form ℙ⁢(ωδ)ℙsuperscript𝜔𝛿{\mathbb{P}}(\omega^{\delta})blackboard_P ( italic_ω start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ).
It turns out that, in ZFC, either the poset sqℙ⁢(α)sqℙ𝛼\mathop{\rm sq}\nolimits{\mathbb{P}}(\alpha)roman_sq blackboard_P ( italic_α ) is σ𝜎\sigmaitalic_σ-closed and completely embeds P⁢(ω)/Fin𝑃𝜔FinP(\omega)/\mathop{\rm Fin}italic_P ( italic_ω ) / roman_Fin
and, hence, preserves ω1subscript𝜔1\omega_{1}italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and forces |𝔠|=|𝔥|𝔠𝔥|{\mathfrak{c}}|=|{\mathfrak{h}}|| fraktur_c | = | fraktur_h |,
or, otherwise, completely embeds the algebra P⁢(λ)/[λ]<λ𝑃𝜆superscriptdelimited-[]𝜆absent𝜆P(\lambda)/[\lambda]^{<\lambda}italic_P ( italic_λ ) / [ italic_λ ] start_POSTSUPERSCRIPT < italic_λ end_POSTSUPERSCRIPT, for some regular ω<λ≤cf(δ)𝜔𝜆cf𝛿\omega<\lambda\leq\mathop{\rm cf}\nolimits(\delta)italic_ω < italic_λ ≤ roman_cf ( italic_δ ), and collapses ω2subscript𝜔2\omega_{2}italic_ω start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to ω𝜔\omegaitalic_ω.
Regarding the Cantor normal form,
the first case appears iff for each i≤n𝑖𝑛i\leq nitalic_i ≤ italic_n we have cf(δi)≤ωcfsubscript𝛿𝑖𝜔\mathop{\rm cf}\nolimits(\delta_{i})\leq\omegaroman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ≤ italic_ω,
or δi=θi+cf(δi)subscript𝛿𝑖subscript𝜃𝑖cfsubscript𝛿𝑖\delta_{i}=\theta_{i}+\mathop{\rm cf}\nolimits(\delta_{i})italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ),
where Ord∋θi≥cf(δi)>cf(θi)=ωcontainsOrdsubscript𝜃𝑖cfsubscript𝛿𝑖cfsubscript𝜃𝑖𝜔\mathop{\mathrm{Ord}}\nolimits\ni\theta_{i}\geq\mathop{\rm cf}\nolimits(\delta%
_{i})>\mathop{\rm cf}\nolimits(\theta_{i})=\omegaroman_Ord ∋ italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≥ roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) > roman_cf ( italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_ω
and θi=limn→ωδnsubscript𝜃𝑖subscript→𝑛𝜔subscript𝛿𝑛\theta_{i}=\lim_{n\rightarrow\omega}\delta_{n}italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = roman_lim start_POSTSUBSCRIPT italic_n → italic_ω end_POSTSUBSCRIPT italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, where cf(δn)=cf(δi)cfsubscript𝛿𝑛cfsubscript𝛿𝑖\mathop{\rm cf}\nolimits(\delta_{n})=\mathop{\rm cf}\nolimits(\delta_{i})roman_cf ( italic_δ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = roman_cf ( italic_δ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), for all n∈ω𝑛𝜔n\in\omegaitalic_n ∈ italic_ω.

2020 MSC:
06A05, 06A10, 03E40, 03E35. 
Keywords: uncountable ordinal, poset of copies, σ𝜎\sigmaitalic_σ-closed poset, cardinal collapse, forcing.",[''],[]
"Synthetic data sets are used in cosmology to test analysis procedures, to verify that systematic errors are well understood and to demonstrate that measurements are unbiased. In this work we describe the methods used to generate synthetic datasets of Lyman-α𝛼\alphaitalic_α quasar spectra aimed for studies with the Dark Energy Spectroscopic Instrument (DESI). In particular, we focus on demonstrating that our simulations reproduces important features of real samples, making them suitable to test the analysis methods to be used in DESI and to place limits on systematic effects on measurements of Baryon Acoustic Oscillations (BAO).
We present a set of mocks that reproduce the statistical properties of the DESI early data set with good agreement. Additionally, we use full survey synthetic data to forecast the BAO scale constraining power with DESI.",[''],[]
"We prove tunneling estimates for two-dimensional Dirac systems which are localized in space due to the presence of a magnetic field.
The Hamiltonian driving the motion admits the decomposition H=H0+W𝐻subscript𝐻0𝑊H=H_{0}+Witalic_H = italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_W, where H0subscript𝐻0H_{0}italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a rotationally symmetric magnetic Dirac operator and W𝑊Witalic_W is a position-dependent matrix-valued potential satisfying certain smoothness condition in the angular variable.
A consequence of our results are upper bounds for the
growth in time
of the expected size of the system and its total angular momentum.",[''],[]
,[''],[]
"Decisions are often made by heterogeneous groups of individuals, each with distinct initial biases and access to information of different quality. We show that in large groups of independent agents who accumulate evidence the first to decide are those with the strongest initial biases. Their decisions align with their initial bias, regardless of the underlying truth. In contrast, agents who decide last make decisions as if they were initially unbiased, and hence make better choices. We obtain asymptotic expressions in the large population limit that quantify how agents’ initial inclinations shape early decisions. Our analysis shows how bias, information quality, and decision order interact in non-trivial ways to determine the reliability of decisions in a group.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA']"
"Earlier in my career, prevalent approaches in the emerging field of market design largely represented the experiences and perspectives of leaders who were commissioned to design or reform various institutions. Since being commissioned for a similar task seemed unlikely for me as an aspiring design economist, I developed my own minimalist approach to market design. Using the policy objectives of stakeholders, my approach creates a new institution from the existing one with minimal interference with its elements that compromise the objectives.
Minimalist market design initially evolved through my integrated research and policy efforts in school choice from 1997 to 2005 and in kidney exchange from 2003 to 2007. Given its success in school choice and kidney exchange, I systematically followed this approach in many other, often unusual real-world settings. In recent years, my efforts in minimalist market design led to the 2021 reform of the US Army’s branching system for its cadets to military specialties, the adoption of reserve systems during the Covid-19 pandemic for vaccine allocation in 15 states and therapies in 2 states, and the deployment of a highly efficient liver exchange system in Türkiye. This same methodology also predicted the rescission of a 1995 Supreme Court judgment in India, resulting in countless litigations and interruptions of public recruitment for 25 years, as well as the mandates of its replacement.
In this monograph, I describe the philosophy, evolution, and successful applications of minimalist market design, contrasting it with the mainstream paradigm for the field. In doing so, I also provide a paradigm for economists who want to influence policy and change institutions through their research.",[''],[]
"The classical Canonical Correlation Analysis (CCA) identifies the correlations between two sets of multivariate variables based on their
covariance, which has been widely applied in diverse fields such as computer vision, natural language processing, and speech analysis. Despite its popularity, CCA can encounter challenges in explaining correlations between two variable sets within high-dimensional data contexts. Thus, this paper studies Sparse Canonical Correlation Analysis (SCCA) that enhances the interpretability of CCA. We first show that SCCA generalizes three well-known sparse optimization problems, sparse PCA, sparse SVD, and sparse regression, which are all classified as NP-hard problems. This result motivates us to develop strong formulations and efficient algorithms. Our main contributions include (i) the introduction of a combinatorial formulation that captures the essence of SCCA and allows the development of approximation algorithms; (ii) the derivation of an equivalent mixed-integer semidefinite programming model that facilitates a specialized branch-and-cut algorithm with analytical cuts; and (iii) the establishment of the complexity results for two low-rank special cases of SCCA. The effectiveness of our proposed formulations and algorithms is validated through numerical experiments.",[''],[]
"New results are presented on a high-statistics measurement of Collins and Sivers asymmetries of charged hadrons produced in deep inelastic scattering of muons on a transversely polarised 66{}^{6}start_FLOATSUPERSCRIPT 6 end_FLOATSUPERSCRIPTLiD target.
The data were taken in 2022 with the COMPASS spectrometer using the 160 GeV muon beam at CERN, balancing the existing data
on transversely polarised proton targets.
The first results from about two-thirds of the new data have total
uncertainties smaller by up to a factor of three compared to
the previous deuteron measurements.
Using all the COMPASS proton and deuteron results, both the transversity and the Sivers distribution functions of the u𝑢uitalic_u and d𝑑ditalic_d quark, as well as the tensor charge
in the measured x𝑥xitalic_x-range are extracted. In particular, the accuracy of the d𝑑ditalic_d quark results is significantly improved.",[''],[]
"Traves and Wehlau [9] recently gave a straightedge construction that checks whether 10 points lie on a plane cubic curve. They also highlighted several open problems in the synthetic geometry of cubics. Hermann Grassmann investigated incidence relations among points on cubic curves in three papers [4, 5, 6] appearing in Crelle’s Journal from 1846 to 1856. Grassmann’s methods give an alternative way to check whether 10 points lie on a cubic. Using Grassmann’s techniques, we solve the synthetic geometry problems introduced by Traves and Wehlau. In particular, we give straightedge constructions that find the intersection of a line with a cubic, find the tangent line to a cubic at a given point, and find the third point of intersection of this tangent line with the cubic. As well, given 5 points on a conic and a cubic and 4 additional points on the cubic, a straightedge construction is given that finds the sixth intersection point of the conic and the cubic. The paper ends with two open problems.",[''],[]
"A sequence of operators Tnsubscript𝑇𝑛T_{n}italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT from a Hilbert space ℌℌ{\mathfrak{H}}fraktur_H
to Hilbert spaces 𝔎nsubscript𝔎𝑛{\mathfrak{K}}_{n}fraktur_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT
which is nondecreasing in the sense of contractive domination
is shown to have a limit which is still a linear operator T𝑇Titalic_T from ℌℌ{\mathfrak{H}}fraktur_H
to a Hilbert space 𝔎𝔎{\mathfrak{K}}fraktur_K.
Moreover, the closability or closedness of Tnsubscript𝑇𝑛T_{n}italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is preserved in the limit.
The closures converge likewise and the connection between the limits is investigated.
There is no similar way of dealing directly with linear relations.
However, the sequence of closures is still nondecreasing
and then the convergence is governed by
the monotonicity principle. There are some related results
for nonincreasing sequences.","['Key words and phrases:', 'Domination of linear relations, nondecreasing sequences of linear relations in the sense\nof domination, monotonicity principle']",[]
,[''],[]
"Medical imaging is an essential tool for diagnosing and treating diseases. However, lacking medical images can lead to inaccurate diagnoses and ineffective treatments. Generative models offer a promising solution for addressing medical image shortage problems due to their ability to generate new data from existing datasets and detect anomalies in this data.
Data augmentation with position augmentation methods like scaling, cropping, flipping, padding, rotation, and translation could lead to more overfitting in domains with little data, such as medical image data.
This paper proposes the GAN-GA, a generative model optimized by embedding a genetic algorithm. The proposed model enhances image fidelity and diversity while preserving distinctive features. The proposed medical image synthesis approach improves the quality and fidelity of medical images, an essential aspect of image interpretation. To evaluate synthesized images: Frechet Inception Distance (FID) is used. The proposed GAN-GA model is tested by generating Acute lymphoblastic leukemia (ALL) medical images, an image dataset, and is the first time to be used in generative models. Our results were compared to those of InfoGAN as a baseline model. The experimental results show that the proposed optimized GAN-GA enhances FID scores by about 6.8%, especially in earlier training epochs. The source code and dataset will be available at: https://github.com/Mustafa-AbdulRazek/InfoGAN-GA.","['Generative', 'Models', 'InfoGAN', 'Medical', 'Image', 'Generation', 'Genetic', 'Algorithms.']",[]
"The Multi-Agent Path Finding (MAPF) problem involves planning collision-free paths for multiple agents in a shared environment. The majority of MAPF solvers rely on the assumption that an agent can arrive at a specific location at a specific timestep. However, real-world execution uncertainties can cause agents to deviate from this assumption, leading to collisions and deadlocks. Prior research solves this problem by having agents follow a Temporal Plan Graph (TPG), enforcing a consistent passing order at every location as defined in the MAPF plan. However, we show that TPGs are overly strict because, in some circumstances, satisfying the passing order requires agents to wait unnecessarily, leading to longer execution time. To overcome this issue, we introduce a new graphical representation called a Bidirectional Temporal Plan Graph (BTPG), which allows switching passing orders during execution to avoid unnecessary waiting time. We design two anytime algorithms for constructing a BTPG: BTPG-naïve and BTPG-optimized. Experimental results show that following BTPGs consistently outperforms following TPGs, reducing unnecessary waits by 8-20%.",[''],[]
,[''],[]
"The chiral magnetic/vortical effect (CME/CVE)
in heavy-ion collisions probe the topological sector of Quantum Chromodynamics, where 𝒫𝒫\cal Pcaligraphic_P and 𝒞⁢𝒫𝒞𝒫\cal CPcaligraphic_C caligraphic_P symmetries are violated locally in strong interactions.
However, the experimental observables for the CME/CVE are dominated by backgrounds related to elliptic flow and nonflow.
We employ event shape variables to mitigate the flow background and event planes based on spectators to minimize the nonflow background.
We report on the CME search in Au+Au collisions at sNNsubscript𝑠NN\sqrt{s_{\rm NN}}square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 7.7, 14.6, 19.6, 27, and 200 GeV, as well as the CVE search at 19.6 and 27 GeV.",[''],[]
,[''],[]
"Heavy-ion collisions provide a unique opportunity to explore nucleon-hyperon (N-Y) interactions through two-particle correlations. The p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlations shed light on both N-Y two-body and N-N-Y three-body interactions, which is crucial for understanding neutron star properties. We present the high precision measurement of p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and the first measurement of d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlation with sNN=subscript𝑠NNabsent\sqrt{s_{{}_{\rm NN}}}=square-root start_ARG italic_s start_POSTSUBSCRIPT start_FLOATSUBSCRIPT roman_NN end_FLOATSUBSCRIPT end_POSTSUBSCRIPT end_ARG = 3 GeV Au+Au collisions at STAR. Using the Lednicky-Lyuboshitz formalism, we characterized emission source size, the scattering length (f0subscript𝑓0f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT), and the effective range (d0subscript𝑑0d_{0}italic_d start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) of p−Λ𝑝Λp-\Lambdaitalic_p - roman_Λ and d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ interactions. Using the f0subscript𝑓0f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and d0subscript𝑑0d_{0}italic_d start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT extracted from two spin states in d−Λ𝑑Λd-\Lambdaitalic_d - roman_Λ correlation, the parameters from the doublet state indicate the hypertriton binding energy is consistent with the current average of world measurements.",[''],[]
"We propose a new way to explain and to visualize neural network classification through a decomposition-based explainable AI (DXAI).
Instead of providing an explanation heatmap, our method yields a decomposition of the image into class-agnostic and class-distinct parts, with respect to the data and chosen classifier. Following a fundamental signal processing paradigm of analysis and synthesis, the original image is the sum of the decomposed parts. We thus obtain a radically different way of explaining classification. The class-agnostic part ideally is composed of all image features which do not posses class information, where the class-distinct part is its complementary.
This new visualization can be more helpful and informative in certain scenarios, especially when the attributes are dense, global and additive in nature, for instance, when colors or textures are essential for class distinction. Code is available at https://github.com/dxai2024/dxai.",[''],[]
"The Ginzburg-Landau (GL) theory is very successful in describing the pairing symmetry, a fundamental characterization of the broken symmetries in a paired superfluid or superconductor. However, GL theory does not describe fermionic excitations such as Bogoliubov quasiparticles or Andreev bound states that are directly related to topological properties of the superconductor. In this work, we show that the symmetries of the fermionic excitations are captured by a Projective Symmetry Group (PSG), which is a group extension of the bosonic symmetry group in the superconducting state. We further establish a correspondence between the pairing symmetry and the fermion PSG. When the normal and superconducting states share the same spin rotational symmetry, there is a simpler correspondence between the pairing symmetry and the fermion PSG, which we enumerate for all 32 crystalline point groups. We also discuss the general framework for computing PSGs when the spin rotational symmetry is spontaneously broken in the superconducting state. This PSG formalism leads to experimental consequences, and as an example, we show how a given pairing symmetry dictates the classification of topological superconductivity.",[''],['USA']
"Kantorovich operators are non-linear extensions of Markov operators and are omnipresent in several branches of mathematical analysis. The asymptotic behaviour of their iterates plays an important role even in classical ergodic, potential and probability theories, which are normally concerned with linear Markovian operators, semi-groups, and resolvents.
The Kantorovich operators that appear implicitly in these cases, though non-linear, are all positively 1111-homogenous. General Kantorovich operators amount to assigning “a cost” to most operations on measures and functions normally conducted “for free” in these classical settings. Motivated by extensions of the Monge-Kantorovich duality in mass transport, the stochastic counterpart of Aubry-Mather theory for Lagrangian systems, weak KAM theory à la Fathi-Mather, and ergodic optimization of dynamical systems, we study the asymptotic properties of general Kantorovich operators.",[''],[]
"A famous theorem in graph theory—originating with Euler—characterizes connected even-degree graphs
as (1) those graphs that admit an Euler tour, and (2) those connected graphs that decompose as a face-disjoint union of cycles.
We explore a 2-dimensional generalization of this theorem, with graphs (i.e., 1-complexes) replaced by
2-complexes. This entails an interesting generalization of cycles, and the introduction
of the notion of a “2-dimensional Euler tour.”",[''],[]
"Approximate Bayesian computation (ABC) methods are standard tools for inferring parameters of complex models when the likelihood function is analytically intractable. A popular approach to improving the poor acceptance rate of the basic rejection sampling ABC algorithm is to use sequential Monte Carlo (ABC SMC) to produce a sequence of proposal distributions adapting towards the posterior, instead of generating values from the prior distribution of the model parameters. Proposal distribution for the subsequent iteration is typically obtained from a weighted set of samples, often called particles, of the current iteration of this sequence. Current methods for constructing these proposal distributions treat all the particles equivalently, regardless of the corresponding value generated by the sampler, which may lead to inefficiency when propagating the information across iterations of the algorithm. To improve sampler efficiency, we introduce a modified approach called stratified distance ABC SMC. Our algorithm stratifies particles based on their distance between the corresponding synthetic and observed data, and then constructs distinct proposal distributions for all the strata. Taking into account the distribution of distances across the particle space leads to substantially improved acceptance rate of the rejection sampling. We further show that efficiency can be gained by introducing a novel stopping rule for the sequential process based on the stratified posterior samples and demonstrate these advances by several examples.",[''],"['Norway', 'henri.e.pesonen@medisin.uio.no', 'Norway', 'UK', 'Finland']"
"We treat some classes of stochastic partial differential equations of Schrödinger type within the framework of white noise analysis,
combined with Wiener-Itô chaos expansions and pseudodifferential operator methods. The initial data and potential term of the Schrödinger operator are assumed to be generalized stochastic processes that have spatial dependence. We prove that the equations under consideration have unique solutions in the appropriate (intersections of
weighted) Sobolev-Kato-Kondratiev spaces.","['Key words and phrases: ', 'Stochastic partial differential equations,', 'Wick product,', 'Chaos expansions,', 'Schrödinger equation, pseudodifferential calculus']",[]
"Two quantum algorithms are presented for the numerical solution of a linear one-dimensional advection-diffusion equation with periodic boundary conditions. Their accuracy and performance with increasing qubit number are compared point-by-point with each other. Specifically, we solve the linear partial differential equation with a Quantum Linear Systems Algorithms (QLSA) based on the Harrow–Hassidim–Lloyd method and a Variational Quantum Algorithm (VQA), for resolutions that can be encoded using up to 6 qubits, which corresponds to N=64𝑁64N=64italic_N = 64 grid points on the unit interval. Both algorithms are of hybrid nature, i.e., they involve a combination of classical and quantum computing building blocks. The QLSA and VQA are solved as ideal statevector simulations using the in-house solver QFlowS and open-access Qiskit software, respectively. We discuss several aspects of both algorithms which are crucial for a successful performance in both cases. These are the sizes of an additional quantum register for the quantum phase estimation for the QLSA and the choice of the algorithm of the minimization of the cost function for the VQA. The latter algorithm is also implemented in the noisy Qiskit framework including measurement and decoherence circuit noise. We reflect the current limitations and suggest some possible routes of future research for the numerical simulation of classical fluid flows on a quantum computer.",[''],[]
,[''],[]
,[''],[]
"Traffic from distributed training of machine learning (ML) models makes up a large and growing fraction of the traffic mix in enterprise data centers. While work on distributed ML abounds, the network traffic generated by distributed ML has received little attention.
Using measurements on a testbed network, we investigate the traffic characteristics
generated by the training of the ResNet-50 neural network
with an emphasis on studying its short-term burstiness.
For the latter we propose metrics that
quantify traffic burstiness at different time scales.
Our analysis reveals that distributed ML traffic exhibits a very high degree of burstiness on
short time scales, exceeding a 60:1 peak-to-mean ratio on time intervals as long as 5 ms. We observe that training software orchestrates
transmissions in such a way that burst transmissions from different sources
within the same application do not result
in congestion and packet losses.
An extrapolation of the measurement data to multiple applications
underscores the challenges of distributed ML traffic
for congestion and flow control algorithms.",[''],[]
"In this work, we consider the offline preference-based reinforcement learning problem. We focus on the two-phase learning approach that is prevalent in previous reinforcement learning from human preference works. We find a challenge in applying two-phase learning in the offline PBRL setting that the learned utility model can be too hard for the learning agent to optimize during the second learning phase. To overcome the challenge, we propose a two-phasing learning approach under behavior regularization through action clipping. The insight is that the state-actions which are poorly covered by the dataset can only provide limited information and increase the complexity of the problem in the second learning phase. Our method ignores such state-actions during the second learning phase to achieve higher learning efficiency. We empirically verify that our method has high learning efficiency on a variety of datasets in robotic control environments.",[''],[]
"This paper presents an efficient coupling of the 3D Stokes flow interacting with an effective perforated periodic heterogeneous anisotropic 2D plate. The effective model was obtained by the asymptotic analysis in earlier works and here an effective numerical algorithm is given. By Q3subscript𝑄3Q_{3}italic_Q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT or bi-cubic spacial interpolation the time-dependent problem was reduced to an algebraic system of ordinary differential equation in time. Different examples were given, demonstrating the influence of the structural plate parameters on the solution.",[''],[]
"We construct various statistical ensembles associated to the 3D Euler equations and prove global regularity of these equations for data living on these sets. Similar results are also proven for generalized SQG equations and some shell models. Qualitative properties of the ensembles and the constructed flows are also given.


Keywords: 3D Euler equation, SQG equations, shell models, global regularity, invariant measure, long time behavior, fluctuation-dissipation, statistical ensemble.

2020 MSC: 35B40, 35B44, 35B65, 35Q31, 35Q35,
76D03.",[''],[]
"In the literature, lines of the projective space PG⁢(3,q)PG3𝑞\mathrm{PG}(3,q)roman_PG ( 3 , italic_q ) are partitioned into classes, each of which is a union of line orbits under the stabilizer group of the twisted cubic. The least studied class is named 𝒪6subscript𝒪6\mathcal{O}_{6}caligraphic_O start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT. This class contains lines external to the twisted cubic which are not its chords or axes and do not lie in any of its osculating planes. For even and odd q𝑞qitalic_q, we propose a new family of orbits of 𝒪6subscript𝒪6\mathcal{O}_{6}caligraphic_O start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and investigate in detail their stabilizer groups and the corresponding submatrices of the point-line and plane-line incidence matrices. To obtain these submatrices, we explored the number of solutions of cubic and quartic equations connected with intersections of lines (including the tangents to the twisted cubic), points, and planes in PG⁢(3,q)PG3𝑞\mathrm{PG}(3,q)roman_PG ( 3 , italic_q ).",[''],[]
"This work focuses on plant leaf disease classification and explores three crucial aspects: adversarial training, model explainability, and model compression. The models’ robustness against adversarial attacks is enhanced through adversarial training, ensuring accurate classification even in the presence of threats. Leveraging explainability techniques, we gain insights into the model’s decision-making process, improving trust and transparency. Additionally, we explore model compression techniques to optimize computational efficiency while maintaining classification performance. Through our experiments, we determine that on a benchmark dataset, the robustness can be the price of the classification accuracy with performance reductions of 3%-20% for regular tests and gains of 50%-70% for adversarial attack tests. We also demonstrate that a student model can be 15-25 times more computationally efficient for a slight performance reduction, distilling the knowledge of more complex models.",[''],[]
,[''],[]
"We compute a nonperturbative effective potential between two static fermions in
light-front Yukawa theory as a Hamiltonian eigenvalue problem.
Fermion pair production is suppressed, to make
possible an exact analytic solution in the form of a coherent state of
bosons that form clouds around the sources. The effective potential is
essentially an interference term between individual clouds. The model
is regulated with Pauli-Villars bosons and fermions, to achieve
consistent quantization and renormalization of masses and couplings.
This extends earlier work on scalar Yukawa theory where Pauli-Villars
regularization did not play a central role. The key result is that
the nonperturbative solution restores rotational symmetry even though
the light-front formulation of Yukawa theory, with its preferred axis,
appears antithetical to such a symmetry.",[''],"['USA', 'USA', 'USA']"
"Let Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be positive definite matrices for every i=1,⋯,m.𝑖1⋯𝑚i=1,\cdots,m.italic_i = 1 , ⋯ , italic_m . Let Z=[Zi⁢j]𝑍delimited-[]subscript𝑍𝑖𝑗Z=[Z_{ij}]italic_Z = [ italic_Z start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ] be the block matrix, where Zi⁢j=Bi12⁢(∑k=1mAk)⁢Bj12subscript𝑍𝑖𝑗superscriptsubscript𝐵𝑖12superscriptsubscript𝑘1𝑚subscript𝐴𝑘superscriptsubscript𝐵𝑗12Z_{ij}=B_{i}^{{}^{\frac{1}{{}_{2}}}}\left(\displaystyle\sum_{k=1}^{m}A_{k}%
\right)B_{j}^{{}^{\frac{1}{{}_{2}}}}italic_Z start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT for every i,j=1,⋯,mformulae-sequence𝑖𝑗1⋯𝑚i,j=~{}1,\cdots,mitalic_i , italic_j = 1 , ⋯ , italic_m. It is shown that



‖|∑i=1m(Ais⁢♯⁢Bis)r|‖≤‖|Zs⁢r2|‖≤‖|((∑i=1mAi)s⁢r⁢p4⁢(∑i=1mBi)s⁢r⁢p2⁢(∑i=1mAi)s⁢r⁢p4)1p|‖,normsuperscriptsubscript𝑖1𝑚superscriptsuperscriptsubscript𝐴𝑖𝑠♯superscriptsubscript𝐵𝑖𝑠𝑟normsuperscript𝑍𝑠𝑟2normsuperscriptsuperscriptsuperscriptsubscript𝑖1𝑚subscript𝐴𝑖𝑠𝑟𝑝4superscriptsuperscriptsubscript𝑖1𝑚subscript𝐵𝑖𝑠𝑟𝑝2superscriptsuperscriptsubscript𝑖1𝑚subscript𝐴𝑖𝑠𝑟𝑝41𝑝\left|\left|\left|\sum_{i=1}^{m}\left(A_{i}^{s}\sharp B_{i}^{s}\right)^{r}%
\right|\right|\right|\leq\left|\left|\left|Z^{{}^{\frac{sr}{{}_{2}}}}\right|%
\right|\right|\leq\left|\left|\left|\left(\left(\scalebox{0.85}{$\displaystyle%
\sum_{i=1}^{m}A_{i}$}\right)^{\frac{srp}{{}_{4}}}\left(\scalebox{0.85}{$%
\displaystyle\sum_{i=1}^{m}B_{i}$}\right)^{\frac{srp}{{}_{2}}}\left(\scalebox{%
0.85}{$\displaystyle\sum_{i=1}^{m}A_{i}$}\right)^{\frac{srp}{{}_{4}}}\right)^{%
\frac{1}{{}_{p}}}\right|\right|\right|,| | | ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ♯ italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT | | | ≤ | | | italic_Z start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT divide start_ARG italic_s italic_r end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT | | | ≤ | | | ( ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ( ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG italic_s italic_r italic_p end_ARG start_ARG start_FLOATSUBSCRIPT 4 end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG start_FLOATSUBSCRIPT italic_p end_FLOATSUBSCRIPT end_ARG end_POSTSUPERSCRIPT | | | ,



for all s≥2𝑠2s\geq 2italic_s ≥ 2, for all p>0𝑝0p>0italic_p > 0 and r≥1𝑟1r\geq 1italic_r ≥ 1 such that r⁢p≥1𝑟𝑝1rp\geq 1italic_r italic_p ≥ 1 and for all unitarily invariant norms.
This result generalizes the results in [8] and gives an affirmative answer to a conjecture in [9] for all s≥2𝑠2s\geq 2italic_s ≥ 2 and for all p>0𝑝0p>0italic_p > 0 and r≥1𝑟1r\geq 1italic_r ≥ 1 such that r⁢p≥1𝑟𝑝1rp\geq 1italic_r italic_p ≥ 1 and t=12𝑡12t=\frac{1}{2}italic_t = divide start_ARG 1 end_ARG start_ARG 2 end_ARG.
This result also leads directly to Dinh, Ahsani, and Tam’s conjecture in [1] and proves Audenaert’s result in [2].","['Key words and phrases:', 'Unitarily invariant norm, positive semidefinite matrix,', 'Bourin’s question, inequality.']",[]
,[''],[]
"Along the lines of the Einstein-Rosen wave equation of General Relativity (GR), we derive a gravitational wave equation with cylindrical symmetry in the Einstein-aether (EA) theory. We show that the gravitational wave in the EA is periodic in time for both the metric functions Ψ⁢(r,t)Ψ𝑟𝑡\Psi(r,t)roman_Ψ ( italic_r , italic_t ) and H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ). However, in GR, Ψ⁢(r,t)Ψ𝑟𝑡\Psi(r,t)roman_Ψ ( italic_r , italic_t ) is periodic in time, but H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ) is semi-periodic in time, having a secular drifting in the wave frequency. The evolution of wave pulses of a given width is entirely different in both theories in the H⁢(r,t)𝐻𝑟𝑡H(r,t)italic_H ( italic_r , italic_t ) metric function due to this frequency drifting. Another fundamental difference between the two theories is the gravitational wave velocity. While in GR, the waves propagate with the speed of light, in EA, there is no upper limit to the wave velocity, reaching infinity if c13→1→subscript𝑐131c_{13}\rightarrow 1italic_c start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT → 1 and zero if c13→−∞→subscript𝑐13c_{13}\rightarrow-\inftyitalic_c start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT → - ∞. We also show that energy-momentum pseudotensor and superpotential get contributions from aether in addition to the usual gravitational field part. All these characteristics are observational signatures that differentiate GR and EA.",[''],[]
"We present the notion of non-abelian descent type, which classifies torsors up to twisting by a Galois cocycle. This relies on the previous construction of kernels and non-abelian Galois 2-cohomology due to Springer and Borovoi. The necessity of descent types arises in the context of the descent theory where no torsors are given a priori, for example, when we wish to study the arithmetic properties such as the Brauer–Manin obstruction to the Hasse principle on homogeneous spaces without rational points. This new definition also unifies the types by Colliot-Thélène–Sansuc, the extended types by Harari–Skorobogatov, and the finite descent type by Harpaz–Wittenberg.",[''],[]
"This is a survey of the recent results and unsolved problems about locally compact homogeneous metric spaces. Mostly, homogeneous finite-dimensional A⁢N⁢R𝐴𝑁𝑅ANRitalic_A italic_N italic_R-spaces are discussed.","['Key words and phrases: absolute neighborhood retracts, cohomological dimension, cohomology and homology groups,\nhomogeneous spaces']",[]
"This paper studies a discrete-time version of the Lucas-Uzawa endogenous growth model with physical and human capital. Equilibrium existence is proved applying tools of dynamic programming with unbounded returns. The proofs rely on properties of homogeneous functions and also apply well-known inequalities in real analysis, seldom used in the literature, which significantly simplifies the task of verifying certain assumptions that are rather technical in nature.
Keywords: Endogenous Growth, Equilibrium, Human capital, Dynamic Programming

JEL Classification: C61, C63, O41",[''],"['Argentina', 'Argentina']"
"The accuracy of 3D Human Pose and Shape reconstruction (HPS) from an image is progressively improving. Yet, no known method is robust across all image distortion. To address issues due to variations of camera poses, we introduce SHARE, a novel fine-tuning method that utilizes adversarial data augmentation to enhance the robustness of existing HPS techniques.
We perform a comprehensive analysis on the impact of camera poses on HPS reconstruction outcomes. We first generated large-scale image datasets captured systematically from diverse camera perspectives. We then established a mapping between camera poses and reconstruction errors as a continuous function that characterizes the relationship between camera poses and HPS quality. Leveraging this representation, we introduce RoME (Regions of Maximal Error), a novel sampling technique for our adversarial fine-tuning method.
The SHARE framework is generalizable across various single-view HPS methods and we demonstrate its performance on HMR, SPIN, PARE, CLIFF and ExPose. Our results illustrate a reduction in mean joint errors across single-view HPS techniques, for images captured from multiple camera positions without compromising their baseline performance. In many challenging cases, our method surpasses the performance of existing models, highlighting its practical significance for diverse real-world applications.",[''],[]
"Over the past decade, characterizing the exact asymptotic risk of regularized estimators in high-dimensional regression has emerged as a popular line of work. This literature considers the proportional asymptotics framework, where the number of features and samples both diverge, at a rate proportional to each other. Substantial work in this area relies on Gaussianity assumptions on the observed covariates. Further, these studies often assume the design entries to be independent and identically distributed. Parallel research investigates the universality of these findings, revealing that results based on the i.i.d. Gaussian assumption extend to a broad class of designs, such as i.i.d. sub-Gaussians. However, universality results examining dependent covariates so far focused on correlation-based dependence or a highly structured form of dependence, as permitted by right rotationally invariant designs. In this paper, we break this barrier and study a dependence structure that in general falls outside the purview of these established classes. We seek to pin down the extent to which results based on i.i.d. Gaussian assumptions persist. We identify a class of designs characterized by a block dependence structure that ensures the universality of i.i.d. Gaussian-based results. We establish that the optimal values of the regularized empirical risk and the risk associated with convex regularized estimators, such as the Lasso and ridge, converge to the same limit under block dependent designs as they do for i.i.d. Gaussian entry designs.
Our dependence structure differs significantly from correlation-based dependence, and enables, for the first time, asymptotically exact risk characterization in prevalent nonparametric regression problems in high dimensions. Finally, we illustrate through experiments that this universality becomes evident quite early, even for relatively moderate sample sizes.",[''],"['University', 'slahiry@fas.harvard.edu', 'University', 'pragya@fas.harvard.edu']"
"We construct a 3333-dimensional cell complex that is the 3333-skeleton for an Eilenberg–MacLane classifying space for the symmetric group 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT.
Our complex starts with the presentation for 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT with n−1𝑛1n-1italic_n - 1 adjacent transpositions with squaring, commuting, and braid relations, and adds seven classes of 3333-cells that fill in certain 2222-spheres bounded by these relations.
We use a rewriting system and a combinatorial method of K. Brown to prove the correctness of our construction.
Our main application is a computation of the second cohomology of 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT in certain twisted coefficient modules; we use this computation in a companion paper to study splitting of extensions related to braid groups.
As another application, we give a concrete description of the third homology of 𝔖nsubscript𝔖𝑛\mathfrak{S}_{n}fraktur_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT with untwisted coefficients in ℤℤ\mathbb{Z}blackboard_Z.",[''],[]
"The advancements in nanotechnology, material science, and electrical engineering have shrunk the sizes of electronic devices down to the micro/nanoscale.
This brings the opportunity of developing the Internet of Nano Things (IoNT), an extension of the Internet of Things (IoT).
With nanodevices, numerous new possibilities emerge in the biomedical, military fields, and industrial products.
However, a continuous energy supply is needed for these devices to work.
At the micro/nanoscale, batteries cannot supply this demand due to size limitations and the limited energy contained in the batteries.
Internet of Harvester Nano Things (IoHNT), a concept of Energy Harvesting (EH), which converts the existing different energy sources, which otherwise would be dissipated to waste, into electrical energy via electrical generators.
Sources for EH are abundant, from sunlight, sound, water, and airflow to living organisms.
IoHNT methods are significant assets to ensure the proper operation of the IoNT; thus, in this review, we comprehensively investigate the most useful energy sources and IoHNT principles to power the nano/micro-scaled electronic devices with the scope of IoNT. We discuss the IoHNT principles, material selections, challenges, and state-of-the-art applications of each energy source for both in-vivo and in vitro applications.
Finally, we present the latest challenges of EH along with future research directions to solve the problems regarding constructing continuous IoNT containing various self-powered nanodevices.
Therefore, IoHNT represents a significant shift in nanodevice power supply, leading us towards a future where wireless technology is widespread.
Hence, it will motivate researchers to envision and contribute to the advancement of the following power revolution in IoNT, providing unmatched simplicity and efficiency.","['Index', 'Terms: \n', 'Energy harvesting,', 'Energy scavenging,', 'Hybrid', 'Energy', 'Harvesting,', 'IoT,', 'IoNT,', 'Nanodevices,', 'Nanogenerators.']",[]
"This work deals with undirected graphs that have the same betweenness centrality for each vertex,
so-called betweenness uniform graphs (or BUGs). The class of these graphs is not trivial and its
classification is still an open problem. Recently, Gago, Coroničová-Hurajová and Madaras conjectured
that for every rational α≥3/4𝛼34\alpha\geq 3/4italic_α ≥ 3 / 4 there exists a BUG having betweenness
centrality α𝛼\alphaitalic_α. We disprove this conjecture, and provide an alternative view of the
structure of betweenness-uniform graphs from the point of view of their complement. This allows
us to characterise all the BUGs with betweennes centrality at most 9/10, and show that their
betweenness centrality is equal to ℓℓ+1ℓℓ1\frac{\ell}{\ell+1}divide start_ARG roman_ℓ end_ARG start_ARG roman_ℓ + 1 end_ARG for some integer ℓ≤9ℓ9\ell\leq 9roman_ℓ ≤ 9. We
conjecture that this characterization extends to all the BUGs with betweenness centrality smaller
than 1.",[''],"['Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic', 'Republic']"
,[''],[]
"We consider normal subgroups N𝑁Nitalic_N of the braid group Bnsubscript𝐵𝑛B_{n}italic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that the quotient Bn/Nsubscript𝐵𝑛𝑁B_{n}/Nitalic_B start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT / italic_N is an extension of the symmetric group by an abelian group.
We show that, if n≥4𝑛4n\geq 4italic_n ≥ 4, then there are exactly 8888 commensurability classes of such subgroups.
We define a Specht subgroup to be a subgroup of this form that is maximal in its commensurability class.
We give descriptions of the Specht subgroups in terms of winding numbers and in terms of infinite generating sets.
The quotient of the pure braid group by a Specht subgroup is a module over the symmetric group.
We show that the modules arising this way are closely related to Specht modules for the partitions (n−1,1)𝑛11(n-1,1)( italic_n - 1 , 1 ) and (n−2,2)𝑛22(n-2,2)( italic_n - 2 , 2 ), working over the integers.
We compute the second cohomology of the symmetric group with coefficients in both of these Specht modules, working over an arbitrary commutative ring.
Finally, we determine which of the extensions of the symmetric group arising from Specht subgroups are split extensions.",[''],[]
,[''],[]
"We investigate the behavior of the empirical neighbourhood distribution of marked graphs in the framework of local weak convergence. We establish a large deviation principle for such families of empirical measures. The proof builds on Bordenave and Caputo’s seminal 2015 paper, and Delgosha and Anantharam’s 2019 introduction of BC entropy, relying on combinatorial lemmas that allow one to construct suitable approximations of measures supported on marked trees.

Keywords and phrases: large deviations, local topology, sparse random graphs. 
MSC 2010: 60F10, 05C80.",[''],[]
"We study inflation driven by the tachyon field in the holographic braneworld by assuming the second slow-roll parameter η𝜂\etaitalic_η is constant. The parameter η𝜂\etaitalic_η can be either defined by the tachyon scalar field and the Hubble parameter or by the Hubble parameter only. By assuming a constant η𝜂\etaitalic_η, we derive and numerically solve a differential equation for the Hubble expansion rate. We calculate numerically the scalar spectral index and the tensor-to-scalar ratio. We confront the results with the observational data and find some constraints on the free model parameters. The swampland conjectures are discussed in the context of the constant-roll inflation, with some accent on the holographic model.",[''],"['Serbia', 'Croatia', 'Serbia', 'Serbia', 'Serbia']"
,[''],[]
"This study focuses on the estimation of the Emax dose-response model, a widely utilized framework in clinical trials, agriculture, and environmental experiments. Existing challenges in obtaining maximum likelihood estimates (MLE) for model parameters are often ascribed to computational issues but, in reality, stem from the absence of MLE. Our contribution provides a new understanding and control of all the experimental situations that pratictioners might face, guiding them in the estimation process.
We derive the exact MLE for a three-point experimental design and we identify the two scenarios where the MLE fails. To address these challenges, we propose utilizing Firth’s modified score, providing its analytical expression as a function of the experimental design. Through a simulation study, we demonstrate that, in one of the problematic cases, the Firth modification yields a finite estimate. For the remaining case, we introduce a design-correction strategy akin to a hypothesis test.","['Key words and phrases: nonlinear regression,', 'Emax model, maximum likelihood, experimental design, small sample, score modification, optimal design']",[]
"This paper develops a stochastic and unifying framework to examine variability in car-following (CF) dynamics of commercial automated vehicles (AVs) and its direct relation to traffic-level dynamics. The asymmetric behavior (AB) model by Chen et al. (2012a) is extended to accommodate a range of CF behaviors by AVs and compare with the baseline of human-driven vehicles (HDVs). The parameters of the extended AB (EAB) model are calibrated using an adaptive sequential Monte Carlo method for Approximate Bayesian Computation (ABC-ASMC) to stochastically capture various uncertainties including model mismatch resulting from unknown AV CF logic. The estimated posterior distributions of the parameters reveal significant differences in CF behavior (1) between AVs and HDVs, and (2) across AV developers, engine modes, and speed ranges, albeit to a lesser degree. The estimated behavioral patterns and simulation experiments further reveal mixed platoon dynamics in terms of traffic throughout reduction and hysteresis.",[''],[]
"Agency is an important human characteristic that users of automated complex technologies are usually denied.
This affects the user’s experience leading to decreased satisfaction and productivity.
In this paper, we consider the ridesharing context and interviewed 7 drivers to understand the controls that would improve the agency they feel.
The results show that they desire transparency, community and an effective ability to seek redress.","['User', 'Agency,', 'Ridesharing']","['ParkPAUSA16802', 'ParkPAUSA16802']"
"In this review, we detail the commonality of mathematical intuitions that underlie three numerical methods used for the quantitative description of electron swarms propagating in a gas under the effect of externally applied electric and/or magnetic fields.
These methods can be linked to the integral transport equation, following a common thread much better known in the theory of neutron transport than in the theory of electron transport. First, we discuss the exact solution of the electron transport problem using Monte Carlo (MC) simulations. In reality we will progress much further, showing the interpretative role that the diagrams used in quantum theory and quantum field theory can play in the development of MC. Then, we present two methods, the Monte Carlo Flux and the Propagator method, which have been developed at this moment. The first one is based on a modified MC method, while the second shows the advantage of explicitly applying the mathematical idea of propagator to the transport problem.",[''],[]
,[''],[]
"Degeneracy plays an important role in understanding Turán- and Ramsey-type properties of graphs. Unfortunately, the usual hypergraphical generalization of degeneracy fails to capture these properties. We define the skeletal degeneracy of a k𝑘kitalic_k-uniform hypergraph as the degeneracy of its 1111-skeleton (i.e., the graph formed by replacing every k𝑘kitalic_k-edge by a k𝑘kitalic_k-clique). We prove that skeletal degeneracy controls hypergraph Turán and Ramsey numbers in a similar manner to (graphical) degeneracy.
Specifically, we show that k𝑘kitalic_k-uniform hypergraphs with bounded skeletal degeneracy have linear Ramsey number. This is the hypergraph analogue of the Burr–Erdős conjecture (proved by Lee). In addition, we give upper and lower bounds of the same shape for the Turán number of a k𝑘kitalic_k-uniform k𝑘kitalic_k-partite hypergraph in terms of its skeletal degeneracy. The proofs of both results use the technique of dependent random choice. In addition, the proof of our Ramsey result uses the ‘random greedy process’ introduced by Lee in his resolution of the Burr–Erdős conjecture.",[''],[]
"We have built and operated a cryogenic Penning trap arrangement that allows for the efficient production, selection, and long-term storage of highly charged atomic ions. In close similarity to an electron-beam ion trap (EBIT) it works by electron-impact ionisation of atoms inside a dedicated confinement region. The electrons are produced by field emission at liquid-helium temperature and are subsequently accelerated to the keV energy range. The electron beam is reflected through the trap multiple times to increase the ionisation efficiency. We show a characterisation of the system and measurements with argon and tungsten ions up to Ar16+limit-from16{}^{16+}start_FLOATSUPERSCRIPT 16 + end_FLOATSUPERSCRIPT and W27+limit-from27{}^{27+}start_FLOATSUPERSCRIPT 27 + end_FLOATSUPERSCRIPT, respectively.",[''],[]
"In this work, we study the effects of random temperature fluctuations on the equation of state of a non-interacting, relativistic fermion gas by means of the replica method. This picture provides a conceptual model for a non-equilibrium system, depicted as an ensemble of subsystems at different temperatures, randomly distributed with respect to a given mean value.
We then assume the temperature displays stochastic fluctuations T=T0+δ⁢T𝑇subscript𝑇0𝛿𝑇T=T_{0}+\delta Titalic_T = italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_δ italic_T with respect to its ensemble average value T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, with zero mean δ⁢T¯=0¯𝛿𝑇0\overline{\delta T}=0over¯ start_ARG italic_δ italic_T end_ARG = 0 and standard deviation δ⁢T2¯=Δ¯𝛿superscript𝑇2Δ\overline{\delta T^{2}}=\Deltaover¯ start_ARG italic_δ italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = roman_Δ. By means of the replica method, we obtain the average grand canonical potential, leading to the equation of state of the fermion gas expressed in terms of the excess pressure caused by these fluctuations with respect to the ideal gas at uniform temperature. We further extend our results for the ideal Bose gas as well. Our findings reveal an increase in pressure as the system’s ensemble average temperature T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT rises, consistently exceeding the pressure observed in an equilibrium state. Finally, we explore the implications for the deconfinement transition in the context of the simple Bag model, where we show that the critical temperature decreases.",[''],"['Chile', 'Africa', 'Chile', 'Chile', 'Chile', 'Chile']"
"A vertex in a graph is said to be sedentary if a quantum state assigned on that vertex tends to stay on that vertex. Under mild conditions, we show that the direct product and join operations preserve vertex sedentariness. We also completely characterize sedentariness in blow-up graphs. These results allow us to construct new infinite families of graphs with sedentary vertices. We prove that a vertex with a twin is either sedentary or admits pretty good state transfer. Moreover, we give a complete characterization of twin vertices that are sedentary, and provide sharp bounds on their sedentariness. As an application, we determine the conditions in which perfect state transfer, pretty good state transfer and sedentariness occur in complete bipartite graphs and threshold graphs of any order.",[''],[]
"Integer or fractional quantum Hall crystals, states postulating the coexistence of charge order with integer or fractional quantum Hall effect, have long been proposed in theoretical studies in Landau levels Kivelson et al. (1986); Halperin et al. (1986); Tešanović et al. (1989); Balents (1996); Fradkin and Kivelson (1999); Murthy (2000a). Inspired by recent experiments on integer or fractional quantum anomalous Hall (IQAH/FQAH) states in MoTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCai et al. (2023); Park et al. (2023); Zeng et al. (2023); Xu et al. (2023a) and rhombohedral multilayer graphene Lu et al. (2023a), this work examines the archetypal correlated flat band model on a checkerboard lattice at filling ν=2/3𝜈23\nu=2/3italic_ν = 2 / 3.
Interestingly, at this filling level, we find that this topological flatband does not stabilize conventional FQAH states. Instead, the unique interplay between smectic charge order and topological order gives rise to two intriguing quantum states. As the interaction strength increases, the system first transitions from a Fermi liquid into FQAH smectic (FQAHS) states, where FQAH topological order coexists cooperatively with smectic charge order. With a further increase in interaction strength, the system undergoes another quantum phase transition and evolves into a polar smectic metal. Contrary to conventional smectic order and FQAHS states, this gapless state spontaneously breaks the two-fold rotational symmetry, resulting in a nonzero electric dipole moment and ferroelectric order.
In addition to identifying the ground states, large-scale numerical simulations are also used to study low-energy excitations and thermodynamic characteristics. We find that FQAHS states exhibit two distinct temperature scales: the onset of charge order and the onset of the fractional Hall plateau, respectively. Interestingly, the latter is dictated by charge-neutral low-energy excitations with finite momenta, known as magnetorotons. Our studies suggest that these nontrivial phenomena could, in principle, be accessed in future experiments with moiré systems.",[''],"['work.', 'China', 'work.', 'China', 'China', 'USA', 'China']"
,[''],[]
"Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on image datasets show that HQ-VAE enhances codebook usage and improves reconstruction performance. We also validated HQ-VAE in terms of its applicability to a different modality with an audio dataset.",[''],[]
,[''],[]
"In this note, we discuss the extension of several important stable square matrices, e.g., D-stable matrices, diagonal dominance matrices, Volterra-Lyapunov stable matrices, to their corresponding non-square matrices. The extension is motivated by some distributed control-related problems, such as decentralized unconditional stability and decentralized integral controllability for non-square processes. We will provide the connections of conditions between these special square matrices and their associated non-square counterparts. Some conjectures for these special matrices are proposed for future research.",[''],[]
"In this paper,
we introduce a novel and simple method for obtaining high-quality text embeddings
using only synthetic data and less than 1111k training steps.
Unlike existing methods that often depend on multi-stage intermediate pre-training
with billions of weakly-supervised text pairs,
followed by fine-tuning with a few labeled datasets,
our method does not require building complex training pipelines
or relying on manually collected datasets that are often constrained by task diversity and language coverage.
We leverage proprietary LLMs to generate diverse synthetic data
for hundreds of thousands of text embedding tasks across nearly 100100100100 languages.
We then fine-tune open-source decoder-only LLMs on the synthetic data using standard contrastive loss.
Experiments demonstrate that our method achieves strong performance on highly competitive text embedding benchmarks
without using any labeled data.
Furthermore, when fine-tuned with a mixture of synthetic and labeled data,
our model sets new state-of-the-art results on the BEIR and MTEB benchmarks.",[''],[]
"This paper explores the impact of biologically plausible neuron models on the performance of Spiking Neural Networks (SNNs) for regression tasks. While SNNs are widely recognized for classification tasks, their application to Scientific Machine Learning and regression remains underexplored. We focus on the membrane component of SNNs, comparing four neuron models: Leaky Integrate-and-Fire, FitzHugh–Nagumo, Izhikevich, and Hodgkin-Huxley. We investigate their effect on SNN accuracy and efficiency for function regression tasks, by using Euler and Runge-Kutta 4th-order approximation schemes. We show how more biologically plausible neuron models improve the accuracy of SNNs while reducing the number of spikes in the system. The latter represents an energetic gain on actual neuromorphic chips since it directly reflects the amount of energy required for the computations.","['Index', 'Terms: ', 'Spiking', 'Neural', 'Networks,', 'LIF model,', 'FitzHugh-Nagumo model,', 'Izhikevich model,', 'Hodgkin-Huxley model,', 'Regression,', 'Scientific', 'Machine', 'Learning']","['mario_de_florio@brown.edu', 'adar_kahana@brown.edu', 'george_karniadakis@brown.edu']"
"Recent image restoration methods can be broadly categorized into two classes: (1) regression methods that recover the rough structure of the original image without synthesizing high-frequency details and (2) generative methods that synthesize perceptually-realistic high-frequency details even though the resulting image deviates from the original structure of the input.
While both directions have been extensively studied in isolation, merging their benefits with a single framework has been rarely studied.
In this paper, we propose UGPNet, a universal image restoration framework that can effectively achieve the benefits of both approaches by simply adopting a pair of an existing regression model and a generative model.
UGPNet first restores the image structure of a degraded input using a regression model and synthesizes a perceptually-realistic image with a generative model on top of the regressed output.
UGPNet then combines the regressed output and the synthesized output, resulting in a final result that faithfully reconstructs the structure of the original image in addition to perceptually-realistic textures.
Our extensive experiments on deblurring, denoising, and super-resolution demonstrate that UGPNet can successfully exploit both regression and generative methods for high-fidelity image restoration.",[''],[]
,[''],[]
"We study the quench dynamics of a two dimensional superconductor in a lattice of size up to 200×200200200200\times 200200 × 200 employing the self-consistent time dependent Bogoliubov-de Gennes (BdG) formalism. In the clean limit, the dynamics of the order parameter for short times, characterized by a fast exponential growth and an oscillatory pattern, agrees with the Bardeen-Cooper-Schrieffer (BCS) prediction. However, unlike BCS, we observe for longer times an universal exponential decay of these time oscillations that we show explicitly
to be induced by the full emergence of spatial inhomogeneities of the order parameter, even in the clean limit, characterized by the exponential growth of its variance.
The addition of a weak disorder does not alter these results qualitatively.
In this region, the spatial inhomogeneities rapidly develops into an intricate spatial structure consisting of ordered fragmented stripes in perpendicular directions where the order parameter is heavily suppressed especially in the central region.
As the disorder strength increases, the fragmented stripes gradually turn into a square lattice of approximately circular spatial regions where the condensate is heavily suppressed. A further increase of disorder leads to the deformation and ultimate destruction of this lattice.
We explore suitable settings for the experimental confirmation of these findings.",[''],"['China', 'China']"
"With the expanding reach of physics, xenon-based detectors such as PandaX-4T in the China Jinping Underground Laboratory aim to cover an energy range from sub-keV to multi-MeV.
A linear response of the photomultiplier tubes (PMTs) is required for both scintillation and electroluminescence signals.
Through a dedicated bench test, we investigated the cause of the non-linear response in the Hamamatsu R11410-23 PMTs used in PandaX-4T.
The saturation and suppression of the PMT waveform observed during the commissioning of PandaX-4T were caused by the high-voltage divider base.
The bench test data validated the de-saturation algorithm used in the PandaX-4T data analysis.
We also confirmed the improvement in linearity of a new PMT base design, which will be used to upgrade the PMT readout system in PandaX-4T.",[''],[]
"We propose EMAGE, a framework to generate full-body human gestures from audio and masked gestures, encompassing facial, local body, hands, and global movements. To achieve this, we first introduce BEATX (BEAT-SMPLX-FLAME), a new mesh-level holistic co-speech dataset. BEATX combines MoShed SMPLX body with FLAME head parameters and further refines the modeling of head, neck, and finger movements, offering a community-standardized, high-quality 3D motion captured dataset.
EMAGE leverages masked body gesture priors during training to boost inference performance. It involves a Masked Audio Gesture Transformer, facilitating joint training on audio-to-gesture generation and masked gesture reconstruction to effectively encode audio and body gesture hints. Encoded body hints from masked gestures are then separately employed to generate facial and body movements.
Moreover, EMAGE adaptively merges speech features from the audio’s rhythm and content and utilizes four compositional VQ-VAEs to enhance the results’ fidelity and diversity. Experiments demonstrate that EMAGE generates holistic gestures with state-of-the-art performance and is flexible in accepting predefined spatial-temporal gesture inputs, generating complete, audio-synchronized results. Our code and dataset are available111https://pantomatrix.github.io/EMAGE/.",[''],[]
,[''],[]
"We investigate the magnetic excitations of the trimerized Heisenberg models with intra-trimer interaction J1subscript𝐽1J_{1}italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and inter-trimer interaction J2subscript𝐽2J_{2}italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT on four different two-dimensional lattices using a combination of stochastic series expansion quantum Monte Carlo (SSE QMC) and stochastic analytic continuation methods (SAC), complemented by cluster perturbation theory (CPT). These models exhibit quasi-particle-like excitations when g=J2/J1𝑔subscript𝐽2subscript𝐽1g=J_{2}/J_{1}italic_g = italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT / italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is small, characterized by low-energy magnons, intermediate-energy doublons, and high-energy quartons. The low-energy magnons are associated with the magnetic ground states. They can be described by the linear spin wave theory (LSWT) of the effective block spin model and the original spin model. Doublons and quartons emerge from the corresponding internal excitations of the trimers with distinct energy levels, which can be effectively analyzed using perturbation theory when the ratio of exchange interactions g𝑔gitalic_g is small. In this small g𝑔gitalic_g regime, we observe a clear separation between the magnon and higher-energy spectra. However, as g𝑔gitalic_g increases, these three spectra gradually merge into the magnon modes or continua. Nevertheless, the LSWT fails to provide quantitative descriptions of the higher-energy excitation bands due to significant quantum fluctuations. Notably, in the Collinear II and trimerized hexagon lattice, a broad continuum emerges above the single-magnon spectrum, originating from the quasi-1D physics due to the dilute connections between chains. Our numerical analysis of these 2D trimers yields valuable theoretical predictions and explanations for the inelastic neutron scattering (INS) spectra of 2D magnetic materials featuring trimerized lattices.",[''],['China']
"We prove a weighted a priori energy estimate for the two dimensional water-waves problem with contact points in the absence of gravity and surface tension. When the surface graph function and its time derivative have some decay near the contact points, we show that there is corresponding decay for the velocity, the pressure and other quantities in a short time interval. As a result, we have fixed contact points and contact angles. To prove the energy estimate, a conformal mapping is used to transform the equation for the mean curvature into an equivalent equation in a flat strip with some weights. Moreover, the weighted limits at contact points for the velocity, the pressure etc. are tracked and discussed. Our formulation can be adapted to deal with more general cases.",[''],[]
"We study the ergodic properties of two classes of random dynamical systems: a type of Markov chain which we call the alternating random walk and a certain stochastic billiard system which describes the motion of a free-moving rough disk bouncing between two parallel rough walls. Our main results characterize the types of Markov transition kernels which make each system ergodic – in the first case, with respect to uniform measure on the state space, and in the second case, with respect to Lambertian measure (a classic measure from geometric optics). In addition, building on results from [25], we give explicit examples of rough microstructures which produce ergodic dynamics in the second system. Both systems have the property that the transition kernel governing the dynamics is singular with respect to uniform measure on the state space. As a result, these systems occupy a kind of mean in the problem space between diffusive processes, where establishing ergodicity is relatively easy, and physically realistic deterministic systems, where questions of ergodicity are far less approachable.",[''],[]
"Deep Learning models have become an integrated component of modern software systems.
In response to the challenge of model design, researchers proposed Automated Machine Learning (AutoML) systems, which automatically search for model architecture and hyperparameters for a given task.
Like other software systems, existing AutoML systems suffer from bugs.
We identify two common and severe bugs in AutoML, performance bug (i.e., searching for the desired model takes an unreasonably long time) and ineffective search bug (i.e., AutoML systems are not able to find an accurate enough model).
After analyzing the workflow of AutoML, we observe that existing AutoML systems overlook potential opportunities in search space, search method, and search feedback, which results in performance and ineffective search bugs.
Based on our analysis, we design and implement DREAM, an automatic debugging and repairing system for AutoML systems.
It monitors the process of AutoML to collect detailed feedback and automatically repairs bugs by expanding search space and leveraging a feedback-driven search strategy.
Our evaluation results show that DREAM can effectively and efficiently repair AutoML bugs.",[''],"['UniversityXi’anChina', 'States', 'States', 'UniversityXi’anChina']"
"In a seminal paper [1],
Watling proposes a stochastic variational inequality approach to model traffic flow equilibrium over a network where
the transportation time is random and
a path is selected by
to transport if the user’s expected utility of the transportation of the path is maximized over their paths.
A key feature of Watling’s model is that the user’s utility function
incorporates a penalty term for lateness
and the resulting equilibrium is known as
Late Arrival Penalised User Equilibrium (LAPUE).
In this paper, we revisit the LAPUE model with a different focus:
we begin by adopting a new penalty function
which gives a smooth transition of the boundary
between lateness and no lateness and demonstrate
the LAPUE model based on the new penalty function
has a unique equilibrium and is stable with respect to (w.r.t.)
small perturbation of probability distribution under moderate conditions.
We then move on to discuss statistical robustness of the modified
LAPUE (MLAPUE) model by considering the
case that the data to be used for fitting the density function may be perturbed in practice or there is a discrepancy between the probability distribution of the underlying uncertainty constructed with empirical data and the true probability distribution in future,
we investigate how the data perturbation may affect the equilibrium. We undertake the analysis from two perspectives:
(a) a few data are
perturbed by outliers and (b)
all data are potentially
perturbed.
In case (a), we use the well-known influence function to quantify the sensitivity of the equilibrium by the outliers and in case (b) we examine
the difference between empirical distributions of the equilibrium based on perturbed data and the equilibrium based on unperturbed data.
To examine the performance of the MLAPUE model and our theoretical analysis of statistical robustness, we carry out some numerical experiments, the preliminary results confirm the statistical robustness as desired.",[''],[]
"At the intersection of computation and cognitive science, graph theory is utilized as a formalized description of complex relationships and structures. Traditional graph models are often static, lacking dynamic and autonomous behavioral patterns. They rely on algorithms with a global view, significantly differing from biological neural networks, in which, to simulate information storage and retrieval processes, the limitations of centralized algorithms must be overcome. This study introduces a directed graph model that equips each node with adaptive learning and decision-making capabilities, thereby facilitating decentralized dynamic information storage and modeling and simulation of the brain’s memory process. We abstract different storage instances as directed graph paths, transforming the storage of information into the assignment, discrimination, and extraction of different paths. To address writing and reading challenges, each node has a personalized adaptive learning ability. A storage algorithm without a “God’s eye” view is developed, where each node uses its limited neighborhood information to facilitate the extension, formation, solidification, and awakening of directed graph paths, achieving competitive, reciprocal, and sustainable utilization of limited resources. Storage behavior occurs in each node, with adaptive learning behaviors of nodes concretized in a microcircuit centered around a variable resistor, simulating the electrophysiological behavior of neurons. Based on Ohm’s and Kirchhoff’s laws, we simulated the dynamics of this directed graph network on a computer, where the network could store and retrieve uploaded instances, confirming the model’s effectiveness and exploring its storage capacity. Under the constraints of neurobiology on the anatomy and electrophysiology of biological neural networks, this model offers a plausible explanation for the mechanism of memory realization, providing a comprehensive, system-level experimental validation of the memory trace theory.",[''],[]
"In this paper, we investigate the concept of infinite dense-lineability recently introduced by M. Calderón-Moreno, P. Gerlach-Mena and J. Prado-Bassas. We answer a question posed by the authors about the equivalence between infinite (pointwise) dense-lineability and (pointwise) dense-lineability. We prove that the equivalence always holds in first-countable topological vector spaces and under some assumptions about the weight of the topology. However, the equivalence is not always true, as shown in an example. Furthermore, we introduce the notions of infinite (α,β)𝛼𝛽(\alpha,\beta)( italic_α , italic_β )-dense-lineability and infinite (strongly) dense-algebrability and obtain some analogous results in these cases. We also obtain a criterion for strongly dense-algebrability for sets of the form X∖Y𝑋𝑌X\setminus Yitalic_X ∖ italic_Y, where X𝑋Xitalic_X is a free algebra and Y𝑌Yitalic_Y is a free subalgebra of X𝑋Xitalic_X.",[''],[]
"Understanding and predicting the emotional trajectory in multi-party multi-turn conversations is of great significance. Such information can be used, for example, to generate empathetic response in human-machine interaction or to inform models of pre-emptive toxicity detection. In this work, we introduce the novel problem of Predicting Emotions in Conversations (PEC) for the next turn (n+1𝑛1n+1italic_n + 1), given combinations of textual and/or emotion input up to turn n𝑛nitalic_n. We systematically approach the problem by modeling three dimensions inherently connected to evoked emotions in dialogues, including (i) sequence modeling, (ii) self-dependency modeling, and (iii) recency modeling. These modeling dimensions are then incorporated into two deep neural network architectures, a sequence model and a graph convolutional network model. The former is designed to capture the sequence of utterances in a dialogue, while the latter captures the sequence of utterances and the network formation of multi-party dialogues. We perform a comprehensive empirical evaluation of the various proposed models for addressing the PEC problem. The results indicate (i) the importance of the self-dependency and recency model dimensions for the prediction task, (ii) the quality of simpler sequence models in short dialogues, (iii) the importance of the graph neural models in improving the predictions in long dialogues.",[''],[]
"Cavity-mediated adiabatic transfer (CMAT) is a robust way to perform a two-qubit gate between trapped atoms inside an optical cavity.
In the previous study by Goto and Ichimura [H. Goto and K. Ichimura, Phys. Rev. A 77, 013816 (2008).], the upper bound of success probability of CMAT was shown where the operation is adiabatically slow.
For practical applications, however, it is crucial to operate CMAT as fast as possible without sacrificing the success probability.
In this paper, we investigate the operational speed limit of CMAT conditioned on the success probability being close to the upper bound.
In CMAT both the adiabatic condition and the decay of atoms and cavity modes limit the operational speed.
We show which of these two conditions more severely limits the operational speed in each cavity-QED parameter region, and find that the maximal operational speed, which is proportional to γ⁢C𝛾𝐶\gamma\sqrt{C}italic_γ square-root start_ARG italic_C end_ARG, is achieved when the influence of cavity decay is dominant compared to spontaneous emission, where γ𝛾\gammaitalic_γ and C𝐶Citalic_C are spontaneous emission rate and cooperativity.",[''],"['Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan']"
"To obtain strong convergence rates of numerical schemes, an overwhelming majority of existing works impose a global monotonicity condition on coefficients of SDEs.
On the contrary, a majority of SDEs from applications do not have globally monotone coefficients.
As a recent breakthrough,
the authors of [Hutzenthaler, Jentzen, Ann. Probab., 2020] originally presented a perturbation theory
for stochastic differential equations (SDEs),
which is crucial to recovering strong convergence rates
of numerical schemes in a non-globally monotone setting.
However, only a convergence rate of order 1/2121/21 / 2
was obtained there for time-stepping schemes such as
a stopped increment-tamed Euler-Maruyama (SITEM) method.
As an open problem,
a natural question was raised
by the aforementioned work as to whether higher
convergence rate than 1/2121/21 / 2 can be obtained
when higher order schemes are used.
The present work attempts to solve
the tough problem. To this end, we develop
some new perturbation estimates that are
able to reveal the order-one
strong convergence of numerical methods.
As the first application of the newly developed estimates,
we identify the expected order-one pathwise uniformly
strong convergence
of the SITEM method for additive noise driven SDEs
and multiplicative noise driven second order SDEs
with non-globally monotone coefficients.
As the other application, we propose and analyze a
positivity preserving explicit Milstein-type method for
Lotka-Volterra competition model driven by multi-dimensional
noise, with a pathwise uniformly strong convergence rate of
order one recovered under mild assumptions.
These obtained results are completely new
and significantly improve the existing theory.
Numerical experiments are also
provided to confirm the theoretical findings.

AMS subject classifications:  60H35,
65C30.

Key Words:  SDEs with non-globally monotone coefficients; explicit method;
exponential integrability properties;
pathwise uniformly strong convergence; order-one strong convergence; Lotka-Volterra competition model.",[''],[]
"In the Constructor-Blocker game, two players, Constructor and Blocker, alternatively claim unclaimed edges of the complete graph Knsubscript𝐾𝑛K_{n}italic_K start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. For given graphs F𝐹Fitalic_F and H𝐻Hitalic_H, Constructor can only claim edges that leave her graph F𝐹Fitalic_F-free, while Blocker has no restrictions. Constructor’s goal is to build as many copies of H𝐻Hitalic_H as she can, while Blocker attempts to stop this. The game ends once there are no more edges that Constructor can claim. The score g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) of the game is the number of copies of H𝐻Hitalic_H in Constructor’s graph at the end of the game when both players play optimally and Constructor plays first.

In this paper, we extend results of Patkós, Stojaković and Vizer on g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) to many pairs of H𝐻Hitalic_H and F𝐹Fitalic_F: We determine g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) when H=Kr𝐻subscript𝐾𝑟H=K_{r}italic_H = italic_K start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and χ⁢(F)>r𝜒𝐹𝑟\chi(F)>ritalic_χ ( italic_F ) > italic_r, also when both H𝐻Hitalic_H and F𝐹Fitalic_F are odd cycles, using Szemerédi’s Regularity Lemma. We also obtain bounds of g⁢(n,H,F)𝑔𝑛𝐻𝐹g(n,H,F)italic_g ( italic_n , italic_H , italic_F ) when H=K3𝐻subscript𝐾3H=K_{3}italic_H = italic_K start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and F=K2,2𝐹subscript𝐾22F=K_{2,2}italic_F = italic_K start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPT.",[''],[]
"It has been more than 30 years since the enigmatic 21 μ𝜇\muitalic_μm emission feature was first discovered in protoplanetary nebulae (PPNs).
Although dozens of different dust carrier candidates have been proposed, there is as yet no widely accepted one.
We present the results of molecular observations toward 21 μ𝜇\muitalic_μm objects using the 10 m Submillimeter Telescope of Arizona Radio Observatory at the 1.3 mm band
and the 13.7 m telescope of Purple Mountain Observatory at the 3 mm band,
aiming to investigate whether the gas-phase environments of these unusual sources have some peculiarities compared to normal PPNs.
We detect 31 emission lines belonging to seven different molecular species, most of which are the first detection in 21 μ𝜇\muitalic_μm PPNs.
The observations provide clues on the identification of the 21 μ𝜇\muitalic_μm feature.
We report a correlation study between the fractional abundance of gas-phase molecules and the strengths of the 21 μ𝜇\muitalic_μm emission.
Our study shows that given the small sample size, the 21 μ𝜇\muitalic_μm feature has weak or no correlations with the gas-phase molecules.
Future radio observations of high spatial and spectral resolution toward a large sample are desirable to elucidate the 21 μ𝜇\muitalic_μm emission phenomena.","['21\u2009μ𝜇\\muitalic_μm feature —', 'ISM: molecules — circumstellar matter —', 'Line: identification —', 'Circumstellar envelopes']","['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
"Answering questions using pre-trained language models (LMs) and knowledge graphs (KGs) presents challenges in identifying relevant knowledge and performing joint reasoning. We compared LMs (fine-tuned for the task) with the previously published QAGNN method for the Question-answering (QA) objective and further measured the impact of additional factual context on the QAGNN performance. The QAGNN method employs LMs to encode QA context and estimate KG node importance, and effectively update the question choice entity representations using Graph Neural Networks (GNNs). We further experimented with enhancing the QA context encoding by incorporating relevant knowledge facts for the question stem. The models are trained on the OpenbookQA dataset, which contains ~6000 4-way multiple choice questions and is widely used as a benchmark for QA tasks.
Through our experimentation, we found that incorporating knowledge facts context led to a significant improvement in performance. In contrast, the addition of knowledge graphs to language models resulted in only a modest increase. This suggests that the integration of contextual knowledge facts may be more impactful for enhancing question-answering performance compared to solely adding knowledge graphs.","['Knowledge graphs (KG), language models (LM), question and answering (QA), graph neural networks (GNN)']","['GeorgiaAtlantaGeorgiaUSA', 'GeorgiaAtlantaGeorgiaUSA', 'GeorgiaAtlantaGeorgiaUSA', 'GeorgiaAtlantaGeorgiaUSA']"
"The investigation of high-temperature superconductors under high
magnetic fields is one of the most important topics in condensed matter physics.
For YBa22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTCu33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTO77{}_{7}start_FLOATSUBSCRIPT 7 end_FLOATSUBSCRIPT (YBCO), the measurements of magnetoresistance
under a high magnetic field are technically challenging because the required magnetic field (B𝐵Bitalic_B) is 100 T class.
The low temperature (from 52 to 150 K) magnetoresistance is measured in optimally-doped
YBCO thin films under the condition B𝐵Bitalic_B∥parallel-to\parallel∥CuO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT-plane up to 103 T by employing the
single-turn coil technique and a radio frequency reflection method.
The electrical resistivity ρ𝜌\rhoitalic_ρ exhibits B𝐵Bitalic_B-linear behavior in the
normal phase in the high magnetic field region.
The field slope coefficient
β𝛽\betaitalic_β (=d⁢ρ/d⁢B𝑑𝜌𝑑𝐵d\rho/dBitalic_d italic_ρ / italic_d italic_B) becomes converged at low temperatures.
The convergency of β𝛽\betaitalic_β below Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT indicates the field-induced strange metal
phase, which is determined by the quantum critical fluctuation at high magnetic fields. The β𝛽\betaitalic_β value difference under the different directions
of the magnetic field suggests the strong anisotropy in quantum critical fluctuations in the strange metal phase of
YBCO.",[''],"['Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan', 'Japan']"
"In the modern world, the amount of visual data recorded has been rapidly increasing. In many cases, data is stored in geographically distinct locations and thus requires a large amount of time and space to consolidate. Sometimes, there are also regulations for privacy protection which prevent data consolidation. In this work, we present federated implementations for object detection and recognition using a federated Faster R-CNN (FRCNN) and image segmentation using a federated Fully Convolutional Network (FCN). Our FRCNN was trained on 5000 examples of the COCO2017 dataset while our FCN was trained on the entire train set of the CamVid dataset. The proposed federated models address the challenges posed by the increasing volume and decentralized nature of visual data, offering efficient solutions in compliance with privacy regulations.",[''],[]
"Evaluating the performance of autonomous vehicle planning algorithms necessitates simulating long-tail traffic scenarios. Traditional methods for generating safety-critical scenarios often fall short in realism and controllability. Furthermore, these techniques generally neglect the dynamics of agent interactions. To mitigate these limitations, we introduce a novel closed-loop simulation framework rooted in guided diffusion models. Our approach yields two distinct advantages: 1) the generation of realistic long-tail scenarios that closely emulate real-world conditions, and 2) enhanced controllability, enabling more comprehensive and interactive evaluations. We achieve this through novel guidance objectives that enhance road progress while lowering collision and off-road rates. We develop a novel approach to simulate safety-critical scenarios through an adversarial term in the denoising process, which allows the adversarial agent to challenge a planner with plausible maneuvers, while all agents in the scene exhibit reactive and realistic behaviors. We validate our framework empirically using the NuScenes dataset, demonstrating improvements in both realism and controllability. These findings affirm that guided diffusion models provide a robust and versatile foundation for safety-critical, interactive traffic simulation, extending their utility across the broader landscape of autonomous driving. For additional resources and demonstrations, visit our project page at https://safe-sim.github.io.",[''],[]
"We improve the upper bound on the Ramsey number R⁢(3,10)𝑅310R(3,10)italic_R ( 3 , 10 ) from 42424242 to 41414141. Hence R⁢(3,10)𝑅310R(3,10)italic_R ( 3 , 10 ) is equal to 40404040 or 41414141.",[''],[]
,[''],[]
,[''],[]
"The Gaussian process (GP) regression model is a widely employed surrogate modeling technique for computer experiments, offering precise predictions and statistical inference for the computer simulators that generate experimental data.
Estimation and inference for GP can be performed in both frequentist and Bayesian frameworks.
In this chapter, we construct the GP model through variational inference, particularly employing the recently introduced energetic variational inference method by Wang et al. (2021).
Adhering to the GP model assumptions, we derive posterior distributions for its parameters.
The energetic variational inference approach bridges the Bayesian sampling and optimization and enables approximation of the posterior distributions and identification of the posterior mode.
By incorporating a normal prior on the mean component of the GP model, we also apply shrinkage estimation to the parameters, facilitating mean function variable selection. To showcase the effectiveness of our proposed GP model, we present results from three benchmark examples.",[''],"['Amherst', 'Technology', 'Riverside', 'Technology']"
"Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs).
Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents.
In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination.
This paper presents RAGTruth, a corpus tailored for analyzing word-level hallucinations in various domains and tasks within the standard RAG frameworks for LLM applications.
RAGTruth comprises nearly 18,000 naturally generated responses from diverse LLMs using RAG.
These responses have undergone meticulous manual annotations at both the individual cases and word levels, incorporating evaluations of hallucination intensity.
We not only benchmark hallucination frequencies across different LLMs, but also critically assess the effectiveness of several existing hallucination detection methodologies.
Furthermore, we show that using a high-quality dataset such as RAGTruth, it is possible to finetune a relatively small LLM and achieve a competitive level of performance in hallucination detection when compared to the existing prompt-based approaches using state-of-the-art large language models such as GPT-4.111The RAGTruth dataset is available at https://github.com/ParticleMedia/RAGTruth",[''],"['NewsBreak', 'NewsBreak', 'NewsBreak', 'NewsBreak', 'NewsBreak', 'NewsBreak', 'NewsBreak', 'Urbana-Champaign']"
"In this work, we introduce the notion of warped Yosida regularization and study the asymptotic behaviour of the orbit of dynamical systems generated by warped Yosida regularization, which includes Douglas-Rachford dynamical system. We analyze an algorithm where the inclusion problem is first approximated by a regularized one and then the preconditioned regularization parameter is reduced to converge to a solution of original problem. We propose and investigate backward-backward splitting using degenerate preconditioning for monotone inclusion problems. The applications provide a tool for finding a minima of a preconditioned regularization of the sum of two convex functions.",[''],['India']
,[''],[]
"We conducted 4-night multiwavelength observations of an active M-dwarf star EV Lac on 2022 October 24−--27 with simultaneous coverage of soft X-rays (NICER; 0.2−--12 keVkeV\mathrm{keV}roman_keV, Swift XRT; 0.2−--10 keVkeV\mathrm{keV}roman_keV), near-ultraviolet (Swift UVOT/UVW2; 1600−--3500 ÅÅ\mathrm{\AA}roman_Å ), optical photometry (TESS; 6000−--10000 ÅÅ\mathrm{\AA}roman_Å), and optical spectroscopy (Nayuta/MALLS; 6350−--6800 ÅÅ\mathrm{\AA}roman_Å).
During the campaign, we detected a flare starting at 12:28 UTC on October 25 with its white-light bolometric energy of 3.4×10323.4superscript10323.4\times 10^{32}3.4 × 10 start_POSTSUPERSCRIPT 32 end_POSTSUPERSCRIPT erg.
At about 1 hour after this flare peak, our H⁢αH𝛼\mathrm{H\alpha}roman_H italic_α spectrum showed a blue-shifted excess component at its corresponding velocity of ∼100⁢km⁢s−1similar-toabsent100kmsuperscripts1\sim 100\>\mathrm{km\>s^{-1}}∼ 100 roman_km roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
This may indicate that the prominence erupted with a 1-hour delay of the flare peak.
Furthermore, the simultaneous 20-second cadence near-ultraviolet and white-light curves show gradual and rapid brightening behaviors during the rising phase at this flare.
The ratio of flux in NUV to white light at the gradual brightening was ∼0.49similar-toabsent0.49\sim 0.49∼ 0.49, which may suggest that the temperature of the blackbody is low (<9000⁢Kabsent9000K<9000\>\mathrm{K}< 9000 roman_K) or the maximum energy flux of a nonthermal
electron beam is less than 5×1011⁢erg⁢cm−2⁢s−15superscript1011ergsuperscriptcm2superscripts15\times 10^{11}\>\mathrm{erg\>cm^{-2}\>s^{-1}}5 × 10 start_POSTSUPERSCRIPT 11 end_POSTSUPERSCRIPT roman_erg roman_cm start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT roman_s start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
Our simultaneous observations of NUV and white-light flare raise the issue of a simple estimation of UV flux from optical continuum data
by using a blackbody model.",[''],[]
We perform a finite-size scaling analysis of the critical point in the heavy-quark region of QCD at nonzero temperature. Our previous analysis on the Binder cumulant at Nt=4subscript𝑁𝑡4N_{t}=4italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 4 is extended to finer lattices with Nt=6subscript𝑁𝑡6N_{t}=6italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 6 and 8888. The aspect ratio is also extended up to 15151515 to suppress the non-singular contribution. High-precision analysis of the Binder cumulant is realized by an efficient Monte-Carlo simulation with the hopping-parameter expansion (HPE). Effects of higher-order terms in the HPE are incorporated by the reweighting method.,[''],[]
"Various popular multiplayer battle royale games share a lot of common elements. Drawing from our observations, we summarized these shared characteristics and subsequently proposed a novel heuristic algorithm named multiplayer battle game-inspired optimizer (MBGO). The proposed MBGO streamlines mainstream multiplayer battle royale games into two discrete phases: movement and battle. Specifically, the movement phase incorporates the principles of commonly encountered “safe zones” to incentivize participants to relocate to areas with a higher survival potential. The battle phase simulates a range of strategies adopted by players in various situations to enhance the diversity of the population. To evaluate and analyze the performance of the proposed MBGO, we executed it alongside eight other algorithms, including three classics and five latest ones, across multiple diverse dimensions within the CEC2017 and CEC2020 benchmark functions. In addition, we employed several industrial design problems to evaluate the scalability and practicality of the proposed MBGO. The results of the statistical analysis reveal that the novel MBGO demonstrates significant competitiveness, excelling not only in convergence speed, but also in achieving high levels of convergence accuracy across both benchmark functions and real-world problems.","['Index', 'Terms: ', 'Optimization ,', 'Heuristic', 'Algorithm ,', 'Evolutionary', 'Computation ,', 'Multiplayer', 'Battle', 'Game-Inspired', 'Optimizer']",[]
Insert your english abstract here.,[''],[]
"Selecting proper clients to participate in the iterative federated learning (FL) rounds is critical to effectively harness a broad range of distributed datasets. Existing client selection methods simply consider the variability among FL clients with uni-modal data, however, have yet to consider clients with multi-modalities. We reveal that traditional client selection scheme in MFL may suffer from a severe modality-level bias, which impedes the collaborative exploitation of multi-modal data, leading to insufficient local data exploration and global aggregation. To tackle this challenge, we propose a Client-wise Modality Selection scheme for MFL (CMSFed) that can comprehensively utilize information from each modality via avoiding such client selection bias caused by modality imbalance. Specifically, in each MFL round, the local data from different modalities are selectively employed to participate in local training and aggregation to mitigate potential modality imbalance of the global model. To approximate the fully aggregated model update in a balanced way, we introduce a novel local training loss function to enhance the weak modality and align the divergent feature spaces caused by inconsistent modality adoption strategies for different clients simultaneously. Then, a modality-level gradient decoupling method is designed to derive respective submodular functions to maintain the gradient diversity during the selection progress and balance MFL according to local modality imbalance in each iteration. Our extensive experiments showcase the superiority of CMSFed over baselines and its effectiveness in multi-modal data exploitation.",[''],[]
,[''],[]
"Single-view 3D shape retrieval is a challenging task that is increasingly important with the growth of available 3D data. Prior work that has studied this task has not focused on evaluating how realistic occlusions impact performance, and how shape retrieval methods generalize to scenarios where either the target 3D shape database contains unseen shapes, or the input image contains unseen objects. In this paper, we systematically evaluate single-view 3D shape retrieval along three different axes: the presence of object occlusions and truncations, generalization to unseen 3D shape data, and generalization to unseen objects in the input images. We standardize two existing datasets of real images and propose a dataset generation pipeline to produce a synthetic dataset of scenes with multiple objects exhibiting realistic occlusions. Our experiments show that training on occlusion-free data as was commonly done in prior work leads to significant performance degradation for inputs with occlusion. We find that that by first pretraining on our synthetic dataset with occlusions and then finetuning on real data, we can significantly outperform models from prior work and demonstrate robustness to both unseen 3D shapes and unseen objects.",[''],[]
,[''],[]
"Some theoretical models for the early universe predict a spike-type enhancement in the primordial power spectrum on a small scale, which would result in forming early-formed dark matter halos (EFHs).
In this work, we study the CMB lensing effect, considering the existence of EFHs, and investigate the potential to probe the EFHs and the primordial perturbations on scales smaller than 1⁢M⁢p⁢c1Mpc1\mathrm{Mpc}1 roman_M roman_p roman_c.
We numerically calculate the angular power spectrum of the lensing potential and the lensed CMB anisotropy of temperature, E-mode, and B-mode polarization, including the nonlinear effects of EFHs.
We find the possibility that the lensed CMB temperature anisotropy is significantly enhanced on small scales, ℓ>1000ℓ1000\ell>1000roman_ℓ > 1000, and could be tested by component decomposition of observed signals through multi-frequency observations.
Through the calculation with different models of the spiky-type power spectrum, we demonstrate that the accurate measurements of the CMB lensing effect would provide insight into the abundance of EFHs within the limited mass range around 1012⁢M⊙superscript1012subscript𝑀direct-product10^{12}M_{\odot}10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT and the primordial power spectrum on the limited scales around k∼1⁢M⁢p⁢c−1similar-to𝑘1Mpsuperscriptc1k\sim 1\mathrm{Mpc}^{-1}italic_k ∼ 1 roman_M roman_p roman_c start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT.
In particular,
we find that the existence of such EFHs can amplify the lensed anisotropy of CMB B-mode polarization even on large scales, ℓ<100ℓ100\ell<100roman_ℓ < 100, as the overall enhancement by ∼10%similar-toabsentpercent10\sim 10\%∼ 10 % level compared to the standard structure formation model without EFHs.
Therefore, future CMB measurements such as the LiteBIRD satellite can probe the existence of the EFHs and the spike-type primordial power spectrum
through the precise measurement
of the large-scale CMB B-mode polarization.",[''],"['Japan', 'Japan']"
"In this paper, we tackle the
following problem:
compute the gcd for several univariate polynomials with parametric coefficients. It amounts
to partitioning the parameter space into “cells” so that the gcd has a uniform expression over each cell and constructing a uniform expression of gcd in each cell.
We tackle the problem as follows.
We begin by making a natural and obvious extension of subresultant
polynomials of two polynomials to several polynomials. Then we develop the following
structural
theories about them.


1.

We generalize Sylvester’s theory
to several polynomials, in order to obtain an elegant relationship between generalized
subresultant polynomials and the gcd of several polynomials, yielding an elegant
algorithm.



2.

We generalize Habicht’s theory to several polynomials, in order to obtain
a systematic relationship between generalized subresultant polynomials and pseudo-remainders, yielding an efficient algorithm.



Using the generalized theories, we present a simple (structurally elegant) algorithm
which is significantly more efficient (both in the output size and computing time) than algorithms based on previous approaches.",[''],[]
"Human Interaction Recognition (HIR) is the process of identifying and understanding interactive actions and activities between multiple participants in a specific environment or situation. The aim of this task is to recognise the action interactions between multiple people or entities and their meaning and purpose. Many single Convolutional Neural Network (CNN) has issues, such as the inability to capture global instance interaction features or difficulty in training, leading to ambiguity in action semantics. In addition, the computational complexity of the Transformer cannot be ignored, and its ability to capture local information and motion features in the image is poor. In this work, we propose a Two-stream Hybrid CNN-Transformer Network (THCT-Net), which exploits the local specificity of CNN and models global dependencies through the Transformer. CNN and Transformer simultaneously model the entity, time and space relationships between interactive entities respectively. Specifically, Transformer-based stream integrates 3D convolutions with multi-head self-attention to learn inter-token correlations; We propose a new multi-branch CNN framework for CNN-based streams that automatically learns joint spatio-temporal features from skeleton sequences. The convolutional layer independently learns the local features of each joint neighborhood and aggregates the features of all joints. And the raw skeleton coordinates as well as their temporal difference are integrated with a dual-branch paradigm to fuse the motion features of the skeleton. Besides, a residual structure is added to speed up training convergence. Finally, the recognition results of the two branches are fused using parallel splicing. Multi-grained information modelling is employed to enhance the accuracy and robustness of the action recognition system. Experimental results on diverse and challenging datasets, such as NTU-RGBD, H2O, and Assembly101, demonstrate that the proposed method can better comprehend and infer the meaning and context of various actions, outperforming state-of-the-art methods.","['Index', 'Terms: \nhuman interaction recognition,', 'CNN,', 'Transformer, multi-grained context.']",[]
,[''],[]
"We perform a combined fit of the invariant mass distribution of X⁢(3872)→J/ψ⁢π+⁢π−→𝑋3872𝐽𝜓superscript𝜋superscript𝜋{X(3872)}\rightarrow{J}/{\psi}\pi^{+}\pi^{-}italic_X ( 3872 ) → italic_J / italic_ψ italic_π start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_π start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT from LHCb and X⁢(3872)→D0⁢D¯0⁣*→𝑋3872superscript𝐷0superscript¯𝐷0{X(3872)}\rightarrow{D}^{0}\overline{D}^{0*}italic_X ( 3872 ) → italic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT over¯ start_ARG italic_D end_ARG start_POSTSUPERSCRIPT 0 * end_POSTSUPERSCRIPT from Belle using an effective field theory approach. In this approach, we can directly determine the Z𝑍Zitalic_Z which is the probability of finding the compact component in X⁢(3872)𝑋3872{X(3872)}italic_X ( 3872 ). In the combined analysis, we find that the Z𝑍Zitalic_Z is 0.52±0.11plus-or-minus0.520.110.52\pm 0.110.52 ± 0.11 for X⁢(3872)𝑋3872{X(3872)}italic_X ( 3872 ).","['Exotic hadron,', 'X\u2062(3872)𝑋3872{X(3872)}italic_X ( 3872 ),', 'Compositeness criterion,', 'Effective field theory,', 'Lineshape']","['China', 'China']"
,[''],[]
"Solving partial differential equations (PDEs) numerically often requires huge computing time, energy cost, and hardware resources in practical applications. This has limited their applications in many scenarios (e.g., autonomous systems, supersonic flows) that have a limited energy budget and require near real-time response. Leveraging optical computing, this paper develops an on-chip training framework for physics-informed neural networks (PINNs), aiming to solve high-dimensional PDEs with fJ/MAC photonic power consumption and ultra-low latency. Despite the ultra-high speed of optical neural networks, training a PINN on an optical chip is hard due to (1) the large size of photonic devices, and (2) the lack of scalable optical memory devices to store the intermediate results of back-propagation (BP). To enable realistic optical PINN training, this paper presents a scalable method to avoid the BP process. We also employ a tensor-compressed approach to improve the convergence and scalability of our optical PINN training. This training framework is designed with tensorized optical neural networks (TONN) for scalable inference acceleration and MZI phase-domain tuning for in-situ optimization. Our simulation results of a 20-dim HJB PDE show that our photonic accelerator can reduce the number of MZIs by a factor of 1.17×103absentsuperscript103\times 10^{3}× 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, with only 1.36 J and 1.15 s to solve this equation. This is the first real-size optical PINN training framework that can be applied to solve high-dimensional PDEs.",[''],[]
"Deep neural networks have significantly improved the performance of face forgery detection models in discriminating Artificial Intelligent Generated Content (AIGC). However, their security is significantly threatened by the injection of triggers during model training (i.e., backdoor attacks). Although existing backdoor defenses and manual data selection can mitigate those using human-eye-sensitive triggers, such as patches or adversarial noises, the more challenging natural backdoor triggers remain insufficiently researched. To further investigate natural triggers, we propose a novel analysis-by-synthesis backdoor attack against face forgery detection models, which embeds natural triggers in the latent space. We thoroughly study such backdoor vulnerability from two perspectives: (1) Model Discrimination (Optimization-Based Trigger): we adopt a substitute detection model and find the trigger by minimizing the cross-entropy loss; (2) Data Distribution (Custom Trigger): we manipulate the uncommon facial attributes in the long-tailed distribution to generate poisoned samples without the supervision from detection models. Furthermore, to completely evaluate the detection models towards the latest AIGC, we utilize both state-of-the-art StyleGAN and Stable Diffusion for trigger generation. Finally, these backdoor triggers introduce specific semantic features to the generated poisoned samples (e.g., skin textures and smile), which are more natural and robust. Extensive experiments show that our method is superior from three levels: (1) Attack Success Rate: ours achieves a high attack success rate (over 99%percent\%%) and incurs a small model accuracy drop (below 0.2%percent\%%) with a low poisoning rate (less than 3%percent\%%); (2) Backdoor Defense: ours shows better robust performance when faced with existing backdoor defense methods; (3) Human Inspection: ours is less human-eye-sensitive from a comprehensive user study.",['Backdoor attacks; face forgery detection; facial attribute editing'],"['SciencesBeijingChina', 'SciencesBeijingChina', 'SciencesBeijingChina', 'TechnologyNanjingChina', 'SciencesBeijingChina']"
,[''],[]
"Video-based facial affect analysis has recently attracted increasing attention owing to its critical role in human-computer interaction.
Previous studies mainly focus on developing various deep learning architectures and training them in a fully supervised manner. Although significant progress has been achieved by these supervised methods, the longstanding lack of large-scale high-quality labeled data severely hinders their further improvements.
Motivated by the recent success of self-supervised learning in computer vision, this paper introduces a self-supervised approach, termed Self-supervised Video Facial Affect Perceiver (SVFAP), to address the dilemma faced by supervised methods.
Specifically, SVFAP leverages masked facial video autoencoding to perform self-supervised pre-training on massive unlabeled facial videos.
Considering that large spatiotemporal redundancy exists in facial videos, we propose a novel temporal pyramid and spatial bottleneck Transformer as the encoder of SVFAP, which not only enjoys low computational cost but also achieves excellent performance.
To verify the effectiveness of our method, we conduct experiments on nine datasets spanning three downstream tasks, including dynamic facial expression recognition, dimensional emotion recognition, and personality recognition.
Comprehensive results demonstrate that SVFAP can learn powerful affect-related representations via large-scale self-supervised pre-training and it significantly outperforms previous state-of-the-art methods on all datasets.
Codes will be available at https://github.com/sunlicai/SVFAP.","['Index', 'Terms: ', 'Video-based facial affect analysis, self-supervised learning, masked autoencoding,Transformer, spatial bottleneck, temporal pyramid']",[]
"In this paper, we study the stability for 2-D plane Poiseuille flow (1−y2,0)1superscript𝑦20(1-y^{2},0)( 1 - italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 0 ) in a channel 𝕋×(−1,1)𝕋11\mathbb{T}\times(-1,1)blackboard_T × ( - 1 , 1 ) with non-slip boundary condition. Three effects are studied in this paper: enhanced dissipation, inviscid damping and boundary layer effect. For the Navier-Stokes equations around Poiseuille flow with non-slip boundary condition, we prove that if the initial perturbation of velocity u0subscript𝑢0u_{0}italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT satisfies



‖u0‖H2+≤ϵ0⁢ν34subscriptnormsubscript𝑢0superscript𝐻limit-from2subscriptitalic-ϵ0superscript𝜈34\|u_{0}\|_{H^{2+}}\leq\epsilon_{0}\nu^{\frac{3}{4}}∥ italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT italic_H start_POSTSUPERSCRIPT 2 + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ≤ italic_ϵ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_ν start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT



for some constants ϵ0>0subscriptitalic-ϵ00\epsilon_{0}>0italic_ϵ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 independent of the viscosity ν𝜈\nuitalic_ν, then the solution to 2-D Navier-Stokes equations does not transit from plane Poiseuille flow. Meanwhile, for the Navier-slip boundary problem, we prove that if the initial perturbation of velocity u0subscript𝑢0u_{0}italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT satisfies



‖u0‖H32+≤ϵ1⁢ν12subscriptnormsubscript𝑢0superscript𝐻limit-from32subscriptitalic-ϵ1superscript𝜈12\|u_{0}\|_{H^{\frac{3}{2}+}}\leq\epsilon_{1}\nu^{\frac{1}{2}}∥ italic_u start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT italic_H start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 2 end_ARG + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ≤ italic_ϵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_ν start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT



for some constants ϵ1>0subscriptitalic-ϵ10\epsilon_{1}>0italic_ϵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0 independent of the viscosity ν𝜈\nuitalic_ν, then the solution to 2-D Navier-Stokes equations does not transit from plane Poiseuille flow, which improves the result of [17] from ν34superscript𝜈34\nu^{\frac{3}{4}}italic_ν start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT to ν12superscript𝜈12\nu^{\frac{1}{2}}italic_ν start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT.",[''],[]
"We consider locally recoverable codes (LRCs) and aim to determine the smallest
possible length n=nq⁢(k,d,r)𝑛subscript𝑛𝑞𝑘𝑑𝑟n=n_{q}(k,d,r)italic_n = italic_n start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_k , italic_d , italic_r ) of a linear [n,k,d]qsubscript𝑛𝑘𝑑𝑞[n,k,d]_{q}[ italic_n , italic_k , italic_d ] start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT-code with locality r𝑟ritalic_r.
For k≤7𝑘7k\leq 7italic_k ≤ 7 we exactly determine all values of n2⁢(k,d,2)subscript𝑛2𝑘𝑑2n_{2}(k,d,2)italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_k , italic_d , 2 ) and for k≤6𝑘6k\leq 6italic_k ≤ 6
we exactly determine all values of n2⁢(k,d,1)subscript𝑛2𝑘𝑑1n_{2}(k,d,1)italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_k , italic_d , 1 ). For the ternary field we also
state a few numerical results. As a general result we prove that nq⁢(k,d,r)subscript𝑛𝑞𝑘𝑑𝑟n_{q}(k,d,r)italic_n start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_k , italic_d , italic_r )
equals the Griesmer bound if the minimum Hamming distance d𝑑ditalic_d is sufficiently
large and all other parameters are fixed.
Mathematics Subject Classification: 94B27, 94B05
Keywords: linear codes, locally recoverable codes, data storage, bounds for parameters",[''],['sascha.kurz@fau.de']
"We consider here the Multi_Bot problem for the scheduling and the resource parametrization of jobs related to the production or the transportation of different products inside a given time horizon. Those jobs must meet known in advance demands. The time horizon is divided into several discrete identical periods representing each the time needed to proceed a job. The objective is to find a parametrization and a schedule for the jobs in such a way they require as less resources as possible. Though this problem derived from the applicative context of reconfigurable robots, we focus here on fundamental issues. We show that the resulting strongly NP-hard Multi_Bot  problem may be handled in a greedy way with an approximation ratio of 4/3434/34 / 3.",[''],"['France', 'France', 'France', 'France']"
"In cross-domain retrieval, a model is required to identify images from the same semantic category across two visual domains. For instance, given a sketch of an object, a model needs to retrieve a real image of it from an online store’s catalog. A standard approach for such a problem is learning a feature space of images where Euclidean distances reflect similarity. Even without human annotations, which may be expensive to acquire, prior methods function reasonably well using unlabeled images for training. Our problem constraint takes this further to scenarios where the two domains do not necessarily share any common categories in training data. This can occur when the two domains in question come from different versions of some biometric sensor recording identities of different people. We posit a simple solution, which is to generate synthetic data to fill in these missing category examples across domains. This, we do via category preserving translation of images from one visual domain to another. We compare approaches specifically trained for this translation for a pair of domains, as well as those that can use large-scale pre-trained text-to-image diffusion models via prompts, and find that the latter can generate better replacement synthetic data, leading to more accurate cross-domain retrieval models. Code for our work is available at https://github.com/samarth4149/SynCDR",[''],[]
"With the rapid progression of deep learning technologies, multi-modality image fusion has become increasingly prevalent in object detection tasks. Despite its popularity, the inherent disparities in how different sources depict scene content make fusion a challenging problem. Current fusion methodologies identify shared characteristics between the two modalities and integrate them within this shared domain using either iterative optimization or deep learning architectures, which often neglect the intricate semantic relationships between modalities, resulting in a superficial understanding of inter-modal connections and, consequently, suboptimal fusion outcomes. To address this, we introduce a text-guided multi-modality image fusion method that leverages the high-level semantics from textual descriptions to integrate semantics from infrared and visible images. This method capitalizes on the complementary characteristics of diverse modalities, bolstering both the accuracy and robustness of object detection. The codebook is utilized to enhance a streamlined and concise depiction of the fused intra- and inter-domain dynamics, fine-tuned for optimal performance in detection tasks. We present a bilevel optimization strategy that establishes a nexus between the joint problem of fusion and detection, optimizing both processes concurrently. Furthermore, we introduce the first dataset of paired infrared and visible images accompanied by text prompts, paving the way for future research. Extensive experiments on several datasets demonstrate that our method not only produces visually superior fusion results but also achieves a higher detection mAP over existing methods, achieving state-of-the-art results.",[''],[]
,[''],[]
"Multivariate time series forecasting poses an ongoing challenge across various disciplines. Time series data often exhibit diverse intra-series and inter-series correlations, contributing to intricate and interwoven dependencies that have been the focus of numerous studies. Nevertheless, a significant research gap remains in comprehending the varying inter-series correlations across different time scales among multiple time series, an area that has received limited attention in the literature. To bridge this gap, this paper introduces MSGNet, an advanced deep learning model designed to capture the varying inter-series correlations across multiple time scales using frequency domain analysis and adaptive graph convolution. By leveraging frequency domain analysis, MSGNet effectively extracts salient periodic patterns and decomposes the time series into distinct time scales. The model incorporates a self-attention mechanism to capture intra-series dependencies, while introducing an adaptive mixhop graph convolution layer to autonomously learn diverse inter-series correlations within each time scale. Extensive experiments are conducted on several real-world datasets to showcase the effectiveness of MSGNet. Furthermore, MSGNet possesses the ability to automatically learn explainable multi-scale inter-series correlations, exhibiting strong generalization capabilities even when applied to out-of-distribution samples. Code is available at https://github.com/YoZhibo/MSGNet.",[''],[]
"Multi-modal intent detection aims to utilize various modalities to understand the user’s intentions, which is essential for the deployment of dialogue systems in real-world scenarios.
The two core challenges for multi-modal intent detection are (1) how to effectively align and fuse different features of modalities and (2) the limited labeled multi-modal intent training data. In this work, we introduce a shallow-to-deep interaction framework with data augmentation (SDIF-DA) to address the above challenges. Firstly, SDIF-DA leverages a shallow-to-deep interaction module to progressively and effectively align and fuse features across text, video, and audio modalities. Secondly, we propose a ChatGPT-based data augmentation approach to automatically augment sufficient training data. Experimental results demonstrate that SDIF-DA can effectively align and fuse multi-modal features by achieving state-of-the-art performance. In addition, extensive analyses show that the introduced data augmentation approach can successfully distill knowledge from the large language model.",[''],[]
"We study twisted Courant sigma models, a class of topological field theories arising from the coupling of 3D 0-/2-form BF theory and Chern-Simons theory and containing a 4-form Wess-Zumino term. They are examples of theories featuring a nonlinearly open gauge algebra, where products of field equations appear in the commutator of gauge transformations, and they are reducible gauge systems.
We determine the solution to the master equation using a technique, the BRST power finesse, that combines aspects of the AKSZ construction (which applies to the untwisted model) and the general BV-BRST formalism. This allows for a geometric interpretation of the BV coefficients in the interaction terms of the master action in terms of an induced generalised connection on a 4-form twisted (pre-)Courant algebroid, its Gualtieri torsion and the basic curvature tensor. It also produces a frame independent formulation of the model. We show, moreover, that the gauge fixed action is the sum of the classical one and a BRST commutator, as expected from a Schwarz type topological field theory.",[''],[]
"Large language models (LLMs) have exhibited remarkable performance on various natural language processing (NLP) tasks, especially for question answering.
However, in the face of problems beyond the scope of knowledge, these LLMs tend to talk nonsense with a straight face, where the potential solution could be incorporating an Information Retrieval (IR) module and generating response based on these retrieved knowledge.
In this paper, we present a novel framework to assist LLMs, such as ChatGPT, to retrieve question-related structured information on the knowledge graph, and demonstrate that Knowledge-based question answering (Keqing) could be a nature Chain-of-Thought (CoT) mentor to guide the LLM to sequentially find the answer entities of a complex question through interpretable logical chains.
Specifically, the workflow of Keqing will execute decomposing a complex question according to predefined templates, retrieving candidate entities on knowledge graph, reasoning answers of sub-questions, and finally generating response with reasoning paths, which greatly improves the reliability of LLM’s response.
The experimental results on KBQA datasets show that Keqing can achieve competitive performance and illustrate the logic of answering each question.",[''],[]
"We prove that the functional volume product for even functions is monotone increasing along the Fokker–Planck heat flow.
This in particular yields a new proof of the functional Blaschke–Santaló inequality by K. Ball and also Artstein-Avidan–Klartag–Milman in the even case.
When the input and its polar function are moreover uniformly log-concave, we prove that the functional volume product experiences a strict jump along the heat evolution. As a corollary of this, we confirm a conjecture due to Barthe–Böröczky–Fradelizi regarding stability estimates under the uniformly log-concave assumption.

To establish these results, we develop a new approach based on ideas from the regularizing effect of the Ornstein–Uhlenbeck heat flow.
Motivated by this link, we establish an improvement of Borell’s reverse hypercontractivity inequality for even functions and identify the sharp range of the admissible exponents.","['Key words and phrases:', 'Blaschke–Santaló inequality,', 'Borell’s reverse hypercontractivity,', 'Brascamp–Lieb inequality,', 'Heat flow monotonicity,', 'Stability estimate']",[]
"Experimental particle physics uses machine learning for many of tasks,
where one application is to classify signal and background events.
The classification can be used to bin an analysis region to
enhance the expected significance for a mass resonance search.
In natural language processing, one of the leading neural network architectures
is the transformer.
In this work, an event classifier transformer is proposed to bin an analysis region,
in which the network is trained with special techniques.
The techniques developed here can enhance the significance
and reduce the correlation between the network’s output and the reconstructed mass.
It is found that this trained network can perform better than
boosted decision trees and feed-forward networks.","['mass resonance search, transformer, significance']",[]
"In today’s era, users have increasingly high expectations regarding the performance and efficiency of communication networks. Network operators aspire to achieve efficient network planning, operation, and optimization through Digital Twin Networks (DTN). The effectiveness of DTN heavily relies on the network model, with graph neural networks (GNN) playing a crucial role in network modeling. However, existing network modeling methods still lack a comprehensive understanding of communication networks. In this paper, we propose DWNet (Deeper and Wider Networks), a heterogeneous graph neural network modeling method based on data-driven approaches that aims to address end-to-end latency and jitter prediction in network models. This method stands out due to two distinctive features: firstly, it introduces deeper levels of state participation in the message passing process; secondly, it extensively integrates relevant features during the feature fusion process. Through experimental validation and evaluation, our model achieves higher prediction accuracy compared to previous research achievements, particularly when dealing with unseen network topologies during model training. Our model not only provides more accurate predictions but also demonstrates stronger generalization capabilities across diverse topological structures.","['Index', 'Terms: \ndigital twin, graph neural networks, deep learning, network modeling']",['0000-0002-2978-0659']
"In the era of Artificial Intelligence Generated Content (AIGC), conditional multimodal synthesis technologies (e.g., text-to-image, text-to-video, text-to-audio, etc) are gradually reshaping the natural content in the real world. The key to multimodal synthesis technology is to establish the mapping relationship between different modalities. Brain signals, serving as potential reflections of how the brain interprets external information, exhibit a distinctive One-to-Many correspondence with various external modalities. This correspondence makes brain signals emerge as a promising guiding condition for multimodal content synthesis. Brian-conditional multimodal synthesis refers to decoding brain signals back to perceptual experience, which is crucial for developing practical brain-computer interface systems and unraveling complex mechanisms underlying how the brain perceives and comprehends external stimuli. This survey comprehensively examines the emerging field of AIGC-based Brain-conditional Multimodal Synthesis, termed AIGC-Brain, to delineate the current landscape and future directions. To begin, related brain neuroimaging datasets, functional brain regions, and mainstream generative models are introduced as the foundation of AIGC-Brain decoding and analysis. Next, we provide a comprehensive taxonomy for AIGC-Brain decoding models and present task-specific representative work and detailed implementation strategies to facilitate comparison and in-depth analysis. Quality assessments are then introduced for both qualitative and quantitative evaluation. Finally, this survey explores insights gained, providing current challenges and outlining prospects of AIGC-Brain. Being the inaugural survey in this domain, this paper paves the way for the progress of AIGC-Brain research, offering a foundational overview to guide future work. A webpage associated with this survey is available at: https://github.com/MichaelMaiii/AIGC-Brain.",[''],[]
"Rendering the visual appearance of moving humans from occluded monocular videos is a challenging task. Most existing research renders 3D humans under ideal conditions, requiring a clear and unobstructed scene. Those methods cannot be used to render humans in real-world scenes where obstacles may block the camera’s view and lead to partial occlusions. In this work, we present Wild2Avatar, a neural rendering approach catered for occluded in-the-wild monocular videos. We propose occlusion-aware scene parameterization for decoupling the scene into three parts - occlusion, human, and background. Additionally, extensive objective functions are designed to help enforce the decoupling of the human from both the occlusion and the background and to ensure the completeness of the human model. We verify the effectiveness of our approach with experiments on in-the-wild videos.",[''],[]
"We investigate the magnetic order and related strongly-correlated effects in
an one-dimensional Ising-Kondo lattice with transverse field. This model is
the anisotropic limit of the conventional isotropic Kondo lattice model, in
the sense that the itinerant electrons interact with the localized magnetic
moments via only longitudinal Kondo exchange. Adopting the numerical
density-matrix-renormalization group method, we map out the ground-state
phase diagram in various parameter spaces. Depending on the Kondo coupling
and filling number, three distinct phases, including a metallic
paramagnetic, a metallic ferromagnetic, and a gapped spin-density wave
phase, are obtained. The spin-density wave is characterized by an ordering
wave vector which coincides with the nesting wave vector of the Fermi
surface. This makes the corresponding magnetic transition a spin analog of
the Peierls transition occurring in the one-dimensional metal. Moreover, by
analyzing the momentum distribution function and charge correlation
function, the conduction electrons are shown to behave like free spinless
fermions in the ferromagnetic phase. We finally discuss the effect of the
repulsive Hubbard interaction between conduction electrons. Our work
enriches the Kondo physics and deepens the current understanding of the
heavy fermion compounds.",[''],"['China', 'China', 'China', 'China', 'China', 'China']"
"We show that a measurable function g:𝕊d−1→ℝ:𝑔→superscript𝕊𝑑1ℝg:\mathbb{S}^{d-1}\to\mathbb{R}italic_g : blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT → blackboard_R, with d≥3𝑑3d\geq 3italic_d ≥ 3, satisfies the functional relation



g⁢(ω)+g⁢(ω*)=g⁢(ω′)+g⁢(ω*′),𝑔𝜔𝑔subscript𝜔𝑔superscript𝜔′𝑔superscriptsubscript𝜔′g(\omega)+g(\omega_{*})=g(\omega^{\prime})+g(\omega_{*}^{\prime}),italic_g ( italic_ω ) + italic_g ( italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT ) = italic_g ( italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) + italic_g ( italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ,



for all admissible ω,ω*,ω′,ω*′∈𝕊d−1𝜔subscript𝜔superscript𝜔′superscriptsubscript𝜔′superscript𝕊𝑑1\omega,\omega_{*},\omega^{\prime},\omega_{*}^{\prime}\in\mathbb{S}^{d-1}italic_ω , italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT , italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT in the sense that




ω+ω*=ω′+ω*′,𝜔subscript𝜔superscript𝜔′superscriptsubscript𝜔′\omega+\omega_{*}=\omega^{\prime}+\omega_{*}^{\prime},italic_ω + italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT = italic_ω start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT + italic_ω start_POSTSUBSCRIPT * end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ,



if and only if it can be written as



g⁢(ω)=A+B⋅ω,𝑔𝜔𝐴⋅𝐵𝜔g(\omega)=A+B\cdot\omega,italic_g ( italic_ω ) = italic_A + italic_B ⋅ italic_ω ,



for some constants A∈ℝ𝐴ℝA\in\mathbb{R}italic_A ∈ blackboard_R and B∈ℝd𝐵superscriptℝ𝑑B\in\mathbb{R}^{d}italic_B ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT.

Such functions form a family of quantized collision invariants which play a fundamental role in the study of hydrodynamic regimes of the Boltzmann–Fermi–Dirac equation near Fermionic condensates, i.e., at low temperatures. In particular, they characterize the elastic collisional dynamics of Fermions near a statistical equilibrium where quantum effects are predominant.",[''],[]
"Large language models (LLMs) have achieved huge success for their general knowledge and ability to solve a wide spectrum of tasks in natural language processing (NLP). Due to their impressive abilities, LLMs have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S).
In the meantime, utilizing NLP techniques in geoscience research and practice is wide and convoluted, contributing from knowledge extraction and document classification to question answering and knowledge discovery.
In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach. We try to specialize an open-sourced LLM into geoscience, by further pre-training the model with a vast amount of texts in geoscience, as well as supervised fine-tuning (SFT) the resulting model with our custom collected instruction tuning dataset.
These efforts result in a model GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is the largest language model for the geoscience domain.
More specifically, GeoGalactica is from further pre-training of Galactica – a top-performing LLM trained with a large number of scientific documents.
We train GeoGalactica over a geoscience-related text corpus containing 65 billion tokens curated from extensive data sources in the big science project Deep-time Digital Earth (DDE), preserving as the largest geoscience-specific text corpus. Then we fine-tune the model with 1 million pairs of instruction-tuning data consisting of questions that demand professional geoscience knowledge to answer.
We validate GeoGalactica on various geoscience examinations and geoscience-related open-domain questions evaluated by a group of senior geoscientists.
GeoGalactica demonstrates the state-of-the-art performance in a diverse range of NLP tasks in geoscience, as well as revealing the potential of using geoscience-related tools.
In this technical report, we will illustrate in detail all aspects of GeoGalactica, including data collection, data cleaning, base model selection, pre-training, SFT, and evaluation.
We open-source our data curation tools and the checkpoints of GeoGalactica during the first 3/4343/43 / 4 of pre-training in https://github.com/geobrain-ai/geogalactica§§{}^{\lx@sectionsign}start_FLOATSUPERSCRIPT § end_FLOATSUPERSCRIPT.",[''],[]
"The Handwritten Mathematical Expression Recognition (HMER) task is a critical branch in the field of OCR. Recent studies have demonstrated that incorporating bidirectional context information significantly improves the performance of HMER models. However, existing methods fail to effectively utilize bidirectional context information during the inference stage. Furthermore, current bidirectional training methods are primarily designed for string decoders and cannot adequately generalize to tree decoders, which offer superior generalization capabilities and structural analysis capacity. In order to overcome these limitations, we propose the Mirror-Flipped Symbol Layout Tree (MF-SLT) and Bidirectional Asynchronous Training (BAT) structure. Our method extends the bidirectional training strategy to the tree decoder, allowing for more effective training by leveraging bidirectional information. Additionally, we analyze the impact of the visual and linguistic perception of the HMER model separately and introduce the Shared Language Modeling (SLM) mechanism. Through the SLM, we enhance the model’s robustness and generalization when dealing with visual ambiguity, particularly in scenarios with abundant training data. Our approach has been validated through extensive experiments, demonstrating its ability to achieve new state-of-the-art results on the CROHME 2014, 2016, and 2019 datasets, as well as the HME100K dataset. The code used in our experiments will be publicly available.",[''],[]
"Efficiently finding optimal correspondences between point clouds is crucial for solving both rigid and non-rigid point cloud registration problems. Existing methods often rely on geometric or semantic feature embedding to establish correspondences and estimate transformations or flow fields. Recently, state-of-the-art methods have employed RAFT-like iterative updates to refine the solution. However, these methods have certain limitations. Firstly, their iterative refinement design lacks transparency, and their iterative updates follow a fixed path during the refinement process, which can lead to suboptimal results. Secondly, these methods overlook the importance of refining or optimizing correspondences (or matching matrices) as a precursor to solving transformations or flow fields. They typically compute candidate correspondences based on distances in the point feature space. However, they only project the candidate matching matrix into some matrix space once with Sinkhorn or dual softmax operations to obtain final correspondences. This one-shot projected matching matrix may be far from the globally optimal one, and these approaches do not consider the distribution of the target matching matrix. In this paper, we propose a novel approach that exploits the Denoising Diffusion Model to predict a searching gradient for the optimal matching matrix within the Doubly Stochastic Matrix Space. Our method incorporates the diffusion model to learn a denoising gradient direction. During the reverse denoising process, our method iteratively searches for better solutions along this denoising gradient, which points towards the maximum likelihood direction of the target matching matrix. Our method offers flexibility by allowing the search to start from any initial matching matrix provided by the online backbone or white noise. Along with the trajectory provided by the reverse sampling process, it iteratively approximates the globally optimal solution. To improve efficiency, we utilize the Denoising Diffusion Implicit Model (DDIM) to accelerate the sampling speed. Experimental evaluations on the 3DMatch/3DLoMatch and 4DMatch/4DLoMatch datasets demonstrate the effectiveness of our newly designed framework.",[''],[]
"Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators.
However, current sample-wise evaluation paradigm suffers from the following issues:
(1) Sensitive to prompt design;
(2) Poor resistance to noise;
(3) Inferior ensemble performance with static reference.
Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BatchEval, a paradigm that conducts batch-wise evaluation iteratively to alleviate the above problems.
We explore variants under this paradigm and confirm the optimal settings are two stage procedure with heterogeneous batch composition strategy and decimal scoring format.
Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate that BatchEval outperforms state-of-the-art methods by 10.5% on Pearson correlations with only 64% API cost on average.
Further analyses have been conducted to verify the robustness, generalization, and working mechanism of BatchEval111Our code and data have been released on https://github.com/ypw0102/BatchEval..",[''],[]
"The ability to locate and classify action segments in long untrimmed video is of particular interest to many applications such as autonomous cars, robotics and healthcare applications. Today, the most popular pipeline for action segmentation is composed of encoding the frames into feature vectors, which are then processed by a temporal model for segmentation. In this paper we present a self-supervised method that comes in the middle of the standard pipeline and generated refined representations of the original feature vectors. Experiments show that this method improves the performance of existing models on different sub-tasks of action segmentation, even without additional hyper parameter tuning.",[''],[]
,[''],[]
"In contrast to the well-investigated field of SAR-to-Optical translation, this study explores the lesser-investigated domain of Optical-to-SAR translation, a challenging field due to the ill-posed nature of this translation. The complexity arises as a single optical data can have multiple SAR representations based on the SAR viewing geometry. We propose a novel approach, termed SAR Temporal Shifting, which inputs an optical data from the desired timestamp along with a SAR data from a different temporal point but with a consistent viewing geometry as the expected SAR data, both complemented with a change map of optical data during the intervening period. This model modifies the SAR data based on the changes observed in optical data to generate the SAR data for the desired timestamp. Our model, a dual conditional Generative Adversarial Network (GAN), named Temporal Shifting GAN (TSGAN), incorporates a siamese encoder in both the Generator and the Discriminator. To prevent the model from overfitting on the input SAR data, we employed a change weighted loss function.
Our approach surpasses traditional translation methods by eliminating the GAN’s fiction phenomenon, particularly in unchanged regions, resulting in higher SSIM and PSNR in these areas. Additionally, modifications to the Pix2Pix architecture and the inclusion of attention mechanisms have enhanced the model’s performance on all regions of the data. This research paves the way for leveraging legacy optical datasets, the most abundant and longstanding source of Earth datary data, extending their use to SAR domains and temporal analyses. To foster further research, we provide the code, datasets used in our study, and a framework for generating paired SAR-Optical datasets for new regions of interest. These resources are available on GitHub at github.com/moienr/TemporalGAN","['Index', 'Terms: ', 'Generative', 'Adversarial', 'Networks (GANs),', 'Attention', 'Mechanism,', 'Temporal', 'Shifting,', 'Weighted', 'Loss,', 'Optical-to-SAR,', 'Super', 'Temporal', 'Resolution.']",[]
,[''],[]
"The fisheye camera, with its unique wide field of view and other characteristics, has found extensive applications in various fields[1, 2]. However, the fisheye camera suffers from significant distortion compared to pinhole cameras, resulting in distorted images of captured objects. Fish-eye camera distortion is a common issue in digital image processing, requiring effective correction techniques to enhance image quality. This review provides a comprehensive overview of various methods used for fish-eye camera distortion correction[3]. The article explores the polynomial distortion model, which utilizes polynomial functions to model and correct radial distortions. Additionally, alternative approaches such as panorama mapping, grid mapping, direct methods, and deep learning-based methods are discussed. The review highlights the advantages, limitations, and recent advancements of each method, enabling readers to make informed decisions based on their specific needs.",[''],[]
"The energy consumption of mobile networks poses a critical challenge.
Mitigating this concern necessitates the deployment and optimization of network energy-saving solutions,
such as carrier shutdown,
to dynamically manage network resources.
Traditional optimization approaches encounter complexity due to factors like the large number of cells, stochastic traffic, channel variations, and intricate trade-offs.
This paper introduces the  simulated reality of communication networks (SRCON) framework, a novel, data-driven modeling paradigm that harnesses live network data and employs a blend of  machine learning (ML)- and expert-based models.
These mix of models accurately characterizes the functioning of network components,
and predicts network energy efficiency and  user equipment (UE) quality of service for any energy carrier shutdown configuration in a specific network.
Distinguishing itself from existing methods,
SRCON eliminates the reliance on expensive expert knowledge, drive testing, or incomplete maps for predicting network performance.
This paper details the pipeline employed by SRCON to decompose the large network energy efficiency modeling problem into ML- and expert-based submodels.
It demonstrates how,
by embracing stochasticity,
and carefully crafting the relationship between such submodels,
the overall computational complexity can be reduced and prediction accuracy enhanced.
Results derived from real network data underscore the paradigm shift introduced by SRCON,
showcasing significant gains over a state-of-the-art method used by a operator for network energy efficiency modeling.
The reliability of this local, data-driven modeling of the network proves to be a key asset for network energy-saving optimization.",[''],"['Spain', 'France', 'Dhabi']"
"The following paper proposes a new target localization system design using an architecture based on reconfigurable intelligent surfaces (RISs) and passive radars (PRs) for integrated sensing and communications systems.
The preamble of the communication signal is exploited in order to perform target sensing tasks, which involve detection and localization.
The RIS in this case can aid the PR in sensing targets that are otherwise not seen by the PR itself, due to the many obstacles encountered within the propagation channel.
Therefore, this work proposes a localization algorithm tailored for the integrated sensing and communications RIS-aided architecture, which is capable of uniquely positioning targets within the scene.
The algorithm is capable of detecting the number of targets along with estimating the position of targets via angles and times of arrival.
Our simulation results demonstrate the performance of the localization method in terms of different localization and detection metrics and for increasing RIS sizes.","['Index', 'Terms: \nintegrated sensing and communications (ISAC), reconfigurable intelligent surfaces (RIS), 6G, localization, passive radar']","['UAE.', 'USA']"
"The limited energy and computing resources of unmanned aerial vehicles
(UAVs) hinder the application of aerial artificial intelligence. The
utilization of split inference in UAVs garners significant attention
due to its effectiveness in mitigating computing and energy requirements.
However, achieving energy-efficient split inference in UAVs remains
complex considering of various crucial parameters such as energy level
and delay constraints, especially involving multiple tasks. In this
paper, we present a two-timescale approach for energy minimization
in split inference, where discrete and continuous variables are segregated
into two timescales to reduce the size of action space and computational
complexity. This segregation enables the utilization of tiny reinforcement
learning (TRL) for selecting discrete transmission modes for sequential
tasks. Moreover, optimization programming (OP) is embedded between
TRL’s output and reward function to optimize the continuous transmit
power. Specifically, we replace the optimization of transmit power
with that of transmission time to decrease the computational complexity
of OP since we reveal that energy consumption monotonically decreases
with increasing transmission time. The replacement significantly reduces
the feasible region and enables a fast solution according to the closed-form
expression for optimal transmit power. Simulation results show that
the proposed algorithm can achieve a higher probability of successful
task completion with lower energy consumption.","['Index', 'Terms: \n', 'Power control, tiny learning, energy-efficient, multiple-task split\ninference.']",[]
"Accreting supermassive black holes (SMBHs) frequently power jets that interact with the interstellar/circumgalactic medium (ISM/CGM), regulating star-formation in the galaxy. Highly supersonic jets launched by active galactic nuclei (AGN) power a cocoon that confines them and shocks the ambient medium. We build upon the models of narrow conical jets interacting with a smooth ambient medium, to include the effect of dense clouds that are an essential ingredient of a multiphase ISM. The key physical ingredient of this model is that the clouds along the supersonic jet-beam strongly decelerate the jet-head, but the subsonic cocoon easily moves around the clouds without much resistance. We propose scalings for important physical quantities – cocoon pressure, head & cocoon speed, and jet radius. We obtain, for the first time, the analytic condition on clumpiness of the ambient medium for the jet to dissipate within the cocoon and verify it with numerical simulations of conical jets interacting with a uniform ISM with embedded spherical clouds. A jet is defined to be dissipated when the cocoon speed exceeds the speed of the jet-head. We compare our models to more sophisticated numerical simulations, direct observations of jet-ISM interaction (e.g., quasar J1316+1753), and discuss implications for the Fermi/eROSITA bubbles. Our work also motivates effective subgrid models for AGN jet feedback in a clumpy ISM unresolved by the present generation of cosmological galaxy formation simulations.","['ISM: jets and outflows – galaxies: jets –', 'ISM: clouds – galaxies: clusters: intracluster medium']","['India', 'India', 'Israel', 'India', 'USA']"
"In contrast to conventional reconfigurable intelligent surface (RIS),
simultaneous transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) has been proposed recently to enlarge the serving
area from 180osuperscript180𝑜180^{o}180 start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT to 360osuperscript360𝑜360^{o}360 start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT coverage. This work considers the
performance of a STAR-RIS aided full-duplex (FD) non-orthogonal multiple
access (NOMA) communication systems. The STAR-RIS is implemented at
the cell-edge to assist the cell-edge users, while the cell-center
users can communicate directly with a FD base station (BS). We first
introduce new user clustering schemes for the downlink and uplink
transmissions. Then, based on the proposed transmission schemes closed-form
expressions of the ergodic rates in the downlink and uplink modes
are derived taking into account the system impairments caused by the
self interference at the FD-BS and the imperfect successive interference
cancellation (SIC). Moreover, an optimization problem to maximize
the total sum-rate is formulated and solved by optimizing the amplitudes
and the phase-shifts of the STAR-RIS elements and allocating the transmit
power efficiently. The performance of the proposed user clustering
schemes and the optimal STAR-RIS design are investigated through numerical
results.","['Index', 'Terms: \n', 'STAR-RIS,', 'Full-duplex,', 'NOMA,', 'Sum-rate.']",[]
"Large language model (LLM) scaling laws are empirical formulas that estimate changes in model quality as a result of increasing parameter count and training data. However, these formulas, including the popular DeepMind Chinchilla scaling laws, neglect to include the cost of inference. We modify the Chinchilla scaling laws to calculate the optimal LLM parameter count and pre-training data size to train and deploy a model of a given quality and inference demand. We conduct our analysis both in terms of a compute budget and real-world costs and find that LLM researchers expecting reasonably large inference demand (~1B requests) should train models smaller and longer than Chinchilla-optimal.",[''],[]
"Despite recent initiatives aimed at improving accessibility, the field of digital accessibility remains markedly behind contemporary advancements in the software industry as a large number of real world software and web applications continue to fall short of accessibility requirements.
A persisting skills deficit within the existing technology workforce has been an enduring impediment, hindering organizations from delivering truly accessible software products.
This, in turn, elevates the risk of isolating and excluding a substantial portion of potential users.
In this paper, we report lessons learned from a training program for teaching digital accessibility using the Communities of Practice (CoP) framework to industry professionals.
We recruited 66 participants from a large multi-national software company and assigned them to two groups: one participating in a CoP and the other using self-paced learning.
We report experiences from designing the training program, conducting the actual training, and assessing the efficiency of the two approaches.
Based on these findings, we provide recommendations for practitioners in Learnng and Development teams and educators in designing accessibility courses for industry professionals.","['Accessibility (a11y), massive open online courses, communities of practice,', 'Computing', 'Education']","['CampusGoaIndia403726', 'CampusGoaIndia403726']"
"Hybridizing different degrees of freedom or physical platforms potentially offers various advantages in building scalable quantum architectures.
We here introduce a fault-tolerant hybrid quantum computation by taking the advantages of both discrete variable (DV) and continuous variable (CV) systems. Particularly, we define a CV-DV hybrid qubit with bosonic cat-code and single photon, which is implementable in current photonic platforms. By the cat-code encoded in the CV part, the dominant loss errors are readily correctable without multi-qubit encoding, while the logical basis is inherently orthogonal due to the DV part. We design fault-tolerant architectures by concatenating hybrid qubits and an outer DV quantum error correction code such as topological codes, exploring their potential merits in developing scalable quantum computation. We demonstrate by numerical simulations that our scheme is at least an order of magnitude more resource-efficient over all previous proposals in photonic platforms, allowing to achieve a record-high loss threshold among existing CV and hybrid approaches. We discuss its realization not only in all-photonic platforms but also in other hybrid platforms including superconduting and trapped-ion systems, which allows us to find various efficient routes towards fault-tolerant quantum computing.",[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Australia', 'Korea', 'USA', 'Korea']"
"A UserWay study in 2021 indicates that an annual global e-commerce revenue loss of approximately $16 billion can be attributed to inaccessible websites and applications. According to the 2023 WebAIM study, only 3.7% of the world’s top one million website homepages are fully accessible. This shows that many software developers use poor coding practices that don’t adhere to the Web Content Accessibility Guidelines (WCAG). This research centers on software professionals and their role in addressing accessibility. This work seeks to understand (a) who within the software development community actively practices accessibility, (b) when and how accessibility is considered in the software development lifecycle, (c) the various challenges encountered in building accessible software, and (d) the resources required by software professionals to enhance product accessibility. Our survey of 269 software professionals from India sheds light on the pressing need for accessibility education within the software industry. A substantial majority (69.9%, N=269) of respondents express the need for training materials, workshops, and bootcamps to enhance their accessibility skills. We present a list of actionable recommendations that can be implemented within the industry to promote accessibility awareness and skills. We also open source our raw data for further research, encouraging continued exploration in this domain.","['Accessibility (a11y),', 'Indian', 'IT', 'Industry, accessibility education']","['CampusGoaIndia403726', 'CampusGoaIndia403726']"
"We deploy an advanced Machine Learning (ML) environment, leveraging a multi-scale cross-attention encoder for event classification, towards the identification of the g⁢g→H→h⁢h→b⁢b¯⁢b⁢b¯→𝑔𝑔𝐻→ℎℎ→𝑏¯𝑏𝑏¯𝑏gg\to H\to hh\to b\bar{b}b\bar{b}italic_g italic_g → italic_H → italic_h italic_h → italic_b over¯ start_ARG italic_b end_ARG italic_b over¯ start_ARG italic_b end_ARG process at the High Luminosity Large Hadron Collider (HL-LHC), where hℎhitalic_h is the discovered Standard Model (SM)-like Higgs boson and H𝐻Hitalic_H a heavier version of it (with mH>2⁢mhsubscript𝑚𝐻2subscript𝑚ℎm_{H}>2m_{h}italic_m start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT > 2 italic_m start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT).  In the ensuing boosted Higgs regime, the final state consists of two fat jets. Our multi-modal network can extract information from the jet substructure and the kinematics of the final state particles through self-attention transformer layers. The diverse learned information is subsequently integrated to improve classification performance using an additional transformer encoder with cross-attention heads. We ultimately prove that our approach surpasses in performance current alternative methods used to establish sensitivity to this process, whether solely based on kinematic analysis or else on a combination of this with mainstream ML approaches. Then, we employ various interpretive methods to evaluate the network results, including attention map analysis and visual representation of Gradient-weighted Class Activation Mapping (Grad-CAM). Finally, we note that the proposed network is generic and can be applied to analyse any process carrying information at different scales. Our code is publicly available for generic use111https://github.com/AHamamd150/Multi-Scale-Transformer-Encoder..",[''],[]
"This paper gives a nearly tight characterization of the quantum communication complexity of the permutation-invariant Boolean functions. With such a characterization, we show that the quantum and randomized communication complexity of the permutation-invariant Boolean functions are quadratically equivalent (up to a logarithmic factor). Our results extend a recent line of research regarding query complexity [2, 17, 11] to communication complexity, showing symmetry prevents exponential quantum speedups.
Furthermore, we show the Log-rank Conjecture holds for any non-trivial total permutation-invariant Boolean function. Moreover, we establish a relationship between the quantum/classical communication complexity and the approximate rank of permutation-invariant Boolean functions. This implies the correctness of the Log-approximate-rank Conjecture for permutation-invariant Boolean functions in both randomized and quantum settings (up to a logarithmic factor).",[''],[]
"Second-order gravitational self-force theory has recently led to the breakthrough calculation of “first post-adiabatic” (1PA) compact-binary waveforms [Phys. Rev. Lett. 130, 241402 (2023)]. The computations underlying those waveforms depend on a method of solving the perturbative second-order Einstein equation in the Fourier domain. In this paper we present that method, which involves dividing the domain into several regions. Different regions utilize different time slicings and allow for the use of “punctures” to tame sources and enforce physical boundary conditions. We demonstrate the method for Lorenz-gauge and Teukolsky equations in the relatively simple case of calculating parametric derivatives (“slow time derivatives”) of first-order fields, which are an essential input at second order.",[''],"['Israel', 'Germany', 'Kingdom', 'V1W8']"
"We study the finite model property of subframe logics with expressible transitive closure modality.
For m>0𝑚0m>0italic_m > 0, let LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT be the logic given by axiom ◆m⁢p→◆⁢p∨p→superscript◆𝑚𝑝◆𝑝𝑝\lozenge^{m}p\rightarrow\lozenge p\vee p◆ start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_p → ◆ italic_p ∨ italic_p.
We construct filtrations for the logics LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. It follows that these logics and their tense counterparts
have the finite model property. Then we show that every canonical subframe logic that contains LmsubscriptL𝑚{\textsc{L}}_{m}L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT have the finite model property.",[''],[]
"We considered two sequences of spiral galaxies with different shapes of the radial gas-phase oxygen abundance distributions from the galaxies in the survey Mapping Nearby Galaxies
at Apache Point Observatory (MaNGA): (1) Galaxies in which the gradient is well approximated by a single linear relation across the whole disc, that is, galaxies with an S (slope)
gradients, (2) galaxies in which the metallicity in the inner region of the disc is at a nearly constant level and the gradient is negative at larger radii, that is, galaxies with
level-slope (LS) gradients. We also selected galaxies with a nearly uniform oxygen abundance across the whole galaxy, that is, galaxies with level (L) gradients (or O/H uniform
galaxies) with a high oxygen abundance that can be the final evolutionary stage of the two galaxy sequences described above. The radial nitrogen abundance distributions
in galaxies with LS oxygen abundance distributions also show breaks at radii smaller than the O/H distribution breaks. The observed behaviour of the oxygen and nitrogen
abundances with radius in these galaxies can be explained by the time delay between the nitrogen and oxygen enrichment together with the variation in the star formation history
along the radius. These galaxies clearly show the effect of the inside-out disc evolution model, which predicts that the galactic centre evolves more rapidly than
the regions at greater galactocentric distances. We find that the shape of the radial abundance distribution in a galaxy is not related to its macroscopic characteristics (rotation
velocity, stellar mass, isophotal radius, and star formation rate) and is independent of its present-day environment.
The correlations between the gradient slopes and macroscopic characteristics of galaxies are weak in the sense that the scatter of the points in each diagram is large.
The galaxies with different abundance distributions (S, LS, or L) in our sample are located within the main sequence of the star-forming
galaxies in the diagram of star formation rate – stellar mass. We also examined the properties of the Milky Way in the context of the considered galaxy samples.","['Key', 'Words.: \ngalaxies: abundances –', 'ISM: abundances –', 'H\u2009ii regions, galaxies']",[]
"We present a surface analog to a dripping faucet, where a viscous liquid slides down an immiscible meniscus.
Periodic pinch-off of the dripping filament is observed, generating a succession of monodisperse floating lenses.
We show that this interfacial dripping faucet can be described analogously to its single-phase counterpart, replacing surface tension by the spreading coefficient, and even undergoes a transition to a jetting regime.
This liquid/liquid/gas system opens perspectives for the study of the dynamics of emulsions at interfaces.",[''],"['Spain', 'Spain', 'Netherlands', 'Netherlands', 'Spain', 'Spain']"
"Autonomous driving technology nowadays targets to level 4 or beyond, but the researchers are faced with some limitations for developing reliable driving algorithms in diverse challenges. To promote the autonomous vehicles to spread widely, it is important to address safety issues on this technology. Among various safety concerns, the sensor blockage problem by severe weather conditions can be one of the most frequent threats for multi-task learning based perception algorithms during autonomous driving. To handle this problem, the importance of the generation of proper datasets is becoming more significant. In this paper, a synthetic road dataset with sensor blockage generated from real road dataset BDD100K is suggested in the format of BDD100K annotation. Rain streaks for each frame were made by an experimentally established equation and translated utilizing the image-to-image translation network based on style transfer. Using this dataset, the degradation of the diverse multi-task networks for autonomous driving, such as lane detection, driving area segmentation, and traffic object detection, has been thoroughly evaluated and analyzed. The tendency of the performance degradation of deep neural network-based perception systems for autonomous vehicle has been analyzed in depth. Finally, we discuss the limitation and the future directions of the deep neural network-based perception algorithms and autonomous driving dataset generation based on image-to-image translation based.",[''],[]
"In environmental health research, it is of interest to understand the effect of the neighborhood environment on health. Researchers have shown a protective association between green space around a person’s residential address and depression outcomes. In measuring exposure to green space,
distance buffers are often used. However, buffer distances differ across studies. Typically, the buffer distance is determined by researchers a priori. It is unclear how to identify an appropriate buffer distance for exposure assessment. To address geographic uncertainty problem for exposure assessment, we present a domain selection algorithm based on the penalized functional linear Cox regression model. The theoretical properties of our proposed method are studied and simulation studies are conducted to evaluate finite sample performances of our method. The proposed method is illustrated in a study of associations of green space exposure with depression and/or antidepressant use in the Nurses’ Health Study.",[''],"['Korea', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Israel', 'USA', 'USA', 'USA']"
"In this article, we prove the existence of rigid analytic families of G𝐺Gitalic_G-stable lattices with locally constant reductions inside families of representations of a topologically compact group G𝐺Gitalic_G, extending a result of Hellman obtained in the semi-simple residual case. Implementing this generalization in the context of Galois representations, we prove a local constancy result for reductions modulo prime powers of trianguline representations of generic dimension d𝑑ditalic_d. Moreover, we present two explicit applications. First, in dimension two, we extend to a prime power setting and to the whole rigid projective line a recent result of Bergdall, Levin and Liu concerning reductions of semi-stable representations of Gal⁢(ℚ¯p/ℚp)Galsubscript¯ℚ𝑝subscriptℚ𝑝\text{Gal}(\overline{\mathbb{Q}}_{p}/\mathbb{Q}_{p})Gal ( over¯ start_ARG blackboard_Q end_ARG start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT / blackboard_Q start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) with fixed Hodge-Tate weights and large ℒℒ\mathcal{L}caligraphic_L-invariant.
Second, in dimension d𝑑ditalic_d, let Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be a sequence of crystalline representations converging in a certain geometric sense to a crystalline representation V𝑉Vitalic_V. We show that for any refined version (V,σ)𝑉𝜎(V,\sigma)( italic_V , italic_σ ) of V𝑉Vitalic_V (or equivalently for any chosen triangulation of its attached (φ,Γ)𝜑Γ(\varphi,\Gamma)( italic_φ , roman_Γ )-module Drig⁢(V)subscript𝐷rig𝑉D_{\text{rig}}(V)italic_D start_POSTSUBSCRIPT rig end_POSTSUBSCRIPT ( italic_V ) over the Robba ring), there exists a sequence of refinement σnsubscript𝜎𝑛\sigma_{n}italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of each of the Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that the limit as refined representations (Vn,σn)subscript𝑉𝑛subscript𝜎𝑛(V_{n},\sigma_{n})( italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) converges to the (V,σ)𝑉𝜎(V,\sigma)( italic_V , italic_σ ). This result does not hold under the weaker assumption that Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT converges only uniformly p𝑝pitalic_p-adically to V𝑉Vitalic_V (in the sense of Chenevier, Khare and Larsen).",[''],['torti.emiliano@gmail.com']
"In this paper, we present a comparative analysis of various self-supervised Vision Transformers (ViTs), focusing on their local representative power. Inspired by large language models, we examine the abilities of ViTs to perform various computer vision tasks with little to no fine-tuning.
We design evaluation framework to analyze the quality of local, i.e. patch-level, representations in the context of few-shot semantic segmentation, instance identification, object retrieval and tracking.
We discover that contrastive learning based methods like DINO produce more universal patch representations that can be immediately applied for downstream tasks with no parameter tuning, compared to masked image modeling. The embeddings learned using the latter approach, e.g. in masked autoencoders, have high variance features that harm distance-based algorithms, such as k-NN, and do not contain useful information for most downstream tasks.
Furthermore, we demonstrate that removing these high-variance features enhances k-NN by providing an analysis of the benchmarks for this work and for Scale-MAE, a recent extension of masked autoencoders.
Finally, we find an object instance retrieval setting where DINOv2, a model pretrained on two orders of magnitude more data, performs worse than its less compute intensive counterpart DINO.",[''],[]
"The usual Sobolev inequality in ℝNsuperscriptℝ𝑁\mathbb{R}^{N}blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT, asserts that ‖∇u‖Lp⁢(ℝN)≥𝒮⁢‖u‖Lp*⁢(ℝN)subscriptnorm∇𝑢superscript𝐿𝑝superscriptℝ𝑁𝒮subscriptnorm𝑢superscript𝐿superscript𝑝superscriptℝ𝑁\|\nabla u\|_{L^{p}(\mathbb{R}^{N})}\geq\mathcal{S}\|u\|_{L^{p^{*}}(\mathbb{R}%
^{N})}∥ ∇ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT ≥ caligraphic_S ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) end_POSTSUBSCRIPT for 1<p<N1𝑝𝑁1<p<N1 < italic_p < italic_N and p*=p⁢NN−psuperscript𝑝𝑝𝑁𝑁𝑝p^{*}=\frac{pN}{N-p}italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT = divide start_ARG italic_p italic_N end_ARG start_ARG italic_N - italic_p end_ARG, with 𝒮𝒮\mathcal{S}caligraphic_S being the sharp constant. This note is concerned, instead, with function restricted to bounded domain Ω⊂ℝNΩsuperscriptℝ𝑁\Omega\subset\mathbb{R}^{N}roman_Ω ⊂ blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT. Based on the recent work of Figalli and Zhang [Duke Math. J., 2022], a remainder term with weak norm is established



‖∇u‖Lp⁢(Ω)‖u‖Lp*⁢(Ω)−𝒮≥𝒞⁢(‖u‖Lwp¯⁢(Ω)‖u‖Lp*⁢(Ω))max⁡{2,p},∀u∈C0∞⁢(Ω)∖{0},formulae-sequencesubscriptnorm∇𝑢superscript𝐿𝑝Ωsubscriptnorm𝑢superscript𝐿superscript𝑝Ω𝒮𝒞superscriptsubscriptnorm𝑢subscriptsuperscript𝐿¯𝑝𝑤Ωsubscriptnorm𝑢superscript𝐿superscript𝑝Ω2𝑝for-all𝑢subscriptsuperscript𝐶0Ω0\frac{\|\nabla u\|_{L^{p}(\Omega)}}{\|u\|_{L^{p^{*}}(\Omega)}}-\mathcal{S}\geq%
\mathcal{C}\left(\frac{\|u\|_{L^{\bar{p}}_{w}(\Omega)}}{\|u\|_{L^{p^{*}}(%
\Omega)}}\right)^{\max\{2,p\}},\quad\forall u\in C^{\infty}_{0}(\Omega)%
\setminus\{0\},divide start_ARG ∥ ∇ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG - caligraphic_S ≥ caligraphic_C ( divide start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_u ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT roman_max { 2 , italic_p } end_POSTSUPERSCRIPT , ∀ italic_u ∈ italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Ω ) ∖ { 0 } ,



for some 𝒞=𝒞⁢(N,p,Ω)>0𝒞𝒞𝑁𝑝Ω0\mathcal{C}=\mathcal{C}(N,p,\Omega)>0caligraphic_C = caligraphic_C ( italic_N , italic_p , roman_Ω ) > 0, where p¯=p*⁢(p−1)/p¯𝑝superscript𝑝𝑝1𝑝\bar{p}=p^{*}(p-1)/pover¯ start_ARG italic_p end_ARG = italic_p start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_p - 1 ) / italic_p and ∥⋅∥Lwp¯⁢(Ω)\|\cdot\|_{L^{\bar{p}}_{w}(\Omega)}∥ ⋅ ∥ start_POSTSUBSCRIPT italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT ( roman_Ω ) end_POSTSUBSCRIPT denotes the weak Lp¯superscript𝐿¯𝑝L^{\bar{p}}italic_L start_POSTSUPERSCRIPT over¯ start_ARG italic_p end_ARG end_POSTSUPERSCRIPT-norm. Furthermore, the weak norm can not be replaced by the strong norm. This result answers the long-standing open problem raised by Bianchi and Egnell [J. Funct. Anal., 1991].",[''],[]
,[''],[]
"Symbolic Music Alignment is the process of matching performed MIDI notes to corresponding score notes.
In this paper, we introduce a reinforcement learning (RL)-based online symbolic music alignment technique.
The RL agent — an attention-based neural network — iteratively estimates the current score position from local score and performance contexts.
For this symbolic alignment task, environment states can be sampled exhaustively and the reward is dense, rendering a formulation as a simplified offline RL problem straightforward.
We evaluate the trained agent in three ways.
First, in its capacity to identify correct score positions for sampled test contexts; second, as the core technique of a complete algorithm for symbolic online note-wise alignment; and finally, as a real-time symbolic score follower.
We further investigate the pitch-based score and performance representations used as the agent’s inputs.
To this end, we develop a second model, a two-step Dynamic Time Warping (DTW)-based offline alignment algorithm leveraging the same input representation.
The proposed model outperforms a state-of-the-art reference model of offline symbolic music alignment.",[''],[]
,[''],[]
"The industrial Internet of Things (IIoT) involves the integration of Internet of Things (IoT) technologies into industrial settings. However, given the high sensitivity of the industry to the security of industrial control system networks and IIoT, the use of software-defined networking (SDN) technology can provide improved security and automation of communication processes. Despite this, the architecture of SDN can give rise to various security threats. Therefore, it is of paramount importance to consider the impact of these threats on SDN-based IIoT environments. Unlike previous research, which focused on security in IIoT and SDN architectures separately, we propose an integrated method including two components that work together seamlessly for better detecting and preventing security threats associated with SDN-based IIoT architectures. The two components consist in a convolutional neural network-based Intrusion Detection System (IDS) implemented as an SDN application and a Blockchain-based system (BS) to empower application layer and network layer security, respectively.
A significant advantage of the proposed method lies in jointly minimizing the impact of attacks such as command injection and rule injection on SDN-based IIoT architecture layers.
The proposed IDS exhibits superior classification accuracy in both binary and multiclass categories.","['Index', 'Terms: ', 'Blockchain,', 'Industrial', 'IoT,', 'SDN,', 'Deep learning,', 'Intrusion detection system, and', 'Security.']",['tarik.taleb}@oulu.fi']
"This review paper examines the concept and advancements in the evolving landscape of Dual-functional Radar Communication (DFRC) systems. Traditionally, radar and communication systems have functioned independently, but current research is actively investigating the integration of these functionalities into a unified platform. This paper discusses the motivations behind the development of DFRC systems, the challenges involved, and the potential benefits they offer. A discussion on the performance bounds for DFRC systems is also presented. The paper encompasses a comprehensive analysis of various techniques, architectures, and technologies used in the design and optimization of DFRC systems, along with their performance and trade-offs. Additionally, we explore potential application scenarios for these joint communication and sensing systems, offering a comprehensive perspective on the multifaceted landscape of DFRC technology.","['Index', 'Terms: ', 'Joint', 'Communication and radar/radio', 'Sensing (JCAS),', 'Dual-functional', 'Radar', 'Communications (DFRC),', 'Integrated', 'Sensing and', 'Communications (ISAC),', 'Wireless', 'Communications, and', 'Radar.']",[]
"We study M-Theory solutions with G𝐺Gitalic_G-flux on the Fermat sextic Calabi-Yau fourfold, focussing on the relationship between the number of stabilized complex structure moduli and the tadpole contribution of the flux. We use two alternative approaches to define the fluxes: algebraic cycles and (appropriately quantized) Griffiths residues. In both cases, we collect evidence for the non-existence of solutions which stabilize all moduli and stay within the tadpole bound.",[''],[]
"Generative models of expressive piano performance are usually assessed by comparing their predictions to a reference human performance.
A generative algorithm is taken to be better than competing ones if it produces
performances that are closer to a human reference performance.
However, expert human performers can (and do) interpret music in different ways, making for different possible references, and quantitative closeness is not necessarily aligned with perceptual similarity, raising concerns about the validity of this evaluation approach.
In this work, we present a number of experiments that shed light on this problem.
Using precisely measured high-quality performances of classical piano music,
we carry out a listening test indicating that listeners can sometimes perceive subtle performance difference that go unnoticed under quantitative evaluation.
We further present tests that indicate that such evaluation frameworks show a lot of variability in reliability and validity across different reference performances and pieces.
We discuss these results and their implications for quantitative evaluation, and hope to foster a critical appreciation of the uncertainties involved in quantitative assessments of such performances within the wider music information retrieval (MIR) community.","['Performance,', 'Expression,', 'Evaluation,', 'Validity,', 'Listening', 'Study']","['UniversityLinzAustria', 'UniversityLinzAustria', 'UniversityLinzAustria', 'UniversityLinzAustria']"
"A proposal is made for what may well be the most elementary Riemannian spaces which are homogeneous but not isotropic. In other words: a proposal is made for what may well be the the nicest symmetric spaces beyond the real space forms, that is, beyond the Riemannian spaces which are homogeneous and isotropic. The above qualification of ‘’nicest symmetric spaces” finds a justification in that, together with the real space forms, these spaces are most natural with respect to the importance in human vision of our ability to readily recognise conformal things and in that  these spaces are most natural with respect to what in Weyl’s view is symmetry in Riemannian geometry.
Following his suggestion to remove the real space forms’ isotropy condition, the quasi space forms thus introduced do offer a metrical, local geometrical solution to the geometrical space form problem as posed by Thurston in his 1979 Princeton Lecture Notes on ‘’The Geometry and Topology of 3-manifolds”. Roughly speaking, quasi space forms are the Riemannian manifolds of dimension greater than or equal to 3, which are not real space forms but which admit two orthogonally complementary distributions such that at all points all the 2-planes that in the tangent spaces there are situated in a same position relative to these distributions do have the same sectional curvatures.",[''],[]
"Motivated by the inapproximability of reconfiguration problems,
we present a new PCP-type characterization of \PSPACE\PSPACE\PSPACE, which we call
a probabilistically checkable reconfiguration proof (PCRP):
Any \PSPACE\PSPACE\PSPACE computation can be encoded into an exponentially long sequence of polynomially long proofs
such that
every adjacent pair of the proofs differs in at most one bit,
and every proof can be probabilistically checked by reading a constant number of bits.
Using the new characterization, we prove \PSPACE\PSPACE\PSPACE-completeness of approximate versions of many reconfiguration problems,
such as the Maxmin 3333-SAT Reconfiguration problem.
This resolves the open problem posed by Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno (ISAAC 2008; Theor. Comput. Sci. 2011)
as well as the Reconfiguration Inapproximability Hypothesis by Ohsaka (STACS 2023) affirmatively.
We also present \PSPACE\PSPACE\PSPACE-completeness of approximating the Maxmin Clique Reconfiguration problem
to within a factor of nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT for some constant ε>0𝜀0\varepsilon>0italic_ε > 0.",[''],[]
"This study focuses on emotion-sensitive spoken dialogue in human-machine speech interaction. With the advancement of Large Language Models (LLMs), dialogue systems can handle multimodal data, including audio. Recent models have enhanced the understanding of complex audio signals through the integration of various audio events. However, they are unable to generate appropriate responses based on emotional speech. To address this, we introduce the Emotional chat Model (E-chat), a novel spoken dialogue system capable of comprehending and responding to emotions conveyed from speech. This model leverages an emotion embedding extracted by a speech encoder, combined with LLMs, enabling it to respond according to different emotional contexts. Additionally, we introduce the E-chat200 dataset, designed explicitly for emotion-sensitive spoken dialogue. In various evaluation metrics, E-chat consistently outperforms baseline LLMs, demonstrating its potential in emotional comprehension and human-machine interaction.",[''],[]
,[''],[]
"Although user cooperation cannot improve the capacity of Gaussian two-way channels (GTWCs) with independent noises, it can improve communication reliability.
In this work,
we aim to enhance and balance the communication reliability in GTWCs by minimizing the sum of error probabilities via joint design of encoders and decoders at the users.
We first formulate general encoding/decoding functions, where the user cooperation is captured by the coupling of user encoding processes.
The coupling effect renders the encoder/decoder design non-trivial, requiring effective decoding to capture this effect, as well as efficient power management at the encoders within power constraints.
To address these challenges,
we propose two different two-way coding strategies: linear coding and learning-based coding.
For linear coding,
we propose optimal linear decoding and discuss new
insights on encoding regarding user cooperation to balance reliability.
We then propose an efficient algorithm
for joint encoder/decoder design.
For learning-based coding, we introduce a novel recurrent neural network (RNN)-based coding architecture, where we propose interactive RNNs and a power control layer for encoding, and we incorporate bi-directional RNNs with an attention mechanism for decoding.
Through simulations, we show that our two-way coding methodologies outperform conventional channel coding schemes (that do not utilize user cooperation) significantly in sum-error performance.
We also demonstrate that our linear coding
excels at high signal-to-noise ratios (SNRs), while
our RNN-based coding performs best at low SNRs.
We further investigate our two-way coding strategies in terms of power distribution, two-way coding benefit, different coding rates, and block-length gain.","['Index', 'Terms: ', 'Gaussian two-way channels, communication reliability, user cooperation, linear coding, neural coding']",[]
"In this paper, we study the large-time behavior of small solutions to the standard form of the systems of 1D cubic nonlinear Schrödinger equations consisting of two components and possessing a coercive mass-like conserved quantity.
The cubic nonlinearity is known to be critical in one space dimension in view of the large-time behavior.
By employing the result by Katayama and Sakoda, one can obtain the large-time behavior of the solution if we can integrate the corresponding ODE system.
We introduce an integration scheme suited to the system. The key idea is to rewrite the ODE system, which is cubic, as a quadratic system of quadratic quantities of the original unknown.
By using this technique, we described the large-time behavior of solutions in terms of elementary functions and the Jacobi elliptic functions for several examples of standard systems.","['Key words and phrases: nonlinear', 'Schrödinger equation, system, nonlinear ordinary differential system, explicit solution of nonlinear ordinary differential system, asymptotic behavior,', 'Jacobi elliptic function']",[]
"In this paper we consider the vector-valued Schrödinger operator −Δ+VΔ𝑉-\Delta+V- roman_Δ + italic_V, where the potential term V𝑉Vitalic_V is a matrix-valued function whose entries belong to Lloc1⁢(ℝd)subscriptsuperscript𝐿1locsuperscriptℝ𝑑L^{1}_{\rm loc}({\mathbb{R}}^{d})italic_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_loc end_POSTSUBSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) and, for every x∈ℝd𝑥superscriptℝ𝑑x\in{\mathbb{R}}^{d}italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, V⁢(x)𝑉𝑥V(x)italic_V ( italic_x ) is a symmetric and nonnegative definite matrix, with non positive off-diagonal terms and with eigenvalues comparable each other. For this class of potential terms we obtain maximal inequality in L1⁢(ℝd,ℝm).superscript𝐿1superscriptℝ𝑑superscriptℝ𝑚L^{1}({\mathbb{R}}^{d},{\mathbb{R}}^{m}).italic_L start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ) . Assuming further that the minimal eigenvalue of V𝑉Vitalic_V belongs to some reverse Hölder class of order q∈(1,∞)∪{∞}𝑞1q\in(1,\infty)\cup\{\infty\}italic_q ∈ ( 1 , ∞ ) ∪ { ∞ }, we obtain maximal inequality in Lp⁢(ℝd,ℝm)superscript𝐿𝑝superscriptℝ𝑑superscriptℝ𝑚L^{p}({\mathbb{R}}^{d},{\mathbb{R}}^{m})italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ), for p𝑝pitalic_p in between 1111 and some q𝑞qitalic_q.","['Key words and phrases: ', 'Vector-valued elliptic operators,', 'Schrödinger operators with unbounded coefficients, vector-valued analytic semigroups, domain characterization,', 'Lebesgue', 'Lpsuperscript𝐿𝑝L^{p}italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT-spaces, reverse', 'Hölder class.']",[]
"To improve our understanding of the quark-gluon dynamics underlying multiquark states, we systematically study their electromagnetic properties. In this study, the electromagnetic properties of the X⁢(4140)X4140\mathrm{X(4140)}roman_X ( 4140 ) and X⁢(4630)X4630\mathrm{X(4630)}roman_X ( 4630 ) states with the quantum numbers JPC=1++superscriptJPCsuperscript1absent\mathrm{J^{PC}=1^{++}}roman_J start_POSTSUPERSCRIPT roman_PC end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + + end_POSTSUPERSCRIPT and JPC=1−+superscriptJPCsuperscript1absent\mathrm{J^{PC}=1^{-+}}roman_J start_POSTSUPERSCRIPT roman_PC end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT - + end_POSTSUPERSCRIPT, respectively are investigated within the framework of the QCD light-cone sum rules method by considering the diquark-antidiquark configuration of these states. We also calculate the magnetic and quadrupole moments of the theoretically predicted singly-charmed state, XAVsubscriptXAV\mathrm{X_{AV}}roman_X start_POSTSUBSCRIPT roman_AV end_POSTSUBSCRIPT, with the quantum numbers JP=1+superscriptJPsuperscript1\mathrm{J^{P}=1^{+}}roman_J start_POSTSUPERSCRIPT roman_P end_POSTSUPERSCRIPT = 1 start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. The predicted results for the magnetic moments are as μX⁢(4140)=−1.11−0.31+0.41⁢μNsubscript𝜇X4140subscriptsuperscript1.110.410.31subscript𝜇𝑁\mu_{\mathrm{X(4140)}}=-1.11^{+0.41}_{-0.31}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X ( 4140 ) end_POSTSUBSCRIPT = - 1.11 start_POSTSUPERSCRIPT + 0.41 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.31 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, μX⁢(4630)=−0.62−0.11+0.13⁢μNsubscript𝜇X4630subscriptsuperscript0.620.130.11subscript𝜇𝑁\mu_{\mathrm{X(4630)}}=-0.62^{+0.13}_{-0.11}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X ( 4630 ) end_POSTSUBSCRIPT = - 0.62 start_POSTSUPERSCRIPT + 0.13 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.11 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT, and μXAV=−0.98−0.21+0.27⁢μNsubscript𝜇subscriptXAVsubscriptsuperscript0.980.270.21subscript𝜇𝑁\mu_{\mathrm{X_{AV}}}=-0.98^{+0.27}_{-0.21}~{}\mu_{N}italic_μ start_POSTSUBSCRIPT roman_X start_POSTSUBSCRIPT roman_AV end_POSTSUBSCRIPT end_POSTSUBSCRIPT = - 0.98 start_POSTSUPERSCRIPT + 0.27 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.21 end_POSTSUBSCRIPT italic_μ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT. The results obtained can be useful in determining the exact nature of these states. This work will hopefully stimulate experimental interest in the study of the electromagnetic properties of multiquark systems.","['Magnetic and quadrupole moments, tetraquarks, diquark-antidiquark picture,', 'QCD light-cone sum rules']",['Türkiye']
"The successful commercialization of flexible spintronic devices requires a complete understanding of the impact of external strain on the structural, electronic, and magnetic properties of a system. The impact of bending-induced strain on flexible films is studied quite well. However, little is known about the effect of other modes of flexibility, e.g., wrinkling, twisting, peeling, and stretching on the functional properties of flexible films. In this context, perpendicular magnetic anisotropic Co/Pt and Co/Pd thin films are prepared on flexible Kapton substrates, and the impact of the peeling mode is studied in detail. The peeling method generates numerous cracks, and buckling in the thin film, along with localized blister formation imaged by scanning electron microscopy. Further, the resistivity measurement confirms a significant enhancement in sample resistance owing to the severe damage of the films. The structural discontinuities strongly affect the magnetization reversal phenomena as measured by the magneto-optic Kerr effect (MOKE)-based microscopy. The bubble domains got converted to elongated-shaped domains due to several hindrances to the wall motion after strain application. Further, the relaxation measurements reveal that the thermal energy is insufficient to switch the magnetization at a few areas due to their high pinning potential associated with the damages. In contrast to bending-induced strain, here, all the modifications in the functional properties are found to be irreversible in nature.",[''],['India']
"A recent study has demonstrated that a fermionic two-leg ladder model, threaded by a flux and characterized by a spatially varying interleg hopping term, gives rise to a quasiflat low-energy band. This band exhibits an unusual ground state at half filling in the presence of interaction—a ferromagnetic Mott insulator. In this paper, we extend the study of this model to other fillings of the quasiflat band and explore the magnetic properties of the ground state at these fillings. In particular, we study four fillings: one-quarter, three-quarters, slightly above half filling (half filling plus two electrons), and slightly below half-filling (half filling minus two electrons). Incorporating interaction within the Hubbard model and using the Density Matrix Renormalization Group method to find the ground states, we find that the spin-spin correlation is ferromagnetic at fillings less than half, similar to that observed at half filling, but is antiferromagnetic beyond half filling. Interestingly, these results hold only when mixing between the lowest quasiflat band and the next-to-lowest dispersive band is negligible; once mixing between the two bands is facilitated by increasing the interaction strength, the correlation becomes ferromagnetic above half filling as well. Additionally, by reducing the strength of the interaction in comparison to the bandwidth, a transition from the ferromagnetic to the antiferromagnetic state is observed in all the cases.",[''],"['India', 'USA', 'USA', 'India']"
"The flow of cerebrospinal fluid through the perivascular spaces of the brain is believed to play a crucial role in eliminating toxic waste proteins. While the driving forces of this flow have been enigmatic, experiments have shown that arterial wall motion is central. In this work, we present a network model for simulating pulsatile fluid flow in perivascular networks. We establish the well-posedness of this model in the primal and dual mixed variational settings, and show how it can be discretized using mixed finite elements. Further, we utilize this model to investigate fundamental questions concerning the physical mechanisms governing perivascular fluid flow. Notably, our findings reveal that arterial pulsations can induce directional flow in branching perivascular networks.",[''],"['[', '[']"
"We establish Jafarian’s 2009 conjecture that every additive spectrum preserving mapping from a von Neumann algebra
onto a semisimple Banach algebra is a Jordan isomorphism.","['Key words and phrases:', 'Von', 'Neumann algebras,', 'Jordan isomorphisms, spectrum preserving mappings']",[]
"Development of power efficient spintronics devices has been the compelling need in the post-CMOS technology era. The effective tunability of spin-orbit-coupling (SOC) in bulk and at the interfaces of hybrid materials stacking is a prerequisite for scaling down the dimension and power consumption of these devices. In this work, we demonstrate the strong chemisorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules when grown on the high SOC β𝛽\betaitalic_β-W layer. The parent CFB/β𝛽\betaitalic_β-W bilayer exhibits large spin-to-charge interconversion efficiency, which can be ascribed to the interfacial SOC observed at the Ferromagnet/Heavy metal interface. Further, the adsorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules on β𝛽\betaitalic_β-W reduces the effective Gilbert damping by ∼similar-to\sim∼15%percent\%% in the CFB/β𝛽\betaitalic_β-W/C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT heterostructures. The anti-damping is accompanied by a gigantic ∼similar-to\sim∼115%percent\%% enhancement in the spin-pumping induced output voltage owing to the molecular hybridization. The non-collinear Density Functional Theory calculations confirm the long-range enhancement of SOC of β𝛽\betaitalic_β-W upon the chemisorption of C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT molecules, which in turn can also enhance the SOC at the CFB/β𝛽\betaitalic_β-W interface in CFB/β𝛽\betaitalic_β-W/C6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPT heterostructures. The combined amplification of bulk as well interfacial SOC upon molecular hybridization stabilizes the anti-damping and enhanced spin-to-charge conversion, which can pave the way for the fabrication of power efficient spintronics devices.",[''],"['India', 'India', 'India']"
"Organic semiconductors (OSCs) are suitable materials for spintronics applications as they form a spinterface when placed next to a ferromagnet, which in turn leads to novel functionalities. The evolution of spinterface can tune the global magnetic anisotropy, magnetization reversal, magnetization dynamics etc. Planar
tris(8-hydroxy-
quinoline)aluminium (Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT) OSC has shown tremendous potential for spintronics application, thanks to its efficient spin-polarized current transport ability. Here, we establish the spinterface when the Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT molecules are deposited on amorphous ferromagnet Co2020{}_{20}start_FLOATSUBSCRIPT 20 end_FLOATSUBSCRIPTFe6060{}_{60}start_FLOATSUBSCRIPT 60 end_FLOATSUBSCRIPTB2020{}_{20}start_FLOATSUBSCRIPT 20 end_FLOATSUBSCRIPT(CFB). The π𝜋\piitalic_π-d𝑑ditalic_d hybridization in CFB/Alq33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT enhances the coercive field and significantly modifies the shape and size of the magnetic domains. A∼similar-to\sim∼ 100%percent\%% increase in uniaxial anisotropic energies and a reduction in magnetic damping are also evident owing to the strong interfacial hybridization.",[''],"['India', 'India', 'India', 'Kingdom', 'Kingdom', 'India']"
"Understanding the physical properties of stars, and putting these properties into the context of stellar evolution, is a core challenge in astronomical research. A key visualization in studying stellar evolution is the Hertzsprung-Russell diagram (HRD), organizing data about stellar luminosity and colour into a form that is informative about stellar structure and evolution. However, connecting the HRD with other sources of information, including stellar time series, is an outstanding challenge. Here we present a new method to turn stellar time series into sound. This method encodes physically meaningful features such that auditory comparisons between sonifications of different stars preserve astrophysical differences between them. We present an interactive multimedia version of the HRD that combines both visual and auditory components and that allows exploration of different types of stars both on and off the main sequence through both visual and auditory media.",[''],[]
"Motivated by classical Alexander invariants of affine hypersurface complements, we endow certain finite dimensional quotients of the homology of abelian covers of complex algebraic varieties with a canonical and functorial mixed Hodge structure (MHS). More precisely, we focus on covers which arise algebraically in the following way: if U𝑈Uitalic_U is a smooth connected complex algebraic variety and G𝐺Gitalic_G is a complex semiabelian variety, the pullback of the exponential map by an algebraic morphism f:U→G:𝑓→𝑈𝐺f:U\to Gitalic_f : italic_U → italic_G yields a covering space π:Uf→U:𝜋→superscript𝑈𝑓𝑈\pi:U^{f}\to Uitalic_π : italic_U start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT → italic_U whose group of deck transformations is π1⁢(G)subscript𝜋1𝐺\pi_{1}(G)italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_G ). The new MHS are compatible with Deligne’s MHS on the homology of U𝑈Uitalic_U through the covering map π𝜋\piitalic_π and satisfy a direct sum decomposition as MHS into generalized eigenspaces by the action of deck transformations. This provides a vast generalization of the previous results regarding univariable Alexander modules of the authors, Geske, Maxim and Wang. Lastly, we reduce the problem of whether the first Betti number of the Milnor fiber of a central hyperplane arrangement complement is combinatorial to a question about the Hodge filtration of certain MHS defined in this paper, providing evidence that the new structures contain interesting information.","['Key words and phrases: abelian cover,', 'Alexander module, mixed', 'Hodge structure, thickened complex, hyperplane arrangements, jump loci']",[]
"Several disciplines, like the social sciences, epidemiology, sentiment analysis, or market research, are interested in knowing the distribution of the classes in a population rather than the individual labels of the members thereof. Quantification is the supervised machine learning task concerned with obtaining accurate predictors of class prevalence, and to do so particularly in the presence of label shift. The distribution-matching (DM) approaches represent one of the most important families among the quantification methods that have been proposed in the literature so far. Current DM approaches model the involved populations by means of histograms of posterior probabilities. In this paper, we argue that their application to the multiclass setting is suboptimal since the histograms become class-specific, thus missing the opportunity to model inter-class information that may exist in the data. We propose a new representation mechanism based on multivariate densities that we model via kernel density estimation (KDE). The experiments we have carried out show our method, dubbed KDEy, yields superior quantification performance with respect to previous DM approaches. We also investigate the KDE-based representation within the maximum likelihood framework and show KDEy often shows superior performance with respect to the expectation-maximization method for quantification, arguably the strongest contender in the quantification arena to date.",[''],[]
"The dyadic representation of any singular integral operator, as an average of dyadic model operators, has found many applications. While for many purposes it is enough to have such a representation for a “suitable class” of test functions, we show that, under quite general assumptions (essentially minimal ones to make sense of the formula), the representation is actually valid for all pairs (f,g)∈Lp⁢(ℝd)×Lp′⁢(ℝd)𝑓𝑔superscript𝐿𝑝superscriptℝ𝑑superscript𝐿superscript𝑝′superscriptℝ𝑑(f,g)\in L^{p}(\mathbb{R}^{d})\times L^{p^{\prime}}(\mathbb{R}^{d})( italic_f , italic_g ) ∈ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) × italic_L start_POSTSUPERSCRIPT italic_p start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ), not just test functions.","['Key words and phrases:', 'Singular integral, dyadic shift']",[]
"Consider Hermitian and symmetric random band matrices H=(σx⁢y⁢Ax⁢y)𝐻subscript𝜎𝑥𝑦subscript𝐴𝑥𝑦H=(\sigma_{xy}A_{xy})italic_H = ( italic_σ start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT ) on the d𝑑ditalic_d-dimensional lattice (ℤ/L⁢ℤ)dsuperscriptℤ𝐿ℤ𝑑\left(\mathbb{Z}/{L\mathbb{Z}}\right)^{d}( blackboard_Z / italic_L blackboard_Z ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, where Ax⁢y=Ay⁢x¯subscript𝐴𝑥𝑦¯subscript𝐴𝑦𝑥A_{xy}=\overline{A_{yx}}italic_A start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT = over¯ start_ARG italic_A start_POSTSUBSCRIPT italic_y italic_x end_POSTSUBSCRIPT end_ARG are independent uniformly distributed random variables on S1superscript𝑆1S^{1}italic_S start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT or {+1,−1}11\{+1,-1\}{ + 1 , - 1 }, and the variance profile σx⁢y2subscriptsuperscript𝜎2𝑥𝑦\sigma^{2}_{xy}italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x italic_y end_POSTSUBSCRIPT is characterized by the bandwidth W𝑊Witalic_W and α𝛼\alphaitalic_α-stable density with α∈(0,2]𝛼02\alpha\in(0,2]italic_α ∈ ( 0 , 2 ].
We investigate local eigenvalue statistics at the spectral edge as W→∞→𝑊W\to\inftyitalic_W → ∞ and observe the critical dimension dc=3⁢αsubscript𝑑𝑐3𝛼d_{c}=3\alphaitalic_d start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 3 italic_α and the critical bandwidth Wc=L(1−d3⁢α)+subscript𝑊𝑐superscript𝐿subscript1𝑑3𝛼W_{c}=L^{(1-\frac{d}{3\alpha})_{+}}italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = italic_L start_POSTSUPERSCRIPT ( 1 - divide start_ARG italic_d end_ARG start_ARG 3 italic_α end_ARG ) start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, possibly with a log⁡L𝐿\log Lroman_log italic_L correction when d=α𝑑𝛼d=\alphaitalic_d = italic_α or 2⁢α2𝛼2\alpha2 italic_α. In the Hermitian case, we establish that
(i) when d<2⁢α𝑑2𝛼d<2\alphaitalic_d < 2 italic_α, GUE edge, interpolating, and Poisson statistics emerge in the supercritical (W≫Wcmuch-greater-than𝑊subscript𝑊𝑐W\gg W_{c}italic_W ≫ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT), critical (W∼Wcsimilar-to𝑊subscript𝑊𝑐W\sim W_{c}italic_W ∼ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT), and subcritical (W≪Wcmuch-less-than𝑊subscript𝑊𝑐W\ll W_{c}italic_W ≪ italic_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT) regimes, respectively;
(ii) when d≥2⁢α𝑑2𝛼d\geq 2\alphaitalic_d ≥ 2 italic_α, as long as W≥L13+ϵ𝑊superscript𝐿13italic-ϵW\geq L^{\frac{1}{3}+\epsilon}italic_W ≥ italic_L start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 3 end_ARG + italic_ϵ end_POSTSUPERSCRIPT for a small constant ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, GUE edge universality holds.
In the symmetric case, we also establish similar but subtle phenomena. In both d=1𝑑1d=1italic_d = 1 and α=2𝛼2\alpha=2italic_α = 2, the subcritical and supercritical results have been proven by Sodin for the band model with a cutoff variance profile [Sod10]. Our proof builds upon Sodin’s program and new techniques of taming the singularity of Feynman diagrams and graph integrals through a connection to the ϕ3superscriptitalic-ϕ3\phi^{3}italic_ϕ start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT model.",[''],[]
"Random Batch Methods (RBM) for mean-field interacting particle systems enable the reduction of the quadratic computational cost associated with particle interactions to a near-linear cost. The essence of these algorithms lies in the random partitioning of the particle ensemble into smaller batches at each time step. The interaction of each particle within these batches is then evolved until the subsequent time step. This approach effectively decreases the computational cost by an order of magnitude while increasing the amount of fluctuations due to the random partitioning. In this work, we propose a variance reduction technique for RBM applied to nonlocal PDEs of Fokker-Planck type based on a control variate strategy. The core idea is to construct a surrogate model that can be computed on the full set of particles at a linear cost while maintaining enough correlations with the original particle dynamics. Examples from models of collective behavior in opinion spreading and swarming dynamics demonstrate the great potential of the present approach.
Keywords: Random batch methods, control variate methods, surrogate models, collective behavior, nonlocal PDEs",[''],[]
"We review the method for constructing local relativistic fields corresponding to the Bargmann-Wigner wave functions that describe
the unitary irreducible representations of the 4⁢D4𝐷4D4 italic_D Poincaré group.
The method is based on the use of the generalized Wigner operator
connecting the wave functions of induced representations and local relativistic fields.
Applications of this operator for constructing
massive local relativistic fields as well as massless helicity local fields and massless local infinite spin fields are considered.",[''],[]
"In this talk, we give the lattice regularized formulation of the mixed ’t Hooft anomaly between the ℤNsubscriptℤ𝑁\mathbb{Z}_{N}blackboard_Z start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT 1111-form symmetry and the θ𝜃\thetaitalic_θ periodicity for 4444d pure Yang-Mills theory, which was originally discussed by Gaiotto et al. in the continuum description.
For this purpose, we define the topological charge of the lattice S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) gauge theory coupled with the background ℤNsubscriptℤ𝑁\mathbb{Z}_{N}blackboard_Z start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT 2222-form gauge fields Bpsubscript𝐵𝑝B_{p}italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT by generalizing Lüscher’s construction of the S⁢U⁢(N)𝑆𝑈𝑁SU(N)italic_S italic_U ( italic_N ) topological charge.
We show that this lattice topological charge enjoys the fractional 1/N1𝑁1/N1 / italic_N shift completely characterized by the background gauge field Bpsubscript𝐵𝑝B_{p}italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, and this rigorously proves the mixed ’t Hooft anomaly with the finite lattice spacings.
As a consequence, the Yang-Mills vacua at θ𝜃\thetaitalic_θ and θ+2⁢π𝜃2𝜋\theta+2\piitalic_θ + 2 italic_π are distinct as the symmetry-protected topological states when the confinement is assumed.",[''],[]
"Surgical tool segmentation and action recognition are fundamental building blocks in many computer-assisted intervention applications, ranging from surgical skills assessment to decision support systems. Nowadays, learning-based action recognition and segmentation approaches outperform classical methods, relying, however, on large, annotated datasets. Furthermore, action recognition and tool segmentation algorithms are often trained and make predictions in isolation from each other, without exploiting potential cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we release the first multimodal, publicly available, in-vivo, dataset for surgical action recognition and semantic instrumentation segmentation, containing 50 suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The aim of the challenge is twofold. First, to enable researchers to leverage the scale of the provided dataset and develop robust and highly accurate single-task action recognition and tool segmentation approaches in the surgical domain. Second, to further explore the potential of multitask-based learning approaches and determine their comparative advantage against their single-task counterparts. A total of 12 teams participated in the challenge, contributing 7 action recognition methods, 9 instrument segmentation techniques, and 4 multitask approaches that integrated both action recognition and instrument segmentation.",[''],[]
"We characterize the sequences of complex numbers (zn)n∈ℕsubscriptsubscript𝑧𝑛𝑛ℕ(z_{n})_{n\in\mathbb{N}}( italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT and the locally complete (D⁢F)𝐷𝐹(DF)( italic_D italic_F )-spaces E𝐸Eitalic_E such that for each (en)n∈ℕ∈Eℕsubscriptsubscript𝑒𝑛𝑛ℕsuperscript𝐸ℕ(e_{n})_{n\in\mathbb{N}}\in E^{\mathbb{N}}( italic_e start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT ∈ italic_E start_POSTSUPERSCRIPT blackboard_N end_POSTSUPERSCRIPT there exists an E𝐸Eitalic_E-valued function 𝐟𝐟\mathbf{f}bold_f on (0,∞)0(0,\infty)( 0 , ∞ ) (satisfying a mild regularity condition) such that




∫0∞tzn⁢𝐟⁢(t)⁢𝑑t=en,∀n∈ℕ,formulae-sequencesuperscriptsubscript0superscript𝑡subscript𝑧𝑛𝐟𝑡differential-d𝑡subscript𝑒𝑛for-all𝑛ℕ\int_{0}^{\infty}t^{z_{n}}\mathbf{f}(t)dt=e_{n},\qquad\forall n\in\mathbb{N},∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_f ( italic_t ) italic_d italic_t = italic_e start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , ∀ italic_n ∈ blackboard_N ,



where the integral should be understood as a Pettis integral. Moreover, in this case, we show that there always exists a solution 𝐟𝐟\mathbf{f}bold_f that is smooth on (0,∞)0(0,\infty)( 0 , ∞ ) and satisfies certain optimal growth bounds near 00 and ∞\infty∞.
The scalar-valued case (E=ℂ)𝐸ℂ(E=\mathbb{C})( italic_E = blackboard_C ) was treated by Durán [13]. Our work is based upon his result.","['Key words and phrases:', 'Stieltjes moment problem; weighted spaces of (vector-valued) smooth functions; linear topological invariants; vector-valued integration']",[]
"By virtue of being atomically thin, the electronic properties of heterostructures built from two-dimensional materials are strongly influenced by atomic relaxation where the atomic layers should be thought of as membranes rather than rigid 2D crystals. We develop an analytical treatment of lattice relaxation for twisted 2D moiré materials obtaining semi-analytical results for lattice displacements, real and momentum space moiré potentials, pseudomagnetic fields and electronic band structures. We benchmark our results for twisted bilayer graphene and twisted homobilayers of tungsten diselenide using large-scale molecular dynamics simulations finding that our theory is valid for magic angle twisted bilayer graphene (angles ≳1∘greater-than-or-equivalent-toabsentsuperscript1\gtrsim 1^{\circ}≳ 1 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT), and for twisted TMDs for twist angles ≳greater-than-or-equivalent-to\gtrsim≳ 7 degrees.",[''],"['117575', '117546', '117542', '117546', '117575', '117546', '117542', '138527']"
,[''],[]
"We construct the deformation quantization with separation of variables on the Grassmannian G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ). The star product on G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ) can be explicitly determined as the solution of the recurrence relations for G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ) given by Hara and one of the authors (A. S.). To give the solution of the recurrence relations, it is necessary to solve a system of linear equations at each order. However, to give the concrete expression of the general term is not easy because the variables increase with the order of the differentiation of the star product. For this reason, there has been no formula to express the general term of the recurrence relations. In this paper, by overcoming this problem by transforming the recurrence relations into simpler ones, we obtain the formula for the general term. We solve the recurrence relations by using creation and annihilation operators on a Fock space. From this solution, we obtain the explicit formula of the star product with separation of variables on G2,4⁢(ℂ)subscript𝐺24ℂG_{2,4}\left(\mathbb{C}\right)italic_G start_POSTSUBSCRIPT 2 , 4 end_POSTSUBSCRIPT ( blackboard_C ).",[''],[]
"We study the flow stability and spatio-temporal spectral dynamics of cellulose nanocrystal (CNC) suspensions in a custom Taylor-Couette flow cell using the intrinsic shear induced birefringence and liquid crystalline properties of CNC suspensions for flow visualizations for the first time. The analysis is performed at constant ramped speed inputs of the independently rotating cylinders for several cases ranging from only inner or outer rotating cylinders to three counter-rotation cases. All CNC suspensions have measurable elastic and shear thinning, both increasing with CNC concentration. We show that the flow patterns recorded are essentially Newtonian-like, with non-Newtonian effects ranging from a decrease in wavenumbers to altering the critical parameters for the onset of instability modes. Outer cylinder rotation flow cases are stable for all concentrations whereas inner cylinder rotation flow cases transition to axisymmetric and azimuthally periodic secondary flows. However, unstable counter-rotation cases become unstable to asymmetric spiral modes. With increasing CNC concentration a counter-rotation case was found where azimuthally periodic wavy patterns transition to asymmetric spiral modes. In contrast to polymeric solutions of similar low to moderate elasticity and shear thinning, the shear-thinning region of CNC suspensions is expected to lead to the breakdown of the chiral nematic phase, whose elastic constants constitute the dominant structural elasticity mechanism. Thus, we interpret the Taylor-Couette stability of the CNC suspensions as dominated by their shear-thinning character due to the expected loss of elasticity in nonlinear flow conditions.",[''],"['Sweden', 'Sweden', '[', 'Sweden', 'Sweden', 'Sweden', 'Sweden', 'Switzerland', 'Switzerland', 'Sweden', 'Sweden', 'Sweden', 'Sweden', 'Sweden']"
,[''],[]
"This paper aims to introduce and analyze the Viz system in a comprehensive way, a novel system architecture that integrates Quantized Low-Rank Adapters (QLoRA) to fine-tune large language models (LLM) within a legally compliant and resource efficient marketplace. Viz represents a significant contribution to the field of artificial intelligence, particularly in addressing the challenges of computational efficiency, legal compliance, and economic sustainability in the utilization and monetization of LLMs. The paper delineates the scholarly discourse and developments that have informed the creation of Viz, focusing primarily on the advancements in LLM models, copyright issues in AI training The New York Times Company (2023), and the evolution of model fine-tuning techniques, particularly low-rank adapters and quantized low-rank adapters, to create a sustainable and economically compliant framework for LLM utilization.The economic model it proposes benefits content creators, AI developers, and end-users, delineating a harmonious integration of technology, economy, and law, offering a comprehensive solution to the complex challenges of today’s AI landscape.",[''],[]
,[''],[]
"Higher-order cellular automata (HOCA) are a type of cellular automata that evolve over multiple time steps. These HOCA generate intricate patterns within the spacetime lattice, which can be utilized to create symmetry-protected topological (SPT) phases. The symmetries of these phases are not global, but act on lower-dimensional subsystems of the lattice, such as lines or fractals. These are referred to as HOCA generated SPT (HGSPT) phases. These phases naturally encompass previously studied phases with subsystem symmetries, including symmetry-protected topological phases protected by symmetries supported on regular (e.g., line-like, membrane-like) and fractal subsystems.
Moreover, these phases include models with subsystem symmetries that extend beyond previously studied phases. They include mixed-subsystem SPT (MSPT) that possess two types of subsystem symmetries simultaneously (for example, fractal and line-like subsystem symmetries or two different fractal symmetries), and chaotic SPT (CSPT) that have chaos-like symmetries, beyond the classification of fractal or regular subsystems.
We propose that each HOCA pattern with a finite initial condition can be represented by a mathematical object X=(d,M)𝑋𝑑𝑀X=(d,M)italic_X = ( italic_d , italic_M ), and HOCA rules 𝐟𝐟\mathbf{f}bold_f can be categorized into different classes [𝐟]delimited-[]𝐟[\mathbf{f}][ bold_f ] based on the pattern that the rule can generate. The class of the HOCA rule of a given HGSPT can be identified by what we dub as the multi-point strange correlator, as a generalization of the strange correlator. We have raised a general procedure to construct multi-point strange correlators to detect the nontrivial SPT orders in the gapped ground states of HGSPT models and the their classes.",[''],['China']
"We consider a Josephson junction built with the two-dimensional semi-Dirac semimetal, which features a hybrid of linear and quadratic dispersion around a nodal point. We model the weak link between the two superconducting regions by a Dirac delta potential because it mimics the thin-barrier limit of a superconductor-barrier-superconductor configuration. Assuming a homogeneous pairing in each region, we set up the BdG formalism for electronlike and holelike quasiparticles propagating along the quadratic-in-momentum dispersion direction. This allows us to compute the discrete bound-state energy spectrum ε𝜀\varepsilonitalic_ε of the subgap Andreev states localized at the junction.
In contrast with the Josephson effect investigated for propagation along linearly dispersing directions,
we find a pair of doubly degenerate Andreev bound states. Using the dependence of ε𝜀\varepsilonitalic_ε on the superconducting phase difference ϕitalic-ϕ\phiitalic_ϕ, we compute the variation of Josephson current as a function of ϕitalic-ϕ\phiitalic_ϕ.",[''],['India']
,[''],[]
"Amplification of quantum transfer and ratchet–type processes are important for quantum technologies. We also expect that quantum ratchet works in quantum photosynthesis, where possible role of quantum effects is now widely discussed but the underlying dynamical processes are still not clearly known. In this work, we study a model of amplification of quantum transfer and making it directed which we call the quantum ratchet model. The model is based on a special quantum control master equation with dynamics induced by a feedback-type process. The ratchet effect is achieved in the quantum control model with dissipation and sink, where the Hamiltonian depends on vibrations in the energy difference synchronized with transitions between energy levels. A similarity between this model and the model of coherent transport in quantum photosynthesis, where the time dependence of the Hamiltonian arises due to vibrons, is studied. Amplitude and frequency of the oscillating vibron together with the dephasing rate are the parameters of the quantum ratchet which determine its efficiency. We study with which parameters the quantum ratchet minimizes the exction recombination time and show that the experimentally known values of the parameters of the photosynthetic reaction center correspond to values of the parameters of the quantum ratchet which realize a local minimum of the exciton recombination time. We also find another values of the parameters of the quantum ratchet minimizing the exciton recombination time, which corresponds to a twice smaller frequency of the vibron compared to that observed in experiments.",[''],[]
"The classical notion of twisted product is studied in the context of partial actions, in particular, we show that the globalization of a partial action is a twisted product. In addition, we establish conditions for the metrizability of twisted products, and some homotopy and categorical properties are proved. Furthermore, sufficient conditions for the enveloping space to be an equivariant absolute neighborhood extensor are also studied.",[''],[]
"The family of Matérn kernels are often used in spatial statistics, function approximation and Gaussian process methods in machine learning.
One reason for their popularity is the presence of a smoothness parameter that controls, for example, optimal error bounds for kriging and posterior contraction rates in Gaussian process regression.
On closed Riemannian manifolds, we show that the smoothness parameter can be consistently estimated from the maximizer(s) of the Gaussian likelihood when the underlying data are from point evaluations of a Gaussian process and, perhaps surprisingly, even when the data comprise evaluations of a non-Gaussian process.
The points at which the process is observed need not have any particular spatial structure beyond quasi-uniformity.
Our methods are based on results from approximation theory for the Sobolev scale of Hilbert spaces.
Moreover, we generalize a well-known equivalence of measures phenomenon related to Matérn kernels to the non-Gaussian case by using Kakutani’s theorem.","['62M30, 62F12, 60G30, 62R30,', 'Whittle–Matérn kernel,', 'Parameter estimation,', 'Equivalence of measures,', 'Maximum likelihood,']",[]
,[''],[]
,[''],[]
"It is believed that for metric-like models in the KPZ class the following property holds: with probability one, starting from any point, there are at most two semi-infinite geodesics with the same direction that do not coalesce. Until now, such a result was only proved for one model - exponential LPP [Cou11] using its inherent connection to the totally asymmetric exclusion process. We prove that the above property holds for the directed landscape, the universal scaling limit of models in the KPZ class. Our proof reduces the problem to one on line ensembles and therefore paves the way to show similar results for other metric-like models in the KPZ class. Finally, combining our result with the ones in [BSS22, Bha23] we obtain the full qualitative geometric description of infinite geodesics in the directed landscape.",[''],[]
"In this study we employ staggered fermions to calculate the two-pion taste singlet states at rest. Leveraging the Clebsch-Gordan coefficients of the symmetry group associated with staggered fermions, we effectively compute the π⁢π𝜋𝜋\pi\piitalic_π italic_π contributions to the resting ρ𝜌\rhoitalic_ρ-meson correlator. To discern the distinct energy states involved, we adopt a generalized eigenvalue problem-solving approach. This work will provide insight into the important role played by the two-pion contribution to the anomalous magnetic moment of the muon.
In this paper we present our group theoretic considerations and preliminary results on the contribution of two-pion states to the rho meson correlation function.",[''],[]
,[''],[]
"Numerous statistical methods have been developed to explore genomic imprinting and maternal effects,
which are causes of parent-of-origin patterns in complex human diseases. However, most of them either
only model one of these two confounded epigenetic effects, or make strong yet unrealistic assumptions
about the population to avoid over- parameterization. A recent partial likelihood method (LIME)
can identify both epigenetic effects based on case-control family data without those assumptions.
Theoretical and empirical studies have shown its validity and robustness. However, because LIME
obtains parameter estimation by maximizing partial likelihood, it is interesting to compare its efficiency
with full likelihood maximizer. To overcome the difficulty in over-parameterization when using full
likelihood, in this study we propose a Monte Carlo Expectation Maximization (MCEM) method to
detect imprinting and maternal effects jointly. Those unknown mating type probabilities, the nuisance
parameters, can be considered as latent variables in EM algorithm. Monte Carlo samples are used to
numerically approximate the expectation function that cannot be solved algebraically. Our simulation
results show that though this MCEM algorithm takes longer computational time, and can give higher bias in some simulations compared to LIME, it can generally detect both epigenetic effects with higher power and smaller standard error which demonstrates that it can be a good complement of LIME method.",[''],[]
"The main result of this note is that the shift of the parameter by 1 in the parameter space of decomposing measures in the problem of harmonic analysis on the infinite-dimensional unitary group corresponds to the taking of the reduced Palm measure at infinity for our decomposing measures. The proof proceeds by finite-dimensional approximation of our measures by orthogonal polynomial ensembles. The key remark is that the taking the reduced Palm measure commutes with the scaling limit transition from finite to infinite particle systems.{NoHyper}
††Keywords: determinantal point processes, Palm measure, infinite-dimensional unitary group, orthogonal polynomial ensemble, integrable kernel, Neretin theorem, Hua—Pickrell measure, confluent hypergeometric kernel, Borodin—Olshanski conjecture

MSC: Primary 60G55; Secondary 05E10

The author was supported by a grant of the Government of the Russian Federation for the state support of scientific research, carried out under the supervision of leading scientists, agreement 075-15-2021-602.",[''],[]
"Entanglement swapping (ES) between memory repeater links is critical for establishing quantum networks via quantum repeaters. So far, ES with atomic-ensemble-based memories has not been achieved. Here, we experimentally demonstrated ES between two entangled pairs of spin-wave memories via Duan-Lukin-Cirac-Zoller scheme. With a cloud of cold atoms inserted in a cavity, we produce non-classically-correlated spin-wave-photon pairs in 12 spatial modes and then prepare two entangled pairs of spin-wave memories via a multiplexed scheme. Via single-photon Bell measurement on retrieved fields from two memories, we project the two remaining memories never entangled previously into an entangled state with the measured concurrence of 𝒞=0.0124±0.003𝒞plus-or-minus0.01240.003{\cal C}=0.0124\pm 0.003caligraphic_C = 0.0124 ± 0.003. The successful probability of ES in our scheme is increased by three times, compared with that in non-multiplexed scheme. Our presented work shows that the generation of entanglement (𝒞>0𝒞0{\cal C}>0caligraphic_C > 0) between the remaining memory ensembles requires the average cross-correlation function of the spin-wave-photon pairs to be ≥30absent30\geq 30≥ 30.",[''],"['030006,China', 'China']"
"Numerous statistical methods have been developed to explore genomic imprinting and maternal effects, which are causes of parent-of-origin patterns in complex human diseases. Most of the methods, however, either only model one of these two confounded epigenetic effects, or make strong yet unrealistic assumptions about the population to avoid over- parameterization. A recent partial likelihood method (L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT) can identify both epigenetic effects based on discordant sibpair family data without those assumptions. Theoretical and empirical studies have shown its validity and robustness. As L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT method obtains parameter estimation by maximizing partial likelihood, it is interesting to compare its efficiency with full likelihood maximizer. To overcome the difficulty in over-parameterization when using full likelihood, this study proposes a discordant sib-pair design based Monte Carlo Expectation Maximization (M⁢C⁢E⁢MD⁢S⁢P𝑀𝐶𝐸subscript𝑀𝐷𝑆𝑃MCEM_{DSP}italic_M italic_C italic_E italic_M start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT) method to detect imprinting and maternal effects jointly. Those unknown mating type probabilities, the nuisance parameters, are considered as latent variables in EM algorithm. Monte Carlo samples are used to numerically approximate the expectation function that cannot be solved algebraically. Our simulation results show that though this M⁢C⁢E⁢MD⁢S⁢P𝑀𝐶𝐸subscript𝑀𝐷𝑆𝑃MCEM_{DSP}italic_M italic_C italic_E italic_M start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT algorithm takes longer computation time, it can generally detect both epigenetic effects with higher power, which demonstrates that it can be a good complement of L⁢I⁢M⁢ED⁢S⁢P𝐿𝐼𝑀subscript𝐸𝐷𝑆𝑃LIME_{DSP}italic_L italic_I italic_M italic_E start_POSTSUBSCRIPT italic_D italic_S italic_P end_POSTSUBSCRIPT method.",[''],['USA']
"Accurate air quality forecasting is of paramount importance in the domains of public health, environmental monitoring and protection, and urban planning. However, existing methods often fail to effectively utilize information across different scales (varying spatial distances or temporal periods). Spatially, previous methods struggle to integrate information between individual monitoring stations and the overall city-scale, lacking flexibility in their interactions. Temporally, existing techniques often overlook or do not fully consider the periodic nature of variations in air quality, thus disregarding valuable insights across different time scales. To address these limitations, we present a novel Multi-spatial Multi-temporal air quality forecasting method based on Graph Convolutional Networks and Gated Recurrent Units (M2G2), bridging the gap in air quality forecasting across spatial and temporal scales. The proposed framework consists of two modules: Multi-scale Spatial GCN (MS-GCN) for spatial information fusion and Multi-scale Temporal GRU(MT-GRU) for temporal information integration. In the spatial dimension, the MS-GCN module employs a bidirectional learnable structure and a residual structure, enabling comprehensive information exchange between individual monitoring stations and the city-scale graph. Regarding the temporal dimension, the MT-GRU module adaptively combines information from different temporal scales through parallel hidden states. Leveraging meteorological indicators and four air quality indicators, we present comprehensive comparative analyses and ablation experiments, showcasing the higher accuracy of M2G2 in comparison to nine currently available advanced approaches across all aspects. The improvements of M2G2 over the second-best method on MAE and RMSE are as follows: PM2.5: (6.22%, 6.63%, 9.71%) and (7.72%, 6.67%, 10.45%), PM10subscriptPM10{\rm PM}_{10}roman_PM start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT: (5.78%, 5.52%, 8.26%) and (6.43%, 5.68%, 7.73%, NO2subscriptNO2{\rm NO}_{2}roman_NO start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT: (5.40%, 9.73%, 19.45%) and (5.07%, 7.76%, 16.60%), O3subscriptO3{\rm O}_{3}roman_O start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT: (7.61%, 7.17%, 10.37%) and (6.46%, 6.86%, 9.79%). Furthermore, we demonstrate the effectiveness of each module of M2G2 by ablation study. Our proposed approach not only addresses the limitations of existing methods but also showcases its potential for advancing air quality forecasting using deep learning techniques.",[''],"['China', 'China;', 'China;', 'China;', 'Sweden', 'China', 'China;']"
"This study is centered on precisely calculating analytical critical points for rotating Bardeen-AdS black holes, examining scenarios with and without external dark field contributions. Importantly, this study represents the inaugural attempt to address the computation of critical points specifically for this category of black holes. Our primary focus is on investigating the impact resulting from variations in the charge of nonlinear electrodynamics on the critical phenomena of rotating Bardeen black holes, incorporating the influence of quintessence field contributions. The analytical investigation is concentrated on the horizon radius, employing two distinct approaches to simplify the complexity and length of the calculations. Furthermore, our examination extends to deciphering the intricate relationship between dark energy and critical phenomena. This includes visually portraying a range of critical behaviors while detailing a recent discovery regarding how the intensity of quintessence affects phase transitions. The shifts in these transitions conform to either a concave or convex function, a characteristic dependent on the sign of quintessence intensity.",[''],[]
"Deep learning techniques have been applied in the context of image super-resolution (SR), achieving remarkable advances in terms of reconstruction performance. Existing techniques typically employ highly complex model structures which result in large model sizes and slow inference speeds. This often leads to high energy consumption and restricts their adoption for practical applications. To address this issue, this work employs a three-stage workflow for compressing deep SR models which significantly reduces their memory requirement. Restoration performance has been maintained through teacher-student knowledge distillation using a newly designed distillation loss. We have applied this approach to two popular image super-resolution networks, SwinIR and EDSR, to demonstrate its effectiveness. The resulting compact models, SwinIRmini and EDSRmini, attain an 89% and 96% reduction in both model size and floating-point operations (FLOPs) respectively, compared to their original versions. They also retain competitive super-resolution performance compared to their original models and other commonly used SR approaches. The source code and pre-trained models for these two lightweight SR approaches are released at https://pikapi22.github.io/CDISM/.","['Index', 'Terms: ', 'Image super-resolution, complexity reduction, model compression, knowledge distillation']",['dave.bull}@bristol.ac.uk']
"In continual learning from demonstration (CLfD), a robot learns a sequence of real-world motion skills continually from human demonstrations. Recently, hypernetworks have been successful in solving this problem. In this paper, we perform an exploratory study of the effects of different optimizers, initializers, and network architectures on the continual learning performance of hypernetworks for CLfD. Our results show that adaptive learning rate optimizers work well, but initializers specially designed for hypernetworks offer no advantages for CLfD. We also show that hypernetworks that are capable of stable trajectory predictions are robust to different network architectures. Our open-source code is available at https://github.com/sebastianbergner/ExploringCLFD.",[''],[]
"The Influence Maximization problem under the Independent Cascade model (IC) is considered. The problem asks for a minimal set of vertices to serve as seed set from which a maximum influence propagation is expected.
New seed-set selection methods are introduced based on the notions of a d𝑑ditalic_d-packing and vertex centrality. In particular, we focus on selecting seed-vertices that are far apart and whose influence-values are the highest in their local communities. Our best results are achieved via an initial computation of a d𝑑ditalic_d-Packing followed by selecting either vertices of high degree or high centrality in their respective closed neighborhoods.
This overall Pack and Measure approach proves highly effective as a seed selection method.",[''],"['Lebanon', 'Lebanon']"
"Given the recent advances in quantum technology, the complexity of quantum states is an important notion. The idea of the Krylov spread complexity has come into focus recently with the goal of capturing this in a quantitative way. The present paper sheds new light on the Krylov complexity measure by exploring it in the context of continuous-time quantum-walks on graphs. A close relationship between Krylov spread complexity and the concept of limiting-distributions for quantum-walks is established. Moreover, using a graph optimization algorithm, quantum-walk graphs are constructed that have minimal and maximal (long-time average) Krylov 𝒞¯¯𝒞\bar{\mathcal{C}}over¯ start_ARG caligraphic_C end_ARG-complexity. This reveals an empirical upper bound for the 𝒞¯¯𝒞\bar{\mathcal{C}}over¯ start_ARG caligraphic_C end_ARG-complexity as a function of Hilbert space dimension and an exact lower bound.",[''],['Germany']
"The aim of this note is to estimate the tail of the distribution of the number of particles in an interval under determinantal and Pfaffian point processes. The main result of the note is that the square of the number of particles under the determinantal point process whose correlation kernel is an entire function of finite order has sub-Poissonian tails. The same result also holds in the symplectic Pfaffian case. As a corollary, sub-Poissonian estimates are also obtained for exponential moments of additive functionals over pairs of particles.",[''],[]
"We show that under standard assumptions on the isotropy groups of an integer GKM
manifold, the equivariant Stiefel–Whitney classes of the action are determined
by the GKM graph. This is achieved via a GKM-style description of the
equivariant cohomology with coefficients in a finite field ℤpsubscriptℤ𝑝\mathbb{Z}_{p}blackboard_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT even though in this setting the
restriction map to the fixed point set is not necessarily injective. This closes a gap in our
argument why the GKM graph of a 6666-dimensional integer GKM manifold determines
its nonequivariant diffeomorphism type. We introduce combinatorial
Stiefel–Whitney classes of GKM graphs and use them to derive a nontrivial
obstruction to realizability of GKM graphs in dimension 8888 and higher.",[''],[]
"We introduce GraphGPT, a novel model for Graph learning by self-supervised Generative Pre-training Transformers.
Our model transforms each graph or sampled subgraph into a sequence of tokens representing the node, edge and attributes reversibly using the Eulerian path first.
Then we feed the tokens into a standard transformer decoder and pre-train it with the next-token-prediction (NTP) task.
Lastly, we fine-tune the GraphGPT model with the supervised tasks.
This intuitive, yet effective model achieves superior or close results to the state-of-the-art methods for the graph-, edge- and node-level tasks on the large scale molecular dataset PCQM4Mv2, the protein-protein association dataset ogbl-ppa and the ogbn-proteins dataset from the Open Graph Benchmark (OGB).
Furthermore, the generative pre-training enables us to train GraphGPT up to 400M+ parameters with consistently increasing performance, which is beyond the capability of GNNs and previous graph transformers.
The source code and pre-trained checkpoints will be released soon111https://github.com/alibaba/graph-gpt to pave the way for the graph foundation model research, and also to assist the scientific discovery in pharmaceutical, chemistry, material and bio-informatics domains, etc.",[''],[]
"We demonstrate that non-Hermitian perturbations can probe topological phase transitions and unambiguously detect non-Abelian zero modes. We show that under carefully designed non-Hermitian perturbations, the Loschmidt echo(LE) decays into 1/N where N is the ground state degeneracy in the topological non-trivial phase, while it approaches 1 in the trivial phase. This distinction is robust against small parameter deviations in the non-Hermitian perturbations. We further study four well-known models that support Majorana or parafermionic zero modes. By calculating their dynamical responses to specific non-Hermitian perturbations, we prove that the steady-state LE can indeed differentiate between different phases. This method avoids the ambiguity introduced by trivial zero-energy states and thus provides an alternative and promising way to demonstrate the emergence of topologically non-trivial phases. The experimental realizations of non-Hermitian perturbations are discussed.",[''],"['China', 'China', 'China', 'China', 'China']"
"Recently, Steinberg used discrete Morse theory to give a new proof of a theorem of Symonds that the orbit space of the poset of nontrivial p𝑝pitalic_p-subgroups of a finite group is contractible. We extend Steinberg’s argument in two ways, covering more general versions of the theorem that were already known. In particular, following a strategy of Libman, we give a discrete Morse theoretic argument for the contractibility of the orbit space of a saturated fusion system.",[''],[]
,[''],[]
"The paper considers the convergence of the complex block Jacobi diagonalization methods under the large set of the generalized serial pivot strategies. The global convergence of the block methods for Hermitian, normal and J𝐽Jitalic_J-Hermitian matrices is proven. In order to obtain the convergence results for the block methods that solve other eigenvalue problems, such as the generalized eigenvalue problem, we consider the convergence of a general block iterative process which uses the complex block Jacobi annihilators and operators.","['Key words and phrases: complex block', 'Jacobi method, complex block', 'Jacobi operators, global convergence,', 'Hermitian matrices, normal matrices,', 'J-Hermitian matrices']",[]
"In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered substantial attention due to its potential impact on financial markets and investment strategies. This paper propose a comparative study on hybrid machine learning algorithms and leverage on enhancing model interpretability. Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM), decision tree regressors are introduced. Through the grounded experiments, we observe linear regressor achieves the best performance among candidate models. For the interpretability, we carry out a systematic overview on the preprocessing techniques of time-series statistics, including decomposition, auto-correlational function, exponential triple forecasting, which aim to excavate latent relations and complex patterns appeared in the financial time-series forecasting. We believe this work may derive more attention and inspire more researches in the realm of time-series analysis and its realistic applications.",[''],[]
"Speech emotion recognition (SER) has received a great deal of attention in recent years in the context of spontaneous conversations. While there have been notable results on datasets like the well-known corpus of naturalistic dyadic conversations, IEMOCAP, for both the case of categorical and dimensional emotions, there are few papers which try to predict both paradigms at the same time. Therefore, in this work, we aim to highlight the performance contribution of multi-task learning by proposing a multi-task, multi-modal system that predicts categorical and dimensional emotions. The results emphasise the importance of cross-regularisation between the two types of emotions. Our approach consists of a multi-task, multi-modal architecture that uses parallel feature refinement through self-attention for the feature of each modality. In order to fuse the features, our model introduces a set of learnable bridge tokens that merge the acoustic and linguistic features with the help of cross-attention. Our experiments for categorical emotions on 10-fold validation yield results comparable to the current state-of-the-art. In our configuration, our multi-task approach provides better results compared to learning each paradigm separately. On top of that, our best performing model achieves a high result for valence compared to the previous multi-task experiments.",[''],"['UniversitySaclayFrance', 'UniversitySaclayFrance', 'UniversityParisFrance']"
"We prove that the anisotropy of quadratic forms over any global field of characteristic not equal to 2222 is diophantine, by using a generalization of the method of Koenigsmann, and some known results in diophantine sets and quadratic forms.",[''],[]
"This paper presents a new technique to study the adsorption and desorption of ions and electrons on insulating surfaces in the presence of strong electric fields in cryoliquids. The experimental design consists of a compact cryostat coupled with a sensitive electro-optical Kerr device to monitor the stability of the electric fields. The behavior of nitrogen and helium ions on a poly(methyl methacrylate) (PMMA) surface was compared to a PMMA surface coated with a mixture of deuterated polystyrene and deuterated polybutadiene. Ion accumulation and removal on these surfaces were unambiguously observed. Within the precision of the data, both surfaces behave similarly for the physisorbed ions. The setup was also used to measure the (quasi-)static dielectric constant of PMMA at T = 70 K. The impact of the ion adsorption on the search for a neutron permanent electric dipole moment in a cryogenic environment, like the nEDM@SNS experiment, is discussed.",[''],"['USA', 'USA', '02139-4307', 'USA', 'USA', 'USA', 'Germany', 'Germany', 'USA', 'USA', 'USA', 'USA', 'USA', 'Canada', '[', 'USA', 'USA', 'USA']"
"In this paper we study short-time behavior of the at-the-money implied volatility for Inverse and Quanto Inverse European options with fixed strike price.
The asset price is assumed to follow a general stochastic volatility process. Using techniques of the Malliavin calculus such as the anticipating Itô’s formula we first compute the level of the implied volatility of the option when the maturity converges to zero. Then, we find a short maturity asymptotic formula for the skew of the implied volatility that depends on the roughness of the volatility model. We apply our general results to the SABR and fractional Bergomi models, and provide some numerical simulations that confirm the accurateness of the asymptotic formula for the skew.",[''],[]
,[''],[]
"For an ideal I𝐼Iitalic_I in a Noetherian ring R𝑅Ritalic_R, the Fitting ideals Fittj⁡(I)subscriptFitt𝑗𝐼\operatorname{Fitt}_{j}(I)roman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) are studied. We discuss the question of when Fittj⁡(I)=IsubscriptFitt𝑗𝐼𝐼\operatorname{Fitt}_{j}(I)=Iroman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) = italic_I or Fittj⁡(I)=IsubscriptFitt𝑗𝐼𝐼\sqrt{\operatorname{Fitt}_{j}(I)}=\sqrt{I}square-root start_ARG roman_Fitt start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_I ) end_ARG = square-root start_ARG italic_I end_ARG for some j𝑗jitalic_j. A classical case is the Hilbert-Burch theorem when j=1𝑗1j=1italic_j = 1 and I𝐼Iitalic_I is a perfect ideal of grade 2222 in a local ring.","['Key words and phrases:', 'Fitting ideal,', 'Hilbert-Burch', 'Theorem, canonical module']",[]
"We present a general convex relaxation approach to study a wide class of Unbalanced Optimal Transport problems for finite non-negative measures with possibly different masses. These are obtained as the lower semicontinuous and convex envelope of a cost for non-negative Dirac masses.
New general primal-dual formulations, optimality conditions, and metric-topological properties are carefully studied and discussed.","['Key words and phrases:', 'Unbalanced', 'Optimal', 'Transport,', 'Kantorovich-Monge problem,', 'Optimality conditions']",[]
"Fix a positive integer n𝑛nitalic_n, a real number p∈(0,1]𝑝01p\in(0,1]italic_p ∈ ( 0 , 1 ], and a (perhaps random)
hypergraph ℋℋ\mathcal{H}caligraphic_H on [n]delimited-[]𝑛[n][ italic_n ].
We introduce and investigate the following
random multigraph model, which we denote 𝔾⁢(n,p;ℋ)𝔾𝑛𝑝ℋ\mathbb{G}(n,p\,;\,\mathcal{H})blackboard_G ( italic_n , italic_p ; caligraphic_H ):
begin with an empty graph on n𝑛nitalic_n vertices, which are labelled by the set [n]delimited-[]𝑛[n][ italic_n ].
For every H∈ℋ𝐻ℋH\in\mathcal{H}italic_H ∈ caligraphic_H choose, independently from previous choices, a doubleton from H𝐻Hitalic_H, say D={i,j}⊂H𝐷𝑖𝑗𝐻D=\{i,j\}\subset Hitalic_D = { italic_i , italic_j } ⊂ italic_H, uniformly at random and then introduce an edge
between the vertices i𝑖iitalic_i and j𝑗jitalic_j in the graph
with probability p𝑝pitalic_p, where each edge is introduced independently of all other edges.",[''],[]
,[''],[]
"Context:The recent parameterisation by the GSP-Spec module of Gaia/Radial Velocity Spectrometer stellar spectra has produced an homogeneous catalogue of about 174,000 Asymptotic Giant Branch (AGB) stars. Among the 13 chemical elements presented in this Gaia third data release, the abundance of two of them (cerium and neodynium) have been estimated in most of these AGB. These two species are formed by slow neutron captures (s𝑠sitalic_s-process) in the interior of low- and intermediate-mass stars. They belong to the family of second peak s𝑠sitalic_s-process elements.
Aims:We study the content and production rate of Ce and Nd in AGB stars, using the atmospheric parameters and chemical abundances derived by the GSP-Spec module.
Methods:We define a working sample of 19,544 AGB stars having high-quality Ce and/or Nd abundances, selected by applying a specific combination of the GSP-Spec quality flags. We compare these abundances with the yield production predicted by AGB evolutionary models.
Results:We first confirmed that the majority of the working sample is composed of AGB stars by estimating their absolute magnitude in the K𝐾Kitalic_K-band and their properties in a Gaia-2MASS diagram. We also checked that these stars are oxygen-rich AGBs, as assumed during the GSP-Spec parameterisation. A good correlation between the Ce and Nd abundances is found, confirming the high quality of the derived abundances and that these species indeed belong to the same s𝑠sitalic_s-process family. We also found higher Ce and Nd abundances for more evolved AGB stars of similar metallicity, illustrating the successive mixing episodes enriching the AGB surface in s𝑠sitalic_s-process elements formed deeper in their stellar interior. We then compared the observed Ce and Nd abundances with FRUITY and Monash AGB yields and found that the higher Ce and Nd abundances can not be explained by AGBs of mass higher than 5 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT. On the contrary, the yields predicted by both models for AGB with an initial mass between ∼similar-to\sim∼1.5 and ∼similar-to\sim∼2.5 M⊙direct-product{}_{\odot}start_FLOATSUBSCRIPT ⊙ end_FLOATSUBSCRIPT and metallicities between ∼similar-to\sim∼-0.5 and ∼similar-to\sim∼0.0 dex are fully compatible with the observed GSP-Spec  abundances.
Conclusions:This work, based on the largest catalogue of high-quality second-peak s𝑠sitalic_s-elements abundances in oxygen-rich AGB, allows to constrain evolutionary models and confirms the fundamental role played by low- and intermediate-mass stars in the enrichment of the Universe in these chemical species.","['Key', 'Words.: ', 'Galaxy: abundances, disc, halo,', 'Stars: abundances, evolution,', 'AGB and post-AGB']",[]
"RGB, infrared, multispectral, and other modal data fundamentally represent different observational approaches to the same geographic object. Therefore, leveraging multimodal data is an inherent requirement for comprehending geographic objects. However, for a long time, due to the high heterogeneity in structure and semantics among various spatiotemporal modal data, the joint interpretation of multimodal spatiotemporal data has been an extremely challenging problem. The primary challenge resides in striking a trade-off between the cohesion and autonomy of diverse modalities, and this trade-off exhibits a progressively nonlinear nature as the number of modalities expands. Inspired by the human cognitive system and linguistic philosophy, where perceptual signals from the five senses converge into language, we introduce the Language as Reference Framework (LaRF), a fundamental principle for constructing a multimodal unified model, aiming to strike a trade-off between the cohesion and autonomy among different modalities. Building upon this, we propose a multimodal spatiotemporal general artificial intelligence model, called AllSpark. Our model integrates thirteen different modalities into a unified framework, including one-dimensional (text, code), two-dimensional (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs, trajectory, oblique photography), and three-dimensional (point clouds, videos) modalities. To achieve modal cohesion, AllSpark uniformly maps diverse modal features to the language modality. In addition, we design modality-specific prompts to guide multi-modal large language models in accurately perceiving multimodal data. To maintain modality autonomy, AllSpark introduces modality-specific encoders to extract the tokens of various spatiotemporal modalities. And modal bridge is employed to achieve dimensional projection from each modality to the language modality. Finally, observing a gap between the model’s interpretation and downstream tasks, we designed task heads to enhance the model’s generalization capability on specific downstream tasks. Experiments indicate that AllSpark, without expert knowledge of the most spatiotemporal modalities and utilizing a unified structure, achieves competitive accuracy in modalities such as RGB and trajectory compared to state-of-the-art models. Moreover, AllSpark showcases excellent adaptability in modalities like MSI, HSI, PointCloud, Table, Code, and Graph. AllSpark demonstrates the potential and possibility of constructing general artificial intelligence with a large language model. This approach contributes to the shift in research paradigm in spatiotemporal intelligence, transitioning from a modality-specific and task-specific paradigm to a general paradigm.",[''],[]
"We study chance constrained optimization problems minx⁡f⁢(x)subscript𝑥𝑓𝑥\min_{x}f(x)roman_min start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x ) s.t. P⁢({θ:g⁢(x,θ)≤0})≥1−ϵ𝑃conditional-set𝜃𝑔𝑥𝜃01italic-ϵP(\mathopen{}\mathclose{{}\left\{\theta:g(x,\theta)\leq 0}\right\})\geq 1-\epsilonitalic_P ( { italic_θ : italic_g ( italic_x , italic_θ ) ≤ 0 } ) ≥ 1 - italic_ϵ where ϵ∈(0,1)italic-ϵ01\epsilon\in(0,1)italic_ϵ ∈ ( 0 , 1 ) is the violation probability, when the distribution P𝑃Pitalic_P is not known to the decision maker (DM). When the DM has access to a set of distributions 𝒰𝒰\mathcal{U}caligraphic_U such that P𝑃Pitalic_P is contained in 𝒰𝒰\mathcal{U}caligraphic_U, then the problem is known as the ambiguous chance-constrained problem [1]. We study ambiguous chance-constrained problem for the case when 𝒰𝒰\mathcal{U}caligraphic_U is of the form {μ:μ⁢(y)ν⁢(y)≤C,∀y∈Θ,μ⁢(y)≥0}conditional-set𝜇formulae-sequence𝜇𝑦𝜈𝑦𝐶formulae-sequencefor-all𝑦Θ𝜇𝑦0\mathopen{}\mathclose{{}\left\{\mu:\frac{\mu(y)}{\nu(y)}\leq C,\forall y\in%
\Theta,\mu(y)\geq 0}\right\}{ italic_μ : divide start_ARG italic_μ ( italic_y ) end_ARG start_ARG italic_ν ( italic_y ) end_ARG ≤ italic_C , ∀ italic_y ∈ roman_Θ , italic_μ ( italic_y ) ≥ 0 }, where ν𝜈\nuitalic_ν is a “reference distribution.” We show that in this case the original problem can be “well-approximated” by a sampled problem in which N𝑁Nitalic_N i.i.d. samples of θ𝜃\thetaitalic_θ are drawn from ν𝜈\nuitalic_ν, and the original constraint is replaced with g⁢(x,θi)≤0,i=1,2,…,Nformulae-sequence𝑔𝑥subscript𝜃𝑖0𝑖12…𝑁g(x,\theta_{i})\leq 0,~{}i=1,2,\ldots,Nitalic_g ( italic_x , italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ≤ 0 , italic_i = 1 , 2 , … , italic_N. We also derive the sample complexity associated with this approximation, i.e., for ϵ,δ>0italic-ϵ𝛿0\epsilon,\delta>0italic_ϵ , italic_δ > 0 the number of samples which must be drawn from ν𝜈\nuitalic_ν so that with a probability greater than 1−δ1𝛿1-\delta1 - italic_δ (over the randomness of ν𝜈\nuitalic_ν), the solution obtained by solving the sampled program yields an ϵitalic-ϵ\epsilonitalic_ϵ-feasible solution for the original chance constrained problem.","['Index', 'Terms: ', 'Robust optimization,', 'Chance constrained problems,', 'Ambiguous chance constrained problems,', 'Randomized algorithms,', 'VC theory,', 'Scenario approach.']",[]
"For a positive integer m𝑚mitalic_m and a finite non-negative Borel measure μ𝜇\muitalic_μ on the unit circle, we study the Hadamard multipliers of higher order weighted Dirichlet-type spaces ℋμ,msubscriptℋ𝜇𝑚\mathcal{H}_{\mu,m}caligraphic_H start_POSTSUBSCRIPT italic_μ , italic_m end_POSTSUBSCRIPT. We show that if α>12,𝛼12\alpha>\frac{1}{2},italic_α > divide start_ARG 1 end_ARG start_ARG 2 end_ARG , then for any f𝑓fitalic_f in ℋμ,m,subscriptℋ𝜇𝑚\mathcal{H}_{\mu,m},caligraphic_H start_POSTSUBSCRIPT italic_μ , italic_m end_POSTSUBSCRIPT , the sequence of generalized Cesàro sums {σnα⁢[f]}superscriptsubscript𝜎𝑛𝛼delimited-[]𝑓\{\sigma_{n}^{\alpha}[f]\}{ italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT [ italic_f ] } converges to f𝑓fitalic_f. We further show that if α=12𝛼12\alpha=\frac{1}{2}italic_α = divide start_ARG 1 end_ARG start_ARG 2 end_ARG then for the Dirac delta measure supported at any point on the unit circle, the previous statement breaks down for every positive integer m𝑚mitalic_m.","['Key words and phrases:', 'Weighted', 'Dirichlet-type integrals,', 'Cesàro mean,', 'Hadamard multiplication']",[]
,[''],[]
"The poset of copies of relational structure 𝕏𝕏{\mathbb{X}}blackboard_X is the partial order ⟨ℙ⁢(𝕏),⊂⟩ℙ𝕏\langle{\mathbb{P}}({\mathbb{X}}),\subset\rangle⟨ blackboard_P ( blackboard_X ) , ⊂ ⟩,
where ℙ⁢(𝕏):={f⁢[X]:f∈Emb(𝕏)}assignℙ𝕏conditional-set𝑓delimited-[]𝑋𝑓Emb𝕏{\mathbb{P}}({\mathbb{X}}):=\{f[X]:f\in\mathop{\rm Emb}\nolimits({\mathbb{X}})\}blackboard_P ( blackboard_X ) := { italic_f [ italic_X ] : italic_f ∈ roman_Emb ( blackboard_X ) }.
We consider the classifications of structures related to the similarities of their posets of copies, in particular, related to isomorphism of their Boolean completions.
The aim of the paper is to extend the known results concerning linear orders to a much larger class of monomorphic structures.

2020 MSC:
06A05, 06A10, 03E40, 03E35. 
Keywords: linear order, poset of copies, monomorphic structure, forcing.",[''],[]
"This work presents 𝙵𝚊𝚌𝚎𝚇𝙵𝚊𝚌𝚎𝚇\mathtt{FaceX}typewriter_FaceX framework, a novel facial generalist model capable of handling diverse facial tasks simultaneously.
To achieve this goal, we initially formulate a unified facial representation for a broad spectrum of facial editing tasks, which macroscopically decomposes a face into fundamental identity, intra-personal variation, and environmental factors.
Based on this, we introduce Facial Omni-Representation Decomposing (FORD) for seamless manipulation of various facial components, microscopically decomposing the core aspects of most facial editing tasks.
Furthermore, by leveraging the prior of a pretrained StableDiffusion (SD) to enhance generation quality and accelerate training, we design Facial Omni-Representation Steering (FORS) to first assemble unified facial representations and then effectively steer the SD-aware generation process by the efficient Facial Representation Controller (FRC).
Our versatile 𝙵𝚊𝚌𝚎𝚇𝙵𝚊𝚌𝚎𝚇\mathtt{FaceX}typewriter_FaceX achieves competitive performance compared to elaborate task-specific models on popular facial editing tasks.
Full codes and models are available at https://github.com/diffusion-facex/FaceX.",[''],[]
"Reasonably large perturbations may push a power grid from its stable synchronous state into an undesirable state. Identifying vulnerabilities in power grids by studying power grid stability against such perturbations can aid in preventing future blackouts. We use two stability measures — stability bound, which deals with a system’s asymptotic behaviour, and survivability bound, which deals with a system’s transient behaviour, to provide information about the strength of perturbations that destabilize the system. Using these stability measures, we have found that certain nodes in tree-like structures have low asymptotic stability, while nodes with a high number of connections generally have low transient stability.",[''],[]
"In this work we state a result that relates the cohomology groups of a Lie algebra 𝔤𝔤\mathfrak{g}fraktur_g and a current Lie algebra 𝔤⊗𝒮tensor-product𝔤𝒮\mathfrak{g}\otimes\mathcal{S}fraktur_g ⊗ caligraphic_S, by means of a short exact sequence – similar to the universal coefficients theorem for modules –, where 𝒮𝒮\mathcal{S}caligraphic_S is a finite dimensional, commutative and associative algebra with unit over a field 𝔽𝔽\mathbb{F}blackboard_F. Although this result can be applied to any Lie algebra, as by-product we determine the cohomology group of 𝔤⊗𝒮tensor-product𝔤𝒮\mathfrak{g}\otimes\mathcal{S}fraktur_g ⊗ caligraphic_S, where 𝔤𝔤\mathfrak{g}fraktur_g is a semisimple Lie algebra.","['Key words and phrases:', 'Lie algebras cohomology;', 'Current', 'Lie algebras;', 'Tensor product;', 'Associative and commutative algebras; semisimple', 'Lie algebras.']",[]
,[''],[]
"Recently, the pulsar timing array (PTA) collaborations, including CPTA, EPTA, NANOGrav, and PPTA, announced that they detected a stochastic gravitational wave background spectrum in the nHz band. This may be relevant to the cosmological phase transition suggested by some models. Magnetic monopoles and primordial black holes (PBHs), two unsolved mysteries in the universe, may also have their production related to the cosmological phase transition.
Inspired by that, we revisit the model proposed by Stojkovic and Freese, which involves PBHs accretion to solve the cosmological magnetic monopole problem. We further develop it by considering the increase in the mass of the PBHs during accretion and taking the effect of Hawking radiation into account. With these new considerations, we find that solutions to the problem still exist within a certain parameter space. In addition, we also generalize the analysis to PBHs with an extended distribution in mass. This may be a more interesting scenario because PBHs that have accreted magnetic monopoles might produce observable electromagnetic signals if they are massive enough to survive in the late universe.",[''],"['China', 'China']"
,"['Key words and phrases:', 'Integrals,', 'Gradshteyn and', 'Ryzhik, method of brackets']",[]
"This paper introduces Sobolev spaces over Gelfand pairs in the framework of hypergroups. The Sobolev spaces in question are constructed from the Fourier transform on hypergroup Gelfand pairs. Mainly, the paper focuses on the investigation of Sobolev embedding results.",[''],[]
"In this paper, we introduce a new class of the kernels of the integral transforms of the Laplace convolution type that we call symmetrical Sonin kernels. For a symmetrical Sonin kernel given in terms of some elementary or special functions, its associated kernel has the same form with possibly different parameter values. Several known and new kernels of this type are derived by means of the Sonin method in the time domain and using the Laplace integral transform in the frequency domain. The new symmetrical Sonin kernels are provided in terms of the Wright function and some extensions of the Horn confluent hypergeometric functions in two variables.",[''],[]
"We study the 2-offer semirandom 3-uniform hypergraph model on n𝑛nitalic_n vertices.
At each step, we are presented with 2 uniformly random vertices.
We choose any other vertex, thus creating a hyperedge of size 3.
We show a strategy that constructs a perfect matching, and another that constructs a loose Hamilton cycle, both succeeding
asymptotically almost surely
within Θ⁢(n)Θ𝑛\Theta(n)roman_Θ ( italic_n ) steps.
Both results extend to s𝑠sitalic_s-uniform hypergraphs.
Much of the analysis is done on an auxiliary graph
that is a uniform k𝑘kitalic_k-out subgraph of a random bipartite graph,
and this tool may be useful in other contexts.",[''],[]
"We provide a comprehensive analysis of the acceleration of magnetic monopoles in intergalactic magnetic fields.
We demonstrate that monopoles with intermediate to low masses
can be accelerated to relativistic velocities. This can significantly affect direct and indirect searches for magnetic monopoles. As an example, we show that the Parker bound is relaxed in the presence of intergalactic fields. We also find that a cosmic population of monopoles can produce significant backreaction on the intergalactic fields.",[''],[]
"We describe QGLAB, a new MATLAB package for analyzing partial differential equations on quantum graphs. The software is built on the existing, object-oriented MATLAB directed-graph class, inheriting its structure and adding additional easy-to-use features. The package allows one to construct a quantum graph and accurately compute the spectrum of elliptic operators, solutions to Poisson problems, the linear and nonlinear time evolution of a variety of PDEs, the continuation of branches of steady states (including locating and switching branches at bifurcations) and more. It uses a unified framework to implement finite-difference and Chebyshev discretizations of differential operators on a quantum graph. For simplicity, the package overloads many built-in MATLAB functions to work on the class.",[''],[]
"Neurological conditions are a major source of movement disorders. Motion modelling and variability analysis have the potential to identify pathology but require profound data. We introduce a systematic dataset of 3D center-out task-space trajectories of human hand transport movements in a natural setting. The transport tasks of this study consist of grasping a cylindric object from a unified start position and transporting it to one of nine target locations in unconstrained operational space. The measurement procedure is automatized to record ten trials per target location. With that, the dataset consists of 90 movement trajectories for each hand of 31 participants without known movement disorders. The participants are aged between 21 and 78 years, covering a wide range. Data are recorded redundantly by both an optical tracking system and an IMU sensor. As opposed to the stationary capturing system, the IMU can be considered as a portable, low-cost and energy-efficient alternative to be implemented on embedded systems.",[''],"['Germany', 'Germany', 'Germany', 'work', 'Germany', 'Germany', 'work', 'Germany', 'Germany']"
,[''],[]
"We study a class of time-dependent backgrounds in string theory which consist of marginal deformations of minimal strings on AdS33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPT. For such backgrounds, we compute the three-point amplitudes and analyze their properties.",[''],[]
"The Photometric objects Around Cosmic webs (PAC) approach developed in Xu et al. (2022b) has the advantage of making full use of spectroscopic and deeper photometric surveys. With the merits of PAC, the excess surface density n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT of neighboring galaxies can be measured down to stellar mass 1010.80⁢M⊙superscript1010.80subscript𝑀direct-product10^{10.80}\,M_{\odot}10 start_POSTSUPERSCRIPT 10.80 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT around quasars at redshift 0.8<zs<1.00.8subscript𝑧s1.00.8<z_{\rm{s}}<1.00.8 < italic_z start_POSTSUBSCRIPT roman_s end_POSTSUBSCRIPT < 1.0, with the data from the Sloan Digital Sky Survey IV (SDSS-IV) extended Baryon Oscillation Spectroscopic Survey (eBOSS) and the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging Surveys. We find that n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT generally increases quite steeply with the decrease of the separation. Using subhalo abundance matching method, we can accurately model the n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT both on small and large scales. We show that the steep increase of the n¯2⁢wpsubscript¯𝑛2subscript𝑤p\bar{n}_{2}w_{{\rm{p}}}over¯ start_ARG italic_n end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT towards the quasars requires that a large fraction fsate=0.29−0.06+0.05subscript𝑓satesuperscriptsubscript0.290.060.05f_{\mathrm{sate}}=0.29_{-0.06}^{+0.05}italic_f start_POSTSUBSCRIPT roman_sate end_POSTSUBSCRIPT = 0.29 start_POSTSUBSCRIPT - 0.06 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + 0.05 end_POSTSUPERSCRIPT of quasars should be satellites in massive halos, and find that this fraction measurement is insensitive to the assumptions of our modeling. This high satellite fraction indicates that the subhalos have nearly the same probability to host quasars as the halos for the same (infall) halo mass, and the large scale environment has negligible effect on the quasar activity. We show that even with this high satellite fraction, each massive halo on average does not host more than one satellite quasar due to the sparsity of quasars.","['AGN host galaxies(2017) —', 'Stellar mass function(1612) —', 'Quasars(1319) —', 'Active galaxies(17)']","['China', 'China', 'UK', 'China', 'China', 'China', 'China', 'China']"
"In this study, we introduce the first-of-its-kind class of tests for detecting change points in the distribution of a sequence of independent matrix-valued random variables. The tests are constructed using the weighted square integral difference of the empirical orthogonal Hankel transforms. The test statistics have a convenient closed-form expression, making them easy to implement in practice. We present their limiting properties and demonstrate their quality through an extensive simulation study. We utilize these tests for change point detection in cryptocurrency markets to showcase their practical use. The detection of change points in this context can have various applications in constructing and analyzing novel trading systems.",[''],[]
"Let T𝑇Titalic_T be the Koopman operator of a measure preserving transformation θ𝜃\thetaitalic_θ of a probability
space (X,Σ,μ)𝑋Σ𝜇(X,\Sigma,\mu)( italic_X , roman_Σ , italic_μ ). We study the convergence properties of the averages
Mn⁢f:=1n⁢∑k=0n−1Tk⁢fassignsubscript𝑀𝑛𝑓1𝑛superscriptsubscript𝑘0𝑛1superscript𝑇𝑘𝑓M_{n}f:=\frac{1}{n}\sum_{k=0}^{n-1}T^{k}fitalic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f := divide start_ARG 1 end_ARG start_ARG italic_n end_ARG ∑ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT italic_T start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_f when f∈Lr⁢(μ)𝑓superscript𝐿𝑟𝜇f\in L^{r}(\mu)italic_f ∈ italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( italic_μ ), 0<r<10𝑟10<r<10 < italic_r < 1. We prove that if
∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0, then f∈(I−T)⁢Lr¯𝑓¯𝐼𝑇superscript𝐿𝑟f\in\overline{(I-T)L^{r}}italic_f ∈ over¯ start_ARG ( italic_I - italic_T ) italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT end_ARG, and show that the converse
fails whenever θ𝜃\thetaitalic_θ is ergodic aperiodic. When θ𝜃\thetaitalic_θ is invertible ergodic aperiodic,
we show that for 0<r<10𝑟10<r<10 < italic_r < 1 there exists fr∈(I−T)⁢Lrsubscript𝑓𝑟𝐼𝑇superscript𝐿𝑟f_{r}\in(I-T)L^{r}italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ∈ ( italic_I - italic_T ) italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT for which Mn⁢frsubscript𝑀𝑛subscript𝑓𝑟M_{n}f_{r}italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT does not converge a.e. (although ∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0). We further establish that for 1≤p<1r,1𝑝1𝑟1\leq p<\frac{1}{r},1 ≤ italic_p < divide start_ARG 1 end_ARG start_ARG italic_r end_ARG , there is a dense Gδsubscript𝐺𝛿G_{\delta}italic_G start_POSTSUBSCRIPT italic_δ end_POSTSUBSCRIPT subset
ℱ⊂Lp⁢(X,μ)ℱsuperscript𝐿𝑝𝑋𝜇{\mathcal{F}}\subset L^{p}(X,\mu)caligraphic_F ⊂ italic_L start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_X , italic_μ ) such that lim supn|Tn⁢h|nr=∞subscriptlimit-supremum𝑛superscript𝑇𝑛ℎsuperscript𝑛𝑟\limsup_{n}\frac{|T^{n}h|}{n^{r}}=\inftylim sup start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT divide start_ARG | italic_T start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_h | end_ARG start_ARG italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT end_ARG = ∞ a.e.
for any h∈ℱℎℱh\in{\mathcal{F}}italic_h ∈ caligraphic_F.
When T𝑇Titalic_T is induced by an irrational rotation of 𝕋𝕋\mathbb{T}blackboard_T, the Hardy spaces Hr⁢(𝕋)superscript𝐻𝑟𝕋H^{r}(\mathbb{T})italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T )
are T𝑇Titalic_T-invariant. For 0<r<10𝑟10<r<10 < italic_r < 1, we prove that
Hr⁢(𝕋)={c⁢o⁢n⁢s⁢t⁢a⁢n⁢t⁢s}⊕(I−T)⁢Hr⁢(𝕋)¯superscript𝐻𝑟𝕋direct-sum𝑐𝑜𝑛𝑠𝑡𝑎𝑛𝑡𝑠¯𝐼𝑇superscript𝐻𝑟𝕋H^{r}(\mathbb{T})=\{constants\}\oplus\overline{(I-T)H^{r}(\mathbb{T})}italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) = { italic_c italic_o italic_n italic_s italic_t italic_a italic_n italic_t italic_s } ⊕ over¯ start_ARG ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) end_ARG, and
∫|Mn⁢f|r⁢𝑑μ→0→superscriptsubscript𝑀𝑛𝑓𝑟differential-d𝜇0\int|M_{n}f|^{r}d\mu\to 0∫ | italic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f | start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_d italic_μ → 0 for f∈(I−T)⁢Hr⁢(𝕋)¯𝑓¯𝐼𝑇superscript𝐻𝑟𝕋f\in\overline{(I-T)H^{r}(\mathbb{T})}italic_f ∈ over¯ start_ARG ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) end_ARG. However, there exists
f∈(I−T)⁢Hr⁢(𝕋)𝑓𝐼𝑇superscript𝐻𝑟𝕋f\in(I-T)H^{r}(\mathbb{T})italic_f ∈ ( italic_I - italic_T ) italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T ) such that Mn⁢fsubscript𝑀𝑛𝑓M_{n}fitalic_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_f does not converge a.e.","['Key words and phrases: ergodic theorem, measure preserving transformations, non-integrable functions,', 'Lr\u2062(μ)superscript𝐿𝑟𝜇L^{r}(\\mu)italic_L start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( italic_μ ) with 0<r<10𝑟10<r<10 < italic_r < 1, circle rotations,', 'Hardy spaces', 'Hr\u2062(𝕋)superscript𝐻𝑟𝕋H^{r}(\\mathbb{T})italic_H start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ( blackboard_T )']",[]
"Introduction Modelling of relative treatment effects is an important aspect to consider when extrapolating the long-term survival outcomes of treatments. Flexible parametric models offer the ability to accurately model the observed data, however, the extrapolated relative treatment effects and subsequent survival function may lack face validity. Methods We investigate the ability of change-point survival models to estimate changes in the relative treatment effects, specifically treatment delay, loss of treatment effects and converging hazards. These models are implemented using standard Bayesian statistical software and propagate the uncertainty associate with all model parameters including the change-point location. A simulation study was conducted to assess the predictive performance of these models compared with other parametric survival models. Change-point survival models were applied to three datasets, two of which were used in previous health technology assessments. Results Change-point survival models typically provided improved extrapolated survival predictions, particularly when the changes in relative treatment effects are large. When applied to the real world examples they provided good fit to the observed data while and in some situations produced more clinically plausible extrapolations than those generated by flexible spline models. Change-point models also provided support to a previously implemented modelling approach which was justified by visual inspection only and not goodness of fit to the observed data. Conclusions We believe change-point survival models offer the ability to flexibly model observed data while also modelling and investigating clinically plausible scenarios with respect to the relative treatment effects.",[''],[]
"Decision making in modern stochastic systems, including e-commerce platforms, financial markets, and healthcare systems, has evolved into a multifaceted process that involves information acquisition and adaptive information sources. This paper initiates a study on this integrated process, where these elements are not only fundamental but also interact in a complex and dynamically intertwined manner.
We introduce a relatively simple model, which, however, captures the novel elements we consider. Specifically, a decision maker (DM) can choose between an established product A𝐴Aitalic_A with a known value and a new product B𝐵Bitalic_B with an unknown value. The DM can observe signals about the unknown value of product B𝐵Bitalic_B and can also opt to exchange it for product A𝐴Aitalic_A if B𝐵Bitalic_B is initially chosen. Mathematically, the model gives rise to a sequential optimal stopping problem with two different informational regimes (before and after buying product B𝐵Bitalic_B), differentiated by the initial, coarser signal and the subsequent, finer one. We analyze the underlying problems using predominantly viscosity solution techniques, differing from the existing literature on information acquisition which is based on traditional optimal stopping techniques. Additionally, our modeling approach offers a novel framework for developing more complex interactions among decisions, information sources, and information costs through a sequence of nested obstacles.",[''],[]
"In this paper we study a natural generalization of symplectic toric manifolds in the context of regular Poisson manifolds of compact types. To be more precise, we consider a class of multiplicity-free Hamiltonian actions by regular proper symplectic groupoids that we call faithful. Given such a groupoid, we classify its faithful multiplicity-free Hamiltonian actions in terms of what we call Delzant subspaces of its orbit space –
certain ‘suborbifolds with corners’ satisfying the Delzant condition relative to the integral affine orbifold structure of the orbit space. This encompasses both the classification of symplectic toric manifolds (due to Delzant) in terms of Delzant polytopes
and the classification of proper Lagrangian fibrations over an integral affine base manifold (due to Duistermaat) in terms of a sheaf cohomology group. Each Delzant subspace comes with an orbifold version of this cohomology, the degree one part of which classifies faithful multiplicity-free Hamiltonian actions with momentum map image equal to the Delzant subspace, provided there exists such an action. The obstruction to existence is encoded by a degree two class in this cohomology: the Lagrangian Dixmier-Douady class. In addition to the above, we introduce another invariant, which leads to a variation of our classification result involving only classical sheaf cohomology and the group cohomology of certain modules for the isotropy groups of the groupoid.",[''],[]
,[''],[]
"In this paper we investigate the problem of the distributivity of Kurepa trees. We show that it is consistent that there are Kurepa trees and for every Kurepa tree there is a small forcing notion which adds a branch to it without collapsing cardinals. On the other hand, we derive a proper forcing notion for making an arbitrary Kurepa tree into a non-distributive tree without collapsing ℵ1subscriptℵ1\aleph_{1}roman_ℵ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and ℵ2subscriptℵ2\aleph_{2}roman_ℵ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT.",[''],[]
,[''],[]
"In this paper, we consider exact WKB analysis to a 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T symmetric quantum mechanics defined by the potential, V⁢(x)=ω2⁢x2+g⁢x2⁢(i⁢x)ε=2𝑉𝑥superscript𝜔2superscript𝑥2𝑔superscript𝑥2superscript𝑖𝑥𝜀2V(x)=\omega^{2}x^{2}+gx^{2}(ix)^{\varepsilon=2}italic_V ( italic_x ) = italic_ω start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_g italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_i italic_x ) start_POSTSUPERSCRIPT italic_ε = 2 end_POSTSUPERSCRIPT with ω∈ℝ≥0𝜔subscriptℝabsent0\omega\in{\mathbb{R}}_{\geq 0}italic_ω ∈ blackboard_R start_POSTSUBSCRIPT ≥ 0 end_POSTSUBSCRIPT, g∈ℝ>0𝑔subscriptℝabsent0g\in{\mathbb{R}}_{>0}italic_g ∈ blackboard_R start_POSTSUBSCRIPT > 0 end_POSTSUBSCRIPT.
We in particular aim to verify a conjecture proposed by Ai-Bender-Sarkar (ABS),
that pertains to a relation between D𝐷Ditalic_D-dimensional 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T-symmetric theories and analytic continuation (AC) of Hermitian theories concerning the energy spectrum or Euclidean partition function.
For the purpose, we construct energy quantization conditions by exact WKB analysis and write down their transseries solution by solving the conditions.
By performing alien calculus to the energy solutions, we verify validity of the ABS conjecture and seek a possibility of its alternative form by Borel resummation theory if it is violated.
Our results claim that the validity of the ABS conjecture drastically changes depending on whether ω>0𝜔0\omega>0italic_ω > 0 or ω=0𝜔0\omega=0italic_ω = 0: If ω>0𝜔0{\omega}>0italic_ω > 0, then the ABS conjecture is violated when exceeding the semi-classical level, but its alternative form is constructable by Borel resummation theory.
The 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T and the AC energies are related to each other by a one-parameter Stokes automorphism, and a median resummed form, which corresponds to a formal exact solution, of the AC energy (resp. 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T energy) is directly obtained by acting Borel resummation to a transseries solution of the 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T energy (resp. AC energy).
If ω=0𝜔0\omega=0italic_ω = 0, then, with respect to the inverse energy level-expansion, not only perturbative/non-perturbative structures of the 𝒫⁢𝒯𝒫𝒯{\cal PT}caligraphic_P caligraphic_T and the AC energies but also their perturbative parts do not match with each other.
These energies are independent solutions, and no alternative form of the ABS conjecture can be reformulated by Borel resummation theory.",[''],[]
"We propose a semi-supervised text classifier based on self-training using one positive and one negative property of neural networks. One of the weaknesses of self-training is the semantic drift problem, where noisy pseudo-labels accumulate over iterations and consequently the error rate soars. In order to tackle this challenge, we reshape the role of pseudo-labels and create a hierarchical order of information. In addition, a crucial step in self-training is to use the classifier confidence prediction to select the best candidate pseudo-labels. This step cannot be efficiently done by neural networks, because it is known that their output is poorly calibrated. To overcome this challenge, we propose a hybrid metric to replace the plain confidence measurement. Our metric takes into account the prediction uncertainty via a subsampling technique. We evaluate our model in a set of five standard benchmarks, and show that it significantly outperforms a set of ten diverse baseline models. Furthermore, we show that the improvement achieved by our model is additive to language model pretraining, which is a widely used technique for using unlabeled documents. Our code is available at https://github.com/p-karisani/RST.",[''],"['Urbana-Champaign', 'University']"
"A wide range of implicit time integration methods, including multi-step, implicit
Runge-Kutta, and Galerkin finite-time element schemes, is evaluated in the context
of chaotic dynamical systems. The schemes are applied to solve the Lorenz equations,
the equation of motion of a Duffing oscillator, and the Kuramoto-Sivashinsky system,
with the goal of finding the most computationally efficient method that
results in the least expensive model for a chosen level of accuracy. It is found
that the quasi-period of a chaotic system strongly limits the
time-step size that can be used in the simulations, and all schemes fail
once the time-step size reaches a significant fraction of that period. In these conditions,
the computational cost per time-step becomes one of the most important factors
determining the efficiency of the schemes. The cheaper, second-order schemes
are shown to have an advantage over the higher-order schemes at large time-step sizes, with one
possible exception being the fourth-order continuous Galerkin scheme. The higher-order schemes become more efficient than the lower-order schemes as accuracy requirements tighten. If going
beyond the second-order is necessary for reasons other than computational
efficiency, the fourth-order methods are shown to perform better than the third-order
ones at all time-step sizes.",[''],[]
"Bayesian inference provides a rigorous framework to encapsulate our knowledge and uncertainty
regarding various physical quantities in a well-defined and self-contained manner. Utilising modern
tools, such Bayesian models can be constructed with a remarkable flexibility, leaving us totally free
to carefully choose which assumption should be strictly enforced and which should on the contrary
be relaxed. The practical evaluation of these assumptions, together with the data-driven selection
or averaging of models, also appears in a very natural way.
In this presentation, I discuss its application in the context of lattice QCD and its common
statistical problems. As a concrete illustration, I present a few parametric and non-parametric
hierarchical models applied to actual correlator data, from single exponential fits to spectral functions.",[''],[]
"We study the completion of approximately low rank matrices with entries missing not at random (MNAR). In the context of typical large-dimensional statistical settings, we establish a framework for the performance analysis of the nuclear norm minimization (ℓ1*superscriptsubscriptℓ1\ell_{1}^{*}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT) algorithm. Our framework produces exact estimates of the worst-case residual root mean squared error (RMSE) and the associated phase transitions (PT), with both exhibiting remarkably simple characterizations. Our results enable to precisely quantify the impact of key system parameters, including data heterogeneity, size of the missing block, and deviation from ideal low rankness, on the accuracy of ℓ1*superscriptsubscriptℓ1\ell_{1}^{*}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT-based matrix completion. To validate our theoretical worst-case RMSE estimates, we conduct numerical simulations, demonstrating close agreement with their numerical counterparts.","['62B10, 94A16, 62D10,', 'Matrix', 'Completion,', 'Approximately low rank,', 'Phase transitions,', 'Nuclear norm,']",[]
"Large Language Models (LLMs), particularly those similar to ChatGPT, have significantly influenced the field of Natural Language Processing (NLP). While these models excel in general language tasks, their performance in domain-specific downstream tasks such as biomedical and clinical Named Entity Recognition (NER), Relation Extraction (RE), and Medical Natural Language Inference (NLI) is still evolving. In this context, our study investigates the potential of instruction tuning for biomedical language processing, applying this technique to two general LLMs of substantial scale. We present a comprehensive, instruction-based model trained on a dataset that consists of approximately 200,000200000200,000200 , 000 instruction-focused samples. This dataset represents a carefully curated compilation of existing data, meticulously adapted and reformatted to align with the specific requirements of our instruction-based tasks. This initiative represents an important step in utilising such models to achieve results on par with specialised encoder-only models like BioBERT and BioClinicalBERT for various classical biomedical NLP tasks. Our work includes an analysis of the dataset’s composition and its impact on model performance, providing insights into the intricacies of instruction tuning. By sharing our codes, models, and the distinctively assembled instruction-based dataset, we seek to encourage ongoing research and development in this area.",[''],[]
,[''],[]
,[''],[]
"Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut purus elit,
vestibulum ut, placerat ac, adipiscing vitae, felis. Curabitur dictum
gravida mauris. Nam arcu libero, nonummy eget, consectetuer id,
vulputate a, magna. Donec vehicula augue eu neque. Pellentesque habitant
morbi tristique senectus et netus et malesuada fames ac turpis egestas.
Mauris ut leo. Cras viverra metus rhoncus sem. Nulla et lectus
vestibulum urna fringilla ultrices. Phasellus eu tellus sit amet tortor
gravida placerat. Integer sapien est, iaculis in, pretium quis, viverra
ac, nunc. Praesent eget sem vel leo ultrices bibendum. Aenean faucibus.
Morbi dolor nulla, malesuada eu, pulvinar at, mollis ac, nulla.
Curabitur auctor semper nulla. Donec varius orci eget risus. Duis nibh
mi, congue eu, accumsan eleifend, sagittis quis, diam. Duis eget orci
sit amet orci dignissim rutrum.",[''],[]
"In the arena of privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) has outstripped the objective perturbation mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD requires a non-trivial privacy overhead (for privately tuning the model’s hyperparameters) and a computational complexity which might be extravagant for simple models such as linear and logistic regression. This paper revamps the objective perturbation mechanism with tighter privacy analyses and new computational tools that boost it to perform competitively with DP-SGD on unconstrained convex generalized linear problems.",[''],[]
"For a semibounded sesquilinear form 𝔱𝔱{\mathfrak{t}}fraktur_t in a Hilbert space ℌℌ{\mathfrak{H}}fraktur_H
there exists a representing map Q𝑄Qitalic_Q from ℌℌ{\mathfrak{H}}fraktur_H to another Hilbert space 𝔎𝔎{\mathfrak{K}}fraktur_K,
such that 𝔱⁢[φ,ψ]−c⁢(φ,ψ)=(Q⁢φ,Q⁢ψ)𝔱𝜑𝜓𝑐𝜑𝜓𝑄𝜑𝑄𝜓{\mathfrak{t}}[\varphi,\psi]-c(\varphi,\psi)\!=\!(Q\varphi,Q\psi)fraktur_t [ italic_φ , italic_ψ ] - italic_c ( italic_φ , italic_ψ ) = ( italic_Q italic_φ , italic_Q italic_ψ ),
φ,ψ∈dom⁢𝔱𝜑𝜓dom𝔱\varphi,\psi\in{\rm dom\,}{\mathfrak{t}}italic_φ , italic_ψ ∈ roman_dom fraktur_t, with c∈ℝ𝑐ℝc\in{\mathbb{R}}italic_c ∈ blackboard_R a lower bound of 𝔱𝔱{\mathfrak{t}}fraktur_t.
Representing maps offer a simplifying tool to study general semibounded forms.
By means of representing maps closedness, closability, and singularity of 𝔱𝔱{\mathfrak{t}}fraktur_t
are immediately translated into the corresponding properties of the operator Q𝑄Qitalic_Q, and vice versa.
Also properties of sum decompositions 𝔱=𝔱1+𝔱2𝔱subscript𝔱1subscript𝔱2{\mathfrak{t}}={\mathfrak{t}}_{1}+{\mathfrak{t}}_{2}fraktur_t = fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of
a nonnegative form 𝔱𝔱{\mathfrak{t}}fraktur_t with two other nonnegative forms 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in ℌℌ{\mathfrak{H}}fraktur_H
can be analyzed by means of associated nonnegative contractions K∈𝐁⁢(𝔎)𝐾𝐁𝔎K\in{\mathbf{B}}({\mathfrak{K}})italic_K ∈ bold_B ( fraktur_K ).
This helps, for instance, to establish an explicit operator theoretic characterization
for the summands 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to be, or not to be, mutually singular.
Such sum decompositions are used to study characteristic properties of the so-called Lebesgue type
decompositions of semibounded forms 𝔱𝔱{\mathfrak{t}}fraktur_t, where 𝔱1subscript𝔱1{\mathfrak{t}}_{1}fraktur_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is closable and 𝔱2subscript𝔱2{\mathfrak{t}}_{2}fraktur_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT singular;
in particular, this includes the Lebesgue decomposition of a semibounded form due to B. Simon.
Furthermore, for a semibounded form 𝔱𝔱{\mathfrak{t}}fraktur_t with its representing map Q𝑄Qitalic_Q
it will be shown that the corresponding semibounded selfadjoint relation Q*⁢Q**+csuperscript𝑄superscript𝑄absent𝑐Q^{*}Q^{**}+citalic_Q start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT * * end_POSTSUPERSCRIPT + italic_c
is uniquely determined by a limit version of the classical representation theorem for the form 𝔱𝔱{\mathfrak{t}}fraktur_t,
being studied by W. Arendt and T. ter Elst in a sectorial context.
Via representing maps a full treatment is given of the convergence of monotone
sequences of semibounded forms.","['Key words and phrases:', 'Semibounded form, closability, singularity,', 'Lebesgue type decompositions of forms,\nrepresenting map, representation theorem']",[]
"We provide a step towards classifying Riemannian four-manifolds in which the curvature tensor has zero
divergence, or – equivalently – the Ricci tensor Ric satisfies the
Codazzi equation. Every known compact manifold of this type belongs to one
of five otherwise-familiar classes of examples. The main result
consists in showing that, if such a manifold (not necessarily compact or even
complete) lies outside of the five classes – a non-vacuous assumption –
then, at all points of a dense open subset, Ric has four distinct eigenvalues,
while suitable local coordinates simultaneously diagonalize Ric, the metric
and, in a natural sense, also the curvature tensor. Furthermore,
in a local orthonormal frame formed by Ricci eigenvectors, the connection form
(or, curvature tensor) has just twelve (or, respectively, six)
possibly-nonzero components, which together satisfy a specific system, not
depending on the point, of homogeneous polynomial equations. A part of the
classification problem is thus reduced to a question in real algebraic
geometry.","['Key words and phrases: harmonic curvature,', 'Codazzi tensor']",[]
"Non-relativistic quantum mechanical scattering from an inverse square
potential in two spatial dimensions leads to a novel representation
of the Bernoulli numbers.",[''],[]
,[''],[]
"High-demand LLM inference services (e.g., ChatGPT and BARD) support a wide range of requests from short chat conversations to long document reading.
To ensure that all client requests are processed fairly, most major LLM inference services have request rate limits, to ensure that no client can dominate the request queue.
However, this rudimentary notion of fairness also results in under-utilization of the resources and poor client experience when there is spare capacity.
While there is a rich literature on fair scheduling, serving LLMs presents new challenges due to their unpredictable request lengths and their unique batching characteristics on parallel accelerators.
This paper introduces the definition of LLM serving fairness based on a cost function that accounts for the number of input and output tokens processed.
To achieve fairness in serving, we propose a novel scheduling algorithm, the Virtual Token Counter (VTC), a fair scheduler based on the continuous batching mechanism.
We prove a 2×2\times2 × tight upper bound on the service difference between two backlogged clients, adhering to the requirement of work-conserving.
Through extensive experiments, we demonstrate the superior performance of VTC in ensuring fairness, especially in contrast to other baseline methods, which exhibit shortcomings under various conditions.",[''],[]
"Composite Higgs models are a class of models proposed to address the hierarchy and naturalness problems associated with the Standard Model fundamental scalar Higgs. S⁢U⁢(2)𝑆𝑈2SU(2)italic_S italic_U ( 2 ) with two fundamental flavours is a minimal model for the composite Higgs sector which is not yet ruled out by experimental data. We present lattice results for S⁢U⁢(2)𝑆𝑈2SU(2)italic_S italic_U ( 2 ) with two fundamental mass degenerate flavours. For the fermion action we use the new exponential clover Wilson fermion action, which offers O⁢(a)𝑂𝑎O(a)italic_O ( italic_a ) improvement. We discuss tuning the cSWsubscript𝑐SWc_{\mathrm{SW}}italic_c start_POSTSUBSCRIPT roman_SW end_POSTSUBSCRIPT parameter through Schrödinger functional simulations, the scale setting of the ensembles using the Wilson gauge flow, and the low energy spectroscopy of the theory including the masses of the pseudoscalar isotriplet Goldstone bosons and the vector isotriplet.",[''],[]
,[''],[]
"A low-energy enhancement (LEE) has been observed in the deexcitation γ𝛾\gammaitalic_γ-ray strength function (γ𝛾\gammaitalic_γSF) of compound nuclei. The LEE has been a subject of intense experimental and theoretical interest since its discovery, and, if the LEE persists in heavy neutron-rich nuclei, it would have significant effects on calculations of r-process nucleosynthesis. Standard configuration-interaction (CI) shell-model calculations in medium-mass nuclei have attributed the LEE to the magnetic dipole γ𝛾\gammaitalic_γSF but such calculations are computationally intractable in heavy nuclei. We review a combination of beyond-mean-field many-body methods within the framework of the CI shell model that enables the calculation of γ𝛾\gammaitalic_γSF in heavy nuclei, and discuss the recent theoretical identification of a LEE in the magnetic dipole γ𝛾\gammaitalic_γSF of lanthanide isotopes.",[''],[]
"Within the ViSE (Voting in Stochastic Environment) model, we study the effectiveness of majority voting in various environments.
By the pit of losses paradox, majority decisions in apparently hostile environments systematically reduce the capital of society.
In such cases, the basic action of “rejecting all proposals without voting” outperforms simple majority. We reveal another pit of losses appearing in favorable environments. Here, the simple action of “accepting all proposals without voting” is superior to simple majority, which thus causes a loss compared to total acceptance. We show that the second pit of losses is a mirror image of the pit of losses in hostile environments and explain this phenomenon.
Technically, we consider a voting society consisting of individual agents whose strategy is supporting all proposals that increase their capital and a group whose members vote for the increase of the total group capital. According to the main result, the expected capital gain of each agent in the environment whose proposal generator ξ𝜉\xiitalic_ξ has mean μ>0𝜇0\mu>0italic_μ > 0 exceeds by μ𝜇\muitalic_μ their expected capital gain with generator −ξ𝜉-\xi- italic_ξ. This result extends to the shift-based families of generators with symmetric distributions. The difference by μ𝜇\muitalic_μ causes symmetry relative to the basic action that rejects/accepts all proposals in unfavorable/favorable environments.",[''],"['[', '[', '[']"
"Simplicity bias is an intriguing phenomenon prevalent in various input-output maps, characterized by a preference for simpler, more regular, or symmetric outputs. Notably, these maps typically feature high-probability outputs with simple patterns, whereas complex patterns are exponentially less probable. This bias has been extensively examined and attributed to principles derived from algorithmic information theory and algorithmic probability. In a significant advancement, it has been demonstrated that the renowned logistic map xk+1=μ⁢xk⁢(1−xk)subscript𝑥𝑘1𝜇subscript𝑥𝑘1subscript𝑥𝑘x_{k+1}=\mu x_{k}(1-x_{k})italic_x start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT = italic_μ italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( 1 - italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ), a staple in dynamical systems theory, and other one-dimensional maps exhibit simplicity bias when conceptualized as input-output systems. Building upon this foundational work, our research delves into the manifestations of simplicity bias within the random logistic map, specifically focusing on scenarios involving additive noise. This investigation is driven by the overarching goal of formulating a comprehensive theory for the prediction and analysis of time series.
Our primary contributions are multifaceted. We discover that simplicity bias is observable in the random logistic map for specific ranges of μ𝜇\muitalic_μ and noise magnitudes. Additionally, we find that this bias persists even with the introduction of small measurement noise, though it diminishes as noise levels increase. Our studies also revisit the phenomenon of noise-induced chaos, particularly when μ=3.83𝜇3.83\mu=3.83italic_μ = 3.83, revealing its characteristics through complexity-probability plots. Intriguingly, we employ the logistic map to underscore a paradoxical aspect of data analysis: more data adhering to a consistent trend can occasionally lead to reduced confidence in extrapolation predictions, challenging conventional wisdom.
We propose that adopting a probability-complexity perspective in analyzing dynamical systems could significantly enrich statistical learning theories related to series prediction and analysis. This approach not only facilitates a deeper understanding of simplicity bias and its implications but also paves the way for novel methodologies in forecasting complex systems behavior, especially in scenarios dominated by uncertainty and stochasticity.
Keywords: Random dynamical systems; algorithmic probability; simplicity bias; time series; machine learning",[''],[]
"This paper considers a multi-group multicasting scenario facilitated by a reconfigurable intelligent surface (RIS). We propose a fast and scalable algorithm for the joint design of the base station (BS) multicast beamforming and the RIS passive beamforming to minimize the transmit power subject to the quality-of-service (QoS) constraints. By exploring the structure of the joint optimization problem, we show that this QoS problem can be broken into a BS multicast QoS subproblem and an RIS max-min-fair (MMF) multicast subproblem, which are solved alternatingly. In our proposed algorithm, we utilize the optimal multicast beamforming structure to obtain the BS beamformers efficiently. Furthermore, we reformulate the challenging RIS multicast subproblem and employ a first-order projected subgradient algorithm (PSA) to solve it, which yields closed-form updates. Simulation results show the efficacy of our proposed algorithm in performance and computational cost compared to other alternative methods.",[''],['Canada']
"Recent advances in large language models (LLMs) have led to the development of various evaluation benchmarks. These benchmarks typically rely on a single instruction template for evaluating all LLMs on a specific task.
In this paper, we comprehensively analyze the brittleness of results obtained via single-prompt evaluations across 6.5M instances, involving 20 different LLMs and 39 tasks from 3 benchmarks. To improve robustness of the analysis, we propose to evaluate LLMs with a set of diverse prompts instead. We discuss tailored evaluation metrics for specific use cases (e.g., LLM developers vs. developers interested in a specific downstream task), ensuring a more reliable and meaningful assessment of LLM capabilities. We then implement these criteria and conduct evaluations of multiple models, providing insights into the true strengths and limitations of current LLMs.",[''],[]
"We introduce a method to reconstruct full rapidity distributions of charged particle multiplicity and net proton yields, crucial for constraining the longitudinal dynamics of nuclear matter created in the beam energy scan program. Employing rapidity distributions within a multistage hydrodynamic model calibrated for Au+Au collisions at sNN=7.7−200subscript𝑠NN7.7200\sqrt{s_{\mathrm{NN}}}=7.7-200\,square-root start_ARG italic_s start_POSTSUBSCRIPT roman_NN end_POSTSUBSCRIPT end_ARG = 7.7 - 200GeV, we estimate the total energy and baryon number deposited into the collision fireball, offering insights into initial dynamics and the identification of nuclear remnants. We explore the potential of rapidity-dependent measurements in probing equations of state at finite chemical potentials. Furthermore, we compare the freeze-out parameters derived from both hydrodynamics and thermal models, highlighting that the parameters extracted via thermal models represent averaged properties across rapidities.",[''],['Canada']
"Generalizing the concept of the Macaulay inverse system, we introduce a way to describe localizations of an ideal in a polynomial ring. This leads to an approach to the differential primary decomposition as a description of the affine scheme defined by the ideal.",[''],[]
"Let π:Y→X:𝜋→𝑌𝑋\pi:Y\rightarrow Xitalic_π : italic_Y → italic_X be a continuous surjection between compact
Hausdorff spaces Y𝑌Yitalic_Y and X𝑋Xitalic_X which is irreducible in the sense that if
F⊊Y𝐹𝑌F\subsetneq Yitalic_F ⊊ italic_Y is closed, then π⁢(F)≠X𝜋𝐹𝑋\pi(F)\neq Xitalic_π ( italic_F ) ≠ italic_X. We exhibit isomorphisms between
various Boolean algebras associated to this data: the regular open
sets of X𝑋Xitalic_X, the regular
open sets of Y𝑌Yitalic_Y, the regular ideals of C⁢(X)𝐶𝑋C(X)italic_C ( italic_X ) and the regular
ideals of C⁢(Y)𝐶𝑌C(Y)italic_C ( italic_Y ).
We call X𝑋Xitalic_X and Y𝑌Yitalic_Y Boolean equivalent if the
regular open sets of X𝑋Xitalic_X and the regular open sets of Y𝑌Yitalic_Y are isomorphic
Boolean algebras. We give a characterization of when two compact
metrizable spaces are Boolean equivalent; this
characterization may be viewed as a topological version of the characterization of
standard Borel spaces.","['Key words and phrases:', 'Irreducible mappings, regular open sets, regular ideals,', 'Boolean algebras']",[]
"Sub-sampling is applied to simulated T1subscript𝑇1T_{1}italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-D𝐷Ditalic_D NMR signals and its influence on inversion performance is evaluated. For this different levels of sub-sampling were employed ranging from the fully sampled signal down to only less than two percent of the original data points. This was combined with multiple sample schemes including fully random sampling, truncation and a combination of both. To compare the performance of different inversion algorithms, the so-generated sub-sampled signals were inverted using Tikhonov regularization, modified total generalized variation (MTGV) regularization, deep learning and a combination of deep learning and Tikhonov regularization. Further, the influence of the chosen cost function on the relative inversion performance was investigated. Overall, it could be shown that for a vast majority of instances, deep learning clearly outperforms regularization based inversion methods, if the signal is fully or close to fully sampled. However, in the case of significantly sub-sampled signals regularization yields better inversion performance than its deep learning counterpart with MTGV clearly prevailing over Tikhonov. Additionally, fully random sampling could be identified as the best overall sampling scheme independent of the inversion method. Finally, it could also be shown that the choice of cost function does vastly influence the relative rankings of the tested inversion algorithms highlighting the importance of choosing the cost function accordingly to experimental intentions.",[''],[]
"We develop a framework relating semiorthogonal de-compositions of a triangulated category 𝒞𝒞\mathcal{C}caligraphic_C to paths in its space of stability conditions. We prove that when 𝒞𝒞\mathcal{C}caligraphic_C is the homotopy category of a smooth and proper pre-triangulated dg-category, every semiorthogonal decomposition whose semiorthogonal factors admit a Bridgeland stability condition can be obtained from our framework.",[''],[]
"Much is known about when a locally optimal solution depends in a
single-valued Lipschitz continuous way on the problem’s parameters,
including tilt perturbations. Much less is known, however, about when
that solution and a uniquely determined multiplier vector associated with
it exhibit that dependence as a primal-dual pair. In classical nonlinear
programming, such advantageous behavior is tied to the combination of the
standard strong second-order sufficient condition (SSOC) for local
optimality and the linear independent gradient condition (LIGC) on the
active constraint gradients. But although second-order sufficient
conditons have successfully been extended far beyond nonlinear programming,
insights into what should replace constraint gradient independence as the
extended dual counterpart have been lacking.

The exact answer is provided here for a wide range of optimization
problems in finite dimensions. Behind it are advances in how coderivatives
and strict graphical derivatives can be deployed. New results about
strong metric regularity in solving variational inequalities and
generalized equations are obtained from that as well.


Keywords: 
second-order variational analysis,
local optimality,
primal-dual stability,
tilt stability,
full stability,
metric regularity,
Kummer’s inverse theorem,
implicit mapping theorems,
graphically Lipschitzian mappings,
crypto-continuity,
strict graphical derivatives,
coderivatives,
variational sufficiency.",[''],[]
,[''],[]
,[''],[]
"Score distillation has emerged as one of the most prevalent approaches for text-to-3D asset synthesis.
Essentially, score distillation updates 3D parameters by lifting and back-propagating scores averaged over different views.
In this paper, we reveal that the gradient estimation in score distillation is inherent to high variance.
Through the lens of variance reduction, the effectiveness of SDS and VSD can be interpreted as applications of various control variates to the Monte Carlo estimator of the distilled score.
Motivated by this rethinking and based on Stein’s identity, we propose a more general solution to reduce variance for score distillation, termed Stein Score Distillation (SSD). SSD incorporates control variates constructed by Stein identity,
allowing for arbitrary baseline functions. This enables us to include flexible guidance priors and network architectures to explicitly optimize for variance reduction.
In our experiments, the overall pipeline, dubbed SteinDreamer, is implemented by instantiating the control variate with a monocular depth estimator.
The results suggest that SSD can effectively reduce the distillation variance and consistently improve visual quality for both object- and scene-level generation.
Moreover, we demonstrate that SteinDreamer achieves faster convergence than existing methods due to more stable gradient updates.
Project page: vita-group.github.io/SteinDreamer/.",[''],[]
"We consider the problem of tracking multiple, unknown, and time-varying numbers of objects using a distributed network of heterogeneous sensors. In an effort to derive a formulation for practical settings, we consider limited and unknown sensor field-of-views (FoVs), sensors with limited local computational resources and communication channel capacity. The resulting distributed multi-object tracking algorithm involves solving an NP-hard multidimensional assignment problem either optimally for small-size problems or sub-optimally for general practical problems. For general problems, we propose an efficient distributed multi-object tracking algorithm that performs track-to-track fusion using a clustering-based analysis of the state space transformed into a density space to mitigate the complexity of the assignment problem. The proposed algorithm can more efficiently group local track estimates for fusion than existing approaches. To ensure we achieve globally consistent identities for tracks across a network of nodes as objects move between FoVs, we develop a graph-based algorithm to achieve label consensus and minimise track segmentation. Numerical experiments with a synthetic and a real-world trajectory dataset demonstrate that our proposed method is significantly more computationally efficient than state-of-the-art solutions, achieving similar tracking accuracy and bandwidth requirements but with improved label consistency.",[''],[]
,[''],[]
"We prove that a complete solution to the Ricci flow on M×[−T,0)𝑀𝑇0M\times[-T,0)italic_M × [ - italic_T , 0 ) which has quadratic curvature decay on some end of M𝑀Mitalic_M
and converges locally smoothly to the end of a cone on that neighborhood as t↗0↗𝑡0t\nearrow 0italic_t ↗ 0 must be a gradient shrinking soliton.",[''],[]
"Camera traps are valuable tools in animal ecology for biodiversity monitoring and conservation.
However, challenges like poor generalization to deployment at new unseen locations limit their practical application.
Images are naturally associated with heterogeneous forms of context possibly in different modalities.
In this work, we leverage the structured context associated with the camera trap images to improve out-of-distribution generalization for the task of species identification in camera traps.
For example, a photo of a wild animal may be associated with information about where and when it was taken, as well as structured biology knowledge about the animal species.
While typically overlooked by existing work, bringing back such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization.
However, effectively integrating such heterogeneous context into the visual domain is a challenging problem.
To address this, we propose a novel framework that reformulates species classification as link prediction in a multimodal knowledge graph (KG).
This framework seamlessly integrates various forms of multimodal context for visual recognition.
We apply this framework for out-of-distribution species classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets and achieve competitive performance with state-of-the-art approaches. Furthermore, our framework successfully incorporates biological taxonomy for improved generalization and enhances sample efficiency for recognizing under-represented species.111Code and data will be released on GitHub.",[''],[]
"We present a review of personality in neural conversational agents (CAs), also called chatbots. First, we define Personality, Persona, and Profile. We explain all personality schemes which have been used in CAs, and list models under the scheme(s) which they use. Second we describe 21 datasets which have been developed in recent CA personality research. Third, we define the methods used to embody personality in a CA, and review recent models using them. Fourth, we survey some relevant reviews on CAs, personality, and related topics. Finally, we draw conclusions and identify some research challenges for this important emerging field.",[''],[]
"This is a report on JamCoders, a four-week long computer-science camp for high school
students in Jamaica. The camp teaches college-level
coding and algorithms, and targets academically excellent students in grades
9–11 (ages 14–17).
Qualitative assessment shows that the camp was, in general terms, a success. We
reflect on the background and academic structure of the camp and share key
takeaways on designing and operating a successful camp. We analyze data
collected before, during and after the camp and map the effects of
demographic differences on student performance in camp. We conclude with a
discussion on possible improvements on our approach.",[''],[]
"Bayesian neural networks (BNNs) are a principled approach to modeling predictive uncertainties in deep learning, which are important in safety-critical applications.
Since exact Bayesian inference over the weights in a BNN is intractable, various approximate inference methods exist, among which sampling methods such as Hamiltonian Monte Carlo (HMC) are often considered the gold standard.
While HMC provides high-quality samples, it lacks interpretable summary statistics because its sample mean and variance is meaningless in neural networks due to permutation symmetry.
In this paper, we first show that the role of permutations can be meaningfully quantified by a number of transpositions metric.
We then show that the recently proposed rebasin method (ainsworth2022git, ) allows us to summarize HMC samples into a compact representation that provides a meaningful explicit uncertainty estimate for each weight in a neural network, thus unifying sampling methods with variational inference.
We show that this compact representation allows us to compare trained BNNs directly in weight space across sampling methods and variational inference, and to efficiently prune neural networks trained without explicit Bayesian frameworks by exploiting uncertainty estimates from HMC.",[''],[]
"We establish that the summability of the series ∑εnsubscript𝜀𝑛\sum\varepsilon_{n}∑ italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is the necessary and sufficient criterion ensuring that every
(1+εn)1subscript𝜀𝑛(1+\varepsilon_{n})( 1 + italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) Markushevich basis in a separable Hilbert space is a Riesz basis. Further we show that if n⁢εn→∞→𝑛subscript𝜀𝑛n\varepsilon_{n}\to\inftyitalic_n italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT → ∞, then in ℓ2subscriptℓ2\ell_{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT there exists a (1+εn)1subscript𝜀𝑛(1+\varepsilon_{n})( 1 + italic_ε start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )
Markushevich basis that under any permutation is non-equivalent to a Schauder basis. We extend this result to any separable Banach space. Finally we provide examples of Auerbach bases in
1-symmetric separable Banach spaces whose no permutations are equivalent to any Schauder basis or (depending on the space) any unconditional Schauder basis.",[''],[]
"Conventional diagonalization methods to calculate nuclear energy levels in the framework of the configuration-interaction (CI) shell model approach are prohibited in very large model spaces. The shell model Monte Carlo (SMMC) is a powerful technique for calculating thermal and ground-state observables of nuclei in very large model spaces, but it is challenging to extract nuclear spectra in this approach. We present a novel method to extract low-lying energy levels for given values of a set of good quantum numbers such as spin and parity. The method is based on imaginary-time one-body density correlation matrices that satisfy asymptotically a generalized eigenvalue problem. We validate the method in a light nucleus that allows comparison with exact diagonalization results of the CI shell model Hamiltonian. The method is applicable to other finite-size quantum many-body systems that can be described within a CI shell model approach.",[''],['USA']
"In this paper we completely describe the winning and losing conditions different from the only “trivial” conditions known before. In other words, we solve the open question of finding a complete nontrivial Schmidt diagram. In addition, we give the new bounds for two family of sets: one related to frequencies of digits in base-2222 expansions, and one connected to the set of the badly approximable numbers.",[''],[]
,[''],[]
"In this paper, we focus on the One-shot Novel View Synthesis (O-NVS) task which targets synthesizing photo-realistic novel views given only one reference image per scene. Previous One-shot Generalizable Neural Radiance Fields (OG-NeRF) methods solve this task in an inference-time finetuning-free manner, yet suffer the blurry issue due to the encoder-only architecture that highly relies on the limited reference image. On the other hand, recent diffusion-based image-to-3d methods show vivid plausible results via distilling pre-trained 2D diffusion models into a 3D representation, yet require tedious per-scene optimization. Targeting these issues, we propose the GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF, a Generative Detail compensation framework via GAN and Diffusion that is both inference-time finetuning-free and with vivid plausible details.
In detail, following a coarse-to-fine strategy, GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF is mainly composed of a One-stage Parallel Pipeline (OPP) and a 3D-consistent Detail Enhancer (Diff3DE). At the coarse stage, OPP first efficiently inserts the GAN model into the existing OG-NeRF pipeline for primarily relieving the blurry issue with in-distribution priors captured from the training dataset, achieving a good balance between sharpness (LPIPS, FID) and fidelity (PSNR, SSIM). Then, at the fine stage, Diff3DE further leverages the pre-trained image diffusion models to complement rich out-distribution details while maintaining decent 3D consistency.
Extensive experiments on both the synthetic and real-world datasets show that GD22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT-NeRF noticeably improves the details while without per-scene finetuning.","['Index', 'Terms: ', 'One-shot novel view synthesis, generalizable neural radiance fields,\n3D reconstruction,', 'GAN, diffusion model.']",[]
"Deep Metric Learning (DML) plays an important role in modern computer vision research, where we learn a distance metric for a set of image representations. Recent DML techniques utilize the proxy to interact with the corresponding image samples in the embedding space. However, existing proxy-based DML methods focus on learning individual proxy-to-sample distance while the overall distribution of samples and proxies lacks attention. In this paper, we present a novel proxy-based DML framework that focuses on aligning the sample and proxy distributions to improve the efficiency of proxy-based DML losses. Specifically, we propose the Data-Augmented Domain Adaptation (DADA) method to adapt the domain gap between the group of samples and proxies. To the best of our knowledge, we are the first to leverage domain adaptation to boost the performance of proxy-based DML. We show that our method can be easily plugged into existing proxy-based DML losses. Our experiments on benchmarks, including the popular CUB-200-2011, CARS196, Stanford Online Products, and In-Shop Clothes Retrieval, show that our learning algorithm significantly improves the existing proxy losses and achieves superior results compared to the existing methods. Our code is available at https://github.com/Noahsark/DADA",[''],[]
"This supplementary material provides additional material not contained in the main paper. Section S.1 delivers proofs of the results for characterizing distributional parallel trends in Appendix LABEL:ssec:appendixA. Section S.2 describes the required derivatives for implementing the Delta method, facilitating the computation of standard errors associated with estimated treatment effects. Section S.3 outlines technical assumptions and results for the estimation of our semiparametric model in the absence of misreporting. Section S.4
presents a decomposition of another possible causal quantity, characterized by the difference between potential self-reported outcome distributions under treatment and control. Finally, Sections S.5 and S.6 display additional simulation and empirical results, respectively.",[''],[]
"We study the evolution with collision energy of the parameters describing the two-pion correlation function in the context of relativistic heavy-ion collisions within the NICA energy range. To this end, we perform UrQMD simulations to produce samples of pions from 5×1065superscript1065\times 10^{6}5 × 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT Bi+Bi collisions for each of the studied energies. The effects of the quantum correlations are introduced using the correlation afterburner code CRAB. We fit the correlation function using Gaussian, Lorentzian and symmetric Lévy distributions and show that for all collision energies the latter provides the best fit. We separate the sample into pions coming from primary processes and pions originating from the decay of long-lived resonances and show that the source size for the latter is significantly larger than for the former, which is consistent with the core-halo picture of pion production. We then simulate the effects of a non-ideal detector introducing a momentum smearing parameter representing the minimum pair momentum and thus a maximum source size that can be resolved. By resorting again to the core-halo picture, we show that the values of the correlation function intercept parameter are affected by the presence of a significant fraction of core pions coming from the decay of long-lived but slow moving resonances. We argue that the study of the evolution of these two core components with the collision energy can provide useful insights to look for signs of criticality in correlation function studies.",[''],['Mexico.']
"The study of ψ−limit-from𝜓\psi-italic_ψ -hyperholomorphic functions defined on domains in ℝ4superscriptℝ4\mathbb{R}^{4}blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT with values in ℍℍ\mathbb{H}blackboard_H, namely null-solutions of the ψ−limit-from𝜓\psi-italic_ψ -Fueter operator, is a topic which captured great interest in quaternionic analysis. This class of functions is more general than that of Fueter regular functions.
In the setting of (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus, also known as post quantum calculus, we introduce a deformation of the ψ−limit-from𝜓\psi-italic_ψ -Fueter operator written in terms of suitable difference operators, which reduces to a deformed q𝑞qitalic_q calculus when q′=1superscript𝑞′1q^{\prime}=1italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 1. We also prove the Stokes and Borel-Pompeiu formulas in this context.
This work is the first investigation of results in quaternionic analysis in the setting of the (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus theory.

Keywords. (q,q′)−limit-from𝑞superscript𝑞′(q,q^{\prime})-( italic_q , italic_q start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) -calculus, Stokes formula, Borel-Pompeiu formula, quaternionic analysis
MSC 2020. Primary: 30G30; 30G35, 05A30, Secondary: 46S05, 47S05",[''],[]
"We get multiplicity of normalized solutions for the fractional Schrödinger equation



{(−Δ)s⁢u+V⁢(ε⁢x)⁢u=λ⁢u+h⁢(ε⁢x)⁢f⁢(u)in⁢ℝN,∫ℝN|u|2⁢𝑑x=a,casessuperscriptΔ𝑠𝑢𝑉𝜀𝑥𝑢𝜆𝑢ℎ𝜀𝑥𝑓𝑢insuperscriptℝ𝑁subscriptsuperscriptℝ𝑁superscript𝑢2differential-d𝑥𝑎missing-subexpression\displaystyle\left\{\begin{array}[]{ll}(-\Delta)^{s}u+V(\varepsilon x)u=%
\lambda u+h(\varepsilon x)f(u)&\mbox{in}\ \mathbb{R}^{N},\\
\displaystyle\int_{\mathbb{R}^{N}}|u|^{2}dx=a,\end{array}\right.{ start_ARRAY start_ROW start_CELL ( - roman_Δ ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT italic_u + italic_V ( italic_ε italic_x ) italic_u = italic_λ italic_u + italic_h ( italic_ε italic_x ) italic_f ( italic_u ) end_CELL start_CELL in blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT , end_CELL end_ROW start_ROW start_CELL ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_x = italic_a , end_CELL start_CELL end_CELL end_ROW end_ARRAY



where (−Δ)ssuperscriptΔ𝑠(-\Delta)^{s}( - roman_Δ ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT is the fractional Laplacian, s∈(0,1)𝑠01s\in(0,1)italic_s ∈ ( 0 , 1 ), a,ε>0𝑎𝜀0a,\varepsilon>0italic_a , italic_ε > 0, λ∈ℝ𝜆ℝ\lambda\in\mathbb{R}italic_λ ∈ blackboard_R is an unknown parameter that appears as a Lagrange multiplier,
V,h:ℝN→[0,+∞):𝑉ℎ→superscriptℝ𝑁0V,h:\mathbb{R}^{N}\rightarrow[0,+\infty)italic_V , italic_h : blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → [ 0 , + ∞ ) are bounded and continuous, and f𝑓fitalic_f is continuous function with L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-subcritical growth. We prove that
the numbers of normalized solutions are at least the numbers of global maximum points of hℎhitalic_h when ε𝜀\varepsilonitalic_ε is small enough.","['Key words and phrases:', 'Fractional', 'Laplacian,', 'Normalized solution,', 'Mass critical exponent']",[]
"Federated Learning (FL) enables collaborative model training among participants while guaranteeing the privacy of raw data. Mainstream FL methodologies overlook the dynamic nature of real-world data, particularly its tendency to grow in volume and diversify in classes over time. This oversight results in FL methods suffering from catastrophic forgetting, where models inadvertently discard previously learned information upon assimilating new data.
In response to this challenge, we propose a novel Federated Class-Incremental Learning (FCIL) method, named FCIL with New-Class Augmented Self-Distillation (FedNASD). FedNASD combines new class scores, which are inferred from current models, with historical models’ predictions. Based on the combined past and present knowledge, it incorporates self-distillation over models on clients, aiming to achieve effective knowledge transfer from historical models to current models. Theoretical analysis demonstrates that FedNASD is equivalent to modeling old class scores as conditional probabilities in the absence of new classes. Additionally, it reconciles the predictions of new classes with current models to refine the conditional probabilities of historical scores where new classes do not exist. Empirical experiments demonstrate the superiority of FedNASD over four baseline algorithms in reducing the average forgetting rate and boosting global accuracy.",[''],[]
"We are concerned with the existence of normalized solutions for a class of generalized Chern-Simons-Schrödinger type problems
with supercritical exponential growth



{−Δ⁢u+λ⁢u+A0⁢u+∑j=12Aj2⁢u=f⁢(u),∂1A2−∂2A1=−12⁢|u|2,∂1A1+∂2A2=0,∂1A0=A2⁢|u|2,∂2A0=−A1⁢|u|2,∫ℝ2|u|2⁢𝑑x=a2,casesΔ𝑢𝜆𝑢subscript𝐴0𝑢superscriptsubscript𝑗12superscriptsubscript𝐴𝑗2𝑢𝑓𝑢missing-subexpressionformulae-sequencesubscript1subscript𝐴2subscript2subscript𝐴112superscript𝑢2subscript1subscript𝐴1subscript2subscript𝐴20missing-subexpressionformulae-sequencesubscript1subscript𝐴0subscript𝐴2superscript𝑢2subscript2subscript𝐴0subscript𝐴1superscript𝑢2missing-subexpressionsubscriptsuperscriptℝ2superscript𝑢2differential-d𝑥superscript𝑎2missing-subexpression\left\{\begin{array}[]{ll}\displaystyle-\Delta u+\lambda u+A_{0}u+\sum\limits_%
{j=1}^{2}A_{j}^{2}u=f(u),\\
\displaystyle\partial_{1}A_{2}-\partial_{2}A_{1}=-\frac{1}{2}|u|^{2},%
\leavevmode\nobreak\ \partial_{1}A_{1}+\partial_{2}A_{2}=0,\\
\displaystyle\partial_{1}A_{0}=A_{2}|u|^{2},\leavevmode\nobreak\ \partial_{2}A%
_{0}=-A_{1}|u|^{2},\\
\displaystyle\int_{\mathbb{R}^{2}}|u|^{2}dx=a^{2},\end{array}\right.{ start_ARRAY start_ROW start_CELL - roman_Δ italic_u + italic_λ italic_u + italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_u + ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_u = italic_f ( italic_u ) , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - divide start_ARG 1 end_ARG start_ARG 2 end_ARG | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∂ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , ∂ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = - italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ∫ start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT | italic_u | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_x = italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , end_CELL start_CELL end_CELL end_ROW end_ARRAY



where a≠0𝑎0a\neq 0italic_a ≠ 0, λ∈ℝ𝜆ℝ\lambda\in\mathbb{R}italic_λ ∈ blackboard_R is known as the Lagrange multiplier
and f∈𝒞1⁢(ℝ)𝑓superscript𝒞1ℝf\in\mathcal{C}^{1}(\mathbb{R})italic_f ∈ caligraphic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( blackboard_R ) denotes the nonlinearity that fulfills the
supercritical exponential growth in the Trudinger-Moser sense at infinity.
Under suitable assumptions, combining the constrained minimization approach together with the homotopy stable family and elliptic regularity theory,
we obtain that the problem has at least a ground state solution.","['Key words and phrases: ', 'Normalized solutions,', 'Chern-Simons-Schrödinger system,', 'Trudinger-Moser inequality,', 'Constrained minimization approach,', 'Ground state solution,', 'Variational method.']",[]
,[''],[]
"Several reports in education have called for transforming physics learning environments by promoting sensemaking of real-world scenarios in light of curricular ideas. Recent advancements in Generative-Artificial Intelligence has garnered increasing traction in educators’ community by virtue of its potential in transforming STEM learning. In this exploratory study, we adopt a mixed-methods approach in comparatively examining student- and AI-generated responses to two different formats of a physics problem through the cognitive lenses of sensemaking and mechanistic reasoning. The student data is derived from think-aloud interviews of introductory students and the AI data comes from ChatGPT’s solutions collected using Zero shot approach. The results highlight AI responses to evidence most features of the two processes through well-structured solutions and student responses to effectively leverage representations in their solutions through iterative refinement of arguments. In other words, while AI responses reflect how physics is talked about, the student responses reflect how physics is practiced. Implications of these results in light of development and deployment of AI systems in physics pedagogy are discussed.",[''],[]
,[''],[]
"We propose a Safe Adversarial Trained Actor Critic (SATAC) algorithm for offline reinforcement learning (RL) with general function approximation in the presence of limited data coverage. SATAC operates as a two-player Stackelberg game featuring a refined objective function. The actor (leader player) optimizes the policy against two adversarially trained value critics (follower players), who focus on scenarios where the actor’s performance is inferior to the behavior policy. Our framework provides both theoretical guarantees and a robust deep-RL implementation. Theoretically, we demonstrate that when the actor employs a no-regret optimization oracle, SATAC achieves two guarantees: (i)𝑖(i)( italic_i ) For the first time in the offline RL setting, we establish that SATAC can produce a policy that outperforms the behavior policy while maintaining the same level of safety, which is critical to designing an algorithm for offline RL. (i⁢i)𝑖𝑖(ii)( italic_i italic_i ) We demonstrate that the algorithm guarantees policy improvement across a broad range of hyperparameters, indicating its practical robustness. Additionally, we offer a practical version of SATAC and compare it with existing state-of-the-art offline safe-RL algorithms in continuous control environments. SATAC outperforms all baselines across a range of tasks, thus validating the theoretical performance.",[''],[]
,[''],[]
"As artificial intelligence (AI) applications continue to expand, there is a growing need for deep neural network (DNN) models. Although DNN models deployed at the edge are promising to provide AI as a service with low latency, their cooperation is yet to be explored. In this paper, we consider the DNN service providers share their computing resources as well as their models’ parameters and allow other DNNs to offload their computations without mirroring. We propose a novel algorithm called coordinated DNNs on edge (CoDE) that facilitates coordination among DNN services by creating multi-task DNNs out of individual models. CoDE aims to find the optimal path that results in the lowest possible cost, where the cost reflects the inference delay, model accuracy, and local computation workload. With CoDE, DNN models can make new paths for inference by using their own or other models’ parameters. We then evaluate the performance of CoDE through numerical experiments. The results demonstrate a 75%percent7575\%75 % reduction in the local service computation workload while degrading the accuracy by only 2%percent22\%2 % and having the same inference time in a balanced load condition. Under heavy load, CoDE can further decrease the inference time by 30%percent3030\%30 % while the accuracy is reduced by only 4%percent44\%4 %.","['Index', 'Terms: ', 'AI as a service, computation offloading, multi-task', 'DNNs, service coordination.']",[]
"Integrating sharded blockchain with IoT presents a solution for trust issues and optimized data flow. Sharding boosts blockchain scalability by dividing its nodes into parallel shards, yet it’s vulnerable to the 1%percent11\%1 % attacks where dishonest nodes target a shard to corrupt the entire blockchain. Balancing security with scalability is pivotal for such systems. Deep Reinforcement Learning (DRL) adeptly handles dynamic, complex systems and multi-dimensional optimization.
This paper introduces a Trust-based and DRL-driven (TbDd) framework, crafted to counter shard collusion risks and dynamically adjust node allocation, enhancing throughput while maintaining network security. With a comprehensive trust evaluation mechanism, TbDd discerns node types and performs targeted resharding against potential threats. The model maximizes tolerance for dishonest nodes, optimizes node movement frequency, ensures even node distribution in shards, and balances sharding risks. Rigorous evaluations prove TbDd’s superiority over conventional random-, community-, and trust-based sharding methods in shard risk equilibrium and reducing cross-shard transactions.","['Index', 'Terms: \nblockchain, sharding, collusion attacks, trustworthiness, deep reinforcement learning, internet-of-things']",[]
"Neural networks are increasingly finding their way into the realm of graphs and modeling relationships between features. Concurrently graph neural network explanation approaches are being invented to uncover relationships between the nodes of the graphs. However, there is a disparity between the existing attribution methods, and it is unclear which attribution to trust. Therefore research has introduced evaluation experiments that assess them from different perspectives. In this work, we assess attribution methods from a perspective not previously explored in the graph domain: retraining. The core idea is to retrain the network on important (or not important) relationships as identified by the attributions and evaluate how networks can generalize based on these relationships. We reformulate the retraining framework to sidestep issues lurking in the previous formulation and propose guidelines for correct analysis. We run our analysis on four state-of-the-art GNN attribution methods and five synthetic and real-world graph classification datasets. The analysis reveals that attributions perform variably depending on the dataset and the network. Most importantly, we observe that the famous GNNExplainer performs similarly to an arbitrary designation of edge importance. The study concludes that the retraining evaluation cannot be used as a generalized benchmark and recommends it as a toolset to evaluate attributions on a specifically addressed network, dataset, and sparsity. Our code is publically available.111
https://github.com/alirezadizaji/GraphROAR",[''],[]
"Realizing photonic graph states, crucial in various quantum protocols, is challenging due to the absence of deterministic entangling gates in linear optics. To address this, emitter qubits are leveraged to establish and transfer the entanglement to photons. We introduce an optimization method for such protocols based on the local Clifford equivalency of states and the graph-shape correlated generation cost parameters. Employing this method, we achieve a 50% reduction in use of the 2-qubit gates for generation of the repeater graph states and a 65% reduction in the total gate count for 15-node random dense graphs.",[''],"['Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada']"
"We introduce a new notion of a periodic pencil of flat connections on a smooth algebraic variety X𝑋Xitalic_X. This is a family ∇(s1,…,sn)∇subscript𝑠1…subscript𝑠𝑛\nabla(s_{1},...,s_{n})∇ ( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) of flat connections on a trivial vector bundle on X𝑋Xitalic_X depending linearly on parameters s1,…,snsubscript𝑠1…subscript𝑠𝑛s_{1},...,s_{n}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and generically invariant, up to isomorphism, under the shifts si↦si+1maps-tosubscript𝑠𝑖subscript𝑠𝑖1s_{i}\mapsto s_{i}+1italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ↦ italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 for all i𝑖iitalic_i. If
in addition ∇∇\nabla∇ has regular singularities, we call it a quasi-motivic pencil. We
use tools from complex analysis to establish various remarkable properties of such pencils over ℂℂ\mathbb{C}blackboard_C. For example, we show that the monodromy of a quasi-motivic pencil is defined over the field of algebraic functions in e2⁢π⁢i⁢sjsuperscript𝑒2𝜋𝑖subscript𝑠𝑗e^{2\pi is_{j}}italic_e start_POSTSUPERSCRIPT 2 italic_π italic_i italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, and that its singularities are
constrained to an arrangement of hyperplanes with integer normal vectors. Then we show that many important examples of families of flat connections, such as Knizhnik-Zamolodchikov, Dunkl, and Casimir connections, are quasi-motivic and thus periodic pencils.
Besides being interesting in its own right, the periodic property of a pencil of flat connections turns out to be very useful in computing the eigenvalues of the p𝑝pitalic_p-curvature of its reduction to positive characteristic. This will be done in our forthcoming paper [EV2].",[''],[]
,[''],[]
,[''],[]
"Relative pose estimation for RGBD cameras is crucial in a number of applications. Previous approaches either rely on the RGB aspect of the images to estimate pose thus not fully making use of depth in the estimation process or estimate pose from the 3D cloud of points that each image produces, thus not making full use of RGB information. This paper shows that if one pair of correspondences is hypothesized from the RGB-based ranked-ordered correspondence list, then the space of remaining correspondences is restricted to corresponding pairs of curves nested around the hypothesized correspondence, implicitly capturing depth consistency. This simple Geometric Depth Constraint (GDC)  significantly reduces potential matches. In effect this becomes a filter on possible correspondences that helps reduce the number of outliers and thus expedites RANSAC significantly. As such, the same budget of time allows for more RANSAC iterations and therefore additional robustness and a significant speedup. In addition, the paper proposed a Nested RANSAC approach that also speeds up the process, as shown through experiments on TUM, ICL-NUIM, and RGBD Scenes v2 datasets.",[''],[]
"We study the Marcinkiewicz-Zygmund strong law of large numbers for the cubic partial sums of the discrete Fourier transform of random
fields. We establish Marcinkiewicz–Zygmund types rate of convergence for the discrete Fourier transform of random
fields under weaker conditions than identical distribution.",[''],[]
"This paper introduces a novel hierarchical Bayesian model specifically designed to address challenges in Inverse Uncertainty Quantification (IUQ) for time-dependent problems in nuclear Thermal Hydraulics (TH) systems. The unique characteristics of time-dependent data, such as high dimensionality and correlation in model outputs requires special attention in the IUQ process. By integrating Gaussian Processes (GP) with Principal Component Analysis (PCA), we efficiently construct surrogate models that effectively handle the complexity of dynamic TH systems. Additionally, we incorporate Neural Network (NN) models for time series regression, enhancing the computational accuracy and facilitating derivative calculations for efficient posterior sampling using the Hamiltonian Monte Carlo Method - No U-Turn Sampler (NUTS).
We demonstrate the effectiveness of this hierarchical Bayesian approach using the transient experiments in the PSBT benchmark. Our results show improved estimates of PMPs’ posterior distributions and a reduced tendency for over-fitting, compared to conventional single-level Bayesian models. This approach offers a promising framework for extending IUQ to more complex, time-dependent problems.",[''],[]
"During times of increasing antibiotic resistance and the spread of infectious diseases like COVID-19, it is important to classify genes related to antibiotic resistance. As natural language processing has advanced with transformer-based language models, many language models that learn characteristics of nucleotide sequences have also emerged. These models show good performance in classifying various features of nucleotide sequences. When classifying nucleotide sequences, not only the sequence itself, but also various background knowledge is utilized. In this study, we use not only a nucleotide sequence-based language model but also a text language model based on PubMed articles to reflect more biological background knowledge in the model. We propose a method to fine-tune the nucleotide sequence language model and the text language model based on various databases of antibiotic resistance genes. We also propose an LLM-based augmentation technique to supplement the data and an ensemble method to effectively combine the two models. We also propose a benchmark for evaluating the model. Our method achieved better performance than the nucleotide sequence language model in the drug resistance class prediction.",[''],[]
"A quantum stochastic differential equation (qsde) on Fock space over L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT differential 1111-forms is given from the small “time” flow of which the trace of the connection Laplacian heat kernel for the spinor endomorphism bundle can be computed over any compact Ricci-flat Riemannian manifold. The existence of the stochastic flow is established by adapting the construction from [14]. When the manifold supports a parallel spinor – Ricci-flatness is a required integrability condition for parallel spinors, the trace of Dirac Laplacian heat kernel of the spinor bundle can be recovered. For 4444-manifolds, this corresponds to the spectral action, and realizes Einstein-Hilbert action as a stochastic flow.",[''],[]
"Wind is one kind of high-efficient, environmentally-friendly and cost-effective energy source.
Wind power, as one of the largest renewable energy in the world, has been playing a more and more important role in supplying electricity.
Though growing dramatically in recent years, the amount of generated wind power can be directly or latently affected by multiple uncertain factors, such as wind speed, wind direction, temperatures, etc.
More importantly, there exist very complicated dependencies of the generated power on the latent composition of these multiple time-evolving variables,
which are always ignored by existing works and thus largely hinder the prediction performances.
To this end, we propose DEWP, a novel Deep Expansion learning for Wind Power forecasting framework to carefully model the complicated dependencies with adequate expressiveness.
DEWP starts with a stack-by-stack architecture, where each stack is composed of (i) a variable expansion block that makes use of convolutional layers to capture dependencies among multiple variables;
(ii) a time expansion block that applies Fourier series and backcast/forecast mechanism to learn temporal dependencies in sequential patterns.
These two tailored blocks expand raw inputs into different latent feature spaces which can model different levels of dependencies of time-evolving sequential data.
Moreover, we propose an inference block corresponding for each stack, which applies multi-head self-attentions to acquire attentive features and maps expanded latent representations into generated wind power.
In addition, to make DEWP more expressive in handling deep neural architectures, we adapt doubly residue learning to process stack-by-stack outputs. Accurate wind power forecasting is then better achieved through fine-grained outputs by continuously removing stack residues and accumulating useful stack forecasts.
Finally, we present extensive experiments in the real-world wind power forecasting application on two datasets from two different turbines, in order to demonstrate the effectiveness of our approach.","['Wind', 'Power', 'Forecasting,', 'Time', 'Series', 'Forecasting,', 'Deep', 'Learning']","['OxfordOxfordUK', 'UniversityTempeArizonaUSA', 'ResearchBeijingChina', 'SciencesBeijingChina', 'TechnologyGuangzhouChina']"
"We prove that the highest density of non-overlapping translates of a given centrally symmetric convex domain relative to its outer parallel domain of given outer radius is attained by a lattice packing in the Euclidean plane. This generalizes some earlier (classical) results. Sharp upper bounds are proved for the analogue problem on congruent circular disks in the spherical (resp., hyperbolic) plane and on congruent balls in Euclidean 3333-space.",[''],[]
"We present magnetostriction and thermal expansion measurements on multiferroic (Ni0.930.93{}_{0.93}start_FLOATSUBSCRIPT 0.93 end_FLOATSUBSCRIPTCo0.070.07{}_{0.07}start_FLOATSUBSCRIPT 0.07 end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT. The high field phase diagrams up to 33 T along the a𝑎aitalic_a, b𝑏bitalic_b and c𝑐citalic_c directions are built. For H//a𝑎aitalic_a, as the magnetic field increasing, two intermediate phases appear between the incommensurate phase and the paramagnetic phase at about 7 K, and then a magnetically induced phase appears above the paramagnetic phase. For H//b𝑏bitalic_b, a thermal expansion measurement indicates a mutation in the spin lattice coupling of the high field phases. The interlaced phase boundary suggests a mixed state in the optical high field phase. For H//c𝑐citalic_c, an intermediate phase between the commensurate phase and the incommensurate phase is detected. A nonlinear boundary between the intermediate phase and the low temperature incommensurate phase, and a clear boundary between the commensurate phase and the paramagnetic phase are found. These results indicate that doping Co2+limit-from2{}^{2+}start_FLOATSUPERSCRIPT 2 + end_FLOATSUPERSCRIPT breaks the weak ferromagnetic moment of the commensurate phase, which exists in the parent compound Ni33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT and (Ni0.90.9{}_{0.9}start_FLOATSUBSCRIPT 0.9 end_FLOATSUBSCRIPTCo0.10.1{}_{0.1}start_FLOATSUBSCRIPT 0.1 end_FLOATSUBSCRIPT)33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT. This nonlinear influence reflects complicated spin modulation in Ni33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTV22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO88{}_{8}start_FLOATSUBSCRIPT 8 end_FLOATSUBSCRIPT by doping Co2+limit-from2{}^{2+}start_FLOATSUPERSCRIPT 2 + end_FLOATSUPERSCRIPT.",[''],['China']
,[''],[]
"We give an example for the Kuznetsov-Shinder conjecture, with infinitely many non-isomorphic but L-equivalent varieties.",[''],[]
,[''],[]
"Smart contracts are computer programs running on blockchains to automate the transaction execution between users.
The absence of contract specifications poses a real challenge to the correctness verification of
smart contracts.
Program invariants are properties that are always preserved throughout the execution, which
characterize an important aspect of the program behaviors.
In this paper, we propose a novel invariant generation framework, InvCon+, for Solidity smart
contracts.
InvCon+ extends the existing invariant detector, InvCon, to automatically produce verified
contract invariants based on both dynamic inference and static verification.
Unlike InvCon+, InvCon only produces likely invariants, which have a high probability to hold,
yet are still not verified against the contract code.
Particularly, InvCon+ is able to infer more expressive invariants that capture richer semantic
relations of contract code.
We evaluate InvCon+ on 361 ERC20 and 10 ERC721 real-world contracts, as well as common
ERC20 vulnerability benchmarks.
The experimental results indicate that InvCon+ efficiently produces high-quality invariant
specifications, which can be used to secure smart contracts from common vulnerabilities.","['Index', 'Terms: ', 'Smart contract, invariant detection.']",['Singapore']
"Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings.","['Index', 'Terms: ', 'Random walk, inductive graph representation learning, node identity embedding, node position embedding.']",[]
"Traditional video steganography methods are based on modifying the covert space for embedding, whereas we propose an innovative approach that embeds secret message within semantic feature for steganography during the video editing process.
Although existing traditional video steganography methods display a certain level of security and embedding capacity, they lack adequate robustness against common distortions in online social networks (OSNs).
In this paper, we introduce an end-to-end robust generative video steganography network (RoGVS), which achieves visual editing by modifying semantic feature of videos to embed secret message. We employ face-swapping scenario to showcase the visual editing effects. We first design a secret message embedding module to adaptively hide secret message into the semantic feature of videos.
Extensive experiments display that the proposed RoGVS method applied to facial video datasets demonstrate its superiority over existing video and image steganography techniques in terms of both robustness and capacity.",[''],[]
"Deceptive images can be shared in seconds with social networking services, posing substantial risks. Tampering traces, such as boundary artifacts and high-frequency information, have been significantly emphasized by massive networks in the Image Manipulation Localization (IML) field. However, they are prone to image post-processing operations, which limit the generalization and robustness of existing methods.
We present a novel Prompt-IML framework. We observe that humans tend to discern the authenticity of an image based on both semantic and high-frequency information, inspired by which, the proposed framework leverages rich semantic knowledge from pre-trained visual foundation models to assist IML.
We are the first to design a framework that utilizes visual foundation models specially for the IML task.
Moreover, we design a Feature Alignment and Fusion module to align and fuse features of semantic features with high-frequency features, which aims at locating tampered regions from multiple perspectives. Experimental results demonstrate that our model can achieve better performance on eight typical fake image datasets and outstanding robustness.",[''],[]
"We obtain a global rigidity result for abelian partially hyperbolic higher rank actions on certain 2−limit-from22-2 -step nilmanifolds XΓsubscript𝑋ΓX_{\Gamma}italic_X start_POSTSUBSCRIPT roman_Γ end_POSTSUBSCRIPT. We show that, under certain natural assumptions, all such actions are C∞−limit-fromsuperscript𝐶C^{\infty}-italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT -conjugated to an affine model. Along the way, we also prove two results of independent interest. We describe fibered partially hyperbolic diffeomorphisms on XΓsubscript𝑋ΓX_{\Gamma}italic_X start_POSTSUBSCRIPT roman_Γ end_POSTSUBSCRIPT and we show that topological conjugacies between partially hyperbolic actions and higher rank affine actions are C∞superscript𝐶C^{\infty}italic_C start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. As a consequence, we obtain a centralizer rigidity result, and we classify all possible centralizers for any C1−limit-fromsuperscript𝐶1C^{1}-italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT -small perturbation of an irreducible, affine partially hyperbolic map on such manifolds.",[''],[]
"In this paper, we prove the existence of periodic solutions with any prescribed minimal period T>0𝑇0T>0italic_T > 0
for even second order Hamiltonian systems and convex first order Hamiltonian systems under the weak Nehari
condition instead of Ambrosetti-Rabinowitz’s. To this end, we shall develop the method of Nehari manifold to directly deal with a
frequently occurring problem where the Nehari manifold is not a manifold.",[''],[]
"We present iDARR, a scalable iterative Data-Adaptive RKHS Regularization method, for solving ill-posed linear inverse problems. The method searches for solutions in subspaces where the true solution can be identified, with the data-adaptive RKHS penalizing the spaces of small singular values. At the core of the method is a new generalized Golub-Kahan bidiagonalization procedure that recursively constructs orthonormal bases for a sequence of RKHS-restricted Krylov subspaces. The method is scalable with a complexity of O⁢(k⁢m⁢n)𝑂𝑘𝑚𝑛O(kmn)italic_O ( italic_k italic_m italic_n ) for m𝑚mitalic_m-by-n𝑛nitalic_n matrices with k𝑘kitalic_k denoting the iteration numbers. Numerical tests on the Fredholm integral equation and 2D image deblurring show that it outperforms the widely used L2superscript𝐿2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and l2superscript𝑙2l^{2}italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT norms, producing stable accurate solutions consistently converging when the noise level decays.",[''],"['Australia.', 'China.', 'USA.']"
"The Alternating Direction Method of Multipliers (ADMM) has gained significant attention across a broad spectrum of machine learning applications. Incorporating the over-relaxation technique shows potential for enhancing the convergence rate of ADMM. However, determining optimal algorithmic parameters, including both the associated penalty and relaxation parameters, often relies on empirical approaches tailored to specific problem domains and contextual scenarios. Incorrect parameter selection can significantly hinder ADMM’s convergence rate. To address this challenge, in this paper we first propose a general approach to optimize the value of penalty parameter, followed by a novel closed-form formula to compute the optimal relaxation parameter in the context of linear quadratic problems (LQPs). We then experimentally validate our parameter selection methods through random instantiations and diverse imaging applications, encompassing diffeomorphic image registration, image deblurring, and MRI reconstruction.",[''],[]
"Acquisition and processing of point clouds (PCs) is a crucial enabler for many emerging applications reliant on 3D spatial data, such as robot navigation, autonomous vehicles, and augmented reality. In most scenarios, PCs acquired by remote sensors must be transmitted to an edge server for fusion, segmentation, or inference. Wireless transmission of PCs not only puts on increased burden on the already congested wireless spectrum, but also confronts a unique set of challenges arising from the irregular and unstructured nature of PCs. In this paper, we meticulously delineate these challenges and offer a comprehensive examination of existing solutions while candidly acknowledging their inherent limitations. In response to these intricacies, we proffer four pragmatic solution frameworks, spanning advanced techniques, hybrid schemes, and distributed data aggregation approaches. In doing so, our goal is to chart a path toward efficient, reliable, and low-latency wireless PC transmission.","['Index', 'Terms: ', 'Wireless point cloud transmission, point cloud compression, semantic communication,', 'DeepJSCC,', 'NeRF.']",[]
"As available data increases, so too does the demand to discover new datasets to solve new problems.
Existing studies using a base dataset and a keyword search often yield coarse-grained results where significant information overlaps and non-relevant data occur.
They also implicitly assume that a user can purchase all datasets found, which is rarely true in practice.
Therefore, achieving dataset discovery results with less redundancy using more fine-grained information needs and a budget is desirable.
To achieve this, we study the problem of finding a set of datasets that maximize distinctiveness based on a user’s fine-grained information needs while keeping the total price of the datasets within a user-defined budget. Note that the user may also have a base dataset that they want to expand.
Here,
the user’s fine-grained information needs are expressed as a query set and the distinctiveness score for a set of datasets, which is the number of distinct tuples produced by running the query set on the datasets which are do not overlap with the base dataset.
First, we prove the NP-hardness of this problem.
Then, we develop a greedy algorithm that achieves an approximation of (1−e−1)/21superscript𝑒12(1-e^{-1})/2( 1 - italic_e start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) / 2.
But this algorithm is neither efficient nor scalable as it frequently computes the exact distinctiveness during dataset selection, which requires every tuple for the query result overlap in multiple datasets to be tested.
To address this limitation, we propose an efficient and effective machine-learning-based (ML-based) algorithm to estimate the distinctiveness for a set of datasets, without the need for testing every tuple.
The proposed algorithm is the first to support cardinality estimation (CE) for a query set on multiple datasets, as previous studies only support CE for a single query on a single dataset, and cannot effectively identify query result overlaps in multiple datasets.
Extensive experiments using five real-world data pools demonstrate that our greedy algorithm using ML-based distinctiveness estimation outperforms all other baselines in both effectiveness and efficiency.",[''],"['University', 'Wollongong', 'University', 'Queensland', 'CSIRO', 'CSIRO']"
,[''],[]
"With the increasing number of fast-electric vehicle charging stations (fast-EVCSs) and the popularization of information technology, electricity price competition between fast-EVCSs is highly expected, in which the utilization of public and/or privacy-preserved information will play a crucial role. Self-interest electric vehicle (EV) users, on the other hand, try to select a fast-EVCS for charging in a way to maximize their utilities based on electricity price, estimated waiting time, and their state of charge. While existing studies have largely focused on finding equilibrium prices, this study proposes a personalized dynamic pricing policy (PeDP) for a fast-EVCS to maximize revenue using a reinforcement learning (RL) approach. We first propose a multiple fast-EVCSs competing simulation environment to model the selfish behavior of EV users using a game-based charging station selection model with a monetary utility function. In the environment, we propose a Q-learning-based PeDP to maximize fast-EVCS’ revenue. Through numerical simulations based on the environment: (1) we identify the importance of waiting time in the EV charging market by comparing the classic Bertrand competition model with the proposed PeDP for fast-EVCSs (from the system perspective); (2) we evaluate the performance of the proposed PeDP and analyze the effects of the information on the policy (from the service provider perspective); and (3) it can be seen that privacy-preserved information sharing can be misused by artificial intelligence-based PeDP in a certain situation in the EV charging market (from the customer perspective).",[''],[]
"Automatic recognition of dysarthric speech remains a highly challenging task to date.
Neuro-motor conditions and co-occurring physical disabilities create difficulty in large-scale data collection for ASR system development.
Adapting SSL pre-trained ASR models to limited dysarthric speech via data-intensive parameter fine-tuning leads to poor generalization.
To this end, this paper presents an extensive comparative study of various data augmentation approaches to improve the robustness of pre-trained ASR model fine-tuning to dysarthric speech.
These include: a) conventional speaker-independent perturbation of impaired speech; b) speaker-dependent speed perturbation, or GAN-based adversarial perturbation of normal, control speech based on their time alignment against parallel dysarthric speech; c) novel Spectral basis GAN-based adversarial data augmentation operating on non-parallel data.
Experiments conducted on the UASpeech corpus suggest GAN-based data augmentation consistently outperforms fine-tuned Wav2vec2.0 and HuBERT models using no data augmentation and
speed perturbation across different data expansion operating points by statistically significant word error rate (WER) reductions up to 2.01% and 0.96% absolute (9.03% and 4.63% relative) respectively on the UASpeech test set of 16 dysarthric speakers.
After cross-system outputs rescoring, the best system produced the lowest published WER of 16.53% (46.47% on very low intelligibility) on UASpeech.",[''],[]
"The recent transformer-based models have dominated the Referring Video Object Segmentation (RVOS) task due to the superior performance. Most prior works adopt unified DETR framework to generate segmentation masks in query-to-instance manner. In this work, we integrate strengths of that leading RVOS models to build up an effective paradigm. We first obtain binary mask sequences from the RVOS models. To improve the consistency and quality of masks, we propose Two-Stage Multi-Model Fusion strategy. Each stage rationally ensembles RVOS models based on framework design as well as training strategy, and leverages different video object segmentation (VOS) models to enhance mask coherence by object propagation mechanism. Our method achieves 75.7%percent75.775.7\%75.7 % 𝒥&ℱ𝒥ℱ\mathcal{J}\&\mathcal{F}caligraphic_J & caligraphic_F on Ref-Youtube-VOS validation set and 70%percent7070\%70 % 𝒥&ℱ𝒥ℱ\mathcal{J}\&\mathcal{F}caligraphic_J & caligraphic_F on test set, which ranks 1st place on 5th Large-scale Video Object Segmentation Challenge (ICCV 2023) track 3. Code is available at https://github.com/RobertLuo1/iccv2023_RVOS_Challenge.",[''],[]
,[''],[]
"We present a deterministic n2+o⁢(1)superscript𝑛2𝑜1n^{2+o(1)}italic_n start_POSTSUPERSCRIPT 2 + italic_o ( 1 ) end_POSTSUPERSCRIPT-time algorithm that approximates the crossing number of any graph G𝐺Gitalic_G of order n𝑛nitalic_n up to an additive error of o⁢(n4)𝑜superscript𝑛4o(n^{4})italic_o ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ). We also provide a randomized polynomial-time algorithm that constructs a drawing of G𝐺Gitalic_G with cr⁢(G)+o⁢(n4)cr𝐺𝑜superscript𝑛4\text{cr}(G)+o(n^{4})cr ( italic_G ) + italic_o ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) crossings. These results are made interesting by the well known fact that every dense n𝑛nitalic_n-vertex graph has crossing number Θ⁢(n4)Θsuperscript𝑛4\Theta(n^{4})roman_Θ ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ). Our work builds on a technique developed by Fox, Pach and Súk [18], who obtained very similar results for the rectilinear crossing number.
The results in [18] and in this paper imply that the (normalized) crossing and rectilinear crossing numbers are estimable parameters. Motivated by this, we introduce two graphon parameters, the crossing density and the rectilinear crossing density, and then we prove that, in a precise sense, these are the correct continuous analogs of the crossing and rectilinear crossing numbers of graphs.",[''],[]
"In this work, we study the δ𝛿\deltaitalic_δ-chromatic number of a graph which is the chromatic number of the δ𝛿\deltaitalic_δ-complement of a graph.
We give a structure of the δ𝛿\deltaitalic_δ-complements and sharp bounds on the δ𝛿\deltaitalic_δ-chromatic numbers of the Cartesian products of graphs.
Furthermore, we compute the δ𝛿\deltaitalic_δ-chromatic numbers of various classes of Cartesian product graphs, including the Cartesian products between cycles, paths, and stars.",[''],[]
"Monte Carlo integration is fundamental in scientific and statistical computation, but requires reliable samples from the target distribution, which poses a substantial challenge in the case of multi-modal distributions. Existing methods often involve time-consuming tuning, and typically lack tailored estimators for efficient use of the samples. This paper adapts the Warp-U transformation (Wang et al., 2022) to form multi-modal sampling strategy called Warp-U sampling. It constructs a stochastic map to transport a multi-modal density into a uni-modal one, and subsequently inverts the transport but with new stochasticity injected. For efficient use of the samples for normalising constant estimation, we propose (i) an unbiased estimation scheme based coupled chains, where the Warp-U sampling is used to reduce the coupling time; and (ii) a stochastic Warp-U bridge sampling estimator, which improves its deterministic counterpart given in Wang et al. (2022). Our overall approach requires less tuning and is easier to apply than common alternatives. Theoretically, we establish the ergodicity of our sampling algorithm and that our stochastic Warp-U bridge sampling estimator has greater (asymptotic) precision per CPU second compared to the Warp-U bridge estimator of Wang et al. (2022) under practical conditions. The advantages and current limitations of our approach are demonstrated through simulation studies and an application to exoplanet detection.",[''],[]
,[''],[]
"In this article, we firstly analyze the electromagnetic form factors of the vector heavy-light mesons to the pseudoscalar heavy-light mesons in the framework of three-point QCD sum rules, where the contributions of vacuum condensate terms ⟨q¯⁢q⟩delimited-⟨⟩¯𝑞𝑞\langle\overline{q}q\rangle⟨ over¯ start_ARG italic_q end_ARG italic_q ⟩, ⟨q¯⁢gs⁢σ⁢G⁢q⟩delimited-⟨⟩¯𝑞subscript𝑔𝑠𝜎𝐺𝑞\langle\overline{q}g_{s}\sigma Gq\rangle⟨ over¯ start_ARG italic_q end_ARG italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_σ italic_G italic_q ⟩, ⟨gs2⁢G2⟩delimited-⟨⟩superscriptsubscript𝑔𝑠2superscript𝐺2\langle g_{s}^{2}G^{2}\rangle⟨ italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⟩, ⟨f3⁢G3⟩delimited-⟨⟩superscript𝑓3superscript𝐺3\langle f^{3}G^{3}\rangle⟨ italic_f start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ⟩ and ⟨q¯⁢q⟩⁢⟨gs2⁢G2⟩delimited-⟨⟩¯𝑞𝑞delimited-⟨⟩superscriptsubscript𝑔𝑠2superscript𝐺2\langle\overline{q}q\rangle\langle g_{s}^{2}G^{2}\rangle⟨ over¯ start_ARG italic_q end_ARG italic_q ⟩ ⟨ italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_G start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⟩ are considered. With these results, we also obtain the radiative decay widths of the vector heavy-light mesons and then compare our results with those of other collaboration’s. The final results about the radiative decay widths are Γ⁢(D*0→D0⁢γ)=1.74−0.37+0.40Γ→superscript𝐷absent0superscript𝐷0𝛾subscriptsuperscript1.740.400.37\Gamma(D^{*0}\to D^{0}\gamma)=1.74^{+0.40}_{-0.37}roman_Γ ( italic_D start_POSTSUPERSCRIPT * 0 end_POSTSUPERSCRIPT → italic_D start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_γ ) = 1.74 start_POSTSUPERSCRIPT + 0.40 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.37 end_POSTSUBSCRIPT keV, Γ⁢(D*+→D+⁢γ)=0.17−0.07+0.08Γ→superscript𝐷absentsuperscript𝐷𝛾subscriptsuperscript0.170.080.07\Gamma(D^{*+}\to D^{+}\gamma)=0.17^{+0.08}_{-0.07}roman_Γ ( italic_D start_POSTSUPERSCRIPT * + end_POSTSUPERSCRIPT → italic_D start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_γ ) = 0.17 start_POSTSUPERSCRIPT + 0.08 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.07 end_POSTSUBSCRIPT keV, Γ⁢(Ds*→Ds⁢γ)=0.027−0.026+0.062Γ→superscriptsubscript𝐷𝑠subscript𝐷𝑠𝛾subscriptsuperscript0.0270.0620.026\Gamma(D_{s}^{*}\to D_{s}\gamma)=0.027^{+0.062}_{-0.026}roman_Γ ( italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT → italic_D start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_γ ) = 0.027 start_POSTSUPERSCRIPT + 0.062 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.026 end_POSTSUBSCRIPT keV, Γ⁢(B*0→B0⁢γ)=0.018−0.005+0.006Γ→superscript𝐵absent0superscript𝐵0𝛾subscriptsuperscript0.0180.0060.005\Gamma(B^{*0}\to B^{0}\gamma)=0.018^{+0.006}_{-0.005}roman_Γ ( italic_B start_POSTSUPERSCRIPT * 0 end_POSTSUPERSCRIPT → italic_B start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_γ ) = 0.018 start_POSTSUPERSCRIPT + 0.006 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.005 end_POSTSUBSCRIPT keV, Γ⁢(B*+→B+⁢γ)=0.015−0.007+0.007Γ→superscript𝐵absentsuperscript𝐵𝛾subscriptsuperscript0.0150.0070.007\Gamma(B^{*+}\to B^{+}\gamma)=0.015^{+0.007}_{-0.007}roman_Γ ( italic_B start_POSTSUPERSCRIPT * + end_POSTSUPERSCRIPT → italic_B start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_γ ) = 0.015 start_POSTSUPERSCRIPT + 0.007 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.007 end_POSTSUBSCRIPT keV and Γ⁢(Bs*→Bs⁢γ)=0.016−0.004+0.003Γ→subscriptsuperscript𝐵𝑠subscript𝐵𝑠𝛾subscriptsuperscript0.0160.0030.004\Gamma(B^{*}_{s}\to B_{s}\gamma)=0.016^{+0.003}_{-0.004}roman_Γ ( italic_B start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT → italic_B start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_γ ) = 0.016 start_POSTSUPERSCRIPT + 0.003 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 0.004 end_POSTSUBSCRIPT keV.",[''],['China']
"Metabolic cybergenetics is a promising concept that interfaces gene expression and cellular metabolism with computers for real-time dynamic metabolic control. The focus is on control at the transcriptional level, serving as a means to modulate intracellular metabolic fluxes. Recent strategies in this field have employed constraint-based dynamic models for process optimization, control, and estimation. However, this results in bilevel dynamic optimization problems, which pose considerable numerical and conceptual challenges. In this study, we present an alternative hybrid physics-informed dynamic modeling framework for metabolic cybergenetics, aimed at simplifying optimization, control, and estimation tasks. By utilizing machine-learning surrogates, our approach effectively embeds the physics of metabolic networks into the process rates of structurally simpler macro-kinetic models coupled with gene expression. These surrogates, informed by flux balance analysis, link the domains of manipulatable intracellular enzymes to metabolic exchange fluxes. This ensures that critical knowledge captured by the system’s metabolic network is preserved. The resulting models can be integrated into metabolic cybergenetic schemes involving single-level optimizations. Additionally, the hybrid modeling approach maintains the number of system states at a necessary minimum, easing the burden of process monitoring and estimation. Our hybrid physics-informed metabolic cybergenetic framework is demonstrated using a computational case study on the optogenetically-assisted production of itaconate by Escherichia coli.",[''],"['USA', 'USA']"
,[''],[]
"In this paper, we propose an orthogonal block wise Kaczmarz (POBK) algorithm based on preprocessing techniques to solve large-scale sparse linear systems A⁢x=f𝐴𝑥𝑓Ax=fitalic_A italic_x = italic_f. Firstly, the Reverse Cuthill McKee Algorithm (RCM) algorithm is used to preprocess the linear system, and then a new partitioning strategy is proposed to divide orthogonal blocks into one category, in order to accelerate the convergence rate of the Kaczmarz algorithm. The convergence of the POBK algorithm has been theoretically proven, and a theoretical analysis of its faster convergence is also provided. In addition, the experimental results confirm that this algorithm is far superior to GRBK, RBK(k), and GREBK(k) algorithms in both iteration steps (IT) and CPU time aspects.",[''],[]
"We prove a large deviation principle for the slow-fast rough differential equations under the controlled rough path framework. The driver rough paths are lifted from the mixed fractional Brownian motion with Hurst parameter H∈(1/3,1/2)𝐻1312H\in(1/3,1/2)italic_H ∈ ( 1 / 3 , 1 / 2 ). Our approach is based on the continuity of the solution mapping and the variational framework for mixed fractional Brownian motion. By utilizing the variational representation, our problem is transformed into a qualitative property of the controlled system. In particular, the fast rough differential equation coincides with Itô SDE almost surely, which possesses a unique invariant probability measure with frozen slow component. We then demonstrate the weak convergence of the controlled slow component by averaging with respect to the invariant measure of the fast equation and exploiting the continuity of the solution mapping.

Keywords.
Rough paths, Slow-fast system, Large deviation principle, Fractional Brownian motion, Weak convergence.
AMS Math Classification.
60F10, 60G15, 60H10.",[''],[]
,[''],"['India', 'Singapore', 'India', 'India', 'Singapore', 'India']"
"Exploring continuous time crystals (CTCs) within the symmetric subspace of spin systems has been a subject of intensive research in recent times. Thus far, the stability of the time-crystal phase outside the symmetric subspace in such spin systems has gone largely unexplored. Here, we investigate the effect of including the asymmetric subspaces on the dynamics of CTCs in a driven dissipative spin model. This results in multistability, and the dynamics becomes dependent on the initial state. Remarkably, this multistability leads to exotic synchronization regimes such as chimera states and cluster synchronization in an ensemble of coupled identical CTCs.",[''],"['Switzerland', 'India', 'Japan', 'Japan', 'Switzerland', 'India', 'India', '117543']"
":Pre-training, which utilizes extensive and varied datasets, is a critical factor in the success of Large Language Models (LLMs) across numerous applications. However, the detailed makeup of these datasets is often not disclosed, leading to concerns about data security and potential misuse. This is particularly relevant when copyrighted material, still under legal protection, is used inappropriately, either intentionally or unintentionally, infringing on the rights of the authors.
In this paper, we introduce a detailed framework designed to detect and assess the presence of content from potentially copyrighted books within the training datasets of LLMs. This framework also provides a confidence estimation for the likelihood of each content sample’s inclusion. To validate our approach, we conduct a series of simulated experiments, the results of which affirm the framework’s effectiveness in identifying and addressing instances of content misuse in LLM training processes. Furthermore, we investigate the presence of recognizable quotes from famous literary works within these datasets. The outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of LLMs, highlighting the need for more transparent and responsible data management practices in this field.",[''],"['TelecommunicationsChina', 'UniversitySingapore', 'UniversitySingaporeSingapore', 'TechnologyChina', 'WalesAustralia', 'UniversitySingapore', 'UniversitySingapore', 'ShenzhenChina', 'TelecommunicationsChina', 'TechnologyChina']"
"Let Qi⁢(i=1,2)subscript𝑄𝑖𝑖12Q_{i}(i=1,2)italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_i = 1 , 2 ) be 2⁢g2𝑔2g2 italic_g dimensional quadrics in ℙ2⁢g+1superscriptℙ2𝑔1\mathbb{P}^{2g+1}blackboard_P start_POSTSUPERSCRIPT 2 italic_g + 1 end_POSTSUPERSCRIPT and let Y𝑌Yitalic_Y be the smooth intersection Q1∩Q2subscript𝑄1subscript𝑄2Q_{1}\cap Q_{2}italic_Q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∩ italic_Q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. We associate the linear subspace in Y𝑌Yitalic_Y with vector bundles on the hyperelliptic curve C𝐶Citalic_C of genus g𝑔gitalic_g by the left adjoint functor of Φ:Db⁢(C)→Db⁢(Y):Φ→superscript𝐷𝑏𝐶superscript𝐷𝑏𝑌\Phi:D^{b}(C)\rightarrow D^{b}(Y)roman_Φ : italic_D start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ( italic_C ) → italic_D start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ( italic_Y ). As an application, we give a different proof of the classification of line bundles and stable bundles of rank 2222 on hyperelliptic curves given by Desale and Ramanan. When g=3𝑔3g=3italic_g = 3, we show that the projection functor induces a closed embedding α:Y→S⁢UCs⁢(4,h):𝛼→𝑌𝑆subscriptsuperscript𝑈𝑠𝐶4ℎ\alpha:Y\rightarrow SU^{s}_{C}(4,h)italic_α : italic_Y → italic_S italic_U start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( 4 , italic_h ) into the moduli space of stable bundles on C𝐶Citalic_C of rank 4444 of fixed determinant.","['Key words and phrases:', 'Derived categories,', 'Kuznetsov components, intersection of quadrics, linear subspaces, moduli space of vector bundles']",[]
,[''],[]
"Let 𝔤𝔤\mathfrak{g}fraktur_g be a complex finite-dimensional simple Lie algebra and let 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT be the corresponding generalized Takiff algebra. This paper studies the affine variety 𝐟+𝔟l𝐟subscript𝔟𝑙{\bf f}+\mathfrak{b}_{l}bold_f + fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT where 𝐟𝐟{\bf f}bold_f is similar to a principal nilpotent element of 𝔤𝔤\mathfrak{g}fraktur_g and 𝔟lsubscript𝔟𝑙\mathfrak{b}_{l}fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT is a subalgebra corresponding to the Borel subalgebra 𝔟𝔟\mathfrak{b}fraktur_b of 𝔤𝔤\mathfrak{g}fraktur_g. Inspired by Kostant’s work then we deal with two questions. One of them is to construct the Whittaker model for the Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT-invariants of symmetric algebra S⁢(𝔤l)𝑆subscript𝔤𝑙S(\mathfrak{g}_{l})italic_S ( fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) where Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT is the adjoint group of 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT and Glsubscript𝐺𝑙G_{l}italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT acts on S⁢(𝔤l)𝑆subscript𝔤𝑙S(\mathfrak{g}_{l})italic_S ( fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) by coadjoint action, and then to classify all nonsingular Whittaker modules over 𝔤lsubscript𝔤𝑙\mathfrak{g}_{l}fraktur_g start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT. Another one is to describe the symplectic structure of the manifold Z⊆𝐟+𝔟l𝑍𝐟subscript𝔟𝑙Z\subseteq{\bf f}+\mathfrak{b}_{l}italic_Z ⊆ bold_f + fraktur_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT of normalized Jacobi elements. Then the Hamiltonian corresponding to a fundamental invariant provides a class of hyperbolic Toda lattices. In particular, a simplest example describes the state of a dynamical system consisting of a positive mass particle and a negative mass particle.",[''],[]
"Several works related to crowdsourcing have been proposed in the direction where the task executers are to perform the tasks within the stipulated
deadlines. Though the deadlines are set, it may be a practical scenario that
majority of the task executers submit the tasks as late as possible. This
situation where the task executers may delay their task submission is termed
as procrastination in behavioural economics. In many applications, these
late submission of tasks may be problematic for task providers. So here, the
participating agents (both task providers and task executers) are articulated
with the procrastination issue. In literature, how to prevent this procrastina-
tion within the deadline is not addressed in crowdsourcing scenario. However,
in a bipartite graph setting one procrastination aware scheduling is proposed
but balanced job (task and job will synonymously be used) distribution in
different slots (also termed as schedules) is not considered there. In this
paper, a procrastination aware scheduling of jobs is proliferated by propos-
ing an (randomized) algorithm in crowdsourcing scenario (also applicable in
mobile and spatial crowdsourcing). Our algorithm ensures that balancing of
jobs in different schedules are maintained. Our scheme is compared with the
existing algorithm through extensive simulation and in terms of balancing
effect, our proposed algorithm outperforms the existing one. Analytically it
is shown that our proposed algorithm maintains the balanced distribution.",[''],"['[', '[']"
"This paper proposes a smooth-trajectory estimator for the labelled multi-Bernoulli (LMB) filter by exploiting the special structure of the generalised labelled multi-Bernoulli (GLMB) filter. We devise a simple and intuitive approach to store the best association map when approximating the GLMB random finite set (RFS) to the LMB RFS. In particular, we construct a smooth-trajectory estimator (i.e., an estimator over the entire trajectories of labelled estimates) for the LMB filter based on the history of the best association map and all of the measurements up to the current time. Experimental results under two challenging scenarios demonstrate significant tracking accuracy improvements with negligible additional computational time compared to the conventional LMB filter. The source code is publicly available at https://tinyurl.com/ste-lmb, aimed at promoting advancements in MOT algorithms.","['Index', 'Terms: ', 'Labelled multi-Bernoulli filter, estimator, smoothing,', 'STE-LMB,', 'RFS.']",[]
"Sequences with low/zero ambiguity zone (LAZ/ZAZ) properties are useful for modern wireless communication and radar systems operating in mobile environments.
This paper first presents a new family of ZAZ sequence sets by generalizing an earlier construction of zero correlation zone (ZCZ) sequences arising from perfect nonlinear functions. We then introduce a second family of ZAZ sequence sets with comb-like spectrum, whereby the local Doppler resilience is ensured by their inherent spectral nulls in the frequency-domain.
Finally, LAZ sequence sets are obtained thanks to its connection with a novel class of mapping functions.
These proposed unimodular ZAZ and LAZ sets are cyclically distinct and asymptotically optimal with respect to the existing theoretical bounds.","['Index', 'Terms: ', 'Unimodular sequence, low ambiguity zone (LAZ), zero ambiguity zone (ZAZ), comb-like spectrum, wireless communication, radar system.']",[]
,[''],[]
"Space AI has become increasingly important and sometimes even necessary for government, businesses, and society. An active research topic under this mission is integrating federated learning (FL) with satellite communications (SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively train a machine learning model. However, the special communication environment of SatCom leads to a very slow FL training process up to days and weeks. This paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed parameter servers (𝒫⁢𝒮𝒫𝒮\mathcal{PS}caligraphic_P caligraphic_Ss) to enhance satellite visibility, and (2) introduces non-orthogonal multiple access (NOMA) into LEO to enable fast and bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a new communication topology that exploits HAPs to bridge satellites among different orbits to mitigate the Doppler shift, and (4) a new FL model aggregation scheme that optimally balances models between different orbits and shells. Moreover, we (5) derive a closed-form expression of the outage probability for satellites in near and far shells, as well as for the entire system. Our extensive simulations have validated the mathematical analysis and demonstrated the superior performance of NomaFedHAP in achieving fast and efficient FL model convergence with high accuracy as compared to the state-of-the-art.","['Index', 'Terms: ', 'Low', 'Earth orbit (LEO), federated', 'Learning, high altitude platform (HAP), non-orthogonal multiple', 'Access (NOMA).']",[]
"In the present paper, we investigate some exact cosmological models in Myrzakulov F⁢(R,T)𝐹𝑅𝑇F(R,T)italic_F ( italic_R , italic_T ) gravity theory. We have considered the arbitrary function F⁢(R,T)=R+λ⁢T𝐹𝑅𝑇𝑅𝜆𝑇F(R,T)=R+\lambda Titalic_F ( italic_R , italic_T ) = italic_R + italic_λ italic_T where λ𝜆\lambdaitalic_λ is an arbitrary constant, R,T𝑅𝑇R,Titalic_R , italic_T are respectively, the Ricci-scalar curvature and the torsion. We have solved the field equations in a flat FLRW spacetime manifold for Hubble parameter and using the MCMC analysis, we have estimated the best fit values of model parameters with 1−σ,2−σ,3−σ1𝜎2𝜎3𝜎1-\sigma,2-\sigma,3-\sigma1 - italic_σ , 2 - italic_σ , 3 - italic_σ regions, for two observational datasets like H⁢(z)𝐻𝑧H(z)italic_H ( italic_z ) and Pantheon SNe Ia datasets. Using these best fit values of model parameters, we have done the result analysis and discussion of the model. We have found a transit phase decelerating-accelerating universe model with transition redshifts zt=0.532,0.435subscript𝑧𝑡0.5320.435z_{t}=0.532,0.435italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.532 , 0.435. The effective dark energy equation of state varies as −1≤ωd⁢e≤−0.9931subscript𝜔𝑑𝑒0.993-1\leq\omega_{de}\leq-0.993- 1 ≤ italic_ω start_POSTSUBSCRIPT italic_d italic_e end_POSTSUBSCRIPT ≤ - 0.993 and the present age of the universe is found as t0=13.92,13.65subscript𝑡013.9213.65t_{0}=13.92,13.65italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 13.92 , 13.65 Gyrs, respectively for two datasets.",[''],[]
"We estimate the Big Bang nucleosynthesis (BBN) constraint on the majoron-like particle J𝐽Jitalic_J in the mass range between 1⁢MeV1MeV1\,{\rm MeV}1 roman_MeV to 10⁢GeV10GeV10\,{\rm GeV}10 roman_GeV which dominantly decays into the standard model neutrinos.
For a lifetime shorter than 1⁢sec1sec1\,{\rm sec}1 roman_sec, the majoron heats up the background plasma by injecting neutrinos and changes the relation of photon temperature and background neutrino temperature, resulting in a deficit of \ce⁢H4⁢e\cesuperscript𝐻4𝑒\ce{{}^{4}He}start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT italic_H italic_e abundance and an enhancement of deuterium abundance.
When the majoron lifetime is longer than 1⁢sec1sec1\,{\rm sec}1 roman_sec, the injected neutrinos directly convert protons to neutrons, and consequently, the deuterium becomes overabundant.
In both cases, the overabundance of deuterium provides the strongest constraint and it excludes the parameter range where the \ce⁢L7⁢i\cesuperscript𝐿7𝑖\ce{{}^{7}Li}start_FLOATSUPERSCRIPT 7 end_FLOATSUPERSCRIPT italic_L italic_i abundance can be explained.
We also estimate other cosmological constraints and compare them with the BBN bound.",[''],"['Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea', 'Korea']"
"Hypergraphs are a representation of complex systems involving interactions among more than two entities and allow to investigation of higher-order structure and dynamics in real-world complex systems.
Community structure is a common property observed in empirical networks in various domains.
Stochastic block models have been employed to investigate community structure in networks.
Node attribute data, often accompanying network data, has been found to potentially enhance the learning of community structure in dyadic networks.
In this study, we develop a statistical framework that incorporates node attribute data into the learning of community structure in a hypergraph, employing a stochastic block model.
We demonstrate that our model, which we refer to as HyperNEO, enhances the learning of community structure in synthetic and empirical hypergraphs when node attributes are sufficiently associated with the communities.
Furthermore, we found that applying a dimensionality reduction method, UMAP, to the learned representations obtained using stochastic block models, including our model, maps nodes into a two-dimensional vector space while largely preserving community structure in empirical hypergraphs.
We expect that our framework will broaden the investigation and understanding of higher-order community structure in real-world complex systems.",[''],"['Japan.', 'nakajima@tmu.ac.jp', 'Japan.']"
"The revolution of natural language processing via large language models has motivated its use in multidisciplinary areas that include social sciences and humanities and more specifically, comparative religion. Sentiment analysis provides a mechanism to study the emotions expressed in text. Recently, sentiment analysis has been used to study and compare translations of the Bhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we use sentiment analysis for studying selected chapters of the Bible. These chapters are known as the Sermon on the Mount. We utilize a pre-trained language model for sentiment analysis by reviewing five translations of the Sermon on the Mount, which include the King James version, the New International Version, the New Revised Standard Version, the Lamsa Version, and the Basic English Version. We provide a chapter-by-chapter and verse-by-verse comparison using sentiment and semantic analysis and review the major sentiments expressed. Our results highlight the varying sentiments across the chapters and verses. We found that the vocabulary of the respective translations is significantly different. We detected different levels of humour, optimism, and empathy in the respective chapters that were used by Jesus to deliver his message.",[''],[]
"While large language models (LLMs) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. As a significant aspect of LLM alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of LLMs. To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs’ responses to instructions with various constraints. We construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. Specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. Finally, we automate the entire evaluation process to facilitate further developments. Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time. We provide extensive evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs. We believe this benchmark will facilitate research into improving the controllability of LLMs’ responses to instructions. Our data and code are available at https://github.com/Xt-cyh/CoDI-Eval.",[''],[]
,[''],"['Engineering', 'Engineering']"
"Cancer diagnosis is a well-studied problem in machine learning since early detection of cancer is often the determining factor in prognosis. Supervised deep learning achieves excellent results in cancer image classification, usually through transfer learning. However, these models require large amounts of labelled data and for several types of cancer, large labelled datasets do not exist.
In this paper, we demonstrate that a model pre-trained using a self-supervised learning algorithm known as Barlow Twins can outperform the conventional supervised transfer learning pipeline. We juxtapose two base models: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a self-supervised fashion on ImageNet. Both are subsequently fine tuned on a small labelled skin lesion dataset and evaluated on a large test set.
We achieve a mean test accuracy of 70% for self-supervised transfer in comparison to 66% for supervised transfer. Interestingly, boosting performance further is possible by self-supervised pretraining a second time (on unlabelled skin lesion images) before subsequent fine tuning. This hints at an alternative path to collecting more labelled data in settings where this is challenging - namely just collecting more unlabelled images. Our framework is applicable to cancer image classification models in the low-labelled data regime.",[''],['[']
"Non-decoupling effects of heavy scalars and vector fields play an important role
in the indirect search of Beyond the Standard Model (BSM) physics at
the LHC.
By exploiting some new differential equations for the 1-PI
amplitudes, we show that such non-decoupling effects are absent
for quite a general class of effective field theories involving dimension six
two-derivatives and dimension eight
four-derivatives operators, once resummation
in certain BSM couplings is taken into account and
some particular regimes of the relevant couplings are considered.",[''],['Italy']
"We consider a rational elliptic surface with a relatively minimal fibration. We compute the number of integral sections in the above rational elliptic surface. As an application, we obtain an estimate of polynomial solutions of some equations.",[''],['China']
"Semi-Supervised Object Detection (SSOD) has achieved resounding success by leveraging unlabeled data to improve detection performance.
However, in Open Scene Semi-Supervised Object Detection (O-SSOD), unlabeled data may contains unknown objects not observed in the labeled data, which will increase uncertainty in the model’s predictions for known objects.
It is detrimental to the current methods that mainly rely on self-training, as more uncertainty leads to the lower localization and classification precision of pseudo labels.
To this end, we propose Credible Teacher, an end-to-end framework.
Credible Teacher adopts an interactive teaching mechanism using flexible labels to prevent uncertain pseudo labels from misleading the model and gradually reduces its uncertainty through the guidance of other credible pseudo labels.
Empirical results have demonstrated our method effectively restrains the adverse effect caused by O-SSOD and significantly outperforms existing counterparts.",[''],[]
"General U⁢(1)𝑈1U(1)italic_U ( 1 ) extension of the Standard Model (SM) is a well motivated beyond the Standard Model(BSM) scenario where three generations of right handed neutrinos (RHNs) are introduced to cancel gauge and mixed gauge-gravity anomalies. After the U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT is broken, RHNs participate in the seesaw mechanism to generate light neutrino masses satisfying neutrino oscillation data. In addition to that, a neutral gauge boson Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is evolved which interacts with the left and right handed fermions differently manifesting chiral nature of the model which could be probed in future collider experiments. As a result, if we consider μ+⁢e−superscript𝜇superscript𝑒\mu^{+}e^{-}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and μ+⁢μ+superscript𝜇superscript𝜇\mu^{+}\mu^{+}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT collisions in μ𝜇\muitalic_μTRISTAN experiment Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT mediated 2→2→222\to 22 → 2 scattering will appear in t−limit-from𝑡t-italic_t - and u−limit-from𝑢u-italic_u -channels depending on the initial and final states being accompanied by the photon and Z𝑍Zitalic_Z mediated interactions. This will result well motivated resulting forward dominant scenarios giving rise to sizable left-right asymmetry. Estimating constrains on general U⁢(1)𝑈1U(1)italic_U ( 1 ) coupling from LEP-II and LHC for different U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT charges, we calculate differential and integrated scattering cross section and left-right asymmetry for μ+⁢e−→μ+⁢e−→superscript𝜇superscript𝑒superscript𝜇superscript𝑒\mu^{+}e^{-}\to\mu^{+}e^{-}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT → italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and μ+⁢μ+→μ+⁢μ+→superscript𝜇superscript𝜇superscript𝜇superscript𝜇\mu^{+}\mu^{+}\to\mu^{+}\mu^{+}italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT → italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_μ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT processes which could be probed at μ𝜇\muitalic_μTRISTAN experiment further enlightening the interaction between Z′superscript𝑍′Z^{\prime}italic_Z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and charged leptons and the U⁢(1)X𝑈subscript1𝑋U(1)_{X}italic_U ( 1 ) start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT breaking scale.",[''],"['Japan', 'Japan', 'Republic']"
"The chemical compositions of stars encode the history of the universe
and are thus fundamental for advancing our knowledge of astrophysics and cosmology.
However, measurements of elemental abundances ratios, and our interpretations of them, strongly depend on the physical assumptions that dictate the generation of synthetic stellar spectra. Three-dimensional radiation-hydrodynamic (3D RHD) “box-in-a-star” simulations of stellar atmospheres offer a more realistic representation of surface convection occurring in late-type stars compared to traditional one-dimensional (1D) hydrostatic models. As evident from a multitude of observational tests, the coupling of 3D RHD models with line-formation in non-local thermodynamic equilibrium (non-LTE) today provides a solid foundation for abundance analysis for many elements. This review describes the ongoing and transformational work to advance the state-of-the-art and replace 1D LTE spectrum synthesis with its 3D non-LTE counterpart. In summary: 




•

3D and non-LTE effects are intricately coupled and consistent modelling thereof is necessary for high-precision abundances, which is currently feasible for individual elements in large surveys. Mean 3D (⟨⁢3⁢D⁢⟩⟨3D⟩\rm\textlangle 3D\textrangle{}⟨ 3 roman_D ⟩) models are not adequate as substitutes.

•

The solar abundance debate is presently dominated by choices and systematic uncertainties that are not specific to 3D non-LTE modelling.

•

3D non-LTE abundance corrections have a profound impact on our understanding of FGK-type stars, exoplanets, and the nucleosynthetic origins of the elements.",[''],"['karin.lind@astro.su.se', 'anish.amarsi@physics.uu.se']"
,[''],[]
"Quantum walks have emerged as a transformative paradigm in quantum information processing and can be applied to various graph problems. This study explores discrete-time quantum walks on simplicial complexes, a higher-order generalization of graph structures. Simplicial complexes, encoding higher-order interactions through simplices, offer a richer topological representation of complex systems. Leveraging algebraic topology and discrete-time quantum walk, we present a quantum walk algorithm for detecting higher-order community structures called simplicial communities. We utilize the Fourier coin to produce entangled translation states among adjacent simplices in a simplicial complex. The potential of our quantum algorithm is tested on Zachary’s karate club network. This study may contribute to understanding complex systems at the intersection of algebraic topology and quantum algorithms.",[''],[]
,[''],[]
"In recent years, text-to-video retrieval methods based on CLIP have experienced rapid development. The primary direction of evolution is to exploit the much wider gamut of visual and textual cues to achieve alignment. Concretely, those methods with impressive performance often design a heavy fusion block for sentence (words)-video (frames) interaction, regardless of the prohibitive computation complexity. Nevertheless, these approaches are not optimal in terms of feature utilization and retrieval efficiency.
To address this issue, we adopt multi-granularity visual feature learning, ensuring the model’s comprehensiveness in capturing visual content features spanning from abstract to detailed levels during the training phase. To better leverage the multi-granularity features, we devise a two-stage retrieval architecture in the retrieval phase. This solution ingeniously balances the coarse and fine granularity of retrieval content. Moreover, it also strikes a harmonious equilibrium between retrieval effectiveness and efficiency.
Specifically, in training phase, we design a parameter-free text-gated interaction block (TIB) for fine-grained video representation learning and embed an extra Pearson Constraint to optimize cross-modal representation learning. In retrieval phase, we use coarse-grained video representations for fast recall of top-k candidates, which are then reranked by fine-grained video representations.
Extensive experiments on four benchmarks demonstrate the efficiency and effectiveness. Notably, our method achieves comparable performance with the current state-of-the-art methods while being nearly 50 times faster.",[''],[]
"In this paper, a viscous shock wave under space-periodic perturbation
of 1-D isentropic Navier-Stokes system in the half space is investigated. It is shown that if the initial
periodic perturbation around the viscous shock wave is small, then the solution time
asymptotically tends to a viscous shock wave with a shift partially determined by the
periodic oscillations. Moreover, the strength of the shock wave could be arbitrarily large. This result essentially improves the previous work ”A. Matsumura, M. Mei, Convergence to travelling fronts of solutions of the p-system with viscosity in the presence of a boundary. Arch. Ration. Mech. Anal. 146 (1999), no. 1, 1-22.” where the strength of shock wave is sufficiently small and the initial periodic oscillations vanish.","['Key words and phrases:', 'Impermeable wall problem,', 'Large amplitude shock,', 'Space-periodic perturbation,', 'Asymptotic stability']",[]
"Black hole solutions of general relativity exhibit a symmetry for the static perturbations around these spacetimes, known as “ladder symmetry”. This symmetry proves useful in constructing a tower of solutions for perturbations and elucidating their general properties. Specifically, the presence of this symmetry leads to vanishing of the tidal love number associated with black holes. In this work, we find the most general spherical symmetric and static black hole spacetime that accommodates this ladder symmetry for scalar perturbation. Furthermore, we extend our calculations beyond spherical symmetry to find the class of stationary Konoplya-Rezzola-Zhidenko black holes, which also possess a similar ladder structure.",[''],"['India', 'India', 'India']"
,[''],[]
"Let G=(V,E)𝐺𝑉𝐸G=(V,E)italic_G = ( italic_V , italic_E ) be a connected graph and dG⁢(u,v)subscript𝑑𝐺𝑢𝑣d_{G}(u,v)italic_d start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_u , italic_v ) be the shortest distance between the vertices u𝑢uitalic_u and v𝑣vitalic_v in G𝐺Gitalic_G. A set S={s1,s2,…,sn}⊂V⁢(G)𝑆subscript𝑠1subscript𝑠2…subscript𝑠𝑛𝑉𝐺S=\{s_{1},s_{2},\ldots,s_{n}\}\subset V(G)italic_S = { italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ⊂ italic_V ( italic_G ) is said to be a resolving set if for all distinct vertices u,v𝑢𝑣u,vitalic_u , italic_v of G𝐺Gitalic_G, there exist an element s∈S𝑠𝑆s\in Sitalic_s ∈ italic_S such that d⁢(s,u)≠d⁢(s,v)𝑑𝑠𝑢𝑑𝑠𝑣d(s,u)\neq d(s,v)italic_d ( italic_s , italic_u ) ≠ italic_d ( italic_s , italic_v ). The minimum cardinality of a resolving set for a graph G𝐺Gitalic_G is called the metric dimension of G𝐺Gitalic_G and it is denoted by β⁢(G)𝛽𝐺\beta{(G)}italic_β ( italic_G ). A resolving set having β⁢(G)𝛽𝐺\beta{(G)}italic_β ( italic_G ) number of vertices is named as metric basis of G𝐺Gitalic_G. The metric dimension problem is to find a metric basis in a graph G𝐺Gitalic_G, and it has several real-life applications in network theory, telecommunication,
image processing, pattern recognition, and many other fields. In this article, we
consider cube of trees T3=(V,E)superscript𝑇3𝑉𝐸T^{3}=(V,E)italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT = ( italic_V , italic_E ), where any two vertices u,v𝑢𝑣u,vitalic_u , italic_v are adjacent if and only if the distance between them is less than equal to three in T𝑇Titalic_T.
We establish the necessary and sufficient conditions of a vertex subset of V𝑉Vitalic_V to become a resolving set for T3superscript𝑇3T^{3}italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. This helps determine the tight bounds (upper and lower) for the metric dimension of T3superscript𝑇3T^{3}italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. Then, for certain well-known cubes of trees, such as caterpillars, lobsters, spiders, and d𝑑ditalic_d-regular trees, we establish the boundaries of the metric dimension. Further, we characterize some restricted families of cube of trees satisfying
β⁢(T3)=β⁢(T)𝛽superscript𝑇3𝛽𝑇\beta{(T^{3})}=\beta{(T)}italic_β ( italic_T start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) = italic_β ( italic_T ). We provide a construction showing the existence of a cube of tree attaining every positive integer value as their metric dimension.",[''],[]
,[''],[]
"We implement a test of MOND and Verlinde’s Emergent Gravity using the galaxy cluster SMACS J0723-7327, which has been recently imaged using the eROSITA X-ray telescope as well as with JWST. We test MOND using two independent methods. The first method involves comparing the dynamical MOND mass and baryonic mass, while the second method entails a comparison of the MOND-estimated temperature with the observed temperature. We then compare the unseen mass predicted by Emergent Gravity with the estimated dark matter mass. We find that MOND is able to explain the mass discrepancy at large radii but not in the central regions. The observed temperature profile is also in slight disagreement with that in the MOND paradigm. Likewise the Emergent Gravity Theory shows a marginal discrepancy in accurately accounting for the dynamical mass in the inner regions. Our results are qualitatively consistent with the earlier tests on other clusters.",[''],"['ep21btech11007@iith.ac.in', 'shntn05@gmail.com', 'India']"
"Nonlocal self-similarity (NSS) is an important prior that has been successfully applied in multi-dimensional data processing tasks, e.g., image and video recovery. However, existing NSS-based methods are solely suitable for meshgrid data such as images and videos, but are not suitable for emerging off-meshgrid data, e.g., point cloud and climate data. In this work, we revisit the NSS from the continuous representation perspective and propose a novel Continuous Representation-based NonLocal method (termed as CRNL), which has two innovative features as compared with classical nonlocal methods. First, based on the continuous representation, our CRNL unifies the measure of self-similarity for on-meshgrid and off-meshgrid data and thus is naturally suitable for both of them. Second, the nonlocal continuous groups can be more compactly and efficiently represented by the coupled low-rank function factorization, which simultaneously exploits the similarity within each group and across different groups, while classical nonlocal methods neglect the similarity across groups. This elaborately designed coupled mechanism allows our method to enjoy favorable performance over conventional NSS methods in terms of both effectiveness and efficiency. Extensive multi-dimensional data processing experiments on-meshgrid (e.g., image inpainting and image denoising) and off-meshgrid (e.g., climate data prediction and point cloud recovery) validate the versatility, effectiveness, and efficiency of our CRNL as compared with state-of-the-art methods.","['Index', 'Terms: ', 'Nonlocal self-similarity,\nlow-rank model,\ntensor', 'Tucker factorization\nimage restoration,\nmultivariate regression.']",[]
"The aim of this article is to study the Clairaut anti-invariant Riemannian maps from/to Kähler manifolds admitting Ricci solitons. We find the curvature relations and calculate the Ricci tensor under different conditions. We obtain conditions for the range and kernel of these maps to be Einstein. Next, we find the scalar curvature for range. Finally, we give some non-trivial examples of Clairaut anti-invariant Riemannian maps from/to Kähler manifolds admitting Ricci solitons.",[''],[]
"Integer sorting is a fundamental problem in computer science.
This paper studies parallel integer sort both in theory and in practice.
In theory, we show tighter bounds for a class of
existing practical integer sort algorithms, which provides a solid
theoretical foundation for their widespread usage
in practice and strong performance.
In practice, we design a new integer sorting algorithm,
DovetailSort, that is theoretically-efficient and has good practical performance.
In particular, DovetailSort overcomes a common challenge in existing
parallel integer sorting algorithms, which is the difficulty of detecting and
taking advantage of duplicate keys.
The key insight in DovetailSort is to combine algorithmic ideas from
both integer- and comparison-sorting algorithms.
In our experiments, DovetailSort achieves competitive or better
performance than existing state-of-the-art parallel integer and
comparison sorting algorithms on various synthetic and real-world
datasets.","['Integer', 'Sort,', 'Radix', 'Sort,', 'Sorting', 'Algorithms,', 'Parallel', 'Algorithms']","['Riverside', 'Maryland', 'Riverside', 'Riverside']"
"Generating 3D human models directly from text helps reduce the cost and time of character modeling.
However, achieving multi-attribute controllable and realistic 3D human avatar generation is still challenging due to feature coupling and the scarcity of realistic 3D human avatar datasets.
To address these issues, we propose Text2Avatar, which can generate realistic-style 3D avatars based on the coupled text prompts.
Text2Avatar leverages a discrete codebook as an intermediate feature to establish a connection between text and avatars, enabling the disentanglement of features.
Furthermore, to alleviate the scarcity of realistic style 3D human avatar data, we utilize a pre-trained unconditional 3D human avatar generation model to obtain a large amount of 3D avatar pseudo data, which allows Text2Avatar to achieve realistic style generation.
Experimental results demonstrate that our method can generate realistic 3D avatars from coupled textual data, which is challenging for other existing methods in this field.",[''],[]
"In planar superconductor thin films, the places of nucleation and arrangements of moving vortices are determined by structural defects. However, various applications of superconductors require reconfigurable steering of fluxons, which is hard to realize with geometrically predefined vortex pinning landscapes. Here, on the basis of the time-dependent Ginzburg-Landau equation, we present an approach for steering of vortex chains and vortex jets in superconductor nanotubes containing a slit. The idea is based on tilting of the magnetic field 𝐁𝐁\mathbf{B}bold_B at an angle α𝛼\alphaitalic_α in the plane perpendicular to the axis of a nanotube carrying an azimuthal transport current. Namely, while at α=0∘𝛼superscript0\alpha=0^{\circ}italic_α = 0 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT vortices move paraxially in opposite directions within each half-tube, an increase of α𝛼\alphaitalic_α displaces the areas with the close-to-maximum normal component |Bn|subscript𝐵n|B_{\mathrm{n}}|| italic_B start_POSTSUBSCRIPT roman_n end_POSTSUBSCRIPT | to the close(opposite)-to-slit regions, giving rise to descending (ascending) branches in the induced-voltage frequency spectrum fU⁢(α)subscript𝑓U𝛼f_{\mathrm{U}}(\alpha)italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT ( italic_α ). At lower B𝐵Bitalic_B, upon reaching the critical angle αcsubscript𝛼c\alpha_{\mathrm{c}}italic_α start_POSTSUBSCRIPT roman_c end_POSTSUBSCRIPT, close-to-slit vortex chains disappear, yielding fUsubscript𝑓Uf_{\mathrm{U}}italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT of the n⁢f1𝑛subscript𝑓1nf_{1}italic_n italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-type (n≥1𝑛1n\geq 1italic_n ≥ 1: an integer; f1subscript𝑓1f_{1}italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: vortex nucleation frequency). At higher B𝐵Bitalic_B, fUsubscript𝑓Uf_{\mathrm{U}}italic_f start_POSTSUBSCRIPT roman_U end_POSTSUBSCRIPT is largely blurry because of multifurcations of vortex trajectories, leading to the coexistence of a vortex jet with two vortex chains at α=90∘𝛼superscript90\alpha=90^{\circ}italic_α = 90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT. In addition to prospects for tuning of GHz-frequency spectra and steering of vortices as information bits, our findings lay foundations for on-demand tuning of vortex arrangements in 3D superconductor membranes in tilted magnetic fields.",[''],"['Germany', 'Moldova', 'Austria', 'Germany', 'Moldova']"
"Intelligent Transportation System (ITS) is vital in improving traffic congestion, reducing traffic accidents, optimizing urban planning, etc.
However, due to the complexity of the traffic network, traditional machine learning and statistical methods are relegated to the background.
With the advent of the artificial intelligence era, many deep learning frameworks have made remarkable progress in various fields and are now considered effective methods in many areas.
As a deep learning method, Graph Neural Networks (GNNs) have emerged as a highly competitive method in the ITS field since 2019 due to their strong ability to model graph-related problems. As a result, more and more scholars pay attention to the applications of GNNs in transportation domains, which have shown excellent performance.
However, most of the research in this area is still concentrated on traffic forecasting, while other ITS domains, such as autonomous vehicles and urban planning, still require more attention.
This paper aims to review the applications of GNNs in six representative and emerging ITS domains: traffic forecasting, autonomous vehicles, traffic signal control, transportation safety, demand prediction, and parking management. We have reviewed extensive graph-related studies from 2018 to 2023, summarized their methods, features, and contributions, and presented them in informative tables or lists.
Finally, we have identified the challenges of applying GNNs to ITS and suggested potential future directions.","['Traffic', 'Flow', 'Prediction,', 'Graph', 'Neural', 'Network,', 'Spatio-temporal', 'Analysis']","['UniversityBeijingChina100871', 'AngelesUSA90095', 'UniversityBeijingChina100871', 'AngelesUSA90095', 'UniversityBeijingChina100871']"
"Magnetization dynamics in magnetic materials are well described by the modified semiclassical Landau-Lifshitz-Gilbert (LLG) equation, which includes the magnetic damping 𝜶^^𝜶\hat{\bm{\alpha}}over^ start_ARG bold_italic_α end_ARG and the magnetic moment of inertia 𝐈^^𝐈\hat{\bm{\mathrm{I}}}over^ start_ARG bold_I end_ARG tensors as key parameters. Both parameters are material-specific and physically represent the time scales of damping of precession and nutation in magnetization dynamics. 𝜶^^𝜶\hat{\bm{\alpha}}over^ start_ARG bold_italic_α end_ARG and 𝐈^^𝐈\hat{\bm{\mathrm{I}}}over^ start_ARG bold_I end_ARG can be calculated quantum mechanically within the framework of the torque-torque correlation model. The quantities required for the calculation are torque matrix elements, the real and imaginary parts of the Green’s function and its derivatives. Here, we calculate these parameters for the elemental magnets such as Fe, Co and Ni in an ab initio framework using density functional theory and Wannier functions. We also propose a method to calculate the torque matrix elements within the Wannier framework. We demonstrate the effectiveness of the method by comparing it with the experiments and the previous ab initio and empirical studies and show its potential to improve our understanding of spin dynamics and to facilitate the design of spintronic devices.",[''],['India']
"Context:
For decades, the spectral variations of β𝛽\beta\>italic_βPictoris have been modelled as the result of the evaporation of
exocomets close to the star, termed falling evaporating bodies (FEBs). Resonant perturbations by a
hypothetical giant planet have been proposed to explain the dynamical origin of these stargrazers. The disk is
now known to harbour two giant planets, β𝛽\beta\>italic_βPic b and c, orbiting the star at 9.9 au and 2.7 au. While the former almost matches the planet formerly suspected, the recent discovery of the latter complicates the picture.
Aims:We first question the stability of the two-planet system. Then we investigate the dynamics of a disk of
planetesimals orbiting the star together with both planets to check the validity of the FEB generation mechanism.
Methods:Symplectic N-body simulations are used to first determine which regions of the planetesimal disk are dynamically stable and which are not. Then we focus on regions where disk particles are able to reach high eccentricities, mainly thanks to resonant mechanisms.
Results:The first result is that the system is dynamically stable. Both planets may temporarily fall in 7:1 mean motion
resonance (MMR). Then, simulations with a disk of particles reveal that the whole region extending between
∼1.5similar-toabsent1.5\sim 1.5\,∼ 1.5au and ∼25similar-toabsent25\sim 25\,∼ 25au is unstable to planetary perturbations. However, a disk below 1.5 au survives, which
appears to constitute an active source of FEBs via high-order MMRs with β𝛽\beta\>italic_βPic c. In this new picture, β𝛽\beta\>italic_βPic b acts as a distant perturber that helps sustain the whole process.
Conclusions:Our new simulations rule out the preceding FEB generation mechanism model, which placed their origin
at around 4–5 au. Conversely, FEBs are likely to originate from a region much further in and related to MMRs with β𝛽\beta\>italic_βPic c. That mechanism also appears to last longer, as new planetesimals are able to continuously enter the MMRs and evolve towards the FEB state. Subsequently, the physical nature of the FEBs may differ from that previously thought, and presumably may not be icy.","['Key', 'Words.: ', 'Stars: circumstellar matter –', 'Stars: planetary systems –', 'Stars individual: β𝛽\\beta\\>italic_βPic–', 'Methods: numerical –', 'Celestial mechanics –', 'Planets and satellites: dynamical evolution and stability']",[]
"A placement of chess pieces on a chessboard is called dominating, if each
free square of the chessboard is under attack by at least one
piece. In this contribution we compute the number of dominating
arrangements of k𝑘kitalic_k rooks on an n×m𝑛𝑚n\times mitalic_n × italic_m chessboard. To this end we derive an
expression for the corresponding generating function, the
domination polynomial of the n×m𝑛𝑚n\times mitalic_n × italic_m rook graph.",[''],[]
,[''],[]
"With the increasing availability of consumer depth sensors, 3D face recognition (FR)
has attracted more and more attention. However, the data acquired by these sensors
are often coarse and noisy, making them impractical to use directly.
In this paper, we introduce an innovative Depth map denoising network (DMDNet) based on
the Denoising Implicit Image Function (DIIF) to reduce noise and enhance
the quality of facial depth images for low-quality 3D FR.
After generating clean depth faces using DMDNet,
we further design a powerful recognition network
called Lightweight Depth and Normal Fusion network (LDNFNet),
which incorporates a multi-branch fusion block to learn unique and complementary
features between different modalities such as depth and normal images.
Comprehensive experiments conducted on four distinct low-quality databases demonstrate the
effectiveness and robustness of our proposed methods.
Furthermore, when combining DMDNet and LDNFNet, we achieve state-of-the-art results on
the Lock3DFace database.",[''],[]
"In this paper, we obtain an improved upper bound involving the systole and area for the volume entropy of a Riemannian surface. As a result, we show that every orientable and closed Riemannian surface of genus g≥17𝑔17g\geq 17italic_g ≥ 17 satisfies Loewner’s systolic ratio inequality.
Keywords: Systole; Loewner’s inequality; entropy.
MSC2020: 53C23, 37C35.",[''],[]
"We present a summary of the full calculation of the axial, scalar and tensor flavor diagonal charges of the nucleon carried out using Wilson-clover fermions on eight ensembles generated using 2+1+1-flavors of highly improved staggered quarks (HISQ) by the MILC collaboration. We also give results for the 3×3333\times 33 × 3 matrix of renormalization factors between the RI-sMOM and MS¯¯MS\overline{\rm MS}over¯ start_ARG roman_MS end_ARG scheme for the 2+1 flavor theory that include flavor mixing. Preliminary results for gA,S,Tu,d,ssuperscriptsubscript𝑔𝐴𝑆𝑇𝑢𝑑𝑠g_{A,S,T}^{u,d,s}italic_g start_POSTSUBSCRIPT italic_A , italic_S , italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u , italic_d , italic_s end_POSTSUPERSCRIPT are presented in the MS¯¯MS\overline{\rm MS}over¯ start_ARG roman_MS end_ARG scheme at scale 2 GeV.",[''],[]
"Accurate medical image segmentation is essential for clinical quantification, disease diagnosis, treatment planning and many other applications. Both convolution-based and transformer-based u-shaped architectures have made significant success in various medical image segmentation tasks. The former can efficiently learn local information of images while requiring much more image-specific inductive biases inherent to convolution operation. The latter can effectively capture long-range dependency at different feature scales using self-attention, whereas it typically encounters the challenges of quadratic compute and memory requirements with sequence length increasing. To address this problem, through integrating the merits of these two paradigms in a well-designed u-shaped architecture, we propose a hybrid yet effective CNN-Transformer network, named BRAU-Net++, for an accurate medical image segmentation task. Specifically, BRAU-Net++ uses bi-level routing attention as the core building block to design our u-shaped encoder-decoder structure, in which both encoder and decoder are hierarchically constructed, so as to learn global semantic information while reducing computational complexity. Furthermore, this network restructures skip connection by incorporating channel-spatial attention which adopts convolution operations, aiming to minimize local spatial information loss and amplify global dimension-interaction of multi-scale features. Extensive experiments on three public benchmark datasets demonstrate that our proposed approach surpasses other state-of-the-art methods including its baseline: BRAU-Net under almost all evaluation metrics. We achieve the average Dice-Similarity Coefficient (DSC) of 82.47, 90.10, and 92.94 on Synapse multi-organ segmentation, ISIC-2018 Challenge, and CVC-ClinicDB, as well as the mIoU of 84.01 and 88.17 on ISIC-2018 Challenge and CVC-ClinicDB, respectively. The codes will be available on GitHub.",[''],[]
,[''],[]
"We showed with J. P. Gollin that if a (possibly infinite) homogeneous linear equation system has only the trivial solution, then there exists
an injective function from the variables to the equations such that each variable has non-zero coefficient in its image. Shortly after a more
elementary proof was found by Aharoni and Guo. In this note we present a very short matroid-theoretic proof which we believe is the simplest
possible proof of this theorem.",[''],[]
"We investigate the impact of different connectivities on the decoherence time in quantum systems under quasi-static Heisenberg noise. We considered three types of fundamental units, including node, stick and triangle and connect them into rings, chains, and trees. We find that rings exhibit greater stability compared to chains, contrary to the expectation that higher average connectivity leads to decreased stability. Additionally, the “stick” configuration is more stable than the “triangle” configuration. We also observe similar trends in entanglement entropy and return probability, indicating their potential use in characterizing decoherence time. Our findings provide insights into the interplay between connectivity and stability in quantum systems, with implications for the design of robust quantum technologies and quantum error correction strategies.",[''],"['China', 'China', 'China', 'China']"
,[''],[]
"We have analyzed Chandra and Suzaku observations of the globular cluster Terzan 6,
made when the recurrent transient GRS 1747–312 was in quiescence. Our analysis reveals the presence of a second eclipsing, bursting neutron-star low-mass X-ray binary in the central regions of the cluster, in addition to GRS 1747–312. The new source, which we name Terzan 6 X2, is located very close to GRS 1747–312 (∼similar-to\sim∼0.7″ away) in the 2021 Chandra images. The detection of a 5.14 ks-long eclipse in the light curve of X2 at a time not predicted by the ephemeris of GRS 1747–312 confirms that it is an unrelated source. Using the Suzaku light curve from 2009, which in addition to a type-I X-ray burst also showed an eclipse-like feature, we constrain the orbital period to be longer than 16.27 h. The 0.5–10 keV luminosities of X2 vary in the range of ∼similar-to\sim∼0.24–5.9×1034absentsuperscript1034\times 10^{34}× 10 start_POSTSUPERSCRIPT 34 end_POSTSUPERSCRIPT erg s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT on time scales of months to years.
We have identified a plausible optical counterpart of X2 in HST F606W and F814W images. This star varied by 2.7 mag in V606subscript𝑉606V_{\rm 606}italic_V start_POSTSUBSCRIPT 606 end_POSTSUBSCRIPT between epochs separated by years. In the cluster color-magnitude diagram, the variable counterpart lies in the blue-straggler region when it was optically bright, about 1.1–1.7 mag above the main-sequence turn-off. From the orbital period–density relation of Roche-lobe filling stars we find the mass-donor radius to be ≳0.8greater-than-or-equivalent-toabsent0.8\gtrsim 0.8≳ 0.8 R⊙subscript𝑅direct-productR_{\odot}italic_R start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.",[''],"['USA', 'USA', 'Canada', 'USA', 'Netherlands', 'Australia', 'Australia']"
"Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary diseases. However, manual interpretation of these images is time-consuming and error-prone. Automated systems utilizing convolutional neural networks (CNNs) have shown promise in improving the accuracy and efficiency of chest X-ray image classification. While previous work has mainly focused on using feature maps from the final convolution layer, there is a need to explore the benefits of leveraging additional layers for improved disease classification. Extracting robust features from limited medical image datasets remains a critical challenge. In this paper, we propose a novel deep learning-based multilayer multimodal fusion model that emphasizes extracting features from different layers and fusing them. Our disease detection model considers the discriminatory information captured by each layer. Furthermore, we propose the fusion of different-sized feature maps (FDSFM) module to effectively merge feature maps from diverse layers. The proposed model achieves a significantly higher accuracy of 97.21% and 99.60% for both three-class and two-class classifications, respectively. The proposed multilayer multimodal fusion model, along with the FDSFM module, holds promise for accurate disease classification and can also be extended to other disease classifications in chest X-ray images.",[''],"['[', '[', '[']"
"Existing deep-learning-based methods for nighttime video deraining rely on synthetic data due to the absence of real-world paired data. However, the intricacies of the real world, particularly with the presence of light effects and low-light regions affected by noise, create significant domain gaps, hampering synthetic-trained models in removing rain streaks properly and leading to over-saturation and color shifts. Motivated by this, we introduce NightRain, a novel nighttime video deraining method with adaptive-rain-removal and adaptive-correction. Our adaptive-rain-removal uses unlabeled rain videos to enable our model to derain real-world rain videos, particularly in regions affected by complex light effects. The idea is to allow our model to obtain rain-free regions based on the confidence scores. Once rain-free regions and the corresponding regions from our input are obtained, we can have region-based paired real data. These paired data are used to train our model using a teacher-student framework, allowing the model to iteratively learn from less challenging regions to more challenging regions. Our adaptive-correction aims to rectify errors in our model’s predictions, such as over-saturation and color shifts. The idea is to learn from clear night input training videos based on the differences or distance between those input videos and their corresponding predictions. Our model learns from these differences, compelling our model to correct the errors. From extensive experiments, our method demonstrates state-of-the-art performance. It achieves a PSNR of 26.73dB, surpassing existing nighttime video deraining methods by a substantial margin of 13.7%.",[''],[]
"The perfectly matched layers method is a well known truncation technique for its efficiency and convenience in numerical implementations of wave scattering problems in unbounded domains. In this paper, we study the convergence of the perfectly matched layers (PML) for wave scattering from a local perturbation of an open waveguide in ℝ+2subscriptsuperscriptℝ2\mathbb{R}^{2}_{+}blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, where the refractive index is a function which is periodic along the axis of the waveguide and equals to one above a finite height. The problem is challenging due to the existence of guided waves, and a typical way to deal with the difficulty is to apply the limiting absorption principle. Based on the Floquet-Bloch transform and a curve deformation theory, the solution from the limiting absorption principle is rewritten as the integral of a coupled family of quasi-periodic problems with respect to the quasi-periodicity parameter on a particularly designed curve. By comparing the Dirichlet-to-Neumann maps on a straight line above the locally perturbed periodic layer, we finally show that the PML method converges exponentially with respect to the PML parameter. Finally, the numerical examples are shown to illustrate the theoretical results.",[''],[]
,[''],[]
"In this work the effect of anisotropy on computational complexity is considered by CA proposal in holographic two-sided black brane dual of a strongly coupled gauge theory. It is shown that due to confinement-deconfinement phase transition there are two different behaviors: by increase in anisotropy there would be an increase in complexity growth rate in small anisotropy and a decreases in the complexity growth rate in large anisotropy. In the extreme case the very large anisotropy leads to the unity of the complexity growth rate and complexity itself, it means that in this case getting the target state from the reference state is reachable by no effort. Moreover, we suggest that 1M⁢d⁢Cd⁢t1𝑀𝑑𝐶𝑑𝑡\frac{1}{M}\frac{dC}{dt}divide start_ARG 1 end_ARG start_ARG italic_M end_ARG divide start_ARG italic_d italic_C end_ARG start_ARG italic_d italic_t end_ARG is a better representation of system degrees of freedom rather than the complexity growth rate d⁢Cd⁢t𝑑𝐶𝑑𝑡\frac{dC}{dt}divide start_ARG italic_d italic_C end_ARG start_ARG italic_d italic_t end_ARG and show that how it is related to inverse anisotropic catalysis. In addition, we consider the one-sided black brane dual to the quantum quench and showed that increase in anisotropy comes with decrease in complexity regardless of the anisotropy value which is due to the fact that the system do not experience a phase transition.",[''],['Iran']
"The distributional analysis of Euclidean algorithms was carried out by Baladi and Vallée.
They showed the asymptotic normality of the number of division steps and associated costs in the Euclidean algorithm as a random variable on the set of rational numbers with bounded denominator based on the transfer operator methods. We extend their result to the Euclidean algorithm over appropriate imaginary quadratic fields by studying dynamics of the nearest integer complex continued fraction map, which is piecewise analytic and expanding but not a full branch map. By observing a finite Markov partition with a regular CW-structure, which enables us to associate the transfer operator acting on a direct sum of spaces of C1superscript𝐶1C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT-functions, we obtain the limit Gaussian distribution as well as residual equidistribution.",[''],[]
"The structure of a network has a major effect on dynamical processes on that network. Many studies of the interplay between network structure and dynamics have focused on models of phenomena such as disease spread, opinion formation and changes, coupled oscillators, and random walks. In parallel to these developments, there have been many studies of wave propagation and other spatially extended processes on networks. These latter studies consider metric networks, in which the edges are associated with real intervals. Metric networks give a mathematical framework to describe dynamical processes that include both temporal and spatial evolution of some quantity of interest — such as the concentration of a diffusing substance or the amplitude of a wave — by using edge-specific intervals that quantify distance information between nodes. Dynamical processes on metric networks often take the form of partial differential equations (PDEs). In this paper, we present a collection of techniques and paradigmatic linear PDEs that are useful to investigate the interplay between structure and dynamics in metric networks. We start by considering a time-independent Schrödinger equation. We then use both finite-difference and spectral approaches to study the Poisson, heat, and wave equations as paradigmatic examples of elliptic, parabolic, and hyperbolic PDE problems on metric networks. Our spectral approach is able to account for degenerate eigenmodes. In our numerical experiments, we consider metric networks with up to about 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT nodes and about 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT edges. A key contribution of our paper is to increase the accessibility of studying PDEs on metric networks. Software that implements our numerical approaches is available at https://gitlab.com/ComputationalScience/metric-networks.",[''],[]
"Diffusion Models (DMs) represent a significant advancement in image Super-Resolution (SR), aligning technical image quality more closely with human preferences and expanding SR applications.
DMs address critical limitations of previous methods, enhancing overall realism and details in SR images.
However, DMs suffer from color-shifting issues, and their high computational costs call for efficient sampling alternatives, underscoring the challenge of balancing computational efficiency and image quality.
This survey gives an overview of DMs applied to image SR and offers a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field.
It presents a unified view of DM fundamentals and explores research directions, including alternative input domains, conditioning strategies, guidance, corruption spaces, and zero-shot methods.
This survey provides insights into the evolution of image SR with DMs, addressing current trends, challenges, and future directions in this rapidly evolving field.","['Index', 'Terms: ', 'Diffusion', 'Models,', 'Image', 'Super-Resolution,', 'Artificial', 'Intelligence,', 'Survey.']",[]
"String matching algorithms in the presence of abbreviations, such as in Stock Keeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In this paper, we present a unified architecture for SKU search that provides both a real-time suggestion system (based on a Trie data structure) as well as a lower latency search system (making use of character level TF-IDF in combination with language model vector embeddings) where users initiate the search process explicitly. We carry out ablation studies that justify designing a complex search system composed of multiple components to address the delicate trade-off between speed and accuracy. Using SKU search in the Dynamics CRM as an example, we show how our system vastly outperforms, in all aspects, the results provided by the default search engine. Finally, we show how SKU descriptions may be enhanced via generative text models (using gpt-3.5-turbo) so that the consumers of the search results may get more context and a generally better experience when presented with the results of their SKU search.
Keywords: String matching ; Data structures ; Large Language Models ; Search Engine Architecture",[''],[]
"The hadro-chemistry of bottom quarks produced in hadronic collisions encodes valuable information on the mechanism of color-neutralization in these reactions. We first compute the chemistry of bottom-hadrons in high-energy p⁢p𝑝𝑝ppitalic_p italic_p collisions employing statistical hadronization with a largely augmented set of states beyond the currently measured spectrum. This enables a comprehensive prediction of fragmentation fractions of weakly decaying bottom hadrons for the first time and a satisfactory explanation of the existing measurements in p⁢p𝑝𝑝ppitalic_p italic_p collisions at the LHC. Utilizing the bottom hadro-chemistry thus obtained as the baseline, we then perform transport simulations of bottom quarks in the hot QCD matter created in PbPb collisions at the LHC energy and calculate the pertinent bottom-hadron observables. The transverse momentum (pTsubscript𝑝𝑇p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) dependent modifications of the bottom baryon-to-meson ratio (Λb0/B−superscriptsubscriptΛ𝑏0superscript𝐵\Lambda_{b}^{0}/B^{-}roman_Λ start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT / italic_B start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT) relative to their p⁢p𝑝𝑝ppitalic_p italic_p counterparts are highlighted as a result of bottom quark diffusion and hadronization in the Quark-Gluon Plasma (QGP). We finally summarize the heavy quark (charm vs bottom) diffusion coefficients as extracted from transport simulations and compare them to result from recent full lattice QCD computations.",[''],[]
,[''],[]
"The effective extraction of spatial-angular features plays a crucial role in light field image super-resolution (LFSR) tasks, and the introduction of convolution and Transformers leads to significant improvement in this area. Nevertheless, due to the large 4D data volume of light field images, many existing methods opted to decompose the data into a number of lower-dimensional subspaces and perform Transformers in each sub-space individually. As a side effect, these methods inadvertently restrict the self-attention mechanisms to a One-to-One scheme accessing only a limited subset of LF data, explicitly preventing comprehensive optimization on all spatial and angular cues. In this paper, we identify this limitation as subspace isolation and introduce a novel Many-to-Many Transformer (M2MT) to address it. M2MT aggregates angular information in the spatial subspace before performing the self-attention mechanism. It enables complete access to all information across all sub-aperture images (SAIs) in a light field image. Consequently, M2MT is enabled to comprehensively capture long-range correlation dependencies. With M2MT as the pivotal component, we develop a simple yet effective M2MT network for LFSR. Our experimental results demonstrate that M2MT achieves state-of-the-art performance across various public datasets. We further conduct in-depth analysis using local attribution maps (LAM) to obtain visual interpretability, and the results validate that M2MT is empowered with a truly non-local context in both spatial and angular subspaces to mitigate subspace isolation and acquire effective spatial-angular representation.","['Index', 'Terms: ', 'Light field,', 'Super-resolution,', 'Image processing,', 'Deep learning.']",[]
"Existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (LLMs) with expected outcomes. However, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. Furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for LLMs to effectively utilize tools.
To tackle this issue, we propose ToolEyes, a fine-grained system tailored for the evaluation of the LLMs’ tool learning capabilities in authentic scenarios. The system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to LLMs in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization.
Additionally, ToolEyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between LLMs and the physical world. Evaluations involving ten LLMs across three categories reveal a preference for specific scenarios and limited cognitive abilities in tool learning.
Intriguingly, expanding the model size even exacerbates the hindrance to tool learning.
These findings offer instructive insights aimed at advancing the field of tool learning. The data is available at https://github.com/Junjie-Ye/ToolEyes.git.",[''],[]
,[''],[]
"Walsh coefficients have been applied extensively
to biallelic systems for quantifying
pairwise and higher order epistasis,
in particular for demonstrating
the empirical importance of
higher order interactions.
Circuits, or minimal dependence
relations,
and related approaches
that use triangulations
of polytopes
have also been applied
to biallelic systems.
Here we
provide biological interpretations of
Walsh coefficients for several alleles,
and discuss circuits in the same general
setting.",[''],[]
"Deep learning for Hamiltonian regression of quantum systems in material research necessitates satisfying the covariance laws, among which achieving SO(3)-equivariance without sacrificing the expressiveness of networks remains an elusive challenge due to the restriction to non-linear mappings on guaranteeing theoretical equivariance. To alleviate the covariance-expressiveness dilemma, we propose a hybrid framework with two cascaded regression stages. The first stage, with a theoretically-guaranteed covariant neural network modeling symmetry properties of 3D atom systems, yields theoretically covariant features and baseline Hamiltonian predictions, assisting the second stage in learning covariance. Meanwhile, the second stage, powered by a non-linear 3D graph Transformer network we propose for structural modeling of 3D atomic systems, refines the first stage’s output as a fine-grained prediction of Hamiltonians with better expressiveness capability. The combination of a theoretically covariant yet inevitably less expressive model with a highly expressive non-linear network enables precise, generalizable predictions while maintaining robust covariance under coordinate transformations. Our method achieves state-of-the-art performance in Hamiltonian prediction for electronic structure calculations, confirmed through experiments on five crystalline material databases.",[''],[]
"The standard Radon transform of holomorphic functions is not always well defined, as the integration of such functions over planes may not converge. In this paper, we introduce new Radon-type transforms of co-(real)dimension 2222 for harmonic and holomorphic functions on the unit ball. These transforms are abstractly defined as orthogonal projections onto spaces of complex harmonic and holomorphic plane waves, respectively. The inversion formulas are derived based on the dual transform, while the latter is defined as an integration on a complex Stiefel manifold. Our transforms are extended to the Fock space and give rise to a new transform defined on the entire L2⁢(ℝn)superscript𝐿2superscriptℝ𝑛L^{2}(\mathbb{R}^{n})italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) through the Segal-Bargmann transform. Furthermore, we develop these transforms for Hermitian monogenic functions on the unit ball, thereby refining the Szegö-Radon transform for monogenic functions introduced by Colombo, Sabadini and Sommen.",[''],[]
,[''],[]
"Whether a PTAS (polynomial-time approximation scheme) exists for equilibriums of games has been an open question,
which relates to the practicality of methods in algorithmic game theory and the problem of non-stationarity in training and curse of dimensionality in multi-agent reinforcement learning.
This paper introduces our theory that implies a method that is sufficient and necessary to be the PTAS for perfect equilibriums of dynamic games.
The theory consists of cone interior dynamic programming and primal-dual unbiased regret minimization.
The former enables the dynamic programming operator to iteratively converge to a perfect equilibrium based on a concept called policy cone.
The latter enables the line search method to approximate a Nash equilibrium based on two concepts called primal-dual bias and unbiased central path, solving a subproblem of the former.
Validity of our discovery is cross-corroborated by a combination of theorem proofs, graphs of the three core concepts, and experimental results.",[''],[]
,[''],[]
"The generalized inverse Gaussian, denoted
GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ), is a flexible family of distributions that includes the gamma, inverse gamma, and inverse Gaussian distributions as special cases. In this article, we derive two novel mixture representations for the GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ): one that expresses the distribution as a continuous mixture of inverse Gaussians and another one that expresses it as a continuous mixture of truncated exponentials. Beyond their conceptual interest, these representations are useful for random number generation. We use the first representation to derive a geometrically ergodic Gibbs sampler whose stationary distribution is GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ), and the second one to define a recursive algorithm to generate exact independent draws from the distribution for half-integer p𝑝pitalic_p. Additionally, the second representation gives rise to a recursive algorithm for evaluating the cumulative distribution function of the GIG⁢(p,a,b)GIG𝑝𝑎𝑏\mathrm{GIG}(p,a,b)roman_GIG ( italic_p , italic_a , italic_b ) for half-integer p𝑝pitalic_p. The algorithms are simple and can be easily implemented in standard programming languages.",[''],[]
"We propose a general mechanism to realize nematic superconductivity (SC) and reveal its exotic vestigial phases in the quasi-crystal (QC). Starting from a Penrose Hubbard model, our microscopic studies suggest that the Kohn-Luttinger mechanism driven SC in the QC is usually gapless due to violation of Anderson’s theorem, rendering that both chiral and nematic SCs are common. The nematic SC in the QC can support novel vestigial phases driven by pairing phase fluctuations above its Tcsubscript𝑇𝑐T_{c}italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Our combined renormalization group and Monte-Carlo studies provide a phase diagram in which, besides the conventional charge-4e SC, two critical vestigial phases emerge, i.e. the quasi-nematic (Q-N) SC and Q-N metal. In the two Q-N phases, the discrete lattice rotation symmetry is counter-intuitively “quasi-broken” with power-law decaying orientation correlations. They separate the phase diagram into various phases connected via Brezinskii-Kosterlitz-Thouless (BKT) transitions. These remarkable critical vestigial phases, which resemble the intermediate BKT phase in the q𝑞qitalic_q-state (q≥5𝑞5q\geq 5italic_q ≥ 5) clock model, are consequence of the five- (or higher-) fold anisotropy field brought about by the unique QC symmetry, which are absent in conventional crystalline materials.",[''],"['China', 'China', 'China', 'China']"
"Machine translation systems have been widely adopted in our daily life, making life easier and more convenient. Unfortunately, erroneous translations may result in severe consequences, such as financial losses.
This requires to improve the accuracy and the reliability of machine translation systems.
However, it is challenging to test machine translation systems because of the complexity and intractability of the underlying neural models.
To tackle these challenges, we propose a novel metamorphic testing approach by syntactic tree pruning (STP) to validate machine translation systems.
Our key insight is that a pruned sentence should have similar crucial semantics compared with the original sentence.
Specifically, STP
(1) proposes a core semantics-preserving pruning strategy by basic sentence structures and dependency relations on the level of syntactic tree representation;
(2) generates source sentence pairs based on the metamorphic relation;
(3) reports suspicious issues whose translations break the consistency property by a bag-of-words model.
We further evaluate STP on two state-of-the-art machine translation systems (i.e., Google Translate and Bing Microsoft Translator) with 1,200 source sentences as inputs.
The results show that STP accurately finds 5,073 unique erroneous translations in Google Translate and 5,100 unique erroneous translations in Bing Microsoft Translator (400% more than state-of-the-art techniques), with 64.5% and 65.4% precision, respectively.
The reported erroneous translations vary in types and more than 90% of them are not found by state-of-the-art techniques.
There are 9,393 erroneous translations unique to STP, which is 711.9% more than state-of-the-art techniques.
Moreover, STP is quite effective in detecting translation errors for the original sentences with a recall reaching 74.0%, improving state-of-the-art techniques by 55.1% on average.","['Software testing,', 'Machine translation,', 'Metamorphic testing']","['UniversityNanjingJiangsuChina210093', 'AmherstAmherstMAUSA01003', 'UniversityNanjingJiangsuChina210093', 'UniversityNanjingJiangsuChina210093', 'UniversityNanjingJiangsuChina210093', 'UniversityNanjingJiangsuChina210093', 'UniversityNanjingJiangsuChina210093']"
"In this contribution we deal with Gaussian quadrature rules based on orthogonal polynomials associated with a weight function w⁢(x)=xα⁢e−x𝑤𝑥superscript𝑥𝛼superscript𝑒𝑥w(x)=x^{\alpha}e^{-x}italic_w ( italic_x ) = italic_x start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_x end_POSTSUPERSCRIPT supported on an interval (0,z)0𝑧(0,z)( 0 , italic_z ), z>0.𝑧0z>0.italic_z > 0 . The modified Chebyshev algorithm is used in order to test the accuracy in the computation of the coefficients of the three-term recurrence relation, the zeros and weights, as well as the dependence on the parameter z.𝑧z.italic_z .","['Key words and phrases:', 'Truncated', 'Laguerre polynomials,', 'Symmetrization process,', 'Quadrature formula']",[]
"Post-stack seismic inversion is a widely used technique to retrieve high-resolution acoustic impedance models from migrated seismic data. Its modelling operator assumes that a migrated seismic data can be generated from the convolution of a source wavelet and the time derivative of the acoustic impedance model. Given the band-limited nature of the seismic wavelet, the convolutional model acts as a filtering operator on the acoustic impedance model, thereby making the problem of retrieving acoustic impedances from seismic data ambiguous. In order to compensate for missing frequencies, post-stack seismic inversion is often regularized, meaning that prior information about the structure of the subsurface is included in the inversion process. Recently, the Plug-and-Play methodology has gained wide interest in the inverse problem community as a new form of implicit regularization, often outperforming state-of-the-art regularization. Plug-and-Play can be applied to any proximal algorithm by simply replacing the proximal operator of the regularizer with any denoiser of choice. We propose to use Plug-and-Play regularization with a 2D pre-trained, deep denoiser for 2D post-stack seismic inversion. Additionally, we show that a generalization of Plug-and-Play, called Multi-Agent Consensus Equilibrium, can be adopted to solve 3D post-stack inversion whilst leveraging the same 2D pre-trained denoiser used in the 2D case. More precisely, Multi-Agent Consensus Equilibrium combines the results of applying such 2D denoiser in the inline, crossline, and time directions in an optimal manner. We verify the proposed methods on a portion of the SEAM Phase 1 velocity model and the Sleipner field dataset.",[''],['*']
"X-ray binaries are known to launch powerful accretion disk winds that can have significant impact on the binary systems and their surroundings. To quantify the impact and determine the launching mechanisms of these outflows, we need to measure the wind plasma number density, an important ingredient in the theoretical disk wind models. While X-ray spectroscopy is a crucial tool to understanding the wind properties, such as their velocity and ionization, in nearly all cases, we lack the signal-to-noise to constrain the plasma number density, weakening the constraints on outflow location and mass outflow rate. We present a new approach to determine this number density in the X-ray binary Hercules X-1 by measuring the speed of the wind ionization response to time-variable illuminating continuum. Hercules X-1 is powered by a highly magnetized neutron star, pulsating with a period of 1.24 s. We show that the wind number density in Hercules X-1 is sufficiently high to respond to these pulsations by modeling the ionization response with the time-dependent photoionization model tpho. We then perform a pulse-resolved analysis of the best-quality XMM-Newton observation of Hercules X-1 and directly detect the wind response, confirming that the wind density is at least 1012superscript101210^{12}10 start_POSTSUPERSCRIPT 12 end_POSTSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT. Finally, we simulate XRISM observations of Hercules X-1 and show that they will allow us to accurately measure the number density at different locations within the outflow. With XRISM we will rule out ∼3similar-toabsent3\sim 3∼ 3 orders of magnitude in density parameter space, constraining the wind mass outflow rate, energetics, and its launching mechanism.",['Accretion (14)'],"['02139', 'USA', '60637', '02139', '02139', 'UK', 'Italy', '02139', 'Germany', 'UK']"
"The crux of graph classification lies in the effective representation learning for the entire graph. Typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. Such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. In this work, we propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the Graph Neural Memory designed to distill a compact graph representation from node features of the backbone. We first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. Then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. Thus, our model can learn more effective graph representation. We demonstrate the merits of SAR-GNN by extensive experiments on seven datasets across various types of graph data. Code will be released.",[''],[]
"Patient representation learning based on electronic health records (EHR) is a critical task for disease prediction. This task aims to effectively extract useful information on dynamic features. Although various existing works have achieved remarkable progress, the model performance can be further improved by fully extracting the trends, variations, and the correlation between the trends and variations in dynamic features. In addition, sparse visit records limit the performance of deep learning models. To address these issues, we propose the Multi-perspective Patient Representation Extractor (MPRE) for disease prediction. Specifically, we propose Frequency Transformation Module (FTM) to extract the trend and variation information of dynamic features in the time-frequency domain, which can enhance the feature representation. In the 2D Multi-Extraction Network (2D MEN), we form the 2D temporal tensor based on trend and variation. Then, the correlations between trend and variation are captured by the proposed dilated operation. Moreover, we propose the First-Order Difference Attention Mechanism (FODAM) to calculate the contributions of differences in adjacent variations to the disease diagnosis adaptively. To evaluate the performance of MPRE and baseline methods, we conduct extensive experiments on two real-world public datasets. The experiment results show that MPRE outperforms state-of-the-art baseline methods in terms of AUROC and AUPRC.","['Index', 'Terms: ', 'Disease', 'Prediction,', 'Patient', 'Representation,', 'Visit', 'Records']",['giovanni.pau@unibo.it']
"Conversational AI software products, such as chat-bot and digital assistant, have been widely used in our daily life. With the power of recent advance of artificial intelligence, such products can generate more vivid conversation with users. However, it can also generate speech that contain bias and stereotype. Previous works on detecting the bias in conversational AI system are either based on training a specific classification model, which can not guarantee the accuracy, or based on human annotation, which need much effort and can not be widely used. In this paper, we propose BiasAsker, a novel testing method that can automatically find the bias in conversational AI software by asking questions. Experimental results show that BiasAsker can reveal up to xxx bias on widely deplored software products and research models.","['Index', 'Terms: ', 'Software testing, metamorphic relations,', 'NLP software,', 'Chatbot,', 'Conversational', 'AI']",[]
"Recently, an anomalous temperature evolution of spin wave excitations
has been observed in a van der Waals metallic ferromagnet Fe33{}_{3}start_FLOATSUBSCRIPT 3 end_FLOATSUBSCRIPTGeTe22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT (FGT)
[S. Bao, et al., Phys. Rev. X 12, 011022 (2022)], whose theoretical
understanding yet remains elusive. Here we study the spin dynamics of a
ferromagnetic Kondo-Heisenberg lattice model at finite temperature, and propose
a mechanism of magnon damping that explains the intriguing experimental results.
In particular, we find the magnon damping rate γ⁢(T)𝛾𝑇\gamma(T)italic_γ ( italic_T ) firstly decreases as
temperature lowers, due to the reduced magnon-magnon scatterings. It then
reaches a minimum at Td*superscriptsubscript𝑇dT_{\rm d}^{*}italic_T start_POSTSUBSCRIPT roman_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT, and rises up again following a logarithmic
scaling γ⁢(T)∼ln⁡((T0/T))similar-to𝛾𝑇subscript𝑇0𝑇\gamma(T)\sim\ln{(T_{0}/T)}italic_γ ( italic_T ) ∼ roman_ln ( start_ARG ( italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT / italic_T ) end_ARG ) (with T0subscript𝑇0T_{0}italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT a constant) for T<Td*𝑇superscriptsubscript𝑇dT<T_{\rm d}^{*}italic_T < italic_T start_POSTSUBSCRIPT roman_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT,
which can be attributed to electron-magnon scatterings of spin-flip type.
Moreover, we obtain the phase diagram containing the ferromagnetic and Kondo
insulator phases by varying the Kondo coupling, which may be relevant for experiments
on pressured FGT. The presence of a magnon damping minimum and
logarithmic scaling at low temperature indicates the emergence of the Kondo
effect reflected in the collective excitations of local moments in a Kondo lattice system.",[''],"['China', 'China', 'China.', 'China', 'China', 'China', 'China.', 'China', 'China', 'China', 'China', 'China', 'China']"
"Let n,d∈\mathbb⁢N𝑛𝑑\mathbb𝑁n,d\in\mathbb{N}italic_n , italic_d ∈ italic_N and n>d𝑛𝑑n>ditalic_n > italic_d. An (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino is a box I1×⋯×Insubscript𝐼1⋯subscript𝐼𝑛I_{1}\times\cdots\times I_{n}italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × ⋯ × italic_I start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT such that Ij∈{[0,1],[1,2]}subscript𝐼𝑗0112I_{j}\in\{[0,1],[1,2]\}italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ { [ 0 , 1 ] , [ 1 , 2 ] } for all j∈N⊂[n]𝑗𝑁delimited-[]𝑛j\in N\subset[n]italic_j ∈ italic_N ⊂ [ italic_n ] with |N|=d𝑁𝑑|N|=d| italic_N | = italic_d and Ii=[0,2]subscript𝐼𝑖02I_{i}=[0,2]italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ 0 , 2 ] for every i∈[n]∖N𝑖delimited-[]𝑛𝑁i\in[n]\setminus Nitalic_i ∈ [ italic_n ] ∖ italic_N. If A𝐴Aitalic_A and B𝐵Bitalic_B are two (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes such that A∪B𝐴𝐵A\cup Bitalic_A ∪ italic_B is an (n−(d−1))𝑛𝑑1(n-(d-1))( italic_n - ( italic_d - 1 ) )-domino, then A,B𝐴𝐵A,Bitalic_A , italic_B is called a twin pair. If C,D𝐶𝐷C,Ditalic_C , italic_D are two (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes which form a twin pair such that A∪B=C∪D𝐴𝐵𝐶𝐷A\cup B=C\cup Ditalic_A ∪ italic_B = italic_C ∪ italic_D and {C,D}≠{A,B}𝐶𝐷𝐴𝐵\{C,D\}\neq\{A,B\}{ italic_C , italic_D } ≠ { italic_A , italic_B }, then the pair C,D𝐶𝐷C,Ditalic_C , italic_D is called a flip of A,B𝐴𝐵A,Bitalic_A , italic_B. A family 𝒟𝒟\mathscr{D}script_D of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-dominoes is a tiling of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT if interiors of every two members of 𝒟𝒟\mathscr{D}script_D are disjoint and ⋃B∈𝒟B=[0,2]nsubscript𝐵𝒟𝐵superscript02𝑛\bigcup_{B\in\mathscr{D}}B=[0,2]^{n}⋃ start_POSTSUBSCRIPT italic_B ∈ script_D end_POSTSUBSCRIPT italic_B = [ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. An (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tiling 𝒟′superscript𝒟′\mathscr{D}^{\prime}script_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is obtained from an (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tiling 𝒟𝒟\mathscr{D}script_D by a flip, if there is a twin pair A,B∈𝒟𝐴𝐵𝒟A,B\in\mathscr{D}italic_A , italic_B ∈ script_D such that 𝒟′=(𝒟∖{A,B})∪{C,D}superscript𝒟′𝒟𝐴𝐵𝐶𝐷\mathscr{D}^{\prime}=(\mathscr{D}\setminus\{A,B\})\cup\{C,D\}script_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( script_D ∖ { italic_A , italic_B } ) ∪ { italic_C , italic_D }, where C,D𝐶𝐷C,Ditalic_C , italic_D is a flip of A,B𝐴𝐵A,Bitalic_A , italic_B. A family of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tilings of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is flip-connected, if for every two members 𝒟,ℰ𝒟ℰ\mathscr{D},\mathscr{E}script_D , script_E of this family the tiling ℰℰ\mathscr{E}script_E can be obtained from 𝒟𝒟\mathscr{D}script_D by a sequence of flips. In the paper some flip-connected class of (n−d)𝑛𝑑(n-d)( italic_n - italic_d )-domino tilings of the box [0,2]nsuperscript02𝑛[0,2]^{n}[ 0 , 2 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is described.",[''],[]
"A Howe curve is defined as the normalization of the fiber product over a projective line of two hyperelliptic curves.
Howe curves are very useful to produce important classes of curves over fields of positive characteristic, e.g., maximal, superspecial, or supersingular ones.
Determining their feasible equations explicitly is a basic problem, and it has been solved in the hyperelliptic case and in the non-hyperelliptic case with genus not greater than 4444.
In this paper, we construct an explicit plane sextic model for non-hyperelliptic Howe curves of genus 5555.
We also determine the number and type of singularities on our sextic model, and prove that the singularities are generically 4444 double points.
Our results together with Moriya-Kudo’s recent ones imply that for each s∈{2,3,4,5}𝑠2345s\in\{2,3,4,5\}italic_s ∈ { 2 , 3 , 4 , 5 }, there exists a non-hyperellptic curve H𝐻Hitalic_H of genus 5555 with Aut⁢(H)⊃𝐕4subscript𝐕4Aut𝐻\mathrm{Aut}(H)\supset\mathbf{V}_{4}roman_Aut ( italic_H ) ⊃ bold_V start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT such that its associated plane sextic has s𝑠sitalic_s double points.",[''],[]
"Conversational AI software products, such as chat-bot and digital assistant, have been widely used in our daily life. With the power of recent advance of artificial intelligence, such products can generate more vivid conversation with users. However, it can also generate speech that contain bias and stereotype. Previous works on detecting the bias in conversational AI system are either based on training a specific classification model, which can not guarantee the accuracy, or based on human annotation, which need much effort and can not be widely used. In this paper, we propose BiasAsker, a novel testing method that can automatically find the bias in conversational AI software by asking questions. Experimental results show that BiasAsker can reveal up to xxx bias on widely deplored software products and research models.","['Index', 'Terms: ', 'Software testing, metamorphic relations,', 'NLP software,', 'Chatbot,', 'Conversational', 'AI']",[]
"Structural global parameter identifiability indicates whether one can determine a parameter’s value in an ODE model from given inputs and outputs. If a given model has parameters for which there is exactly one value, such parameters are called identifiable. We present a procedure for replacing, if possible, a given ODE model involving not identifiable parameters by an equivalent one such that the new set of parameters is identifiable. We first derive this as an algorithm for one-dimensional ODE models and then reuse this approach for higher-dimensional models.",[''],[]
"Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel metamorphic testing framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on any changes related to gender, race, and age. BiasPainter adopts a testing oracle that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models.
To evaluate the effectiveness of BiasPainter, we use BiasPainter to test five widely-used commercial image generation software and models, such as stable diffusion and Midjourney. Experimental results show that 100% of the generated test cases can successfully trigger social bias in image generation models. According to our human evaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection, which is significantly higher than the results reported in previous work. Additionally, BiasPainter provides interesting and valuable insights from evaluating the fairness of image generation models, which is helpful for developers to improve the models in the future. All the code, data, and experimental results will be released to facilitate future research.",[''],"['KongChina', 'KongChina', 'KongChina', 'KongChina', 'ShenzhenShenzhenChina', 'AngelesUSA', 'AngelesUSA', 'KongChina']"
"We continue the survey initiated in Kimura:2020bed  to explore the Bethe/Gauge correspondence between supersymmetric SO/Sp gauge theories in 2d/3d/4d and open spin chain with integrable boundaries. We collect the known Bethe ansatz equations of different types of spin chains with general boundaries that have been analyzed in the literature, and compare them with the vacua equations of the quiver gauge theories. It seems that not all the vacua equations of quiver gauge theory with BCD-type gauge groups can be realized as some known Bethe ansatz equations of integrable spin chain models.",[''],[]
"Cryptography is the study of securing information. It is the physical process that scrambles the information by rearrangement and substitution of content, so that it becomes difficult for anyone to understand. In today’s world, security has become an inevitable part of our day-to-day life, right from normal browsing to performing critical payment transactions. Hackers work endlessly to break the security present in the apps/websites on which we perform day-to-day operations and salvage valuable information. Because of this, many illegal activities have taken place which affect the user. One such illegal activity is tapping the voice communication between two users. If left unencrypted, the communication between the users is compromised, thereby causing issues. One way to prevent this act is to encrypt the audio in that the contents cannot have tampered with unless the receiver has the valid key to decrypt it. The proposed solution termed ”HexE” aims to create a puzzle-based algorithm which would encrypt and decrypt the audio files without manipulating the file header, thus securing the contents. The algorithm works on an NxN SuDoKu-based puzzle which is accepted both by the sender and receiver. Using the timestamp of the event (UNIX based), a grid from the puzzle is chosen which in turn will act as the key for both encryption and decryption. If the timestamp is slightly adjusted, the process will end up in failure during decryption, thus ensuring confidentiality. Another approach to secure the audio files is to implement IPFS (Inter Planetary File System) alongside the puzzle algorithm in which the encrypted audio is stored on it and the receiver can fetch the audio provided if the valid IPFS Hash of the file is present. In this way, the audio file is secured.",[''],[]
"It is challenging but highly desired to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus exclusively on specific restoration or enhancement tasks, being insufficient in exploiting multi-image. Motivated by that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize bracketing photography to unify restoration and enhancement tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. The dataset, code, and pre-trained models are available at https://github.com/cszhilu1998/BracketIRE.",[''],[]
"Let G𝐺Gitalic_G be a finite group, and g∈G𝑔𝐺g\in Gitalic_g ∈ italic_G. Then g𝑔gitalic_g is said to be a vanishing element of G𝐺Gitalic_G, if there exists an irreducible character χ𝜒\chiitalic_χ of G𝐺Gitalic_G such that χ⁢(g)=0𝜒𝑔0\chi(g)=0italic_χ ( italic_g ) = 0. Denote by Vo⁢(G)Vo𝐺{\rm Vo}(G)roman_Vo ( italic_G ) the set of the orders of vanishing elements of G𝐺Gitalic_G. We say a non-abelian group G𝐺Gitalic_G is V-recognizable, if any group N𝑁Nitalic_N with Vo⁢(N)=Vo⁢(G)Vo𝑁Vo𝐺{\rm Vo}(N)={\rm Vo}(G)roman_Vo ( italic_N ) = roman_Vo ( italic_G ) is isomorphic to G𝐺Gitalic_G. In this paper, we investigate the V-recognizability of E8⁢(p)subscript𝐸8𝑝E_{8}(p)italic_E start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ( italic_p ), where p𝑝pitalic_p is a prime number. As an application, among the 610 primes p𝑝pitalic_p with p<10000𝑝10000p<10000italic_p < 10000 and p≡0,1,4(mod5)𝑝01annotated4moduloabsent5p\equiv 0,1,4\,(\!\!\!\mod 5)italic_p ≡ 0 , 1 , 4 ( roman_mod 5 ), we obtain that the method is always valid for confirming the V-recognizability of E8⁢(p)subscript𝐸8𝑝E_{8}(p)italic_E start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ( italic_p ) for all such p𝑝pitalic_p but 919,1289,1931,3911,4691,538191912891931391146915381919,1289,1931,3911,4691,5381919 , 1289 , 1931 , 3911 , 4691 , 5381 and 7589758975897589.",[''],[]
"With the onset of the era of gravitational-wave (GW) astronomy, the search for continuous gravitational waves (CGWs), which remain undetected to date, has intensified in more ways than one. Rapidly rotating neutron stars with non-axisymmetrical deformations are the main targets for CGW searches. The extent of this quadrupolar deformation is measured by the maximum ellipticity that can be sustained by the crust of a neutron star and it places an upper limit on the CGW amplitudes emitted by such systems. In this paper, following previous works on this subject, we calculate the maximum ellipticity of a neutron star generated by the Lorentz force exerted on it by the internal magnetic fields. We show that the ellipticity of stars deformed by such a Lorentz force is of the same order of magnitude as previous theoretical and astrophysical constraints. We also consider if this ellipticity can be further enhanced by crustal surface currents. We discover that this is indeed true; surface currents at crustal boundaries are instrumental towards enhancing the ellipticity of magnetized neutron stars.",[''],[]
"In this paper, we present a theoretical, experimental, and numerical study of the dynamics of cavitation bubbles inside a droplet suspended in another host fluid. On the theoretical side, we provided a modified Rayleigh collapse time and natural frequency for spherical bubbles in our particular context, characterized by the density ratio between the two liquids and the bubble-to-droplet size ratio. Regarding the experimental aspect, experiments were carried out for laser-induced cavitation bubbles inside oil-in-water (O/W) or water-in-oil (W/O) droplets. Two distinct fluid-mixing mechanisms were unveiled in the two systems, respectively. In the case of O/W droplets, a liquid jet emerges around the end of the bubble collapse phase, effectively penetrating the droplet interface. We offer a detailed analysis of the criteria governing jet penetration, involving the standoff parameter and impact velocity of the bubble jet on the droplet surface. Conversely, in the scenario involving W/O droplets, the bubble traverses the droplet interior, inducing global motion and eventually leading to droplet pinch-off when the local Weber number exceeds a critical value. This phenomenon is elucidated through the equilibrium between interfacial and kinetic energies. Lastly, our boundary integral model faithfully reproduces the essential physics of nonspherical bubble dynamics observed in the experiments. We conduct a parametric study spanning a wide parameter space to investigate bubble-droplet interactions. The insights from this study could serve as a valuable reference for practical applications in the field of ultrasonic emulsification, pharmacy, etc.",[''],['China']
"Vector-like quarks have been predicted in various new physics scenarios beyond the Standard Model (SM). In a simplified modelling of a (B,Y)𝐵𝑌(B,Y)( italic_B , italic_Y ) doublet including a vector-like quark Y𝑌Yitalic_Y, with charge −4343-\frac{4}{3}- divide start_ARG 4 end_ARG start_ARG 3 end_ARGe, there are only two free parameters: the Y𝑌Yitalic_Y coupling κYsubscript𝜅𝑌\kappa_{Y}italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT and mass mYsubscript𝑚𝑌m_{Y}italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. In the five flavor scheme, we investigate the single production of the Y𝑌Yitalic_Y state decaying into W⁢b𝑊𝑏Wbitalic_W italic_b at the
Large Hadron Collider (LHC) Run-III and High-Luminosity LHC (HL-LHC) operating at s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 14 TeV, the possible High-Energy LHC (HE-LHC) with s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 27 TeV as well as the Future Circular Collider in hadron-hadron mode (FCC-hh) with s𝑠\sqrt{s}square-root start_ARG italic_s end_ARG = 100 TeV. Through detailed signal-to-background analyses and detector simulations, we assess the exclusion capabilities of the Y𝑌Yitalic_Y state at the different colliders.
We find that this can be improved significantly with increasing collision energy, especially at the HE-LHC and FCC-hh, both demonstrating an obvious advantage with respect to the HL-LHC case
in the case of high mYsubscript𝑚𝑌m_{Y}italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. Assuming a 10% systematic uncertainty on the background event rate, the exclusion capabilities are summarized as follows:
(1) the LHC Run-III can exclude the correlated regions of κY∈[0.044,0.5]subscript𝜅𝑌0.0440.5\kappa_{Y}\in[0.044,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.044 , 0.5 ] and mY∈[1000⁢ GeV,3099⁢ GeV]subscript𝑚𝑌1000 GeV3099 GeVm_{Y}\in[1000\text{ GeV},3099\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 3099 GeV ] with integrated luminosity L=300⁢ fb−1𝐿300superscript fb1L=300\text{ fb}^{-1}italic_L = 300 fb start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT;
(2) the HL-LHC can exclude the correlated regions of κY∈[0.027,0.5]subscript𝜅𝑌0.0270.5\kappa_{Y}\in[0.027,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.027 , 0.5 ] and mY∈[1000⁢ GeV,3653⁢ GeV]subscript𝑚𝑌1000 GeV3653 GeVm_{Y}\in[1000\text{ GeV},3653\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 3653 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT;
(3) the HE-LHC can exclude the correlated regions of κY∈[0.030,0.5]subscript𝜅𝑌0.0300.5\kappa_{Y}\in[0.030,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.030 , 0.5 ] and mY∈[1000⁢ GeV,4936⁢ GeV]subscript𝑚𝑌1000 GeV4936 GeVm_{Y}\in[1000\text{ GeV},4936\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 4936 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT;
(4) the FCC-hh can exclude the correlated regions of κY∈[0.051,0.5]subscript𝜅𝑌0.0510.5\kappa_{Y}\in[0.051,0.5]italic_κ start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 0.051 , 0.5 ] and mY∈[1000⁢ GeV,6610⁢ GeV]subscript𝑚𝑌1000 GeV6610 GeVm_{Y}\in[1000\text{ GeV},6610\text{ GeV}]italic_m start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ∈ [ 1000 GeV , 6610 GeV ] with L=3𝐿3L=3italic_L = 3 ab−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT.",[''],['UK']
"We discuss the gravitational wave (GW) spectra predicted from
the electroweak scalegenesis of the Higgs portal type
with a large number of dark chiral flavors, which many flavor QCD would underlie and give the dynamical explanation of the negative Higgs portal coupling required to trigger the electroweak symmetry breaking.
We employ the linear-sigma model as the low-energy description of dark many flavor QCD and show that the model undergoes ultra-supercooling due to the produced
strong first-order thermal phase transition along the (approximately realized) flat direction based on the Gildener-Weinberg mechanism.
Passing through evaluation of the bubble nucleation/percolation, we address
the reheating and relaxation processes, which are generically non-thermal and nonadiabatic.
Parametrizing the reheating epoch in terms of the efolding number, we propose
proper formulae for the redshift effects on the GW frequencies and signal
spectra.
It then turns out that the ultra-supercooling predicted from the Higgs-portal scalegenesis generically
yields none of GW signals with the frequencies as low as nano Hz, instead, prefers to give the higher frequency signals,
which still keeps the future prospected detection sensitivity, like at LISA, BBO, and DECIGO, etc.
We also find that with large flavors in the dark sector, the GW signals are made further smaller
and the peak frequencies higher.
Characteristic phenomenological consequences related to
the multiple chiral scalars include the prediction of dark pions
with the mass much less than TeV scale, which is also briefly addressed.",[''],"['China', 'Japan', 'China']"
,[''],[]
"Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors.
To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover, the proposed method leverages variational inference for Dirichlet process mixtures to ensure efficient and fast computation. Empirical studies with benchmark datasets demonstrate that our method outperforms existing approaches for unsupervised outlier detection.",[''],"['Korea', 'Korea', 'USA', 'Korea', 'Korea']"
"In this paper, we establish some reciprocity formulas for certain generalized Hardy sums by using the Fourier series technique and some properties of the periodic zeta function and Lerch zeta function. It turns out that one of Hardy’s reciprocity theorems is deduced as a special case.",[''],[]
"Text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. We review popular methods for text analysis, ranging from
topic modeling to the recent neural language models.
In particular, we review Topic-SCORE, a statistical approach to topic modeling, and discuss how to use it to analyze MADStat - a dataset on statistical publications
that we collected and cleaned.
The application of Topic-SCORE and other methods on MADStat leads to interesting findings.
For example,
11111111 representative topics in statistics are identified.
For each journal, the evolution of
topic weights over time can be visualized, and these results are used to analyze the trends in
statistical research. In particular, we propose a new statistical model for ranking the citation impacts of 11111111 topics, and we also
build a cross-topic citation graph to illustrate how research results on different topics spread to one another.
The results on MADStat provide a data-driven picture of the statistical
research in 1975197519751975–2015201520152015, from a text analysis perspective.",[''],[]
"In recent years, edge computing has served as a paradigm that enables many future technologies like AI, Robotics, IoT, and high-speed wireless sensor networks (like 5G) by connecting cloud computing facilities and services to the end users. Especially in medical and healthcare applications, it provides remote patient monitoring and increases voluminous multimedia.
From the robotics angle, robot-assisted therapy (RAT) is an active-assistive robotic technology in rehabilitation robotics, attracting many researchers to study and benefit people with disability like autism spectrum disorder (ASD) children.
However, the main challenge of RAT is that the model capable of detecting the affective states of ASD people exists and can recall individual preferences. Moreover, involving expert diagnosis and recommendations to guide robots in updating the therapy approach to adapt to different statuses and scenarios is a crucial part of the ASD therapy process. This paper proposes the architecture of edge cognitive computing by combining human experts and assisted robots collaborating in the same framework to help ASD patients with long-term support. By integrating the real-time computing and analysis of a new cognitive robotic model for ASD therapy, the proposed architecture can achieve a seamless remote diagnosis, round-the-clock symptom monitoring, emergency warning, therapy alteration, and advanced assistance.",[''],[]
"Herschend–Liu–Nakaoka introduced the concept of n𝑛nitalic_n-exangulated categories as higher-dimensional analogues of extriangulated categories defined by Nakaoka–Palu. The class of n𝑛nitalic_n-exangulated categories contains n𝑛nitalic_n-exact categories and (n+2)𝑛2(n+2)( italic_n + 2 )-angulated categories as specific examples. In this article, we introduce the notion of hereditary n𝑛nitalic_n-exangulated categories, which generalize hereditary extriangulated categories. We provide two classes of hereditary n𝑛nitalic_n-exangulated categories through closed subfunctors. Additionally, we define the concept of 00-Auslander n𝑛nitalic_n-exangulated categories and discuss the circumstances under which these two classes of hereditary n𝑛nitalic_n-exangulated categories become 00-Auslander.

Keywords: (n+2)𝑛2(n+2)( italic_n + 2 )-angulated category; n𝑛nitalic_n-exact category; hereditary n𝑛nitalic_n-exangulated category; 00-Auslander n𝑛nitalic_n-exangulated category; closed subfunctor

 2020 Mathematics Subject Classification: 18G80; 18E10",[''],[]
"Lawson’s iteration is a classical and effective method for solving the linear (polynomial) minimax approximation in the complex plane. Extension of Lawson’s iteration for the rational minimax approximation with both computationally high efficiency and theoretical guarantee is challenging. A recent work [L.-H. Zhang, L. Yang, W. H. Yang and Y.-N. Zhang, A convex dual programming for the rational minimax approximation and Lawson’s iteration, 2023, https://arxiv.org/pdf/2308.06991v1] reveals that Lawson’s iteration can be viewed as a method for solving the dual problem of the original rational minimax approximation, and a new type of Lawson’s iteration was proposed. Such a dual problem is guaranteed to obtain the original minimax solution under Ruttan’s sufficient condition, and numerically, the proposed Lawson’s iteration was observed to converge monotonically with respect to the dual objective function. In this paper, we perform theoretical convergence analysis for Lawson’s iteration for both the linear and rational minimax approximations. In particular, we show that


 (i)

for the linear minimax approximation, the near-optimal Lawson exponent β𝛽\betaitalic_β in Lawson’s iteration is β=1𝛽1\beta=1italic_β = 1, and




(ii)

for the rational minimax approximation, the proposed Lawson’s iteration converges monotonically with respect to the dual objective function for any sufficiently small β>0𝛽0\beta>0italic_β > 0, and the convergent solution fulfills the complementary slackness: all nodes associated with positive weights achieve the maximum error.",[''],[]
"Temporal validity is an important property of text that is useful for many downstream applications, such as recommender systems, conversational AI, or story understanding. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, in many cases, additional contextual information, such as sentences in a story or posts on a social media profile, can be collected from the available text stream. This contextual information may greatly alter the duration for which a statement is expected to be valid. We propose Temporal Validity Change Prediction, a natural language processing task benchmarking the capability of machine learning models to detect contextual statements that induce such change. We create a dataset consisting of temporal target statements sourced from Twitter and crowdsource sample context statements. We then benchmark a set of transformer-based language models on our dataset. Finally, we experiment with temporal validity duration prediction as an auxiliary task to improve the performance of the state-of-the-art model.",[''],[]
"Riemann-Cartan geometries are metric based geometries admitting a non-zero torsion tensor. These geometries have been investigated as geometric frameworks for potential theories in physics including quantum gravity theories and have many important differences when compared to Riemannian geometries. One notable difference, is the number of symmetries for a Riemann-Cartan geometry is potentially smaller than the number of Killing vector fields for the metric. In this paper we will review the investigation of symmetries in Riemann-Cartan geometries and the mathematical tools used to determine geometries that admit a given group of symmetries. As an illustration we will determine all static spherically symmetric and all stationary spherically symmetric Riemann-Cartan geometries. Further, we will determine the subclasses of spherically symmetric Riemann-Cartan geometries that admit a seven-dimensional group of symmetries.",[''],"['Norway', '3J5', '2W5']"
,[''],[]
"We investigate evolution of a flat Emergent Universe (EU) obtained with a non-linear equation of state (nEoS) in Einstein’s general theory of Relativity. The nEoS is equivalent to three different types of barotropic cosmic fluid, which is known from the nEoS parameter. The EU began expanding initially with no interaction among the cosmic fluids. Assuming an interaction that sets in at a time t>ti𝑡subscript𝑡𝑖t>t_{i}italic_t > italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT among the fluid components, we study the evolution of the EU that leads to the present observed universe. A dynamical system analysis is performed to characterize the cosmological evolution and the stable behavior of the critical points of the autonomous system for an EU with or without interaction. The autonomous system of ordinary differential equations of the field equations are used to derive the evolution using dimensionless parameters. We determine critical points, and we analyze the stability of the critical points, drawing the phase portraits. The density parameters and the corresponding cosmological parameters are obtained for both the non-interacting and interacting phases to explore the dynamics of evolution.
Key Words : Emergent Universe, Dynamical analysis, Cosmological Parameters",[''],['India']
"The notion of Frobenius Betti numbers generalizes the Hilbert-Kunz multiplicity theory and serves as an invariant that measures singularity.
However, the explicit computation of the Frobenius Betti numbers of rings has been limited to very few specific cases. This article focuses on the explicit computation of Frobenius Betti numbers of Cohen-Macaulay graded rings of finite Cohen-Macaulay type.","['Key words and phrases:', 'Frobenius', 'Betti number,', 'Hilbert-Kunz multiplicity, finite', 'Cohen-Macaulay type']",[]
"We consider dilute Bose gases on the three dimensional unit torus that interact through a pair potential with scattering length of order Nκ−1superscript𝑁𝜅1N^{\kappa-1}italic_N start_POSTSUPERSCRIPT italic_κ - 1 end_POSTSUPERSCRIPT, for some κ>0𝜅0\kappa>0italic_κ > 0. For the range κ∈[0,143)𝜅0143\kappa\in[0,\frac{1}{43})italic_κ ∈ [ 0 , divide start_ARG 1 end_ARG start_ARG 43 end_ARG ), [1] proves complete BEC of low energy states into the zero momentum mode based on a unitary renormalization through operator exponentials that are quartic in creation and annihilation operators. In this paper, we give a new and self-contained proof of BEC of the ground state for κ∈[0,120)𝜅0120\kappa\in[0,\frac{1}{20})italic_κ ∈ [ 0 , divide start_ARG 1 end_ARG start_ARG 20 end_ARG ) by combining some of the key ideas of [1] with the novel diagonalization approach introduced recently in [16], which is based on the Schur complement formula. In particular, our proof avoids the use of operator exponentials and is significantly simpler than [1].",[''],[]
"Superradiant Raman scattering of Rubidium atoms has been explored in the experiment [Nature 484, 78 (2012)] to prove the concept of the superradiant laser, which attracts significant attentions in quantum metrology due to the expected ultra-narrow linewidth down to millihertz. To better understand the physics involved in this experiment, we have developed a quantum master equation theory by treating the Rubidium atoms as three-level systems, and coupling them with a dressed laser and an optical cavity. Our simulations show different superradiant Raman scattering pulses for the systems within the crossover and strong coupling regime, and the shifted and broader spectrum of the steady-state Raman scattering. Thus, our studies provide a unified view on the superradiant Raman scattering pulses, and an alternative explanation to the broad spectrum of the steady-state Raman scattering, as observed in the experiment. In future, our theory can be readily applied to study other interesting phenomena relying on the superradiant Raman scattering, such as magnetic field sensing, real-time tracking of quantum phase, Dicke phase transition of non-equilibrium dynamics and so on.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China']"
"We show that a “generic” finite metric space can be identified by the asymptotic behavior of the magnitude function.
In particular, almost every finite set in Euclidean space can be determined by the magnitude function.",[''],[]
,[''],[]
"The high cost of full-parameter fine-tuning (FFT) of Large Language Models (LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods. However, it remains unclear which methods provide the best cost-performance trade-off at different model scales. We introduce Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. Through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that FFT generally leads to the best downstream performance across all scales, and PEFT methods differ significantly in their efficacy based on the model scale. LoRA usually offers the most favorable trade-off between cost and performance. Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. At last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. We find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance.",[''],[]
"Understanding human actions from videos of first-person view poses significant challenges. Most prior approaches explore representation learning on egocentric videos only, while overlooking the potential benefit of exploiting existing large-scale third-person videos.
In this paper,
(1) we develop EgoInstructor, a retrieval-augmented multimodal captioning model that automatically retrieves semantically relevant third-person instructional videos to enhance the video captioning of egocentric videos.
(2) For training the cross-view retrieval module, we devise an automatic pipeline to discover ego-exo video pairs from distinct large-scale egocentric and exocentric datasets.
(3) We train the cross-view retrieval module with a novel EgoExoNCE loss that pulls egocentric and exocentric video features closer by aligning them to shared text features that describe similar actions.
(4) Through extensive experiments, our cross-view retrieval module demonstrates superior performance across seven benchmarks. Regarding egocentric video captioning, EgoInstructor exhibits significant improvements by leveraging third-person videos as references.",[''],[]
"The group of homeomorphisms of the closed interval that are orientation preserving, absolutely continuous and have an absolutely continuous inverse was shown by Solecki to admit a natural Polish group topology τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT. We observe that, more generally, under some conditions on a compact space endowed with a finite Borel measure an analogous Polish group topology can be defined on the subgroup of the homeomorphism group which push forward the measure to another one with which it is mutually absolutely continuous.

We use a probabilistic argument involving approximations by supmartingale processes to show that in many cases there is no group topology between τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT and the restriction τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT of the compact-open topology.
This applies, in particular, to any compact topological manifold equipped with an Oxtoby-Ulam measure and to the Cantor space endowed with some natural Borel measures.
In fact, we show that in such cases any separable group topology strictly finer than τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT has to be also finer than τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT. For one-dimensional manifolds well-known arguments show that the compact-open topology is a minimum Hausdroff group topology on the group, which implies that τc⁢osubscript𝜏𝑐𝑜\tau_{co}italic_τ start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT and τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT are the only Hausdorff group topologies coarser than τa⁢csubscript𝜏𝑎𝑐\tau_{ac}italic_τ start_POSTSUBSCRIPT italic_a italic_c end_POSTSUBSCRIPT.

We also show that while Solecki’s example is not Roelcke precompact, the group of bi-absolutely continuous homeomorphisms of the Cantor space endowed with the measure given by the Fräissé limit of the class of measured boolean algebras with rational probability measures is Roelcke precompact.",[''],[]
"The momentum ray transform Imksuperscriptsubscript𝐼𝑚𝑘I_{m}^{k}italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT integrates a rank m𝑚mitalic_m symmetric tensor field f𝑓fitalic_f on ℝnsuperscriptℝ𝑛{{\mathbb{R}}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT over lines with the weight tksuperscript𝑡𝑘t^{k}italic_t start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT,
Imk⁢f⁢(x,ξ)=∫−∞∞tk⁢⟨f⁢(x+t⁢ξ),ξm⟩⁢dtsuperscriptsubscript𝐼𝑚𝑘𝑓𝑥𝜉superscriptsubscriptsuperscript𝑡𝑘𝑓𝑥𝑡𝜉superscript𝜉𝑚differential-d𝑡I_{m}^{k}f(x,\xi)=\int_{-\infty}^{\infty}t^{k}\langle f(x+t\xi),\xi^{m}\rangle%
\,\mathrm{d}titalic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_f ( italic_x , italic_ξ ) = ∫ start_POSTSUBSCRIPT - ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ⟨ italic_f ( italic_x + italic_t italic_ξ ) , italic_ξ start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ⟩ roman_d italic_t.
We compute the normal operator Nmk=(Imk)⁢Imk*superscriptsubscript𝑁𝑚𝑘superscriptsubscript𝐼𝑚𝑘superscriptsuperscriptsubscript𝐼𝑚𝑘N_{m}^{k}=(I_{m}^{k}){}^{*}I_{m}^{k}italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = ( italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT italic_I start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT and present an inversion formula recovering a rank m𝑚mitalic_m tensor field f𝑓fitalic_f from the data (Nm0⁢f,…,Nmm⁢f)superscriptsubscript𝑁𝑚0𝑓…superscriptsubscript𝑁𝑚𝑚𝑓(N_{m}^{0}f,\dots,N_{m}^{m}f)( italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT italic_f , … , italic_N start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_f ).
Keywords. Ray transform, inverse problems, symmetric tensor fields, tensor tomography, momentum ray transform.
Mathematics Subject Classification (2020): Primary 44A12, Secondary 53C65.",[''],[]
"We discuss how grand unification can be probed with experiments at low energies using quantum sensors. Specifically, we show that scalar multiplets coupled to the gauge sector of a grand unified theory provide a mechanism for a time-varying unified coupling which has low-energy consequences which can be probed with quantum sensors. We then assume that the multiplets represent ultra light dark matter. Constraints on ultra light dark matter couplings to regular matter are extracted using atomic clock comparisons, pulsar timing arrays (NANOGrav) and MICROSCOPE.",[''],['Kingdom']
"With the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect the privacy of inference data and model parameters. However, the application of SMPC in Privacy-Preserving Inference (PPI) for large language models, particularly those based on the Transformer architecture, often leads to considerable slowdowns or declines in performance. This is largely due to the multitude of nonlinear operations in the Transformer architecture, which are not well-suited to SMPC and are difficult to circumvent or optimize effectively. To address this concern, we introduce an advanced optimization framework called SecFormer, designed to strike an optimal balance between performance and efficiency in PPI for Transformer models. By implementing knowledge distillation techniques, we successfully eliminate the high-cost exponential and maximum operations in PPI without sacrificing model performance. Additionally, we have developed a suite of efficient SMPC protocols that utilize segmented polynomials and Goldschmidt’s method to handle other complex nonlinear functions within PPI, such as GeLU, LayerNorm, and Softmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer in performance, showing improvements of 5.6%percent5.65.6\%5.6 % and 24.2%percent24.224.2\%24.2 % for BERTBASEBASE{}_{\text{BASE}}start_FLOATSUBSCRIPT BASE end_FLOATSUBSCRIPT and BERTLARGELARGE{}_{\text{LARGE}}start_FLOATSUBSCRIPT LARGE end_FLOATSUBSCRIPT, respectively. In terms of efficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its effectiveness and speed.",[''],[]
,[''],[]
,[''],[]
"Harnessing the advantages of shared entanglement for sending quantum messages often requires the implementation of complex two-particle entangled measurements. We investigate entanglement advantages in protocols that use only the simplest two-particle measurements, namely product measurements. For experiments in which only the dimension of the message is known, we show that robust entanglement advantages are possible, but that they are fundamentally limited by Einstein-Podolsky-Rosen steering. Subsequently, we propose a natural extension of the standard scenario for these experiments and show that it circumvents this limitation. This leads us to prove entanglement advantages from every entangled two-qubit Werner state, evidence its generalisation to high-dimensional systems and establish a connection to quantum teleportation. Our results reveal the power of product measurements for generating quantum correlations in entanglement-assisted communication and they pave the way for practical semi-device-independent entanglement certification well-beyond the constraints of Einstein-Podolsky-Rosen steering.",[''],"['Austria', 'Austria', 'Sweden', 'Sweden']"
"Pre-trained recommendation models (PRMs) have attracted widespread attention recently. However, their totally different model structure, huge model size and computation cost hinder their application in practical recommender systems.
Hence, it is highly essential to explore how to practically utilize PRMs in real-world recommendations.
In this paper, we propose a novel joint knowledge distillation from different pre-trained recommendation models named PRM-KD for recommendation, which takes full advantages of diverse PRMs as teacher models for enhancing student models efficiently.
Specifically, PRM-KD jointly distills diverse informative knowledge from multiple representative PRMs such as UniSRec, Recformer, and UniM22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPTRec. The knowledge from the above PRMs are then smartly integrated into the student recommendation model considering their confidence and consistency.
We further verify the universality of PRM-KD with various types of student models, including sequential recommendation, feature interaction, and graph-based models.
Extensive experiments on five real-world datasets demonstrate the effectiveness and efficacy of PRM-KD, which could be viewed as an economical shortcut in practically and conveniently making full use of different PRMs in online systems.","['Knowledge', 'Distillation', 'Pre-trained', 'Recommendation.']",[]
,[''],[]
,[''],[]
"Factor importance measures the impact of each feature on output prediction accuracy. Many existing works focus on the model-based importance, but an important feature in one learning algorithm may hold little significance in another model. Hence, a factor importance measure ought to characterize the feature’s predictive potential without relying on a specific prediction algorithm. Such algorithm-agnostic importance is termed as intrinsic importance in Williamson et al. (2023), but their estimator again requires model fitting. To bypass the modeling step, we present the equivalence between predictiveness potential and total Sobol’ indices from global sensitivity analysis, and introduce a novel consistent estimator that can be directly estimated from noisy data. Integrating with forward selection and backward elimination gives rise to FIRST, Factor Importance Ranking and Selection using Total (Sobol’) indices. Extensive simulations are provided to demonstrate the effectiveness of FIRST on regression and binary classification problems, and a clear advantage over the state-of-the-art methods.",[''],[]
"We improve the best known upper bound for the bracketing number of d𝑑ditalic_d-dimensional axis-parallel boxes anchored in 00
(or, put differently, of lower left orthants intersected with the d𝑑ditalic_d-dimensional unit cube [0,1]dsuperscript01𝑑[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT).
More precisely, we provide a better upper bound for the cardinality of an algorithmic bracketing cover construction due to Eric Thiémard, which
forms the core of his algorithm to approximate the star discrepancy of arbitrary point sets from
[E. Thiémard, An algorithm to compute bounds for the star discrepancy, J. Complexity 17 (2001), 850 – 880].
Moreover, the new upper bound for the bracketing number of anchored axis-parallel boxes yields an improved upper bound for the bracketing number of arbitrary axis-parallel boxes in [0,1]dsuperscript01𝑑[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT.
In our upper bounds all constants are fully explicit.",[''],[]
"Context:Stellar evolution theory predicts the existence of He-core remnants of the primary components of intermediate-mass close binaries that lost most of their H/He envelopes due to the mass exchange. They are expected to be observed as (1 – 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT hot He-rich stars located in the HRD between sdOB and WR-stars. Several thousands of such stars are expected to exist in the Galaxy, but none of them have been identified so far.
Aims:We aim to provide comprehensive predictions of the numbers and fundamental properties of He-stars and their companions in the Galaxy. This is a necessary first step to guide observations, to enable a comparison between evolutionary models and observed populations, and to determine the feedback of He-stars in the Galaxy.
Methods: We expanded the previously considered space of parameters of progenitors of He-stars and applied a population synthesis based on a grid of models computed by the code MESA.
Results:The estimated number of Galactic binaries hosting (1 – 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT He-stars is ≃20 000similar-to-or-equalsabsent20000\simeq 20\,000≃ 20 000; it declines to
≃3 000similar-to-or-equalsabsent3000\simeq 3\,000≃ 3 000 for mass
  ∼>superscriptsimilar-to\buildrel>\over{\sim}start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG > end_ARG end_RELOP   2 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT. The decisive factor that defines the number of
He-stars is runaway mass loss after Roche lobe overflow by primary components, resulting in formation of common envelopes and merger of components. He-stars are much less numerous than expected, since a fraction of close binaries with M1,0∼<superscriptsimilar-tosubscript𝑀10absentM_{1,0}\ {\raise-2.15277pt\hbox{$\buildrel<\over{\sim}$}}\ italic_M start_POSTSUBSCRIPT 1 , 0 end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG < end_ARG end_RELOP(5 - 7) M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT produce subdwarfs with masses ≲1less-than-or-similar-toabsent1\lesssim 1≲ 1 M⊙subscript𝑀direct-productM_{\odot}italic_M start_POSTSUBSCRIPT ⊙ end_POSTSUBSCRIPT.
Conclusions:Overwhelming majority of He-stars reside in binaries with an early-type companions and can be identified neither by the UV excess nor by emission features.
The large periods of a significant fraction of binaries hosting stripped stars (  ∼>superscriptsimilar-to\buildrel>\over{\sim}start_RELOP SUPERSCRIPTOP start_ARG ∼ end_ARG start_ARG > end_ARG end_RELOP   several hundred days) also hamper their discovery.","['Key', 'Words.: ', 'Stars: evolution –', 'Stars: mass-loss –', 'Methods: numerical']",[]
"We show that there exists a complete local Noetherian normal domain of prime characteristic whose perfection is a non-coherent GCD domain, answering a question of Patankar in the negative concerning characterizations of F𝐹Fitalic_F-coherent rings. This recovers and extends a result of Glaz using tight closure methods.",[''],[]
,[''],[]
"We investigate quadratic quasinormal mode coupling in black hole spacetime through numerical simulations of single perturbed black holes using both numerical relativity and second-order black hole perturbation theory.
Focusing on the dominant ℓ=|m|=2ℓ𝑚2\ell=|m|=2roman_ℓ = | italic_m | = 2 quadrupolar modes, we find good agreement (within ∼10%similar-toabsentpercent10\sim 10\%∼ 10 %) between these approaches, with discrepancies attributed to truncation error and uncertainties from mode fitting.
Our results align with earlier studies extracting the coupling coefficients from select binary black hole merger simulations, showing consistency for the same remnant spins.
Notably, the coupling coefficient is insensitive to a diverse range of initial data, including configurations that led to a significant (up to 5%percent55\%5 %) increase in the remnant black hole mass.
These findings present opportunities for testing the nonlinear dynamics of general relativity with ground-based gravitational wave observatories.
Lastly, we provide evidence of a bifurcation in coupling coefficients between counter-rotating and co-rotating quasinormal modes as black hole spin increases.",[''],"['USA', 'USA', 'USA', 'USA', 'USA', 'Canada', 'USA', 'College', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'Germany', 'USA', 'USA', 'USA']"
"Urban air mobility (UAM), a transformative concept for the transport of passengers and cargo, faces several integration challenges in complex urban environments. Community acceptance of aircraft noise is among the most noticeable of these challenges when launching or scaling up a UAM system. Properly managing community noise is fundamental to establishing a UAM system that is environmentally and socially sustainable. In this work, we develop a holistic and equitable approach to manage UAM air traffic and its community noise impact in urban environments. The proposed approach is a hybrid approach that considers a mix of different noise mitigation strategies, including limiting the number of operations, cruising at higher altitudes, and ambient noise masking. We tackle the problem through the lens of network system control and formulate a multi-objective optimization model for managing traffic flow in a multi-layer UAM network while concurrently pursuing demand fulfillment, noise control, and energy saving. Further, we use a social welfare function in the optimization model as the basis for the efficiency-fairness trade-off in both demand fulfillment and noise control. We apply the proposed approach to a comprehensive case study in the city of Austin and perform design trade-offs through both visual and quantitative analyses.",[''],[]
"This work is about a partition problem which is an instance of the distance magic graph labeling problem.
Given positive integers n,k𝑛𝑘n,kitalic_n , italic_k and p1≤p2≤⋯≤pksubscript𝑝1subscript𝑝2⋯subscript𝑝𝑘p_{1}\leq p_{2}\leq\cdots\leq p_{k}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ ⋯ ≤ italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that p1+⋯+pk=nsubscript𝑝1⋯subscript𝑝𝑘𝑛p_{1}+\cdots+p_{k}=nitalic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ⋯ + italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_n and k𝑘kitalic_k divides ∑i=1nisuperscriptsubscript𝑖1𝑛𝑖\sum_{i=1}^{n}i∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_i, we study the problem of characterizing the cases where it is possible to find a partition of the set {1,2,…,n}12…𝑛\{1,2,\ldots,n\}{ 1 , 2 , … , italic_n } into k𝑘kitalic_k subsets of respective sizes p1,…,pksubscript𝑝1…subscript𝑝𝑘p_{1},\dots,p_{k}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, such that the element sum in each subset is equal.
Using a computerized search we found examples showing that the necessary condition, ∑i=1p1+⋯+pj(n−i+1)≥j⁢(n+12)/ksuperscriptsubscript𝑖1subscript𝑝1⋯subscript𝑝𝑗𝑛𝑖1𝑗binomial𝑛12𝑘\sum_{i=1}^{p_{1}+\cdots+p_{j}}(n-i+1)\geq j{\binom{n+1}{2}}/k∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ⋯ + italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_n - italic_i + 1 ) ≥ italic_j ( FRACOP start_ARG italic_n + 1 end_ARG start_ARG 2 end_ARG ) / italic_k for all j=1,…,k𝑗1…𝑘j=1,\ldots,kitalic_j = 1 , … , italic_k,
is not generally sufficient, refuting a past conjecture.
Moreover, we show that there are infinitely many such counter-examples.
The question whether there is a simple characterization is left open and for all we know the corresponding decision problem might be NP-complete.",[''],[]
"We have used data from the Outer Galaxy High-Resolution Survey (OGHReS) to refine the velocities, distances, and physical properties of a large sample of 3 584 clumps detected in far infrared/submillimetre emission in the Hi-GAL survey located in the ℓ=250⁢°−280⁢°ℓ250°280°\ell=250\degr-280\degrroman_ℓ = 250 ° - 280 ° region of the Galactic plane. Using 1212{}^{12}start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPTCO and 1313{}^{13}start_FLOATSUPERSCRIPT 13 end_FLOATSUPERSCRIPTCO spectra, we have determined reliable velocities to 3 412 clumps (95 per cent of the sample). In comparison to the velocities from the Hi-GAL catalogue, we find good agreement for 80 per cent of the sample (within 5 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT). Using the higher resolution and sensitivity of OGHReS has allowed us to correct the velocity for 632 clumps and provide velocities for 687 clumps for which no velocity had been previously allocated. The velocities are used with a rotation curve to refine the distances to the clumps and to calculate the clumps’ properties using a distance-dependent gas-to-dust ratio. We have determined reliable physical parameters for 3 200 outer Galaxy dense clumps (∼similar-to\sim∼90 per cent of the Hi-GAL sources in the region). We find a trend of decreasing luminosity-to-mass ratio with increasing Galactocentric distance, suggesting the star formation efficiency is lower in the outer Galaxy or that it is resulting in more lower mass stars than in the inner Galaxy. We also find a similar surface density for protostellar clumps located in the inner and outer Galaxy, revealing that the surface density requirements for star formation are the same across the Galactic disc.",[''],[]
"Federated Learning (FL) is a machine-learning approach enabling collaborative model training across multiple decentralized edge devices that hold local data samples, all without exchanging these samples. This collaborative process occurs under the supervision of a central server orchestrating the training or via a peer-to-peer network. The significance of FL is particularly pronounced in industries such as healthcare and finance, where data privacy holds paramount importance.
However, training a model under the Federated learning setting brings forth several challenges, with one of the most prominent being the heterogeneity of data distribution among the edge devices. The data is typically non-independently and non-identically distributed (non-IID), thereby presenting challenges to model convergence. This report delves into the issues arising from non-IID and heterogeneous data and explores current algorithms designed to address these challenges.",[''],[]
"A degree one element of the Orlik-Solomon algebra of a
hyperplane arrangement defines a cochain complex
known as the Aomoto complex. The Aomoto complex
can be considerd as the “linear approximation” of the
twisted cochain complex with coefficients in
a complex rank one local system.
In this paper, we discuss q𝑞qitalic_q-deformations of the Aomoto complex.
The q𝑞qitalic_q-deformation is defined by replacing the entries of
representation matrices of the coboundary maps with their
q𝑞qitalic_q-analogues.
While the resulting maps do not generally defines cochain complexes,
for certain special basis derived from
real structures, the q𝑞qitalic_q-deformation becomes again
a cochain complex.
Moreover, it exhibits universality in the sense that
any specialization of q𝑞qitalic_q to a complex number yields
the cochain complex computing the corresponding local system
cohomology group.","['Key words and phrases:', 'Hyperplane arrangements,', 'Aomoto complex,\nlocal system cohomology, q𝑞qitalic_q-deformation']",[]
"Nowadays, dialogue systems are used in many fields of industry and research. There are successful instances of these systems, such as Apple Siri, Google Assistant, and IBM Watson. Task-oriented dialogue system is a category of these, that are used in specific tasks. They can perform tasks such as booking plane tickets or making restaurant reservations. Shopping is one of the most popular areas on these systems. The bot replaces the human salesperson and interacts with the customers by speaking. To train the models behind the scenes of these systems, annotated data is needed. In this paper, we developed a dataset of dialogues in the Persian language through crowd-sourcing. We annotated these dialogues to train a model. This dataset contains nearly 22k utterances in 15 different domains and 1061 dialogues. This is the largest Persian dataset in this field, which is provided freely so that future researchers can use it. Also, we proposed some baseline models for natural language understanding (NLU) tasks. These models perform two tasks for NLU: intent classification and entity extraction. The F-1 score metric obtained for intent classification is around 91% and for entity extraction is around 93%, which can be a baseline for future research.



Keywords: Task-oriented dialogue systems, Shopping systems, Persian dataset, Annotating, Crowd-sourcing, Chatbots, Natural Language Understanding (NLU)",[''],[]
"This report on axisymmetric ultraspherical/Gegenbauer polynomials [Geg77] and their use in Ambisonic directivity design in 2D and 3D presents an alternative mathematical formalism to what can be read in, e.g., my and Matthias Frank’s book on Ambisonics or Jérôme Daniel’s thesis, Gary Elko’s differential array book chapters, or Boaz Rafaely’s spherical microphone array book. 

My original—but discarded—intention was to already include ultraspherical polynomials in the Ambisonics book to pursue a simple thought: retrieving suitable axisymmetric continuous-direction functions that serve the discrete-direction metrics for experimental psychoacoustic findings in spatial audio uniformly, for any number DD\mathrm{D}roman_D of space dimensions, of course typically D=2,3D23\mathrm{D}=2,3roman_D = 2 , 3. But the cost for this natural way to understand spherical/circular polynomials and their directional sampling was too high. This would have required carrying out both the derivations of two entire formalisms from scratch, the ultraspherical/Gegenbauer polynomials and the circular/spherical harmonics, of which only the latter ones define the Ambisonic format. 

Nevertheless, ultraspherical/Gegenbauer polynomials are highly valuable when designing axisymmetric beams and understanding spherical t𝑡titalic_t designs that this report will shed some light on what circular, spherical, and ultraspherical axisymmetric polynomials are. While mathematically interesting by themselves already, they can be useful in spherical beamforming as described in the literature on spherical and differential microphone arrays, e.g. [Raf19, Elk00, Elk04].
What are polynomials bases for axisymmetric functions, say axisymmetric harmonics (or ultraspherical or Gegenbauer) polynomials? How can they be utilized to define Ambisonic order weightings or spherical beamformers? 

In this report, these ultraspherical/Gegenbauer polynomials will be used to uniformly derive for arbitrary dimensions DD\mathrm{D}roman_D the various directivity designs or Ambisonic order weightings known from literature: max-DI/basic [Dan01], max-rEsubscript𝑟Er_{\mathrm{E}}italic_r start_POSTSUBSCRIPT roman_E end_POSTSUBSCRIPT [Dan01], supercardioid [Raf19, Elk00, Elk04], cardioid/inphase [Dan01]. Is there a way to relate higher-order cardioids and supercardioids? How could one define directivity patterns with an on-axis flatness constraint?",[''],[]
"By 2050, it is predicted that there will be 9 billion people on the planet, which will call for more production, lower costs, and the preservation of natural resources. It is anticipated that atypical occurrences and climate change will pose severe risks to agricultural output. It follows that a 70% or more significant rise in food output is anticipated. Smart farming, often known as agriculture 4.0, is a tech-driven revolution in agriculture with the goal of raising industry production and efficiency. Four primary trends are responsible for it: food waste, climate change, population shifts, and resource scarcity. The agriculture industry is changing as a result of the adoption of emerging technologies. Using cutting-edge technology like IoT, AI, and other sensors, smart farming transforms traditional production methods and international agricultural policies. The objective is to establish a value chain that is optimized to facilitate enhanced monitoring and decreased labor expenses. The agricultural sector has seen tremendous transformation as a result of the fourth industrial revolution, which has combined traditional farming methods with cutting-edge technology to increase productivity, sustainability, and efficiency. To effectively utilize the potential of technology gadgets in the agriculture sector, collaboration between governments, private sector entities, and other stakeholders is necessary. This paper covers Agriculture 4.0, looks at its possible benefits and drawbacks of the implementation methodologies, compatibility, reliability, and investigates the several digital tools that are being utilized to change the agriculture industry and how to mitigate the challenges.","['Index', 'Terms: ', 'Smart', 'Farming,', 'Agriculture 4.0,', 'Precision', 'Farming,', 'Sustainable,', 'IoT,', 'Security,', 'Sensor']",['States']
"This paper proposes an algorithm to calculate the maximal probability of unsafety with respect to trajectories of a stochastic process and a hazard set. The unsafe probability estimation problem is cast as a primal-dual pair of infinite-dimensional linear programs in occupation measures and continuous functions. This convex relaxation is nonconservative (to the true probability of unsafety) under compactness and regularity conditions in dynamics. The continuous-function linear program is linked to existing probability-certifying barrier certificates of safety.
Risk contours for initial conditions of the stochastic process may be generated by suitably modifying the objective of the continuous-function program, forming an interpretable and visual representation of stochastic safety for test initial conditions. All infinite-dimensional linear programs are truncated to finite dimension by the Moment-Sum-of-Squares hierarchy of semidefinite programs. Unsafe-probability estimation and risk contours are generated for example stochastic processes.",[''],[]
"Deep learning is the current de facto state of the art in tomographic imaging. A common approach is to feed the result of a simple inversion, for example the backprojection, to a convolutional neural network (CNN) which then computes the reconstruction. Despite strong results on “in-distribution” test data similar to the training data, backprojection from sparse-view data delocalizes singularities, so these approaches require a large receptive field to perform well. As a consequence, they overfit to certain global structures which leads to poor generalization on out-of-distribution (OOD) samples. Moreover, their memory complexity and training time scale unfavorably with image resolution, making them impractical for application at realistic clinical resolutions, especially in 3D: a standard U-Net requires a substantial 140GB of memory and 2600 seconds per epoch on a research-grade GPU when training on 1024 ×\times× 1024 images. In this paper, we introduce Glimpse, a local processing neural network for computed tomography which reconstructs a pixel value by feeding only the measurements associated with the neighborhood of the pixel to a simple MLP. While achieving comparable or better performance with successful CNNs like the U-Net on in-distribution test data, Glimpse significantly outperforms them on OOD samples while maintaining a memory footprint almost independent of image resolution; 5GB memory suffices to train on 1024 ×\times× 1024 images. Further, we built Glimpse to be fully differentiable, which enables feats such as recovery of accurate projection angles if they are out of calibration.","['Index', 'Terms: ', 'Deep', 'Learning,', 'Computed', 'Tomography,', 'MLP,', 'Uncalibrated', 'Imaging']",[]
"For a space X𝑋Xitalic_X let 𝒦⁢(X)𝒦𝑋\mathcal{K}(X)caligraphic_K ( italic_X ) be the set of compact subsets of X𝑋Xitalic_X ordered by inclusion. A map ϕ:𝒦⁢(X)→𝒦⁢(Y):italic-ϕ→𝒦𝑋𝒦𝑌\phi:\mathcal{K}(X)\to\mathcal{K}(Y)italic_ϕ : caligraphic_K ( italic_X ) → caligraphic_K ( italic_Y ) is a relative Tukey quotient if it carries compact covers to compact covers. When there is such a Tukey quotient write (X,𝒦⁢(X))≥T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))\geq_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ), and write (X,𝒦⁢(X))=T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))=_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) = start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ) if (X,𝒦⁢(X))≥T(Y,𝒦⁢(Y))subscript𝑇𝑋𝒦𝑋𝑌𝒦𝑌(X,\mathcal{K}(X))\geq_{T}(Y,\mathcal{K}(Y))( italic_X , caligraphic_K ( italic_X ) ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_Y , caligraphic_K ( italic_Y ) ) and vice versa.
We investigate the initial structure of pairs (X,𝒦⁢(X))𝑋𝒦𝑋(X,\mathcal{K}(X))( italic_X , caligraphic_K ( italic_X ) ) under the relative Tukey order, focussing on the case of separable metrizable spaces. Connections are made to Menger spaces.
Applications are given demonstrating the diversity of free topological groups, and related free objects, over separable metrizable spaces. It is shown a topological group G𝐺Gitalic_G has the countable chain condition if it is either σ𝜎\sigmaitalic_σ-pseudocompact or for some separable metrizable M𝑀Mitalic_M, we have 𝒦⁢(M)≥T(G,𝒦⁢(G))subscript𝑇𝒦𝑀𝐺𝒦𝐺\mathcal{K}(M)\geq_{T}(G,\mathcal{K}(G))caligraphic_K ( italic_M ) ≥ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_G , caligraphic_K ( italic_G ) ).
Keywords: Tukey order, compact covers, separable metrizable space.
MSC Classification: 03E04, 06A07, 22A05, 54D30, 54D45, 54E35, 54H11.",[''],[]
"We study the structure of the asymptotic expansion of the probability that a
combinatorial object is connected.
We show that the coefficients appearing in those asymptotics are integers and
can be interpreted as the counting sequences of other derivative
combinatorial classes.
The general result applies to rapidly growing combinatorial structures, which we
call gargantuan, that also admit a sequence decomposition.
The result is then applied to several models of graphs, of surfaces
(square-tiled surfaces, combinatorial maps), and to geometric models of
higher dimension (constellations, graph encoded manifolds).
The corresponding derivative combinatorial classes are irreducible
(multi)tournaments, indecomposable (multi)permutations and indecomposable
perfect (multi)matchings.",[''],[]
"High-frequency wide-bandwidth cellular communications over mmW and sub-THz offer the opportunity for high data rates, however, it also presents high pathloss, resulting in limited coverage. To mitigate the coverage limitations, high-gain beamforming is essential. Implementation of beamforming involves a large number of antennas, which introduces analog beam constraint, i.e., only one frequency-flat beam is generated per transceiver chain (TRx). Recently introduced joint phase-time array (JPTA) architecture, which utilizes both true time delay (TTD) units and phase shifters (PSs), alleviates analog beam constraint by creating multiple frequency-dependent beams per TRx, for scheduling multiple users at different directions in a frequency-division manner. One class of previous studies offered solutions with “rainbow” beams, which tend to allocate a small bandwidth per beam direction. Another class focused on uniform linear array (ULA) antenna architecture, whose frequency-dependent beams were designed along a single axis of either azimuth or elevation direction. In this paper, we present a novel 3D beamforming codebook design aimed at maximizing beamforming gain to steer radiation toward desired azimuth and elevation directions, as well as across sub-bands partitioned according to scheduled users’ bandwidth requirements. We provide both analytical solutions and iterative algorithms to design the PSs and TTD units for a desired subband beam pattern. Through simulations of the beamforming gain, we observe that our proposed solutions outperform the state-of-the-art solutions reported elsewhere.
††This work was done in part while O. Yildiz was an intern at Samsung Research America.","['Index', 'Terms: ', 'True time delay, beamforming, millimeter wave, 3D, joint phase-time array, uniform planar array']",['USA']
"Important: This paper does NOT advocate for the use of large language models (LLMs) in therapeutic settings, NOR establish their readiness. Instead, our objective is to enable systematic characterization and assessment of the behavior of current LLMs when they are used for therapy. 
††footnotetext: * Equal contribution
The emergence of ChatGPT and other large language models (LLMs) has greatly increased interest in utilizing LLMs as therapists to support individuals struggling with mental health challenges. However, due to the lack of systematic studies, our understanding of how LLM therapists behave, i.e., ways in which they respond to clients, is significantly limited. Understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences. In this paper, we propose Bolt, a novel computational framework to study the conversational behavior of LLMs when employed as therapists. We develop an in-context learning method to quantitatively measure the behavior of LLMs based on 13 different psychotherapy techniques including reflections, questions, solutions, normalizing, and psychoeducation. Subsequently, we compare the behavior of LLM therapists against that of high- and low-quality human therapy, and study how their behavior can be modulated to better reflect behaviors observed in high-quality therapy. Our analysis of GPT and Llama-variants reveals that these LLMs often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions, which is against typical recommendations. At the same time, unlike low-quality therapy, LLMs reflect significantly more upon clients’ needs and strengths. Our analysis framework suggests that despite the ability of LLMs to generate anecdotal examples that appear similar to human therapists, LLM therapists are currently not fully consistent with high-quality care, and thus require additional research to ensure quality care.",[''],[]
"We consider a toy model for the study of monitored dynamics in a many-body quantum systems. We study the stochastic Schrodinger equation resulting from the continuous monitoring with a rate ΓΓ\Gammaroman_Γ of a random hermitian operator chosen at every time from the gaussian unitary ensemble (GUE). Due to invariance by unitary transformations, the dynamics of the eigenvalues {λα}α=1nsuperscriptsubscriptsubscript𝜆𝛼𝛼1𝑛\{\lambda_{\alpha}\}_{\alpha=1}^{n}{ italic_λ start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_α = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT of the density matrix can be decoupled from that of the eigenvectors. Thus, stochastic equations are derived that exactly describe the dynamics of λ𝜆\lambdaitalic_λ’s. We consider two regimes: in the presence of an extra dephasing term, which can be generated by imperfect quantum measurements, the density matrix has a stationary distribution, and we show that in the limit of large sizes the distribution of λ𝜆\lambdaitalic_λ’s is described by an inverse Marchenko Pastur distribution.
In the case of perfect measurements instead,
purification eventually occurs and we focus on finite-time dynamics. In this case, remarkably, we find an exact solution for the joint probability distribution of λ𝜆\lambdaitalic_λ’s at each time t𝑡titalic_t and for each size n𝑛nitalic_n. Two relevant regimes emerge: at small times t⁢Γ=O⁢(1)𝑡Γ𝑂1t\Gamma=O(1)italic_t roman_Γ = italic_O ( 1 ), the spectrum is in a Coulomb gas regime, with a well-defined continuous spectral distribution in the limit of n→∞→𝑛n\to\inftyitalic_n → ∞. In that case, all moments of the density matrix become self-averaging and it is possible to characterize the entanglement spectrum exactly. In the limit of large times t⁢Γ=O⁢(n)𝑡Γ𝑂𝑛t\Gamma=O(n)italic_t roman_Γ = italic_O ( italic_n ) one enters instead a regime in which the eigenvalues are exponentially separated log⁡(λα/λβ)=O⁢(Γ⁢t/n)subscript𝜆𝛼subscript𝜆𝛽𝑂Γ𝑡𝑛\log(\lambda_{\alpha}/\lambda_{\beta})=O(\Gamma t/n)roman_log ( italic_λ start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT / italic_λ start_POSTSUBSCRIPT italic_β end_POSTSUBSCRIPT ) = italic_O ( roman_Γ italic_t / italic_n ), but fluctuations ∼O⁢(Γ⁢t/n)similar-toabsent𝑂Γ𝑡𝑛\sim O(\sqrt{\Gamma t/n})∼ italic_O ( square-root start_ARG roman_Γ italic_t / italic_n end_ARG ) play an essential role. We are still able to characterize the asymptotic behaviors of entanglement entropy in this regime.",[''],"['France', 'France', 'France', 'France']"
,[''],[]
"We introduce Starcoder, a graph-aware autoencoder ensemble framework, with associated formalisms and tooling, designed to facilitate deep learning for scholarship in the humanities. By composing sub-architectures to produce a model isomorphic to a humanistic domain we maintain interpretability while providing function signatures for each sub-architectural choice, allowing both traditional and computational researchers to collaborate without disrupting established practices. We illustrate a practical application of our approach to a historical study of the American post-Atlantic slave trade, and make several specific technical contributions: a novel hybrid graph-convolutional autoencoder mechanism, batching policies for common graph topologies, and masking techniques for particular use-cases. The effectiveness of the framework for broadening participation of diverse domains is demonstrated by a growing suite of two dozen studies, both collaborations with humanists and established tasks from machine learning literature, spanning a variety of fields and data modalities. We make performance comparisons of several different architectural choices and conclude with an ambitious list of imminent next steps for this research.","['Machine', 'Learning,', 'Humanities']",[]
"Neural Radiance Fields (NeRF) has shown its remarkable performance in neural rendering-based novel view synthesis. However, NeRF suffers from severe visual quality degradation when the input images have been captured under imperfect conditions, such as poor illumination, defocus blurring and lens aberrations. Especially, defocus blur is quite common in the images when they are normally captured using cameras. Although few recent studies have proposed to render sharp images of considerably high-quality, yet they still face many key challenges. In particular, those methods have employed a Multi-Layer Perceptron (MLP) based NeRF which requires tremendous computational time. To overcome these shortcomings, this paper proposes a novel technique Sharp-NeRF—a grid-based NeRF that renders clean and sharp images from the input blurry images within a half an hour training. To do so, we used several grid-based kernels to accurately model the sharpness/blurriness of the scene. The sharpness level of the pixels is computed to learn the spatially varying blur kernels. We have conducted experiments on the benchmarks consisting of blurry images and have evaluated full-reference and non-reference metrics. The qualitative and quantitative results have revealed that our approach renders the sharp novel views with vivid colors and fine details, and it has considerably faster training time than the previous works. Our code is available at https://github.com/benhenryL/SharpNeRF.",[''],[]
"Resource allocation of wide-area internet networks is inherently a combinatorial optimization problem that if solved quickly, could provide near real-time adaptive control of internet-protocol traffic ensuring increased network efficacy and robustness, while minimizing energy requirements coming from power-hungry transceivers. In recent works we demonstrated how such a problem could be cast as a quadratic unconstrained binary optimization (QUBO) problem that can be embedded onto the D-Wave Advantage™  quantum annealer system, demonstrating proof of principle. Our initial studies left open the possibility for improvement of D-Wave solutions via judicious choices of system run parameters. Here we report on our investigations for optimizing these system parameters, and how we incorporate machine learning (ML) techniques to further improve on the quality of solutions. In particular, we use the Hamming distance to investigate correlations between various system-run parameters and solution vectors. We then apply a decision tree neural network (NN) to learn these correlations, with the goal of using the neural network to provide further guesses to solution vectors. We successfully implement this NN in a simple integer linear programming (ILP) example, demonstrating how the NN can fully map out the solution space was not captured by D-Wave. We find, however, for the 3-node network problem the NN is not able to enhance the quality of space of solutions.
\helveticabold


1 Keywords:

discrete optimization,
integer linear program,
machine learning,
quantum annealing,
quantum computing,
resource allocation,
wide-area networks",[''],[]
"We prove that every partially ordered set on n𝑛nitalic_n elements
contains k𝑘kitalic_k subsets A1,A2,…,Aksubscript𝐴1subscript𝐴2…subscript𝐴𝑘A_{1},A_{2},\dots,A_{k}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that either each of these subsets has size Ω⁢(n/k5)Ω𝑛superscript𝑘5\Omega(n/k^{5})roman_Ω ( italic_n / italic_k start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT ) and, for every i<j𝑖𝑗i<jitalic_i < italic_j, every element in Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is less than or equal to every element in Ajsubscript𝐴𝑗A_{j}italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, or each of these subsets has size Ω⁢(n/(k2⁢log⁡n))Ω𝑛superscript𝑘2𝑛\Omega(n/(k^{2}\log n))roman_Ω ( italic_n / ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n ) )
and, for every i≠j𝑖𝑗i\not=jitalic_i ≠ italic_j, every element in Aisubscript𝐴𝑖A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is incomparable with every element in Ajsubscript𝐴𝑗A_{j}italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for i≠j𝑖𝑗i\neq jitalic_i ≠ italic_j. This answers a question of the first author from 2006. As a corollary, we prove for each positive integer hℎhitalic_h there is Chsubscript𝐶ℎC_{h}italic_C start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT such that for any hℎhitalic_h partial orders <1,<2,…,<hsubscript1subscript2…subscriptℎ<_{1},<_{2},\dots,<_{h}< start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , < start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , < start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT on a set of n𝑛nitalic_n elements, there exists k𝑘kitalic_k subsets A1,A2,…,Aksubscript𝐴1subscript𝐴2…subscript𝐴𝑘A_{1},A_{2},\dots,A_{k}italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT each of size at least n/(k⁢log⁡n)Ch𝑛superscript𝑘𝑛subscript𝐶ℎn/(k\log n)^{C_{h}}italic_n / ( italic_k roman_log italic_n ) start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT end_POSTSUPERSCRIPT such that for each partial order <ℓsubscriptℓ<_{\ell}< start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT, either a1<ℓa2<ℓ⋯<ℓaksubscriptℓsubscript𝑎1subscript𝑎2subscriptℓ⋯subscriptℓsubscript𝑎𝑘a_{1}<_{\ell}a_{2}<_{\ell}\dots<_{\ell}a_{k}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ⋯ < start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT for any tuple of elements (a1,a2,…,ak)∈A1×A2×⋯×Aksubscript𝑎1subscript𝑎2…subscript𝑎𝑘subscript𝐴1subscript𝐴2⋯subscript𝐴𝑘(a_{1},a_{2},\dots,a_{k})\in A_{1}\times A_{2}\times\dots\times A_{k}( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ∈ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × ⋯ × italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, or a1>ℓa2>ℓ⋯>ℓaksubscriptℓsubscript𝑎1subscript𝑎2subscriptℓ⋯subscriptℓsubscript𝑎𝑘a_{1}>_{\ell}a_{2}>_{\ell}\dots>_{\ell}a_{k}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ⋯ > start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT for any (a1,a2,…,ak)∈A1×A2×⋯×Aksubscript𝑎1subscript𝑎2…subscript𝑎𝑘subscript𝐴1subscript𝐴2⋯subscript𝐴𝑘(a_{1},a_{2},\dots,a_{k})\in A_{1}\times A_{2}\times\dots\times A_{k}( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ∈ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × ⋯ × italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, or aisubscript𝑎𝑖a_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is incomparable with ajsubscript𝑎𝑗a_{j}italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for any i≠j𝑖𝑗i\neq jitalic_i ≠ italic_j, ai∈Aisubscript𝑎𝑖subscript𝐴𝑖a_{i}\in A_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and aj∈Ajsubscript𝑎𝑗subscript𝐴𝑗a_{j}\in A_{j}italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. This improves on a 2009 result of Pach and the first author motivated by problems in discrete geometry.",[''],[]
"We consider the problem of sampling discrete field configurations ϕitalic-ϕ\phiitalic_ϕ from the Boltzmann distribution [d⁢ϕ]⁢Z−1⁢e−S⁢[ϕ]delimited-[]𝑑italic-ϕsuperscript𝑍1superscript𝑒𝑆delimited-[]italic-ϕ[d\phi]Z^{-1}e^{-S[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S [ italic_ϕ ] end_POSTSUPERSCRIPT, where S𝑆Sitalic_S is the lattice-discretization of the continuous Euclidean action 𝒮𝒮\mathcal{S}caligraphic_S of some quantum field theory. Since such densities arise as the approximation of the underlying functional density [𝒟⁢ϕ⁢(x)]⁢𝒵−1⁢e−𝒮⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscript𝒵1superscript𝑒𝒮delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}^{-1}e^{-\mathcal{S}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator 𝒱tsubscript𝒱𝑡\mathcal{V}_{t}caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT whose time integral provides a mapping between the functional distributions of the free theory [𝒟⁢ϕ⁢(x)]⁢𝒵0−1⁢e−𝒮0⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscriptsubscript𝒵01superscript𝑒subscript𝒮0delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}_{0}^{-1}e^{-\mathcal{S}_{0}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT and of the target theory [𝒟⁢ϕ⁢(x)]⁢𝒵−1⁢e−𝒮⁢[ϕ⁢(x)]delimited-[]𝒟italic-ϕ𝑥superscript𝒵1superscript𝑒𝒮delimited-[]italic-ϕ𝑥[\mathcal{D}\phi(x)]\mathcal{Z}^{-1}e^{-\mathcal{S}[\phi(x)]}[ caligraphic_D italic_ϕ ( italic_x ) ] caligraphic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - caligraphic_S [ italic_ϕ ( italic_x ) ] end_POSTSUPERSCRIPT.
Whenever a particular lattice is chosen, the operator 𝒱tsubscript𝒱𝑡\mathcal{V}_{t}caligraphic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT can be discretized to a finite dimensional, time-dependent vector field Vtsubscript𝑉𝑡V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT which in turn induces a continuous normalizing flow between finite dimensional distributions over the chosen lattice. This flow can then be trained to be a diffeormorphism between the discretized free and target theories [d⁢ϕ]⁢Z0−1⁢e−S0⁢[ϕ]delimited-[]𝑑italic-ϕsuperscriptsubscript𝑍01superscript𝑒subscript𝑆0delimited-[]italic-ϕ[d\phi]Z_{0}^{-1}e^{-S_{0}[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT [ italic_ϕ ] end_POSTSUPERSCRIPT, [d⁢ϕ]⁢Z−1⁢e−S⁢[ϕ]delimited-[]𝑑italic-ϕsuperscript𝑍1superscript𝑒𝑆delimited-[]italic-ϕ[d\phi]Z^{-1}e^{-S[\phi]}[ italic_d italic_ϕ ] italic_Z start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - italic_S [ italic_ϕ ] end_POSTSUPERSCRIPT. We run experiments on the ϕ4superscriptitalic-ϕ4\phi^{4}italic_ϕ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT-theory to explore to what extent such operator-based flow architectures generalize to lattice sizes they were not trained on and show that pretraining on smaller lattices can lead to speedup over training only a target lattice size.",[''],[]
"The dichromatic number χ⁢(G→)𝜒→𝐺\chi(\vec{G})italic_χ ( over→ start_ARG italic_G end_ARG ) of a digraph G→→𝐺\vec{G}over→ start_ARG italic_G end_ARG is the minimum number of colors needed to color the vertices V⁢(G→)𝑉→𝐺V(\vec{G})italic_V ( over→ start_ARG italic_G end_ARG ) in such a way that no monochromatic directed cycle is obtained. In this note, for any k∈ℕ𝑘ℕk\in\mathbb{N}italic_k ∈ blackboard_N, we give a simple construction of tournaments with dichromatic number exactly equal to k𝑘kitalic_k. The proofs are based on a combinatorial lemma on partitioning a checkerboard which may be of independent interest. We also generalize our finite construction to give an elementary construction of a complete digraph of cardinality equal to the cardinality of ℝℝ\mathbb{R}blackboard_R and having an uncountable dichromatic number. Furthermore, we also construct an oriented balanced complete n𝑛nitalic_n-partite graph K→n(m)subscriptsuperscript→𝐾𝑚𝑛\vec{K}^{(m)}_{n}over→ start_ARG italic_K end_ARG start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, such that the minimum number of colors needed to color its vertices such that there is no monochromatic directed triangle is greater than or equal to n⁢m/(n+2⁢m−2)𝑛𝑚𝑛2𝑚2nm/(n+2m-2)italic_n italic_m / ( italic_n + 2 italic_m - 2 ).",[''],[]
"Control design of autonomous vehicles (AVs) has mostly focused on achieving a prespecified goal for an individually controlled AV or for a swarm of cooperatively controlled AVs. However, the impact of autonomous driving on human-driven vehicles (HVs) has been largely ignored in AV controller synthesis, which could result in egoistic AV behavior detrimental to the safety of passengers and surrounding traffic. In this study we develop a general framework for socially compliant control design of AVs with a useful metric of social psychology, called social value orientation (SVO), allowing AVs to leverage their impact on the behavior of the following HVs. This is critical since AVs that behave in a socially compliant manner enable human drivers to comprehend their actions and respond appropriately. Within the proposed framework, we define the utilities of the controlled AV and its following vehicle, to be maximized in a weighted fashion determined by the AV’s SVO. The utility maximization covers an array of design objectives given the goal of the AV and the benefits for the following HV stemming from the courtesy of socially compliant AV controls. An optimal control problem is then formulated to maximize the utility function defined, which is numerically solved using Pontryagin’s minimum principle with optimality guarantees. The methodology developed is applied to synthesize socially compliant control for eco-driving of AVs. A set of numerical results are presented to show the mechanism and effectiveness of the proposed approach using real-world experimental data collected on Highway 55 in Minnesota.",[''],[]
"We give a brief survey of the results on coarse or uniform embeddings of Banach spaces into c0⁢(Γ)subscript𝑐0Γc_{0}(\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ ) and the point character of Banach spaces.
In the process we prove several new results in this direction (for example we determine the point character of the spaces Lp⁢(μ)subscript𝐿𝑝𝜇L_{p}(\mu)italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_μ ), 1≤p≤21𝑝21\leq p\leq 21 ≤ italic_p ≤ 2)
solving open problems posed by C. Avart, P. Komjáth, and V. Rödl and by G. Godefroy, G. Lancien, and V. Zizler.
In particular, we show that X=Lp⁢(μ)𝑋subscript𝐿𝑝𝜇X=L_{p}(\mu)italic_X = italic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_μ ), 1≤p<∞1𝑝1\leq p<\infty1 ≤ italic_p < ∞, bi-Lipschitz embeds into c0⁢(Γ)subscript𝑐0Γc_{0}(\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ ) if and only if dens⁡X<ωωdens𝑋subscript𝜔𝜔\operatorname{dens}X<\omega_{\omega}roman_dens italic_X < italic_ω start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT.","['Key words and phrases: point character, uniform embeddings into c0\u2062(Γ)subscript𝑐0Γc_{0}(\\Gamma)italic_c start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( roman_Γ )']",[]
"The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. Grounded in theory of multimedia learning, this paper explores the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs could range from content creation to tailored support for learning, fostering competencies in scientific practices, and providing assessment and feedback. These scenarios are not limited to text-based and uni-modal formats but can be multimodal, increasing thus personalization, accessibility, and potential learning effectiveness. Besides many opportunities, challenges such as data protection and ethical considerations become more salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educator’s role, ensuring thus an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs on the evolving role of educators and to extend the discourse beyond science education to other disciplines. Through the exploration of potentials, challenges, and future implications, we aim to contribute to a preliminary understanding of the transformative trajectory of MLLMs in science education and beyond.","['Artificial', 'Intelligence,', 'Large', 'Language', 'Models (LLMs),', 'ChatGPT,', 'Multimodal', 'Learning,', 'Cognitive', 'Theory of', 'Multimedia', 'Learning,', 'Science', 'Education']","['MunichMunichBYGermany', 'GeorgiaAthensGAUSA']"
"Despite significant progress in deep learning-based optical flow methods, accurately estimating large displacements and repetitive patterns remains a challenge. The limitations of local features and similarity search patterns used in these algorithms contribute to this issue. Additionally, some existing methods suffer from slow runtime and excessive graphic memory consumption. To address these problems, this paper proposes a novel approach based on the RAFT framework. The proposed Attention-based Feature Localization (AFL) approach incorporates the attention mechanism to handle global feature extraction and address repetitive patterns. It introduces an operator for matching pixels with corresponding counterparts in the second frame and assigning accurate flow values. Furthermore, an Amorphous Lookup Operator (ALO) is proposed to enhance convergence speed and improve RAFT’s ability to handle large displacements by reducing data redundancy in its search operator and expanding the search space for similarity extraction. The proposed method, Efficient RAFT (Ef-RAFT), achieves significant improvements of 10% on the Sintel dataset and 5% on the KITTI dataset over RAFT. Remarkably, these enhancements are attained with a modest 33% reduction in speed and a mere 13% increase in memory usage. The code is available at: https://github.com/n3slami/Ef-RAFT","['Index', 'Terms: ', 'Optical', 'Flow,', 'Large', 'Displacement,', 'Repetitive', 'Patterns,', 'Attention', 'Mechanism,', 'Deep', 'Neural', 'Networks']",['kasaei}@sharif.edu']
"Recent studies in Radiance Fields have paved the robust way for novel view synthesis with their photorealistic rendering quality. Nevertheless, they usually employ neural networks and volumetric rendering, which are costly to train and impede their broad use in various real-time applications due to the lengthy rendering time.
Lately 3D Gaussians splatting-based approach has been proposed to model the 3D scene, and it achieves remarkable visual quality while rendering the images in real-time. However, it suffers from severe degradation in the rendering quality if the training images are blurry. Blurriness commonly occurs due to the lens defocusing, object motion, and camera shake, and it inevitably intervenes in clean image acquisition. Several previous studies have attempted to render clean and sharp images from blurry input images using neural fields. The majority of those works, however, are designed only for volumetric rendering-based neural radiance fields and are not straightforwardly applicable to rasterization-based 3D Gaussian splatting methods.
Thus, we propose a novel real-time deblurring framework, deblurring 3D Gaussian Splatting, using a small Multi-Layer Perceptron (MLP) that manipulates the covariance of each 3D Gaussian to model the scene blurriness. While deblurring 3D Gaussian Splatting can still enjoy real-time rendering, it can reconstruct fine and sharp details from blurry images. A variety of experiments have been conducted on the benchmark, and the results have revealed the effectiveness of our approach for deblurring. Qualitative results are available at https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/",[''],[]
"This paper presents the CMB angular power spectrum obtained using the CAMB code for three different models of inflation: the Starobinsky inflationary model, the generalized Starobinsky inflationary model, and the chaotic inflationary model with a step. The results are compared with the most recent data reported for the Planck mission. An analysis of the large (l≲90less-than-or-similar-to𝑙90l\lesssim 90italic_l ≲ 90), intermediate (90≲l≲900less-than-or-similar-to90𝑙less-than-or-similar-to90090\lesssim l\lesssim 90090 ≲ italic_l ≲ 900), and small (l≳900greater-than-or-equivalent-to𝑙900l\gtrsim 900italic_l ≳ 900) angular scales is performed. We report the position of the peaks in the intermediate region so as the cosmological parameters obtained in each of the models: age of the universe, ΩmsubscriptΩ𝑚\Omega_{m}roman_Ω start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, ΩbsubscriptΩ𝑏\Omega_{b}roman_Ω start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT, ΩΛsubscriptΩΛ\Omega_{\Lambda}roman_Ω start_POSTSUBSCRIPT roman_Λ end_POSTSUBSCRIPT, ΩKsubscriptΩ𝐾\Omega_{K}roman_Ω start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT and nSsubscript𝑛Sn_{\mathrm{S}}italic_n start_POSTSUBSCRIPT roman_S end_POSTSUBSCRIPT.",[''],[]
"The heterochaos baker maps are piecewise affine maps of the unit square or cube introduced by Saiki et al. [59],
to provide a hands-on, elementary understanding of complicated phenomena in systems of large degrees of freedom.
We review recent progress on a dynamical systems theory of the heterochaos baker maps, and present new results on properties of measures of maximal entropy and the underlying Lebesgue measure.
We address several conjectures and questions that may illuminate new aspects of heterochaos and inspire future research.",[''],[]
"In recent years, the techniques of analytic combinatorics in several variables (ACSV) have been applied to determine asymptotics for several families of lattice path models restricted to the orthant ℕdsuperscriptℕ𝑑\mathbb{N}^{d}blackboard_N start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and defined by step sets 𝒮⊂{−1,0,1}d∖{𝟎}𝒮superscript101𝑑0\mathcal{S}\subset\{-1,0,1\}^{d}\setminus\{\mathbf{0}\}caligraphic_S ⊂ { - 1 , 0 , 1 } start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ∖ { bold_0 }. Using the theory of ACSV for smooth singular sets, Melczer and Mishna determined asymptotics for the number of walks in any model whose set of steps 𝒮𝒮\mathcal{S}caligraphic_S is ‘highly symmetric’ (symmetric over every axis). Building on this work, Melczer and Wilson determined asymptotics for all models where 𝒮𝒮\mathcal{S}caligraphic_S is ‘mostly symmetric’ (symmetric over all but one axis) except for models whose set of steps have a vector sum of zero but are not highly symmetric. In this paper we complete the asymptotic classification of the mostly symmetric case by analyzing a family of saddle-point-like integrals whose amplitudes are singular near their saddle points.",[''],[]
"Locally harmonic manifolds are Riemannian manifolds in which small geodesic spheres are isoparametric hypersurfaces, i.e., hypersurfaces whose nearby parallel hypersurfaces are of constant mean curvature. Flat and rank one symmetric spaces are examples of harmonic manifolds. Damek–Ricci spaces are non-compact harmonic manifolds, most of which are non-symmetric. Taking the limit of an “inflating” sphere through a point p𝑝pitalic_p in a Damek–Ricci space as the center of the sphere runs out to infinity along a geodesic half-line γ𝛾\gammaitalic_γ starting from p𝑝pitalic_p, we get a horosphere. Similarly to spheres, horospheres are also isoparametric hypersurfaces. In this paper, we define the sphere-like hypersurfaces obtained by “overinflating the horospheres” by pushing the center of the sphere beyond the point at infinity of γ𝛾\gammaitalic_γ along a virtual prolongation of γ𝛾\gammaitalic_γ. They give a new family of isoparametric hypersurfaces in Damek–Ricci spaces connecting geodesic spheres to some of the isoparametric hypersurfaces constructed by J. C. Díaz-Ramos and M. Domínguez-Vázquez [17] in Damek–Ricci spaces. We study the geometric properties of these isoparametric hypersurfaces, in particular their homogeneity and the totally geodesic condition for their focal varieties.","['Key words and phrases: ', 'Isoparametric hypersurface, focal variety,', 'Damek–Ricci space, mean curvature']",[]
,[''],[]
"Accurately selecting and estimating smooth functional effects in additive models with potentially many functions is a challenging task. We introduce a novel Demmler-Reinsch basis expansion to model the functional effects that allows us to orthogonally decompose an effect into its linear and nonlinear parts. We show that our representation allows to consistently estimate both parts as opposed to commonly employed mixed model representations. Equipping the reparameterized regression coefficients with normal beta prime spike and slab priors allows us to determine whether a continuous covariate has a linear, a nonlinear or no effect at all. We provide new theoretical results for the prior and a compelling explanation for its superior Markov chain Monte Carlo mixing performance compared to the spike-and-slab group lasso. We establish an efficient posterior estimation scheme and illustrate our approach along effect selection on the hazard rate of a time-to-event response in the geoadditive Cox regression model in simulations and data on survival with leukemia.",[''],['Dortmund']
"We translate Giovanni Curi’s predicative least fixed point theorem into type theory. There are benefits to having a type theoretic formulation apart from the potential for routine formalization. By taking advantage of (higher) inductive types, we have skirted the painstaking set theoretic constructions and as a result believe our presentation is conceptually clearer. Additionally, due the predicative admissibility of (higher) inductive types we take a step towards the \saysystem independent derivation that Curi calls for in his conclusion. To conclude the paper we explore a condition on monotone maps that guarantees they are ‘generated’ in a sense we make precise. This allows for an alternative statement of the least fixed point theorem which goes beyond the version found in Curi’s work.",[''],[]
"In 2008, L. Zádori proved that the subspace lattice Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) of a vector space V𝑉Vitalic_V of finite dimension at least 3333 over a finite field F𝐹Fitalic_F has a 5-element generating set, i.e., Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is 5-generated. We extend his result to all 1111-generated fields; in particular, to all fields F𝐹Fitalic_F such that the extension from the prime field of F𝐹Fitalic_F to F𝐹Fitalic_F is of finite degree.
Furthermore, we prove that if the field F𝐹Fitalic_F is t𝑡titalic_t-generated for some finite or infinite cardinal number t𝑡titalic_t, d≥3𝑑3d\geq 3italic_d ≥ 3 denotes the finite dimension of V𝑉Vitalic_V, and
m𝑚mitalic_m is the least cardinal such that m⁢(d−1)𝑚𝑑1m(d-1)italic_m ( italic_d - 1 ) is at least t𝑡titalic_t, then Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is (4+m)4𝑚(4+m)( 4 + italic_m )-generated and the k𝑘kitalic_k-th direct power of Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is (5+m)5𝑚(5+m)( 5 + italic_m )-generated for many positive integers k𝑘kitalic_k; for all positive integers k𝑘kitalic_k if F𝐹Fitalic_F is infinite. In particular, if t𝑡titalic_t is finite, then Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) is 5-generated for all but finitely many values of d𝑑ditalic_d.
We prove also that, for a fixed d𝑑ditalic_d, as t𝑡titalic_t (now the minimum number of elements generating F𝐹Fitalic_F) tends to infinity or is infinite, then so does or so is the minimum number of elements of the generating sets of Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ), respectively.
Finally, let n𝑛nitalic_n be a positive integer.
For i=1,…,n𝑖1…𝑛i=1,\dots,nitalic_i = 1 , … , italic_n, let pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be a prime number or 0, and let Visubscript𝑉𝑖V_{i}italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the 3-dimensional vector space over the prime field of characteristic pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. We prove that the direct product of the lattices Sub⁢(V1)Subsubscript𝑉1\textup{Sub}(V_{1})Sub ( italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), …, Sub⁢(Vn)Subsubscript𝑉𝑛\textup{Sub}(V_{n})Sub ( italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) is 4-generated if and only if each of the numbers p1subscript𝑝1p_{1}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, …, pnsubscript𝑝𝑛p_{n}italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT occurs in the sequence p1subscript𝑝1p_{1}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, …, pnsubscript𝑝𝑛p_{n}italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT at most four times. Neither this direct product nor any of the subspace lattices Sub⁢(V)Sub𝑉\textup{Sub}(V)Sub ( italic_V ) above is 3-generated.","['Key words and phrases:', 'Small generating set, four element generating set, subspace lattice, projective space, coordinatization of lattices, field extension']",[]
"In distributed radar systems, when several transmitters radiate simultaneously,
the reflected signals
need to be distinguished at the receivers to detect various targets. If the transmit signals are in different frequency bands, they require a large overall bandwidth.
Instead, a set of pseudo-orthogonal waveforms derived from the Zadoff-Chu (ZC) sequences could be accommodated in the same band, enabling the efficient use of available bandwidth for better range resolution.
In such a design, special care must be given to the ‘near-far’ problem, where a reflection could possibly become difficult to detect due to the presence of stronger reflections.
In this work, a scheme to detect multiple targets in such distributed radar systems is proposed.
It performs successive cancellations (SC) starting from the strong, detectable reflections in the domain of the Discrete Chirp-Fourier Transform (DCFT) after compensating for Doppler shifts, enabling the subsequent detections of weaker targets which are not trivially detectable.
Numerical
simulations corroborate the efficacy and usefulness
of the proposed method in detecting weak target reflections.","['Index', 'Terms: ', 'Distributed', 'Radar,', 'Multistatic', 'Radar,', 'Multi-Target', 'Detection,', 'Zadoff-Chu', 'Sequences,', 'Successive', 'Cancellation,', 'Discrete', 'Chirp-Fourier', 'Transform (DCFT).']",['k.giridhar}@telwise-research.com']
"We propose a semi-analytic Stokes expansion ansatz for finite-depth
standing water waves and devise a recursive algorithm to solve the
system of differential equations governing the expansion
coefficients. We implement the algorithm on a supercomputer using
arbitrary-precision arithmetic. The Stokes expansion introduces
hyperbolic trigonometric terms that require exponentiation of power
series. We handle this efficiently using Bell polynomials. Under mild
assumptions on the fluid depth, we prove that there are no exact
resonances, though small divisors may occur. Sudden changes in growth
rate in the expansion coefficients are found to correspond to
imperfect bifurcations observed when families of standing waves are
computed using a shooting method. A direct connection between small
divisors in the recursive algorithm and imperfect bifurcations in the
solution curves is observed, where the small divisor excites
higher-frequency parasitic standing waves that oscillate on top of the
main wave. A 109th order Padé approximation maintains 25–30 digits
of accuracy on both sides of the first imperfect bifurcation
encountered for the unit-depth problem. This suggests that even if the
Stokes expansion is divergent, there may be a closely related
convergent sequence of rational approximations.","['standing water waves finite depth semi-analytic', 'Stokes\nexpansion conformal map bifurcation']",[]
"The nearly continuous stream of miniature comets dominated by the
Kreutz sungrazers has been an unexpected great bonanza for cometary
science initiated by the launch of the Solar and Heliospheric Observatory
(SOHO) in 1995. Over the nearly 30 years since the time, no serious attempt
has been made to formulate a self-consistent model for the formation and
evolution of this stream of Kreutz comets — the goal of the present two-part
investigation. Part I describes historical highlights of the research
that has been relevant to the problem of SOHO sungrazers (including the major
contributions by Hubbard, Kreutz, and Marsden) and furnishes preliminaries
of diagnostic value that are intended to facilitate, and provide critical
information for, the work in Part II. Formerly noted issues, such as the
high frequency of close pairs in the SOHO database, are proposed to be
products of a broader process of swarming, seen in both the nodal longitude
and time. I present examples of tight swarms revealed by high arrival rates
of the SOHO Kreutz sungrazers, primarily from Population I.","['Subject headings: individual comets:', 'X/1106', 'C1,', 'C/1843', 'D1,', 'C/1880', 'C1,', 'C/1882', 'R1,', 'C/1963', 'R1,', 'C/1965', 'S1,', 'C/1970', 'K1,', 'C/2011', 'W3; methods: data analysis']",['ZdenSek@gmail.com']
"The proposed Laser Interferometer Space Antenna (LISA) mission is tasked with the detection and characterization of gravitational waves from various sources in the universe. This endeavor is challenged by transient displacement and acceleration noise artifacts, commonly called glitches. Uncalibrated glitches impact the interferometric measurements and decrease the signal quality of LISA’s time-delay interferometry (TDI) data used for astrophysical data analysis. The paper introduces a novel calibration pipeline that employs a neural network ensemble to detect, characterize, and mitigate transient glitches of diverse morphologies. A convolutional neural network is designed for anomaly detection, accurately identifying and temporally pinpointing anomalies within the TDI time series. Then, a hybrid neural network is developed to differentiate between gravitational wave bursts and glitches, while a long short-term memory (LSTM) network architecture is deployed for glitch estimation. The LSTM network acts as a TDI inverter by processing noisy TDI data to obtain the underlying glitch dynamics. Finally, the inferred noise transient is subtracted from the interferometric measurements, enhancing data integrity and reducing biases in the parameter estimation of astronomical targets. We propose a low-latency solution featuring generalized LSTM networks primed for rapid response data processing and alert service in high-demand scenarios like predicting binary black hole mergers. The research highlights the critical role of machine learning in advancing methodologies for data calibration and astrophysical analysis in LISA.",[''],['Switzerland']
"We present a lightweight and affordable motion capture method based on two smartwatches and a head-mounted camera. In contrast to the existing approaches that use six or more expert-level IMU devices, our approach is much more cost-effective and convenient. Our method can make wearable motion capture accessible to everyone, enabling 3D full-body motion capture in diverse environments.
As a key idea to overcome the extreme sparsity and ambiguities of sensor inputs, we integrate 6D head poses obtained from the head-mounted cameras for motion estimation.
To enable capture in expansive indoor and outdoor scenes, we propose an algorithm to track and update floor level changes to define head poses, coupled with a multi-stage Transformer-based regression module.
We also introduce novel strategies leveraging visual cues of egocentric images to further enhance the motion capture quality while reducing ambiguities.
We demonstrate the performance of our method on various challenging scenarios, including complex outdoor environments and everyday motions including object interactions and social interactions among multiple individuals.",[''],[]
"We study two-site deconstructions of the S⁢U⁢(2)L𝑆𝑈subscript2𝐿SU(2)_{L}italic_S italic_U ( 2 ) start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT gauge group factor of the SM. Models based on this approach can explain the hierarchies of the quark masses and CKM mixing between the third and light families if these fields are localised on different sites, leading to a global accidental U⁢(2)q×U⁢(3)u×U⁢(3)d𝑈subscript2𝑞𝑈subscript3𝑢𝑈subscript3𝑑U(2)_{q}\times U(3)_{u}\times U(3)_{d}italic_U ( 2 ) start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT × italic_U ( 3 ) start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT × italic_U ( 3 ) start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT flavour symmetry. This symmetry prevents dangerously large effects in flavour observables, making a TeV scale realisation possible. Given the structure of PMNS matrix in the neutrino sector, we explore different possibilities for the arrangement of the leptons on the two sites, and consider different models with U⁢(2)ℓ𝑈subscript2ℓU(2)_{\ell}italic_U ( 2 ) start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT or U⁢(3)ℓ𝑈subscript3ℓU(3)_{\ell}italic_U ( 3 ) start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT flavour symmetries. The phenomenology of the models is mostly governed by a massive vector triplet of S⁢U⁢(2)L𝑆𝑈subscript2𝐿SU(2)_{L}italic_S italic_U ( 2 ) start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT. We study the interesting interplay between LHC searches and precision observables. In particular, one of the models can give a sizeable lepton flavour universal effect in the Wilson coefficient C9subscript𝐶9C_{9}italic_C start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT
while naturally suppressing contributions to C10subscript𝐶10C_{10}italic_C start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT,
as suggested by current b→s⁢ℓ+⁢ℓ−→𝑏𝑠superscriptℓsuperscriptℓb\to s\ell^{+}\ell^{-}italic_b → italic_s roman_ℓ start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT roman_ℓ start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT data, predicting simultaneously a mild positive shift in the W𝑊Witalic_W boson mass.",[''],"['Italy,', 'Kingdom', 'Spain', 'Switzerland', 'Switzerland', 'Switzerland', 'Spain', 'Poland']"
"In the evolution of Vision-Language Pre-training, shifting from short-text comprehension to encompassing extended textual contexts is pivotal.
Recent autoregressive vision-language models like [2, 14], leveraging the long-context capability of Large Language Models, have excelled in few-shot text generation tasks but face challenges in alignment tasks.
Addressing this gap, we introduce the contrastive loss into text generation models, presenting the COntrastive-Streamlined MultimOdal framework (CosMo), strategically partitioning the language model into dedicated unimodal text processing and adept multimodal data handling components.
CosMo, our unified framework, merges unimodal and multimodal elements, enhancing model performance for tasks involving textual and visual data while notably reducing learnable parameters.
However, these models demand extensive long-text datasets, yet the availability of high-quality long-text video datasets remains limited.
To bridge this gap, this work introduces Howto-Interlink7M, an inaugural interleaved video-text dataset featuring comprehensive captions, marking a significant step forward.
Demonstrating its impact, we illustrate how Howto-Interlink7M enhances model performance in image-text tasks.
With 34% learnable parameters and utilizing 72% of the available data, our model demonstrates significant superiority over OpenFlamingo [3].
For instance, in the 4-shot flickr captioning task, performance notably improves from 57.2% to 65.1%.
The contributions of CosMo and Howto-Interlink7M are underscored by notable performance gains across 14 diverse downstream datasets encompassing both image-text and video-text tasks.",[''],[]
"Given the difficulty of manually annotating motion in video, the current best motion estimation methods are trained with synthetic data, and therefore struggle somewhat due to a train/test gap. Self-supervised methods hold the promise of training directly on real video, but typically perform worse. These include methods trained with warp error (i.e., color constancy) combined with smoothness terms, and methods that encourage cycle-consistency in the estimates (i.e., tracking backwards should yield the opposite trajectory as tracking forwards). In this work, we take on the challenge of improving state-of-the-art supervised models with self-supervised training. We find that when the initialization is supervised weights, most existing self-supervision techniques actually make performance worse instead of better, which suggests that the benefit of seeing the new data is overshadowed by the noise in the training signal. Focusing on obtaining a “clean” training signal from real-world unlabelled video, we propose to separate label-making and training into two distinct stages. In the first stage, we use the pre-trained model to estimate motion in a video, and then select the subset of motion estimates which we can verify with cycle-consistency. This produces a sparse but accurate pseudo-labelling of the video. In the second stage, we fine-tune the model to reproduce these outputs, while also applying augmentations on the input. We complement this boot-strapping method with simple techniques that densify and re-balance the pseudo-labels, ensuring that we do not merely train on “easy” tracks. We show that our method yields reliable gains over fully-supervised methods in real videos, for both short-term (flow-based) and long-range (multi-frame) pixel tracking.",[''],[]
"We study the holographic complexity of a pair of asymptotically dS universes in the presence of axion matter, to characterize these observables in more general spacetimes. The system is prepared in a two-copy Hartle-Hawking state by slicing an Euclidean wormhole, which entangles the two universes. We derive the evolution of codimension-1 Complexity=Anything proposals by anchoring the probes to a worldline observer in each of the universes and connecting them through the Euclidean wormhole. We investigate how the axion charge competes with the cosmological constant in the time evolution of complexity. When the complexity proposal equals the volume of an extremal surface, its evolution is determined by the scale factor of the axion-dS universe, and as a result, the observable might increase nearly exponentially for low axion charge, while it decreases to a vanishing value as one approaches the maximal axion charge allowed by de Sitter space.",[''],[]
"In this paper, we introduce the notion of the diagonal property and the weak point property for an ind-variety. We prove that the ind-varieties of higher rank divisors of integral slopes on a smooth projective curve have the weak point property. Moreover, we show that the ind-variety of (1,n)1𝑛(1,n)( 1 , italic_n )-divisors has the diagonal property. Furthermore, we obtain that the Hilbert schemes associated to the good partitions of a constant polynomial satisfy the diagonal property. In the process of obtaining this, we provide the exact number of such Hilbert schemes up to isomorphism by proving that the multi symmetric products associated to two distinct partitions of a positive integer n𝑛nitalic_n are not isomorphic.",[''],[]
"Light and sound waves have the fascinating property that they can move objects through the transfer of linear or angular momentum. This ability has led to the development of optical and acoustic tweezers, with applications ranging from biomedical engineering to quantum optics. Although impressive manipulation results have been achieved, the stringent requirement for a highly controlled, low-reverberant, and static environment still hinders the applicability of these techniques in many scenarios. Here, we overcome this challenge and demonstrate the manipulation of objects in disordered and dynamic media, by optimally tailoring the momentum of sound waves iteratively in the far field. The method does not require information about the object’s physical properties or the spatial structure of the surrounding medium but relies only on a real-time scattering matrix measurement and a positional guidestar. Our experiment demonstrates the possibility of optimally moving and rotating objects, extending the reach of wave-based object manipulation to complex and dynamic scattering media. We envision new opportunities for biomedical applications, sensing, or manufacturing.","['Object manipulation, wave-momentum shaping, scattering, adaptive acoustics.']","['Switzerland.', 'Kazakhstan.', 'Switzerland.', 'France.', 'Austria', 'Switzerland.']"
,[''],"['Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'Germany', 'tim.schroeder@physik.hu-berlin.de']"
"These instructions give you guidelines for preparing papers for
IEEE Transactions and Journals. Use this document as a template if you are
using LATEX. Otherwise, use this document as an
instruction set. The electronic file of your paper will be formatted further
at IEEE. Paper titles should be written in uppercase and lowercase letters,
not all uppercase. Avoid writing long formulas with subscripts in the title;
short formulas that identify the elements are fine (e.g., ”Nd–Fe–B”). Do
not write “(Invited)” in the title. Full names of authors are preferred in
the author field, but are not required. Put a space between authors’
initials. The abstract must be a concise yet comprehensive reflection of
what is in your article. In particular, the abstract must be self-contained,
without abbreviations, footnotes, or references. It should be a microcosm of
the full article. The abstract must be between 150–250 words. Be sure that
you adhere to these limits; otherwise, you will need to edit your abstract
accordingly. The abstract must be written as one paragraph, and should not
contain displayed mathematical equations or tabular material. The abstract
should include three or four different keywords or phrases, as this will
help readers to find it. It is important to avoid over-repetition of such
phrases as this can result in a page being rejected by search engines.
Ensure that your abstract reads well and is grammatically correct.","['Index', 'Terms: ', 'Enter key words or phrases in alphabetical\norder, separated by commas.', 'For a list of suggested keywords, send a blank\ne-mail to keywords@ieee.org or visit http://www.ieee.org/organizations/pubs/ani_prod/keywrd98.txt']",[]
,[''],[]
"Climate change and global warming have been trending topics worldwide since the Eco-92 conference. However, little progress has been made in reducing greenhouse gases (GHGs). The problems and challenges related to emissions are complex and require a concerted and comprehensive effort to address them. Emissions reporting is a critical component of GHG reduction policy and is therefore the focus of this work.
It is crucial to improve the process efficiency of emissions reporting in order to achieve better emissions reduction results, as there is a direct link between effective emissions policies implemented by cities and emissions reduction (or increase) due to the effectiveness of these policies. Hence, to achieve this goal, this work proposes a series of steps to investigate, search and develop performance indicators (PIs) for emissions reporting. These performance indicators are based on the data provided by cities on the processes they go through to address emission problems. PIs can be used to guide and optimize the policies responsible for implementing emission reduction measures at the city level. Therefore, the main goal of this work is two-fold: (i) to propose an emission reporting evaluation model to leverage emissions reporting overall quality and (ii) to use artificial intelligence (AI) to support the initiatives that improve emissions reporting.
Thus, this work presents an Emissions Reporting Maturity Model (ERMM) for examining, clustering, and analysing data from emissions reporting initiatives to help the cities to deal with climate change and global warming challenges. The model is built using Capability Maturity Model (CMM) concepts and uses artificial intelligence clustering technologies, performance indicator candidates and a qualitative analysis approach to find the data flow along the emissions-related processes implemented by cities. The Performance Indicator Development Process (PIDP) proposed in this work provides ways to leverage the quality of the available data necessary for the execution of the evaluations identified by the ERMM. Hence, the PIDP supports the preparation of the data from emissions-related databases, the classification of the data according to similarities highlighted by different clustering techniques, and the identification of performance indicator candidates, which are strengthened by a qualitative analysis of selected data samples.
Thus, the main goal of ERRM is to evaluate and classify the cities regarding the emission reporting processes, pointing out the drawbacks and challenges faced by other cities from different contexts, and at the end to help them to leverage the underlying emissions-related processes and emissions mitigation initiatives.",[''],[]
"This letter proposes the experimental validation of an optimisation method for periodic metasurfaces. A previous study showed the design and simulation of a classical anomalous reflecting metasurface and enlightened the parasitic reflection induced by the translational invariances of the structure. The method applies to periodic structures, in the framework of the Floquet analysis. It consists of the exploitation of the Floquet type simulation outputs of a periodic element of the structure to predict the behaviour of the complete structure in terms of radar cross section (RCS). The proposed application focuses on the reduction of the RCS level of the structure in one particular Floquet direction. The fabricated metasurfaces and experimental setup are presented with the associated measurements. The well-agreeing simulation and experimental results validate the proposed optimization procedure.",[''],"['France', 'France', 'matthieu.elineau.scholar@gmail.com', 'France', 'France', 'France', 'France', 'France', 'France']"
"The metaverse is expected to provide immersive entertainment, education, and business applications. However, virtual reality (VR) transmission over wireless networks is data- and computation-intensive, making it critical to introduce novel solutions that meet stringent quality-of-service requirements. With recent advances in edge intelligence and deep learning, we have developed a novel multi-view synthesizing framework that can efficiently provide computation, storage, and communication resources for wireless content delivery in the metaverse.
We propose a three-dimensional (3D)-aware generative model that uses collections of single-view images. These single-view images are transmitted to a group of users with overlapping fields of view, which avoids massive content transmission compared to transmitting tiles or whole 3D models. We then present a federated learning approach to guarantee an efficient learning process. The training performance can be improved by characterizing the vertical and horizontal data samples with a large latent feature space, while low-latency communication can be achieved with a reduced number of transmitted parameters during federated learning.
We also propose a federated transfer learning framework to enable fast domain adaptation to different target domains. Simulation results have demonstrated the effectiveness of our proposed federated multi-view synthesizing framework for VR content delivery.","['Index', 'Terms: ', 'Metaverse, virtual reality, multi-view synthesizing, federated learning, deep learning.']",[]
"Recent progress in quantum technologies with ultracold atoms has been propelled by spatially fine-tuned control of lasers and diffraction-limited imaging. The state-of-the-art precision of optical alignment to achieve this fine-tuning is reaching the limits of manual control. Here, we show how to automate this process. One of the elementary techniques of manual alignment of optics is cross-walking of laser beams. Here, we generalize this technique to multi-variable cross-walking. Mathematically, this is a variant of the well-known Alternating Minimization (AM) algorithm in convex optimization and is closely related to the Gauss-Seidel algorithm. Therefore, we refer to our multi-variable cross-walking algorithm as the modified AM algorithm. While cross-walking more than two variables manually is challenging, one can do this easily for machine-controlled variables. We apply this algorithm to mechanically align high numerical aperture (NA) objectives and show that we can produce high-quality diffraction-limited tweezers and point spread functions (PSF). After a rudimentary coarse alignment, the algorithm takes about 1111 hour to align the optics to produce high-quality tweezers. Moreover, we use the same algorithm to optimize the shape of a deformable mirror along with the mechanical variables and show that it can be used to correct for optical aberrations produced, for example, by glass thickness when producing tweezers and imaging point sources. The shape of the deformable mirror is parametrized using the first 14141414 non-trivial Zernike polynomials, and the corresponding coefficients are optimized together with the mechanical alignment variables. We show PSF with a Strehl ratio close to 1111 and tweezers with a Strehl ratio >0.8absent0.8>0.8> 0.8. The algorithm demonstrates exceptional robustness, effectively operating in the presence of significant mechanical fluctuations induced by a noisy environment.",[''],['States']
,[''],[]
,[''],[]
,[''],[]
"The magnetic state of UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT was determined experimentally to be anti-ferromagnetic. Starting from this experimental fact, researchers have calculated other properties within the Hubbard-corrected density-functional theory, DFT+U. Up to now, the Hubbard parameters for UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT were usually so chosen that the calculations give good results for some experimental data.
Also, to our knowledge there exists no valid theoretical research report on the energetically stable magnetic state of this system. In present work, employing the new method which is based on density-functional perturbation theory, we have determined self-consistently the Hubbard parameters and ground-state energies for UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT crystal in both ferromagnetic and anti-ferromagnetic configurations, and the calculated results show that UO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT crystal energetically favors an anti-ferromagnetic state with a small energy difference.
In all the calculations the PBE-sol approximation was used for the exchange-correlation energy functional.","['Uranium dioxide;', 'Ferromagnetism;', 'Anti-ferromagnetism;', 'Density-Functional', 'Theory;', 'Hubbard', 'Model;', 'Mott', 'Insulator;', 'DFT+U.']",['Iran']
"Data science pipelines commonly utilize dataframe and array operations for tasks such as data preprocessing, analysis, and machine learning. The most popular tools for these tasks are pandas and NumPy. However, these tools are limited to executing on a single node, making them unsuitable for processing large-scale data.
Several systems have attempted to distribute data science applications to clusters while maintaining interfaces similar to single-node libraries, enabling data scientists to scale their workloads without significant effort. However, existing systems often struggle with processing large datasets due to Out-of-Memory (OOM) problems caused by poor data partitioning.
To overcome these challenges, we develop Xorbits, a high-performance, scalable data science framework specifically designed to distribute data science workloads across clusters while retaining familiar APIs. The key differentiator of Xorbits is its ability to dynamically switch between graph construction and graph execution.
Xorbits has been successfully deployed in production environments with up to 5k CPU cores. Its applications span various domains, including user behavior analysis and recommendation systems in the e-commerce sector, as well as credit assessment and risk management in the finance industry.
Users can easily scale their data science workloads by simply changing the import line of their pandas and NumPy code.
Our experiments demonstrate that Xorbits can effectively process very large datasets without encountering OOM or data-skewing problems.
Over the fastest state-of-the-art solutions, Xorbits achieves an impressive 2.66×\times× speedup on average. In terms of API coverage, Xorbits attains a compatibility rate of 96.7%, surpassing the fastest framework by an impressive margin of 60 percentage points.
Xorbits is available at https://github.com/xorbitsai/xorbits.","['Index', 'Terms: \nscalable data science, dataframe, array, tiling, computation graph']",[]
"For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. In this paper, we provide quantifier-free necessary and sufficient conditions for two symmetric matrices to realize a given eigenvalue configuration. The basic idea is to generate a set of polynomials in the entries of the two matrices whose roots can be counted to uniquely determine the eigenvalue configuration.
This result can be seen as a
generalization of Descartes’ rule of signs to the case of two real univariate polynomials.",[''],"['USA', 'USA', 'Spain']"
"In this paper we show how tensor networks help in developing explainability of machine learning algorithms. Specifically, we develop an unsupervised clustering algorithm based on Matrix Product States (MPS) and apply it in the context of a real use-case of adversary-generated threat intelligence. Our investigation proves that MPS rival traditional deep learning models such as autoencoders and GANs in terms of performance, while providing much richer model interpretability. Our approach naturally facilitates the extraction of feature-wise probabilities, Von Neumann Entropy, and mutual information, offering a compelling narrative for classification of anomalies and fostering an unprecedented level of transparency and interpretability, something fundamental to understand the rationale behind artificial intelligence decisions.",[''],"['Spain', 'Spain', 'Spain', 'Spain', 'Spain']"
"J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ production in high-energy hadronic collisions is sensitive to both perturbative and non-perturbative aspects of quantum chromodynamics (QCD) calculations. The production of a heavy-quark pair is well-described by perturbative QCD, whereas the
formation of the bound state involves non-perturbative processes, treated in different ways by various available theoretical models. ALICE can measure inclusive J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ at both forward and midrapidity down to low pTsubscript𝑝T{p_{\rm T}}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT and the prompt and non-prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ separation can be performed at midrapidity. The study of the production of non-prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ originating from the decay of beauty hadrons, besides allowing to isolate the prompt J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ cross section from the inclusive J/ψJ𝜓\mathrm{J}/\psiroman_J / italic_ψ cross section, can be used to estimate open beauty-hadron production. Heavy-flavour particle production in pp collisions as a function of charged-particle multiplicity can provide insight into the processes occuring in the collision at the partonic level, as well as the interplay between the hard and soft mechanisms in particle production.",[''],[]
"In the evolving field of machine learning, video generation has witnessed significant advancements with autoregressive-based transformer models and diffusion models, known for synthesizing dynamic and realistic scenes. However, these models often face challenges with prolonged inference times, even for generating short video clips such as GIFs. This paper introduces FlashVideo, a novel framework tailored for swift Text-to-Video generation. FlashVideo represents the first successful adaptation of the RetNet architecture for video generation, bringing a unique approach to the field. Leveraging the RetNet-based architecture, FlashVideo reduces the time complexity of inference from 𝒪⁢(L2)𝒪superscript𝐿2\mathcal{O}(L^{2})caligraphic_O ( italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to 𝒪⁢(L)𝒪𝐿\mathcal{O}(L)caligraphic_O ( italic_L ) for a sequence of length L𝐿Litalic_L, significantly accelerating inference speed. Additionally, we adopt a redundant-free frame interpolation method, enhancing the efficiency of frame interpolation. Our comprehensive experiments demonstrate that FlashVideo achieves a ×9.17absent9.17\times 9.17× 9.17 efficiency improvement over a traditional autoregressive-based transformer model, and its inference speed is of the same order of magnitude as that of BERT-based transformer models.",[''],[]
"Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern. Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources. We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget. The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model’s memory of the original input. A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields. P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments. Experimental results indicate P2F’s robust capability to obfuscate LLM’s memory, attaining a forgetfulness score of around 90% without any utility loss. This represents an enhancement of up to 63% when contrasted with the naive direct instruction technique, highlighting P2F’s efficacy in mitigating memory retention of sensitive information within LLMs. Our findings establish the first benchmark in the novel field of the LLM forgetting task, representing a meaningful advancement in privacy preservation in the emerging LLM domain.",[''],"['[', '[', '[']"
"Identifying spatially complete planar primitives from visual data is a crucial task in computer vision.
Prior methods are largely restricted to either 2D segment recovery or simplifying 3D structures, even with extensive plane annotations.
We present PlanarNeRF, a novel framework capable of detecting dense 3D planes through online learning.
Drawing upon the neural field representation, PlanarNeRF brings three major contributions.
First, it enhances 3D plane detection with concurrent appearance and geometry knowledge.
Second, a lightweight plane fitting module is proposed to estimate plane parameters.
Third, a novel global memory bank structure with an update mechanism is introduced, ensuring consistent cross-frame correspondence.
The flexible architecture of PlanarNeRF allows it to function in both 2D-supervised and self-supervised solutions, in each of which it can effectively learn from sparse training signals, significantly improving training efficiency.
Through extensive experiments, we demonstrate the effectiveness of PlanarNeRF in various scenarios and remarkable improvement over existing works.",[''],[]
,[''],[]
"Self-supervised learning is a popular and powerful method for utilizing large amounts of unlabeled data, for which a wide variety of training objectives have been proposed in the literature. In this study, we perform a Bayesian analysis of state-of-the-art self-supervised learning objectives, elucidating the underlying probabilistic graphical models in each class and presenting a standardized methodology for their derivation from first principles. The analysis also indicates a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a novel lower bound which is proven to reliably penalize the most important failure modes. Furthermore, this newly proposed lower bound enables the training of a standard backbone architecture without the necessity for asymmetric elements such as stop gradients, momentum encoders, or specialized clustering layers—typically introduced to avoid learning trivial solutions. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, thus showing that our objective function allows to outperform existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that GEDI can be integrated into a neural-symbolic framework to mitigate the reasoning shortcut problem and to learn higher quality symbolic representations thanks to the enhanced classification performance.",[''],[]
"We investigate the temperature effects in an imbalanced superfluid atomic Fermi gas. We consider a bilayer system of two-component dipolar fermionic atoms with one layer containing atoms of one component and the other layer the atoms of other component with an imbalance between the populations of the two components. This imbalance results in uniform and nonuniform superfluid phases such as phase-separated BCS, Fulde-Ferrel-Larkin-Ovchinnikov (FFLO), Sarma and normal Fermi liquid phases for different system parameters. Using the mean-field BCS theory together with the superfluid mass-density criterion we classify different phases in thermodynamic phase diagram. Our results indicate that for a dipolar Fermi system the Sarma phase is stable for large imbalance at finite temperature below the critical temperature, and the FFLO phase is stable for intermediate imbalance on the BCS side of a BCS-BCE crossover. The phase diagram in the temperature and population imbalance plane indicate three Lifshitz points: one corresponding to coexistance of BCS, FFLO and normal Fermi liquid phase while the other two correspond to the coexistance of the Sarma phase, FFLO phase and normal Fermi phase for dipolar interactions.",[''],['India.']
"The ability of snapshot compressive imaging (SCI) systems to efficiently capture high-dimensional (HD) data depends on the advent of novel optical designs to sample the HD data as two-dimensional (2D) compressed measurements. Nonetheless, the traditional SCI scheme is fundamentally limited, due to the complete disregard for high-level information in the sampling process. To tackle this issue, in this paper,
we pave the first mile toward the advanced design of adaptive coding masks for SCI. Specifically, we propose an efficient and effective algorithm to generate coding masks with the assistance of saliency detection, in a low-cost and low-power fashion.
Experiments demonstrate the effectiveness and efficiency of our approach.
Code is available at: https://github.com/IndigoPurple/SASA.",[''],[]
"Analyzing connections between brain regions of interest (ROI) is vital to detect neurological disorders such as autism or schizophrenia. Recent advancements employ graph neural networks (GNNs) to utilize graph structures in brains, improving detection performances. Current methods use correlation measures between ROI’s blood-oxygen-level-dependent (BOLD) signals to generate the graph structure. Other methods use the training samples to learn the optimal graph structure through end-to-end learning. However, implementing those methods independently leads to some issues with noisy data for the correlation graphs and overfitting problems for the optimal graph. In this work, we proposed Bargrain (balanced graph structure for brains), which models two graph structures: filtered correlation matrix and optimal sample graph using graph convolution networks (GCNs). This approach aims to get advantages from both graphs and address the limitations of only relying on a single type of structure. Based on our extensive experiment, Bargrain outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.","['Brain', 'Network', 'Classification', 'Graph', 'Learning', 'Graph', 'Neural', 'Networks', 'Disease', 'Detection']",[]
"The generative priors of pre-trained latent diffusion models have demonstrated great potential to enhance the perceptual quality of image super-resolution (SR) results. Unfortunately, the existing diffusion prior-based SR methods encounter a common problem, i.e., they tend to generate rather different outputs for the same low-resolution image with different noise samples. Such stochasticity is desired for text-to-image generation tasks but problematic for SR tasks, where the image contents are expected to be well preserved. To improve the stability of diffusion prior-based SR, we propose to employ the diffusion models to refine image structures, while employing the generative adversarial training to enhance image fine details. Specifically, we propose a non-uniform timestep learning strategy to train a compact diffusion network, which has high efficiency and stability to reproduce the image main structures, and finetune the pre-trained decoder of variational auto-encoder (VAE) by adversarial training for detail enhancement. Extensive experiments show that our proposed method, namely content consistent super-resolution (CCSR), can significantly reduce the stochasticity of diffusion prior-based SR, improving the content consistency of SR outputs and speeding up the image generation process. Codes and models can be found at https://github.com/csslc/CCSR.",[''],[]
"We report the measurement of the cross sections for e+⁢e−→hadrons→superscript𝑒superscript𝑒hadronse^{+}e^{-}\rightarrow{\rm hadrons}italic_e start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT → roman_hadrons at
center-of-mass (c.m.) energies from 3.645 to 3.871 GeV.
We observe a new resonance ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 ) in the cross sections for the
first time, and observe the ℛ⁢(3760)ℛ3760\mathcal{R}(3760)caligraphic_R ( 3760 ) resonance with high significance
in the cross sections.
The ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 ) has a mass of (3804.5±0.9±0.9)plus-or-minus3804.50.90.9(3804.5\pm 0.9\pm 0.9)( 3804.5 ± 0.9 ± 0.9 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT,
a total width of (5.4±3.5±3.2)plus-or-minus5.43.53.2(5.4\pm 3.5\pm 3.2)( 5.4 ± 3.5 ± 3.2 ) MeV,
and an electronic partial width of (19.4±7.4±12.1)plus-or-minus19.47.412.1(19.4\pm 7.4\pm 12.1)( 19.4 ± 7.4 ± 12.1 ) eV.
Its significance is 7.7⁢σ7.7𝜎7.7\sigma7.7 italic_σ. The ℛ⁢(3810)ℛ3810\mathcal{R}(3810)caligraphic_R ( 3810 )
could be interpreted as a hadro-charmonium resonance predicted by Quantum Chromodynamics (QCD).
In addition, we measure the mass (3751.9±3.8±2.8)plus-or-minus3751.93.82.8(3751.9\pm 3.8\pm 2.8)( 3751.9 ± 3.8 ± 2.8 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT,
the total width (32.8±5.8±8.7)plus-or-minus32.85.88.7(32.8\pm 5.8\pm 8.7)( 32.8 ± 5.8 ± 8.7 ) MeV,
and the electronic partial width (184±75±86)plus-or-minus1847586(184\pm 75\pm 86)( 184 ± 75 ± 86 ) eV with improved precision
for the ℛ⁢(3760)ℛ3760\mathcal{R}(3760)caligraphic_R ( 3760 ). Furthermore, for the ℛ⁢(3780)ℛ3780\mathcal{R}(3780)caligraphic_R ( 3780 ) we measure the mass
(3778.7±0.5±0.3)plus-or-minus3778.70.50.3(3778.7\pm 0.5\pm 0.3)( 3778.7 ± 0.5 ± 0.3 )  MeV/c2superscript𝑐2c^{2}italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and total width
(20.3±0.8±1.7)plus-or-minus20.30.81.7(20.3\pm 0.8\pm 1.7)( 20.3 ± 0.8 ± 1.7 ) MeV with improved precision,
and the electronic partial width (265±69±83)plus-or-minus2656983(265\pm 69\pm 83)( 265 ± 69 ± 83 ) eV.
The ℛ⁢(3780)ℛ3780\mathcal{R}(3780)caligraphic_R ( 3780 ) can be interpreted as the 13⁢D1superscript13subscript𝐷11^{3}D_{1}1 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT state of charmonium.
Its mass and total width differ significantly from the corresponding
fitted values given by the Particle Data Group in 2022 by
7.1 and 3.2 times the uncertainties for ψ⁢(3770)𝜓3770\psi(3770)italic_ψ ( 3770 ), respectively.
ψ⁢(3770)𝜓3770\psi(3770)italic_ψ ( 3770 ) has been interpreted as the 13⁢D1superscript13subscript𝐷11^{3}D_{1}1 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT state for 45 years.",[''],[]
"In the absence of data protection measures, software applications lead to privacy breaches, posing threats to end-users and software organisations. Privacy Enhancing Technologies (PETs) are technical measures that protect personal data, thus minimising such privacy breaches. However, for software applications to deliver data protection using PETs, software developers should actively and correctly incorporate PETs into the software they develop. Therefore, to uncover ways to encourage and support developers to embed PETs into software, this Systematic Literature Review (SLR) analyses 39 empirical studies on developers’ privacy practices. It reports the usage of six PETs in software application scenarios. Then, it discusses challenges developers face when integrating PETs into software, ranging from intrinsic challenges, such as the unawareness of PETs, to extrinsic challenges, such as the increased development cost. Next, the SLR presents the existing solutions to address these challenges, along with the limitations of the solutions. Further, it outlines future research avenues to better understand PETs from a developer perspective and minimise the challenges developers face when incorporating PETs into software.","['Privacy', 'Enhancing', 'Technologies, data protection, developers, secure computation']","['Zealand', 'CSIROCanberraAustralia', 'UniversitySydneyAustralia', 'Zealand']"
,[''],[]
,[''],[]
"Rush hour and sustained traffic flows in eight cities are studied using the IBM Mega
Traffic Simulator to understand the importance of road structures and vehicle
acceleration in the prevention of gridlock. Individual cars among the tens of
thousands launched are monitored at every simulation time step using live streaming
data transfer from the simulation software to analysis software on another computer.
A measure of gridlock is the fraction of cars moving at less than 30% of their
local road speed. Plots of this fraction versus the instantaneous number of cars on
the road show hysteresis during rush hour simulations, indicating that it can take
twice as long to unravel clogged roads as fill them. The area under the hysteresis
loop is used as a measure of gridlock to compare different cities normalized to the
same central areas. The differences between cities, combined with differences
between idealized models using square or triangular road grids, indicate that
gridlock tends to occur most when there are a small number of long roads that
channel large fractions of traffic. These long roads help light traffic flow but
they make heavy flows worse. Increasing the speed on these long roads makes gridlock
even worse in heavy conditions. City throughput rates are also modeled using a
smooth ramp up to a constant vehicle launch rate. Models with increasing
acceleration for the same road speeds show clear improvements in city traffic flow
as a result of faster interactions at intersections and merging points. However,
these improvements are relatively small when the gridlock is caused by long roads
having many cars waiting to exit at the same intersection. In general, gridlock in
our models begins at intersections regardless of the available road space in the
network.","['traffic, cities, simulation, agent based, gridlock']",['10598']
,[''],[]
"Electrostatic force actuation is a key component of the system of geodesic reference test masses (TM) for the LISA orbiting gravitational wave observatory and in particular for performance at low frequencies, below 1 mHz, where the observatory sensitivity is limited by stray force noise. The system needs to apply forces of order 10−99{}^{-9}start_FLOATSUPERSCRIPT - 9 end_FLOATSUPERSCRIPT N while limiting fluctuations in the measurement band to levels approaching 10−1515{}^{-15}start_FLOATSUPERSCRIPT - 15 end_FLOATSUPERSCRIPT N/Hz1/212{}^{1/2}start_FLOATSUPERSCRIPT 1 / 2 end_FLOATSUPERSCRIPT. We present here the LISA actuation system design, based on audio-frequency voltage carrier signals, and results of its in-flight performance test with the LISA Pathfinder test mission. In LISA, TM force actuation is used to align the otherwise free-falling TM to the spacecraft-mounted optical metrology system, without any forcing along the critical gravitational wave-sensitive interferometry axes. In LISA Pathfinder, on the other hand, the actuation was used also to stabilize the TM along the critical x𝑥xitalic_x axis joining the two TM, with the commanded actuation force entering directly into the mission’s main differential acceleration science observable. The mission allowed demonstration of the full compatibility of the electrostatic actuation system with the LISA observatory requirements, including dedicated measurement campaigns to amplify, isolate, and quantify the two main force noise contributions from the actuation system, from actuator gain noise and from low frequency “in band” voltage fluctuations. These campaigns have shown actuation force noise to be a relevant, but not dominant, noise source in LISA Pathfinder and have allowed performance projections for the conditions expected in the LISA mission.",[''],"['\\addressa', '\\addressb', '\\addressca', '\\addressgg', '\\addressc', '\\addressb', '\\addressf', '\\addressu', '\\addressi', '\\addressk', '\\addresso', '\\addressi', '\\addressj', '\\addressi', '\\addressb', '\\addressa', '\\addresshh', '\\addressii', '\\addressb', '\\addressj', '\\addressi', '\\addressl', '\\addressi', '\\addressm', '\\addressa', '\\addressn', '\\addressl', '\\addressee', '\\addressi', '\\addressb', '\\addresskk', '\\addresso', '\\addressh', '\\addressp', '\\addressb', '\\addressb', '\\addressb', '\\addressd', '\\addressj', '\\addressi', '\\addresscb', '\\addressca', '\\addressh', '\\addressq', '\\addressa', '\\addressbb', '\\addressb', '\\addressca', '\\addressr', '\\addressi', '\\addressn', '\\addressn', '\\addressp', '\\addressl', '\\addressn', '\\addressa', '\\addressa', '\\addressca', '\\addressh', '\\addressp', '\\addressa', '\\addressl', '\\addressff', '\\addressn', '\\addressb', '\\addressr', '\\addressc', '\\addressca', '\\addressca', '\\addressff', '\\addresss', '\\addressb', '\\addresscc', '\\addressi', '\\addressr', '\\addressx', '\\addressi', '\\addressi', '\\addressaa', '\\addressll', '\\addressu', '\\addressn', '\\addressjj', '\\addressd', '\\addressl', '\\addressa', '\\addressu', '\\addressi', '\\addressi', '\\addressb', '\\addressr', '\\addressd', '\\addressdd', '\\addressi', '\\addressb', '\\addressb', '\\addressi', '\\addressl']"
"Reservoir computing is a machine learning technique which has been shown to be able to replicate the chaotic attractor, including the fractal dimension and the entire Lyapunov spectrum, of the dynamical system on which it is trained. We quantitatively relate the generalized synchronization dynamics of a driven reservoir computer during the training stage to the performance of the autonomous reservoir computer at the attractor reconstruction task. We show that, for successful attractor reconstruction and Lyapunov exponent estimation, the largest conditional Lyapunov exponent of the driven reservoir must be significantly smaller (more negative) than the smallest (most negative) Lyapunov exponent of the true system. We find that the maximal conditional Lyapunov exponent of the reservoir depends strongly on the spectral radius of the reservoir adjacency matrix, and therefore, for attractor reconstruction and Lyapunov exponent estimation, small spectral radius reservoir computers perform better in general. Our arguments are supported by numerical examples on well-known chaotic systems.",[''],[]
,[''],[]
"Searches for spacetime variations of fundamental constants have entered an era of unprecedented precision. New, high quality quasar spectra require increasingly refined analytic methods. In this article, a continuation in a series to establish robust and unbiased methodologies, we explore how convergence criteria in non-linear least squares optimisation impact on quasar absorption system measurements of the fine structure constant α𝛼\alphaitalic_α. Given previous claims for high-precision constraints, we critically examine the veracity of a so-called “blinding” approach, in which α𝛼\alphaitalic_α is fixed at the terrestrial value during the model building process, releasing it as a free parameter only after the “final” absorption system kinematic structure has been obtained. We show that this approach results in an extended flat canyon in χ2superscript𝜒2\chi^{2}italic_χ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-α𝛼\alphaitalic_α space, such that convergence is unlikely to be reached, even after as many as 1000 iterations. The fix is straightforward: α𝛼\alphaitalic_α must be treated as a free parameter from the earliest possible stages of absorption system model building. The implication of the results presented here is that all previous measurements that have used initially-fixed α𝛼\alphaitalic_α should be reworked.",[''],[]
"We report unbiased AI measurements of the fine structure constant α𝛼\alphaitalic_α in two proximate absorption regions in the spectrum of the quasar HE0515−--4414. The data are high resolution, high signal to noise, and laser frequency comb calibrated, obtained using the ESPRESSO spectrograph on the VLT. The high quality of the data and proximity of the regions motivate a differential comparison, exploring the possibility of spatial variations of fundamental constants, as predicted in some theories. We show that if the magnesium isotopic relative abundances are terrestrial, the fine structure constants in these two systems differ at the 7σ𝜎\sigmaitalic_σ level. A 3σ𝜎\sigmaitalic_σ discrepancy between the two measurements persists even for the extreme non-terrestrial case of 100% 2424{}^{24}start_FLOATSUPERSCRIPT 24 end_FLOATSUPERSCRIPTMg, if shared by both systems. However, if Mg isotopic abundances take independent values in these two proximate systems, one terrestrial, the other with no heavy isotopes, both can be reconciled with a terrestrial α𝛼\alphaitalic_α, and the discrepancy between the two measurements falls to 2σ𝜎\sigmaitalic_σ. We discuss varying constant and varying isotope interpretations and resolutions to this conundrum for future high precision measurements.","['Cosmology: cosmological parameters –', 'Cosmology: dark energy –', 'Cosmology: dark matter –', 'Galaxies: intercluster medium –', 'Electroweak interaction']","['UK,', 'UK,', 'Australia.', 'Australia.', 'Italy,', 'Italy,', 'Italy.', 'Australia.', 'UK.']"
,[''],[]
"In this work, we consider the atypical non-equilibrium state found in [1708.06328] which holographically represents a behind-the-horizon excitation in a blackhole spacetime. The special feature of this state is that it looks like an equilibrium state when probed by a class of low-energy operators. First, we retrieve this property using the uniformization mapping in the limit of large central charge, in the process we are able to derive rather than presume approximate thermal physics.
Furthermore, in the large-c and high-energy limit we realize these excitations as elements of the commutant algebra of a GNS representation of the light operator algebra. Instead of analytically continuing a mixed heavy-light Euclidean correlator to a Lorentzian correlator, we identify the Euclidean correlator as a GNS linear form and interpret the Lorentzian correlator as a vacuum expectation value of representatives of the light operator algebra on the GNS vacuum.","['Conformal', 'Field', 'Theory,', 'AdS/CFT, von', 'Neumann', 'Algebras']",[]
,[''],[]
"Let g1,…,gMsubscript𝑔1…subscript𝑔𝑀g_{1},\dots,g_{M}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_g start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT be additive functions for which there exist nonconstant polynomials G1,…,GMsubscript𝐺1…subscript𝐺𝑀G_{1},\dots,G_{M}italic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_G start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT satisfying gi⁢(p)=Gi⁢(p)subscript𝑔𝑖𝑝subscript𝐺𝑖𝑝g_{i}(p)=G_{i}(p)italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_p ) = italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_p ) for all primes p𝑝pitalic_p and all i∈{1,…,M}𝑖1…𝑀i\in\{1,\dots,M\}italic_i ∈ { 1 , … , italic_M }. Under fairly general and nearly optimal hypotheses, we show that the functions g1,…,gMsubscript𝑔1…subscript𝑔𝑀g_{1},\dots,g_{M}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_g start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT are jointly
equidistributed among the residue classes to moduli q𝑞qitalic_q varying uniformly up to a fixed but arbitrary power of log⁡x𝑥\log xroman_log italic_x. Thus, we obtain analogues of the Siegel-Walfisz Theorem for primes in arithmetic progressions, but with primes replaced by values of such additive functions.
Our results partially extend work of Delange from fixed moduli to varying moduli, and also generalize recent work done for a single additive function.","['Key words and phrases: additive function, uniform distribution, equidistribution, joint distribution, joint equidistribution']",[]
"The proliferation of social network data has unlocked unprecedented opportunities for extensive, data-driven exploration of human behavior. The structural intricacies of social networks offer insights into various computational social science issues, particularly concerning social influence and information diffusion. However, modeling large-scale social network data comes with computational challenges. Though large language models make it easier than ever to model textual content, any advanced network representation methods struggle with scalability and efficient deployment to out-of-sample users. In response, we introduce a novel approach tailored for modeling social network data in user detection tasks. This innovative method integrates localized social network interactions with the capabilities of large language models. Operating under the premise of social network homophily, which posits that socially connected users share similarities, our approach is designed to address these challenges. We conduct a thorough evaluation of our method across seven real-world social network datasets, spanning a diverse range of topics and detection tasks, showcasing its applicability to advance research in computational social science.","['Social', 'Network,', 'User', 'Detection,', 'User', 'Behavior,', 'Network', 'Homophily']","['USA', 'USA']"
"Federated learning (FL) underpins advancements in privacy-preserving distributed computing by collaboratively training neural networks without exposing clients’ raw data. Current FL paradigms primarily focus on unimodal data, while exploiting the knowledge from distributed multimodal data remains largely unexplored. Existing multimodal FL (MFL) solutions are mainly designed for statistical or modality heterogeneity from the input side, however, have yet to solve the fundamental issue, ‘modality imbalance’, in distributed conditions, which can lead to inadequate information exploitation and heterogeneous knowledge aggregation on different modalities.In this paper, we propose a novel Cross-Modal Infiltration Federated Learning (FedCMI) framework that effectively alleviates modality imbalance and knowledge heterogeneity via knowledge transfer from the global dominant modality. To avoid the loss of information in the weak modality due to merely imitating the behavior of dominant modality, we design the two-projector module to integrate the knowledge from dominant modality while still promoting the local feature exploitation of weak modality. In addition, we introduce a class-wise temperature adaptation scheme to achieve fair performance across different classes. Extensive experiments over popular datasets are conducted and give us a gratifying confirmation of the proposed framework for fully exploring the information of each modality in MFL.",[''],[]
"Using martingale theory, we compute, in very few lines, exact analytical expressions for various first-exit-time statistics associated with one-dimensional biased diffusion. Examples include the distribution for the first-exit time from an interval, moments for the first-exit site, and functionals of the position, which involve memory and time integration. As a key example, we compute analytically the mean area swept by a biased diffusion until it escapes an interval that may be asymmetric and have arbitrary length. The mean area allows us to derive the hitherto unexplored cross-correlation function between the first-exit time and the first-exit site, which vanishes only for exit problems from symmetric intervals. As a colophon, we explore connections of our results with gambling, showing that betting on the time-integrated value of a losing game it is possible to design a strategy that leads to a net average win.","['Martingale theory,', 'First-passage processes,', 'Brownian motion']","['Italy', 'Italy', 'Italy', 'Italy']"
"Within recent approaches to text-to-video (T2V) generation, achieving controllability in the synthesized video is often a challenge. Typically, this issue is addressed by providing low-level per-frame guidance in the form of edge maps, depth maps, or an existing video to be altered. However, the process of obtaining such guidance can be labor-intensive. This paper focuses on enhancing controllability in video synthesis by employing straightforward bounding boxes to guide the subject in various ways, all without the need for neural network training, finetuning, optimization at inference time, or the use of pre-existing videos. Our algorithm, TrailBlazer, is constructed upon a pre-trained (T2V) model, and easy to implement.111Our project page: https://hohonu-vicml.github.io/Trailblazer.Page/ The subject is directed by a bounding box through the proposed spatial and temporal attention map editing. Moreover, we introduce the concept of keyframing, allowing the subject trajectory and overall appearance to be guided by both a moving bounding box and corresponding prompts, without the need to provide a detailed mask. The method is efficient, with negligible additional computation relative to the underlying pre-trained model. Despite the simplicity of the bounding box guidance, the resulting motion is surprisingly natural, with emergent effects including perspective and movement toward the virtual camera as the box size increases.",[''],[]
"As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data.
Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training.
This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities.
In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures and more.
Then, we systematically investigate its wide-ranging applications across domains.
Furthermore, we also explore the commonalities and differences between masked modeling methods in different fields.
Toward the end of this paper, we conclude by discussing the limitations of current techniques and point out several potential avenues for advancing masked modeling research.
A paper list project with this survey is available at https://github.com/Lupin1998/Awesome-MIM.","['Index', 'Terms: ', 'Self-supervised', 'Learning,', 'Masked', 'Modeling,', 'Generative', 'Model,', 'Natural', 'Language', 'Processing,', 'Audio and', 'Speech,', 'Graph']",[]
"Let R𝑅Ritalic_R be a commutative ring with identity and a fixed invertible element q12superscript𝑞12q^{\frac{1}{2}}italic_q start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT, and suppose q+q−1𝑞superscript𝑞1q+q^{-1}italic_q + italic_q start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is invertible in R𝑅Ritalic_R. For each planar surface Σ0,n+1subscriptΣ0𝑛1\Sigma_{0,n+1}roman_Σ start_POSTSUBSCRIPT 0 , italic_n + 1 end_POSTSUBSCRIPT, we present its Kauffman bracket skein algebra over R𝑅Ritalic_R by explicit generators and relations. The presentation is independent of R𝑅Ritalic_R, and can be considered as a quantization of the trace algebra of n𝑛nitalic_n generic 2×2222\times 22 × 2 unimodular matrices.
Keywords: planar surface; Kauffman bracket skein algebra; character variety; quantization; presentation 
MSC2020: 57K16, 57K31",[''],[]
,[''],[]
"Sperm whales (Physeter macrocephalus) navigate underwater with a series of impulsive, click-like sounds known as echolocation clicks. These clicks are characterized by a multipulse structure (MPS) that serves as a distinctive pattern. In this work, we use the stability of the MPS as a detection metric for recognizing and classifying the presence of clicks in noisy environments. To distinguish between noise transients and to handle simultaneous emissions from multiple sperm whales, our approach clusters a time series of MPS measures while removing potential clicks that do not fulfil the limits of inter-click interval, duration and spectrum.
 As a result, our approach can handle high noise transients and low signal-to-noise ratio. The performance of our detection approach is examined using three datasets: seven months of recordings from the Mediterranean Sea containing manually verified ambient noise; several days of manually labelled data collected from the Dominica Island containing approximately 40,000 clicks from multiple sperm whales; and a dataset from the Bahamas containing 1,203 labelled clicks from a single sperm whale. Comparing with the results of two benchmark detectors, a better trade-off between precision and recall is observed as well as a significant reduction in false detection rates, especially in noisy environments. To ensure reproducibility, we provide our database of labelled clicks along with our implementation code.","['Index', 'Terms: \n', 'Sperm whale clicks, passive acoustic monitoring (PAM), real-time detection,', 'Inter-pulse interval (IPI),', 'Inter-click interval (ICI).']","['Israel', 'Croatia', 'roee.d@univ.haifa.ac.il']"
"Video grounding aims to localize a spatio-temporal section in a video corresponding to an input text query. This paper addresses a critical limitation in current video grounding methodologies by introducing an Open-Vocabulary Spatio-Temporal Video Grounding task. Unlike prevalent closed-set approaches that struggle with open-vocabulary scenarios due to limited training data and predefined vocabularies, our model leverages pre-trained representations from foundational spatial grounding models. This empowers it to effectively bridge the semantic gap between natural language and diverse visual content, achieving strong performance in closed-set and open-vocabulary settings. Our contributions include a novel spatio-temporal video grounding model, surpassing state-of-the-art results in closed-set evaluations on multiple datasets and demonstrating superior performance in open-vocabulary scenarios.
Notably, the proposed model outperforms state-of-the-art methods in closed-set settings on VidSTG (Declarative and Interrogative) and HC-STVG (V1 and V2) datasets. Furthermore, in open-vocabulary evaluations on HC-STVG V1 and YouCook-Interactions, our model surpasses the recent best-performing models by 4.26 m_vIoU and 1.83% accuracy, demonstrating its efficacy in handling diverse linguistic and visual concepts for improved video understanding. Our codes will be released at https://github.com/TalalWasim/Video-GroundingDINO.",[''],[]
"This paper uses the MIMIC-IV dataset to examine the fairness and bias in an XGBoost binary classification model predicting the Intensive Care Unit (ICU) length of stay (LOS). Highlighting the critical role of the ICU in managing critically ill patients, the study addresses the growing strain on ICU capacity. It emphasizes the significance of LOS prediction for resource allocation. The research reveals class imbalances in the dataset across demographic attributes and employs data preprocessing and feature extraction. While the XGBoost model performs well overall, disparities across race and insurance attributes reflect the need for tailored assessments and continuous monitoring. The paper concludes with recommendations for fairness-aware machine learning techniques for mitigating biases and the need for collaborative efforts among healthcare professionals and data scientists.",[''],[]
"For different alternating-sign multi-pulse trains electric fields with oscillation, the effects of the electric field pulse number and the relative phase of the combined electric field on pair production are investigated by solving quantum Vlasov equation.
It is found that the number density of created particles in the combined electric fields is increased by more than one order of magnitude compared to the results without oscillating structure for both zero transverse momentum and full momentum space.
In the case of zero transverse momentum, the created particles longitudinal momentum spectrum are monochromatic for large pulse numbers and some suitable relative phases. The number density depends nonlinearly on the relative phase that enables the optimal relative phase parameters for the number density. Moreover, for the full momentum space, the created particles number density and momentum spectrum under different multi-pulse trains electric fields are given and discussed. We also find that the number density as a function of pulse number satisfies the power law with index 5.3425.3425.3425.342 for the strong but slowly varying electric field with large pulse numbers.",[''],"['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
,[''],[]
,[''],[]
"We prove the compactness of the set of solutions to the CR Yamabe problem on a compact strictly pseudoconvex CR manifold of dimension three whose blow-up manifolds at every point have positive p-mass.
As a corollary we deduce that compactness holds for CR-embeddable manifolds which are not CR-equivalent to S3superscript𝑆3S^{3}italic_S start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT.
The theorem is proved by blow-up analysis.",[''],[]
"Fine-tuning Large Language Models (LLMs) adapts a trained model to specific downstream tasks, significantly improving task-specific performance. Supervised Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce desired answers. However, LLMs trained with SFT sometimes make simple mistakes and result in hallucinations on reasoning tasks such as question-answering. Without external feedback, it is difficult for SFT to learn a good mapping between the question and the desired answer, especially with a small dataset. This paper introduces an alternative to SFT called Natural Language Feedback for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they will receive from an annotator — we find that requiring such reflection can significantly improve the accuracy in in-domain question-answering tasks, providing a promising direction for the application of natural language feedback in the realm of SFT LLMs. Additional ablation studies show that the portion of human-annotated data in the annotated datasets affects the fine-tuning performance.",[''],[]
"Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure. Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices. Furthermore, we devise a pre-training objective that learns to infill text segments. This approach allows us to address irregular layouts and heterogeneous content frequently encountered in visual documents. The pre-trained model is fine-tuned using a large-scale instruction dataset, covering four core document intelligence tasks. We demonstrate that our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.",[''],[]
"Despite the remarkable performance of score distillation in text-to-3D generation, such techniques notoriously suffer from view inconsistency issues, also known as “Janus” artifact, where the generated objects fake each view with multiple front faces.
Although empirically effective methods have approached this problem via score debiasing or prompt engineering, a more rigorous perspective to explain and tackle this problem remains elusive.
In this paper, we reveal that the existing score distillation-based text-to-3D generation frameworks degenerate to maximal likelihood seeking on each view independently and thus suffer from the mode collapse problem, manifesting as the Janus artifact in practice.
To tame mode collapse, we improve score distillation by re-establishing in entropy term in the corresponding variational objective, which is applied to the distribution of rendered images. Maximizing the entropy encourages diversity among different views in generated 3D assets, thereby mitigating the Janus problem.
Based on this new objective, we derive a new update rule for 3D score distillation, dubbed Entropic Score Distillation (ESD).
We theoretically reveal that ESD can be simplified and implemented by just adopting the classifier-free guidance trick upon variational score distillation.
Although embarrassingly straightforward, our extensive experiments successfully demonstrate that ESD can be an effective treatment for Janus artifacts in score distillation.",[''],[]
"Motion segmentation is a complex yet indispensable task in autonomous driving. The challenges introduced by the ego-motion of the cameras, radial distortion in fisheye lenses, and the need for temporal consistency make the task more complicated, rendering traditional and standard Convolutional Neural Network (CNN) approaches less effective. The consequent laborious data labeling, representation of diverse and uncommon scenarios, and extensive data capture requirements underscore the imperative of synthetic data for improving machine learning model performance. To this end, we employ the PD-WoodScape synthetic dataset developed by Parallel Domain, alongside the WoodScape fisheye dataset.
Thus, we present the WoodScape fisheye motion segmentation challenge for autonomous driving, held as part of the CVPR 2023 Workshop on Omnidirectional Computer Vision (OmniCV).
As one of the first competitions focused on fisheye motion segmentation, we aim to explore and evaluate the potential and impact of utilizing synthetic data in this domain.
In this paper, we provide a detailed analysis on the competition which attracted the participation of 112 global teams and a total of 234 submissions. This study delineates the complexities inherent in the task of motion segmentation, emphasizes the significance of fisheye datasets, articulate the necessity for synthetic datasets and the resultant domain gap they engender, outlining the foundational blueprint for devising successful solutions. Subsequently, we delve into the details of the baseline experiments and winning methods evaluating their qualitative and quantitative results, providing with useful insights.",[''],[]
,[''],[]
"Window-based transformers have demonstrated strong ability in large-scale point cloud understanding by capturing context-aware representations with affordable attention computation in a more localized manner. However, because of the sparse nature
of point clouds, the number of voxels per window varies significantly. Current methods partition the voxels in each window into multiple subsets of equal size, which cost expensive overhead in sorting and padding the voxels, making them run slower than sparse convolution based methods. In this paper, we present ScatterFormer, which, for the first time to our best knowledge, could directly perform attention on voxel sets with variable length. The key of ScatterFormer lies in the innovative Scatter Linear Attention (SLA) module, which leverages the linear attention mechanism to process in parallel all voxels scattered in different windows. Harnessing the hierarchical computation units of the GPU and matrix blocking algorithm, we reduce the latency of the proposed SLA module to less than 1 ms on moderate GPUs. Besides, we develop a cross-window interaction module to simultaneously enhance the local representation and allow the information flow across windows, eliminating the need for window shifting. Our proposed ScatterFormer demonstrates 73 mAP (L2) on the large-scale Waymo Open Dataset and 70.5 NDS on the NuScenes dataset, running at an outstanding detection rate of 28 FPS. Code is available at https://github.com/skyhehe123/ScatterFormer.",[''],[]
"Using the Hydro-Coal-Frag model that combines hydrodynamics at low pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, quark coalescence at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, and the LBT transport model at high pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT, we study the spectra and elliptic flow of identified hadrons in high multiplicity p–Pb and p–p collisions at the Large Hadron Collider (LHC). In p–Pb collisions, the Hydro-Coal-Frag model gives a good description of the differential elliptic flow over the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT range from 0 to 6 GeV and the approximate number of constituent quark (NCQ) scaling at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT. Although Hydro-Coal-Frag model can also roughly describe the elliptic flow in high multiplicity p–p collisions with the quark coalescence process, the larger contribution from the string fragmentations leads to a notable violation of the NCQ scaling of v2subscript𝑣2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT at intermediate pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT as observed in the experiment. Comparison runs of the Hydro-Frag model without the coalescence process demonstrate that regardless the parameter adjustments, the Hydro-Frag model cannot simultaneously describe the pTsubscript𝑝Tp_{\rm T}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT spectra and the elliptic flow of identified hadrons in either p–Pb collisions or p–p collisions. The calculations in this paper thus provide support for the existence of partonic degrees of freedom and the possible formation of the QGP in the small systems created at the LHC.",[''],"['China', 'USA', 'USA', 'China', 'China']"
"Structure formation heralds the era of deviation of the matter content of the Universe away from thermal equilibrium, so the gravitational contribution to entropy, in the form of Weyl curvature, must become active in order for the overall entropy of the Universe to remain increasing. The tidal and frame dragging sectors of the Weyl tensor must inevitably both be present in this dynamic environment, as they mutually induce each other. The frame dragging effect is able to impress vorticity onto the plasma current arising due to the mass disparity between electrons and protons, which in turn begets a magnetic field from none. We show that this gravity-driven magnetogenesis mechanism, besides being able to operate outside of galaxies, thus facilitate large coherence length scales, may be able to generate the field strength necessary to seed dynamo processes.",[''],"['China', 'China']"
,[''],[]
,[''],[]
"Hybrid model predictive control with both continuous and discrete variables is widely applicable to robotic control tasks, especially those involving contact with the environment. Due to the combinatorial complexity, the solving speed of hybrid MPC can be insufficient for real-time applications. In this paper, we proposed a hybrid MPC solver based on Generalized Benders Decomposition (GBD). The algorithm enumerates and stores cutting planes online inside a finite buffer. After a short cold-start phase, the stored cuts provide warm-starts for the new problem instances to enhance the solving speed. Despite the disturbance and randomly changing environment, the solving speed maintains. Leveraging on the sparsity of feasibility cuts, we also propose a fast algorithm for Benders master problems. Our solver is validated through controlling a cart-pole system with randomly moving soft contact walls, and a free-flying robot navigating around obstacles. The results show that with significantly less data than previous works, the solver reaches competitive speeds to the off-the-shelf solver Gurobi despite the Python overhead.",[''],[]
"Using a sample of (10087±44)×106plus-or-minus1008744superscript106(10087\pm 44)\times 10^{6}( 10087 ± 44 ) × 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT J/ψ𝐽𝜓J/\psiitalic_J / italic_ψ events collected with the BESIII detector at the BEPCII collider, a partial wave analysis on the decay J/ψ→γ⁢γ⁢ϕ→𝐽𝜓𝛾𝛾italic-ϕJ/\psi\rightarrow\gamma\gamma\phiitalic_J / italic_ψ → italic_γ italic_γ italic_ϕ is performed to investigate the intermediate resonances in J/ψ→γ⁢X,X→γ⁢ϕformulae-sequence→𝐽𝜓𝛾𝑋→𝑋𝛾italic-ϕJ/\psi\rightarrow\gamma X,X\rightarrow\gamma\phiitalic_J / italic_ψ → italic_γ italic_X , italic_X → italic_γ italic_ϕ. The resonances f1⁢(1285)subscript𝑓11285f_{1}(1285)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1285 ), η⁢(1405)𝜂1405\eta(1405)italic_η ( 1405 ), f1⁢(1420)subscript𝑓11420f_{1}(1420)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1420 ), f1⁢(1510)subscript𝑓11510f_{1}(1510)italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1510 ), f2⁢(1525)subscript𝑓21525f_{2}(1525)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1525 ), X⁢(1835)𝑋1835X(1835)italic_X ( 1835 ), f2⁢(1950)subscript𝑓21950f_{2}(1950)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1950 ), f2⁢(2010)subscript𝑓22010f_{2}(2010)italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 2010 ), f0⁢(2200)subscript𝑓02200f_{0}(2200)italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( 2200 ) and ηcsubscript𝜂𝑐\eta_{c}italic_η start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT are observed with statistical significance greater than 5σ𝜎\sigmaitalic_σ. The product branching fractions ℬ⁢(J/ψ→γ⁢X,X→γ⁢ϕ)ℬformulae-sequence→𝐽𝜓𝛾𝑋→𝑋𝛾italic-ϕ\mathcal{B}(J/\psi\rightarrow\gamma X,X\rightarrow\gamma\phi)caligraphic_B ( italic_J / italic_ψ → italic_γ italic_X , italic_X → italic_γ italic_ϕ ) are reported. The resonance parameters of η⁢(1405)𝜂1405\eta(1405)italic_η ( 1405 ) and X⁢(1835)𝑋1835X(1835)italic_X ( 1835 ) are also measured.",[''],[]
,[''],[]
"We investigate the interference of two-dimensional Bose-Einstein condensates in micro-gravity, which influenced by the interaction strength, initial momentum, gravitational potential and phase difference. We demonstrate that the gravitational potential from the Earth can change the density distribution and phase distribution of the condensate’s wave function. As time evolves, a portion of the gravitational potential energy of the microscopic particles can be converted into kinetic energy, which changes the motion of the microscopic particles, and leads to the varying of the density and phase distribution of the wave function.
Nevertheless, the influences of the Earth’s gravity on the wave function can be eliminated by the micro-gravity environment, which confirmed by many micro-gravity cold atom experiments.
Our results present the influences of gravity and other parameters on interference of Bose-Einstein condensates, which help us to reveal the intrinsic natures of the related theoretical predictions and experimental phenomena. Furthermore, our work builds a bridge between the related physical phenomena and our physical intuition about the Bose-Einstein condensates in micro-gravity environment.",[''],['China']
"Self-supervised pre-training paradigms have been extensively explored in the field of
skeleton-based action recognition. In particular, methods based on
masked prediction have pushed the performance of pre-training to a new height.
However, these methods take low-level features, such as raw joint coordinates or
temporal motion, as prediction targets for the masked regions, which is suboptimal.
In this paper, we show that using high-level contextualized features as prediction
targets can achieve superior performance. Specifically, we propose Skeleton2vec,
a simple and efficient self-supervised 3D action representation learning framework,
which utilizes a transformer-based teacher encoder taking unmasked training samples as
input to create latent contextualized representations as prediction targets.
Benefiting from the self-attention mechanism, the latent representations generated by
the teacher encoder can incorporate the global context of the entire training samples,
leading to a richer training task.
Additionally, considering the high temporal correlations in skeleton sequences, we propose a
motion-aware tube masking strategy which divides the skeleton sequence into
several tubes and performs persistent masking within each tube based on motion priors,
thus forcing the model to build long-range spatio-temporal connections and focus on
action-semantic richer regions. Extensive experiments on NTU-60, NTU-120, and PKU-MMD
datasets demonstrate that our proposed Skeleton2vec outperforms previous methods and
achieves state-of-the-art results.
The source code of Skeleton2vec is available at https://github.com/Ruizhuo-Xu/Skeleton2vec.",[''],[]
,[''],[]
"Shape modeling research in Computer Graphics has been an active area for decades. The ability to create and edit complex 3D shapes has been of key importance in Computer-Aided Design, Animation, Architecture, and Entertainment. With the growing popularity of Virtual and Augmented Reality, new applications and tools have been developed for artistic content creation; real-time interactive shape modeling has become increasingly important for a continuum of virtual and augmented reality environments (eXtended Reality (XR)). Shape modeling in XR opens new possibilities for intuitive design and shape modeling in an accessible way. Artificial Intelligence (AI) approaches generating shape information from text prompts are set to change how artists create and edit 3D models. There has been a substantial body of research on interactive 3D shape modeling. However, there is no recent extensive review of the existing techniques and what AI shape generation means for shape modeling in interactive XR environments. In this state-of-the-art paper, we fill this research gap in the literature by surveying free-form shape modeling work in XR, with a focus on sculpting and 3D sketching, the most intuitive forms of free-form shape modeling. We classify and discuss these works across five dimensions: contribution of the articles, domain setting, interaction tool, auto-completion, and collaborative designing. The paper concludes by discussing the disconnect between interactive 3D sculpting and sketching and how this will likely evolve with the prevalence of AI shape-generation tools in the future.",[''],[]
"We construct a local Noetherian splinter (in fact, a weakly F𝐹Fitalic_F-regular domain) in prime characteristic which is not catenary, which we view as an analogue of a theorem of Ogoma in equal characteristic zero. Moreover, we construct a weakly F𝐹Fitalic_F-regular local UFD which is not Cohen–Macaulay. Both of these examples are obtained via finding sufficient conditions ensuring that a complete local ring of prime characteristic is the completion of some weakly F𝐹Fitalic_F-regular local domain, which we expect to be of independent interest.",[''],[]
"In standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients’ blood using microscopes. These isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. This methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. Contemporary leukocyte detection methods exhibit limitations in dealing with images with fewer leukocyte features and the disparity in scale among different leukocytes, leading to unsatisfactory results in most instances. To address these issues, this paper proposes an innovative method of leukocyte detection: the Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte scale disparity, we designed the High-level Screening-feature Fusion Pyramid (HS-FPN), enabling multi-level fusion. This model uses high-level features as weights to filter low-level feature information via a channel attention module and then merges the screened information with the high-level features, thus enhancing the model’s feature expression capability. Further, we address the issue of leukocyte feature scarcity by incorporating a multi-scale deformable self-attention module in the encoder and using the self-attention and cross-deformable attention mechanisms in the decoder, which aids in the extraction of the global features of the leukocyte feature maps. The effectiveness, superiority, and generalizability of the proposed MFDS-DETR method are confirmed through comparisons with other cutting-edge leukocyte detection models using the private WBCDD, public LISC and BCCD datasets. Our source code and private WBCCD dataset are available at https://github.com/JustlfC03/MFDS-DETR.",[''],"['[', '[', '[', '[', '[', '[']"
The Aragón Artacho–Campoy algorithm (AACA) is a new method for finding zeros of sums of monotone operators. In this paper we complete the analysis of [2] and [1] by providing study of the two possible Aragón Artacho–Campoy operators.,[''],[]
"Open Source Intelligence (OSINT) investigations, which rely entirely on publicly available data such as social media, play an increasingly important role in solving crimes and holding governments accountable. The growing volume of data and complex nature of tasks, however, means there is a pressing need to scale and speed up OSINT investigations. Expert-led crowdsourcing approaches show promise, but tend to either focus on narrow tasks or domains, or require resource-intense, long-term relationships between expert investigators and crowds. We address this gap by providing a flexible framework that enables investigators across domains to enlist crowdsourced support for discovery and verification of OSINT. We use a design-based research (DBR) approach to develop OSINT Research Studios (ORS), a sociotechnical system in which novice crowds are trained to support professional investigators with complex OSINT investigations. Through our qualitative evaluation, we found that ORS facilitates ethical and effective OSINT investigations across multiple domains.
We also discuss broader implications of expert–crowd collaboration and opportunities for future work.","['OSINT, open source intelligence, design-based research, social media investigation, collaboration, crowdsourcing']","['TechBlacksburgVAUSA', 'CollegeSwarthmorePAUSA', 'TechArlingtonVAUSA']"
"This paper presents GenH2R, a framework for learning generalizable vision-based human-to-robot (H2R) handover skills. The goal is to equip robots with the ability to reliably receive objects with unseen geometry handed over by humans in various complex trajectories. We acquire such generalizability by learning H2R handover at scale with a comprehensive solution including procedural simulation assets creation, automated demonstration generation, and effective imitation learning. We leverage large-scale 3D model repositories, dexterous grasp generation methods, and curve-based 3D animation to create an H2R handover simulation environment named GenH2R-Sim, surpassing the number of scenes in existing simulators by three orders of magnitude. We further introduce a distillation-friendly demonstration generation method that automatically generates a million high-quality demonstrations suitable for learning. Finally, we present a 4D imitation learning method augmented by a future forecasting objective to distill demonstrations into a visuo-motor handover policy. Experimental evaluations in both simulators and the real world demonstrate significant improvements (at least +10% success rate) over baselines in all cases.",[''],[]
"In the paper we prove generalization of Schlömilch’s and Zetel’s theorems about concurrent lines in a triangle. This generalization is obtained as a corollary of sharp geometric inequality about the ratio of triangular areas which is proved using discrete variant of Hölder’s inequality. Also a new sharp refinement of J.F. Rigby’s inequality, which itself generalized Möbius theorem about the areas of triangles formed by cevians of a triangle, is proved.",[''],[]
"The high energy (Regge) limit provides a playground for understanding all loop structures of scattering amplitudes, and plays an important role in the description of many phenomenologically relevant cross-sections.
While well understood in the planar limit, the structure of non-planar corrections introduces many fascinating complexities, for which a general organizing principle is still lacking.
We study the structure of multi-reggeon exchanges in the context of the effective field theory for forward scattering, and derive their factorization into collinear operators (impact factors) and soft operators.
We derive the structure of the renormalization group consistency equations in the effective theory, showing how the anomalous dimensions of the soft operators are related to those of the collinear operators, allowing us to derive renormalization group equations in the Regge limit purely from a collinear perspective.
The rigidity of the consistency equations provides considerable insight into the all orders organization of Regge amplitudes in the effective theory, as well as its relation to other approaches. Along the way we derive a number of technical results that improve the understanding of the effective theory.
We illustrate this collinear perspective by re-deriving all the standard BFKL equations for two-Glauber exchange from purely collinear calculations, and we show that this perspective provides a number of conceptual and computational advantages as compared to the standard view from soft or Glauber physics.
We anticipate that this formulation in terms of collinear operators will enable a better understanding of the relation between BFKL and DGLAP in gauge theories, and facilitate the analysis of renormalization group evolution equations describing Reggeization beyond next-to-leading order.",[''],[]
"We develop a numerical approach to compute polar parity perturbations within fully relativistic models of black hole systems embedded in generic, spherically symmetric, anisotropic fluids. We apply this framework to study gravitational wave generation and propagation from extreme mass-ratio inspirals in the presence of several astrophysically relevant dark matter models, namely the Hernquist, Navarro-Frenk-White, and Einasto profiles. We also study dark matter spike profiles obtained from a fully relativistic calculation of the adiabatic growth of a BH within the Hernquist profile, and provide a closed-form analytic fit of these profiles. Our analysis completes prior numerical work in the axial sector, yielding a fully numerical pipeline to study black hole environmental effects. We study the dependence of the fluxes on the DM halo mass and compactness. We find that, unlike the axial case, polar fluxes are not adequately described by simple gravitational-redshift effects, thus offering an exciting avenue for the study of black hole environments with gravitational waves.",[''],"['USA', 'USA', 'Denmark', 'Portugal', 'Kyoto', 'Italy', 'Italy']"
"The elusive polarized microwave signal from the Fermi bubbles is disentangled from the more extended polarized lobes, which similarly emanate from the Galactic plane but stretch farther west of the bubbles.
The ∼20%similar-toabsentpercent20\sim 20\%∼ 20 % synchrotron polarization reveals magnetic fields preferentially parallel to the bubble edges, as expected downstream of a strong shock.
The ∼20%similar-toabsentpercent20\sim 20\%∼ 20 % polarization of thermal dust emission is similarly oriented, constraining grain alignment in an extreme environment.
We argue that the larger lobes arise from an older Galactic-center, likely supermassive black-hole, outburst.",[''],['ukeshet@bgu.ac.il']
"We present the UV-to-NIR size evolution of a sample of 161 quiescent galaxies with M*>1010⁢M☉subscript𝑀superscript1010subscript𝑀☉M_{*}>10^{10}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT > 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT over 0.5<z<50.5𝑧50.5<z<50.5 < italic_z < 5. With deep multi-band NIRCam images in GOODS-South from JADES, we measure the effective radii (Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT) of the galaxies at rest-frame 0.3, 0.5 and 1µmµm\micronroman_µm. On average, we find that quiescent galaxies are 45% (15%) more compact at rest-frame 1µmµm\micronroman_µm than they are at 0.3µmµm\micronroman_µm (0.5µmµm\micronroman_µm). Regardless of wavelengths, the Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT of quiescent galaxies strongly evolves with redshift, and this evolution depends on stellar mass. For lower-mass quiescent galaxies with M*=1010−1010.6⁢M☉subscript𝑀superscript1010superscript1010.6subscript𝑀☉M_{*}=10^{10}-10^{10.6}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT - 10 start_POSTSUPERSCRIPT 10.6 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT, the evolution follows Re∝(1+z)−1.1proportional-tosubscript𝑅𝑒superscript1𝑧1.1R_{e}\propto(1+z)^{-1.1}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z ) start_POSTSUPERSCRIPT - 1.1 end_POSTSUPERSCRIPT, whereas it becomes steeper, following Re∝(1+z)−1.7proportional-tosubscript𝑅𝑒superscript1𝑧1.7R_{e}\propto(1+z)^{-1.7}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z ) start_POSTSUPERSCRIPT - 1.7 end_POSTSUPERSCRIPT, for higher-mass quiescent galaxies with M*>1010.6⁢M☉subscript𝑀superscript1010.6subscript𝑀☉M_{*}>10^{10.6}M_{\sun}italic_M start_POSTSUBSCRIPT * end_POSTSUBSCRIPT > 10 start_POSTSUPERSCRIPT 10.6 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT. To constrain the physical mechanisms driving the apparent size evolution, we study the relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and the formation redshift (zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT) of quiescent galaxies. For lower-mass quiescent galaxies, this relationship is broadly consistent with Re∝(1+zform)−1proportional-tosubscript𝑅𝑒superscript1subscript𝑧form1R_{e}\propto(1+z_{\rm{form}})^{-1}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ∝ ( 1 + italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, in line with the expectation of the progenitor effect. For higher-mass quiescent galaxies, the relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT depends on stellar age. Older quiescent galaxies have a steeper relationship between Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT and zformsubscript𝑧formz_{\rm{form}}italic_z start_POSTSUBSCRIPT roman_form end_POSTSUBSCRIPT than that expected from the progenitor effect alone, suggesting that mergers and/or post-quenching continuous gas accretion drive additional size growth in very massive systems. We find that the z>3𝑧3z>3italic_z > 3 quiescent galaxies in our sample are very compact, with mass surface densities Σe≳1010⁢M☉/kpc2greater-than-or-equivalent-tosubscriptΣ𝑒superscript1010subscript𝑀☉superscriptkpc2\Sigma_{e}\gtrsim 10^{10}M_{\sun}/\rm{kpc}^{2}roman_Σ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ≳ 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT ☉ end_POSTSUBSCRIPT / roman_kpc start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, and their Resubscript𝑅𝑒R_{e}italic_R start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT are possibly even smaller than anticipated from the size evolution measured for lower-redshift quiescent galaxies. Finally, we take a close look at the structure of GS-9209, one of the earliest confirmed massive quiescent galaxies at zspec∼4.7similar-tosubscript𝑧spec4.7z_{\rm{spec}}\sim 4.7italic_z start_POSTSUBSCRIPT roman_spec end_POSTSUBSCRIPT ∼ 4.7. From UV to NIR, GS-9209 becomes increasingly compact, and its light profile becomes more spheroidal, showing that the color gradient is already present in this earliest massive quiescent galaxy.","['Galaxy formation(595);', 'Galaxy evolution(594);', 'Galaxy structure(622);', 'High-redshift galaxies(734)']","['USA', 'USA', 'USA', 'USA', 'USA', 'UK', 'UK', 'USA', 'USA', 'USA', 'UK', 'UK', 'Canada', 'Spain', 'USA', 'Australia', 'Australia', 'UK', 'Italy', 'France', 'USA', 'UK', 'UK', 'UK', 'UK', 'Germany', 'USA', 'USA', 'USA', 'USA', '21218', 'USA', 'UK', 'UK', 'USA', 'UK', 'UK', 'UK', 'USA', 'USA', 'USA', 'USA', 'Germany', 'UK', 'UK', 'USA', 'UK', 'UK', 'USA', 'Canada', 'UK', 'UK']"
"We present a differentiable model that explicitly models boundaries—including contours, corners and junctions—using a new mechanism that we call boundary attention. We show that our model provides accurate results even when the boundary signal is very weak or is swamped by noise. Compared to previous classical methods for finding faint boundaries, our model has the advantages of being differentiable; being scalable to larger images; and automatically adapting to an appropriate level of geometric detail in each part of an image. Compared to previous deep methods for finding boundaries via end-to-end training, it has the advantages of providing sub-pixel precision, being more resilient to noise, and being able to process any image at its native resolution and aspect ratio.",[''],[]
"The importance of the information in the direct sound to human perception of spatial sound sources is an ongoing research topic. The classification between direct sound and diffuse or reverberant sound forms the basis of numerous studies in the field of spatial audio. In particular, parametric spatial audio representation methods use this classification and employ signal processing in order to enhance the audio quality at reproduction. However, current literature does not provide information concerning the impact of ideal direct sound representation on externalization, in the context of Ambisonics. This paper aims to assess the importance of the spatial information in the direct sound in the externalization of a sound field when using binaural reproduction. This is done in the spherical harmonics (SH) domain, where an ideal direct sound representation within an otherwise Ambisonics signal is simulated, and its perceived externalization is evaluated in a formal listening test. This investigation leads to the conclusion that externalization of a first order Ambisonics signal may be significantly improved by enhancing the direct sound component, up to a level similar to a third order Ambisonics signal.",[''],"['Israel', 'Israel']"
"We show that the half-ball in ℝ4superscriptℝ4\mathbb{R}^{4}blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT can be conformally changed so that the only contribution to the Gauss–Bonnet formula is a constant term at the corner.
This may be seen as a fourth-order Cherrier–Escobar-type problem on the half-ball.","['Key words and phrases:', 'Bilaplacian, manifolds with corners, corner regularity,', 'Gauss-Bonnet,', 'Q𝑄Qitalic_Q-curvature,', 'T𝑇Titalic_T-curvature,', 'U𝑈Uitalic_U-curvature']",[]
"A weak formulation is devised for the K⁢(m,n)𝐾𝑚𝑛K(m,n)italic_K ( italic_m , italic_n ) equation
which is a nonlinearly dispersive generalization of the gKdV equation
having compacton solutions.
With this formulation, explicit weak compacton solutions are derived,
including ones that do not exist as classical (strong) solutions.
Similar results are obtained for a nonlinearly dispersive generalization of the gKP equation in two dimensions,
which possesses line compacton solutions.",[''],[]
"We employ a deep learning method to deduce the bulk spacetime from boundary optical conductivity. We apply the neural ordinary differential equation technique, tailored for continuous functions such as the metric, to the typical class of holographic condensed matter models featuring broken translations: linear-axion models. We successfully extract the bulk metric from the boundary holographic optical conductivity. Furthermore, as an example for real material, we use experimental optical conductivity of UPd2⁢Al3subscriptUPd2subscriptAl3\text{UPd}_{2}\text{Al}_{3}UPd start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT Al start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, a representative of heavy fermion metals in strongly correlated electron systems, and construct the corresponding bulk metric. To our knowledge, our work is the first illustration of deep learning bulk spacetime from boundary holographic or experimental conductivity data.",[''],[]
"Given a player is guaranteed the same payoff for each delivery path in a single-cube delivery network, the player’s best response is to randomly divide all goods and deliver them to all other nodes, and the best response satisfies the Kuhn-Tucker condition. The state of the delivery network is randomly complete. If congestion costs are introduced to the player’s maximization problem in a multi-cubic delivery network, the congestion paradox arises where all coordinates become congested as long as the previous assumptions about payoffs are maintained.
Keywords:
Network theory; Optimal transport; Cubic network; 3D network; Congestion; Transaction cost; Transportation; UAM; Urban air mobility; AAM; Advanced air mobility; Drone; Flying car 
JEL Classification: 
R41; D23; L14.",[''],[]
"We present the numerical codes 𝖳𝖠𝖴𝖱𝖴𝖲𝗉𝖺𝗏subscript𝖳𝖠𝖴𝖱𝖴𝖲𝗉𝖺𝗏\textsf{TAURUS}_{\textsf{pav}}TAURUS start_POSTSUBSCRIPT pav end_POSTSUBSCRIPT and 𝖳𝖠𝖴𝖱𝖴𝖲𝗆𝗂𝗑subscript𝖳𝖠𝖴𝖱𝖴𝖲𝗆𝗂𝗑\textsf{TAURUS}_{\textsf{mix}}TAURUS start_POSTSUBSCRIPT mix end_POSTSUBSCRIPT that, combined, perform the configuration mixing of symmetry-projected real general Bogoliubov quasiparticle states represented in a spherical harmonic oscillator basis. The model space considered is invariant under spatial and isospin rotations but no specific set of orbits is assumed such that the codes can carry out both valence-space and no-core calculations.
In addition, no number parity is assumed for the Bogoliubov quasiparticle states such that the codes can be used to describe even-even, odd-even and odd-odd nuclei.
To demonstrate the potential of the codes, we perform an example no-core calculation of 2424{}^{24}start_FLOATSUPERSCRIPT 24 end_FLOATSUPERSCRIPTMg using a modern microscopic interaction.",[''],[]
"This paper investigates the relationship between scientific innovation in biomedical sciences and its impact on industrial activities, focusing on how the historical impact and content of scientific papers influenced future funding and innovation grant application content for small businesses. The research incorporates bibliometric analyses along with SBIR (Small Business Innovation Research) data to yield a holistic view of the science-industry interface. By evaluating the influence of scientific innovation on industry across 10,873 biomedical topics and taking into account their taxonomic relationships, we present an in-depth exploration of science-industry interactions where we quantify the temporal effects and impact latency of scientific advancements on industrial activities, spanning from 2010 to 2021. Our findings indicate that scientific progress substantially influenced industrial innovation funding and the direction of industrial innovation activities. Approximately 76% and 73% of topics showed a correlation and Granger-causality between scientific interest in papers and future funding allocations to relevant small businesses. Moreover, around 74% of topics demonstrated an association between the semantic content of scientific abstracts and future grant applications. Overall, the work contributes to a more nuanced and comprehensive understanding of the science-industry interface, opening avenues for more strategic resource allocation and policy developments aimed at fostering innovation.",[''],"['USA', 'khanreza@msu.edu', 'USA', 'USA', 'UAE', 'USA', 'USA', 'USA']"
"We study entanglement entropy in a non-relativistic Schrödinger field theory at finite temperature and electric charge using the principle of gauge/gravity duality. The spacetime geometry is obtained from a charged AdS black hole by a null Melvin twist. By using an appropriate modification of the holographic Ryu-Takayanagi formula, we calculate the entanglement entropy, mutual information, and entanglement wedge cross-section for the simplest strip subsystem. The entanglement measures show non-trivial dependence on the black hole parameters.",[''],[]
,[''],[]
"The EM algorithm is a powerful tool for maximum likelihood estimation with missing data. In practice, the calculations required for the EM algorithm are often intractable. We review numerous methods to circumvent this intractability, all of which are based on Monte Carlo simulation. We focus our attention on the Monte Carlo EM (MCEM) algorithm and its various implementations. We also discuss some related methods like stochastic approximation and Monte Carlo maximum likelihood. Generating the Monte Carlo samples necessary for these methods is, in general, a hard problem. As such, we review several simulation strategies which can be used to address this challenge.
Given the wide range of methods available for approximating the EM, it can be challenging to select which one to use. We review numerous comparisons between these methods from a wide range of sources, and offer guidance on synthesizing the findings. Finally, we give some directions for future research to fill important gaps in the existing literature on the MCEM algorithm and related methods.",[''],['wruth@sfu.ca']
"Let M=Sn/Γ𝑀superscript𝑆𝑛ΓM=S^{n}/\Gammaitalic_M = italic_S start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT / roman_Γ and h∈π1⁢(M)ℎsubscript𝜋1𝑀h\in\pi_{1}(M)italic_h ∈ italic_π start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_M ) be a non-trivial element of finite order p𝑝pitalic_p, where the integers n,p≥2𝑛𝑝2n,p\geq 2italic_n , italic_p ≥ 2 and ΓΓ\Gammaroman_Γ is a finite abelian group which acts on the sphere freely and isometrically. Therefore M𝑀Mitalic_M is diffeomorphic to a compact space form which is a typical non-simply connected manifold. For Γ=ℤ2Γsubscriptℤ2\Gamma=\mathbb{Z}_{2}roman_Γ = blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, we obtain there are at least two non-contractible closed geodesics on ℝ⁢P2ℝsuperscript𝑃2\mathbb{R}P^{2}blackboard_R italic_P start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT whose lengths are bounded by geometry of the manifold from above. Moreover, suppose g0subscript𝑔0g_{0}italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is standard Riemannian metric. We prove that there exists at least n𝑛nitalic_n prime non-contractible closed geodesics on (M,F)𝑀𝐹(M,F)( italic_M , italic_F ) of prescribed class [h]delimited-[]ℎ[h][ italic_h ] without self-intersections, provided F2<(λ+1λ)2⁢g0superscript𝐹2superscript𝜆1𝜆2subscript𝑔0F^{2}<(\frac{\lambda+1}{\lambda})^{2}g_{0}italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT < ( divide start_ARG italic_λ + 1 end_ARG start_ARG italic_λ end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and



(λλ+1)2<K≤1⁢ for n is odd or ⁢ 0<K≤1⁢ for n is even,superscript𝜆𝜆12𝐾1 for n is odd or  0𝐾1 for n is even(\frac{\lambda}{\lambda+1})^{2}<K\leq 1\text{ for $n$ is odd or }\;0<K\leq 1%
\text{ for $n$ is even},( divide start_ARG italic_λ end_ARG start_ARG italic_λ + 1 end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT < italic_K ≤ 1 for italic_n is odd or 0 < italic_K ≤ 1 for italic_n is even ,



where λ𝜆\lambdaitalic_λ is the reversibility and K𝐾Kitalic_K is the flag curvature. Some results on stability are obtained.
Key words: Compact space forms; Non-contractible closed geodesics; Equivariant Morse theory; Self-intersections

AMS Subject Classification: 53C22, 58E05, 58E10.",[''],[]
"Amount of information in SAT is estimated and compared with the amount
of information in the fixed code algorithms.
A remark on SAT Kolmogorov complexity is made.
It is argued that SAT can be polynomial-time solvable, or not,
depending on the solving algorithm information content.",[''],[]
"The laws that govern the nature often set certain limits or bans. Approaching those limits is a common paradigm of breakthroughs in human knowledge and technological application, such as time slowing to a stop as one approaches the speed of light, electrons flowing freely with no resistance as one approaches the absolute zero, and an event horizon arising as one approaches a black hole. A well-known ban concerning the statistical mechanics of cooperative phenomena, such as ice melting into water, is the nonexistence of phase transition at finite temperature in the Ising model with short-range interactions in one dimension. Yet, little is known about whether this forbidden transition could be approached arbitrarily closely at fixed finite temperature. To explore such asymptoticity, the notion of marginal phase transition (MPT) was introduced recently, and both the spontaneous MPT and the field-induced MPT were discovered respectively in ladder and single-chain Ising models decorated with geometric frustration. Here I push the limit down to the minimal single-chain Ising model—without geometric frustration—in a magnetic field; then, a hidden frustration is revealed to drive the first-order MPT with large latent heat. Furthermore, as one approaches the zero field, MPT appears continuous with no latent heat, displays abrupt change in sublattice magnetization and a kink-like minimum in overall magnetization with temperature, and vanishes when the field drops below a threshold. These findings deepen our understanding of cooperative phenomena via the doubly forbidden and open new avenues to the design and engineering of the Ising systems with the different types of MPT for exploring exotic phenomena and low-dimensional device applications.",[''],['USA']
"Portfolio’s optimal drivers for diversification are common causes of the constituents’ correlations. A closed-form formula for the conditional probability of the portfolio given its optimal common drivers is presented, with each pair constituent-common driver joint distribution modelled by Gaussian copulas. A conditional risk-neutral PDE is obtained for this conditional probability as a system of copulas’ PDEs, allowing for dynamical risk management of a portfolio as shown in the experiments. Implied conditional portfolio volatilities and implied weights are new risk metrics that can be dynamically monitored from the PDEs or obtained from their solution.",[''],[]
,[''],[]
,[''],[]
"Say we have a collection of independent random variables X0,…,Xnsubscript𝑋0…subscript𝑋𝑛X_{0},\ldots,X_{n}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_X start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT,
where X0∼𝒩⁢(μ0,σ02)similar-tosubscript𝑋0𝒩subscript𝜇0superscriptsubscript𝜎02X_{0}\sim\mathcal{N}\left(\mu_{0},\sigma_{0}^{2}\right)italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∼ caligraphic_N ( italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ),
but Xi∼𝒩⁢(μ,σ2)similar-tosubscript𝑋𝑖𝒩𝜇superscript𝜎2X_{i}\sim\mathcal{N}\left(\mu,\sigma^{2}\right)italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∼ caligraphic_N ( italic_μ , italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), for 1≤i≤n1𝑖𝑛1\leq i\leq n1 ≤ italic_i ≤ italic_n.
We characterize the distribution of R0≔1+∑i=1n𝟏{Xi≤X0}≔subscript𝑅01superscriptsubscript𝑖1𝑛subscript1subscript𝑋𝑖subscript𝑋0R_{0}\coloneqq 1+\sum_{i=1}^{n}\mathbf{1}_{\left\{X_{i}\leq X_{0}\right\}}italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≔ 1 + ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_1 start_POSTSUBSCRIPT { italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT } end_POSTSUBSCRIPT,
the rank of the random variable whose distribution potentially differs
from that of the others—the odd normal out. We show that R0−1subscript𝑅01R_{0}-1italic_R start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - 1
is approximately beta-binomial, an approximation that becomes equality
as σ/σ0𝜎subscript𝜎0\nicefrac{{\sigma}}{{\sigma_{0}}}/ start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG or (μ−μ0)/σ0𝜇subscript𝜇0subscript𝜎0\nicefrac{{\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}/ start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG
become large or small. The intra-class correlation of the approximating
beta-binomial depends on Pr⁡(X1≤X0)Prsubscript𝑋1subscript𝑋0\Pr\left(X_{1}\leq X_{0}\right)roman_Pr ( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and Pr⁡(X1≤X0,X2≤X0)Prsubscript𝑋1subscript𝑋0subscript𝑋2subscript𝑋0\Pr\left(X_{1}\leq X_{0},X_{2}\leq X_{0}\right)roman_Pr ( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ).
Our approach relies on the conjugacy of the beta distribution for
the binomial: Φ⁢((X0−μ)/σ)Φsubscript𝑋0𝜇𝜎\Phi\left(\nicefrac{{\left(X_{0}-\mu\right)}}{{\sigma}}\right)roman_Φ ( / start_ARG ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - italic_μ ) end_ARG start_ARG italic_σ end_ARG )
is approximately Beta⁢(α⁢(σ/σ0,(μ−μ0)/σ0),β⁢(σ/σ0,(μ−μ0)/σ0))Beta𝛼𝜎subscript𝜎0𝜇subscript𝜇0subscript𝜎0𝛽𝜎subscript𝜎0𝜇subscript𝜇0subscript𝜎0\mathrm{Beta}\left(\alpha\left(\nicefrac{{\sigma}}{{\sigma_{0}}},\nicefrac{{%
\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}\right),\beta\left(\nicefrac{{\sigma}}%
{{\sigma_{0}}},\nicefrac{{\left(\mu-\mu_{0}\right)}}{{\sigma_{0}}}\right)\right)roman_Beta ( italic_α ( / start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , / start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ) , italic_β ( / start_ARG italic_σ end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , / start_ARG ( italic_μ - italic_μ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_σ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ) )
for functions α,β>0𝛼𝛽0\alpha,\beta>0italic_α , italic_β > 0. We study the distributions of the
in-normal ranks. Throughout, simulations corroborate the formulae
we derive.",[''],[]
"We compute explicitly the MTW tensor (or cross curvature) for the optimal transport problem on ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT with a cost function of form 𝖼⁢(x,y)=𝗎⁢(x𝔱⁢y)𝖼𝑥𝑦𝗎superscript𝑥𝔱𝑦\mathsf{c}(x,y)=\mathsf{u}(x^{\mathfrak{t}}y)sansserif_c ( italic_x , italic_y ) = sansserif_u ( italic_x start_POSTSUPERSCRIPT fraktur_t end_POSTSUPERSCRIPT italic_y ), where 𝗎𝗎\mathsf{u}sansserif_u is a scalar function with inverse 𝗌𝗌\mathsf{s}sansserif_s, x𝔱⁢ysuperscript𝑥𝔱𝑦x^{\mathfrak{t}}yitalic_x start_POSTSUPERSCRIPT fraktur_t end_POSTSUPERSCRIPT italic_y is a nondegenerate bilinear pairing of vectors x,y𝑥𝑦x,yitalic_x , italic_y belonging to an open subset of ℝnsuperscriptℝ𝑛\mathbb{R}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. The condition that the MTW-tensor vanishes on null vectors under the Kim-McCann metric is a fourth-order nonlinear ODE, which could be reduced to a linear ODE of the form 𝗌(2)−S⁢𝗌(1)+P⁢𝗌=0superscript𝗌2𝑆superscript𝗌1𝑃𝗌0\mathsf{s}^{(2)}-S\mathsf{s}^{(1)}+P\mathsf{s}=0sansserif_s start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT - italic_S sansserif_s start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT + italic_P sansserif_s = 0 with constant coefficients P𝑃Pitalic_P and S𝑆Sitalic_S. The resulting inverse functions include Lambert and generalized inverse hyperbolic/trigonometric functions. The square Euclidean metric and log\logroman_log-type costs are equivalent to instances of these solutions. The optimal map for the family is also explicit. For cost functions of a similar form on a hyperboloid model of the hyperbolic space and unit sphere, we also express this tensor in terms of algebraic expressions in derivatives of 𝗌𝗌\mathsf{s}sansserif_s using the Gauss-Codazzi equation, obtaining new families of strictly regular costs for these manifolds, including new families of power function costs. We analyze the sinh\sinhroman_sinh-type hyperbolic cost, providing examples of 𝖼𝖼\mathsf{c}sansserif_c-convex functions and divergence.","['Key words and phrases:', 'Optimal transport, convex potential, divergence,', 'Ma-Trudinger-Wang tensor, sectional curvature.']",[]
"Optical Fabry-Perot cavity with a movable mirror is a paradigmatic
optomechanical systems. While usually the mirror is supported by a
mechanical spring, it has been shown that it is possible to keep one
of the mirrors in a stable equilibrium purely by optical levitation
without any mechanical support. In this work we expand previous studies
of nonlinear dynamics of such a system by demonstrating a possibility
for mechanical parametric instability and emergence of the “phonon
laser” phenomenon.",[''],"['USA.', 'USA', 'Israel']"
,[''],[]
"The study of cometary composition is important for understanding our solar system’s early evolutionary processes. Carbon dioxide (CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT) is a common hypervolatile in comets that can drive activity but is more difficult to study than other hypervolatiles due to severe telluric absorption. CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT can only be directly observed from space-borne assets. Therefore, a proxy is needed to measure CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT abundances in comets using ground-based observations. The flux ratio of the [O i] 5577 Å line to the sum of the [O i] 6300 Å and [O i] 6364 Å lines (hereafter referred to as the [O i] line ratio) has, with some success, been used in the past as such a proxy. We present an [O i] line ratio analysis of comet 45P/Honda–Mrkos–Pajdušáková (HMP), using data obtained with the Tull Coudé Spectrograph on the 2.7-meter Harlan J. Smith telescope at McDonald Observatory, taken from UT February 21-23, 2017 when the comet was at heliocentric distances of 1.12-1.15 AU. HMP is a hyperactive Jupiter family comet (JFC). Icy grains driven out by CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT sublimation have been proposed as a driver of hyperactivity, but the CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT abundance of HMP has not been measured. From our [O i] line ratio measurements, we find a CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT/H22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO ratio for HMP of 22.9±1.4%plus-or-minus22.9percent1.422.9\pm 1.4\%22.9 ± 1.4 %. We compare the CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT/H22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPTO ratios to the active fractions of the nine comets (including HMP) in the literature that have data for both values. We find no correlation. These findings imply that CO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT sublimation driving out icy grains is not the only factor influencing active fractions for cometary nuclei.","['Comets (280) —', 'Comae (271) —', 'Carbon dioxide (196) —', 'Comet volatiles (2162) —', 'Short period comets (1452)']","['mikayla.huffman@colorado.edu', 'mckayaj@appstate.edu', 'USA']"
"In this paper, we generalize the well-known hyperbolic numbers to
certain numeric structures scaled by the real numbers. Under our scaling
of ℝℝ\mathbb{R}blackboard_R, the usual hyperbolic numbers are understood to be
our 1111-scaled hyperbolic numbers. If a scale t𝑡titalic_t is not positive
in ℝℝ\mathbb{R}blackboard_R, then our t𝑡titalic_t-scaled hyperbolic numbers have similar
numerical structures with those of the complex numbers of ℂℂ\mathbb{C}blackboard_C,
however, if a scale is positive in ℝℝ\mathbb{R}blackboard_R, then their numerical
properties are similar to those of the classical hyperbolic numbers.
We here understand scaled-hyperbolic numbers as elements of the scaled-hypercomplex
rings {ℍt}t∈ℝsubscriptsubscriptℍ𝑡𝑡ℝ\left\{\mathbb{H}_{t}\right\}_{t\in\mathbb{R}}{ blackboard_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t ∈ blackboard_R end_POSTSUBSCRIPT, introduced
in [1]. This scaled-hyperbolic analysis is done by algebra, analysis,
operator theory, operator-algebra theory and free probability on scaled-hypercomplex
numbers.","['Key words and phrases:', 'Scaled', 'Hypercomplex', 'Rings,', 'Scaled', 'Hypercomplex', 'Monoids,', 'Scaled', 'Hyperbolic,Numbers,', 'Free', 'Probability']",[]
,[''],[]
"This study investigates the integration of assistive therapeutic robotics, wearable sensors, and spatial sensors within an intelligent environment tailored for dementia care. The feasibility study aims to assess the collective impact of these technologies in enhancing care giving by seamlessly integrating supportive technology in the background. The wearable sensors track physiological data, while spatial sensors monitor geo-spatial information, integrated into a system supporting residents without necessitating technical expertise. The designed space fosters various activities, including robot interactions, medication delivery, physical exercises like walking on a treadmill (Bruce protocol), entertainment, and household tasks, promoting cognitive stimulation through puzzles. Physiological data revealed significant participant engagement during robot interactions, indicating the potential effectiveness of robot-assisted activities in enhancing the quality of life for residents.","['Index', 'Terms: ', 'Humanoid', 'Robot,', 'Pepper robot, dementia friendly living space,', 'Alzheimer’s care giving,', 'Electrodermal activity,', 'EDA;', 'Physiological data;']","['0000-0001-8779-9617', 'rjd6099@psu.edu', 'mart5877@d.umn.edu', 'dowli026@d.umn.edu', 'rana.z.imtiaz@gmail.com']"
"We present the results of a sensitive search for high-velocity gas in interstellar absorption lines associated with the Cygnus Loop supernova remnant (SNR). We examine high-resolution, high signal-to-noise ratio optical spectra of six stars in the Cygnus Loop region with distances greater than ∼similar-to\sim∼700 pc. All stars show low-velocity Na i and Ca ii absorption. However, only one star, HD 198301, exhibits high-velocity Ca ii absorption components, at velocities of +62, +82, and +96 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT. The distance to this star of ∼similar-to\sim∼870 pc helps to constrain the distance to the receding edge of the Cygnus Loop’s expanding shock front. One of our targets, HD 335334, was previously thought to exhibit high positive and high negative velocity interstellar Na i and Ca ii absorption. This was one factor leading Fesen et al. to derive a distance to the Cygnus Loop of 725±15plus-or-minus72515725\pm 15725 ± 15 pc. However, we find that HD 335334 is in fact a double-line spectroscopic binary and shows no evidence of high-velocity interstellar absorption. As such, the distance to HD 335334 cannot be used to constrain the distance to the Cygnus Loop. Our detection of Ca ii absorption approaching 100 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT toward HD 198301 is the first conclusive detection of high-velocity absorption from a low ionization species associated with the Cygnus Loop SNR. A large jump in the Na i column density toward BD+31 4218, a star located beyond the northwestern boundary of the Cygnus Loop, helps to constrain the distance to a large molecular cloud complex with which the Cygnus Loop is evidently interacting.",[''],[]
"Structured data in the form of tabular datasets contain features that are distinct and discrete, with varying individual and relative importances to the target. Combinations of one or more features may be more predictive and meaningful than simple individual feature contributions. R’s mixed effect linear models library allows users to provide such interactive feature combinations in the model design. However, given many features and possible interactions to select from, model selection becomes an exponentially difficult task. We aim to automate the model selection process for predictions on tabular datasets incorporating feature interactions while keeping computational costs small. The framework includes two distinct approaches for feature selection: a Priority-based Random Grid Search and a Greedy Search method. The Priority-based approach efficiently explores feature combinations using prior probabilities to guide the search. The Greedy method builds the solution iteratively by adding or removing features based on their impact. Experiments on synthetic demonstrate the ability to effectively capture predictive feature combinations. Code is available at 111https://github.com/AmballaAvinash/ModelSelection.",[''],[]
"Cold, neutral interstellar gas, the reservoir for star formation, is
traced through the absorption of the 21-centimetre continuum
radiation by neutral hydrogen (HI). Although detected in one
hundred cases in the host galaxies of distant radio sources, only
recently have column densities approaching the maximum value
observed in Lyman-α𝛼\alphaitalic_α absorption systems (NHI∼1022similar-tosubscript𝑁HIsuperscript1022N_{\text{HI}}\sim 10^{22}italic_N start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT ∼ 10 start_POSTSUPERSCRIPT 22 end_POSTSUPERSCRIPT cm−2superscriptcm2\hbox{{\rm cm}}^{-2}cm start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT) been found. Here we explore the implications these
have for the hypothesis that the detection rate of HI absorption is
dominated by photo-ionisation from the active galactic nucleus
(AGN). We find, with the addition all of the current searches for
HI absorption at z≥0.1𝑧0.1z\geq 0.1italic_z ≥ 0.1, a strong correlation between
the HI absorption strength and the ionising photon rate, with the
maximum value at which HI is detected remaining close to the theoretical value
in which all of the neutral gas would be ionised in a large spiral
galaxy (QHI=2.9×1056subscript𝑄HI2.9superscript1056Q_{\text{HI}}=2.9\times 10^{56}italic_Q start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT = 2.9 × 10 start_POSTSUPERSCRIPT 56 end_POSTSUPERSCRIPT ionising photons s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT).
We also rule out other effects (excitation by the radio
continuum and changing gas properties) as the dominant cause for
the decrease in the detection rate with redshift. Furthermore, from the
maximum theoretical column density we find that the five high
column density systems have spin temperatures close to those of the
Milky Way (Tspin∼<300superscriptsimilar-tosubscript𝑇spin300T_{\rm spin}\stackrel{{\scriptstyle<}}{{{}_{\sim}}}300italic_T start_POSTSUBSCRIPT roman_spin end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG start_FLOATSUBSCRIPT ∼ end_FLOATSUBSCRIPT end_ARG start_ARG < end_ARG end_RELOP 300 K), whereas, from our model of a
gaseous galactic disk, the HI detection at QHI=2.9×1056subscript𝑄HI2.9superscript1056Q_{\text{HI}}=2.9\times 10^{56}italic_Q start_POSTSUBSCRIPT HI end_POSTSUBSCRIPT = 2.9 × 10 start_POSTSUPERSCRIPT 56 end_POSTSUPERSCRIPT s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT yields Tspin∼10 000similar-tosubscript𝑇spin10000T_{\rm spin}\sim 10\,000italic_T start_POSTSUBSCRIPT roman_spin end_POSTSUBSCRIPT ∼ 10 000 K,
consistent with the gas being highly ionised.",[''],['Zealand']
,[''],[]
"The recognition of human activities based on WiFi Channel State Information (CSI) enables contactless and visual privacy-preserving sensing in indoor environments. However, poor model generalization, due to varying environmental conditions and sensing hardware, is a well-known problem in this space. To address this issue, in this work, data augmentation techniques commonly used in image-based learning are applied to WiFi CSI to investigate their effects on model generalization performance in cross-scenario and cross-system settings. In particular, we focus on the generalization between line-of-sight (LOS) and non-line-of-sight (NLOS) through-wall scenarios, as well as on the generalization between different antenna systems, which remains under-explored. We collect and make publicly available a dataset of CSI amplitude spectrograms of human activities. Utilizing this data, an ablation study is conducted in which activity recognition models based on the EfficientNetV2 architecture are trained, allowing us to assess the effects of each augmentation on model generalization performance. The gathered results show that specific combinations of simple data augmentation techniques applied to CSI amplitude data can significantly improve cross-scenario and cross-system generalization.","['Index', 'Terms: ', 'Data', 'Augmentation,', 'Model', 'Generalization,', 'Human', 'Activity', 'Recognition,', 'WiFi,', 'Channel', 'State', 'Information']",['martin.kampel}@tuwien.ac.at']
"Exploring generative model training for synthetic tabular data, specifically in sequential contexts such as credit card transaction data, presents significant challenges. This paper addresses these challenges, focusing on attaining both high fidelity to actual data and optimal utility for machine learning tasks. We introduce five pre-processing schemas to enhance the training of the Conditional Probabilistic Auto-Regressive Model (CPAR), demonstrating incremental improvements in the synthetic data’s fidelity and utility. Upon achieving satisfactory fidelity levels, our attention shifts to training fraud detection models tailored for time-series data, evaluating the utility of the synthetic data. Our findings offer valuable insights and practical guidelines for synthetic data practitioners in the finance sector, transitioning from real to synthetic datasets for training purposes, and illuminating broader methodologies for synthesizing credit card transaction time series.",[''],[]
,[''],[]
"We show that the seemingly different methods used to derive non-Lorentzian (Galilean and Carrollian) gravitational theories from Lorentzian ones are equivalent. Specifically, the pre-nonrelativistic and the pre-ultralocal parametrizations can be constructed from the gauging of the Galilei and Carroll algebras, respectively. Also, the pre-ultralocal approach of taking the Carrollian limit is equivalent to performing the ADM decomposition and then setting the signature of the Lorentzian manifold to zero. We use this uniqueness to write a generic expansion for the curvature tensors and construct Galilean and Carrollian limits of all metric theories of gravity of finite order ranging from the f⁢(R)𝑓𝑅f(R)italic_f ( italic_R ) gravity to a completely generic higher derivative theory, the f⁢(gμ⁢ν,Rμ⁢ν⁢σ⁢ρ,∇μ)𝑓subscript𝑔𝜇𝜈subscript𝑅𝜇𝜈𝜎𝜌subscript∇𝜇f(g_{\mu\nu},R_{\mu\nu\sigma\rho},\nabla_{\mu})italic_f ( italic_g start_POSTSUBSCRIPT italic_μ italic_ν end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_μ italic_ν italic_σ italic_ρ end_POSTSUBSCRIPT , ∇ start_POSTSUBSCRIPT italic_μ end_POSTSUBSCRIPT ) gravity. We present an algorithm for calculation of the n𝑛nitalic_n-th order of the Galilean and Carrollian expansions that transforms this problem into a constrained optimization problem. We also derive the condition under which a gravitational theory becomes a modification of general relativity in both limits simultaneously.",[''],"['Republic', 'Republic']"
"After making correct, and then improving, our definition of the category of irregular mixed Hodge modules thanks to Mochizuki’s recent results, we show how these results allow us to obtain Kodaira-Saito-type vanishing theorems for the irregular Hodge filtration of irregular mixed Hodge modules.",[''],[]
"Recently, Bemrose et al. [2] developed a theory of weaving frames, which was motivated by a problem regarding distributed signal processing. In this present article, we introduce the atomic g𝑔gitalic_g-system and we generalize some of the known results in continuous L𝐿Litalic_L-frames, weaving continuous and weaving continuous g𝑔gitalic_g-frames, also we study weaving continuous L𝐿Litalic_L-g𝑔gitalic_g-frames in Hilbert spaces.
Moreover, we study the behaviour continuous L𝐿Litalic_L-g𝑔gitalic_g-frames under some perturbations, and we show that approximate L𝐿Litalic_L-duals are stable under small perturbation and that it is possible to remove some elements of a woven continuous L𝐿Litalic_L-g𝑔gitalic_g-frame and still have a woven continuous L𝐿Litalic_L-g𝑔gitalic_g-frame.","['Key words and phrases:', 'Continuous', 'K𝐾Kitalic_K-frames,', 'Continuous g𝑔gitalic_g-frames,', 'Weaving continuous', 'K𝐾Kitalic_K-g𝑔gitalic_g-frames, perturbation.']",[]
"Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a naïve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",[''],[]
"Recent advancements in deep neural networks have markedly enhanced the
performance of computer vision tasks, yet the specialized nature of
these networks often necessitates extensive data and high computational
power. Addressing these requirements, this study presents a novel neural
network model adept at optical character recognition (OCR) across
diverse domains, leveraging the strengths of multi-task learning to
improve efficiency and generalization. The model is designed to achieve
rapid adaptation to new domains, maintain a compact size conducive to
reduced computational resource demand, ensure high accuracy, retain
knowledge from previous learning experiences, and allow for
domain-specific performance improvements without the need to retrain
entirely. Rigorous evaluation on open datasets has validated the model’s
ability to significantly lower the number of trainable parameters
without sacrificing performance, indicating its potential as a scalable
and adaptable solution in the field of computer vision, particularly for
applications in optical text recognition.",[''],[]
,[''],[]
,[''],"['md-imran.hossen1@louisiana.edu', 'sai-venkatesh.chilukoti1@louisiana.edu', 'liqun.shan@louisiana.edu', 'vtida001@csbsju.edu', 'xiali.hei@louisiana.edu']"
"Devising procedures for downstream task-oriented generative model selections is an unresolved problem of practical importance. Existing studies focused on the utility of a single family of generative models. They provided limited insights on how synthetic data practitioners select the best family generative models for synthetic training tasks given a specific combination of machine learning model class and performance metric. In this paper, we approach the downstream task-oriented generative model selections problem in the case of training fraud detection models and investigate the best practice given different combinations of model interpretability and model performance constraints. Our investigation supports that, while both Neural Network(NN)-based and Bayesian Network(BN)-based generative models are both good to complete synthetic training task under loose model interpretability constrain, the BN-based generative models is better than NN-based when synthetic training fraud detection model under strict model interpretability constrain. Our results provides practical guidance for machine learning practitioner who is interested in replacing their training dataset from real to synthetic, and shed lights on more general downstream task-oriented generative model selection problems.",[''],[]
,[''],[]
,[''],[]
"We analyse XMM-Newton RGS spectra of Wolf-Rayet (WR) 140, an archetype long-period eccentric WR+O colliding wind binary.
We evaluate the spectra of O and Fe emission lines and find that the plasmas emitting these lines have the largest approaching velocities with the largest velocity dispersions
between phases 0.935 and 0.968 where the inferior conjunction of the O star occurs.
This behaviour is the same as
that of the Ne line-emission plasma presented in our previous paper.
We perform diagnosis of electron number density nesubscript𝑛en_{\rm e}italic_n start_POSTSUBSCRIPT roman_e end_POSTSUBSCRIPT using He-like triplet lines of O and Ne-like Fe-L lines.
The former results in a conservative upper limit of ne≲1010less-than-or-similar-tosubscript𝑛esuperscript1010n_{\rm e}\lesssim 10^{10}italic_n start_POSTSUBSCRIPT roman_e end_POSTSUBSCRIPT ≲ 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT-101212{}^{12}start_FLOATSUPERSCRIPT 12 end_FLOATSUPERSCRIPT cm−33{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT on the O line-emission site, while the latter can not impose any constraint on the Fe line-emission site because of statistical limitations.
We calculate the line-of-sight velocity and its dispersion separately along the shock cone. By comparing the observed and calculated line-of-sight velocities,
we update the distance of the Ne line-emission site from the stagnation point.
By assuming radiative cooling of the Ne line-emission plasma using the observed temperature and the local stellar wind density, we estimate the line-emission site extends along the shock cone by at most ±plus-or-minus\pm±58 per cent (phase 0.816) of the distance from the stagnation point.
In this framework, excess of the observed velocity dispersion over the calculated one is ascribed to
turbulence in the hot-shocked plasma at earlier orbital phases of 0.816, 0.912, and 0.935, with the largest velocity dispersion of 340-630 km s−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT at phase 0.912.",[''],[]
,[''],"['China', 'UK', 'China', 'China']"
"Neural radiance fields (NeRFs) are promising 3D representations for scenes, objects, and humans. However, most existing methods require multi-view inputs and per-scene training, which limits their real-life applications. Moreover, current methods focus on single-subject cases, leaving scenes of interacting hands that involve severe inter-hand occlusions and challenging view variations remain unsolved. To tackle these issues, this paper proposes a generalizable visibility-aware NeRF (VA-NeRF) framework for interacting hands. Specifically, given an image of interacting hands as input, our VA-NeRF first obtains a mesh-based representation of hands and extracts their corresponding geometric and textural features. Subsequently, a feature fusion module that exploits the visibility of query points and mesh vertices is introduced to adaptively merge features of both hands, enabling the recovery of features in unseen areas. Additionally, our VA-NeRF is optimized together with a novel discriminator within an adversarial learning paradigm. In contrast to conventional discriminators that predict a single real/fake label for the synthesized image, the proposed discriminator generates a pixel-wise visibility map, providing fine-grained supervision for unseen areas and encouraging the VA-NeRF to improve the visual quality of synthesized images. Experiments on the Interhand2.6M dataset demonstrate that our proposed VA-NeRF outperforms conventional NeRFs significantly. Project Page: https://github.com/XuanHuang0/VANeRF.",[''],[]
,[''],[]
,[''],[]
"Ramanujan’s celebrated partition congruences modulo ℓ∈{5,7,11}ℓ5711\ell\in\{5,7,11\}roman_ℓ ∈ { 5 , 7 , 11 } assert that



p⁢(ℓ⁢n+δℓ)≡0(modℓ),𝑝ℓ𝑛subscript𝛿ℓannotated0pmodℓp(\ell n+\delta_{\ell})\equiv 0\pmod{\ell},italic_p ( roman_ℓ italic_n + italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) ≡ 0 start_MODIFIER ( roman_mod start_ARG roman_ℓ end_ARG ) end_MODIFIER ,



where 0<δℓ<ℓ0subscript𝛿ℓℓ0<\delta_{\ell}<\ell0 < italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT < roman_ℓ satisfies 24⁢δℓ≡1(modℓ).24subscript𝛿ℓannotated1pmodℓ24\delta_{\ell}\equiv 1\pmod{\ell}.24 italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ≡ 1 start_MODIFIER ( roman_mod start_ARG roman_ℓ end_ARG ) end_MODIFIER . By proving Subbarao’s Conjecture, Radu showed that there are no such congruences when it comes to parity. There are infinitely many odd (resp. even) partition numbers in every arithmetic progression.
For primes ℓ≥5,ℓ5\ell\geq 5,roman_ℓ ≥ 5 , we give a new proof of the conclusion that there are infinitely many m𝑚mitalic_m for which p⁢(ℓ⁢m+δℓ)𝑝ℓ𝑚subscript𝛿ℓp(\ell m+\delta_{\ell})italic_p ( roman_ℓ italic_m + italic_δ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) is odd. This proof uses a generalization, due to the second author and Ramsey, of a result of Mazur in his classic paper on the Eisenstein ideal. We also refine a classical criterion of Sturm for modular form congruences, which allows us to show that the smallest such m𝑚mitalic_m satisfies m<(ℓ2−1)/24,𝑚superscriptℓ2124m<(\ell^{2}-1)/24,italic_m < ( roman_ℓ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 1 ) / 24 ,
representing a significant improvement to the previous bound.",['Key words and phrases: partition function congruences'],[]
"A hybrid encryption (HE) system is an efficient public key encryption system for arbitrarily long messages.
An HE system consists of a public key component called
key encapsulation mechanism (KEM), and a symmetric key component called data encapsulation mechanism (DEM). The HE encryption algorithm uses a KEM generated key k to encapsulate the message using DEM, and send the ciphertext together with the encapsulaton of k, to the decryptor who decapsulates k and uses it to decapsulate the message using the corresponding KEM and DEM components. The KEM/DEM composition theorem proves that if KEM and DEM satisfy well-defined security notions, then HE will be secure with well defined security.
We introduce HE in correlated randomness model where the encryption and decryption algorithms have samples of correlated random variables that are partially leaked to the adversary. Security of the new KEM/DEM paradigm is defined against computationally unbounded or polynomially bounded adversaries. We define iKEM and cKEM with respective information theoretic computational security, and prove a composition theorem for them and a computationally secure DEM, resulting in secure HEs with proved computational security (CPA and CCA) and without any computational assumption.
We construct two iKEMs that provably satisfy the required security notions of the composition theorem.
The iKEMs are used to construct two efficient quantum-resistant HEs when used with an AES based DEM.
We also define and construct combiners with proved security that combine the new KEM/DEM paradigm of HE with the traditional public key based paradigm of HE.","['Index', 'Terms: ', 'Post-quantum cryptography,', 'Hybrid encryption,', 'Correlated randomness model,', 'Key', 'Encapsulation', 'Mechanism.']",[]
"Stochastic gravitational-wave (GW) background (SGWB) contains information about
the early Universe and astrophysical processes. The recent evidence of SGWB by
pulsar timing arrays in the nanohertz band is a breakthrough in the GW
astronomy. For ground-based GW detectors, while unfortunately in data analysis
the SGWB can be masked by loud GW events from compact binary coalescences
(CBCs). Assuming a next-generation ground-based GW detector network, we
investigate the potential for detecting the astrophysical and cosmological SGWB
with non-CBC origins by subtracting recovered foreground signals of loud CBC
events. As an extension of the studies by Sachdev et al. (2020) and Zhou
et al. (2023), we incorporate aligned spin parameters in our waveform
model. Because of the inclusion of spins, we obtain significantly more
pessimistic results than the previous work, where the residual energy density of
foreground is even larger than the original background. The degeneracy between
the spin parameters and symmetric mass ratio is strong in the parameter
estimation process and it contributes most to the imperfect foreground
subtraction. Our results have important implications for assessing the
detectability of SGWB from non-CBC origins for ground-based GW detectors.",[''],"['China', 'China', 'China', 'China', 'China']"
"In this note, we mainly focus on real and complex algebras, and occasionally on algebras over general fields. We show how to develop the spectral theory in the context of complex (resp. real) alternative topological algebras.
Along the way, the spectral theory is used to prove the counterparts of the well-known theorems of Gelfand-Mazur, Frobenius, and Zorn in the setting of topological alternative algebras whose topological duals separate their elements. We prove that vector space norms on quadratic real algebras are uniquely determined under a mild condition on the norms; more precisely, given a positive integer k>1𝑘1k>1italic_k > 1, on any real quadratic algebra, there exists at most one nonzero vector space norm, say, ∥.∥\|.\|∥ . ∥, satisfying the identity ‖ak‖=‖a‖knormsuperscript𝑎𝑘superscriptnorm𝑎𝑘\|a^{k}\|=\|a\|^{k}∥ italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∥ = ∥ italic_a ∥ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT on the algebra. A consequence of this result is that given a positive integer k>1𝑘1k>1italic_k > 1, the Euclidean norm |.||.|| . | on ℝnsubscriptℝ𝑛\mathbb{R}_{n}blackboard_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, the
real Cayley-Dickson algebra of dimension 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, is the only nonzero real vector space norm satisfying the identity |xk|=|x|ksuperscript𝑥𝑘superscript𝑥𝑘|x^{k}|=|x|^{k}| italic_x start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | = | italic_x | start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT on ℝnsubscriptℝ𝑛\mathbb{R}_{n}blackboard_R start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Among other things, we present simple proofs of the algebraic versions of the celebrated theorems of Frobenius, Zorn, and Gelfand-Mazur, and revisit their topological counterparts, e.g., theorems of Albert, Kaplansky, and Urbanik-Wright to name a few, in several settings.","['Key words and phrases: nonassociative algebras, power-associative/alternative algebras, division algebras, topological/normed/C*- algebras, spectrum, real, complex, quaternion, octonion numbers,', 'Frobenius/Zorn/Gelfand-Mazur theorems']",[]
,[''],[]
"The causal inference literature frequently focuses on estimating the mean of the potential outcome, whereas the quantiles of the potential outcome may carry important additional information. We propose a universal approach, based on the inverse estimating equations, to generalize a wide class of causal inference solutions from estimating the mean of the potential outcome to its quantiles.
We assume that an identifying moment function is available to identify the mean of the threshold-transformed potential outcome, based on which a convenient construction of the estimating equation of quantiles of potential outcome is proposed. In addition, we also give a general construction of the efficient influence functions of the mean and quantiles of potential outcomes, and identify their connection. We motivate estimators for the quantile estimands with the efficient influence function, and develop their asymptotic properties when either parametric models or data-adaptive machine learners are used to estimate the nuisance functions. A broad implication of our results is that one can rework the existing result for mean causal estimands to facilitate causal inference on quantiles, rather than starting from scratch. Our results are illustrated by several examples.",[''],[]
"The rise of multimodal large language models (MLLMs) has spurred interest in language-based driving tasks. However, existing research typically focuses on limited tasks and often omits key multi-view and temporal information which is crucial for robust autonomous driving. To bridge these gaps, we introduce NuInstruct, a novel dataset with 91K multi-view video-QA pairs across 17 subtasks, where each task demands holistic information ( e.g., temporal, multi-view, and spatial), significantly elevating the challenge level. To obtain NuInstruct, we propose a novel SQL-based method to generate instruction-response pairs automatically, which is inspired by the driving logical progression of humans. We further present BEV-InMLLM, an end-to-end method for efficiently deriving instruction-aware Bird’s-Eye-View (BEV) features, language-aligned for large language models. BEV-InMLLM integrates multi-view, spatial awareness, and temporal semantics to enhance MLLMs’ capabilities on NuInstruct tasks. Moreover, our proposed BEV injection module is a plug-and-play method for existing MLLMs. Our experiments on NuInstruct demonstrate that BEV-InMLLM significantly outperforms existing MLLMs, e.g. 9%percent99\%9 % improvement on various tasks. We plan to release our NuInstruct for future research development.",[''],[]
"Since distribution shifts are likely to occur after a model’s deployment and can drastically decrease the model’s performance, online test-time adaptation (TTA) continues to update the model during test-time, leveraging the current test data. In real-world scenarios, test data streams are not always independent and identically distributed (i.i.d.). Instead, they are frequently temporally correlated, making them non-i.i.d. Many existing methods struggle to cope with this scenario. In response, we propose a diversity-aware and category-balanced buffer that can simulate an i.i.d. data stream, even in non-i.i.d. scenarios. Combined with a diversity and entropy-weighted entropy loss, we show that a stable adaptation is possible on a wide range of corruptions and natural domain shifts, based on ImageNet. We achieve state-of-the-art results on most considered benchmarks.",[''],[]
"We study properties of the Maxwell electromagnetic invariant
in the external region of spinning and charged horizonless stars.
We analytically find that the minimum negative
value of the Maxwell electromagnetic invariant is obtained
on the equator of the star surface.
We are interested in scalar fields
non-minimally coupled to the Maxwell electromagnetic invariant.
The negative enough Maxwell electromagnetic invariant can lead to a
negative effective mass term, which forms a
binding potential well for the scalar field.
It means that the scalar field
coupled to the Maxwell electromagnetic invariant may mostly
exist around the surface of the star on the equator.",[''],['China']
,[''],[]
"More than one hundred tidal disruption events (TDEs) have been detected at multi-bands, which can be viewed as extreme laboratories to investigate the accretion physics and gravity in the immediate vicinity of massive black holes (MBHs). Future transient surveys are expected to detect several tens of thousands of TDEs, among which a small fraction may be strongly gravitationally lensed by intervening galaxies. In this paper, we statistically etsimate the detection rate of lensed TDEs, with dependence on the limiting magnitude of the transient all-sky surveys searching for them. We find that the requisite limiting magnitude for an all-sky transient survey to observe at least 1111 yr−11{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT is ≳21.3greater-than-or-equivalent-toabsent21.3\gtrsim 21.3≳ 21.3, 21.221.221.221.2, and 21.521.521.521.5 mag in the u-, g-, and z-bands, respectively. If the limiting magnitude of the all-sky survey can reach ∼25−26similar-toabsent2526\sim 25-26∼ 25 - 26 mag in the u-, g-, and z-bands, the detection rate can be upto about several tens to hundreds per year. The discovery and identification of the first image of the lensed TDE can be taken as an early-warning of the second and other subsequent images, which may enable detailed monitoring of the pre-peak photometry and spectroscopy evolution of the TDE. The additional early-stage information may help to constrain the dynamical and radiation processes involving in the TDEs.","['Accretion (14);', 'Gravitational lensing (670);', 'Supermassive black holes (1663);', 'Tidal disruption (1696);', 'Time domain astronomy(2019);', 'Transient sources (1851)']","['China;', 'China', 'China;', 'China', 'China', 'China;']"
"In this paper we first show that among all double-toroidal and triple-toroidal finite graphs only K8⊔9⁢K1square-unionsubscript𝐾89subscript𝐾1K_{8}\sqcup 9K_{1}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, K8⊔5⁢K2square-unionsubscript𝐾85subscript𝐾2K_{8}\sqcup 5K_{2}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 5 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, K8⊔3⁢K4square-unionsubscript𝐾83subscript𝐾4K_{8}\sqcup 3K_{4}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 3 italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT, K8⊔9⁢K3square-unionsubscript𝐾89subscript𝐾3K_{8}\sqcup 9K_{3}italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 italic_K start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, K8⊔9⁢(K1∨3⁢K2)square-unionsubscript𝐾89subscript𝐾13subscript𝐾2K_{8}\sqcup 9(K_{1}\vee 3K_{2})italic_K start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT ⊔ 9 ( italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∨ 3 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ), 3⁢K63subscript𝐾63K_{6}3 italic_K start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT and 3⁢K6⊔4⁢K4⊔6⁢K2square-union3subscript𝐾64subscript𝐾46subscript𝐾23K_{6}\sqcup 4K_{4}\sqcup 6K_{2}3 italic_K start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT ⊔ 4 italic_K start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ⊔ 6 italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT can be realized as commuting graphs of finite groups. As consequences of our results we also show that for any finite non-abelian group G𝐺Gitalic_G if the commuting graph of G𝐺Gitalic_G (denoted by Γc⁢(G)subscriptΓ𝑐𝐺\Gamma_{c}(G)roman_Γ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_G )) is double-toroidal or triple-toroidal then Γc⁢(G)subscriptΓ𝑐𝐺\Gamma_{c}(G)roman_Γ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_G ) and its complement satisfy Hansen-Vukičević Conjecture and E-LE conjecture. In the process we find a non-complete graph, namely the non-commuting graph of the group (ℤ3×ℤ3)⋊Q8right-normal-factor-semidirect-productsubscriptℤ3subscriptℤ3subscript𝑄8(\mathbb{Z}_{3}\times\mathbb{Z}_{3})\rtimes Q_{8}( blackboard_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT × blackboard_Z start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) ⋊ italic_Q start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT, that is hyperenergetic. This gives a new counter example to a conjecture of Gutman regarding hyperenergetic graphs.",[''],"['Nath)', 'Nath)']"
,[''],[]
,[''],[]
"The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones).
To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm.
Then, considering two kinds of representative and heterogeneous attack
mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we implement another instance called MMIA-SafeCompress by
extending SafeCompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. We conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. The results show the effectiveness and generalizability of our framework. We also discuss how to adapt SafeCompress to other attacks besides membership inference attack, demonstrating the flexibility of SafeCompress.","['Index', 'Terms: ', 'AI software safe compression, test-driven development, heterogeneous membership inference attack.']",[]
"The sensitivity of Impact Factors (IFs) to journal size causes systematic bias in IF rankings, in a process akin to stacking the cards: A random “journal” of n𝑛nitalic_n papers can attain a range of IF values that decreases rapidly with size, as ∼1/nsimilar-toabsent1𝑛\sim 1/\sqrt{n}∼ 1 / square-root start_ARG italic_n end_ARG . The Central Limit Theorem, which underlies this effect, allows us also to correct for it by standardizing citation averages for scale and subject in a geometrically intuitive manner analogous to calculating the z𝑧zitalic_z-score. We thus propose the ΦΦ\Phiroman_Φ index, a standardized scale- and subject-independent citation average. The ΦΦ\Phiroman_Φ index passes the “random sample test”, a simple check for scale and subject independence that we argue ought to be used for every citation indicator. We present ΦΦ\Phiroman_Φ index rankings for 12,173 journals using data from the 2020 Journal Citation Reports. We show how scale standardization alone affects rankings, then we demonstrate the additional effect of subject standardization for monodisciplinary journals, and we discuss how to treat multidisciplinary journals.
ΦΦ\Phiroman_Φ index rankings offer a clear improvement over IF rankings. And because the ΦΦ\Phiroman_Φ index methodology is general, it can also be applied to compare individual researchers, universities, or countries.",[''],[]
"This paper concerns the scattering problem for a nonlinear medium of compact support, D𝐷Ditalic_D, with second-harmonic generation. Such a medium, when probed with monochromatic light beams at frequency ω𝜔\omegaitalic_ω, generates additional waves at frequency 2⁢ω2𝜔2\omega2 italic_ω. The response of the medium is governed by a system of two coupled semilinear partial differential equations for the electric fields at frequency ω𝜔\omegaitalic_ω and 2⁢ω2𝜔2\omega2 italic_ω. We investigate whether there are situations in which the generated 2⁢ω2𝜔2\omega2 italic_ω wave is localized inside D𝐷Ditalic_D, that is, the nonlinear interaction of the medium with the probing wave is invisible to an outside observer. This leads to the analysis of a semilinear elliptic system formulated in D𝐷Ditalic_D with non-standard boundary conditions. The analysis presented here sets up a mathematical framework needed to investigate a multitude of questions related to nonlinear scattering with second-harmonic generation.",[''],[]
"With copper-substituted lead apatite below room temperature, we observe diamagnetic dc magnetization under magnetic field of 25 Oe with remarkable bifurcation between zero-field-cooling and field-cooling measurements, and under 200 Oe it changes to be paramagnetism. A glassy memory effect is found during cooling. Typical hysteresis loops for superconductors are detected below 250 K, along with an asymmetry between forward and backward sweep of magnetic field. Our experiment suggests at room temperature the Meissner effect is possibly present in this material.",[''],['China']
"We discuss the critical points of modular forms, or more generally the zeros of quasimodular forms of depth 1111 for PSL2⁢(ℤ)subscriptPSL2ℤ\mathrm{PSL}_{2}(\mathbb{Z})roman_PSL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_Z ). In particular, we consider the derivatives of the unique weight k𝑘kitalic_k modular forms fksubscript𝑓𝑘f_{k}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with the maximal number of consecutive zero Fourier coefficients following the constant 1111. Our main results state that (1) every zero of a depth 1111 quasimodular form near the derivative of the Eisenstein series in the standard fundamental domain lies on the geodesic segment {z∈ℍ:ℜ⁡(z)=1/2}conditional-set𝑧ℍ𝑧12\{z\in\mathbb{H}:\Re(z)=1/2\}{ italic_z ∈ blackboard_H : roman_ℜ ( italic_z ) = 1 / 2 }, and (2) more than half of zeros of fksubscript𝑓𝑘f_{k}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in the standard fundamental domain lie on the geodesic segment {z∈ℍ:ℜ⁡(z)=1/2}conditional-set𝑧ℍ𝑧12\{z\in\mathbb{H}:\Re(z)=1/2\}{ italic_z ∈ blackboard_H : roman_ℜ ( italic_z ) = 1 / 2 } for large enough k𝑘kitalic_k with k≡0(mod12)𝑘annotated0pmod12k\equiv 0\pmod{12}italic_k ≡ 0 start_MODIFIER ( roman_mod start_ARG 12 end_ARG ) end_MODIFIER.",[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
,[''],[]
"Text-to-image diffusion models have demonstrated unprecedented abilities at flexible and realistic image synthesis.
However, the iterative process required to produce a single image is costly and incurs a high latency, prompting researchers to further investigate its efficiency.
Typically, improvements in latency have been achieved in two ways: (1) training smaller models through knowledge distillation (KD); and (2) adopting techniques from ODE-theory to facilitate larger step sizes.
In contrast, we propose a training-free approach that does not alter the step-size of the sampler.
Specifically, we find the repeated calculation of attention maps to be both costly and redundant; therefore, we propose a structured reuse of attention maps during sampling.
Our initial reuse policy is motivated by rudimentary ODE-theory, which suggests that reuse is most suitable late in the sampling procedure.
After noting a number of limitations in this theoretical approach, we empirically search for a better policy.
Unlike methods that rely on KD, our reuse policies can easily be adapted to a variety of setups in a plug-and-play manner.
Furthermore, when applied to Stable Diffusion-1.5, our reuse policies reduce latency with minimal repercussions on sample quality.",[''],[]
,[''],[]
"Unsupervised Anomaly Detection (UAD) with incremental training is crucial in industrial manufacturing, as unpredictable defects make obtaining sufficient labeled data infeasible.
However, continual learning methods primarily rely on supervised annotations, while the application in UAD is limited due to the absence of supervision.
Current UAD methods train separate models for different classes sequentially, leading to catastrophic forgetting and a heavy computational burden.
To address this issue, we introduce a novel Unsupervised Continual Anomaly Detection framework called UCAD, which equips the UAD with continual learning capability through contrastively-learned prompts.
In the proposed UCAD, we design a Continual Prompting Module (CPM) by utilizing a concise key-prompt-knowledge memory bank to guide task-invariant ‘anomaly’ model predictions using task-specific ‘normal’ knowledge.
Moreover, Structure-based Contrastive Learning (SCL) is designed with the Segment Anything Model (SAM) to improve prompt learning and anomaly segmentation results.
Specifically, by treating SAM’s masks as structure, we draw features within the same mask closer and push others apart for general feature representations.
We conduct comprehensive experiments and set the benchmark on unsupervised continual anomaly detection and segmentation, demonstrating that our method is significantly better than anomaly detection methods, even with rehearsal training.
The code will be available at https://github.com/shirowalker/UCAD.",[''],[]
"Programming problems can be solved in a multitude of functionally correct ways, but the quality of these solutions (e.g. readability, maintainability) can vary immensely.
When code quality is poor, symptoms emerge in the form of ‘code smells’, which are specific negative characteristics (e.g. duplicate code) that can be resolved by applying refactoring patterns.
Many undergraduate computing curricula train students on this software engineering practice, often doing so via exercises on unfamiliar instructor-provided code.
Our observation, however, is that this makes it harder for novices to internalise refactoring as part of their own development practices.
In this paper, we propose a new approach to teaching refactoring, in which students must first complete a programming exercise constrained to ensure they will produce a code smell.
This simple intervention is based on the idea that learning refactoring is easier if students are familiar with the code (having built it), that it brings refactoring closer to their regular development practice, and that it presents a powerful opportunity to learn from a ‘mistake’.
We designed and conducted a study with 35 novice undergraduates in which they completed various refactoring exercises alternately taught using a traditional and our ‘mistake-based’ approach, finding that students were significantly more effective and confident at completing exercises using the latter.","['Refactoring, code smells, code quality, software maintenance, software engineering, mistake-based learning, undergraduate course']","['UniversitySingapore', 'UniversitySingapore']"
"In this paper, our objective is to present a constraining principle governing the spectral properties of the sample covariance matrix. This principle exhibits harmonious behavior across diverse limiting frameworks, eliminating the need for constraints on the rates of dimension p𝑝pitalic_p and sample size n𝑛nitalic_n, as long as they both tend to infinity. We accomplish this by employing a suitable normalization technique on the original sample covariance matrix. Following this, we establish a harmonic central limit theorem for linear spectral statistics within this expansive framework. This achievement effectively eliminates the necessity for a bounded spectral norm on the population covariance matrix and relaxes constraints on the rates of dimension p𝑝pitalic_p and sample size n𝑛nitalic_n, thereby significantly broadening the applicability of these results in the field of high-dimensional statistics. We illustrate the power of the established results by considering the test for covariance structure under high dimensionality, freeing both p𝑝pitalic_p and n𝑛nitalic_n.","['62H15, 62B20, 62D10, ultra-high dimension\ncovariance matrix; central limit theorem; limiting spectral distribution; linear spectral statistics;', 'M-P law,']",[]
"Recent research at CHU Sainte-Justine’s Pediatric Critical Care Unit (PICU) has revealed that traditional machine learning methods, such as semi-supervised label propagation and K-nearest neighbors, outperform Transformer-based models in artifact detection from PPG signals, mainly when data is limited. This study addresses the underutilization of abundant unlabeled data by employing self-supervised learning (SSL) to extract latent features from these data, followed by fine-tuning on labeled data. Our experiments demonstrate that SSL significantly enhances the Transformer model’s ability to learn representations, thereby improving its robustness in artifact classification tasks. Among various SSL techniques—including masking, contrastive learning, and DINO (self-distillation with no labels)—contrastive learning exhibited the most stable and superior performance in small PPG datasets. Further, we delve into optimizing contrastive loss functions, which are crucial for contrastive SSL. Inspired by InfoNCE, we introduce a novel contrastive loss function that facilitates smoother training and better convergence, thereby enhancing performance in artifact classification. In summary, this study establishes the efficacy of SSL in leveraging unlabeled data, particularly in enhancing the capabilities of the Transformer model. This approach holds promise for broader applications in PICU environments, where annotated data is often limited.","['Index', 'Terms: \nclinical', 'PPG signals, self-supervised, contrastive learning, imbalanced classes, and artifact detection.']",[]
"In this paper, we investigate k𝑘kitalic_k-nonseparable (2≤k≤n)2𝑘𝑛(2\leq k\leq n)( 2 ≤ italic_k ≤ italic_n ) entanglement measures based on geometric mean of all entanglement values of k𝑘kitalic_k-partitions in n𝑛nitalic_n-partite quantum systems. We define a class of entanglement measures called k𝑘kitalic_k-GM concurrence which explicitly detect all k𝑘kitalic_k-nonseparable states in multipartite systems. It is rigorously shown that the k𝑘kitalic_k-GM concurrence complies with all the conditions of an entanglement measure. Compared to k𝑘kitalic_k-ME concurrence [Phys. Rev. A 86, 062323 (2012)], the measures proposed by us emerge several different aspects, embodying that (i) k𝑘kitalic_k-GM concurrence can reflect the differences in entanglement but k𝑘kitalic_k-ME concurrence fails at times, (ii) k𝑘kitalic_k-GM concurrence does not arise sharp peaks when the pure state being measured varies continuously, while k𝑘kitalic_k-ME concurrence appears discontinuity points, (iii) the entanglement order is sometimes distinct. In addition, we establish the relation between k𝑘kitalic_k-ME concurrence and k𝑘kitalic_k-GM concurrence, and further derive a strong lower bound on the k𝑘kitalic_k-GM concurrence by exploiting the permutationally invariant part of a quantum state. Furthermore, we parameterize k𝑘kitalic_k-GM concurrence to obtain two categories of more generalized entanglement measures, q𝑞qitalic_q-k𝑘kitalic_k-GM concurrence (q>1,2≤k≤n)formulae-sequence𝑞12𝑘𝑛(q>1,2\leq k\leq n)( italic_q > 1 , 2 ≤ italic_k ≤ italic_n ) and α𝛼\alphaitalic_α-k𝑘kitalic_k-GM concurrence (0≤α<1,2≤k≤n)formulae-sequence0𝛼12𝑘𝑛(0\leq\alpha<1,2\leq k\leq n)( 0 ≤ italic_α < 1 , 2 ≤ italic_k ≤ italic_n ), which fulfill the properties possessed by k𝑘kitalic_k-GM concurrence as well. Moreover, α𝛼\alphaitalic_α-2222-GM concurrence (0<α<1)0𝛼1(0<\alpha<1)( 0 < italic_α < 1 ), as a type of genuine multipartite entanglement measures, is proven in detail satisfying the requirement that the GHZ state is more entangled than the W𝑊Witalic_W state in multiqubit systems.",[''],"['China', 'China']"
"In our previous work, we introduced McKinsey-Tarski algebras (MT-algebras for short) as an alternative pointfree approach to topology. Here we study local compactness in MT-algebras.
We establish the Hofmann-Mislove theorem
for sober MT-algebras, using which we develop the MT-algebra versions of such well-known dualities in pointfree topology as
Hofmann-Lawson, Isbell, and Stone dualities. This yields
a new perspective on these classic results.","['Key words and phrases:', 'Interior operator, pointfree topology, duality theory, local compactness, compactness']",[]
,[''],[]
,[''],[]
